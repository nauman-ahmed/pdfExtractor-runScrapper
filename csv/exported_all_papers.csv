link,title,author_email,abstract,published_year,keywords,publication_title,created_on,business_score,business_score_justification
https://www.sciencedirect.com/science/article/pii/S0883902624000806,Reaching out or going it alone? How birth order shapes networking behavior and entrepreneurial action in the face of obstacles,Julia M.=Kensbock: kensbock@uni-bremen.de,"Abstract
Whether individuals grew up as first-born or later-born siblings in their families can influence their behavior well into adulthood. This study examines the impact of birth order on networking behavior and entrepreneurial action, integrating birth order theory with psychological threat response theories. It suggests that first-born and later-born entrepreneurs inherently differ in their social responses to the uncertainties and threats of entrepreneurship, which affects how intensively they engage in networking behavior and entrepreneurial action. Three empirical studies involving over 900 entrepreneurs were conducted using between-family analysis. The results indicate that later-borns, overall, exhibit more adaptive behavior than first-borns when navigating the challenges of entrepreneurship: Especially when facing severe threatening obstacles, later-born entrepreneurs tend to intensify their efforts to build, seek, and use external networks, which enables them to engage in more entrepreneurial action. This study offers new insights into the relationship between birth order and entrepreneurship, enhancing our understanding of why some individuals may respond more adaptively to threats, network more intensively, and exploit opportunities more actively than others.", March 2025,"Birth order, Entrepreneurial action, Networking, Obstacles, Family",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000776,Hype: Marker and maker of entrepreneurial culture,R. Daniel=Wadhwani: dwadhwani@marshall.usc.edu; Christina=Lubinski: cl.bhl@cbs.dk,"Abstract
This article extends existing scholarship that views hype primarily as an individual entrepreneurial storytelling strategy for generating excitement about a venture's future. We argue that hype also functions as a cultural marker, distinguishing entrepreneurial modes of communication and behavior from those of traditional corporate culture. By tracing the conceptual history of hype, we demonstrate that the term and its associated practices (a.) originated in early-twentieth-century criminal subcultures to distinguish them from respectable culture, (b.) was subsequently adopted by mid-twentieth-century countercultures to distinguish themselves from mainstream culture, and (c.) ultimately became a marker used by late twentieth-century startup culture to distinguish itself from corporate culture. Understanding these historical roots, we contend, illuminates key characteristics of contemporary Western startup culture: the valorization of revolutionary futures, the celebration of rule-breaking, and the embrace of social deviance as a hallmark of entrepreneurial authenticity. By historicizing hype in this manner, we can better appreciate both its “destructive” and “productive” dimensions and explore alternative modes of communication that are prevalent in other entrepreneurial contexts.", March 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000715,The body as a cultural resource for entrepreneurs in stigmatized settings: The case of sex toys by women for women,Neva=Bojovic: neva.bojovic@kedgebs.com; Raghu=Garud: rgarud@psu.edu; Mohammed=Cheded: m.cheded@lancaster.ac.uk,"Abstract
Entrepreneurs seeking legitimacy for their stigmatized products with mainstream audiences must deploy strategies to redefine their products' cultural significance. This paper investigates how the body, often a focal point of stigma, serves as the foundation for these strategies. Through an analysis of exemplary cases in the sex toy industry, we identify three strategies—visibilizing, obfuscating, and transforming—used by entrepreneurs to deal with different sources of stigma, including tribal stigma, blemishes, and abominations associated with the products. Our findings provide novel insights into the role of the body in entrepreneurial strategies to tackle stigma and gain legitimacy for their products, thereby contributing to the literatures on entrepreneurship in stigmatized settings and cultural entrepreneurship.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000612,Para-social mentoring: The effects of entrepreneurship influencers on entrepreneurs,Laura=D'Oria: ldoria@iastate.edu; David J.=Scheaf: David_Scheaf@baylor.edu; Timothy L.=Michaelis: tmichaelis@niu.edu; Michael P.=Lerman: mlerman@iastate.edu,"Abstract
Research on social media influencers and entrepreneurship tends to adopt an influencer-as-entrepreneur perspective by examining how influencers leverage social media as entrepreneurial opportunities. However, it remains unclear how entrepreneurs in the audience interpret and leverage influencer content in their entrepreneurial endeavors. Using a two-study approach, Study 1 inductively uncovers that entrepreneurs interpret entrepreneurship influencers' content as para-social mentoring—a one-to-many, mostly unreciprocated mentor-protégé relationship in which media users envision themselves as protégés and perceive media figures as providing individualized career-related and psychosocial support despite knowing that the media figures do not know intimate details about themselves or their circumstances. Our model posits that para-social mentoring between entrepreneurs and entrepreneurship influencers relates to critical entrepreneurship-related outcomes. Using data from 613 entrepreneurs, Study 2 deductively finds general support for the model derived from Study 1. Our study highlights how para-social mentoring operates like a double-edged sword that can benefit entrepreneurs while also exposing them to specific hazards not common in traditional mentoring.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000739,A listening model of venture growth: entrepreneurs' listening abilities and ventures' listening capabilities,Dean A.=Shepherd: Dshephe1@nd.edu,"Abstract
While we understand the importance of entrepreneurs listening to stakeholders, we lack a sufficient theory-driven understanding of why some entrepreneurs and their ventures can listen to their stakeholders more effectively than others. We offer a listening model of venture growth based on listening theories and the literatures on new ventures and capability development. Listening is initially facilitated by entrepreneurs' cognitive and behavioral processes, but continued venture growth creates a paradox for entrepreneurs. Listening to stakeholders may also deplete entrepreneurs' personal resources, diminishing their listening capacity. This paradox can be overcome by generating their ventures' listening capability—behavioral routines and attention structures for listening—enabling them to acquire and interpret quality information from stakeholders more effectively to build or adapt the capabilities necessary for venture growth. The ventures' listening capability acts as a dynamic capability, which itself can be dynamic. This listening model of venture growth contributes to the entrepreneurship literature on stakeholders, entrepreneurs' abilities, and ventures' capabilities and dynamic capabilities.
Executive summary
Entrepreneurs need to acquire resources from stakeholders to create and grow their ventures. Therefore, stakeholder enrollment is a critical task for entrepreneurs. The predominant research on stakeholder enrollment has been on entrepreneurs' overt behaviors to secure the support of stakeholders—a unidirectional communication pattern in which entrepreneurs communicate to audiences and stakeholders listen to and decide whether to commit their resources to ventures. However, entrepreneurs need to communicate and listen to their stakeholders. Although scholars recognize the importance of entrepreneurs listening to stakeholders, we lack sufficient understanding of why some entrepreneurs and their ventures can listen to their stakeholders more effectively than others and thus acquire and use stakeholder support critical for venture growth. Therefore, we ask, Why are some entrepreneurial actors more effective at listening to stakeholders than others?
To address this question, we integrate theories of listening and the literatures on new ventures and the creation of organizational capabilities to develop a listening model of venture growth. This model explains the importance and the limitations of entrepreneurs' listening ability in acquiring and interpreting stakeholder information for venture growth. Venture members can learn from and formalize entrepreneurs' listening ability to build ventures' listening capability, which overcomes the entrepreneurs' listening limitations. Ventures' listening capability includes acquiring and interpreting stakeholder information to inform and/or change additional capabilities critical for venture growth.
Specifically, the model begins with communication from stakeholders to an entrepreneur and their venture. The entrepreneur engages cognitively in listening to the stakeholders' communication and acquiring and interpreting this stakeholder information. The entrepreneur also listens behaviorally, providing back-channeling that encourages the stakeholders to share more high-quality information. The entrepreneur's listening ability can enhance and change the venture's capabilities. However, the entrepreneur's ability to notice and interpret stakeholder information is limited. Other venture members can learn the entrepreneur's cognitive and behavioral listening to represent an organizational-level listening capability. This listening capability is reflected in the venture's routines and attention structures.
The venture's listening capability can build and adapt the venture's nonlistening capabilities. The venture's capabilities drive venture growth. Because the listening capability generates and enables the interpretation of more high-quality stakeholder information, the venture can use this information to change its capabilities to obtain or maintain a tight fit with a changing environment. In doing so, the venture's listening capability represents a dynamic capability—listening can change the venture's capabilities.
As the venture grows, the strain on the entrepreneur's listening ability further constrains the entrepreneur as a source of information for building and adapting the venture's capabilities. Venture growth also stretches the venture's listening capability, leading to changes in this listening capability and thus building and adapting the venture's nonlistening capabilities for subsequent venture growth. Venture growth can also lead to an increase in stakeholders and, thus, more stakeholder information to be noticed and interpreted by the venture's listening capability and to adapt the venture's nonlistening capabilities if necessary.
With this work, we make three primary contributions to the entrepreneurship literature: We provide theoretical insights into (1) the workings of entrepreneurs' listening ability for promoting venture growth; (2) entrepreneurs' learning from their listening ability and formalizing this ability into organizational capabilities, which is critical for information to enact nonlistening capabilities for venture growth; and (3) a venture's listening capability as a dynamic capability.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000600,Innovation at the interface: A configurational approach to corporate venture capital,Magnus=Schückes: schueckes@bwl.uni-mannheim.de; Benedikt=Unger: benedikt.unger@economics.unibz.it; Tobias=Gutmann: tobias.gutmann@ebs.edu; Gerwin=Fels: fels@campus.tu-berlin.de,"Abstract
This study explores how corporate venture capital (CVC) units can be configured to effectively achieve innovation performance and succeed amidst the tensions they face at the intersection of the corporate and venture domain. Using a fuzzy-set qualitative comparative analysis (fsQCA) of 30 dedicated CVC investment arms, we analyze how successful units configure their internal arrangements in response to these tensions and generate various innovation outcomes for their parent organizations. We identify four different solutions for effective CVC unit configurations, highlighting that explorative and exploitative innovation success require different setups. Moreover, we find that more mature and explorative CVC units distance themselves via buffering from their corporate sponsor, while at the same time increasing their efforts to maintain deliberate connections via bridging to representatives of the very same corporate environment they stem from. For ambidextrous CVC units, a more dynamic setup that allows corporate leadership to selectively initiate collaboration with the corporate core when beneficial while facilitating distancing at other times proved successful. Our study contributes new evidence and theory on how CVC units can navigate tensions and balance competing demands at the interface of the corporate and venturing domains.", January 2025,"M13, L21, L22, O32",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000582,Legitimately distinct entrepreneurial stories in evolving market categories,Shannon=Younger: syounger@walton.uark.edu; Jonathan=Preedom: jcpreedom@lsu.edu; Chad=Navis: chadn@clemson.edu,"Abstract
We develop a theoretical framework explaining how the evolving uncertainty imperatives of the 
nascent
, 
emerging
, and 
mature
 stages of a market category influence the entrepreneurial stories that audiences judge as legitimately distinct. Our focus is on the sensemaking role of different story components in shaping these judgments, both independently and through their holistic interplay. We also relate these story components to the broader issues that audiences seek to resolve at each stage, which affects their potential resonance. This framework provides a contextualized understanding of legitimate distinctiveness and identifies unique tensions in each stage of an evolving market category, offering a valuable integration and advancement of existing scholarship.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000740,Echoes of the past: The long-lasting effects of entrepreneurs' generational imprints on value-creation models,Ileana=Maldonado-Bautista: ileanam@iastate.edu; Paul=Sanchez-Ruiz: psanch26@iastate.edu; Annaleena=Parhankangas: leena@iastate.edu; Karen=Watkins: karen.watkins@unir.net,"Abstract
We draw from theories of generations and imprinting to introduce an alternative conceptualization of the effects of age on entrepreneurship—namely, entrepreneurs' generational imprints. We theorize how imprinted characteristics of entrepreneurs from a conservative generation (vs. a progressive generation) are positively (negatively) associated with higher levels of financial returns and negatively (positively) associated with higher engagement in corporate social responsibility. In two studies in the Mexican context, we find that entrepreneurs from a conservative generation create more financial value than social value, while entrepreneurs from a progressive generation create more social value than financial value. We also explore the intervening mechanisms and find that entrepreneurs who are more embedded in the church and their families and have more family obligations are more likely to experience generational imprinting. We further show that women tend to experience generational imprinting differently than men, leading to important heterogeneity in our results. Finally, we find that older entrepreneurs experience generational imprints more acutely than their counterparts. Overall, this study provides new insights into entrepreneurs' generational imprints and demonstrates how and why generational imprinting matters in entrepreneurial research.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000764,Effect of venture capital investment horizon on new product development: Evidence from the medical device sector,Moonsik=Shin: moonshin@chapman.edu; Joonhyung=Bae: joonbae@skku.edu; Umit=Ozmel: uozmelya@purdue.edu,"Abstract
Drawing on entrepreneurial financing literature, we investigate how venture capital (VC) firms' investment horizons affect their ventures' product quality problems. We argue that when a VC firm has a short investment horizon, it may guide its portfolio companies to develop new products fast to increase the likelihood of successful exits. However, this deliberate effort may act as a double-edged sword for ventures. That is, VC firms' guidance on product commercialization could inadvertently expose ventures to product quality problems. Building on this notion, we suggest that ventures backed by VC firms with short investment horizons may experience more product quality problems than those backed by VC firms with long investment horizons. We further suggest that the effect of a VC firm's investment horizon on product quality problems is mitigated when the venture is invested by corporate VC investors but amplified when the venture develops complex products. We test our hypotheses using a dataset on product recalls of VC-backed ventures in the U.S. medical device industry.
Executive summary
The success and survival of new ventures largely depend on their ability to develop and commercialize innovative products. Due to their limited resources, these ventures often seek support from venture capital (VC) investors. However, the involvement of VC investors can be a double-edged sword, as their focus on timely (or even accelerated) product introduction may lead to unforeseen problems. This occurs because VC firms may adopt different approaches to supporting ventures in new product development, depending on their investment horizons, which are constrained by their contractual obligations to their limited partners (LPs). Specifically, VC firms with long investment horizons may allow their portfolio companies to have sufficient time to develop new products. In contrast, VC firms with short investment horizons may be under time pressure and guide their portfolio companies to speed up the product development process to increase the chances of ventures' exits within a limited timeline.
Building on this notion, we examine how the investment horizons of VC investors impact ventures' product quality problems. Ventures invested by VC firms with short investment horizons may face pressure to accelerate the new product development process, preventing the ventures from engaging in time-intensive learning processes necessary for cultivating new technological and market knowledge. Therefore, we propose that ventures invested by VC firms with short investment horizons may experience more product quality problems than those invested by VC firms with long investment horizons. We further propose two boundary conditions to validate our theoretical mechanisms. First, we suggest that the negative effect of VC investors' time horizons on product quality problems is mitigated by the presence of corporate VC (CVC) firms in the investment syndicate. As CVC firms have long investment horizons and pursue strategic goals, they can counterbalance the influence of VC firms with short investment horizons on ventures' product development process. Second, we suggest that the complexity of the products developed by ventures amplifies the impact of VC firms' investment horizons on product quality problems. This is because complex products require more time for intensive learning and information processing, making ventures particularly susceptible to product quality problems when under time pressure.
To test these arguments, we use the data on product recalls of VC-backed ventures in the U.S. medical device industry. We also incorporate insights from interviews with venture capitalists and entrepreneurs to validate our arguments. This study enhances our understanding of how partner-specific characteristics (VC firms' investment horizons in our context) affect private ventures' development paths and outcomes. By highlighting the tradeoffs associated with VC funding, we provide a more balanced perspective to the literature on VC investments, which has predominantly emphasized the benefits of VC investment. Our arguments and findings suggest that the time pressure faced by VC investors can be transferred to ventures, potentially resulting in unexpected product quality problems.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000752,Funding-source-induced bias: How social ties influence entrepreneurs' anticipated guilt and risk-taking preferences,Emily=Neubert: e.neubert@tcu.edu; Greg=Fisher: fisherg@iu.edu; Donald F.=Kuratko: dkuratko@iu.edu; Regan=Stevenson: rstev@iu.edu,"Abstract
Raising money from family and friends is a common form of startup funding. However, we know little about how accepting funds from these individuals influences an entrepreneur's risk-taking preferences. We theorize that as an entrepreneur's relationship with an investor strengthens, the entrepreneur is more likely to anticipate guilt that could emerge from a potential venture failure, which prompts the entrepreneur to make more conservative venture growth decisions. We test our model using a quasi-experimental vignette-based approach. Based on the results, we argue that the tendency for an entrepreneur to become more risk averse in their entrepreneurial decision making due to feelings of anticipated guilt after receiving funding from strong ties demonstrates a 
funding-source-induced bias
.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262400079X,False signaling by platform team members and post-campaign venture outcomes: Evidence from an equity crowdfunding platform,Virginie=Mataigne: virginie.mataigne@ugent.be; Michele=Meoli: michele.meoli@unibg.it; Tom=Vanacker: tomr.vanacker@ugent.be; Silvio=Vismara: silvio.vismara@unibg.it,"Abstract
In equity crowdfunding (ECF), early investments serve as signals of venture potential to prospective investors, making them more likely to join an offering. We argue that ECF platform team members can exploit this mechanism and convey false signals to unsophisticated investors. Data from a prominent ECF platform indicate that platform team members “invest” in ventures that exhibit weaker post-campaign outcomes. However, in ventures that successfully fundraise, platform team members typically withdraw their investment (after it incentivized others to join), and these ventures show even weaker post-campaign outcomes. Finally, ventures' post-campaign outcomes are particularly weak when this “invest-and-withdraw” tactic is executed by the platform's upper echelons, whose investments can further be perceived as endorsement signals by the crowd, despite significant goal incongruence between the upper echelons and the crowd. Our study presents novel theoretical and empirical insights into the signaling, financial misconduct, and ECF literature, and holds important policy implications.
Executive summary
Past research has shown that equity crowdfunding (ECF) platforms can reduce agency problems between entrepreneurs and ECF investors, such as adverse selection problems, by providing selection and due diligence activities. In other words, past research has focused on the bright side of ECF platforms. However, this study focuses on a possible dark side of ECF platforms. The paper investigates the practice of ECF platform team members fabricating support (i.e., using an invest-and-withdraw tactic) towards firms with weaker prospects listed on their own platform.
ECF platform team members can use an invest-and-withdraw tactic in firms with weaker prospects. Indeed, through their investments, ECF platform team members influence early investments, which are often used by prospective ECF investors as a quality signal to influence their own investment decisions. However, platform team members then withdraw their investments (after their investment lured follow-on investors to the offering). As such, platform team members convey false signals to unsophisticated ECF investors. The paper highlights an underexplored agency problem between ECF platforms and investors, where platform goals (such as higher platform fundraising success rates and increasing revenue generation, which require platforms where more deals get done) may conflict with investor interests.
Theoretically, these agency problems and the fact that one can withdraw investments at zero cost during a cooling-off period may explain why ECF platform team members engage in false signaling to support firms with weaker prospects. More specifically, we expect that platform team members will invest in firms with weaker post-campaign prospects. Also, their investment withdrawals are expected to be especially correlated with weaker post-campaign venture outcomes. Finally, the investments of the platform’s upper echelons are expected to be particularly correlated with weaker post-campaign outcomes.
Empirically, we use unique data from a leading ECF platform from a country with developed financial markets. The paper provides empirical support for the above expectations and underscores the need for policy attention to mitigate such possible misconduct. The goals of ECF platform team members are unlikely to always align with what ECF investors want. More specifically, ECF platform team members can use private information and exploit rules meant to protect buyers online (i.e., the cooling-off period, which allows for investment withdrawals at no cost) to support the fundraising of firms with weaker prospects on their platform.
Our research adds to the signaling literature by highlighting false signals conveyed by ECF platform team members and especially the upper echelon members. The paper further contributes to the misconduct literature in entrepreneurial finance, which has mostly focused on entrepreneur and/or investor misconduct, while we focused on possible misconduct by platform team members who are generally viewed as benign. It focuses on an underexplored agency problem in entrepreneurial finance between platforms and ECF investors. The paper also adds to the ECF literature by providing novel insights into post-campaign venture outcomes. Finally, the paper further contributes to the discussion about the need for better regulations in ECF markets. More transparent information and limiting the possibility of invest-and-withdraw tactics might help channel funds to the most promising ventures, ultimately providing added value for the economy and ensuring the long-term prospects of the ECF market.", January 2025,"Equity crowdfunding, Misconduct, Information cascades, Platforms, Digital finance, Entrepreneurial finance",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000818,Rethinking entrepreneurship in causally entangled crises: A poly-crisis perspective,Kim=Klyver: kkl@sam.sdu.dk; Jeffery S.=McMullen: mcmullej@indiana.edu,"Abstract
Over the last few years, the world has witnessed the emergence of a poly-crisis era in which overlapping, causally entangled crises, such as pandemics, war, inflation, natural disasters, etc. converge to challenge assumptions of societal stability upon which much of the field's knowledge base has been developed over the last few decades. In this editorial, we propose a poly-crisis perspective to entrepreneurship and compare it with entrepreneurship under both normal times and a single crisis. In doing so, we highlight the need to reexamine the boundary conditions of our models and to propose some questions, constructs, and methods that deserve increased attention in a world where institutional uncertainty is the rule rather than the exception.", January 2025,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000788,Amplifying angels: Evidence from the INVEST program,Marius=Berger: marius.berger@zew.de,"Abstract
This paper shows that angel investor grants encourage new investors to enter the risk finance market, where they syndicate investments with other investors. We argue that this results from the high cost of information acquisition for new investors. New investors bring additional capital into the market but provide little managerial support. However, as these investors join syndicates, ventures can raise larger financing amounts without compromising managerial support. Taken together, these factors positively affect the performance of entrepreneurial ventures. To test our hypotheses, we consider the case of Germany, where the federal government has introduced an investment grant for angel investors. Combining applicant data from the subsidy program with company and ownership information on the quasi-universe of German companies and a large-scale company-level panel survey covering over 900 angel-financed ventures to empirically assess our hypotheses provides strong support for our predictions.", January 2025,"G24, L26, L38, M13",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000508,Labor market reform as an external enabler of high-growth entrepreneurship: A multi-level institutional contingency perspective,Daniel L.=Bennett: daniel.bennett.2@louisville.edu,"Abstract
We investigate the impact of friction-reducing labor market reforms on regional high-growth entrepreneurship (HGE) through the effects of reduced legal enforceability of noncompete agreements (NCAs). We draw on new institutional economic theory and the external enablement framework, with insights from the theory of market-preserving federalism, to explore how these reforms enable (disable) HGE within the context of other, concurrent institutional changes at different governance levels. We assemble a novel multi-level longitudinal dataset and employ staggered difference-in-differences estimation to assess causal effects. Our findings suggest that while reducing the enforceability of NCAs can foster regional HGE, the effectiveness of such reforms is heavily influenced by concurrent federal and local institutional changes. In sectors facing significant federal regulatory expansion, the benefits brought by the reduction of NCA enforceability are negated. However, local pro-market institutional changes can counteract the disabling effects of federal regulatory expansion. This highlights the need to consider how the evolving institutional environment influences potential enablers of HGE, cautioning against claims that these labor market reforms (or other exogenous environmental changes) universally yield positive entrepreneurship outcomes.", November 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000557,Trouble brewing: Craft ventures during market disruption,Daniel S.=Andrews: dsandrews@gsu.edu; Blake=Mathias: bdmathia@iu.edu; Arun=Kumaraswamy: akumaras@fiu.edu; Andreas P.J.=Schotter: aschotter@ivey.ca,"Abstract
Prior studies of craft-based categories have emphasized member ventures' prototypical features of smallness and innovativeness, collaboration and cohesiveness norms, and a perception of shared fate forging their strong oppositional identity vis-a-vis industrialized producers. However, our study of craft breweries reveals the potential pitfalls of rigidly adhering to these features and norms during market disruptions. As consumer behaviors changed during the COVID-19 crisis, smallness and innovativeness became liabilities while scale and familiarity became indispensable, favoring larger breweries over prototypical members. This shift exposed hidden divisions within the category, challenging long-held beliefs in shared fate and entrenching heterogeneity among members. The consequent realignment within the category demonstrates how market disruptions can reshape craft-based ventures and categories. Our study advances a theoretical understanding of the dynamic nature of prototypical features and norms: An adherence to category prototypes can become a source of vulnerability during times of significant upheaval.", November 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000569,Journal of business venturing 2023 year in review: The year of the whole-person entrepreneur,Jeffery S.=McMullen: mcmullej@iu.edu,"Abstract
This editorial reflects on a strong recurring theme noticed when evaluating the JBV publications of 2023 (Volume 38, Issues 1–6) for the annual best paper award. We refer to this theme as “whole-person entrepreneurship”, i.e., how does the who of entrepreneurship shape the what of entrepreneurship. It consists of articles that sought an understanding of entrepreneurs as children, mothers, spouses, religious believers, political beings, hobbyists, victims, and community-members. These articles revealed how an understanding of who “else” entrepreneurs are (other than some role or function) had much to teach about what entrepreneurs do as well as how, why, where, and when they do it. In the following editorial, we offer some evidence for this observation, provide explanation for how the field may have arrived at this “humanistic turn”, and articulate some ways in which it this humanistic turn might shape scholarship in entrepreneurship going forward.", November 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000545,"Feeding the hype cycle: Entrepreneurial swagger, passion, and inflated expectations",Kevin=Heupel: kevin.heupel@okstate.edu,"Abstract
Hype occurs when expectations exceed reality. For founders promoting innovative technologies, hype often attracts the resources necessary to grow a new venture. Hype is gaining prominence in entrepreneurship literature, and it is understood that many entrepreneurs jumpstart their ventures by promoting optimistic, future projections to entice stakeholders. Unfortunately, little is known about how skilled cultural founders generate hype to attract stakeholders. In our study, we examine how founders function as “skilled cultural operatives” to positively manipulate the emergence of hype. We conduct an experiment on 148 members of the media, and we find support for our theorizing in that founders who display their entrepreneurial abilities (swagger) combined with an authentic emotional commitment to the venture (passion), it increases media expectations (hype).
Executive summary
For the founders of innovative technologies, hype is not just beneficial, it is a strategic necessity. Hype is characterized by an overinflated interest in emerging technologies where future expectations outweigh current capabilities. It serves as a magnet for essential resources such as funding and customer interest. This dynamic, albeit critical, is often misunderstood and underestimated, in particular as regards the founder's role in its development. It is therefore of paramount importance to unravel the nuances of how founders contribute to the creation of hype.
This study explores founders as “skilled cultural operatives,” adept at using their cultural toolkit through sensegiving to inflate media expectations, thereby creating hype. Sensegiving in entrepreneurship involves a mix of verbal and non-verbal cues to communicate, clarify, and justify new technology. It is particularly important if there are no historical references or industry standards. The study posits that effective sensegiving through metaphorical reasoning, in which founders display their confidence and passion in a highly visible and expressive way, is key to generating media attention to generate hype.
In the present study, the concept of “swagger” emerged as a critical sensegiving mechanism. Defined as a conspicuous display of confidence through various expressions, swagger is a tool for founders to project their abilities and attract media coverage. However, this swagger, even if it attracts attention, may initially be perceived negatively, as a mere showmanship without substance. This research provides a nuanced understanding of this perception and shows that if swagger is infused with genuine passion, it transforms into a powerful catalyst for generating hype.
Conclusively, this study enriches the literature on hype cycles, moving beyond mere descriptions to a deeper understanding of how founders generate hype. By introducing and operationalizing the concept of entrepreneurial swagger, this study expands the range of sensegiving strategies available to founders. This study guides founders on how to effectively leverage swagger, demonstrating that when combined with passion, swagger can successfully generate hype and attract the necessary resources for innovative technologies.", November 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000429,Impact creation approaches of community-based enterprises: A configurational analysis of enabling conditions,Björn C.=Mitzinneck: b.c.mitzinneck@rug.nl,"Abstract
This study investigates which local conditions enable community-based enterprises (CBEs) to create impact. Advancing our limited understanding of the various contexts that enable CBEs to tackle societal issues locally, we investigate supportive conditions across 77 CBEs driving the energy transition in their geographic community. Through qualitative comparative analysis, we identify four condition configurations for CBE impact creation. Across these configurations, we reveal transferable mechanisms helping CBEs to engage community members (
Opportunity-
 and 
Community-anchoring
) and handle the absence of a supportive condition 
(Circumventing
 and 
Compensating).
 Our study suggests how CBEs can combine these mechanisms to create impact in varied local contexts.", November 2024,"Community-based enterprises, Impact, Entrepreneurship, Community, Fuzzy-set qualitative comparative analysis, QCA",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000570,Quasipractice: How the entrepreneurship educator develops entrepreneurial practice expertise,Raj K.=Shankar: rajkrishnan.s@greatlakes.edu.in; Andrew C.=Corbett: acorbett@babson.edu,"Abstract
There is a growing interest in exploring the practice-based foundations of entrepreneurship education. Despite significant advancement in scholarship regarding entrepreneurship education, our understanding of the ‘educator’, especially how they develop and sustain their abilities to enable learning in practice-based entrepreneurship education, remains sorely understudied. In contrast to existing cognitive learning approaches, we suggest practice-based knowing as an alternative pathway to develop entrepreneurial practice expertise. We build on Heidegger's existential ontology and use the ideas of entwinement and breakdown to build—
quasipractice
—
a process of developing entrepreneurial practice expertise through proximal engagement in the actions, emotions, and cognitive experiences of an entrepreneur, including the experience of temporary breakdowns, and reflection on the breakdowns experienced.
 Quasipractice helps advance the literature on both the professional development of the entrepreneurship educator and the larger area of practice-based entrepreneurship education.", November 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000594,Navigating the temporal commitments of entrepreneurial hype: Insights from entrepreneur and backer interactions in crowdfunded ventures,Matthew S.=Wood: ms_wood@ou.edu; Sean M.=Dwyer: seandwyer@ou.edu; David J.=Scheaf: david_scheaf@baylor.edu,"Abstract
This paper examines how entrepreneurs manage temporal commitments associated with hyped audience expectations. We examine hype in the crowdfunding context, conducting an inductive study of 155 entrepreneur project updates from five new ventures that mobilized significant funding on Kickstarter. Entrepreneur updates were matched with 17,807 backer comments, creating call and response pairs. Using LIWC sentiment analysis, we tracked changes in backer negative tone over time and observed spikes and dips corresponding with temporal events. The pattern suggested that entrepreneurs have techniques to tamp down negative sentiment from backers as they delay product shipments. Through inductive examination of entrepreneur and backer interactions, we uncover entrepreneurs' use of four narrative practices to manage the temporal constraints of hyped audience expectations: frequent communication, evidence of progress, proximal temporal reach, and time-quality trade-off. While initially effective, these practices have diminishing returns over time, eventually triggering backer outrage as continual delays frustrate backers. We additionally find that the effectiveness of the narrative practices is influenced by external temporal pacers, with entrepreneurs using pacers to amplify narrative practice effectiveness, while backers use them as reasons to reject delays.", November 2024,"Entrepreneurial hype, Time, Temporality, Resource mobilization, Crowdfunding",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000405,"Aging and entrepreneurs' emotional exhaustion: The role of entrepreneurial strategy, psychological capital, and felt age gap",Ewald=Kibler: ewald.kibler@aalto.fi; Charlotta=Sirén: charlotta.siren@unisg.ch; Daniela=Maresch: daniela.maresch@grenoble-em.com; Virva=Salmivaara: vsalmivaara@audencia.com; Matthias=Fink: matthias.fink@grenoble-em.com,"Abstract
In this paper, we draw from the theory of social and emotional aging to examine the mechanisms of age-related emotional exhaustion among entrepreneurs. Based on longitudinal data from a sample of 840 entrepreneurs in four European countries, our study shows that, with increasing biological age, entrepreneurs experience less emotional exhaustion due to their enhanced psychological capital and because they apply less 
entrepreneurial strategies
 which focus on the creation of new market opportunities and the development of new products and services. In addition, we highlight the still under-explored role of entrepreneurs' felt age gap by demonstrating that, among the same age-group, individuals who feel younger than their biological age gain well-being benefits because they possess higher levels of psychological capital and become less exhausted from the application of entrepreneurial strategies. In conclusion, our study offers two significant contributions to the literature on entrepreneurial well-being. First, we introduce the concept of the ‘Hebe Effect in entrepreneurship’, named after the Greek goddess of youth, which demonstrates how feeling younger than one's biological age acts as a buffer against stress and protects entrepreneurs from the strains of entrepreneurship. Second, we deepen understandings of how entrepreneurs' strategic choices evolve over their lifespan and influence their personal well-being. These insights also carry practical implications for 
aging societies
 that promote entrepreneurship across individuals' lifespans.
Executive summary
This study addresses a critical gap in the entrepreneurship literature on aging and well-being by examining how age influences emotional exhaustion among entrepreneurs. Despite significant research conducted on aging and entrepreneurship, studies have yet to explore the interplay between biological age, subjective age, and emotional exhaustion. Furthermore, the manner in which entrepreneurs subject themselves to, and protect themselves from, emotional exhaustion across their lifespans remains severely underexplored. This lacuna is particularly striking given global trends of increased life expectancy, the burgeoning number of older individuals engaging in entrepreneurship, and the risks posed by emotional exhaustion to entrepreneurial efforts and individuals' lives, as well as the societal costs related thereto.
By using the theory of social and emotional aging (SEA), we investigate how biological age and subjective age impact entrepreneurs' emotional exhaustion. Our 
longitudinal study
, based on data from 840 entrepreneurs across four European countries, reveals that older entrepreneurs experience less emotional exhaustion than their younger peers. This is due to their increased psychological capital and reduced engagement in strategies focused on new market opportunities and product development. Additionally, entrepreneurs who subjectively feel younger than their biological age benefit from higher psychological capital and are less affected by the emotional strain of entrepreneurial strategies.
Our research introduces the ‘Hebe Effect in entrepreneurship’, illustrating that feeling younger than one's biological age serves as a buffer against emotional exhaustion. This effect is mediated by enhanced psychological capital and the strategic choices made by entrepreneurs as they age. By developing and testing the novel Age-Strategy-PsyCap-Exhaustion (ASPE) model, we demonstrate how biological age and felt age gap jointly influence entrepreneurs' emotional exhaustion through psychological capital and strategic choices. The study makes significant contributions to both theory and practice. The concept of the Hebe Effect in entrepreneurship provides a new lens through which to understand how subjective age can protect entrepreneurs from emotional exhaustion. Furthermore, our ASPE model offers a comprehensive framework for explicating the mechanisms through which age-related factors impact entrepreneurial well-being.
From a practical perspective, our findings suggest important policy implications for aging societies. Encouraging entrepreneurship among older adults can yield well-being benefits and enhance resilience, thus underscoring the value of an inclusive approach to entrepreneurial support. In addition, specifically tailored support mechanisms that consider both biological and subjective aging can help mitigate emotional exhaustion, thereby fostering sustainable entrepreneurial activities across all ages. In conclusion, this study advances our understanding of the complex relationship between aging and entrepreneurial well-being, offering valuable insights for both academic research and practical applications in promoting a healthy and resilient form of entrepreneurship.", September 2024,"Entrepreneurship, Emotional exhaustion, Well-being, Aging, Age, Subjective age, Strategy, Psychological capital",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262400017X,"“I can't get it out of my mind” - Why, how, and when crisis rumination leads entrepreneurs to act and pivot during crises",Bach=Nguyen: b.nguyen@exeter.ac.uk; Hai-Anh=Tran: hai-anh.tran@manchester.ac.uk; Ute=Stephan: ute.stephan@kcl.ac.uk; Ha Nguyen=Van: hanv@hvnh.edu.vn; Pham Thi Hoang=Anh: anhpth@hvnh.edu.vn,"Abstract
Why do some entrepreneurs pivot their business models in a crisis, while others are more passive? Integrating 
Conservation of Resources
 theory with work on crisis rumination, we developed a micro-level model to explain why entrepreneurs who are under strain due to a crisis, as indicated by experiencing crisis rumination, adopt an active approach – i.e., using active coping and engaging in pivoting. Moreover, prevention-focused entrepreneurs who are habitually more sensitive to losses are especially stimulated by crisis rumination to pivot to prevent (further) resource losses. We tested our model in an experiment and an eight-month 
longitudinal study
 with entrepreneurs during an 
inflation
 crisis.", July 2024,"CISSCoping Inventory for Stressful Situations, Coping Inventory for Stressful Situations, CORConservation of Resources, Conservation of Resources, LSBSLongitudinal Small Business Survey, Longitudinal Small Business Survey, ONSOffice for National Statistics, Office for National Statistics, VIFVariance Inflation Factor, Variance Inflation Factor",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000399,The Internet and the gender gap in entrepreneurship: Evidence from China,Xuanli=Xie: xxl@nsd.pku.edu.cn,"Abstract
The Internet has transformed economic activities in many important ways over the past two decades. This study examines the role of the Internet in narrowing the gender gap in entrepreneurship. Building on the assumptions that the Internet facilitates information transmission and breaks down information barriers for aspiring entrepreneurs, the study hypothesizes that (a) the Internet narrows the gender gap in the probability of entrepreneurship, and (b) the gender gap–mitigating effect of the Internet is stronger for the more disadvantaged members of society. These hypotheses are tested with six waves of data from the China Family Panel Studies, a nationally representative longitudinal survey series from 2010 to 2020. Empirical evidence based on the analysis of 25,177 individuals confirms that Internet use is associated with a narrower gender gap in entrepreneurship. In addition, the gender gap–mitigating effect of the Internet is stronger for less educated individuals and those who live in regions with a lower level of gender equality. The gender gap–mitigating effect of the Internet is also stronger for informal (rather than formal) entrepreneurship. The Internet appears to have a democratizing effect by facilitating entrepreneurship among the more socially and economically disadvantaged subsets of society.", September 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000417,"Organizational scaling, scalability, and scale-up: Definitional harmonization and a research agenda",Nicole=Coviello: ncoviello@wlu.ca,"Abstract
The concepts of ‘scaling,’ ‘scalability,’ and ‘scale-up’ are increasingly used in business research and practice. However, the literature reveals a range of definitions for each, and often, their meanings are only implied. This diminishes the ability to build cumulative and meaningful insight - and conduct research - on each concept. In this editorial, we offer a 
systematic review
 that assesses and harmonizes prior definitions of these important concepts. This allows us to define and differentiate between (a) scaling as an organizational process, (b) scalability as an ordinary organizational capability, and (c) scale-up as a phase of organizational development. Complementing and extending existing scholarly work, we develop a rich agenda for scaling-related research in entrepreneurship.", September 2024,"Scaling, Scalability, Scale-up, Entrepreneurship, Systematic review, High growth",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000430,Linking anxiety to passion: Emotion regulation and entrepreneurs' pitch performance,Lily Yuxuan=Zhu: lily.zhu@wsu.edu; Maia J=Young: maia.young@uci.edu; Christopher W.=Bauman: cwbauman@uci.edu,"Abstract
We investigate a strategy entrepreneurs can use to manage their emotions prior to pitching: 
linking anxiety to passion
. We theorize that internally acknowledging anxiety and interpreting it as a reflection of one's passion for the venture can make passionate feelings salient, facilitate expressions of passion during pitches, and increase judges' evaluations of pitch performance. A 
field study
 and a randomized experiment support the theory, offering insights for how entrepreneurs can mentally reframe their seemingly detrimental emotional experiences for beneficial outcomes. More broadly, this work demonstrates the utility of fostering beneficial emotions rather than just alleviating negative ones.", September 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000168,The effect of regime change on entrepreneurship: A real options approach with evidence from US gubernatorial elections,David S.=Lucas: dlucas01@syr.edu,"Abstract
Although political turnover is said to be a healthy component of the business environment, the literature is equivocal about the effects of regime change on early-stage 
entrepreneurial activity
. I present incumbent displacement—the electoral defeat of an incumbent political party's candidate—as a source of regime change, and I analyze how this affects business formation through the lens of 
real options
 theory. I test my theory using US gubernatorial elections from 2004 to 2022, leveraging a 
Regression Discontinuity design
 to compare changes in business formation trends following elections where a challenger party candidate wins or loses by a close margin. I find that regime change reduces venture creation activity for growth-oriented ventures specifically. I also find evidence of a partial rebound in subsequent months—suggestive that some entrepreneurs delay entry while others permanently abandon their ventures.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000156,The gendered effect of populism on innovation,Jintong=Tang: jintong.tang@slu.edu; Wenping=Ye: yewenping@jnu.edu.cn; Mingzhi=Hu: mzhu@zjut.edu.cn; Stephen X.=Zhang: stephen.zhang@adelaide.edu.au; Shaji A.=Khan: shajikhan@umsl.edu,"Abstract
This research addresses the impact of the remarkable rise in populism on innovative new ventures. Integrating institutional theory with gender role 
congruity theory
, we reason that the surge of populist discourse by a nation's top political leaders decreases the innovativeness of new ventures, and this negative relationship is more pronounced for women entrepreneurs. We also consider two critical yet overlooked institutions, 
gender inequality
 and grammatical gender marking in the dominant languages that entrepreneurs speak, and propose that they reinforce this negative relationship. Data from 69,406 observations of entrepreneurs across 40 countries during the period of 2005–2018, analyzed with a difference-in-differences (DiD) design, support our hypotheses. Theoretical and policy implications are discussed for the challenges of promoting innovation among women entrepreneurs, in countries with greater 
gender inequality
 and where the dominant language exhibits greater intensity of grammatical gender marking, with populism on the rise worldwide.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000144,Non-probabilistic reasoning in navigating entrepreneurial uncertainty: A psychology of religious faith lens,Robert J.=Pidduck: rpidduck@odu.edu; David M.=Townsend: dtown@vt.edu; Lowell W.=Busenitz: busenitz@ou.edu,"Abstract
Uncertainty permeates the world of entrepreneurship. Yet, understanding how entrepreneurs perceive and make decisions in the face of uncertainty remains elusive. The value of Bayesian decision models with their probabilistic-based assumptions is only of limited help to entrepreneurs in solving the problem of uncertainty. This research extends the utility of 
non-probabilistic
 modes of entrepreneurial cognition as a supplementary epistemology for shedding light into the ‘black box’ of how entrepreneurs navigate unknowable futures. We conceptualize core insights, on how decision-makers make sense of, interpret, and act amidst life's deep uncertainties. Specifically, we introduce four decision heuristics entrepreneurs adopt—grounded in the shared foundations in broader conceptions of uncertainty from the psychology of religious faith—that help systematize why (a) intuitive insight, (b) generative doubt, (c) redemptive choice, and (d) transcendent faith, enhance our understanding of how elements of uncertainty throughout the venture development journey are often addressed. Implications for future research are discussed.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000260,A framework for investigating new firm entry: The (limited) overlap between informal-formal and necessity-opportunity entrepreneurship,Saul=Estrin: s.estrin@lse.ac.uk; Maribel=Guerrero: maribel.guerrero@asu.edu; Tomasz=Mickiewicz: t.mickiewicz@aston.ac.uk,"Abstract
We analyse entrepreneurial entry along the dimensions of informal-formal and necessity-opportunity entrepreneurship, distinguishing between them yet considering them jointly. While the dominant view in the literature conflates necessity with informal entry, and opportunity with formal entry, we hypothesise that informal entrepreneurship may be attractive to higher-income individuals as a testing ground for entrepreneurial ideas. We also explain why higher-income individuals may undertake necessity entrepreneurship. We utilise individual Global Entrepreneurship Monitor (GEM) data from Chile (2019–2021), which identifies informal-formal and necessity-opportunity entrepreneurial entry modes, to test hypotheses on the role of individuals´ income in the four types of entrepreneurial entry. We also consider changes in entrepreneurial entry during a crisis and a non-crisis periods. Our results confirm that the patterns in the data are consistent with hypotheses derived from our proposed theoretical framework.
Executive summary
Emerging markets economies have very large informal sectors, and their entrepreneurial entry is often motivated by economic necessity rather than by business opportunity. But neither informal nor necessity entrepreneurship are usually expected to generate the positive benefits for growth and development predicted for formal and opportunity entrepreneurship. We argue that the dominant stream in the literature actually conflates informal and necessity entrepreneurship, both of which have been associated with low human and financial capital and productivity. We propose that the appropriate typology is more complex than this because there are examples of successful and dynamic informal firms. This leads us to identify four categories of entrepreneurial entry: informal-necessity (Type 1), formal-opportunity (Type 2), informal-opportunity (Type 3), and formal-necessity (Type 4). While necessity entrepreneurship has typically been associated with low-income individuals, we propose that formal-necessity entrepreneurship may be an entry path for both low- and high-income individuals, though for different reasons. Informal opportunity entry may likewise be an option for people with low-income as well as high-income.
We therefore seek to disentangle the analysis of opportunity-necessity and of formal-informal entry and to demonstrate that the two less explored entry modes - informal-opportunity, and formal-necessity - are of considerable theoretical and practical significance in emerging economies. We test our framework in the emerging market economy setting of Chile, one of the more prosperous and open economies in Latin America. We use Global Entrepreneurship Monitor (GEM) data which uniquely for Chile allow us to distinguish between individuals along both the formal-informal and the necessity-opportunity dimensions. On this basis, we distinguish empirically between these four categories of entrepreneurial entry and explain how higher-income individuals may use informal-opportunity entrepreneurial entry as a “seed bed” to test their new business ideas. At the same time, we show that necessity entrepreneurship may be attractive to both lower- and higher-income individuals.
We also show that the interplay between individuals´ income groups and four entrepreneurial entry modes is stable over “normal times” versus “crisis periods”. We observe that in response to a crisis, individuals with lower-incomes are likely to engage more in informal-necessity entrepreneurship while opportunity-informal entry by higher-income individuals will decline. These changes represent a more complex adjustment pattern than has been identified for developed economies, where 
entrepreneurial activity
 has been found to be countercyclical. Thus, in emerging markets, informal-necessity entrepreneurship plays a stabilizing role for those individuals with a more marginal position in the 
labor market
 during the crisis. In contrast, for those individuals who have access to higher household income, all forms of entrepreneurship become a less attractive option. We interpret this as indicating that these individuals have the option to wait for higher return opportunities to re-emerge. This is one of the first papers to explore the impact of the COVID-19 pandemic on entrepreneurship in an emerging market economy.", July 2024,"Informal entrepreneurship, Opportunity, Necessity, Income, Crisis, Global entrepreneurship monitor, Chile",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000284,Exploring the microfoundations of hybridity: A judgment-based approach,Carmen-Elena=Dorobat: c.dorobat@mmu.ac.uk; Matthew=McCaffrey: Matthew.mccaffrey@manchester.ac.uk; Mihai Vladimir=Topan: mihai.topan@rei.ase.ro,"Abstract
We explore the concept of organizational hybridity from the perspective of the Judgment-Based Approach to entrepreneurship (JBA). The JBA provides much-needed 
microfoundations
 for hybridity in the form of a more nuanced, action-based view of the market mechanism in shaping 
enterprises
. Rather than a problem of conflicting logics at the organizational level, hybridity is redefined as entrepreneurial judgment at the individual level about combinations of monetary and psychic profit. Viewed this way, hybridity is a universal characteristic of real-world enterprises rather than a defining feature of a specific subset of them. This approach thus ultimately reshapes our understanding of hybridity and suggests an alternative view that is less conflictual and insular, and more conciliatory and integrated. It also sheds light on various problems facing such enterprises, including strategy formation, practical wisdom, normative pressures, mission drift, entrepreneurial groups, and public policy.
Executive summary
Hybrid enterprises are said to combine different logics or orientations within an organization. These logics are typically described as either economic or social, and are usually conceived as existing in inherent tension with each other; hence, hybrid enterprises are neither conventional monetary profit-seeking businesses nor purely social or charitable organizations, but some awkward, possibly paradoxical combination of both. The best-known and most frequently studied types of hybrids are social enterprises, which straddle the line between monetary profit-seeking and the pursuit of broader social goals or social value.
The literature on hybrids is growing rapidly, but to date there has been little agreement over its fundamental concepts and frameworks, and key questions remain about the origins, meaning, and development of hybrids. There is particular debate about whether the different “logics” of hybrids are necessarily in tension or conflict, or whether they exist harmoniously, as complements. Are hybrids just another form of profit-seeking market organization? As organizations, are they puzzles to solve, or perhaps paradoxes to confront? Answering these questions is crucial for understanding of what hybrids are, how they work, and what their broader implications are for economy and society.
We address to these debates by developing a new conceptual basis for studying hybrid enterprises. We argue that current controversies are usually the result of studying hybridity only at the organizational level. In response, we explore the microfoundations of hybridity, showing that what is called hybrid organizing simply reflects entrepreneurs' choices about how to pursue 
monetary profits
 and 
psychic profits
. Drawing on the Judgment-Based Approach to entrepreneurship (JBA), we show how entrepreneurial decision-making constantly negotiates the boundaries of monetary calculation and profit-seeking and alternative, non-monetary goals such as providing 
social benefits
. Understanding the interplay between the monetary and psychic profit leads to a more realistic and nuanced account of the causal foundations of hybridity, while also dispelling some confusions that have arisen in the literature. Ultimately, what is called hybridity at the organizational level is simply the result of 
entrepreneurial action
 at the individual level about combinations of profit.
This approach leads to several notable results. First, it emphasizes that all enterprises are to some extent social and contain elements of what is called hybridity. Second, as a result, microfoundations challenge the importance of hybridity as such as a key construct. What is called hybridity is not a defining characteristic of certain organizations, but exists in all enterprises, and is a persistent aspect of entrepreneurial decisions regarding how to organize and restructure firms. Third, a micro-level approach dissolves the perceived tension between different logics in the enterprise, promoting a view that is less conflictual and insular, and more conciliatory and integrated. Fourth, microfoundations can help connect meso- and macro- level research as a way of encouraging a more comprehensive research program that includes all sizes and shapes of enterprise. Fifth, they also shed light on various problems facing enterprises of all types, including strategy formation, practical wisdom, normative pressures, mission drift, entrepreneurial groups, and public policy.", July 2024,"Hybridity, Social enterprise, Judgment, Psychic profit, Strategy as simple rules",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000247,Legitimate incongruity: Strategic positioning within hybrid categories,Kostas=Alexiou: kalexiou@ut.edu,"Abstract
The primary purpose of this research is to examine the extent to which positioning hybrid ventures as more or less congruent with their category influences perceptions of their legitimacy. To do so, we first introduce and define the notion of a 
hybrid category
 as an institutional context which combines two or more dominant institutional logics that both constrain and enable organizational action. We then construct a theoretical framework instantiated within a hybrid category, suggesting that moderate incongruence between a new venture's identity 
narrative
 and the expectations most strongly associated with the category will positively influence perceived legitimacy. We further predict specific relationships among dimensions of perceived legitimacy, as well as their downstream effects on an individual's willingness to contribute resources. Across three studies in which we experimentally manipulate congruence with a hybrid category, we find a consistent pattern of support for our hypotheses and reveal a unique benefit for new hybrid ventures who position themselves in a manner that is moderately incongruent with the hybrid category. In addition, our results suggest that moral legitimacy perceptions act as a precursor to cognitive legitimacy perceptions in new hybrid categories.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000259,To profit or not to profit: Founder identity at the intersection of religion and entrepreneurship,Jody=Delichte: jody@drdelichte.org; E. Erin=Powell: eepowel2@ncsu.edu; Ralph=Hamann: ralph.hamann@uct.ac.za; Ted=Baker: tbaker@business.rutgers.edu,"Abstract
For more than a century, discussion of the connections between religion and entrepreneurship has pointed to what we would now label questions of identity. Our study of 25 participants in a program in Northern Kenya that aimed to introduce and stimulate capitalist entrepreneurship within extremely poor pastoralist communities shows that differences in participants' religious social identities strongly shaped whether or not they adopted new roles and role identities as capitalist entrepreneurs. This process also shifted the domains in which their religious and collectivist social identities were salient and helped to explain the emergence of important and contested changes in social and economic relations. We contribute to the development of founder identity theory by building research at the intersection of entrepreneurship and religion and at the intersection of entrepreneurship and poverty alleviation.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000296,Entrepreneurial hustle: Scale development and validation,Emily=Neubert: e.neubert@tcu.edu; Devin=Burnell: d.burnell@tcu.edu; Greg=Fisher: fisherg@indiana.edu; Matthew R.=Marvel: mrmarvel@bsu.edu; Regan=Stevenson: rstev@indiana.edu; Donald F.=Kuratko: dkuratko@indiana.edu,"Abstract
Entrepreneurial hustle refers to the urgent and unorthodox actions entrepreneurs use to address obstacles and opportunities under uncertainty. Research examining this construct has been limited by the lack of a valid and reliable measure to capture these actions. Within this paper, we advance the conceptualization of the construct and develop a measure to capture the behavioral tendency to engage in entrepreneurial hustle. We test the nomological validity of entrepreneurial hustle, including key antecedents and an outcome derived from 
entrepreneurial action
 theory. Finally, we propose a future research agenda that uses the new measure developed herein.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000302,The entrepreneurship of marginalized groups and compatibility between the market and emancipation,Alexander C.=Lewis: alexander.lewis@utsa.edu,"Abstract
This paper offers a market-compatible perspective of the emancipatory entrepreneurship of marginalized groups. We identify two dimensions of market-emancipation compatibility that derive from tensions inherent in the emancipatory entrepreneurship of marginalized groups. Ends-compatibility reflects the misalignment of emancipatory outcomes with market outcomes. Means-compatibility reflects the constraint entrepreneurs from marginalized groups encounter in market structures. We engage with these tensions in the context of the businesses, processes, and products that emerge from the entrepreneurship of marginalized groups. We use these tensions to derive propositions that speak to the likelihood emancipatory opportunities develop and that these opportunities are exploited by marginalized groups. With these propositions, we contribute to debates about entrepreneurship's overall emancipatory capacity. Specifically, we contribute a conceptual space in which the market forces that structure 
entrepreneurial activity
 and the material realities of venturing from marginalized social positions are incorporated into theorizing and testing entrepreneurship's capacity to enable marginalized groups with respect to structural disadvantage.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000314,The needle of charisma and the threads of trust: Advancing effectuation theory's crazy quilt principle,Tanurima=Dutta: tanurima.dutta@baruch.cuny.edu; Mark D.=Packard: packardm@fau.edu,"Abstract
Effectuation theory posits that the accrual of disparate resources from various stakeholders is key to opening up transformational opportunities to the effectual venture. Here we aim to theoretically unravel the social exchange processes of the ‘effectual ask’—petitioning resource pre-commitments—pertaining to the so-called ‘crazy quilt’ principle. To do so, we introduce and integrate into effectuation theory's foundational mechanics key insights from 
social exchange theory
 (SET), which sees social interactions as mutually beneficial ‘exchanges.’ Revisiting a prior debate, we theorize on the different types of trust, how they distinctly influence the entrepreneurship process (particularly in obtaining resource pre-commitments), and how they are built over time. We also introduce charisma as a key factor in the trust-building process, distinguishing two types of charisma—causal and effectual—as individual-level mechanisms for enabling different types of stakeholder trust and commitment.", July 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000028,The signaling value of legal form in entrepreneurial debt financing,Felix=Bracht: felix.bracht@kuleuven.be; Jeroen=Mahieu: j.e.l.mahieu@uu.nl; Steven=Vanhaverbeke: steven.vanhaverbeke@kuleuven.be,"Abstract
This study examines the impact of mandatory legal form choices on startups' debt financing opportunities. We posit that an entrepreneur's initial legal form decision serves as a reliable signal to outside lenders, reducing adverse selection concerns. Using data from German startups, we find that 
limited liability companies
 with low capital requirements disproportionately secure less debt than their high-capital counterparts. This financing disparity is particularly pronounced for younger firms in areas dominated by small relationship banks, but it diminishes with firm age. Our findings highlight the unintended consequences of recent global deregulation efforts.
Executive summary
Formal debt financing is arguably the most important source of external financing for startups. Despite its importance, many startups find it challenging to secure such financing due to informational opacity: they lack the track record or publicly available evidence needed to prove that they are a sound investment. This raises a pressing question: How can startups credibly convey their creditworthiness to potential lenders?
We posit that a startup entrepreneur's choice of legal form acts as a pivotal signal to potential lenders, allowing them to differentiate between high-risk and low-risk ventures. Every startup must decide what legal form it will adopt at incorporation. Unlike most other, industry-specific decisions, the choice of legal form acts as a consistent and universally applicable signal. Moreover, recent shifts in global regulations have seen the emergence of companies with low-capital legal forms, a development further underscoring the importance of studying these choices (World Bank, 2020).
We theorize that adopting a legal form with high minimum paid-in capital requirements signals that a venture will be less likely to default on a loan: entrepreneurs who anticipate a higher likelihood of default will be less inclined to pick a legal form with high minimum capital requirements since they would be liable for the amount of paid-in capital in the case of 
bankruptcy
. The opportunity costs of such a choice would also be higher as founding a high-capital firm would entail foregoing alternative, safer investment opportunities. Furthermore, the reputational costs and potential stigma of failure associated with defaulting when choosing a high- versus low-capital legal form may induce high-risk types to choose the latter. Importantly, we posit that the legal form choice has signaling value beyond the amount of paid-in capital: among firms with the same amount of equity and similar firm and founder characteristics, those ventures with a low-capital legal form have more difficulty in attracting the necessary external funding.
We utilize comprehensive administrative and survey data from German firms to empirically test our hypotheses. In 2008, Germany introduced the “mini-LLC” or “low-capital LLC,” allowing founders to opt for a lower minimum capital requirement than the traditional 25,000 Euro. This shift presented a unique opportunity to study the implications of legal form choice on external financing. Our findings suggest that low-capital LLCs typically secure less debt and more frequently experience financial constraints, despite the lack of any significant difference between their financing needs and those of high-capital LLCs. We further demonstrate that the total effect consists of a mild positive intentional impact from choosing a high-capital legal form and a strong negative unintentional impact from opting for a low-capital form.
Notably, these signaling effects are more pronounced for smaller, “relationship banks,” which tend to rely more on nonfinancial cues for risk assessment due to their limited access to sophisticated financial evaluation tools. As the firm-bank relationship matures, the weight of this signal diminishes, indicating that banks adjust their assessment based on acquired knowledge of the firm's quality. However, larger, “transactional banks,” which focus more on hard data, tend to maintain their reliance on this signal for extended periods.
For entrepreneurs, the key takeaway is that a trade-off exists between capital requirements and debt accessibility. The stigma tied to low-capital legal forms disproportionately affects their ability to secure debt. Opting for a legal form with low capital requirements might be advantageous to those not heavily dependent on external financing in the early stages, and fostering long-standing relationships with banks is one way of mitigating the unintended consequences of choosing a low-capital legal structure. Entrepreneurs should consider the prevalent banking landscape in their regions; in areas dominated by smaller banks, the legal form choice is especially crucial.
For policymakers, the implications are clear. Regulations regarding firm incorporation can unintentionally impact startups' access to external funding, potentially stifling growth. Understanding these dynamics when formulating policies that shape the entrepreneurial landscape is essential.", May 2024,"D80, G30, M48",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262400003X,Old but gold? Examining the effect of age bias in reward-based crowdfunding,Benedikt David Christian=Seigner: benedikt.seigner@ie.edu; Aaron F.=McKenny: amckenny@iu.edu; David K.=Reetz: david.reetz@tum.de,"Abstract
While age is positively related to entrepreneurial success, the prevailing stereotype favors younger entrepreneurs. To better understand how these contradictory perspectives influence funding decisions, we examine the role of age in a sample of 41,602 reward-based crowdfunding campaigns from Indiegogo. We find a negative correlation between an entrepreneur's apparent age and funding performance, indicating a preference for younger entrepreneurs. However, we also find age-based homophily where older entrepreneurs' campaigns attract older backers. Our study distinguishes between statistical and status-based discrimination to understand the multi-faceted nature of age in reward-based crowdfunding and demonstrate how investment motives mitigate and reinforce age-based discrimination.", May 2024,"Age stereotypes, Homophily, Reward-based crowdfunding, Entrepreneurial finance, Discrimination",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000120,Parental divorce in early life and entrepreneurial performance in adulthood,Mateja=Andric: mateja.andric@unisg.ch,"Abstract
We examine how parental divorce in early life affects performance in entrepreneurship in adulthood. Drawing on life course theory and empirical analyses of US self-employment and childhood data from the National Longitudinal Survey of Youth 1979, we show that entrepreneurs' experience of parental divorce in childhood benefits their entrepreneurial performance in adulthood through a gain in self-efficacy while simultaneously suppressing entrepreneurial performance through a shortfall in 
human capital
. We also show that whether the performance advantages or disadvantages from parental divorce dominate depends on parental human capital. While parental divorce is associated with underperformance for entrepreneurs whose parents have high levels of human capital, it is positively related to entrepreneurial performance for those with low parental human capital. Our study contributes new theory and evidence on the intertemporal relationship between past family contexts and present entrepreneurial performance.", May 2024,"Entrepreneurial performance, Parental divorce, Family context, Life course theory, Childhood adversity",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000041,The effects of firm-specific incentives (stock options) on mobility and employee entrepreneurship,Vilma=Chila: v.chila@uva.nl; Shivaram=Devarakonda: s.v.devarakonda@tilburguniversity.edu,"Abstract
We consider the effect of employee stock options on employee mobility and employee entrepreneurship. Employee stock options are firm-specific, long-term, equity-based incentive instruments—attractive properties for affecting employee behaviors and decisions. We argue that employee stock options reduce employee mobility levels. By contrast, we posit that employee stock options increase employee entrepreneurship levels, and even more so when a firm's knowledge scope is narrow. Using the 
semiconductor industry
 as the setting, we document not only the negative effect of employee stock options on employee mobility levels but also the positive impact on employee entrepreneurship levels; the positive impact is also more substantial in firms with a narrow knowledge scope. We contribute to the literature that examines the influence of organizational conditions on the origins of entrepreneurship. We also inform research on strategic 
human capital
 by explicating the divergent effects of firm-specific incentives on two crucial human capital outcomes for firms.", May 2024,"Firm specific incentives, Employee entrepreneurship, Employee stock options",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000132,The value of a reputation for sustaining commitment in interfirm relationships: The inclusion of corporate venture capitalists in investment syndicates,Joseph J.=Cabral: jcabral@lsu.edu; M.V. Shyam=Kumar: kumarm2@rpi.edu; Haemin Dennis=Park: parkhd@utdallas.edu,"Abstract
We explore the importance of sustaining commitment in inter-firm relationships in the corporate venture capital setting. We find that a corporate investor's past behavior in terms of committing to investment relationships and not abandoning them prematurely confers reputational benefits that increase the likelihood of its participation in future investment opportunities. These reputational effects have a greater impact when the corporate investor has extensive patent stocks and has higher levels of potential slack. Our study highlights the value of sustaining commitment in interfirm relationships, and offers a deeper understanding of an important driver of corporate venture capital program investment opportunities.", May 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000812,Growing pains in scale-ups: How scaling affects new venture employee burnout and job satisfaction,Mohamed=Genedy: Mohamed.genedy@ju.se; Karin=Hellerstedt: Karin.hellerstedt@ju.se; Lucia=Naldi: Lucia.naldi@ju.se; Johan=Wiklund: jwiklund@syr.edu,"Abstract
Although academic interest in organizational scaling is growing, extant research has focused primarily on the antecedents and processes, neglecting how employees experience scaling. Drawing on the scale-up, firm growth, and well-being literature, we take an employee perspective to examine the impact of scaling on employee burnout and job satisfaction. Using a sample of 10,908 new venture employees in Sweden, we show that scaling is positively associated with employee burnout, and negatively with job satisfaction. We also show that the link between scaling, burnout, and job satisfaction depends on whether the employee is in a managerial position or has prior new venture experience.", March 2024,"L26, M13",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000782,Sight unseen: The visibility paradox of entrepreneurship in an informal economy,Robert=Nason: robert.nason@mcgill.ca; Siddharth=Vedula: siddharth.vedula@tum.de; Joel=Bothello: joel.bothello@concordia.ca; Sophie=Bacq: sophie.bacq@imd.org; Andrew=Charman: andrew.charman@livelihoods.org.za,"Abstract
In many informal economies, entrepreneurs face a visibility paradox: increasing visibility to resource-granting stakeholders simultaneously increases exposure to resource-extracting stakeholders. To investigate this phenomenon, we leverage a unique, hand-collected, small-area census dataset of firms in the township of Delft in Cape Town, South Africa, providing rare insight into a population of otherwise unobserved firms. Through an abductive, multimethod approach, we address three interrelated research questions: (i) How do informal economy entrepreneurs make their firms visible? (ii) Which informal economy entrepreneurs make their firms visible? (iii) How does firm visibility relate to firm performance? Our analysis identifies distinct dimensions of authority- and community-oriented visibility and introduces the concept of 
selective visibility
, which refers to making a firm visible to certain stakeholders (e.g., community members) but not others (e.g., authorities). Using a 
social embeddedness
 lens, we find that while highly embedded entrepreneurs are more associated with invisibility, less embedded entrepreneurs are more associated with community-oriented selective visibility. The QCA results also indicate a configurational relationship such that visibility's association with performance varies with an entrepreneur's level of embeddedness. As a whole, our study builds theory regarding the taken-for-granted concept of firm visibility and provides important insights that are generative for entrepreneurship research in informal economies and other difficult-to-access settings.", March 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000836,Adapting a collective will and a way during a civil war: The persistence of an entrepreneurial ecosystem as an architecture of hope,Trenton Alma=Williams: trentonwilliams@byu.edu; Ramzi=Fathallah: fathallah@telfer.uottawa.ca,"Abstract
Persistent war is an increasing reality for millions of people worldwide. War contexts create a wide range of problems, but paradoxically may fuel some 
entrepreneurial activities
. This inductive, 
qualitative study
 explores how an 
entrepreneurial ecosystem
 was launched and sustained amid an ongoing civil war despite repeated setbacks, disruptions, and impediments to pursuing collective goals. Building on our longitudinal qualitative data, we show how the 
entrepreneurial ecosystem
 was repeatedly reshaped by altering collective goals as well as providing the pathways and sense of agency needed to make progress toward ever-shifting goals. Our research culminates in a grounded theoretical model of an entrepreneurial ecosystem of hope, which contributes to our comprehension of entrepreneurship within war-affected regions and provides valuable insights into the dynamics of collective hope. This study offers practical implications for policy makers and practitioners by illuminating the role of entrepreneurial phenomena in the challenging context of war.", March 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000927,Flip the tweet – the two-sided coin of entrepreneurial empathy and its ambiguous influence on new product development,Konstantin=Kurz: konstantin.kurz@tu-darmstadt.de; Carolin=Bock: carolin.bock@tu-darmstadt.de; Leonard=Hanschur: leonard@diehanschurs.de,"Abstract
Is empathy a uniformly good thing for entrepreneurs? Contrasting the hitherto predominantly positive view advocated by the extant entrepreneurship literature, we develop a novel model of entrepreneurial empathy's mechanisms and suggest a ‘too-much-of-a-good-thing’ perspective. We empirically confirm this model using a dataset of 4425 real entrepreneurs, where we find that empathy influences entrepreneurial 
new product development
 as an essential 
entrepreneurial activity
 in an inverted U-shaped pattern. We further show that empathy's negative effects are particularly detrimental for very anxious entrepreneurs. These findings provide strong evidence for considering entrepreneurial empathy an important but highly ambiguous success factor.", March 2024,"C45, C55, D91, L26, O31",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000016,When a crisis hits: An examination of the impact of the global financial crisis and the COVID-19 pandemic on financing for women entrepreneurs,Wei=Yu: iseyw@nus.edu.sg; Jipeng=Fei: fei_jp@bnu.edu.cn; Grace=Peng: b.peng@bbk.ac.uk; James=Bort: jbort@depaul.edu,"Abstract
Crises have significant implications for entrepreneurs' businesses. Female entrepreneurs are often found to suffer from crises due to their marginalized positions. Despite the increasing research at the nexus of crisis, entrepreneurship, and gender, how a crisis may influence investors' funding decisions concerning female entrepreneurs and whether different macro crises bring with them different implications remain under-explored questions. Drawing on role 
congruity theory
 and the crisis and strategic decision-making literature, this paper proposes that macro crises can shake the perceived incongruity between traditional stereotypes of the female gender role and masculine stereotypes related to the entrepreneur's role, thereby affecting financing for female entrepreneurs. We further compare two specific crises having different associated implications: the global financial crisis (GFC) and the COVID-19 pandemic. We conducted two studies, one emphasizing experimental manipulation and the second based on observational data. We found consistent evidence that investors were more likely to invest in female-founded ventures after the GFC; however, the opposite phenomenon occurred after COVID-19. Our experiment demonstrates that changed perceptions of gender role incongruity are a critical underlying mechanism driving our results. Our research has implications for both the entrepreneurship literature and role 
congruity theory
.
Executive summary
Amidst the expanding body of research on crisis, entrepreneurship, and gender, there is a predominant focus on the entrepreneur, leaving a discernible gap in our understanding of how macro-level crises specifically influence investors' funding decisions related to female entrepreneurs, and whether different types of crises lead to varying outcomes. This paper aims to bridge this gap, drawing insights from role congruity theory and integrating perspectives from crisis and strategic decision-making literature. We suggest that macro crises have the potential to shift investors' perceived incongruities between female gender roles and the masculine stereotypes commonly associated with entrepreneur roles, consequently affecting funding decisions for female-founded ventures.
To test our hypothesis, we conducted two comprehensive studies within the contexts of two different crises, each with unique implications: the Global Financial Crisis (GFC) and the COVID-19 pandemic. Our first study employed experimental manipulation, while the second relied on observational data. Across both studies, the results were consistent: post-GFC, investors demonstrated an increased propensity to invest in female-founded ventures; conversely, after the onset of COVID-19, this trend reversed. Crucially, our findings underscore the pivotal role of perceptions of gender role incongruity in shaping the observed outcomes.
Our framework enriches the existing body of literature, offering nuanced insights into how various crises may impact investors' funding decisions based on gender. Moreover, our results underscore the importance of aligning actions with macro-level shifts as we strive to cultivate more inclusive 
entrepreneurial ecosystems
.", March 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000587,Doing the right things at the right times: The role of temporal enactment in venture outcome attainment,Trey=Lewis: treylewis@vt.edu; Diana M.=Hechavarría: diana.hechavarria@ttu.edu; David W.=Williams: dww@utk.edu; Melissa S.=Cardon: mcardon@utk.edu,"Abstract
Nascent entrepreneurs (NEs) take action in the startup process by initiating startup activities in hopes of manifesting a new firm, though some NEs experience a quit outcome. Other NEs find themselves in a still trying status (i.e., continuing to work on the startup) after a span (window) of time. We draw upon recent 
entrepreneurial action
.
theory on how temporal enactment – the ways in which NEs map, or initiate, startup activities within a span of time –helps NEs navigate the uncertainty in the startup process and avoid the still trying status to instead reach a startup outcome. We take an exploratory approach to examine framing questions of: (1) How does pace (12-, 24-, or 36-month time windows) (2) engaging in specific categories of startup activities and (3) initiating specific sequences of categories of startup activities impact NEs' likelihood of reaching startup outcomes? Using logit analysis with data from the harmonized PSED, our findings show that categories of startup activities (i.e., what NEs do) as well as the pace and sequential ordering of these activities (i.e., when they do them) matter for NEs reaching startup outcomes and avoiding the still trying status. Our findings point to a consistent sequential pattern of action that maximizes NE's likelihood of reaching a startup outcome, offering an early roadmap for temporal enactment among NEs.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000563,Social entrepreneurs concerned about Impact Drift. Evidence from contexts of persistent and pervasive need,Alessia=Argiolas: alessia.argiolas@tum.de; Hans=Rawhouser: hans.rawhouser@unlv.edu; Alisa=Sydow: asydow@escp.eu,"Abstract
In the Global North, where social entrepreneurs and their stakeholders agree that social 
enterprise
 needs to do more for stakeholders than traditional business, social entrepreneurs balancing financial and pro-social goals seek to avoid mission drift by being responsive to their stakeholders. In many areas of the Global South, despite the work of 
NGOs
 and foreign aid, social problems remain persistent and pervasive, so social entrepreneurs face vastly different stakeholder demands. Our 
qualitative study
 of 36 social entrepreneurs in Kenya, 
Uganda
, and Rwanda builds on 
behavioral theory
 to understand how social entrepreneurs balance pro-social and financial goals in this context. We find that they experience a mismatch between their social impact aspirations and the expectations of stakeholders, which leads to concerns of Impact Drift, which we define as the decoupling of pro-social actions from enduring social impact outcomes. Concerns of impact drift prompt a norm-breaking approach to social impact, involving orchestrating novel coalitions of stakeholders and employing heuristics to limit their focus and reassure them about their approach.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262300054X,"From distinctiveness to optimal distinctiveness: External endorsements, innovativeness and new venture funding",Kazem=Mochkabadi: mochkabadi@wiwi.uni-wuppertal.de; Simon=Kleinert: s.kleinert@maastrichtuniversity.nl; Diemo=Urbig: urbig@b-tu.de; Christine=Volkmann: volkmann@wiwi.uni-wuppertal.de,"Abstract
We examine how external endorsements help new ventures with varying degrees of innovativeness to attract funding. According to optimal distinctiveness theory, new ventures should be as different from competitors as legitimately possible. However, initial research suggests that new ventures can also buffer their legitimacy through external endorsements. We clarify that effects of such legitimacy buffers depend critically on an audience's unique legitimacy-distinctiveness relationship. Specifically, external endorsements lead to different predictions about shifts in optimal distinctiveness for return-seeking audiences compared to novelty-seeking audiences as relevant new venture funders. For return-seeking audiences, new ventures are perceived as less legitimate when they are non-innovative or radically innovative so that incrementally innovative new ventures are most attractive without endorsements. External endorsements can thus buffer the legitimacy of non-innovative and radically innovative new ventures, but they lead to different performance implications for a return-seeking audience. While non-innovative new ventures increase their attractiveness, only radically innovative new ventures can become optimally distinctive and outperform other distinctiveness configurations. In contrast, novelty-seeking audiences already have a higher tolerance for radically innovative new ventures, so the effects of external endorsements are less pronounced. Four empirical studies, using observational data and experiments in equity and reward-based crowdfunding, provide strong support for this theory and account for alternative explanations such as risk perceptions. In turn, we shed new light on the crucial, audience-specific function of external endorsements, namely, as a means to alter optimal distinctiveness levels.", January 2024,"Innovation, Endorsements, Optimal distinctiveness, Legitimacy, Equity crowdfunding, Entrepreneurship, Reward crowdfunding, Resource acquisition",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000575,A chip off the old block: Founders' prior experience and the geographic diversification of export sales in international new ventures,Giuseppe=Criaco: criaco@rsm.nl,"Abstract
Integrating the cognition literature in entrepreneurship and strategy with the career imprinting literature, we propose that the geographic diversification of export sales in international new ventures (INVs) resembles that of their founders' most recent (geographically diversified) employer because founders bear a repertoire of the ‘logics of action’ from their employers regarding how to diversify geographically. We then propose two boundary conditions that influence the relationship between the geographic diversification of export sales of founders' most recent employers and that of their INVs: length of exposure and time since last exposure to their most recent geographically diversified employer. We test these hypotheses using longitudinal data on a sample of 3420 INVs. Our findings broadly support our theoretical propositions except for the moderating role of founders' length of exposure.", January 2024,"Geographic diversification, Export sales, International new ventures, International experience, Cognition, Founder career imprinting, International entrepreneurship",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000551,Exploring the relative efficacy of ‘within-logic contrasting’ and ‘cross-logic analogizing’ framing tactics for adopting new entrepreneurial practices in contexts of poverty,Angelique=Slade Shantz: sladeshantz@ualberta.ca; Charlene=Zietsma: czietsma@umich.edu; Geoffrey M.=Kistruck: gkistruck@schulich.yorku.ca; Luciano Barin=Cruz: luciano.barin-cruz@hec.ca,"Abstract
Entrepreneurship education and training targeting individuals living within impoverished regions has proliferated. However, empirical results suggest recipients are failing to adopt the newly prescribed practices, particularly the practice of experimenting with product, process, and marketing innovations. Research on institutional logics suggests the way practices are framed plays an important role in adoption. In a field experiment involving 683 entrepreneurs within rural Sri Lanka, we compared the effectiveness of two framing tactics: within-logic contrasting, and cross-logic analogizing. We find that cross-logic analogizing is more effective, and suggest our findings likely extend to other contexts where logics are highly institutionalized.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000617,Star entrepreneurs on digital platforms: Heavy-tailed performance distributions and their generative mechanisms,Kaushik=Gala: kgala@iastate.edu,"Abstract
This study extends emerging theories of star performers to digital platforms, an increasingly prevalent entrepreneurial context. It hypothesizes that the unique characteristics of many digital platforms (e.g., low marginal costs, feedback loops, and network effects) produce heavy-tailed performance distributions, indicating the existence of 
star entrepreneurs
. Using longitudinal data from an online learning platform, proportional differentiation is identified as the most likely generative mechanism and 
lognormal distribution
 as the most likely shape for distributions of entrepreneurial performance in digital contexts. This study contributes theory and empirical evidence for non-normal entrepreneurial performance with implications for scholars and practitioners of digital entrepreneurship.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000708,A temporal typology of entrepreneurial opportunities: Implications for the optimal timing of entrepreneurial action,Jeffery S.=McMullen: mcmullej@indiana.edu,"Abstract
Entrepreneurial opportunities emerge and dissipate over time, yet little is known about how and why they vary in their ephemerality and what the implications of temporal variance are for the optimal timing of 
entrepreneurial action
. Building on the actualization theory of opportunity and signal processing theory, we propose that profit possibilities exist in the convolution of consumer desire, technical feasibility, and economic viability of an innovation. Conceiving consumer desire – a necessary ingredient of any profit opportunity – as consisting of fleeting or enduring consumer preferences and fixed or variable consumer expectations, we identify four possible distributions of consumer desire over time. We then show how the interaction of these distributions with technical feasibility functions produces a temporal typology of entrepreneurial opportunities. Our analysis suggests that, despite sharing conceptual similarities in structure, each type of opportunity emphasizes a different form of asymmetry across opportunity categories, which is likely to differentially affect the optimal timing of 
entrepreneurial action
. We conclude by pointing out how considerations of time facilitate the move away from fruitless philosophical debates and toward a more theoretically nuanced and empirically informative view of the concept.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000745,United we stand? Organizational groups and spinoff mortality in the context of academic entrepreneurship,Aleksios=Gotsopoulos: agotsopo@g.skku.edu; Konstantinos=Pitsakis: k.pitsakis@londonmet.ac.uk,"Abstract
We study failures between 1993 and 2017 in the complete population of 1731 English and Scottish university spinoffs founded since 1977. We borrow and expand the concept of density dependence from 
organizational ecology
 to theorize that a spinoff's propensity to fail is affected by the number of spinoffs active not only in the aggregate population but also within its parent university's portfolio. We contribute to 
organizational theory
, demonstrating the importance of organizational groups that form within larger populations on individual organizations' propensity to fail. We contribute to literature on academic entrepreneurship showing that, for most universities, spinoff portfolio growth can lower associated spinoffs' failure rates, but that such effects need to be juxtaposed to the aggregate population's finite capacity to support an expanding number of spinoffs.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000733,"Climate impact, institutional context, and national climate change adaptation IP protection rates",Hyungseok=Yoon: h.yoon@leeds.ac.uk; Peter=Tashman: Peter_Tashman@uml.edu; Mirko H.=Benischke: benischke@rsm.nl; Jonathan=Doh: jonathan.doh@villanova.edu; Namil=Kim: namilkim@konkuk.ac.kr,"Abstract
We study how the physical 
effects of climate change
 motivate entrepreneurs to develop and protect 
climate change
 adaptation (CCA) 
intellectual property
 (IP) in heterogeneous ways across countries. Integrating the sustainable entrepreneurship literature with the attention-based view, we show that country-level climate impact redirects managerial attention to the disruptive potential of climate change and spurs the sector into action to pursue and protect CCA-related IP. We also find that strong intellectual-property rights regulations and environmental movements in countries strengthen this effect. Our results extend the sustainable entrepreneurship literature by showing how the 
geography
 of climate impact explains how CCA IP protection efforts are distributed globally.
Executive summary
Why do entrepreneurs in some countries engage in more climate change adaptation (CCA) intellectual property (IP) protection than others? We postulate that entrepreneurs' attention is simultaneously situated in their country's climatic and institutional environments, and that these contexts shape the salience of CCA IP protection. Formally, we predict that entrepreneurs who would normally deprioritize CCA IP protection as an opportunity in the face of more urgent socioeconomic issues become more attuned to it as their country's climate impact increases. We then theorize institutional conditions that influence entrepreneurs' responsiveness to climate impact. First, we predict that stronger 
intellectual property rights
 institutions reduce entrepreneurs' uncertainty in capturing rents from their CCA IP and hence strengthen the relationship between climate impact and CCA IP protection. Second, we predict that informal institutions aligned with environmental movements increase the salience of climate impacts to corporate entrepreneurs by spurring their interests in 
environmental issues
 and hence also strengthen the climate impact-CCA IP protection relationship. Our empirical analyses using 689 country-year observations consisting of 95 countries over the period 2005 to 2015 reveal that country-level climate impact drives CCA IP protection, especially when there are strong 
intellectual property rights
 (IPR) regimes and environmental movements.", January 2024,"Climate impact, Climate change adaptation, Innovation",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000769,ESG and crowdfunding platforms,Silvio=Vismara: silvio.vismara@unibg.it,"Abstract
We hypothesize that environmental, social, and governance (ESG) goals enable crowdfunding platforms to attract more investors and thus survive longer. Using data on the population of 508 security-based platforms established in the 38 
OECD
 countries between 2007 and 2020, we document that platforms with higher levels of ESG selection criteria are more likely to survive over time. The importance of ESG criteria is more pronounced for platforms operating in countries with lower 
power distance
. In decomposing ESG, we find that governance is the most significant component of the three, while environmental criteria have increased in importance for platform survival in recent years.", January 2024,"ESG, Fintech, Digital finance, Platforms, Entrepreneurial finance",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000770,"Interorganizational triads for foreign-market entry: Partnerships among Western, bridge-economy, and local VCs in Mainland China",Jing=Zhang: j3zhang@odu.edu; Wei=Zhang: zhangw3@sem.tsinghua.edu.cn; Andreas=Schwab: aschwab@iastate.edu,"Abstract
This study introduces the novel construct of bridge-economy partners, which can assist Western firms in learning how to collaborate with local partners when entering unfamiliar foreign countries that have substantially different socioeconomic characteristics. We offer initial empirical evidence regarding the relevance of establishing such interorganizational partnership triads among Western, bridge-economy, and local firms for the entries of Western venture capital firms (VCs) into Mainland China between 1997 and 2008. Venture age, regional legal maturity, and the Western VCs' accumulated local experience are identified as relevant contingency factors for the likelihood of adopting this type of collaboration, which involves partners from three different types of economies. We supplement our quantitative analyses with anecdotal qualitative evidence from interviews with VC executives and fund managers.
Executive summary
This study introduces the novel construct of bridge-economy partners and outlines their potentially beneficial roles in the context of foreign-market entry undertaken by Western firms. The established literature suggests that Western firms consider collaboration with a local firm as an accelerator for learning about and adapting to local conditions. However, the substantial socioeconomic differences that may exist between home and host country can create paramount challenges for collaborations between Western firms and their local partners. Adding a third type of partner from a country with substantial socioeconomic overlap to both firms' home countries can help “bridge the socioeconomic gap” between Western and local firms. The bridge-economy partners can assist Western firms in learning how to collaborate with their new local partners.
This study offers initial empirical evidence for the relevance of such interorganizational partnership triads between Western, bridge-economy, and local firms by using the data of Western VC firms and their entries into Mainland China between 1997 and 2008. Venture age, regional legal maturity, and accumulated local experience of Western VCs are identified as relevant contingency factors for the likelihood of adopting this type of triadic interorganizational partnership. Quantitative hypothesis tests are supplemented with anecdotal qualitative evidence.
Reported findings extend the emerging entrepreneurship literature that focuses on foreign-market entry and globalization. Our focus on triadic partnerships and the role of bridge-economy firms extends the previous research that has instead nearly exclusively focused on dyadic collaborations between Western firms and local partners. A triadic Western, bride-economy, and local firms (WBL) partnership offers an alternative strategy to use when entering foreign markets that have substantially different cultural, economic, and institutional characteristics. Our findings further highlight that even though such triadic WBL partnerships make intuitive sense, successfully implementing such complex collaborations requires minimum levels of accumulated host-country experiences and can benefit from mature legal environments. For policymakers in emerging economies that are interested in supporting foreign investment, the creation of legal environments conducive to forming such triadic WBL collaborations introduces a promising policy option. Beyond these initial key insights, this study also provides guidance for systematic future research into this promising type of collaboration for foreign market entry.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000757,Just a number? Using artificial intelligence to explore perceived founder age in entrepreneurial fundraising,Michael J.=Matthews: michael.j.matthews-1@ou.edu; Aaron H.=Anglin: a.anglin@tcu.edu; Marcus T.=Wolfe: mtwolfe@ou.edu,"Abstract
Leveraging work on role theory and age stereotypes, we deploy a randomized experiment that uses AI to manipulate founder age in fundraising appeals. Broadly, we find that age perceptions matter to investors. Using 949 equity crowdfunding observations, we show that entrepreneurs benefit from appearing older when seeking funding. However, these benefits wane as age perceptions increase, and age perceptions eventually become detrimental to funding efforts, resulting in an inverted-U relationship between age perceptions and funding evaluations. Perceptions of founder intelligence, creativity, energy, and experience mediate this relationship. This study opens new frontiers by introducing founder age perceptions as an important, yet overlooked factor in entrepreneurial fundraising.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000794,No politics in funding pitches: An expectancy violations theory perspective of entrepreneurs' political expressions in crowdfunding,Aaron H.=Anglin: a.anglin@tcu.edu; Jeffrey A.=Chandler: jeffrey.chandler@unt.edu; Fizza=Kanwal: fizzakanwal@unt.edu; Jeremy C.=Short: jeremy.short@unt.edu,"Abstract
Drawing from expectancy violation theory, we investigate how entrepreneurs' language-based expressions of their 
political ideology
 influence the performance of their crowdfunding campaigns. We argue that crowdfunding funders expect campaigns to be apolitical, suggesting that entrepreneurs' expressing their political ideologies – regardless of the specific ideology – create a negative expectancy violation that decreases funding performance. As 
source credibility
 is a central boundary condition for expectancy violation theory predictions, we also suggest this relationship is mitigated by three indicators of entrepreneurial credibility: prior successful experience, 
media usage
, and third-party endorsements. Using a sample of 19,898 Kickstarter campaigns and a randomized experiment, we find support for our theoretical predictions.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000800,Event-based entrepreneurship,Greg=Fisher: fisherg@indiana.edu; Matthew A.=Josefy: mjosefy@iu.edu; Emily=Neubert: eneubert@ttu.edu,"Abstract
Many entrepreneurial opportunities are associated with events, including 
sports competitions
, races and tournaments, concerts and music festivals, and conferences and exhibitions, yet this variant of entrepreneurship has not been specifically accounted for in the literature. We integrate insights from entrepreneurship research with research on temporary organizational forms, 
stakeholder theory
, and platform strategy to define Event-Based Entrepreneurship (EBE) and propose factors that account for the founding and scaling of event-based ventures. In so doing, we lay the conceptual foundations and offer theoretical and practical directions for an expanded research agenda on EBE.", January 2024,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000599,"Scalability, venture capital availability, and unicorns: Evidence from the valuation and timing of IPOs",Deepak=Somaya: dsomaya@illinois.edu; Jingya=You: jingyay3@illinois.edu,"Abstract
The growing phenomenon of highly valued startups (e.g., unicorns) poses fundamental questions for entrepreneurship research. We posit that venture scalability and VC funding availability may explain startups' IPO valuations (and timing). Highly scalable ventures may not only capture very large market opportunities, but their scaling strategies may also be constrained by the governance and regulatory burdens faced by public firms. Accordingly, we hypothesize and find that more scalable ventures undertake IPOs at higher valuations, which is positively moderated by VC funding availability. Highly scalable startups also delay their IPOs for longer but only when VC funding availability is high.", January 2024,"Scalability, Scaling, Unicorns, Initial public offerings (IPOs), Startup valuation",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000435,The benefits of having an entrepreneur-mother: Influence of mother's entrepreneurial status on human capital formation among children,Wenchao=Li: wenchaoli.1022@gmail.com; Di=Tong: tongdi@shisu.edu.cn,"Abstract
Prior research shows that childcare is a unique driver for female entrepreneurship, as entrepreneurship allows women to increase time allocation on child supervision. Yet, whether female entrepreneurship actually promotes 
childrearing
 outcomes remains contentious in extant literature. This study focuses on child 
human capital formation
 as a key childrearing outcome. Drawing on the occupational inheritance literature, we suggest that, in addition to supervision, entrepreneur-mothers may foster child human capital formation through value transmission—in particular, transmitting self-direction values to children. Using nationally representative data from China, we find that children with entrepreneur-mothers exhibit better human capital formation outcomes—especially when they are younger and female. We further show that both supervision and value transmission are present, with the latter being a more important mechanism. Reconciling conflicting views in the literature, our study has both theoretical and practical implications.
Executive summary
Prior female entrepreneurship research suggests that women often choose to be entrepreneurs out of family, particularly childrearing, considerations. Entrepreneurship offers work 
autonomy
 and scheduling flexibility, allowing entrepreneur-mothers to better allocate time to childrearing activities. Given that numerous studies document a positive relationship between maternal time allocation and childrearing outcomes, conceivably entrepreneur-mothers should achieve favorable childrearing outcomes. Entrepreneurial research focusing on the business-family interface, however, suggests female entrepreneurs often face unanticipated pressures that limit their ability to care for family members. In addition, some female entrepreneurs may be motivated more by career than by childcare considerations. As such, the relationship between female entrepreneurship and childrearing outcomes remains conceptually and empirically ambiguous. Given the foregoing situation, we examine this relationship both theoretically and empirically, focusing on child human capital formation as a specific and important childrearing outcome.
Examining how female entrepreneurship relates to child human capital formation is of both scholarly and practical importance. First, it brings enhanced clarity to our understanding of the family- and child-related consequences of female entrepreneurship, thus affording reconciliation of the ambiguous predictions found in extant theories. Accordingly, we advance research on female entrepreneurship. Exploring the relationship also adds to the family embeddedness perspective in the broader entrepreneurship literature, because child development is a crucial component within the family domain.
Second, our research has practical values and policy implications. Prospective female entrepreneurs may, regardless of their pre-entry intentions, be interested in learning how entering entrepreneurship could affect childrearing outcomes. Policymakers worldwide have been actively promoting entrepreneurship in the past few decades, mainly driven by economic and technological considerations. Because such efforts likely increase female participation in 
entrepreneurial activities
, they should be evaluated to account for their family or childrearing consequences in addition to the economic and technological implications. Therefore, we provide evidence which prospective female entrepreneurs and policymakers can use to make informed decisions.
To study the effect of female entrepreneurship on child human capital formation, we note that the ambiguous predictions in extant work arise because it predominantly focuses on whether entrepreneur-mothers can allocate more time to childrearing activities, which we call “supervision”. We suggest that this supervision mechanism is not the only way in which the intergenerational impact occurs. Drawing on 
sociological research
 in occupational inheritance, we propose that entrepreneur-mothers could foster child human capital formation through transmitting self-direction values, thus promoting children's aspirations and achievements. To test these theoretical hypotheses, we use data from a nationally representative Chinese household survey, which contains separately surveyed parent and child data.
Our empirical analyses reveal that children with entrepreneur-mothers outperform those with non-entrepreneur-mothers in both cognitive and noncognitive skills. The effect is stronger for daughters and 
younger children
. Additional analyses verify the presence of both supervision and value transmission mechanisms, with value transmission being more importantly in explaining the entrepreneur-mother effect.
Findings in this study deepen our knowledge on whether and how entrepreneur-mothers foster children's human capital formation. They highlight that—in addition to supervision—value transmission is a crucial channel through which entrepreneur-mothers exert an intergenerational impact on children. Our results also indicate that women running larger businesses—likely those with career motives and targets of policies that promote entrepreneurship—see better child human capital formation outcomes despite having potentially limited supervision capacity. Finally, our findings not only shed light on female entrepreneurship in China, a context with growing relevance in the global economy and rate of entrepreneurial activities, but also offer generalizable insights to other economies.", November 2023,"Female entrepreneurship, Child human capital formation, Childrearing, Family embeddedness perspective, Value transmission",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000538,Entrepreneurs as prime targets: Insights from Mexican ventures on the link between venture visibility and crime of varying severity,Timothy L.=Michaelis: tmichaelis@niu.edu; Paul=Sanchez-Ruiz: psanch26@iastate.edu; Matthew S.=Wood: ms_wood@ou.edu; Jaime=Suarez: jaime_suarez1@baylor.edu,"Abstract
This study addresses entrepreneurs as targets of crime. Leveraging insights from strategic responses to institutional pressures as the main theoretical frame, coupled with supporting insights from 
routine activities theory
 and interview data from 14 entrepreneurs who have been victims of crime, we introduce entrepreneur-led ventures becoming targets of crime via their engagement in routine activities that increase venture visibility. We then conceptualize that crime severity pushes entrepreneurs toward venture visibility-reduction responses, such as truncating growth, relocating, or discontinuing the venture. Survey data from 87,486 legally registered entrepreneur-led ventures in 
Mexico
 provide strong support for the relationships in our theoretical model. We find that as routine venture activities increase, entrepreneurs encounter crime of increasing severity, with the routine venture activity of making transactions at a bank serving as the strongest attractor of crime. Building on these findings, we observe an indirect effect through crime severity such that the choice to relocate the venture is the most likely response to being targeted by criminals. Our results advance the literature at the intersection of crime and entrepreneurship, especially in developing economies, and offers venture visibility as a mechanism that shapes both criminals' targeting of ventures and entrepreneurs' attempts to reduce being targeted.", November 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000423,Team resilience building in response to co-founder exits,Rebecca=Preller: Rebecca.preller@uni-bayreuth.de; Nicola=Breugst: nicola.breugst@tum.de; Holger=Patzelt: patzelt@tum.de; Rieke=Dibbern: r.dibbern@tum.de,"Abstract
Founding teams often experience the exit of co-founders. To develop theory about how founding teams deal with adversity emerging from the exit of one of their members, we take a team-resilience perspective and study the development of six founding teams. Our inductive model highlights how founding teams take different trajectories following team member exits, leading to different types of psychological closure, which impact the teams' resilience building. Our model also suggests how teams not engaging in distancing from the exit-related adversity experience additional adversity within the continuing team, eventually leading to team failure. Our findings challenge and extend extant studies on exits in founding teams and team resilience.", November 2023,"Founding teams, Entrepreneurial exit, Team resilience, Adversity, Psychological closure, Team membership change",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000605,From platform growth to platform scaling: The role of decision rules and network effects over time,Suzana=Varga: varga@rsm.nl; Magdalena=Cholakova: cholakova@rsm.nl; Justin J.P.=Jansen: jjansen@rsm.nl; Tom J.M.=Mom: tmom@rsm.nl; Guus J.M.=Kok: guus.kok@capgemini.com,"Abstract
Although firms increasingly operate with platform-based business models, only a few have been shown to prosper and survive in the long run. While the literature has traditionally focused on platform growth along with facilitating network effects through value creation, our knowledge around platform scaling remained rather limited. Using an inductive theory elaboration approach with a longitudinal 
case study
 of a two-sided platform, Takeaway.com, we offer in-depth understanding about how the top management team members used decision rules to navigate emergent opportunities and challenges over time, and to transition from platform growth to platform scaling. We find that the top management team members purposefully and repeatedly use and revise a portfolio of decision rules to cultivate indirect and data network effects, which allows them to initially facilitate the growth of their platform and over time support the transition to scaling the platform. Our findings provide important implications about the distinct nature of platform growth and platform scaling, and the role of decision rules in cultivating a combination of network effects over time in order to arrive at platform scaling and ensure platform survival and prosperity over an extended period.", November 2023,"Platforms, Growth, Scaling, Network effects, Decision rules",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000320,Visual totality of rewards-based crowdfunding pitch videos: Disentangling the impact of peak negative affective visual expression on funding outcomes,Yi=Huang: yi002@e.ntu.edu.sg; Marilyn A.=Uy: muy@ntu.edu.sg; Chang=Liu: chang015@e.ntu.edu.sg; Maw-Der=Foo: mawderfoo@ntu.edu.sg; Zhuyi Angelina=Li: lizhuyi@rmbs.ruc.edu.cn,"Abstract
In this study, we introduce visual totality of a crowdfunding pitch video which considers not only visual segments with human 
faces
 but also segments without human 
faces
. Drawing from Emotions as Social Information (EASI) theory and expression theory, we analyze more than 4 million frames in 3184 Indiegogo rewards-based crowdfunding pitch videos using the ResNet 50 deep 
neural network
. Results indicate that the impact of peak negative affective visual expression on funding performance is stronger than that of its positive counterpart for both segments with and without human 
faces
. Additionally, the influence of peak negative affective visual expression from human 
faces
 is stronger in the first half (vs. the second half) of the pitch video. Further, we found a substitute moderating effect between the peak negative affective visual expression from segments with and without human faces on funding performance. We conducted an additional data collection to ascertain that pain points serve as the underlying mechanism through which negative affective visual expressions related to funding outcome. We discuss the theoretical and practical implications of our study to the crowdfunding literature and the broader research on entrepreneurial resource acquisition.", September 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000307,Prêt-à-quitter: Career mobility and entrepreneurship in the global high-end fashion industry,Stanislav D.=Dobrev: Dobrev@uwm.edu; Kim=Claes: kc2258@cornell.edu; Frédéric=Godart: Frederic.Godart@insead.edu,"Abstract
We test a general model of career mobility and entrepreneurship based on the premise that job transitions between organizations are influenced by the unique role of the organizational founder. Three related ideas inform our inquiry. First, individuals in that role are endowed with the right to act as representatives of their organizations which increases commitment and deters external mobility. Second, the founder role, because of its uniqueness, defines how entrepreneurs think of themselves thus aligning person and position. Repeat entrepreneurship occurs because after a founder leaves, this alignment is disrupted and the need to restore it leads to becoming a founder again. Third, we see the founder role as imbued with charismatic authority. This creates an aura of deference and a propensity to emulate the founder that inspires organizational members working alongside the founder to themselves become entrepreneurs. We investigate these ideas empirically in the context of the global high-end fashion industry through a research design that allows us to compare leading designers' career histories as both founders and members and their transitions to and out of entrepreneurship.", September 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000411,Work hard or play hard: the effect of leisure crafting on opportunity recognition and venture performance,Timothy L.=Michaelis: tmichaelis@niu.edu; Alexander B.=Hamrick: alex.hamrick@richmond.edu; Ted A.=Paterson: Ted.Paterson@oregonstate.edu; Charles Y.=Murnieks: charles.murnieks@umkc.edu; Paraskevas=Petrou: petrou@essb.eur.nl,"Abstract
Given the challenges inherent in starting companies, investigation of how entrepreneurs use their time at work to develop ventures has received prominent attention by scholars. We argue that how entrepreneurs use their leisure time has not received commensurate scrutiny. Leisure crafting, the proactive pursuit of particular leisure activities for specific goals, could play an important role in the entrepreneurial process. Herein, we develop and test a theoretical model describing how leisure crafting among entrepreneurs affects opportunity recognition and venture performance. Using three studies we provide strong evidence that leisure crafting positively relates to opportunity recognition and venture performance, which is mediated by thriving at work and moderated by work task focus. These findings provide generative insights into the nature of leisure and the micro-processes that drive entrepreneurship.", September 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262300040X,The entrepreneur identity assimilation process: It's not all work and no play,Claudia G.=Smith: smithcg@uvic.ca; Shasha=Liu: shashaliu@sdu.edu.cn; J. Brock=Smith: smithb@uvic.ca,"Abstract
We develop a comprehensive entrepreneur identity assimilation process model by drawing on in-depth interviews with 30 employees who completed the process and 12 employees who initiated but did not complete it. Extending identity process and identity-play theories, we uncover the mechanisms of daydream-play and substantive play undertaken in phases of broad, focused and specific exploration leading to identity assimilation. Extending 
prior knowledge
 of possible selves, we also find that the dynamic pairing of undesirable employee possible self and aspirational entrepreneur possible self builds commitment to entrepreneur identity assimilation over time. Implications for theory and practice are discussed.", September 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000137,Network to passion or passion to network? Disentangling entrepreneurial passion selection and contagion effects among peers and teams in a startup accelerator,Kai=Becker: k.becker@vu.nl; Joris J.=Ebbers: jebbers@luiss.nl; Yuval=Engel: y.engel@uva.nl,"Abstract
Entrepreneurial passion is socially contagious. However, do entrepreneurs also select whom they interact with based on passion similarity? The complex 
interdependencies
 between social networks and entrepreneurial passion remain undertheorized and empirically puzzling. Using a stochastic actor-oriented model (SIENA) and four waves of panel data, we test hypotheses about the co-evolution of social networks and entrepreneurial passion during a 5-month startup accelerator program. We observe that social ties occur more frequently among peer entrepreneurs who are similar in levels of passion for founding. Initial 
homophily
 selection explains 34% of this observed similarity whereas 
social contagion
 explains 57%. Finally, we find that passion for founding is more contagious among members of startup teams than across other peer ties. Surprisingly, none of these effects are significant for passion for inventing. We discuss the theoretical and practical implications of these findings.", July 2023,"Entrepreneurial passion, Social networks, Peer selection, Social contagion, Stochastic actor-oriented model, SIENA",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000174,Facing the future through entrepreneurship theory: A prospective inquiry framework,Pablo=Muñoz: pablo.munoz-roman@durham.ac.uk; Dimo=Dimov: dpd24@bath.ac.uk,"Abstract
In this paper, we address a thorny challenge: how can entrepreneurship scholarship enhance its impact without compromising the pursuit of conceptual rigor and theoretical novelty? We propose a 
prospective
 inquiry framework for entrepreneurship. It aims to align the scholarly pursuit of theoretical novelty with the entrepreneurs' focus on the future, in a shared aspiration to make a difference in the world. By expanding the focus of theoretical work toward the future, scholarship can focus on the formulation, exploration, and evaluation of alternatives to the present, as theories for desired futures. Prospective inquiry retains the primacy of theorizing while expanding its purpose, value, and use in entrepreneurship research, unleashing its generative power. It opens new spaces for theoretical excellence, dissolves the research-practice gap, and allows researchers and practitioners to theorize and enact their aspirations for the future.", July 2023,"Entrepreneurship theory, Research-practice gap, Prospective theorizing, Co-creation, Scholarly impact",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000265,Not so silent partners: Exploring the interconnected roles of entrepreneurs and their spouses,Blake=Mathias: bdmathia@iu.edu; Stephanie=Wang: slwang@iu.edu,"Abstract
When launching their ventures, the majority of entrepreneurs are married. Yet, our understanding of the spousal influence on the entrepreneurial process remains limited. This is surprising considering the spouse represents one of the most influential figures in an individual's life. Through an inductive qualitative analysis of 18 spouse-entrepreneur pairs, we explore the interactive nature of venture-related roles between the spousal couple and how these spousal roles evolve over the course of the venture. Our study shows that the dynamic alignment between entrepreneurial roles and spousal roles allows the venture to progress through various stages of firm innovation, creation, and growth. Thus, our paper extends the broader literature on roles during the venturing process as we illuminate the “not-so-silent role” of spouses in entrepreneurship.", July 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000162,Moving on: Narrative identity reconstruction after entrepreneurial failure,Itziar=Castelló: Itziar.Castello-Molina@city.ac.uk; David=Barberá-Tomás: jobarto@ingenio.upv.es; Eero=Vaara: eero.vaara@sbs.ox.ac.uk,"Abstract
Despite increasing interest in the narratives of entrepreneurial failure, the understanding of how entrepreneurs reconstruct their identity as they advance from experiences of failure to new ventures remains partial. Based on a narrative analysis of 49 entrepreneurs' experiences, we uncover three narrative types used by entrepreneurs when moving on: shielding, transformation, and authenticity. In particular, we elaborate on how the entrepreneurs employ specific discursive practices in their narratives to deal with three central aspects of identity reconstruction: construction of responsibility, identity transition, and identity validation. Thus, our analysis elucidates the narrative underpinnings of dealing with failure and deepens our understanding of entrepreneurial identity construction in the context of moving on.", July 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000277,A tale of two life stages: The imprinting effect of macroeconomic contractions on later life entrepreneurship,Panagiotis=Sotirakopoulos: panagiotis.sotirakopoulos@curtin.edu.au; Matthew P.=Mount: matthew.mount@adelaide.edu.au; Cahit=Guven: cahit.guven@gmail.com; Aydogan=Ulker: aydogan.ulker@deakin.edu.au; Carol=Graham: cgraham@brookings.edu,"Abstract
Studies argue that 
macroeconomic
 contractions create immediate incentives for individuals to pursue entrepreneurship. However, research has not addressed whether past 
macroeconomic
 contractions 
imprint
 on individuals and influence their future entrepreneurship. Integrating literature on the business cycle and imprinting with insights from lifespan psychology, we develop and test competing theoretical arguments aligned to two distinct life stages about 
when
 a 
macroeconomic
 contraction will imprint on individuals to influence their future entrepreneurship, and 
how
 such effects are imprinted. Our findings show that only contractions experienced during early adulthood influence entrepreneurship and this effect is transmitted culturally via country-level preferences for time discounting.", July 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000289,Early-stage business model experimentation and pivoting,Devin=Burnell: dsburnel@iu.edu,"Abstract
Recent literature suggests entrepreneurs struggle to pivot—or fundamentally change aspects of their venture—due to identity-based resistance to change. Yet, when entrepreneurs receive negative feedback, overcoming this resistance may be important to pivoting their business model. We adopt a convergent, 
mixed methods
 research design to explore when and why some entrepreneurs overcome resistance to change in response to negative feedback during early-stage business model experimentation. Building upon qualitative data that we gathered and analyzed, we theorize entrepreneurs may resist pivoting their value proposition relative to other business model components despite receiving negative feedback on this aspect of their business model. However, we find three factors – 
entrepreneurial experience
, startup mentoring, and team size – may enable entrepreneurs to pivot in response to negative feedback. We theorize that these factors broaden a startup team's perspective, enabling value proposition pivoting during early-stage business model experimentation. We test these relationships with quantitative data from 80 startups engaged in business model experimentation and find support across hypotheses. We contribute to understanding when and why entrepreneurs pivot aspects of their business models in response to negative feedback during early-stage business model experimentation.
Executive summary
The entrepreneurship literature suggests startups may benefit from experimentation and pivoting different parts of their business model in response to negative feedback from stakeholders (Andries et al., 2021; Camuffo et al., 2020; Shepherd and Gruber, 2021). In early stages of starting a new venture, a business model refers to a cognitive schema or belief about an activity system that could potentially create and capture value (Massa et al., 2017; Shepherd and Gruber, 2021). Business model experimentation is the process of testing assumptions underlying this potential business model and pivoting business model assumptions in response to negative feedback (Andries et al., 2013; McDonald and Eisenhardt, 2020; Leatherbee and Katila, 2020). Building upon prior literature, we define 
business model pivoting
 as a fundamental change to parts of the business model (Berends et al., 2021; Snihur and Clarysse, 2022; Shepherd and Gruber, 2021). Yet, literature also suggests founders often struggle to pivot assumptions despite negative feedback. Motives to preserve and protect certain assumptions relevant to founders' identities can interfere with pivoting (Grimes, 2018; Kirtley and O'Mahony, 2023; Zuzul and Tripsas, 2020). Despite the general understanding that founders struggle to change their ideas, however, the entrepreneurship literature currently lacks precise insight into when and why founders can overcome resistance to pivoting.
In this research, we explore when and why startups pivot different parts of their business model. We do so within the context of early-stage business model experimentation, where founders explicitly state assumptions about different parts of their potential business model, test those assumptions against stakeholder feedback, and are encouraged to pivot business model components in response to negative feedback. Through a 
mixed methods research design
, we find (1) founders tend to resist pivoting their value propositions relative to other parts of a business model in response to negative feedback; and (2) 
entrepreneurial experience
, startup mentoring, and team size enables startups to overcome this resistance to pivoting in response to negative feedback. We theorize these factors broaden founders' perspectives (Warshay, 1962), contributing to a greater willingness to pivot during experimentation.
We contribute to the literature on entrepreneurial pivoting by explaining nuanced variation in pivoting distinct business model components during experimentation. This contribution is important because it reveals that resistance to pivoting the business model may be more complex than previously thought. We also contribute to the literature at the nexus of business model experimentation and entrepreneurial cognition by finding that entrepreneurial experience, startup mentoring, and team size enable startups to pivot despite psychological resistance to pivoting in response to negative feedback because it broadens founders' perspectives. This insight is important theoretically because it advances what we know about enabling experimenting with business models under conditions of uncertainty. The research presented here has clear and important implications for practice. This research suggests founders often resist changing the value proposition versus other components of their business models in early stages of venture development. This resistance can impede experimentation and pivoting in response to negative feedback. To the extent founders want to broaden their perspective to enable pivoting their value propositions in response to negative feedback during early stages of venture development, our data suggest they may be able to do so by recruiting members with entrepreneurial experience on their team (or gain entrepreneurial experience themselves), engage frequently with startup mentors, and increase the size of their team. Overall, we view the breath of perspective that comes from experience and interactions with others as an advantage for entrepreneurs when experimenting with their business models during early stages of venture development.", July 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000290,Preparing for scaling: A study on founder role evolution,Nicola=Breugst: nicola.breugst@tum.de; Evy=Van Lancker: Evy.VanLancker@UGent.be; Mirjam=Knockaert: Mirjam.Knockaert@UGent.be; Veroniek=Collewaert: Veroniek.Collewaert@Vlerick.com,"Abstract
One of the major entrepreneurial challenges faced by scaling firms involves changing their internal organization. Our study focuses on a particular aspect of internal organizing—namely, how founder roles evolve in preparation for scaling. By means of an in-depth 
case study
 and a combination of data collection methods, we study the evolution of formal and informal founder roles. For both types of roles, we identify a founder-driven and an interaction-driven phase, during which founder and/or joiner role-crafting take place. Through both types of role-crafting, founder roles are (re)shaped. Particularly unique to our study is that we identify three scaling-specific paths through which the role-crafting of joiners shapes founders' roles. Specifically, founders experience a role efficiency increase as they take over some of the joiner-introduced role behaviors, or a role set decrease as joiners take over some of their (formal or informal) roles. We further point to the importance of psychological safety and value fit for successful joiner role-crafting to occur and for founder roles to change following founder-joiner interactions. Our study adds to the literatures on scaling and entrepreneurship as well as to role theory and role-crafting literature.", July 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262300006X,Progress without a venture? Individual benefits of post-disruption entrepreneuring,Sara=Thorgren: sara.thorgren@ltu.se; Trenton Alma=Williams: trenwill@iu.edu,"Abstract
Entrepreneurial action
 only rarely results in the full transition to venture creation. Yet, extant research has focused almost exclusively on explaining how entrepreneurial action influences venture performance outcomes such as emergence and growth. Therefore, to advance theory, there is a need to uncover other outcomes of entrepreneurial action by decoupling it from venture creation. In this study, we begin such decoupling by exploring how entrepreneurial action can create individual benefits irrespective of venture emergence and financial success. We collected longitudinal data from a group of individuals who, due to forced migration, experienced significant disruption and then engaged in entrepreneurial action with the general goal of adapting to a new (to them) context. From this data, we integrated theory on entrepreneuring to develop a grounded model of post-disruption entrepreneuring. This model has three main components: (a) 
disruption assessment impact
—interpretation of how the disruption will influence one's ability to pursue tasks and goals that provide meaning in life; (b) 
use of entrepreneuring
—function and application of entrepreneuring activities in addressing opportunities or threats; and (c) 
projected goals
—anticipated outcomes that provide meaning, motivation, and purpose. These attempts at assessing the contextual conditions provide individuals with an objective way of framing their situation. Thus, entrepreneuring can serve as an accessible mental structure that facilitates adaptation. In elaborating on post-disruption entrepreneuring, this study contributes to the literature by demonstrating the generative capacity of entrepreneurial action even in the absence of venture creation.", May 2023,"Entrepreneuring, Disruption, Entrepreneurial action, Individual outcomes, Rewards",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000970,A system dynamics modelling of entrepreneurship and growth within firms,Jinfeng=Lu: jl2647@bath.ac.uk; Dimo=Dimov: d.p.dimov@bath.ac.uk,"Abstract
This paper uses system dynamics modelling to explore processes through which entrepreneurial initiatives within firms lead to firm growth. Our model captures the interplay among various sub-processes and finds these processes form a complex system involving multiple interacting feedback processes. Simulation analysis shows that minor changes in firm conditions could lead to qualitatively different growth trajectories. They involve growth dynamics such as better before worse and worse before better scenarios. These findings prompt us to move beyond linear understanding of how entrepreneurship contributes to firm growth.", May 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000150,Rationality in the entrepreneurship process: Is being rational actually rational? Introduction to the special issue,Melissa S.=Cardon: mcardon@utk.edu; Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Matthew W.=Rutherford: matthew.rutherford@okstate.edu; Enrica N.=Ruggs: enruggs@bauer.uh.edu; Lakshmi=Balachandra: lbalachandra@babson.edu; Robert A.=Baron: robert.baron@okstate.edu,"Abstract
In this special issue, we aim to explore the topic of rationality and its manifestations in entrepreneurship. The six articles in this special issue cover a range of questions about rationality – what it is, where it comes from, how it influences decision-making as well as understanding contextual factors that influence it. Reflecting our call for submissions as well as the accepted articles included in this special issue, we recognize, but also depart from, rationality's origins in economics to provide a range of perspectives on rationality in the entrepreneurship process. We also discuss common themes and future research directions for the field.", May 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000149,From community rootedness to individuated entrepreneuring: The development of entrepreneurial motivation through a temporary community of practice,Yuliya=Shymko: yshymko@audencia.com; Theodore A.=Khoury: tkhoury@pdx.edu,"Abstract
We study the development of entrepreneurial motivation of participants in an Ecuadorian incubator. Using a narrative inquiry approach based on 41 interviews, we uncover how different modes of rootedness in distinct communities shape entrepreneurial dispositions and shed light on the role of a temporary community of practice in intermediating the development and ultimate transformation of these dispositions into individuated motivations. By bringing to the frontline the role of communities in shaping the formation process of entrepreneurial motivation, we offer a new theoretical angle for understanding intricate relations between social embeddedness, temporary communities of practice, and entrepreneurial pursuits in non-Western contexts.", May 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000830,The nature and origins of social venture mission: An exploratory study of political ideology and moral foundations,David S.=Lucas: dlucas01@syr.edu; U. David=Park: udpark@syr.edu,"Abstract
Although organizational mission is central to social venturing, little is known about the nature and origins of social ventures' missions. In particular, the field lacks a framework for understanding the moral content of nascent ventures' “prosocial” missions that rely on quite different—and potentially conflicting—moral values. We engage in an exploratory study, drawing on moral foundations theory and upper echelons theory to develop framing questions related to the moral discourse in social venture missions and the role of founders' 
political ideology
 in relation to this moral discourse. We construct a novel dataset using computer-aided text analysis on the mission statements of over 50,000 nascent nonprofit ventures in the United States, supplemented by voter registration data from 17 states and Washington, D.C. Our findings reveal rich nuance in the moral discourse found in organizations' mission statements. Furthermore, founding teams' political ideologies are strongly associated with the moral discourse in their social ventures' stated missions—and in ways that differ intriguingly from findings in moral psychology at the individual level. We draw on these new insights to develop a roadmap for future research on organizational mission in relation to social venturing, moral markets, mission drift, and 
political ideology
.", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000829,"The good, the bad and the uncertain: Employers' perceptions of former entrepreneurs",Alexander=Küsshauer: kuesshauer@uni-bonn.de; Matthias=Baum: matthias.baum@uni-bayreuth.de,"Abstract
Do employers perceive former entrepreneurs as suitable candidates for paid employment? We argue that (positive and negative) stereotypes and uncertainty drive 
employability
 perceptions regarding former entrepreneurs; these perceptions are contingent upon job type and the background of both the applicant and the person evaluating them. Two empirical studies yield broad support for our predictions. In Study 1 (a vignette study), we find lower 
employability
 perceptions regarding former entrepreneurs compared to other applicants, which are significantly mediated by positive and negative stereotypes as well as uncertainty perceptions. In Study 2 (conjoint experiments with two separate samples: recruiters and executives), we substantiate the results of Study 1, revealing that when former entrepreneurs apply for a job involving personnel responsibility or when there is evidence of a failure in their vita, they are less likely to 
face
 devaluations. Further, we find evidence for similarity effects; more specifically, entrepreneurs do not suffer from employability devaluation when the recruiter is a part-time entrepreneur or the executive is the business owner. We discuss the implications as part of the employability debate about former entrepreneurs.", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000842,Job burnout and work engagement in entrepreneurs: How the psychological utility of entrepreneurship drives healthy engagement,Ewald=Kibler: ewald.kibler@aalto.fi; Martin=Obschonka: m.obschonka@uva.nl; Ignacio=Pavez: ignaciopavez@udd.cl; Teemu=Kautonen: teemu.kautonen@uaeu.ac.ae; Katariina=Salmela-Aro: katariina.salmela-aro@helsinki.fi; Joakim=Wincent: joakim.wincent@hanken.fi,"Abstract
What is the real value of entrepreneurship? We propose a framework of psychological utility by integrating Job Demands-Resources (JD-R) theory with a recovery approach from a personal agency perspective. We hypothesize that personal agency together with the positive JD-R pattern of entrepreneurship generates outstanding psychological utility, which maintains and rewards a healthy, strong work engagement that spills over to off-work time. This benefits entrepreneurs, but also their businesses reliant on strong work engagement that avoids burnout. We validate our framework by means of panel data comprising four waves (348 entrepreneurs and 1002 employees), where we also analyze different types of entrepreneurs.", March 2023,"Entrepreneurship, Psychological utility, Well-being, Job burnout, Work engagement, Work recovery, Job demands, Job resources, Psychological capital, Solo entrepreneurs",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000945,"Tweeting like Elon? Provocative language, new-venture status, and audience engagement on social media",Benedikt David Christian=Seigner: b.seigner@lmu.de; Hana=Milanov: hana.milanov@tum.de; Erik=Lundmark: erik.lundmark@mq.edu.au; Dean A.=Shepherd: dshephe1@nd.edu,"Abstract
This article theorizes and empirically investigates how status and provocative language influence audience engagement with new-venture posts on social media platforms. Using venture capital funding as a status proxy, we analyzed 369,142 Twitter posts by 268 new ventures. We found that status (1) increases engagement with ventures' tweets, and that it (2) moderates the effect of provocative language on audience engagement so that provocative language has a negative effect for low-status ventures but a positive effect for high-status ventures. Post-hoc analyses provide a basis for pragmatic theorizing and explore the effects of status tiers and subdimensions of provocative language.", March 2023,"Audience engagement, Social media platforms, Provocative language, Status, Venture capital",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000969,Investing in yourself by investing in the field: The long-term benefits of reviewing,Jeffery S.=McMullen: mcmullej@indiana.edu; Scott L.=Newbert: scott.newbert@baruch.cuny.edu,"Abstract
This editorial highlights the importance of a robust reviewer pool to the development of the field. We emphasize the role that authors play in ensuring the sustainability of that commons and consider both the field-level and individual-level consequences of failing to do so. In addition, we make a case for the long-term benefits of reviewing, while exploring strategic and tactical concerns such as where you should be reviewing, how much you should be reviewing, whether and when to review, who should review, and, finally, how to develop a reputation as a good reviewer.", March 2023,"Development of an academic field, Review process, Reviewer pool, Reviewing, Tragedy of the commons",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000982,A founding-team model of creating a venture's culture,Dean A.=Shepherd: dshephe1@nd.edu,"Abstract
As many new ventures are started by founding teams, it is these founding teams that likely engage in creating their venture's culture. We draw on theories of cultural dynamics and the literature on team cognitive diversity to investigate the creation of a new venture's culture. Specifically, we theorize how a founding team's cognitive diversity impacts the team's production of cultural information and the transmission of that information throughout the venture. Cognitive diversity directly influences the founding team's production of cultural information by shaping the diversity of the information set and the speed of its production. Moreover, cognitive diversity can give rise to faultlines within the venture, impacting how venture members interpret cultural information. Importantly, our model suggests a complex interplay between the production and interpretation of cultural information. Understanding culture creation in new ventures is important because a new venture's culture shapes its legitimacy and thus its access to stakeholder resources for venture emergence.", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000022,Community and aftershock: New venture founding in the wake of deadly natural disasters,Arkangel M.=Cordero: arkangel.cordero@utsa.edu,"Abstract
The entrepreneurship literature has advanced our understanding of how natural disasters affect new venture founding in their wake. However, despite providing valuable insights, most existing studies focus on theoretical mechanisms that, explicitly or implicitly, invoke material losses or do not hone in on the theoretical effect of human losses caused by these events. This is an important omission because the social psychology literature suggests that individual reactions to human death are not only stronger than (i.e., higher in scale), but qualitatively different (i.e., 
infinitely stronger
) from, those involving other types of losses. The present study addresses this oversight by drawing from the social psychology literature on the emotive and cognitive heuristics (e.g., the incidental emotion and availability biases) induced by human death and developing and testing a theory of how the death toll caused by natural disasters decreases new venture founding by inducing irresolvable uncertainty. Moreover, the study draws from research on how strong pre-disaster local participation in voluntary associations—by increasing the social, symbolic, cultural and material resources in a community—protects against such negative effects. Contributions to both the post-disaster venturing and the broader resiliency literatures are discussed.
Executive summary
Natural disasters are on the rise, and the United Nations predicts that these phenomena will pose the single most important threat to social, political and economic stability in the upcoming decades. Entrepreneurship holds great promise for helping regions recover from the havoc wreaked by these events. However, much of the existing entrepreneurship research has not focused sufficiently on how the human death toll caused by natural disasters affects subsequent new venture creation. This is an important question because the existing psychology literature suggests that human death elicits disproportionately high negative individual reactions, which may lead prospective entrepreneurs in afflicted regions to stop or delay their plans to start new ventures, precisely at the time when those ventures are needed the most to help with regional recovery. This study fills this gap by examining how the death toll caused by natural disasters affect new venture creation in counties in the United States between 1991 and 2018. The study finds that the death toll caused by natural disasters in a county has a negative effect on post-disaster venturing in that county, but that strong pre-disaster participation in voluntary associations (e.g., the Girl Scouts, parent teacher associations, etc.) protects against this effect because it allows communities to work together to overcome the challenges posed by these deadly events. This last result highlights the importance that policymakers at every government level and local communities realize the critical role that local participation in voluntary associations prior to deadly disasters can have in fostering entrepreneurship after such events, thereby accelerating regional recovery.", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000010,Childhood adversities: Mixed blessings for entrepreneurial entry,Wei=Yu: iseyw@nus.edu.sg,"Abstract
The 
developmental psychology
 literature has linked childhood adversities to detrimental development outcomes that can undermine 
labor market
 participation and performance. In contrast, emerging entrepreneurship studies raise the possibility that childhood adversities may positively affect entrepreneurial action with some diverging findings. We reconcile these opposing theoretical perspectives in their effects on entrepreneurial entry by theorizing that childhood adversities are a mixed blessing for entrepreneurship and affect entry through two countervailing theoretical mechanisms. Childhood adversities increase the likelihood of entrepreneurial entry by promoting rule-breaking tendency and simultaneously decrease the likelihood of entry by negatively impacting individual ability (self-efficacy and educational attainment). We further theorized that childhood adversities have different implications for different types of entrepreneurial entry (incorporated and unincorporated) and for men versus women. We tested our hypotheses on a longitudinal sample of 4222 individuals from the NLSY79 child and young adult cohort data, which tracks the development of children born to a representative sample of U.S. young women from childhood through youth to adulthood. Our study offers new insight into the effects of childhood adversities on entrepreneurship, including gender-specific manifestations and outcomes of childhood adversities.", March 2023,"Entrepreneurship, Childhood adversity, Rule-breaking, Self-efficacy, Educational attainment, Gender",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000046,Empathy-driven entrepreneurial action: Well-being outcomes for entrepreneurs and target beneficiaries,Dean A.=Shepherd: dshephe1@nd.edu,"Abstract
Empathy is a primary driver of social entrepreneurship and 
entrepreneurial action
. However, empathizing individuals can arrive at different conclusions about what targets need. This variance in entrepreneurs' empathy for targets is important because it will help explain the type of interventions they initiate to help targets and the production of a range of benefits and costs for the targets and the entrepreneur. This study builds on and extends the theory of empathic interpersonal emotion regulation to construct an empathy-driven entrepreneurial-action model of well-being. We explore how an entrepreneur's empathy orientation for entrepreneurial action—the patterned way entrepreneurs focus their attention on a target's problems and then seek to enact this position through 
entrepreneurial action
 to help the target—shapes the organizing of an entrepreneurial intervention and the likely outcomes. We theorize entrepreneurial orientation of entrepreneurial action manifests as a hedonic paternalistic, counterhedonic, paternalistic, hedonic cooperative, or counter-hedonic cooperative. This empathy-driven entrepreneurial-action model of well-being contributes to the social entrepreneurship literature and inter-personal theories of empathy.", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000034,Actions in words: How entrepreneurs use diversified and changing speech acts to achieve funding success,Pyayt P.=Oo: pyayt.oo@uta.edu,"Abstract
Linguistic attributes in entrepreneurs' funding campaign descriptions play an important role in attracting resources. Going beyond examining the effect of individual linguistic attributes, this study takes a portfolio approach by viewing a narrative as a portfolio or collection of linguistic attributes. Specifically, we posit a narrative as a portfolio of “speech acts” and examine the combined effects of select speech acts based on their variation within a narrative. Speech acts are actions that a communicator performs with their words, such as making an assertion, establishing a commitment, expressing feelings, and directing listeners to evoke certain behaviors. Drawing on the stimuli variation perspective and speech acts theory, we examine how the diversity of and changes in “
speech acts
” in a narrative can influence funding outcomes. Using a sample of 28,000 crowdfunding campaigns and a supervised machine-learning approach, we find that entrepreneurs who adopt a variety of speech acts and frequently change from one speech act to another in a narrative are more likely to achieve funding success. Results also support inverted U-shaped relationships of individual speech acts with funding success. This study contributes to both the entrepreneurial narratives and resource acquisition literatures.", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000058,"Crime, community social capital and entrepreneurship: Evidence from Australian communities",Sefa=Awaworyi Churchill: sefa.churchill@rmit.edu.au; Mathew=Hayward: mathew.hayward@monash.edu; Trong-Anh=Trinh: trong-anh.trinh@monash.edu,"Abstract
Crime is an anti-social blight on communities that increases the cost of doing business, including for entrepreneurs. Drawing on Australian longitudinal data, this study examines the links between crime rates and the propensity for entrepreneurship within communities. We do so by matching propensity for entrepreneurship with types of crime found at the community level where crime occurs. We find that higher total crime rates, crimes against the person and property crime, significantly lower the propensity for entrepreneurship in communities. We also show that the core facets of community social capital – trust, membership in voluntary organizations and support and cooperation – mediate this relationship.
Executive summary
We comprehensively examine whether higher community crime rates – crime on people and crime on property – cause lower rates of entrepreneurship.
 Entrepreneurship research extensively examines how gaining social capital, defined as the social resources one gains within one's community, promotes entrepreneurship. This study considers whether a pervasive community dynamic in crime impedes entrepreneurship. Specifically, we show that the two main kinds of crime – people and property – inhibit entrepreneurship.
We show the facets of community social capital that mediate the relationship between crime and entrepreneurship.
 We inform the role of community-based social capital in promoting entrepreneurship (Kwon et al., 2013) by considering how higher crime lowers social capital and in turn entrepreneurship. We show that core facets of relational social capital – trust, voluntary membership in community bodies, support, and cooperation – mediate the relationship between crime and entrepreneurship. Likewise, communities with more robust reserves of social capital are better able to withstand crime and promote entrepreneurship.
Examining the link between crime and entrepreneurship allows us to contribute to the literature on entrepreneurship and social capital.
 We discuss the various ways in which crime diminishes social capital to shape entrepreneurship. In our framework that is predicated on theory on community social capital, crime creates distrust because it causes citizens to be wearier and more suspicious of each other, impeding sharing of ideas and knowledge for ventures. Crime impedes the efficacy and membership of community-based organizations that allow entrepreneurs to network. Crime reduces the support available for founders to start and sustain businesses in focal communities, as individuals seek opportunities and resources outside their communities. Crime diminishes the extent to which people take pride in and identify with their communities, as evidenced by voluntary membership in community organizations. Crime reduces collaboration because it leads to self-protective behaviors, including flight from high-crime communities, that hinder norms of reciprocity. Crime reduces cooperation as criminals are more likely to resort to coercion, as enforced by monitoring and violence, to solve business problems.
Findings rely on a comprehensive database of crime rates across Australian postcodes.
 Crime is typically a localized phenomenon – it affects business outcomes in local communities. We obtain community-level crime rates from each Australian state and 
territory
 police force or relevant government agencies and match these data with entrepreneurship rates by postcode. Our primary identification strategy follows Dustmann and Fasani (2016), who estimate the effect of local area crime on mental health in the United Kingdom (UK). This identification strategy removes the effects of residential sorting and correlates crime with time-varying unobserved entrepreneurship determinants if there is no endogenous migration from local crime. The main findings are robust to instrumenting for local area crime to which movers are exposed and for historical abortion rates in the state or 
territory
 where the individual lives, as well as a number of other approaches to obtaining causal inference.
The article holds considerable practical relevance for policymakers seeking to promote community entrepreneurship
. Our study is highly relevant to community leaders and policymakers working to boost local entrepreneurship. Findings strongly suggest that efforts to reduce crime are a primary mechanism to protect social capital within communities and, therefore, entrepreneurship. Policy initiatives dedicated to creating and expanding social ventures would a) boost entrepreneurship and social capital and b) mitigate the detrimental effects of crime on entrepreneurship (Wry and York, 2017).", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000702,"Financing sustainable entrepreneurship: ESG measurement, valuation, and performance",Sasan=Mansouri: mansouri@finance.uni-frankfurt.de; Paul P.=Momtaz: momtaz@ucla.edu,"Abstract
Sustainability orientation has a positive effect on startups' initial valuation and a negative effect on their post-funding financial performance. All else equal, improving sustainability orientation by one 
standard deviation
 increases startups' funding amount by 28 % and decreases investors' abnormal returns per post-funding year by 16 %. The results hold in a large sample of blockchain-based crowdfunding campaigns, also known as Initial Coin Offerings (ICOs) or token offerings. A key contribution is a machine-learning approach to assess startups' Environment, Society and Governance (ESG) properties from textual data, which we make readily available at 
www.SustainableEntrepreneurship.org
.", November 2022,"L26, M13, Q01, Q56",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000714,(S)training experiences: Toward understanding decreases in entrepreneurial self-efficacy during action-oriented entrepreneurship training,Carina=Bohlayer: carina.bohlayer@leuphana.de; Michael M.=Gielnik: gielnik@leuphana.de,"Abstract
While most participants benefit from action-oriented entrepreneurship training, such programs can paradoxically also have negative effects. Training programs in which participants actively engage in entrepreneurship involve facing problems that might be too difficult to overcome, potentially decreasing trainees' entrepreneurial self-efficacy. Based on theories of self-regulation, we argue that error mastery orientation is a factor that explains under which condition problems do or do not lead to decreases in entrepreneurial self-efficacy during training. To test our model, we conducted a 12-week action-oriented training program and applied a longitudinal design with one 
baseline measurement
, seven measurements during training, and one measurement after training. Analyses based on 415 lagged observations from 109 training participants indicated that participants with low error mastery orientation experienced decreases in entrepreneurial self-efficacy during training when facing problems. In contrast, participants high in error mastery orientation could buffer the negative effects of problems on entrepreneurial self-efficacy. Our results suggest that error mastery orientation is a critical factor to understand why participants' episodic experiences of problems during training negatively influence their entrepreneurial self-efficacy. Shedding light on these self-regulatory factors advances the understanding of the potential dark side of action-oriented entrepreneurship training.", January 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000805,Inclusive entrepreneurship: A call for a shared theoretical conversation about unconventional entrepreneurs,Jeffery S.=McMullen: mcmullej@indiana.edu; Rene M.=Bakker: bakker@rsm.nl,"Abstract
Entrepreneurship has the potential to be an inclusive space comprising many types of conventional as well as unconventional entrepreneurs. In this essay we will argue that when it comes to unconventional entrepreneurs—ranging from refugee entrepreneurs and entrepreneurs with a physical or cognitive disability, to 
elder
 entrepreneurs, former convict entrepreneurs, and many others—there are important questions we are not asking because we tend to look at each subgroup in isolation. Our central message is that looking for shared wisdom across various groups of unconventional entrepreneurs may facilitate a shared theoretical conversation that aids the transfer of knowledge, prevents silos and the unnecessary reinventing of the wheel, boosts the field's appeal and critical mass, and facilitates a broader exchange of ideas. To facilitate that conversation, we identify who unconventional entrepreneurs are; identify obstacles to a common theoretical conversation and how these obstacles could be overcome; outline a set of common theoretical themes that apply across various groups of unconventional entrepreneurs; and show how further theorizing unconventional entrepreneurs could challenge the community to reach beyond our existing knowledge horizons to develop pioneering entrepreneurship research.", January 2023,"Inclusion, Unconventional entrepreneurs, Underdog entrepreneurs, Inclusive entrepreneurship",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000817,Institutional work to navigate ethical dilemmas: Evidence from a social enterprise,Pradeep Kumar=Hota: pradeep.hota@thapar.edu; Babita=Bhatt: babita.bhatt@anu.edu.au; Israr=Qureshi: israr.qureshi@anu.edu.au,"Abstract
Social entrepreneurs encounter 
ethical dilemmas
 while addressing their social and commercial missions. The literature has implicitly acknowledged the 
ethical dilemmas
 social entrepreneurs 
face
; however, the nature and implications of these ethical dilemmas and how social entrepreneurs navigate them are underexplored and undertheorized. We address this by conducting a 36-month 
field study
 of a social 
enterprise
 operating in a rural resource-constrained environment in 
India
 and dealing with a stigmatized product. We found four categories of ethical dilemmas faced by social entrepreneurs: challenges in engaging the community (
equality
 vs. 
efficiency
 and 
fairness
 vs. 
care
), challenges related to 
spillover effects
 (
right
 vs. 
responsibilities
), challenges in balancing diverse stakeholders (
emotionally detached
 vs. 
emotionally engaged
), and challenges related to cross-subsidization efforts (
utilitarianism
 vs. 
fairness
). Further, we identified three types of institutional work social entrepreneurs engage in to address ethical dilemmas: 
recognition work
, 
responsibilization
 work
, and 
reflective judgment work
. We label these three institutional works as inclusion work - purposive actions of an entity to address ethical dilemmas by implementing its program in a way that supports the most marginalized. Our study makes an important contribution to the literature on ethics in the context of social entrepreneurship by identifying specific ethical dilemmas social entrepreneurs 
face
 in managing hybridity (balancing social-commercial objectives) and enhancing social impact (managing social-social objectives). Moreover, through the concept of 
inclusion work,
 our research not only integrates insights from ethics and institutional theories but also responds to the recent call to address grand societal challenges through institutional work.", January 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000623,Made to be broken? A theory of regulatory governance and rule-breaking entrepreneurial action,David S.=Lucas: dlucas01@syr.edu,"Abstract
Although regulatory institutions are said to enable and constrain 
entrepreneurial action
, ventures frequently emerge with products, processes, and business models that skirt or defy these rules. We provide a theory of rule-breaking 
entrepreneurial action
, focusing on why entrepreneurs are only sometimes constrained by law, regulation, and other formal constraints. In this, we attend to the dual roles of social context and subjective interpretation. Drawing on the 
sociology of law
, we position regulatory rules within a system of governance, where public actors and legal intermediaries collectively construct the meaning of rule compliance and enact sanctions to enforce this interpretation. We leverage this to describe how enforcement imperfections and heterogeneous rule interpretations give rise to the possibility of ‘black market’ and ‘gray market’ entrepreneurial actions. In turn, we theorize how actors' knowledge and motivations can lead them to identify and exploit breakable rule conditions via the creation of new ventures. We illustrate our framework with examples from startups Zenefits, Square, and Aereo. Our framework changes the way we think about regulatory institutions and entrepreneurial action by presenting governance as a multilevel, social, and subjective process—such that some actors conform their 
entrepreneurial activities
 to established rules while others recognize and exploit breakable rule conditions.", November 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000611,When do spinouts benefit from market overlap with parent firms?,Aliasghar=Bahoo-Torodi: aliasghar.bahoo@aalto.fi; Salvatore=Torrisi: salvatore.torrisi@unimib.it,"Abstract
We examine how market overlap with parent organizations impacts the performance of startups founded by the former employees of these incumbent firms. Building on knowledge inheritance and competitive dynamics theories, we propose that the degree to which the operating markets of spinouts overlap with their parent organizations has a curvilinear relationship with their likelihood of survival. Market overlap is beneficial to spinouts because it reduces uncertainty during the early stages of new venture development. However, substantial market overlap may spark hostile actions by the parent organizations, thereby creating disruptive competition that may lower the likelihood of spinouts' survival. Furthermore, we hypothesize that the previous hierarchical position of founders in parent organizations moderates the overlap–performance relationship. Using a sample of European biotech spinouts and their parent firms, we find support for our hypotheses.", November 2022,"Spinouts, Knowledge inheritance, Competitive tension, New ventures' performance, Biotech",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000726,Momentum for entrepreneurial internationalization: Friction at the interface between international and domestic institutions,Wei=Hua: Wei.Hua@ttu.edu,"Abstract
In response to profound and emerging challenges arising from changes in the international order that affect international entrepreneurship, we address a gap in explanations for how the system for 
international relations
 shapes entrepreneurial 
internationalization
. To do so, we develop a model that further explains the role of institutions in supporting international new ventures. We focus on how frictions in the interface between international and domestic institutions can influence momentum for entrepreneurial 
internationalization
. We theorize how institutional work 
on
 the international-domestic interface can facilitate entrepreneurial 
internationalization
 that occurs 
in
 that interface. As such we provide additional understanding regarding factors that influence entrepreneurial 
internationalization
.", November 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000416,Will the startup succeed in your eyes? Venture evaluation of resource providers during entrepreneurs' informational signaling,Curtis L.=Wesley II: cwesley@bauer.uh.edu; Dejun Tony=Kong: dejuntony.kong@colorado.edu; Connor J.=Lubojacky: lubojacc@nsuok.edu; M.=Kim Saxton: mksaxton@iu.edu; Todd=Saxton: tsaxton@iu.edu,"Abstract
Experienced founders and investors are arguably the venture community members most likely to possess needed financial and social resources for startups. We present a model of venture evaluation where entrepreneurs solicit these resource providers for needed financial and social resources. Our model addresses how resource providers' venture investment propensity influences their evaluation of entrepreneurs' informational signals and how their venture evaluation predicts their willingness to provide financial and social resources. We test our model using real-time decisions and find resource providers with founding experience (both non-investor founders and investors with founding experience) leverage their investment propensity more than non-founder investors when evaluating new ventures. In addition, our post-hoc analysis reveals that resource providers' founding experience is associated with their willingness to confer social resources. Overall, this paper focuses on the perspective of resource providers and addresses how their investment propensity, types of venturing experience, and venture evaluation influence their willingness to render resource support to new ventures.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262200043X,Communities at the nexus of entrepreneurship and societal impact: A cross-disciplinary literature review,Sophie=Bacq: bacqs@iu.edu; Christina=Hertel: christina.hertel@epfl.ch; G.T.=Lumpkin: lumpkin@ou.edu,"Abstract
Although there is wide recognition of the importance of entrepreneurship for generating 
societal impact
, 
entrepreneurial activities
 alone rarely achieve a positive impact without the engagement of communities. To date, however, entrepreneurship researchers have tended to overlook the importance of community for creating 
societal impact
 through entrepreneurship, and lack a comprehensive understanding of the nature and roles of communities. To address this, we conduct a 
systematic review
 of the literature published in 51 journals across the Management and Entrepreneurship, Economic Development/Community Development, 
Economic Geography
 and 
Regional Science
, Energy, and Public Administration disciplines that makes three contributions. First, it identifies a new typology of community and proposes a comprehensive framework of roles through which 
societal impact
 is created by entrepreneurship 
for, in, with, enabled by,
 and 
driven by
 communities. Second, it demonstrates that the key to understanding how community relates to 
societal impact
 creation is to jointly account for both its type(s) and role(s). By linking community types and roles, the findings also suggest a theoretical contribution based on the relationship between the degree of formalization of a community type, and the degree of agency that a community role enacts. Third, the review underscores that communities are not just static settings but can also be dynamic actors in efforts to use entrepreneurship to create societal impact. Our cross-disciplinary review highlights trends and gaps in the extant literature and provides researchers with an evidence-based research agenda to guide future inquiry on this vital topic.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000453,Advancing societal grand challenge research at the interface of entrepreneurship and international business: A review and research agenda,Stephanie A.=Fernhaber: sfernhab@butler.edu; Huan=Zou: h.zou@soas.ac.uk,"Abstract
Societal grand challenges are increasingly attracting the attention of both entrepreneurship and international business scholars. While entrepreneurship focuses on the opportunities that emerge and need for bold and innovative solutions, 
international business research
 emphasizes the global reach of the challenges and role of multinational 
enterprises
. Although both conversations are insightful, we argue that examining one without the other gives an incomplete picture on how to address grand challenges. In this paper, we conduct a 
systematic review
 of the conversation on grand challenges in the international business and entrepreneurship literature. Upon synthesizing the results, we create an integrated framework and research agenda for viewing grand challenges through an international entrepreneurial lens.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000428,Referrals among VCs and the length of due diligence: The effect of relational embeddedness,Christina=Guenther: Christina.guenther@whu.edu; Serden=Özcan: Serden.ozcan@whu.edu; Dirk=Sassmannshausen: Dirk.sassmannshausen@whu.edu,"Abstract
Venture capital is a socially embedded business where VCs refer investment opportunities to one another. While we know that these referrals increase the chances of a start-up passing the initial screening process, we investigate to what extent the intensity of relational 
embeddedness
 between referrer and referee relates to the length of the 
due diligence
 process of the start-up being referred. Extending 
information processing
 theory by social network theory arguments, we argue that referees have access to more and better information during the 
due diligence
 as relational 
embeddedness
 increases. This will lead to a more in-depth and rigorous evaluation. Moreover, the referee will be subject to social obligations to invest additional resources in the assessment, the more so, the stronger the relational 
embeddedness
. Both factors lead to a prolongation of the due diligence process. Furthermore, we find that the individual investment manager's current performance and experience moderate this relationship.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306972,Partnerships as an enabler of resourcefulness in generating sustainable outcomes,Todd W.=Moss: tmoss@syr.edu,"Abstract
Resourcefulness research has provided many insights into how entrepreneurs do more with less, yet these studies are focused primarily on resourceful behaviors undertaken by singular actors. However, partnerships may also behave resourcefully to positively influence venture growth and sustainable outcomes. Through a 
qualitative study
 of 11 small enterprises in business partnerships with a common resource-rich partner in 
Mexico
, we show how such partnerships yield uniquely resourceful behaviors. Our analysis also reveals that such partnership-based behaviors require distinct capacity building for resourcefulness. We thus extend theory by creating a process model in which resourcefulness mediates the relationship between nonmarket logics/informal governance and sustainable outcomes.", January 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000441,Digital infrastructure and entrepreneurial action-formation: A multilevel study,Philipp=Schade: philipp.schade-2@wirtschaft.uni-giessen.de; Monika C.=Schuhmacher: monika.schuhmacher@wirtschaft.uni-giessen.de,"Abstract
This study investigates how country-level digital infrastructure shapes the relationships between the action-formation mechanisms of socio-cognitive traits, i.e., entrepreneurial self-efficacy, fear of failure, and opportunity recognition, and 
entrepreneurial action
. We amalgamate the agent-centric 
social cognitive theory
 with the external enabler framework and apply mechanism-based theorizing to explain how access-related mechanisms provided by digital infrastructure influence entrepreneurial action-formation. Based on a 
multilevel analysis
 of 344,265 individual-level observations from 46 countries and an additional robustness analysis of 391,119 individuals from 53 countries, we find that an individual's proclivity to starting a new venture is contingent upon the level of the digital infrastructure of a country. The empirical results show that a country's digital infrastructure is an external enabler that moderates the relationship between socio-cognitive traits and 
entrepreneurial action
.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000490,The effect of trademark breadth on IPO valuation and post-IPO performance: an empirical investigation of 1510 European IPOs,Michele=Meoli: michele.meoli@unibg.it; Silvio=Vismara: silvio.vismara@unibg.it; Christian=Fisch: christian.fisch@uni.lu; Jörn H.=Block: block@uni-trier.de,"Abstract
Trademarks differ in breadth and can cover a wide range of categories of goods and services. We draw on 
real options
 theory and argue that greater trademark breadth constitutes a valuable real option that is associated with higher 
firm valuation
 and performance. We analyze a sample of 1510 firms that went public in Europe between 2002 and 2015 and find a positive effect of trademark breadth on initial public offering (IPO) valuation and post-IPO performance. We implement a contingency analysis to contrast 
real options
 and signaling theory and find stronger support for the real options perspective.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262200057X,Modeling new-firm growth and survival with panel data using event magnitude regression,Frédéric=Delmar: delmar@em-lyon.com,"Abstract
We introduce a new model to address three methodological biases in research on new venture growth and survival. The model offers entrepreneurship scholars numerous benefits. The biases are identified using a 
systematic review
 of 96 papers using longitudinal data published over a period of 20 years. They are: (1) distributional properties of new ventures; (2) selection bias; and (3) causal asymmetry. The biases make the popular use of normal distribution models problematic. As a potential solution, we introduce and test an event magnitude regression model approach (EMM). In this two-stage model, the first model explores the probability of four events: a firm staying the same size, expanding, contracting, or exiting. In the second stage, if the firm contracts or expands, we estimate the magnitude of the change. A suggested benefit is that researchers can better separate the likelihood of an event from its magnitude, thereby opening new avenues for research. We provide an overview of our model analyzing an example data set involving longitudinal venture level data. We provide a new package for the statistical software R. Our findings show that EMM outperforms the widely adopted normal distribution model. We discuss the benefits and consequences of our model, identify areas for future research, and offer recommendations for research practice.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000593,Do I have a big ego? Angel investors' narcissism and investment behaviors,Wan-Chien=Lien: wlien@yuntech.edu.tw; Jianhong=Chen: Jianhong.Chen@unh.edu; Jeffrey=Sohl: jeff.sohl@unh.edu,"Abstract
In this study, we draw on the threatened egotism theory to examine the effect of angel 
narcissism
 on their investment behaviors and the boundary condition of past investment performance. We propose that angel 
narcissism
 is positively related to deal size and portfolio 
industry
 diversification but negatively related to the number of co-investors. Moreover, past investment performance moderates these relationships such that the effects of angel narcissism on their investment behaviors are stronger when past investment performance is lower. Data from a 
longitudinal analysis
 of 133 angels from 2010 to 2019 largely supported our hypotheses. Our study, the first to examine angel narcissism, highlights the psychological foundation of angel investing.", September 2022,"Angel investors, Investment behaviors, Narcissism, Past investment performance",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262200060X,"Rags to riches? Entrepreneurs' social classes, resourceful time allocation, and venture performance",Jianhua=Ge: gejianhua@rmbs.ruc.edu.cn; Joanna Mingxuan=Li: joli@iu.edu; Eric Yanfei=Zhao: ericzhao@indiana.edu; Fan=Yang: rmbsyangfan@ruc.edu.cn,"Abstract
Social classes shape entrepreneurial pursuits in that entrepreneurs from lower social class groups face more resource deficiencies compared to those from higher social class groups. In this study, we theorize that being resourceful with a particular resource—
time
—helps ventures run by lower-class entrepreneurs achieve better performance. However, we further argue that the extent to which entrepreneurs use time resourcefully is affected by the cognitive schemas stamped on them by their social class backgrounds. Our empirical analysis of 8663 Chinese private entrepreneurs between 2006 and 2010 lends robust support to these arguments. By revealing both material and cognitive constraints stemming from entrepreneurs' social classes, our study contributes to research on social classes and entrepreneurial resourcefulness and has important implications for understanding the persistence of inequality in entrepreneurship.", September 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000179,"Questioning boundedly rational frameworks in practice: The case of women entrepreneurs in Kumasi, Ghana",Arielle=Badger Newman: arnewman@syr.edu; Sharon=Alvarez: salvarez@katz.pitt.edu,"Abstract
Management research has a foundation in bounded rationality, wherein individuals seek to make the best choice to satisfy preferences within limits posed by informational incompleteness. This work addresses how the notion of rationality that models Western, male centric business concerns is not universal. Gender has been left out of the assumptions of boundedly rational models and the use of these models often advantage men at the expense of women. The work in this paper explores the absence of gender in the assumptions of bounded rationality and how this theory is applied in emerging contexts. The paper explores the structural obstacles based on bounded rationality that are imposed on women's businesses and their decision-making and how these obstacles constrain the potential of female entrepreneurs. The paper examines these issues through 220 interviews with stakeholders in the Kumasi Central Market social system in Kumasi, Ghana. The evidence shows that when considering business registration, what is most salient to entrepreneurs is the prevailing cultural expectations for men and women, despite female economic and social prowess as entrepreneurs that predated this business registration laws by centuries. This tension between expectations for female entrepreneurial competency and the simultaneous marginalization of female entrepreneurs using frameworks based on bounded rationality is explored.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000210,Co-creation in effectuation processes: A stakeholder perspective on commitment reasoning,Jonathan Van=Mumford: jonathan.v.mumford@utu.fi; Peter=Zettinig: peter.zettinig@utu.fi,"Abstract
In this article, we seek to contribute to theory on market co-creation through effectuation. To achieve this goal, we examine the different kinds of reasoning behind stakeholder commitments in effectuation processes. Although effectual and causal logics sufficiently account for decision-making in instrumental rationality, scholars have paid little attention to value rationality, and how it might influence stakeholder commitments and behavior. Different commitments may follow different rationales, ranging from instrumentally rational commitments based on causal or effectual logics, to value rational commitments based on state-belief or change-belief. The typology of these four commitment reasoning types provides a framework for analyzing stakeholder behavior based on different perceptions of the commitment decision space. Our typology shows that commitments based on value rationality may be qualitatively different from those driven by instrumental rationality and that value rationality may enable commitments under conditions that preclude instrumentally rational actions. Furthermore, different commitments influence market co-creation processes in different ways. In this article, we examine how different commitments affect (1) conflict and effectual churn and (2) the relative 
path dependence
, or shapability, of the market co-creation space. Based on this typology, we propose avenues for future research on co-creation in effectuation processes, with a special focus on stakeholders.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000209,"The origins of capabilities: Resource allocation strategies, capability development, and the performance of new firms",Noni=Symeonidou: noni.symeonidou@wbs.ac.uk; Aija=Leiponen: aija.leiponen@cornell.edu; Erkko=Autio: erkko.autio@imperial.ac.uk; Johan=Bruneel: j.bruneel@ieseg.fr,"Abstract
Resource-constrained new ventures need to decide how to allocate their scarce resources to develop internal functional capabilities in order to survive and grow. Drawing on the longitudinal Kauffman Firm Survey of U.S. start-ups, we explore the performance implications of broad versus narrow scope in new firms' functional capability development and show that focus rather than breadth in capability development is conducive to higher revenue performance, although financial and knowledge resource availability moderate this relationship. Studying capability development in entrepreneurial firms informs our understanding of capability development in any firm competing under time and resource constraints.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000222,Persist or let it go: Do rational entrepreneurs make decisions rationally?,Nidthida=Lin: Nidthda.Lin@mq.edu.au; Ralf=Wilden: Ralf.Wilden@mq.edu.au; Francesco=Chirico: Francesco.Chirico@mq.edu.au; Elahe=Ghasrodashti: Elahe.Ghasrodashti@students.mq.edu.au; Dawn R.=DeTienne: Dawn.Detienne@colostate.edu,"Abstract
We theorize that both highly rational entrepreneurs and entrepreneurs with a high need for cognitive closure (NFCC) are likely to put more emphasis on retrospective factors (period and degree of underperformance, personal investments) and less on prospective factors (risk of going into default, potential for growth, personal options) when deciding whether to persist with an underperforming venture. Our findings from three discrete choice experiments with three independent samples of entrepreneurs (a sample of 176 Australian entrepreneurs; a 
narrow-replication
 with 128 Australian entrepreneurs; and a 
quasi-replication
 with 157 United Kingdom entrepreneurs) consistently show that entrepreneurs who perceive themselves as rational do not always demonstrate rational behavior and entrepreneurs with a high NFCC put more emphasis on retrospective factors in persistence decisions. Important theoretical and practical contributions flowing from our study are shared in the concluding section.", July 2022,"Entrepreneurial persistence, Need for cognitive closure, Rational decision-making style, Discrete choice experiment",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000180,The potentials and perils of prosocial power: Transnational social entrepreneurship dynamics in vulnerable places,Florian=Koehne: florian.koehne@jku.at; Richard=Woodward: rick.woodward@ed.ac.uk; Benson=Honig: bhonig@mcmaster.ca,"Abstract
Social entrepreneurs can be powerful change agents for alleviating the suffering of the disadvantaged. However, their prosocial motivation and behavior frequently result in detrimental impacts on those they intend to support, especially when their operations span different socio-spatial contexts. We conducted a multiple comparative 
case study
 among 12 transnational social entrepreneurs of foreign, domestic non-indigenous, and local indigenous origin, who are seeking to improve the livelihoods of indigenous communities in rural Ecuador. We introduce the concept of prosocial power to social entrepreneurship research and demonstrate how it can work as a double-edged sword in the hands of transnationally embedded social entrepreneurs who operate in vulnerable places. Context-bound variations in social distance, bi-directional learning, reflexive impact measurement, and socio-spatial dominance were identified as being decisive for prosocial power to lead to positive or negative impacts on disadvantaged others.", July 2022,"Prosocial organizing, Prosocial power, Social entrepreneurship, Transnational entrepreneurship, Indigenous communities",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000192,Overconfidence and entrepreneurship: A meta-analysis of different types of overconfidence in the entrepreneurial process,Priscilla S.=Kraft: priscilla.kraft@whu.edu; Christina=Günther: christina.guenther@whu.edu; Nadine H.=Kammerlander: nadine.kammerlander@whu.edu; Jan=Lampe: jan.o.lampe@wirtschaft.uni-giessen.de,"Abstract
While research on 
overconfidence
 and entrepreneurship has grown rapidly in recent decades, extant studies provide conflicting theoretical predictions and empirical results about the role of 
overconfidence
 for entrepreneurship. To help resolve the controversy in the literature, we draw on information-processing theory to propose a theoretical framework that disentangles the influence of three types of overconfidence (i.e., overprecision, overestimation, and overplacement) in three major phases of the entrepreneurial process. The results of meta-analytical 
structural equation modeling
 (MASEM) based on 62 primary studies reveal varying effects of the three types of overconfidence in the entrepreneurial process. We discuss the implications of these findings and identify future research opportunities to advance this stream of research.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000349,Women's entrepreneurship and well-being at the base of the pyramid,Dean A.=Shepherd: dshephe1@nd.edu; Ira=Chatterjee: ira.chatterjee@hanken.fi,"Abstract
Women's entrepreneurship at the base of the pyramid can offer a way out of poverty for families, foster the development of communities, and provide a route to modernizing countries. Yet, we know little about what entrepreneurship means for the well-being of these entrepreneurs. This study investigates the well-being of marginalized women entrepreneurs engaged in an entrepreneurship training and venture creation program. Based on a qualitative 
case study
 method, our findings show that despite successful venture creation, the women differed in their experiences of well-being, with some flourishing and others languishing. Specifically, we found that the languishing women entrepreneurs lacked family support and prior work experience outside the home, which was associated with abstract goals and unrealistic expectations of venture creation outcomes. In contrast, flourishing women entrepreneurs, benefitting from prior work experience and family support, tended to set concrete goals for their entrepreneurial endeavors and had realistic expectations. Our findings provide new insights into some of the limitations of entrepreneurship programs for women at the base of the pyramid and emphasize the importance of well-being as a measure of successful venture creation.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000337,Ecological rationality and entrepreneurship: How entrepreneurs fit decision logics to decision content and structure,Ute=Stephan: ute.stephan@kcl.ac.uk; Sonia=Koller: sonia-cristina.codreanu@kcl.ac.uk; Gorkan=Ahmetoglu: g.ahmetoglu@ucl.ac.uk,"Abstract
During new venture creation, entrepreneurs make decisions in a variety of areas from seeking funding to 
hiring employees
. When and why entrepreneurs use effectual or causal logics to make such decisions is poorly understood. In this study, we integrate ecological rationality theory and effectuation theory to examine how the nature of decisions influences entrepreneurs' use of decision logics. In a 
qualitative study
 with 41 entrepreneurs across 290 decisions, we explore how decision content (what the decision is about) and decision structure (what information about a decision is represented in the decision-maker's mind) influence entrepreneurs' use of effectual or causal logics. We extend our findings in an experiment with 224 entrepreneurs where we manipulate decision structure. Our results suggest that decision content influences entrepreneurs' mental representations of decision structure. In turn, the combination of two elements of decision structure — decision complexity and the perceived costs of implementing different options — drives entrepreneurs' use of decision logics. We contribute to the effectuation literature by integrating it with ecological rationality theory, introducing the concept of 
decision fit
 as a driver of decision logics, and developing our understanding of hybrid decision-making (the simultaneous use of effectuation and causation).", July 2022,"Effectuation, Ecological rationality, Decision fit, Decision content, Decision structure",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000325,The role of prototype fidelity in technology crowdfunding,Michael=Wessel: wessel@cbs.dk; Ferdinand=Thies: ferdinand.thies@bfh.ch; Alexander=Benlian: benlian@ise.tu-darmstadt.de,"Abstract
The presentation of a prototype is pervasive when technology entrepreneurs pitch to potential resource providers. Yet, we know little about how the fidelity of a prototype—the degree to which it approximates the final product—can affect funding decisions. We study the relationship between 
prototype fidelity
 and resource acquisition of nascent technology ventures in online crowdfunding. Based on the community logic under which crowdfunding operates and the diverse motivations of funders to participate, we develop the seemingly counterintuitive idea that moderate prototype fidelity is more effective in gaining support from funders than high prototype fidelity. Across our three empirical studies, we find support for the hypothesis that prototype fidelity has an inverted U-shaped relationship with crowdfunding performance. This relationship is moderated by the materiality of the offered rewards and the quality of the prototype presentation delivered through the online interface.", July 2022,"Prototype fidelity, Technology ventures, Crowdfunding, Resource acquisition, Institutional logics",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000350,The right touch of pitch assertiveness: Examining entrepreneurs' gender and project category fit in crowdfunding,Jordan J.=McSweeney: jjmcsweeney@suffolk.edu; Kevin T.=McSweeney: kevin.mcsweeney@sbs.ox.ac.uk; Justin W.=Webb: justin.w.webb@uncc.edu; Cynthia E.=Devers: cdevers@mays.tamu.edu,"Abstract
Scholars have devoted significant attention to the role of entrepreneurs' communication, and gender in crowdfunding. Yet, how female and male entrepreneurs can effectively configure their assertive communication style and the role gender norms within project categories play in shaping crowdfunders' evaluations of entrepreneurs' communication style remains unanswered. To address this, we conduct an exploratory qualitative comparative case analysis (QCA) of 1600 entrepreneurs who pitched their ventures on Kickstarter. From prior research, we identified four distinct kinds of assertive language (certain, power, social, tentative) and explore how female and male entrepreneurs' configurations of assertive language relate to crowdfunding success and failure in male-dominated and female-dominated contexts. We found six pitch assertiveness themes, two associated with success, two associated with failure, and two where success versus failure depends on nuanced considerations of the entrepreneur's gender and the gendering of the context. Our study extends our understanding of communication and gender in crowdfunding.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000362,Regional social capital and moral hazard in crowdfunding,Tse-Chun=Lin: tsechunlin@hku.hk; Vesa=Pursiainen: vesa.pursiainen@unisg.ch,"Abstract
We contribute to institutional and 
social capital theory
 by developing a theoretical framework that suggests that informal and formal institutions are important in mitigating moral hazard in reward-based crowdfunding. We analyze a large sample of Kickstarter campaigns to test these predictions. We find a strong positive relationship between entrepreneurs' home-county social capital and their crowdfunding performance. A rule change that strengthens entrepreneurs' obligation to provide backers with the promised rewards is associated with a reduction in the effect of social capital, suggesting that formal institutions can substitute for informal ones and provides causal evidence of the effect of social capital.", July 2022,"D22, D81, G02, G23, L26",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000374,Entrepreneur-investor rivalry over new venture control: The battle for Balcones Distilling,Jeffery S.=McMullen: mcmullej@indiana.edu; Theodore L.=Waldron: theodore.waldron@ttu.edu; Oleg V.=Petrenko: opetrenk@uark.edu; Lori=Tribble Trudell: LLTRIBB@clemson.edu; Olivia=Aronson: oaronson@richmond.edu,"Abstract
Entrepreneurs and investors sometimes battle for control of new ventures when their relationships deteriorate, a phenomenon that we describe as entrepreneur-investor rivalry. Theoretical accounts of entrepreneurs' and investors relationships preclude the potential for true rivalry, battles where either side can emerge with venture control, yet such rivalry can and does happen. To address the disconnect between theory and practice, we develop an initial theory of entrepreneur-investor rivalry from the in-depth, qualitative analysis of a battle to control a renowned craft distillery. Our theory elaborates why entrepreneur-investor rivalry can occur, how it can unfold, and how it can conclude, attending to contextual factors and interaction dynamics that shape the outcomes of three sequential stages and the overall rivalry process. In conceptualizing the features of entrepreneur-investor rivalry, we improve extant theory's capacity to explain such rivalry, provide practical prescriptions to mitigate or avoid it, and till fertile ground on which to invigorate its study. Most importantly, we provide a theoretical foundation to invigorate research on entrepreneur-investor rivalry and other relational dynamics of importance to venture 
resource mobilization
, moving beyond assumptions that we “know all there is to know” about these relationships.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000386,Progress toward understanding tensions in corporate venture capital: A systematic review,Euiju=Jeon: euije@dtu.dk; Markku=Maula: markku.maula@aalto.fi,"Abstract
We systematically review the past four decades of research on tensions in corporate venture capital (CVC) and inductively identify three main tensions: (1) multiple stakeholders championing CVC-based exploration versus core business-focused exploitation, (2) CVC programs simultaneously belonging to the corporate parent versus the startup/venture capital (VC) world, and (3) startups and VCs viewing CVC programs as a threat versus an opportunity. By combining the understanding of the CVC phenomenon with that of the paradox literature, we expand our understanding of why, how, and when contradictory goals and multiple stakeholder expectations result in tensions and how these tensions can be managed.", July 2022,"G24, M13, O31, O32",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000404,Categorically right? How firm-level distinctiveness affects performance across product categories,Jonas=Janisch: jonasjanisch@gmail.com; Alexander=Vossen: alexander.vossen@uni-siegen.de,"Abstract
In their pursuit of “optimal distinctiveness,” firms need to simultaneously adhere to norms and stand out from the competition. Using longitudinal data from Amazon Launchpad, an online B2C marketplace for entrepreneurial products, we offer a multi-level perspective on optimal distinctiveness from a consumer goods market in which firms are active across different and heterogeneous product categories. Arguing along categorization, organizational identity, and the fit with audiences' 
theory of value
, we challenge the assumption that firm-level distinctiveness, i.e., the distinctiveness of a firm's organizational identity and category claims, delivers equal benefits to all products it offers and showcase the decisive role of product category context. In product categories that share less overlap with other categories and thus occupy a more distinct position in the classification system, products offered by firms with high firm-level distinctiveness benefit, whereas in product categories that share frequent relations to other categories and thus occupy a non-distinct position, products do not benefit at all. This offers researchers and managers alike a new and more nuanced perspective on firm-level distinctiveness: It is not invariably efficient in addressing audiences once the “optimal” level is found, but requires careful consideration of both the firm-level appeal and the product category in which a firm seeks to operate. Firm-level distinctiveness provides firms with the means to increase the differentiation of their own products, yet this effect is most meaningful in product categories with an increasingly distinct position.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000039,"Ventures' conscious knowledge transfer to close partners, and beyond: A framework of performance, complementarity, knowledge disclosure, and knowledge broadcasting",Theresa=Veer: theresa.veer@uni-tuebingen.de; Philip=Yang: philip.yang@uni-tuebingen.de; Jan=Riepe: j.riepe@uni-tuebingen.de,"Abstract
We build a new theoretical framework that conceptually differentiates ventures' knowledge disclosure to their corporate venture capitalist (CVC) from knowledge broadcasting beyond the venture-CVC dyad and links them to venture-CVC complementarity. We test their direct, indirect, and interactive effects on venture performance. Our moderated mediation model (i) establishes knowledge disclosure as a mechanism that connects complementarity with venture performance, and (ii) predicts knowledge broadcasting beyond this dyad as a boundary condition to this indirect effect. We use 944 observations of 349 ventures along with Twitter data to test our model. Disclosure and broadcasting have a positive direct effect on performance, complementarity has an indirect effect on performance through disclosure, and this indirect link diminishes with broadcasting. Our findings point to a conflict in ventures' broadcasting strategies.", May 2022,"Knowledge disclosure, Knowledge broadcasting, Venture performance, Early-stage ventures, Corporate venture capital, Moderated mediation.",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000040,Social corporations under the spotlight: A governance perspective,Coline=Serres: serres@rsm.nl; Marek=Hudon: marek.hudon@ulb.be; François=Maon: f.maon@ieseg.fr,"Abstract
A series of new legal statutes for profit-seeking social ventures has emerged across geographic and institutional settings. Extant studies commonly do not make a clear distinction between these ventures. Such confusion leads to blurriness in research design and methodology, thereby limiting the relevance of findings. Moreover, researchers, entrepreneurs, and policymakers often lack a clear view of the unique organizational and governance aptitudes these ventures call for, to sustain and grow over time. Thus, this study has two objectives: (1) to clarify the panorama of novel companies that legally commit themselves to a social mission, gathered under the term “social corporation,” by providing a comprehensive typology of these organizations and (2) to identify the governance capabilities that social corporations develop to be sustainable and avoid mission drift in the long run. Our analysis of corporate-governing documents leads us to classify social corporations into three types: hard-law, soft-law, and bylaw. In addition to this typology, our multiple 
case study
 uncovers five key governance capabilities of social corporations related to performance, conformance, and responsibility—the main pillars of organizational governance. Overall, our work contributes to a better understanding of novel forms of social entrepreneurship emerging on the market. More important, it casts light on the governance processes that characterize them.", May 2022,"Social venture, Benefit corporation, Governance, Typology, Capabilities",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000027,Cracks in the wall: Entrepreneurial action theory and the weakening presumption of intended rationality,Richard A.=Hunt: rickhunt@vt.edu; Daniel A.=Lerner: Daniel.Lerner@ie.edu; Sheri L.=Johnson: sljohnson@berkeley.edu; Michael A.=Freeman: mfreeman@econa.net,"Abstract
Entrepreneurship scholarship finds itself in something of a quandary concerning rationality. While an increasingly large body of empirical work has found evidence of less-deliberative and even impulsive drivers of business venturing, the dominant theories of 
entrepreneurial action
 remain anchored to the assumption that intended rationality is a defining attribute of entrepreneurship. The growing schism between entrepreneurial action theory (EAT) on the one hand, and empirics and practice on the other hand, represents a consequential and exciting opportunity for the field to revisit its core assumptions regarding rationality, particularly the presence, role, and function of rational intentionality. In this study, we undertake a review and exploratory investigation of the assertion that without reasoned intentionality there is no entrepreneurship. Our work generates three important insights that contribute to rethinking key facets of the most prominent and influential EATs: alternative, non-rational pathways to business venturing exist with a non-ignorable prevalence; a proclivity towards reasoned intentionality is not invariably prescriptive; and, less-reasoned, less-deliberative tendencies do not constitute an entrepreneurial death sentence. Rather, entrepreneurs (including highly successful ones) embody a shifting blend of rational and non-rational proclivities, motivations, decisions, and actions.", May 2022,"rationality, non-rationality, impulse-driven logics, non-deliberative pathways, Entrepreneurial Action, entrepreneurial action theory, neurodiversity, ADHD, hypomania, impulsivity, mental health, entrepreneurship",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000052,Can you hear me now? Engendering passion and preparedness perceptions with vocal expressions in crowdfunding pitches,Melissa S.=Cardon: mcardon@utk.edu; Thomas H.=Allison: t.allison@tcu.edu; Benjamin J.=Warnick: b.warnick@wsu.edu; Blakley C.=Davis: bcdavis@vcu.edu,"Abstract
The voice is often the only continuous channel of expression in pitch videos. We isolate the influence of entrepreneurs' vocal expressions on funding by examining how valence (positivity/negativity) and arousal (activation) shape funders' perceptions of passion and preparedness. We show that an entrepreneur's high-arousal vocal expressions, whether positive or negative, increase perceptions of their passion. Entrepreneurs are perceived as more prepared when the valence and arousal of their vocal expressions are congruent. We test our hypotheses in the context of rewards-based crowdfunding, using both an experiment and a speech affect analysis of real-world crowdfunding pitches.", May 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000167,Staying poor: Unpacking the process of barefoot institutional entrepreneurship failure,Maria L.=Granados: m.granados@westminster.ac.uk; Ainurul=Rosli: Ainurul.Rosli@brunel.ac.uk; Manto=Gotsi: m.gotsi@bbk.ac.uk,"Abstract
Research on barefoot entrepreneurship is growing, yet we still know little about the potential limits of 
institutional entrepreneurship
 in the context of extreme poverty. Challenging institutional 
entrepreneurship theory's
 agency-centric assumptions, we seek to understand how barefoot institutional entrepreneurship efforts fail amidst resistance from powerful actors in the institutional context. Our 
qualitative study
 of marginalized waste pickers in Colombia sheds light on the role of power in barefoot institutional entrepreneurship failure. We unpack a paradox of inclusion: the more marginalized barefoot entrepreneurs push for and gain regulatory legitimacy for their market inclusion, the more this accentuates overt and covert power mechanisms that work to suppress the diffusion of institutional change, aggravating barefoot entrepreneurs' market exclusion. Our study shows that while regulatory change is necessary to enhance barefoot entrepreneurs' market inclusion, on its own it is not sufficient, without normative and cognitive support from powerful actors in the institutional field.", May 2022,"Barefoot institutional entrepreneurship, Failure, Power mechanisms, Market inclusion, Paradox of inclusion, Process",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000064,Radical innovation in (multi)family owned firms,Francesco=Chirico: francesco.chirico@mq.edu.au; R.=Duane Ireland: direland@mays.tamu.edu; Daniel=Pittino: daniel.pittino@ju.se; Valeriano=Sanchez-Famoso: valeriano.sanchezfamoso@ehu.eus,"Abstract
By integrating 
organizational learning
 theory with the family firm literature, we seek to enhance our understanding of radical innovation in (multi)family-owned firms. We theorize that the goal diversity and path dependency that multifamily ownership creates negatively affects the positive relationship between knowledge integration and radical innovation. However, this is not the case for multifamily-owned firms in which family members embrace a commitment to change. We contend that commitment to change mitigates the negative moderating effect of multifamily ownership by ensuring the effective translation of integrated knowledge into radical innovation within the firm. Overall, our results highlight the complexity of radical innovation in (multi)family-owned firms as a product of the joint effect of knowledge integration, the number of unrelated owning families, and a commitment to change.", May 2022,"Multifamily-owned firms, Radical innovation, Knowledge integration, Commitment to change",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000860,Sitting on the fence - Untangling the role of uncertainty in entrepreneurship and paid employment for hybrid entry,Gertraud M.=Gänser-Stickler: gaenser-stickler@wiso.uni-koeln.de; Matthias=Schulz: matthias.schulz@wiso.uni-koeln.de; Christian=Schwens: schwens@wiso.uni-koeln.de,"Abstract
Prior research agrees that uncertainty in entrepreneurship shapes individuals' decision between hybrid and full-time entry, but largely neglects the role of uncertainty in paid employment. By theorizing that hybrid entrepreneurship is a portfolio of 
real options
 in entrepreneurship and paid employment, we argue that both uncertainty in entrepreneurship and paid employment as well as their interplay determine individuals' decisions regarding their mode of entry into entrepreneurship. We validate our theory using data from the Current Population Survey and the Study of Income and Program Participation and contribute to the hybrid entrepreneurship literature and research on uncertainty in entrepreneurship.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000872,When sergeants can outrank generals: Person-organization fit and the performance of franchisees as agents of their franchisor,Thorsten=Semrau: semrau@uni-trier.de; Torsten=Biemann: biemann@bwl.uni-mannheim.de,"Abstract
We introduce a person-organization fit perspective to explain how franchise organization characteristics shape the link between franchisees' individual attributes and their performance as agents of their franchisor. Showcasing this idea, we develop arguments to suggest why the links between franchisees' agent performance and their prior 
industry
 and educational experiences are contingent upon the franchise organization's entrepreneurial orientation, centralization, and formalization. The results from 
multilevel analyses
 using the data of 276 franchisees from 47 franchise organizations largely support our ideas. We discuss the theoretical and practical implications of our study for franchising and beyond.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000951,Now that's interesting and important! Moving beyond averages to increase the inferential value of empirical findings in entrepreneurship research,Scott L.=Newbert: scott.newbert@baruch.cuny.edu; Romi=Kher: romi.kher@baruch.cuny.edu; Shu=Yang: shu.yang@hofstra.edu,"Abstract
Amid the debate over whether scholars should conduct interesting or important research, we contend that entrepreneurship scholars can achieve both ends by acknowledging the foundational role context plays in our discipline and designing our empirical research in ways that enable us to explore and exploit the heterogeneity of our samples. In turn, we provide a non-exhaustive list of analytical approaches and empirical methods that can enable scholars to look past sample-wide averages and, instead, explore the nuances that exist beneath the surface of those findings. By contextualizing empirical research in these ways, scholars can move beyond these averages in order to better understand not only whether a given result is “true,” but more importantly where, when, and for whom it is or is not true, thereby increasing the inferential value of our findings.", March 2022,"Analytical approaches, Contextualizing research, Empirical methods, Quantitative research",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262100094X,Taking root in fertile ground: Community context and the agglomeration of hybrid companies,Michael V.=Russo: mrusso@uoregon.edu; Andrew G.=Earle: andrew.earle@unh.edu; Brooke A.=Lahneman: brooke.lahneman@montana.edu; Suzanne G.=Tilleman: suzanne.tilleman@umontana.edu,"Abstract
Where do hybrid companies flourish and why? We draw on 
economic theories
 of agglomeration and 
sociocultural theories
 of community to examine the 
specific contexts
 in which hybrids flourish, and offer an understanding of why 
place
 matters to the unique business models they employ. We hypothesize that a community's 
collectivism
, political orientation, and 
third sector
 
munificence
 have distinct roles in promoting hybrid company agglomeration. We test these hypotheses with data drawn from a variety of sources, covering 260 U.S. Metropolitan Statistical Areas across 17 years. Our results indicate that both economic and 
sociocultural theories
 offer explanatory power, and their union more completely explains hybrid agglomeration. Additional analyses enrich our understanding of how this agglomeration unfolds over time.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000665,An institutional perspective on borrowing discouragement among female-owned enterprises and the role of regional female empowerment,Juanita Kimiyo=Forrester: forrester_jk@mercer.edu; François=Neville: nevillef@mcmaster.ca,"Abstract
We develop an institutional perspective to examine the important, albeit largely overlooked, occurrence of borrowing discouragement for female-owned 
enterprises
: the likelihood that they will not seek business financing because they believe their requests will be rejected. Given a prevailing business logic casting the field of entrepreneurship as largely male-typed, we theorize that female-owned enterprises will be more likely than their male-owned counterparts to exhibit borrowing discouragement. However, we also further propose that gender-based borrowing discouragement will be influenced by female empowerment levels in three distinct indicators of female empowerment that vary by geographic region within a society: social and economic 
autonomy
, 
reproductive rights
, and 
political participation
. We find strong support for our predictions using a unique multi-sourced sample of 4090 small businesses operating in the United States.", November 2021,"Borrowing discouragement, Entrepreneurial finance, Entrepreneurship, Female entrepreneurship, Gender inequality",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000963,Perceived social undermining keeps entrepreneurs up at night and disengaged the next day: The mediating role of sleep quality and the buffering role of trait resilience,Wei=Yu: iseyw@nus.edu.sg,"Abstract
Entrepreneurs work in an uncertain, novel, and high-stakes environment. This environment can lead to disagreements and conflicts over how to develop, grow, and run a business venture, thus triggering destructive social interactions. This research sheds light on the role of destructive 
interpersonal relationships
 by examining daily perceived social undermining from work partners and how and when this perceived undermining affects entrepreneurs' work engagement. Building on a resource-based self-regulation perspective, we develop a theoretical model of the self-regulation impairment process whereby an entrepreneur's perceived social undermining disrupts sleep quality at night, which dampens work engagement the next day. We further theorize trait resilience as a self-regulation capacity that buffers this impairment process. We test the model in a study based on daily surveys over 10 workdays from 77 entrepreneurs. The results largely support our hypotheses and further indicate that trait resilience is more crucial for less experienced entrepreneurs. Our study contributes to research on how entrepreneurs' interpersonal relationships—particularly destructive ones—affect entrepreneurial well-being.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000987,Good apples in spoiled barrels: A temporal model of firm formalization in a field characterized by widespread informality,Valeria=Cavotta: valeria.cavotta@unibz.it; Elena=Dalpiaz: e.dalpiaz@imperial.ac.uk,"Abstract
Entrepreneurship scholars have devoted increasing attention to formalization (i.e., a firm's transition from informality to compliance with formal institutions). However, little is known about the actual 
process
 through which informal firms transition to pursue opportunities in a fully legally compliant way. This transition poses formidable challenges, especially in fields in which informality rather than formality is widespread. To understand how firms transition to full formality and manage the related institutional challenges in such contexts, we conduct a longitudinal, inductive 
case study
 of an informal firm, confiscated from the Mafia in Italy, and examine how it succeeded in operating formally in a field in which informality regulated transactions and was accepted across society. The findings suggest that formalizing in such contexts is a two-phase process that entails first 
extricating
 the 
enterprise
 from the influence of informal institutions and then 
cultivating formal institutions
 in the field to increase the firm's legitimacy. The study contributes to the literature on formalization, entrepreneurship, and institutional work by advancing the understanding of formalization as a dynamic and entrepreneurial endeavor that requires specific institutional work at different points in time to succeed.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000859,Failed but validated? The effect of market validation on persistence and performance after a crowdfunding failure,Regan=Stevenson: rstev@indiana.edu,"Abstract
We investigate the impact of market validation on persistence and subsequent performance following a specific type of failure (crowdfunding failure). We leverage a 
mixed methods
 design, employing a controlled lab experiment with entrepreneurs (Study 1) and a four-year lagged longitudinal 
field study
 which combines two archival databases (Study 2). In our experiment, we find that market validation encourages entrepreneur persistence through affective activation and cognition-based action intentions (specifically search and knowledge integration). We also find that another form of validation, expert validation, strengthens this relationship. In our 
field study
, market validation is shown to be a stronger predictor of performance after a crowdfunding failure in comparison to expert validation. We draw from the social proof and wisdom of the crowd perspectives to develop our theoretical model and explain the implications of our findings.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000015,The challenges of supporting necessity entrepreneurs: Understanding loan officer exit in microfinance,Laura=Doering: Laura.Doering@Rotman.Utoronto.Ca,"Abstract
Necessity entrepreneurship can serve as a pathway out of poverty for low-income individuals, with microfinance often providing important financial support. Yet the relational lending strategies common among microfinance institutions may influence loan officer turnover and, in turn, compromise entrepreneurs' access to credit. While there is some reason to suspect that relational lending with poor entrepreneurs will increase retention, we propose that serving the poor may make loan officers more likely to 
quit
: loan officers in commercial microfinance institutions are unlikely to have strong commitments to 
poverty alleviation
 and may be taxed by the challenging fieldwork associated with lending in poor areas. Qualitative and quantitative data from a microfinance bank in Latin America support our expectations, showing that exit becomes more likely when loan officers' work involves more poor clients and that the effect is strongest when such work demands intensive fieldwork in low-income areas. Supplementary analyses of trends across the global microfinance 
industry
 demonstrate that poor clients have a stronger impact on exit in for-profits than non-profits, suggesting that prosocial motives among non-profit employees may have a buffering effect. Overall, our study reveals how providing services to necessity entrepreneurs can have negative, unexpected consequences for frontline employees.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306911,An agentic perspective of resourcefulness: Self-reliant and joint resourcefulness behaviors within the entrepreneurship process,David J.=Scheaf: David_Scheaf@baylor.edu; Timothy L.=Michaelis: tmichaelis@niu.edu; Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Jon C.=Carr: jccarr@ncsu.edu,"Abstract
We integrate 
social cognitive theory
, and its tenets of personal and collective agency, to develop an individual-level perspective on entrepreneurs' resourcefulness behaviors that illustrates how resourcefulness behaviors can be classified as ‘self-reliant behaviors’ or ‘joint resourcefulness behaviors’. Using this novel cognitive theoretical approach, we provide and test a framework that explains how dispositional, perceptual, and behavioral factors interact in the enactment of purposeful action with regards to entrepreneurs' resourceful behaviors. Consistent with our hypotheses, results from a 
quantitative study
 of entrepreneurs (
N
 = 178), as well as a supplemental study involving 
qualitative interviews
 with entrepreneurs (
N
 = 15), highlight that entrepreneurs higher in 
frugality
 tend to perceive higher levels of environmental hostility. This relationship, in turn, leads to higher amounts of self-reliant resourcefulness behaviors (i.e., customer-related and internal self-financing bootstrapping behaviors) but not joint resourcefulness behaviors. Multiple theoretical and practical contributions emerge from our findings as the extant literature does not yet account for human agency as a reason why some entrepreneurs may choose to engage in certain resourceful behaviors relative to other behaviors.", January 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619302472,"Sold, not bought: Market orientation and technology as drivers of acquisitions of private biotechnology ventures",Maija=Renko: Maija.renko@depaul.edu; Helena=Yli-Renko: hylirenko@marshall.usc.edu; Lien=Denoo: l.c.i.denoo@tilburguniversity.edu,"Abstract
Acquisitions are an important exit strategy for technology entrepreneurs and investors, but what can technology ventures do to increase their chances of achieving an acquisition? We draw on signaling theory to examine the role that market orientation plays behind acquisitions. We test our hypotheses in a sample of young biotechnology ventures, and our findings are three-fold. First, we show that a target's market orientation is an important direct driver of acquisitions, thus incorporating a marketing perspective into a literature that has hitherto focused primarily on technological and reputational factors. Second, we find a substitutive interaction effect between market orientation and 
new product development
 stage, indicating that for exits through acquisitions, a high level of market orientation can compensate for an early stage of product development. Third, a fuzzy-set Qualitative Comparative Analysis (fsQCA) shows that in some contexts, the 
monopoly
 power afforded by patents can further amplify the positive effect of market orientation on acquisition likelihood. Taken together, our findings contribute to a more nuanced understanding of how different signals interact, and suggest that technology ventures should invest in market orientation early on in their life cycle.", January 2022,"Acquisitions, Technology ventures, Market orientation, fsQCA, Signaling theory, Product-market fit",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619303209,The evolution of founder identity as an authenticity work process,Isobel=O'Neil: isobel.oneil@nottingham.ac.uk; Deniz=Ucbasaran: Deniz.Ucbasaran@wbs.ac.uk; Jeffrey G.=York: jeffrey.york@colorado.edu,"Abstract
Research has shown founders' identities have a significant impact on their ventures. Yet, the process through which founder identity evolves and takes shape remains relatively unexplained. This paper explores the evolution of founder identity through a qualitative study of first-time sustainable entrepreneurs, and their stakeholders, over a three years period. Our analysis revealed the importance of personal identity, the aspect of the self that defines a person as a unique individual based largely on values and beliefs. We found that first-time founders sought to align their personal identity with their evolving founder identity over time. Based on these findings we theorize a process model of 
founder authenticity work
, defined as 
the activities founders engage in to feel and seem authentic while engaged in entrepreneurial action
. This study thus details the significance of personal identity as a guidepost for founder identity evolution, complementing extant founder identity studies focused on role and social identities. In addition, our analysis enriches the current conceptualization of authenticity in entrepreneurship research by linking it to validation of personal identity and highlighting its negotiated nature in the evolution of authentic founder identities.", January 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301375,"Discipline, abjection, and poverty alleviation through entrepreneurship: A constitutive perspective",Luca=Castellanza: castellanza@ifm.uni-mannheim.de,"Abstract
Collective entrepreneurship has been found to alleviate extreme poverty by helping poor individuals integrate into their societies and overcome their multiple intertwined liabilities. We complement this line of inquiry by exploring the conditions under which group structures may instead reinforce economic and gendered poverty constraints.
We conducted grounded-theoretical interviews with 104 women entrepreneurs operating in farming cooperatives and non-farm groups in war-torn South-West Cameroon. Analysing our data through a constitutive lens, we found that discipline, the extent to which rules determine and control individual behaviours, helps poor women overcome extreme economic constraints but prevents them from attaining prosperity and emancipation.", January 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000732,A personal adversity model of justifying the costs of entrepreneurial action: The case of oil thieves in the Niger DELTA,Dean A.=Shepherd: DShepherd@nd.edu,"Abstract
While entrepreneurship can generate economic and 
social benefits
, it can also be a source of negative outcomes. We need to gain a deeper understanding of how individual entrepreneurs interpret their context and engage in 
entrepreneurial action
 that can generate substantial negative outcomes. In this paper we shed light on the entrepreneurial process at the micro-level by exploring how bunkerers—oil thieves—engage in, justify, and persist with 
entrepreneurial action
 that, while generating some benefits for the entrepreneurs and the local community, causes substantial destruction to the local environment, community, and the entrepreneurs' health. By inductively generating a personal adversity model of justifying entrepreneurial action that generates substantial negative outcomes (for the local community and environment), we provide new insights into (1) the link between aspects of entrepreneurship under adversity and substantial costs (and some benefits) experienced by local communities already facing adverse conditions, (2) how entrepreneurs' claim varying levels of agency in the same justification of the same action and its negative consequences, and (3) how entrepreneurs entangle the self and others to justify their actions and its costs.", January 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000744,Sowing the seeds of failure: Organizational identity dynamics in new venture pivoting,Yuliya=Snihur: y.snihur@tbs-education.fr; Bart=Clarysse: bclarysse@ethz.ch,"Abstract
New ventures in nascent markets often pivot while still developing their organizational identity. A strong identity helps attract investors and employees and pivoting helps pursue new opportunities. How do they interact? To illuminate this process, we conduct an in-depth longitudinal 
field study
 of a new venture developing a technology to transform Internet websites for mobile devices. The venture completes a first pivot but fails during a second attempted pivot of its business model in the nascent market. Comparing the completed and the attempted pivot, our analysis suggests that new venture pivoting relies on the ability to crystallize the individual roles of organizational members (“what we do”) in line with organizational identity (“who we are”). Our findings shed light on stakeholder constraints on pivoting by scaling new ventures through the micro-mechanism of role crystallization. Our analysis also delineates the inter-temporal effects of lingering organizational identity, thereby advancing research on the organizational identity dynamics of new ventures.", January 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618308929,A country-level institutional perspective on entrepreneurship productivity: The effects of informal economy and regulation,Joakim=Wincent: joakim.wincent@hanken.fi; Ashkan=Fredström: ashkan.fredstrom@hanken.fi; Juhana=Peltonen: juhana.peltonen@hanken.fi,"Abstract
Developing the concept of institutional incongruence and employing panel data from 60 countries, we outline an alternative view of the informal economy and the effects of regulative institutions on entrepreneurship productivity. We find evidence that the informal economy's size is, largely, negatively associated with entrepreneurship productivity, and that in the presence of a large informal economy, governmental efforts to improve governance quality can be counterproductive. Our results suggest policy interventions aimed at changing institutions to practice formal entrepreneurship should be implemented cautiously to avoid inducing institutional incongruence.", September 2021,"Entrepreneurship productivity, Opportunity-driven entrepreneurship, Necessity-driven entrepreneurship, Informal economy, Regulative institutions, Institutional incongruence",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000756,"Owls, larks, or investment sharks? The role of circadian process in early-stage investment decisions",Regan=Stevenson: rstev@indiana.edu; Cristiano L.=Guarana: cguarana@iu.edu; J.=Jeffrey Gish: jgish@ucf.edu; Ji Woon=Ryu: jiwryu@iu.edu; Rohan=Crawley: crawleyr@purdue.edu,"Abstract
Investors in early-stage companies want to detect and select high-potential opportunities to maximize their long-term returns. However, in uncertain and risky early-stage investment contexts, company information is often opaque, and decision-making timeframes are compressed. Although there is an abundance of prior work on how investors make structured decisions based on their experience and expertise, there is a very limited understanding of how 
time-based factors
 can sway investment decisions. The circadian process is the 24-hour sequence that serves as an individual's internal timer influencing not only sleep cycles, but also attention and performance on a wide range of cognitive tasks. Understanding how the circadian process impacts early-stage investment holds implications for optimal investment decisions. We build on 
social cognitive theory
 and propose that investor-level factors (i.e., chronotypes) and environmental factors (time of the day) interact to influence the amount of information investors search for, and consequently, their investment decisions. We hypothesize and find that investors are influenced by the time of day they make early-stage investment decisions. Lark investors make better investment decisions in the morning, whereas owl investors make better decisions in the evening. Information search effort mediates this relationship.", January 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000550,Technology ventures' engagement of external actors in the search for viable market applications: On the relevance of Technology Broadcasting and Systematic Validation,Bart=Clarysse: bclarysse@ethz.ch; Petra=Andries: petra.andries@ugent.be; Sergio=Costa: aspdc20@bath.ac.uk,"Abstract
In order to succeed, technology ventures need to find a profitable market application for their technology. Although external market actors may provide important information for the identification and validation of potential technology-market combinations, it remains largely unclear how technology ventures can involve them in this process. Building on insights from organizational search literature, this study follows five university spin-offs trying to commercialize early-stage technologies. We find that ventures are cognitively constrained in proactively identifying and approaching external market actors. Interestingly, the better performing ventures in our sample engage in a previously undocumented market search process we label Technology Broadcasting. They communicate their technological competencies to a broad range of market actors and react to these actors' assessment and spontaneous expressions of interest, thereby overcoming their own cognitive constraints. Resource constraints require filtering these expressions of interest through Systematic Validation with additional market players. These results complement the existing insights on market search by entrepreneurial ventures and advance the literature on organizational search.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000562,Stakeholder identification as entrepreneurial action: The social process of stakeholder enrollment in new venture emergence,J. Robert=Mitchell: rob.mitchell@colostate.edu,"Abstract
There is growing interest in understanding the role of stakeholders—including financiers, employees, customers, suppliers, and communities—in the process of new venture emergence. We see potential to advance this stream of research by bridging a gap we observe between recent research on stakeholder enrollment in new ventures and longstanding research on stakeholder identification in established firms. To do so, we seek to explain why, how, and when, through 
social action
, stakeholder identification and enrollment may (or may not) occur as an entrepreneur goes from an imagined opportunity to a new venture with enrolled stakeholders. To this end, we develop a model that conceptualizes stakeholder identification and enrollment as iterative, recursive, and constitutive social processes involving action in: refining and justifying to result in commonality with other actors; probing and positioning to result in mutuality with specific stakeholders identified; and enrolling and engaging to result in reciprocity with identified stakeholders. We argue that these social processes constitute the means through which opportunities are formed, specific stakeholders are identified, and stakes in new ventures are created and maintained, respectively. In doing so, we offer a more nuanced explanation of the 
dynamism
 implied in stakeholder identification and enrollment in emerging ventures.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000574,"Writing bold, broad, and rigorous review articles in entrepreneurship",Sophie=Bacq: bacqs@iu.edu; Phillip H.=Kim: pkim1@babson.edu,"Abstract
Despite the importance of review articles in entrepreneurship, specific guidance to authors remains limited. Alongside JBV's rolling annual review issue, we provide authors practical tips for preparing review articles. Building on widely accepted principles employed in general management review articles, we tailor our guidance to the “entrepreneurship” way of writing review articles in entrepreneurship. Specifically, we call on authors to write bold, broad, and rigorous reviews that exemplify JBV's mission to publish and disseminate high-quality entrepreneurship research.", November 2021,"Editorial, Review article guidance, Review issue",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000586,The relationship between venture capital backing and the top management team quality of firms going public and implications for initial public offerings,Thomas J.=Chemmanur: chemmanu@bc.edu; Manish=Gupta: manish.gupta@nottingham.ac.uk; Karen=Simonyan: ksimonya@suffolk.edu; Hassan=Tehranian: tehranih@bc.edu,"Abstract
We make use of hand-collected data on a large sample of entrepreneurial firms going public to analyze the association between venture capital (VC) backing and the top management team (TMT) quality of firms at the time of their initial public offerings (IPOs), and the effect of both VC-backing and TMT quality on the growth in their post-IPO operating performance and IPO 
firm valuations
. We first show that VC-backing is associated with higher TMT quality. We then show that both higher TMT quality and VC-backing lead to higher growth in post-IPO operating performance and higher IPO valuations. We find that the above two variables affect the growth in post-IPO operating performance through an “ability channel,” whereby the TMTs of such firms choose projects with higher equilibrium scale and implement them more ably. Further, TMT quality and VC-backing affect IPO 
firm valuations
 not only through the above ability channel, but also through a “certification channel,” whereby higher TMT quality and VC-backing credibly certify intrinsic firm value to the IPO market, thus reducing the extent of asymmetric information facing such firms in the IPO market and yielding these firms higher IPO valuations. Finally, we show that TMT quality and VC-backing act as complements in their effect on IPO firms' growth in post-IPO operating performance.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000677,From cultural entrepreneurship to economic entrepreneurship in cultural industries: The role of digital serialization,Jeffery S.=McMullen: mcmullej@indiana.edu,"Abstract
Digitization has provided entrepreneurs direct access to consumers in cultural 
industries
 while offering intermediaries an alternative to critics' reviews when deciding whether to invest in creative products. Using data from the Chinese online self-publishing industry, we examine whether and how intermediaries use popular acclaim when deciding to invest in self-published books. We then flip the script and examine whether cultural entrepreneurs generate intermediary investment through popular acclaim and to what extent they do so through a digital 
serialization
 strategy. We find that, by encouraging both popular acclaim and intermediary investment, digital 
serialization
 emancipates cultural entrepreneurs from the indirect and uncertain reciprocity historically described by cultural 
entrepreneurship theory
. Instead, digital serialization allows cultural entrepreneurs to generate consumer attention directly through economic entrepreneurship and to alter the power and roles of intermediaries and entrepreneurs in the cultural production process.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000689,In the heat of the game: Analogical abduction in a pragmatist account of entrepreneurial reasoning,Anastasia=Sergeeva: sergeeva@rsm.nl,"Abstract
We draw on Searle's philosophy of language to distinguish between “opportunities” as intentional content directed towards a preferred future that entrepreneurs aim to fulfill and opportunities as conditions to be met for their satisfaction. We maintain that studying the former requires adopting a 
player stance
 rather than the 
analyst
 stance that prevails in the current literature. We build on pragmatist conceptions of truth and imagination to elaborate on the player stance and propose analogical abduction as a mechanism for conceiving and fulfilling “opportunities”. We develop a pragmatist process model of entrepreneurial reasoning that balances the two stances, and derive action principles for entrepreneurs from it.", November 2021,"Analogy, Abduction, Entrepreneurial opportunities, Learning, Pragmatism",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000690,From homo economicus to homo agens: Toward a subjective rationality for entrepreneurship,Mark D.=Packard: mpackard@unr.edu; Per L.=Bylund: per.bylund@okstate.edu,"Abstract
The aim of this article is to expound the subjectivist position on the concept of ‘rationality.’ To begin, we review the longstanding and still ongoing debate in philosophy over the differences (or not) between the natural and social sciences. While 
positivism
, which supposes no difference between the sciences, has been the tradition whence the economic rationality construct (
homo economicus
 and its modern variants) has derived, a longstanding interpretivist tradition holds that social science is innately distinct from, and should be studied differently than, the natural sciences. From this interpretivist vantage, we assess and critique the positivist conception of rationality and put forth a subjectivist account of rationality as a process in its stead. Rationality here emerges as an intentional process of betterment over time. Because entrepreneurship is definitionally such a process, we explore the implications of this process rationality for 
entrepreneurial action
 theory.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000707,"Trust, fast and slow: A comparison study of the trust behaviors of entrepreneurs and non-entrepreneurs",Qingqing=Bi: claire.bi@canterbury.ac.nz; Wai Fong=Boh: awfboh@ntu.edu.sg; Georgios=Christopoulos: cgeorgios@ntu.edu.sg,"Abstract
Following the cognitive and behavioral approach, this study compares the trust behaviors of entrepreneurs and non-entrepreneurs in a dynamic environment. Due to the differences in the contexts that they face, the thinking frameworks they adopt, and the knowledge structures they form from experience, we argue that entrepreneurs display different trust behaviors from non-entrepreneurs when facing volatile environments in the decision-making process. Adopting established paradigms from behavioral 
game theory
 (trust game), we examine the evolution of trust behaviors of the two groups for trust building, trust violation, and trust recovery. In a Singapore-based sample, we find that entrepreneurs build trust more quickly, decrease trust more quickly when faced with trust violations, and recover more quickly from trust violations than non-entrepreneurs. This study contributes to a better understanding of entrepreneurs' trust behaviors over time, their responses to variations in social exchanges, while contributing to overall ongoing discussions of the unique characteristics of entrepreneurs.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000720,Venture distress and problemistic search among entrepreneurs in Brazilian favelas,Anna-Katharina=Lenz: anna-katharina.lenz@rmit.edu.au; Christopher=Sutter: sutterc@miamioh.edu; Rafael=Goldszmidt: rafael.goldszmidt@fgv.br; Cesar=Zucco: cesar.zucco@fgv.br,"Abstract
When do entrepreneurs in emerging markets seek out help from organizational sponsors? Problemistic search theory suggests that entrepreneurs will seek out sponsors in moments of venture distress. However, this theory was developed in the context of large organizations; it is not clear how it might apply to entrepreneurs in resource-constrained contexts. We use three inductive studies conducted in favelas in Brazil to examine when entrepreneurs seek help. Consistent with problemistic search theory, we find evidence that entrepreneurs seek out help from organizational sponsors in moments of venture distress. We also explore what types of entrepreneurs are most likely to seek help in a situation of venture distress and find that entrepreneurs who are more socially embedded and have more social obligations are more likely to take up sponsorship services, leading to important heterogeneity in our results on take-up. We find that women, more mature ventures, and middle-aged entrepreneurs are all more likely to engage in problemistic search. We contribute to a more contextualized theory of problemistic search for small entrepreneurs in emerging markets. We also provide important theoretical and practical insights about the demand-side of organizational sponsorship.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618308619,Launching for success: The effects of psychological distance and mental simulation on funding decisions and crowdfunding performance,Stefan=Rose: rose@time.rwth-aachen.de; Daniel=Wentzel: wentzel@time.rwth-aachen.de; Christian=Hopp: hopp@time.rwth-aachen.de; Jermain=Kaminski: j.kaminski@maastrichtuniversity.nl,"Abstract
This research examines how potential backers form mental representations of products in reward-based crowdfunding campaigns, and how these representations affect funding decisions and campaign performance. To test our framework, we conducted four experiments and also drew on a sample of 961 Kickstarter campaigns. Our results show that two campaign characteristics – the product's development stage and the indicated time to product delivery – determine the psychological distance that supporters experience in response to a campaign, and that psychological distance, in turn, inhibits individual campaign contributions and cumulative campaign success. Furthermore, we find that encouraging supporters to imagine the benefits of product usage is an effective means to increase support for campaigns that elicit high psychological distance.", November 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000495,Toward a theological turn in entrepreneurship: How religion could enable transformative research in our field,Jeffery S.=McMullen: mcmullej@indiana.edu; Melissa S.=Cardon: mcardon@utk.edu; Brett R.=Smith: smithbr2@miamioh.edu,"Abstract
Despite its overwhelming importance to millions of people across the planet both currently and throughout history, religion has been largely neglected by entrepreneurship research. Yet, because of its prevalence, centrality, established base of scientific inquiry, and ability to offer novel insight into emerging phenomena, religion offers numerous opportunities for transformative research. In this editorial, we offer a glimpse of what a “theological turn” in entrepreneurship research might look like: first, by identifying obstacles to religion’s inclusion and how these barriers may be overcome; second, by explaining how the theological turn enables alternative explanations of important phenomena and stimulates research questions that build on the growing integration of religion and entrepreneurship in practice; and finally, by showing how a theological turn could challenge researchers to reach beyond our existing knowledge horizons to develop a future of impactful, relevant, and pioneering scholarship in the field of entrepreneurship.", September 2021,"Religion, Entrepreneurial action, Social entrepreneurship, Identity, Entrepreneurial context, Theological turn, Entrepreneurship",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000537,A holistic approach to the evolution of an entrepreneurial ecosystem: An exploratory study of academic spin-offs,Johan=Wiklund: jwiklund@syr.edu; Hooman=Abootorabi: sseyedab@syr.edu; Alan R.=Johnson: alan.r.johnson@nord.no; Cameron D.=Miller: cdmiller@syr.edu,"Abstract
Borrowing nomenclature and concepts from ecology and evolutionary biology, we apply descriptive exploratory methods to extend our understanding about the complex dynamics of an 
entrepreneurial ecosystem
. We take a holistic approach to ecosystem analysis, and we analyze the evolution of multiple activities (i.e., entry, exit, growth, and survival) within an 
entrepreneurial ecosystem
 and the interactions of these activities with the ecosystem actors and resource providers. Applying our approach to nearly the entire population of academic spin-offs in Norway from 2000 to 2015, we generate a number of important findings. By characterizing the dynamics of an entrepreneurial ecosystem, we take a major step towards theorizing the ecosystem perspective. Our findings have important implications for public policies targeted to promote academic entrepreneurship.", September 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000525,Now is the time: The effects of linguistic time reference and national time orientation on innovative new ventures,Jintong=Tang: jintong.tang@slu.edu; Wenping=Ye: yewenping@jnu.edu.cn; Shaji A.=Khan: shajikhan@umsl.edu; Jun=Yang: yangjun_0708@zju.edu.cn,"Abstract
Two perspectives stand out in examining international variations in innovative new venture creation: institutions and national culture. However, systematic insights into the interconnections between institutional and cultural perspectives and their effects on entrepreneurship are severely lacking. In order to fill this gap, the current research integrates two prominent yet under-explored institutional and cultural factors: linguistic future-time reference (FTR) as an institutional factor and long-term orientation as a cultural factor, and considers how they are linked through the time perspective reflected in risk and uncertainty perception. Drawing upon linguistic relativity theory and cultural theory, we propose that institutions with strong FTR languages and cultures with short-term orientation are more likely to foster innovative new venture creation. We utilized merged, multi-level, and multi-source data of 34,673 entrepreneurs from 42 countries to test our hypotheses. We also conducted a series of scenario-based, intra-group experiments with bilingual entrepreneurs to further confirm that strong-FTR has a positive relationship with innovative new venture creation. Results offer compelling support for our hypotheses.", September 2021,"Future-time reference, Short-term orientation, Innovative new ventures",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000513,Breaking boundaries to creatively generate value: The role of resourcefulness in entrepreneurship,Trenton Alma=Williams: trenwill@iu.edu; Eric Yanfei=Zhao: ericzhao@indiana.edu; Deniz=Ucbasaran: Deniz.Ucbasaran@wbs.ac.uk; Scott=Sonenshein: scotts@rice.edu; Gerard=George: gerard.george@georgetown.edu,"Abstract
Entrepreneurial resourcefulness is a concept that resonates with practitioners and scholars alike from a diverse set of theoretical and empirical backgrounds. Despite the prevalence and promise of this concept, the literature on entrepreneurial resourcefulness is fragmented and lacks cohesion in how it is labeled, conceptualized, measured, and deployed. In many cases, it appears that bringing resources to bear for entrepreneurial purposes is taken for granted, which limits theoretical development of if and how ventures emerge and grow. In this editorial, we explore the theoretical underpinnings of resourcefulness, offer a definition, and provide a roadmap for future scholarship. In addition, we introduce the six articles that comprise the Special Issue on entrepreneurial resourcefulness, discuss their contributions, and explore how they relate to our overall perspective on resources and resourcefulness. It is our hope that this Special Issue will mobilize additional scholarship to enhance our knowledge on resourcefulness, which we view as a fundamental part of entrepreneurship.", September 2021,"Entrepreneurial resourcefulness, Resources, Social and psychological foundations, Special issue, Research agenda",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000501,Habitual entrepreneurship in digital platform ecosystems: A time-contingent model of learning from prior software project experiences,Andreas=Schwab: aschwab@iastate.edu,"Abstract
The emergence of large-scale digital platforms such as Facebook, Google Play and Apple App Store around 2008 has created opportunities for independent entrepreneurs to offer their self-developed software applications (“apps”) to large groups of platform users. The development and release of tens of thousands of apps by thousands of independent developers has created dynamic 
entrepreneurial ecosystems
. This paper investigates whether and how learning by independent habitual entrepreneurs unfolds in substantively different ways in such dynamic platform-based environments. We argue that in these 
entrepreneurial ecosystems
, the timing of learning efforts becomes essential. For Facebook app developers, we find that learning from their own prior app projects remains feasible. However, entrepreneurs have only a few months during which they can benefit from what they learned from a prior app project. This study supports the feasibility of time-contingent learning from prior app projects for increasingly prevalent dynamic entrepreneurial ecosystems such as digital platforms. Implications for future research and management practice are outlined.", September 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618308358,Entrepreneurs' stressors and well-being: A recovery perspective and diary study,Ute=Stephan: ute.stephan@kcl.ac.uk; Dominika=Wach: dominika.wach@tu-dresden.de; Eva=Weinberger: e.weinberger@aston.ac.uk; Jürgen=Wegge: juergen.wegge@tu-dresden.de,"Abstract
Although entrepreneurs are said to have extremely stressful work, how they may be able to maintain their well-being in light of this is only poorly understood. Newly integrating the challenge-hindrance stressor framework with the stressor-detachment model of recovery from work stress, we 
investigate how specific
 challenge and hindrance stressors—
cognitive
 and emotional demands—impact entrepreneurs' well-being by influencing their ability to detach and recover from work stress. 
Our diary study yielded
 386 day-pair data points from 55 entrepreneurs. Challenge and hindrance stressors inhibited psychological detachment from work in the evening through increasing problem-solving pondering and work-related affective rumination, which diminished entrepreneurs' well-being the next morning. These effects are robust to alternative explanations (e.g., objectively measured sleep efficiency) and differ from relationships observed across entrepreneurs. Our findings elucidate the nature of stressors and the micro-foundational mechanisms of stress and recovery.", September 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000549,When the beacon goes dark: Legitimacy repair work by subsequent actors in an emerging market category,Brett R.=Smith: Smithbr2@Miamioh.edu,"Abstract
Extant research explains how entrepreneurial ventures can serve as a beacon in emerging market categories, blazing a trail for other ventures and contributing to their successful 
legitimation
. However, what happens when a beacon is unsuccessful? Using a qualitative 
case study
 of particularly sensitive interviews and secondary data from the social venture accelerator category, we examine how subsequent entrants overcome recursive legitimacy challenges caused by beacon underperformance and failure. Through our study, we develop a model of legitimacy repair work, which consists of decoupling legitimacy assessments, prioritizing distinctiveness identity claims, and enabling selective generalization. Following legitimacy loss, we highlight how actors prioritize and sequence distinctiveness claims over legitimacy claims, which we refer to as distinctive legitimacy. We also identify a key mechanism of selective generalization, where identity claims are made to direct audience attention toward some (and not other) attributes of the organization and category to acquire resources. Our findings have important implications for new venture legitimacy: mitigating legitimacy loss, the process of optimal distinctiveness, and legitimacy management over time.", September 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000483,Unfolding refugee entrepreneurs' opportunity-production process — Patterns and embeddedness,Kim=Klyver: kkl@sam.sdu.dk; Yi Dragon=Jiang: yjiang@escp.eu; Caroline=Straub: caroline.straub@bfh.ch; René=Mauer: rmauer@escp.eu,"Abstract
We observe the opportunity-production processes of aspiring refugee entrepreneurs in their host countries. Our process data from eighteen refugee entrepreneurs reveal heterogeneity in how entrepreneurs move across the opportunity-production stages of conceptualization, objectification, and enactment. We identify four patterns, which are characterized by differences in iteration, order, and continuity. By theorizing on process characteristics and connecting these characteristics to 
embeddedness
 and temporality, we provide insights into how cognitive alignment and use of networks from home countries versus host countries help expand the explanatory scope of the opportunity-production theory from ordinary entrepreneurs to entrepreneurs who are subject to disruption in their lives.", September 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000409,"Venture Idea Assessment (VIA): Development of a needed concept, measure, and research agenda",Per=Davidsson: per.davidsson@qut.edu.au; Denis A.=Grégoire: denis.gregoire@hec.ca; Maike=Lex: lex.maike@gmail.com,"Abstract
To address challenges constraining prior research on evaluation of entrepreneurial projects, we develop the concept of Venture Idea Assessment (VIA) and validate an instrument to capture it. VIA concerns the assessment of Venture Ideas (VI) unbundled from assessment of any agents with whom they may be associated. The assessment can be performed by anybody at any stage of the venture development process, not just by potential founders at its outset. We develop and validate a parsimonious VIA measure across six empirical studies using a broad set of assessors and VIs using interviews, experiments and surveys following real-world start-up processes and decisions. In a research agenda we outline how the VIA platform—the concept and its operationalization—can be employed in novel research across various streams of entrepreneurship research.", September 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000392,Managing negative emotions from entrepreneurial project failure: When and how does supportive leadership help employees?,Marcus T.=Wolfe: mtwolfe@ou.edu; Holger=Patzelt: patzelt@tum.de; Dean A.=Shepherd: dshephe1@nd.edu; Leire=Gartzia: leire.gartzia@deusto.es,"Abstract
Drawing on Affective Events Theory and a sample of 112 matched manager-employee dyads involved in failed corporate entrepreneurial projects, we develop and test a model of when and how managerial leadership can foster high employee performance in their subsequent endeavors. Through 
path analysis
 modeling, we show that perceptions of supportive managerial leadership behaviors can limit the detrimental effects of recalled negative emotions from prior project failures on employee job satisfaction, and through job satisfaction, on employee performance. However, the benefits of supportive managerial leadership behaviors dissipate with more time since the project has failed.", September 2021,"Corporate entrepreneurship, Project failure, Job satisfaction, Job performance, Leadership, Negative emotions",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618307195,Timing is everything? Curvilinear effects of age at entry on new firm growth and survival and the moderating effect of IPO performance,David W.=Williams: dww@utk.edu; Jiaju=Yan: jyan16@vols.utk.edu,"Abstract
Theory suggests that an earlier age at international entry results in improved growth but also decreased survival chances. Empirical studies tell a different story, providing mixed and equivocal results that challenge the tenets of extant theory. To begin to bridge the gap between theory and results, we develop theoretical explanations for curvilinear (inverted U-shaped) relationships between age at entry and both firm growth and firm survival as well as the moderating impact of resource-providing initial public offering (IPO) on the resource-intensive 
internationalization
 process. Our findings support the inverted U-shaped relationships and that IPO performance steepens the 
growth curve
 and flattens the survival curve. Taken together, our study enhances understanding of the effects of age at entry, bridges the IPO and international entrepreneurship literatures, and offers avenues for extending the micro-foundations of the development of capabilities for new foreign market entry. In doing so, we advance knowledge about the conditions under which earlier or later 
internationalization
 leads some firms to thrive while others fail.", September 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301247,On the origins of entrepreneurship: Evidence from sibling correlations,Theodor=Vladasel: theodor.vladasel@upf.edu; Matthew J.=Lindquist: matthew.lindquist@sofi.su.se; Joeri=Sol: J.Sol@uva.nl; Mirjam=van Praag: mvp.si@cbs.dk,"Abstract
Despite the consensus that entrepreneurship runs in the family, we lack evidence regarding the total importance of family and community background, as well as the relative importance of different background influences that affect entrepreneurship. We draw on 
human capital formation
 theories to argue that families and communities provide a salient context for the development of individual entrepreneurial skills and preferences, beyond the existing focus on parental entrepreneurship. We posit that early influences are more important than later influences and propose a hierarchy of family influences, whereby genes have the largest explanatory power, followed by parental entrepreneurship, neighborhoods, and parental resources, and finally by parental immigration, family structure, and sibling peers. Finally, we argue that the higher human and financial capital intensity of 
incorporated
 relative to unincorporated entrepreneurship predictably alters the hierarchy of family influences, as does gender. Sibling correlations estimated on Swedish register data confirm our hypotheses.", September 2021,"Entrepreneurship, Self-employment, Family background, Sibling correlations",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301867,Entrepreneurial Finance and Moral Hazard: Evidence from Token Offerings,Paul P.=Momtaz: momtaz@ucla.edu,"Abstract
This paper provides the first evidence of a 
moral hazard in signaling
 in an entrepreneurial 
finance
 context, by examining token offerings or Initial Coin Offerings (ICOs). Entrepreneurs' ability to signal quality is crucial to succeeding in the competition for growth capital. However, the absence of institutions that verify endogenous signals may induce a moral hazard in signaling. Consistent with this hypothesis, artificial linguistic intelligence indicates that token issuers systematically exaggerate information disclosed in whitepapers. Exaggerating entrepreneurs raise more funds in less time, suggesting that investors do not see through this practice initially. Eventually, the crowd learns about the exaggeration bias through trading with other investors. The resulting investor disappointment causes the 
cryptocurrency
 to depreciate and the probability of platform failure to increase.", September 2021,"G14, G30, L26, M13, O16",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000185,Turning a curse into a blessing: Contingent effects of geographic distance on startup–VC partnership performance,Jiamin=Zhang: jiamin.zhang@unimelb.edu.au; Qian=Gu: qgu@gsu.edu,"Abstract
This study aims to unravel the dynamic effect of geographic distance on startup–VC partnership performance by incorporating the possibility of accessibility improvement triggered by China's high-speed railway (HSR) during the partnership. We find that the negative effect of geographic distance is significantly weakened when HSR becomes available after the startup–VC partnership formation. We draw on the relational view to explore what types of geographically distant startup–VC partners can benefit more from HSR technology advancement. Results indicate that startup–VC partners that rely heavily on knowledge-sharing, have more complementary resources, or have more complex governance structures can better leverage the improved accessibility from HSR to transform the disadvantages of the long-distance to advantages.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262100015X,Mortgage affordability and entrepreneurship: Evidence from spatial discontinuity in Help-to-Buy equity loans,Enrico=Vanino: e.vanino@sheffield.ac.uk,"Abstract
We exploit a policy change in the UK Help-to-Buy (HTB) equity loan scheme in order to identify the causal link between 
mortgage
 
affordability
 and entrepreneurship activity at the local level. We contribute to the literature on the relationship between 
housing finance
 and entrepreneurship by demonstrating the impact of government equity loans on entrepreneurship through the release of trapped liquidity. When less equity is required to buy a house, households could use the ‘additional’ liquidity to start a business. We use a spatial discontinuity in treatment methodology to take advantage of the reform of the Help-to-Buy scheme in 2016, which increased the limit of equity loans provided in London. By using data on business population at the postcode sector level, we are able to measure the impact of the new policy by comparing similar areas on the opposite sides of the Greater London Authority boundary. Our results show that an increase in 
mortgage
 
affordability
 fosters 
entrepreneurial activity
 in affected areas by 20%, resulting in 1 more start-up on average per postcode per year. The new businesses are mainly single-plant micro 
enterprises
 in capital intensive sectors with low income volatility.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000197,"Express yourself: Facial expression of happiness, anger, fear, and sadness in funding pitches",Benjamin J.=Warnick: b.warnick@wsu.edu,"Abstract
We build upon theory from 
evolutionary psychology
 and emotional expression, including basic emotion theory and the dual threshold model of anger in organizations, to extend knowledge about the influence of facial expressions of emotion in entrepreneurial fundraising. First, we conduct a qualitative analysis to understand the objects of entrepreneurs' facial expressions of four basic emotions in their pitches: happiness, anger, fear, and sadness. This provides a base for our theorizing that the frequency of entrepreneurs' facial expression of each of these emotions exhibits an inverted U-shaped relationship with funding. We also argue that the frequency of changes in entrepreneurs' facial expressions is positively related to funding. We test our predictions with a sample of 489 funding pitches using computer-aided facial expression analysis. Results support inverted U-shaped relationships of the frequency of facial expression of happiness, anger, and fear with funding, but show a negative relationship of sadness with funding. Results further support that the frequency of change in entrepreneurs' facial expressions promotes funding.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000173,A multi-motivational general model of entrepreneurial intention,Evan J.=Douglas: evan.douglas@sasin.edu,"Abstract
We develop and test an overarching model of entrepreneurial intention that includes profit, social impact, and innovation as the three main drivers of entrepreneurial behavior. A holistic model is developed to identify separately the generic intention to be a self-employed entrepreneur from the associated intention to be a specific type of entrepreneur. The latter is revealed by using a conjoint experiment to reveal the individual's relative preferences for profit, social impact, and innovation outcomes. Using fuzzy-set qualitative comparative analysis we provide insights into individuals' motivations for different types of entrepreneurial careers and for their multiple pathways to the same entrepreneurial type.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000203,Beyond bricolage: Early-stage technology venture resource mobilization in resource-scarce contexts,Hana=Milanov: hana.milanov@tum.de; Sophie=Bacq: bacqs@iu.edu; Lina=Reypens: lina.reypens@tum.de,"Abstract
This inductive, multiple-case study advances scholarly understanding of resourcefulness by examining the combination of 
resource mobilization
 behaviors over time, and associated performance outcomes, within seven early-stage medical technology ventures in the relatively resource-scarce context of Kampala, 
Uganda
. Our analysis reveals two 
resource mobilization
 trajectories, characterized by different dynamic combinations of 
bricolage
 and resource seeking as ventures develop. High-performing ventures increased resource seeking as they developed and dynamically alternated lower and higher levels of 
bricolage
, opting back into bricolage upon substantial resource acquisition. We explain the divergence in trajectories with ventures' reactions to catalytic events and reinterpretation of their resource spaces beyond local environs.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618307316,Career patterns in self-employment and career success,Michael=Koch: m.koch@kent.ac.uk; Sarah=Park: J.W.Park@kent.ac.uk; Shaker A.=Zahra: zahra004@umn.edu,"Abstract
A substantial body of research examines entry into and exit from self-employment. However, little is known about the career patterns of the self-employed, their transitions into and from self-employment and the success associated with different patterns of their careers. To address these issues, we examine the career patterns of individuals with self-employment experience and their relationship to objective and subjective career success using data from the German Household Panel (SOEP). Our results show that persistent self-employment careers have higher gross labor income and exhibit higher job and 
life satisfaction
 than all other self-employment career patterns.", January 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000318,The art of discovering and exploiting unexpected opportunities: The roles of organizational improvisation and serendipity in new venture performance,Andrew E.F.=Fultz: aefultz@utep.edu; Keith M.=Hmieleski: k.hmieleski@tcu.edu,"Abstract
This study examines a model linking organizational improvisation with new venture performance, via serendipity, at varying levels of resource constraints and informal 
organizational structure
. Results from a national sample of 326 startups, based throughout the United States, indicate that the association of improvisation with serendipity is greatest when resource constraints are high, and—in turn—that serendipity is positively related to new venture performance when informal 
organizational structure
 is high. These findings highlight novel pathways and contingencies through which improvisation may prove to be a resourceful means for startups to identify new opportunities and gain performance advantages.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000306,Persuasive or polarizing? The influence of entrepreneurs' use of ingratiation rhetoric on investor funding decisions,Paul=Sanchez-Ruiz: psanch26@depaul.edu; Matthew S.=Wood: ms_wood@baylor.edu; Anna=Long-Ruboyianes: annajinyu.long@csusb.edu,"Abstract
We add richness and depth to investor decision-making research by exploring the influence of entrepreneurs' use of ingratiation rhetoric in their investor pitch presentations on investor funding decisions. Drawing on ingratiation theory, we model the effects of flattery, self-deprecation, opinion conformity, and self-promotion as distinct forms of ingratiation rhetoric. We do so independently and in tandem, conceptualizing the confluence of ingratiation forms as driving an overall aggregate effect on the amount of funding allocated by investors. We then theorize that entrepreneur charisma and entrepreneur performance are moderators of the aggregate effect. We test our model in the angel investment context with data from 789 entrepreneur pitch presentations to 27 investors on the 
Shark Tank
 television program from 2009 through 2020. We find that on their own, the different forms of ingratiation rhetoric have mixed effects, with flattery and self-deprecation negatively impacting investor funding amount and opinion conformity and self-promotion positively relating to funding amount. When used together, we find an overall negative effect, and this effect is positively moderated by entrepreneur charisma and entrepreneur performance. These findings shed new light on ingratiation rhetoric as a powerful force in entrepreneurs' efforts to secure funding.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000331,Navigating interpersonal feedback seeking in social venturing: The roles of psychological distance and sensemaking,Andreana=Drencheva: a.drencheva@sheffield.ac.uk; Ute=Stephan: ute.stephan@klc.ac.uk; Malcolm G.=Patterson: m.patterson@sheffield.ac.uk; Anna=Topakas: a.topakas@sheffield.ac.uk,"Abstract
This study advances understanding of interpersonal feedback seeking as a relational micro-foundational process whereby social entrepreneurs proactively involve others in venturing and engage in sensemaking when this fails. Our inductive analysis of 82 interviews with 36 social entrepreneurs reveals the agency in and the plurality and precariousness of feedback seeking by identifying three distinct feedback-seeking trajectories. Feedback seeking is an identity-driven process whereby how and why social entrepreneurs seek feedback depends on their psychological closeness to the targeted social issue. Our study elucidates the relationship between identity and feedback processes and uncovers psychological distance from the social issue as a new construct in social venturing.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000343,Explaining serial crowdfunders' dynamic fundraising performance,Ahmed=Sewaid: ahmedkas@insper.edu.br; Simon C.=Parker: sparker@ivey.ca; Abdulkader=Kaakeh: a.kaakeh@uu.nl,"Abstract
This paper investigates serial crowdfunders' performance over successive campaigns. Adopting an expected utility maximization framework in a setting with asymmetric information about hidden 
entrepreneurial actions
 and types, we propose that crowdfunding amounts raised will follow a cyclical pattern over successive campaigns. A sample drawn from the population of serial crowdfunders on Kickstarter confirms this prediction and suggests that signaling reputations via the cyclical adjustment of campaign effort may be the mechanism driving it. Implications for theory and practice are discussed.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000355,Co-creative entrepreneurship,Masoud=Karami: m.karami@otago.ac.nz; Stuart=Read: stuartread@gmail.com,"Abstract
Interest in applying the idea of co-creation to entrepreneurship is emerging through research on opportunity creation and entrepreneur heuristics. We place co-creation in the conceptual center of the entrepreneurship research discussion. Doing so requires relaxing the view of a central entrepreneur and adopting a view of stakeholders as peers in the venture, providing resources and deriving benefit. We formalize this insightinto a central proposition and derive implications of it for major themes ofentrepreneurship research, entrepreneurial outcomes, and three challenges unique to entrepreneurship. The sum of our work suggests moving the discussion in entrepreneurship research from the unit of analysis of the individual entrepreneur, venture, or opportunity to entrepreneurship as a collaborative process undertaken by aconstellation of stakeholders that come together to co-create novelty in the environment.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000367,Pivoting or persevering with venture ideas: Recalibrating temporal commitments,Hans=Berends: j.j.berends@vu.nl,"Abstract
We examine how entrepreneurs rework the temporal commitments implicated in their venture ideas when they persevere or pivot upon confronting unexpected events. To gain a deeper understanding of how entrepreneurs recalibrate temporal positioning, length, and ordering of actions and milestones, we systematically analyzed 22 episodes across five ventures when entrepreneurs had to decide whether to persevere or to pivot. To persevere, entrepreneurs positioned their actions as a continuation of the past, while increasing the temporal length and complexity of temporal ordering, thereby avoiding disruptive changes to their relational commitments. In contrast, entrepreneurs repositioned their actions on a revised timeline in order to pivot. We conclude the paper by discussing the implications of our findings for theory on 
entrepreneurial action
.", July 2021,"Entrepreneurship, Perseverance, Pivoting, Process, Time",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000379,How cultural tightness interacts with gender in founding teams: Insights from the commercialization of social ventures,Ikenna=Uzuegbunam: ikennauzuegbunam@gmail.com; Seemantini=Pathak: pathaks@umsl.edu; Amy=Taylor-Bianco: taylor-b@ohio.edu; Brandon=Ofem: ofemb@umsl.edu,"Abstract
Though discussion of culture is central in the literature on gender in entrepreneurial settings, prior studies have paid scant attention to the specific impact of cultural norms. We propose that the impact of gender composition in new venture teams (NVTs) on commercialization of social ventures is contingent on the strength of cultural norms of a nation. Our view of gender as a culture-contingent resource reveals ordering mechanisms that distinguish gender effects in culturally tight versus culturally loose societies with respect to commercialization 
intent
 and legal form. The empirical analysis of an international sample of 6657 social ventures from 30 countries supports the study hypotheses. The findings show that 
gender differences
 in new ventures are more significant in tight societies compared to loose societies.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000380,Opportunity evaluation in teams: A social cognitive model,Mark P.=Healey: mark.healey@manchester.ac.uk,"Abstract
Research on opportunity evaluation is flourishing but we know little about how teams evaluate opportunities rather than individuals. Conceptualizing opportunity evaluation as a collective process, we develop an agent-based model to investigate how the social cognitive mechanisms of team formation affect the ability of 
entrepreneurial teams
 to choose good opportunities and forgo bad ones. We find that opportunity evaluation decisions depend on the cognitive status of the lead entrepreneurs who found the team and the team formation strategy they use, i.e., whether they select team members based on interpersonal similarity (i.e., cognitive homophily) or complementary knowledge (i.e., cognitive heterophily). Moreover, we show that learning moderates the effects of team formation on opportunity evaluation. Overall, our work provides a new view of opportunity evaluation as a dynamic social process contingent upon entrepreneurs' networks and team founders' characteristics and their choices of who to turn for judgments of an opportunity's potential.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618303112,Alert and Awake: Role of alertness and attention on rate of new product introductions,Thomas H.=Allison: t.allison@tcu.edu; Smita=Srivastava: smita.srivastava@wsu.edu; Arvin=Sahaym: arvin@wsu.edu,"Abstract
Integrating the attention-based view and entrepreneurial alertness perspective, we develop our theoretical framework to test the influence of CEO attention and alertness on rate of new product introduction (NPI). We propose that a firm's rate of NPI is predicted independently and jointly by attention and alertness, two different yet complementary cognitive characteristics of the CEO. Using a sample of 271 US-based small and medium size 
enterprises
 (SMEs) from 2004 to 2015, we show that CEO's attention to R&D, customers, and competitors positively influence NPI, while attention to organization negatively impacts the relationship. We also find that CEO alertness has positive impact on the rate of NPI; however, high alertness hurts the rate of NPI. Such theoretical elaboration and empirical illustrations contribute to a better understanding of the 
microfoundations
 of managerial cognition and its role in NPI. By adding alertness from entrepreneurship literature and explicating the nexus between alertness and attention, our study explains how some CEOs who are able to acquire novel information and stay focused are able to achieve higher rate of NPI.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000057,Economic inequality – Is entrepreneurship the cause or the solution? A review and research agenda for emerging economies,Anna-Katharina=Lenz: anna-katharina.lenz@rmit.edu.au; Christopher=Sutter: sutterc@miamioh.edu,"Abstract
In this paper we examine whether entrepreneurship is a cause or solution to economic inequality in emerging economies. Using an institutional lens, we review 40 articles and find that entrepreneurship can increase or decrease economic inequality, depending on the sector where it occurs (formal or informal), and its effect on institutions (making them more inclusive or more exclusive). To develop a future research agenda, we build on these insights by examining 68 additional articles on economic inequality in emerging economies from a range of disciplines. The result is a rich research agenda on entrepreneurship and economic inequality in emerging markets.", May 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000161,Fatal attraction: A systematic review and research agenda of the dark triad in entrepreneurship,Katrina M.=Brownell: ingram@indiana.edu,"Abstract
Using meta-analytic techniques, relations among the 
Dark Triad
 
personality traits
 – Machiavellianism, 
narcissism
, and 
psychopathy
 – were examined in relation to outcomes associated with two different stages of the entrepreneurial process: entrepreneurial intention and entrepreneurial performance. From 39 independent samples (
N
 = 11,819), we found that Machiavellianism positively relates to entrepreneurial intention (
r
c
 = 0.16) and negatively relates to entrepreneurial performance (
r
c
 = −0.22), 
narcissism
 positively relates to entrepreneurial intention (
r
c
 = 0.24) and entrepreneurial performance (
r
c
 = 0.09), and 
psychopathy
 positively relates to entrepreneurial intention (
r
c
 = 0.17) and negatively relates to entrepreneurial performance (
r
c
 = −0.10). Amid conflicting empirical results and theoretical viewpoints, we leverage our findings to present an exploration into how and why the 
Dark Triad
 
personality traits
 relate to the initiation and performance of entrepreneurship. We interpret the existing literature through the lens of Nietzsche's will to power and propose that power acquired over others (domination) is likely to be as viable a predictor of entrepreneurial agency as power removed from others (emancipation). Limitations to the primary studies included in our review are thoroughly examined, and we offer direction for future research.", May 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000045,Getting more from many—A framework of community resourcefulness in new venture creation,Christina=Hertel: christina.hertel@epfl.ch; Julia=Binder: julia.binder@epfl.ch; Emmanuelle=Fauchart: emmanuelle.fauchart@unifr.ch,"Abstract
In this study, we move beyond the predominant focus entrepreneurship researchers have put on the acquisition of financial capital from professional investors by exploring how, and with what effects, entrepreneurs can mobilize all required resources—financial, human, physical, and social—from local communities. Our temporal analysis of the 
resource mobilization
 processes of seven cases of community-based 
enterprises
 (CBEs) reveals four sets of activities with distinct goals and effects, which explain how entrepreneurs can meet or even exceed their 
resource mobilization
 goals by mobilizing a greater variety of resources from a broader base of resource providers. Importantly, the findings show how entrepreneurs can achieve a multiplier effect meaning that they can perpetuate the inflow of significant amounts of unsolicited resources by continuously engaging in activities targeted at creating a sense of identification and ownership, which require comparatively little extra effort and resource inputs. We synthesize our findings in a framework of community resourcefulness in new venture creation. This framework adds a new perspective of resourcefulness as “getting more from many,” and demonstrates that resourceful behavior is not necessarily about individuals' ability to respond to situational constraints but also about their ability to recognize and seize situational resource potentials. Our findings have important implications for our understanding of resourcefulness in entrepreneurship and the nascent body of literature on community-based 
enterprises
.", May 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262100001X,How childhood ADHD-like symptoms predict selection into entrepreneurship and implications on entrepreneurial performance,Nasir=Rajah: N.A.Rajah@leeds.ac.uk; Vassiliki=Bamiatzi: v.bamiatzi@sussex.ac.uk; Nick=Williams: N.E.Williams@leeds.ac.uk,"Abstract
This study advances research on 
mental health
 and entrepreneurship through the examination of 
Attention Deficit Hyperactivity Disorder
 (ADHD)-like symptoms, associated with hyperactivity/impulsivity and inattention. We examine the impact of these symptoms at age 10 on entrepreneurial performance as an adult. We find that while ADHD-like symptoms in childhood may have a positive impact on entrepreneurial selection, they negatively impact on survival and performance, with a variant effect by each symptom, predominantly among males. We find that high levels of inattention predict business failure and lower take-home income, while high levels of hyperactivity/impulsivity contribute to overall negative earnings' growth.", May 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000021,Trends and patterns in sustainable entrepreneurship research: A bibliometric review and research agenda,Amitabh=Anand: amitabh.anand@skema.edu; Padmaja=Argade: padmaja.argade02@kedgebs.com; Fanny=Salignac: fanny.salignac@kedgebs.com,"Abstract
Sustainable entrepreneurship (SE) has attracted significant scholarly attention over the last decade. Given its rapid development and its multidisciplinary character, the SE literature is increasingly difficult to navigate. We combine two bibliometric approaches (i.e. co-citation analysis of references and bibliographic coupling of documents) with manual coding of documents to take stock of progress within the field, mapping out focal points as well as blind spots in the SE research agenda. We show how distinct subfields have formed around key ideas expressed in subsets of seminal papers, shedding light on the relational nature of knowledge creation – uncovering the characteristics, evolution and future trajectories of these subfields. We develop a future research agenda based on the developments of the overall field as well as the subfields of SE.", May 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618306566,Enhancing measures of ESE to incorporate aspects of place: Personal reputation and place-based social legitimacy,Helen=Pushkarskaya: helen.pushkarskaya@yale.edu; Nicole=Breazeale: nbreazeale@uky.edu; David R.=Just: drj3@cornell.edu,"Abstract
We argue that existing measures of entrepreneurial self-efficacy (ESE) are underspecified in the context of tight-knit communities, where personal reputation plays a major role. We propose a new place-based ESE dimension that measures assessment by individuals of their ability to elicit respect from their community. This integral ESE component points to the very meaning of entrepreneurship in highly relational contexts. Although our enhanced ESE measure incorporates some influences of place, other aspects, such as geographical context, continue to moderate the relationship between ESE and entrepreneurial aptitude. We conclude with a discussion of the relevance and utility of this enhanced measure.
Executive summary
Scholars have invested considerable energy in understanding the motivations and practices of high-growth entrepreneurs and urban ecosystems, where business interactions tend to be impersonal and transactional. Most entrepreneurial measures assess either individual characteristics or place-based characteristics. Rural areas or developing regions, where entrepreneurs may be the best hope for 
revitalization
 (Sarasvathy, 2008), operate according to cultural principles that are different from those of “high-performance” 
entrepreneurial ecosystems
, and they remain understudied. We argue that in such resource-constrained, tight-knit communities, some important factors in the creation of a venture will jointly depend on place and individual—measuring the fitness of individuals in their community. In such environments, the belief of individuals in their ability to gain a positive reputation within their local community to advance their new 
enterprise
 is among the decisive factors for the venture creation process. We develop a measure of such beliefs.
We enhance measures of entrepreneurial self-efficacy (ESE) to account for the confidence of individuals in their ability to fit within their community. ESE is the belief of an individual about his or her ability to perform the various tasks and roles required of a venture creator, which has been shown to be the most robust predictor of 
entrepreneurial actions
 and success. Current measures of ESE are place-agnostic; they assess a person's self-efficacy relative to general business activities, such as marketing, innovation, and so forth. However, some features of place have integral effects on ESE beliefs and act as neither antecedents nor moderators. We argue that a perceived ability to navigate complex social networks within the relevant community is a core component of ESE. How people see themselves in relation to their local community—and how they believe others see them—is central to how they think about their entrepreneurial potential. We propose a new ESE dimension that evaluates the fit between an individual and a place by measuring the confidence of an individual in their ability to elicit respect from the community (ERC). We expected ERC to be most relevant in small, tight-knit, and indigenous communities defined by social hierarchies (e.g., rural), where reputable individuals are better positioned to employ resources embedded in that place to benefit their 
enterprise
.
We developed a new ESE dimension that quantifies ERC beliefs. In doing so, we followed the established protocol (Furr, 2011; Hinkin, 1995). We derived an initial pool of items from existing literature (Chen et al., 1998; De Noble et al., 1999; McGee et al., 2009), enhanced this pool based on 
semistructured interviews
 with 23 rural residents with a history of self-employment, finalized the item pool based on feedback from eight experts, administered a large-scale survey of 1481 Kentucky residents (established, nascent, and non-entrepreneurs; approximately half of whom were from rural areas), derived the scale structure using exploratory and 
confirmatory factor analyses
, and examined its reliability and validity. Contrary to our expectations, we found that the enhanced ESE scale converged to the same structure in both rural and urban subsamples, which indicates that ERC is a unique dimension of ESE in both settings.
Although our enhanced ESE measure incorporates some components of place, we show that other aspects, such urban or rural context, continue to moderate the relationship between ESE and entrepreneurial aptitudes. For instance, the urban/rural moderates ERC's impact on individual propensity toward business risk-taking (BRT). In urban areas, as expected, the relationship between ERC and BRT was positive and monotonic. In rural areas, however, the relationship had an inverse U-shape, which may reflect the problem of over-embedding: whereas those who are embedded in their communities may be more likely to pursue entrepreneurship, a high level of community 
embeddedness
 could discourage venture creation. Overall, our results suggest that some common measures of entrepreneurship may be underspecified for small-world, relational environments. Many of these environments have been left behind by uneven development and thus could benefit from a research-based understanding of how to foster 
entrepreneurial activity
 and innovation.", May 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306923,Legitimation of a heterogeneous market category through covert prototype differentiation,Erik=Lundmark: erik.lundmark@mq.edu.au; Anna=Krzeminska: anna.krzeminska@mq.edu.au; Charmine E.J.=Härtel: Charmine.Hartel@monash.edu,"Abstract
The literature on market category formation provides insufficient insights into how entrepreneurs address the need for collective 
legitimation
 of a market category while simultaneously managing tensions between heterogeneous practices. Through a study of the Autism@Work market category, this article shows that covert prototype differentiation constitutes a distinct construct that explains how entrepreneurs in heterogeneous market categories can strengthen category legitimacy while supporting the practices that they perceive as appropriate, without triggering conflicts related to category heterogeneity. The article also provides insights into how market category legitimacy is perceived by entrepreneurs and the antecedents and implications of such perceptions.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306935,Navigating compromise: How founder authenticity affects venture identification amidst organizational hybridity,Anna M.=Wagenschwanz: anna.wagenschwanz@bain.com,"Abstract
Founders of hybrid ventures encounter organizational tensions that can compel compromise in both their organizations' and their own personal values. Such compromises may, in turn, undermine founders' identification with their ventures. In a multi-case study analysis we examine why social entrepreneurs differ in their responses to organizational tensions, both at the firm- and individual-level, and how such differences relate to their venture identification. Specifically, our findings reveal that strategic decisions made in the context of values-based complexity are often accompanied by concerns regarding founder authenticity—that is, judgments about the alignment between founders' actions and the commitments or responsibilities associated with their identities as entrepreneurs. Yet, because founders differ in the basis from which they seek to maintain such alignment, these differences shape both hybridity management and subsequent venture identification. By unpacking such differences, our findings contribute new theory, bridging recent scholarship on founder authenticity with longstanding research on organizational identification and hybrid organizing.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306959,"Toward a coping-dueling-fit theory of the ADHD-entrepreneurship relationship: Treatment's influence on business venturing, performance, and persistence",Nathan Sidney=Greidanus: nathan.greidanus@umanitoba.ca,"Abstract
We examine the relationship between 
Attention Deficit
 and Hyperactivity Disorder (ADHD) and entrepreneurship with a specific focus on the influence of treatment. To guide our analysis, we develop the Coping-Dueling-Fit (CDF) theory as an extension to the dueling symptoms and person-environment fit perspectives. The CDF posits that ADHD symptoms' fit with entrepreneurship can act as both an asset and liability, and that coping, which we operationalize as treatment, serves to moderate this relationship to the benefit of the individual. We test our hypotheses by drawing on unique data from the Panel Study of Income Dynamics and find that treatment moderates the relationships between ADHD and business venturing, performance, and persistence. A post-hoc analysis further explores nuances in the variety of ADHD including the influences of comorbidity with depression, treatment type, push and pull factors in entrepreneurial entry, as well as persistence in the face of negative performance.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306960,Head in the clouds? Cannabis users' creativity in new venture ideation depends on their entrepreneurial passion and experience,Benjamin J.=Warnick: b.warnick@wsu.edu,"Abstract
New venture ideation is critical to the entrepreneurial process. To generate creative ideas, some entrepreneurs turn to cannabis, proposing its benefits. However, extant research has not validated such claims. Using a new venture ideation task, we explore differences between cannabis users' and non-users' creativity in new venture ideation by assessing the originality and feasibility of their ideas. We theorized and found that cannabis users generate new venture ideas that are more original, but less feasible, compared to non-users. Further building upon creativity research emphasizing that motivation and knowledge shape creative thinking, we theorize that the 
cognitive effects
 of being a cannabis user on idea originality and feasibility are influenced by entrepreneurial passion for inventing—which reflects motivation to explore new venture ideas—and 
entrepreneurial experience
 (i.e., founding experience). Consistent with our theorizing, the increased originality and decreased feasibility of cannabis users' ideas surfaced to the extent that they had entrepreneurial passion for inventing and diminished commensurate with their 
entrepreneurial experience
. Our study contributes to the literatures on new venture ideation, entrepreneurial passion, entrepreneurial experience, and cannabis users' creativity by providing an integrated perspective of cognitive, motivational, and experiential factors that drive entrepreneurs' creativity.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306704,Twitter sentiment as a weak signal in venture capital financing,Reiner=Braun: reiner.braun@tum.de,"Abstract
How do venture capitalists (VCs) incorporate weak and strong signals in the valuation of technology-based startups? Based on a sociocognitive perspective of signaling theory, we introduce Twitter sentiment as a novel and weak signal, which we juxtapose with patents as a traditional, strong signal. While we find a positive association between both signals and VCs' venture valuations, our results reveal that Twitter sentiment does not correlate with actual long-term investment success, whereas patents do. Additionally, we identify and test novelty and experience characteristics (i.e., startup age and VC firm experience) as boundary conditions for our proposed signal-valuation relationships.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306947,Signal configurations: Exploring set-theoretic relationships in angel investing,Linda F.=Edelman: ledelman@bentley.edu; Tatiana S.=Manolova: tmanolova@bentley.edu; Candida G.=Brush: cbrush@babson.edu; Clifton M.=Chow: cchow@bentley.edu,"Abstract
Anchored in signaling theory, we use a configurational approach to examine how new ventures credibly communicate their underlying firm quality, using a unique dataset of 117 new ventures that sought investment from a prominent angel group located in the Northeastern United States. Unlike existing research, which employs 
econometric models
 to reflect one best solution, we use crisp-set qualitative comparative analysis (cs/QCA) to understand signal configurations during the angel investment decision-making process. Our findings suggest that there are multiple paths to our three outcomes, passed small group screening, passed large group presentation, and passed due diligence/invested, validating notions of equifinality. Signals are complementary and configurations differ by 
industry
 sector. We also find that effective signal configurations differ by stage of investment, thereby offering evidence of cognitive dual processing on the part of the 
angel investors
. We contribute to the literature on signaling by linking our findings to recent work on signal interactions and by highlighting the configurational and temporal aspects of signaling in the angel investment context. Implications are discussed.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306984,Knowable opportunities in an unknowable future? On the epistemological paradoxes of entrepreneurship theory,Stratos=Ramoglou: s.ramoglou@soton.ac.uk,"Abstract
It is often assumed that opportunities can be known 
ex ante
 in spite of the fact that the future is simultaneously acknowledged to be unknowable. This paper endeavors to resolve this epistemological paradox in a manner that facilitates a more meaningful treatment of the knowledge problems of entrepreneurship. To this end, we draw from linguistic philosophy and undertake three interrelated analytical steps at the conceptual foundations of entrepreneurship theory. First, we clarify subtle logical aspects underlying the meaningful use of the word “uncertainty” 
qua
 unknowability. When properly used, uncertainty reflects the epistemological assessment that enterprising actors may only believe – not know – that new ventures can succeed. When incorrectly used, uncertainty is misrepresented as an obstacle that can be overcome by some and not others. Second, we explain how prevalent linguistic practices (“opportunity discovery”, “opportunity recognition”) lie at the root of epistemological tensions in opportunity theory. They act as a distorting mirror that trivializes the unknowability of the future and nourishes impressions of mental agencies allowing entrepreneurs to know the unknowable. Third, we urge a more nuanced understanding of the knowledge problems of entrepreneurship. On the one hand, we submit that opportunities are ineliminably unknowable. On the other hand, however, we argue that there exist knowable Opportunity-Ingredients (OIs) whose knowability varies across contexts. These analytical developments further contribute to the ongoing “opportunity wars”, strengthen the epistemological foundations of opportunity-actualization, improve construct clarity, and reveal new possibilities for research.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306716,Childhood adversity and the propensity for entrepreneurship: A quasi-experimental study of the Great Chinese Famine,Mathew=Hayward: mathew.hayward@monash.edu; Zhiming=Cheng: zhiming.cheng@unsw.edu.au; Wei=Guo: weiguo@nju.edu.cn; Haining=Wang: wanghn36@mail.sysu.edu.cn,"Abstract
Studies on the determinants of entrepreneurship emphasize that challenged adults tend to become entrepreneurs. However, research has not addressed the childhood origins surrounding the propensity for entrepreneurship. This article links childhood adversity to the propensity of individuals to become migrant entrepreneurs later in life. We test hypotheses derived from this theory in the context of whether, and when, children who survived the Great Chinese Famine of 1959–1961 became migrant entrepreneurs. Results strongly indicate that those who survived greater hardship during the Famine are more likely to become entrepreneurs, especially when they were younger during the famine years. We also find that being younger at the time of migration increased the likelihood of becoming entrepreneurs in their new locale. Overall, this study casts light on why, how and when childhood adversity shapes the propensity for entrepreneurship.", January 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306728,Social entrepreneurship and values work: The role of practices in shaping values and negotiating change,Ira=Chatterjee: Ira.chatterjee@hanken.fi; Joep=Cornelissen: cornelissen@rsm.nl; Joakim=Wincent: Joakim.wincent@hanken.fi,"Abstract
Prior research on social entrepreneurship highlights the role and importance of values in managing change, yet few studies examine processes of managing values to achieve social change. Through a longitudinal 
case study
 of the 
social organization
 Barefoot College, we explored how a social entrepreneur navigated conflicting values to address issues of 
gender inequality
 and effect social change. We found that the social entrepreneur engaged in values-related work, purposively interpreting and enacting values-laden practices to bring about a quiet transformation within the community. In our resulting value augmentation model, we capture a process that anchors and amplifies social values, rather than replaces them, and with this model, we develop theory on values work and sustainable social change.", January 2021,"Social entrepreneurship, Values work, Practices, Social change, Gender equality",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262030673X,Globalization and affordability of microfinance,Sunny Li=Sun: li_sun@uml.edu; Hao=Liang: hliang@smu.edu.sg,"Abstract
We study how globalization can differentially affect 
financial inclusion
 through the lens of microfinance. Based on an institutional logics perspective, we argue that MFIs embody both social logic and market logic with regard to provision of affordable microfinance loans. Speicially, social logic is amplified by greater social globalization and the stronger presence of 
nonprofit organizations
 (NPOs) in the microfinance 
industry
. In contrast, economic globalization catalyzes MFIs' market logic, leading to weaker or greater 
affordability
 of microfinance, depending on the relative strength of the profit-maximizing motive and real competition. We test these predictions by focusing on MFI interest-rate setting and using longitudinal data from 2030 MFI observations across 50 countries from 2002 to 2012. We find that country-level social globalization measure is negatively associated with the average MFI loan interest rates and that country-level economic globalization measure has an inverse U-shaped relationship with the average MFI loan interest rates. These results support our hypotheses and suggest a more nuanced view on how globalization affects 
affordability
 of microfinance.", January 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S2352673421000512,Which crisis strategies are (expectedly) effective among SMEs during COVID-19?,Kim=Klyver: kkl@sam.sdu.dk; Suna Løwe=Nielsen: sso@sam.sdu.dk,"Abstract
We investigate COVID-19 as a disabling and an enabling mechanism for small and mid-size 
enterprises
 (SMEs), particularly how SMEs’ crisis strategies might help them through the crisis. SMEs can follow a 
retrenchment
 strategy, a persevering strategy, or an innovation strategy, and they can do so narrowly or broadly. Using a representative sample of Danish SMEs, we test how crisis strategies are associated with turnover expectations. We find distinct differences in how effective crisis strategies are linked to turnover expectations, depending on how the crisis affected the SMEs in the first place (i.e., the SMEs were crisis victims, crisis immunes, or crisis exploiters).",November 2021,"Small and medium-sized enterprise, SME, COVID-19, Coronavirus, Crisis strategy, Crisis management",Business Venturing Insights,2025-03-08T00:00:00,7.0,"Understanding crisis strategies for SMEs during COVID-19 can offer practical value to European startups facing similar challenges, enhancing their chances of survival and success."
https://www.sciencedirect.com/science/article/pii/S0883902620306844,Do we understand each other? Toward a simulated empathy theory for entrepreneurship,Mark D.=Packard: mpackard@unr.edu; Thomas A.=Burnham: thomasburnham@unr.edu,"Abstract
Entrepreneurs often face the daunting task of predicting consumer demand before it exists—what consumers will want if and when the entrepreneur might make it available to them. Such alertness and judgment require an entrepreneur's vicarious imagination—the supposition of what a value experience would be like for another—such as empathy. Prevailing theories of empathy, however, are ill-suited for entrepreneurship theory as they are defined as and focused on an emotion-matching process. We propose that empathy be understood instead as a vicarious mental simulation of another's experience that, when accurate, produces similar emotions but also similar experiential knowledge. According to our ‘simulated empathy theory,’ empathy is a rational imagination process, intentional and knowledge-based. We connect this empathy process to contemporary entrepreneurship theory, namely opportunity recognition and evaluation processes. We also revise the concept of empathic accuracy accordingly, and derive therefrom some practical implications regarding how entrepreneurs can increase their empathic accuracy and, thereby, their chances of success.", January 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306832,The sandwich game: Founder-CEOs and forecasting as impression management,Veroniek=Collewaert: veroniek.collewaert@vlerick.com; Tom=Vanacker: TomR.Vanacker@UGent.be; Frederik=Anseel: f.anseel@unsw.edu.au; Dries=Bourgois: dries.bourgois@kuleuven.be,"Abstract
Drawing on impression management and 
social exchange theory
, we examine the use of positively biased forecasts by (non-)founder-CEOs as an impression management tactic vis-à-vis their existing investors. Contrary to their non-founder counterparts, founder-CEOs identify more with the venture they founded and, therefore, experience greater instrumental and affective concerns about the long-term relationship with their investors. Consequently, we hypothesize that founder-CEOs will strategically provide less positively biased forecasts to their investors than non-founder-CEOs. Using two independent samples with revenue forecasts reported to different venture capital investors and a causal chain scenario study consisting of two experiments, we find consistent support for our hypothesis. Overall, this study provides new insights into the use of forecasts as a post-investment impression management tactic by distinct types of CEOs in entrepreneurial ventures.", January 2021,"Forecasts, Venture capital, Founder, Impression management, Social exchange theory",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306820,"Lab, Gig or Enterprise? How scientist-inventors form nascent startup teams",Daniel P.=Forbes: forbe010@umn.edu,"Abstract
The 
entrepreneurial teams
 that form around university-based technologies influence whether and how those technologies are commercialized. Past research has emphasized the roles of external actors, such as technology transfer officers or investors, in managing the evolution of academic startup teams. But less is known about how individual scientist-inventors form their initial teams. To explore that process, we conducted longitudinal interviews with nine scientist-inventors leading nascent startups at major U.S. universities. Our analyses revealed that these scientists were working with a more extensive set of commercially-relevant knowledge and network connections than past research has accounted for. In fact, the scientists had their own “lay theories” of academic entrepreneurship that encompassed team-specific ideas as well as broader ideas about how their technologies ought to be commercialized. We identified four “design principles” capturing key variations in what the scientists hoped to achieve through their teams: 
control
, 
scope
, 
entitativity
, and 
dynamism
. We further found these principles clustered into three distinct commercialization models, which we called 
Lab, Gig,
 and 
Enterprise
. Finally, we elaborated the models' implications for the scientists' team formation strategies, the sources through which they identified new members, and their approaches to dealing with administrators and investors. Our findings change what we know about nascent academic startups by showing how scientists play a critical internal role alongside, prior to, and sometimes instead of the external drivers of team formation whose roles have been more extensively documented.", January 2021,"Academic entrepreneurship, Entrepreneurial teams, Founders, Cognition, Knowledge, New ventures, Team design",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618305421,Business founders' work design and new venture development,Ryan Shuwei=Hsu: ryanswhsu@ntnu.edu.tw; Aichia=Chuang: achuang@uncg.edu; An-Chih=Wang: wac@ceibs.edu,"Abstract
This study aims to explain the interplay between business founders' work design and new venture development. Our 
qualitative research
 reveals that founders' work design differs in terms of unsettled and settled work. In unsettled work, founders redesign their work to serve the needed changes in their new ventures. In settled work, founders, who develop a commitment to their self-created work, often maintain rather than change their work, regardless of the potentially needed changes in the new ventures. Our findings suggest that founders' work has a subtle structure that results in direct, day-to-day experience that is integral in shaping new ventures.", January 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619302691,Age and entrepreneurial career success: A review and a meta-analysis,,"Abstract
Entrepreneurship has become an attractive career option for both the young and the old, but age has not been thoroughly examined as a variable of interest among entrepreneurship scholars. In this review, we present 12 theoretical perspectives regarding the effect of age on entrepreneurs' success and our critiques. We then present results of an exploratory meta-analysis with effect sizes from 102 samples. The results show that age has a weak, positive linear relationship with overall entrepreneurial success, but it does exhibit signs of a U-shaped relationship, with the relationship being negative among younger samples but positive among older samples. The positive effect size becomes more pronounced when more females are included in the sample. The effect size of age does not differ by entrepreneurs' tenure running the firm. In terms of the type of success measures, age has a negative effect on growth but a positive effect on subjective success, firm size, and financial success, and no effect on survival. We compare our results with previous meta-analyses on employees' age to show the uniqueness of entrepreneurs' careers and we offer suggestions for future studies.
Executive summary
The work population is aging, and entrepreneurship has become an attractive career option for both the young and the old. Age has often been included in empirical studies as a control variable to predict entrepreneurs' success, but with inconsistent empirical findings and inadequate attention to age's theoretical role, it is not clear whether older entrepreneurs are as successful as their younger counterparts.
The current study has two related components. First, we provided a much-needed review of the alternative theoretical perspectives on the effect of age on entrepreneurial success. These 12 perspectives focused on various age-related mechanisms, namely personal health, 
rigidity
, risk propensity, time's value, discrimination, 
human capital
, social capital, financial capital, emotion, life stages, family obligation, and gender stereotype. We found that explicit theoretical explanations are rare and fragmented for addressing entrepreneurs' age-success relationship. Most of the existing perspectives are simplistic, equivocal, and sometimes contradictory. Guided by the above review, we proposed several research questions about several contingency factors, such as the entrepreneur's life stage, gender, and tenure running the business, which would help us gain a more nuanced understanding of the age-success relationship.
Second, we empirically examined the research questions in an exploratory meta-analysis based on 102 independent samples. Indeed, we found more nuanced results than are typically apparent. The results show that age has a weak, positive linear relationship with overall entrepreneurial success (
ρ
̂
=0.02), but it does exhibit signs of a U-shaped relationship, with the relationship being negative among younger samples but positive among older samples. The positive effect size becomes more pronounced when more females are included in the sample, suggesting female entrepreneurs' chance of success is higher at later life stages. The effect size of age does not differ by entrepreneurs' tenure running the firm, thus ruling out the possibility that the age-success effect is primarily driven by tenure effect or selection bias.
We performed some robustness checks for the meta-analytic results. We found age's effect is not affected by the study's publication year, but the effect differs across the world. In terms of the type of success measures, we found age has a negative effect on growth, but a positive effect on subjective success, firm size, and financial success, and no effect on firm survival. Older entrepreneurs tend to have larger businesses, so older entrepreneurs are “punished” for having a larger denominator in the calculation of growth, putting them in an unfair position if growth is the sole measure of success.
We compared our results with previous meta-analyses on employees' age, and one clear distinction is that previous meta-analyses reported an inverted U-shaped relationship between employees' age and overall performance, while our study shows the opposite, U-shaped relationship between entrepreneurs' age and success. This difference is probably due to the fact that entrepreneurial careers involve different resource commitments, job requirements, and success criteria compared to traditional careers, making people at a specific age more likely to succeed in one career but not in the other.
Our study shows that researchers need to rethink the theoretical role of age, account for potentially simultaneous operation of theoretical mechanisms, and identify new research directions. We call for more studies to address the unique promises and challenges entrepreneurs in each life stage will face, and we provided some suggestions to increase the rigor of future studies. It is imperative to study the intra-individual aging effect through tracking a large cohort of entrepreneurs over decades with repeated measures of their cognitive intelligence, motivations, role identities, and success. Because male entrepreneurs outnumber female entrepreneurs, it is necessary to oversample female entrepreneurs or seek a matched sample, so that any gender-related differential effects can be demonstrated fully. Because many entrepreneurs work in teams, future studies can compare founding teams of the same age (e.g., college classmates) and teams of different ages, and investigate how members of each type of team can collaborate to maximize their chance of success.", January 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619307311,How does entrepreneurial failure change an entrepreneur's digital identity? Evidence from Twitter data,Jörn H.=Block: block@uni-trier.de; Christian=Fisch: cfisch@uni-trier.de,"Abstract
We assess whether and how entrepreneurs' digital identities change in response to entrepreneurial failure based on a sample of 760 entrepreneurs who experienced failure. We analyze a longitudinal dataset of Twitter messages before, during, and after a business failure with a language-based method of computerized text analysis. The results of our explorative research indicate that the financial, social, and psychological consequences of failure are reflected in entrepreneurs' Tweets and lead to changes in their digital identities. Among others, entrepreneurs' language decreases in emotional tone and indicates increased 
psychological distress
. Simultaneously, we observe higher levels of self-assurance and reflection after failure. We conclude by outlining the potential of using Twitter-generated digital footprints in future entrepreneurship research.", January 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306595,From principles to action: Community-based entrepreneurship in the Toquaht Nation,Matthew=Murphy: mmurph@uvic.ca,"Abstract
This article draws upon research undertaken in partnership with the Toquaht Nation, a Canadian First Nations community, which reveals how guiding principles that reflect Indigenous values, knowledge and heritage shape community-based entrepreneurial opportunity identification. Using a community-based participatory research approach, we leveraged insights across a range of methods, participants and points in time to co-create a decision support and impact evaluation system – grounded in the Toquaht people's vision of well-being and development – that is used by the Toquaht Nation to evaluate the potential and actual impacts of community-based entrepreneurial opportunities across multiple dimensions of well-being. By elaborating a notion of collective effectuation, the research demonstrates how a more explicit consideration of the social and cultural context of entrepreneurship can provide novel insights that enrich existing theories and paradigms, and highlights the complexities of the phenomena we collectively aim to study.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306558,"Self-employment and eudaimonic well-being: Energized by meaning, enabled by societal legitimacy",Ute=Stephan: ute.stephan@kcl.ac.uk; Susana M.=Tavares: susana.tavares@iscte-iul.pt; Helena=Carvalho: helena.carvalho@iscte-iul.pt; Joaquim J.S.=Ramalho: joaquim.jose.ramalho@iscte-iul.pt; Susana C.=Santos: santossc@rowan.edu; Marc=van Veldhoven: m.j.p.m.vanveldhoven@tilburguniversity.edu,"Abstract
This study investigates 
why
 and 
where
 self-employment is related to higher levels of eudaimonic well-being. We focus on meaningfulness as an important eudaimonic process and subjective vitality as a eudaimonic well-being outcome that is central to entrepreneurs' proactivity. Building on self-determination theory, we posit that self-employment, relative to wage-employment, is a more self-determined and volitional career choice, which enhances the experience of meaningfulness at work and perceptions of work 
autonomy
. In a multi-level study of 22,002 individuals and 16 European countries, meaningfulness at work mediates the relationship between self-employment and subjective vitality and explains this relationship better than work autonomy. We identify moderating effects of context: the societal legitimacy of entrepreneurship in a country affects the choice set of alternative career options that individuals can consider and thus shapes the experience of meaningfulness at work and work autonomy, and thereby indirectly subjective vitality. These findings expand our understanding of eudaimonic well-being, entrepreneurs' work, and the role of context in entrepreneurship and well-being research. They complement existing research on hedonic well-being of entrepreneurs and extend the scarce literature on their eudaimonic well-being.", November 2020,"L26: Entrepreneurship, I310: General welfare, well-being, O520: Economy-wide country studies: Europe",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306546,"External enablement of new venture creation: An exploratory, query-driven assessment of China's high-speed rail expansion",Leona Shao-Zhi=Li: leonali@um.edu.mo,"Abstract
This study seeks to build upon empirical and conceptual work examining the characteristics, mechanisms, and roles of exogenous, actor-independent drivers of 
entrepreneurial actions
 and outcomes, known as “external enablers” (EE). These aggregate-level changes – ranging from unforeseen, episodic EEs such as natural disasters and pandemics, to evolving, pan-generational EEs such as socio-demographic shifts, 
climate change
, and breakthrough technologies – constitute a burgeoning stream of research concerning the manner and degree to which disequilibrating circumstances facilitate or forestall business venturing. The central focus of our investigation takes up the critical issue of an EE's temporal, spatial, and sectoral scope. Specifically, we seek to extend and enhance the EE framework by offering a more nuanced assessment of how and why the actions and outcomes elicited by EEs vary, often significantly, as a function of an EE's characteristics. To delve into this emerging line of inquiry, we conduct an abductive, query-driven, exploratory investigation of the impact China's high-speed rail expansion has had on new business venturing. Our findings contribute to further refinement of the theoretical EE framework, provide an important road map for future empirical studies, and offer considerable practical and policy implications.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262030656X,Entrepreneurial imaginativeness and new venture ideation in newly forming teams,Jeffery S.=McMullen: mcmullej@indiana.edu; Alexander S.=Kier: alex.kier@wsu.edu,"Abstract
Entrepreneurial imaginativeness is important for new venture ideation (the generation, evaluation, and development of ideas for new ventures), but its effects have only been examined at the individual level. Research suggests that new venture creation, including ideation, tends to involve multiple individuals, who are in the process of becoming a team for the first time. Given myriad possible combinations of individual imaginativeness in newly forming teams, we ask whether team configurations might vary in composition and performance when seeking to generate and develop new venture ideas. To answer this question, we conduct a field survey of 51 new venture teams in six different startup competitions. We find that various configurations among newly forming teams yield different new venture ideation performance outcomes and conclude by unpacking the theoretical and practical implications of our findings for new venture ideation, entrepreneurship, and team composition.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306571,A review of and future agenda for research on identity in entrepreneurship,Blake=Mathias: bdmathia@iu.edu; David W.=Williams: dww@utk.edu; Melissa S.=Cardon: mcardon@utk.edu; Nick A.=Mmbaga: nmmbaga@butler.edu,"Abstract
Research on identity in entrepreneurship represents a central, dynamic, and quickly growing field of research. Yet, rapid growth has led to a diversity of theoretical conversations and methodological advancements that has yielded a largely disjointed body of existing work. To advance research in this area, we systematically review 180 articles on identity(ies) in entrepreneurship from the last 20 years. We conducted a 
bibliometric analysis
 using terms in the keywords, titles, and abstracts of identified articles to examine the co-occurrence of these terms. We then develop an organizing framework that reflects four unique conversations within the body of research—distinctions, variations, constructions, and intersections—and highlight the key research questions and themes studied with each conversation. We chart a path for future research that reflects the broad spectrum of views in the literature and propose new opportunities for research that takes a network-based approach, explores post-emergent venture states of identity, and moves the study of identity to the digital world of online communities.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306534,A knowledge-based view of managing dependence on a key customer: Survival and growth outcomes for young firms,Helena=Yli-Renko: hylirenko@marshall.usc.edu; Lien=Denoo: l.c.i.denoo@tilburguniversity.edu; Ramkumar=Janakiraman: ram@moore.sc.edu,"Abstract
Young firms in business-to-business markets often experience a high level of dependence on a key customer, but what are the firm-level effects of such dependence on survival and growth? And what can entrepreneurs do to manage such dependence? Many of the mechanisms suggested by resource dependence studies (such as safeguarding investments, symmetrical dependence, or acquisitions) are not available for young firms with limited resources. In this article, we develop a knowledge-based framework to examine how young firms can utilize congenital, experiential, and interorganizational learning to manage the effects of dependence on firm survival and growth. We test our hypotheses in a sample of young technology-based firms in the UK. First, we find a significant negative effect of key customer dependence on firm survival. Further, we find that 
experiential knowledge
 (accumulated as the firm ages) mitigates this negative effect, indicating that dependence is particularly hazardous for the youngest firms. Surprisingly, contrary to our hypothesis, we find that, for surviving firms, dependence has a 
positive
 effect on customer portfolio growth, and that this effect is stronger for less experienced, i.e., younger, firms. The effect is also amplified by congenital learning from the top management team's 
industry
 experience. Finally, interorganizational learning (facilitated by the relationship quality of the key customer relationship) has a 
negative
 moderating effect on the dependence-growth relationship. This indicates an impeding effect on the young firm's ability to acquire other customers. Taken together, our results contribute a more dynamic and nuanced view of young firms' customer relationships, shedding light on two distinct performance outcomes, firm survival and firm growth.", November 2020,"Customer relationships, Key customer, Resource dependence, Organizational learning, Firm survival, Customer portfolio growth",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S2352673421000524,Economic uncertainty and business formation: A cross-country analysis,Reza=Tajaddini: rtajaddini@swin.edu.au; Hassan F.=Gholipour: H.Fereidouni@westernsydney.edu.au,"Abstract
The purpose of this study is to explore the long-run relationship between economic uncertainty and new business formation. By applying panel ARDL/PMG and dynamic fixed-effects models for three samples of countries over the period of 2006–2018, our results show that higher levels of economic uncertainty have an adverse relationship with the new business formation in the long-run. Our findings are robust with the inclusion of control variables, different estimation methods, and alternative measures of economic uncertainty.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study on economic uncertainty and new business formation, while relevant, may have limited direct impact on European early-stage ventures in the short term."
https://www.sciencedirect.com/science/article/pii/S0883902620306686,Escaping the knowledge corridor: How founder human capital and founder coachability impacts product innovation in new ventures,Matthew R.=Marvel: mrmarvel@bsu.edu; Donald F.=Kuratko: dkuratko@indiana.edu; Marcus T.=Wolfe: mtwolfe@ou.edu,"Abstract
Innovation is of central importance to entrepreneurship research, as independent entrepreneurs account for the most fundamentally novel product offerings. This study investigates how founder 
human capital
 and founder coachability relate to exploiting 
product innovation
 in new ventures. Drawing on a dyadic sample of founders and startup coaches, we clarify how general 
human capital
 broadens the knowledge corridor to enhance 
product innovation
. Conversely, our study shines a light on the dark side of specific human capital and illustrates how specific 
prior knowledge
 constrains the knowledge corridor to limit product innovation. Further, we find that founder coachability—the degree to which an entrepreneur seeks, considers, and integrates feedback—is related to exploiting product innovation. Perhaps most importantly, we advance coachability as a learning mechanism that moderates the relationship between specific human capital and product innovation to overcome knowledge corridor constraints. Our findings have implications for human capital, coachability, and entrepreneurial learning.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306583,More than words! How narrative anchoring and enrichment help to balance differentiation and conformity of entrepreneurial products,Alexander=Vossen: alexander.vossen@uni-siegen.de; Christoph=Ihl: christoph.ihl@tuhh.de,"Abstract
Entrepreneurs face the challenge of having to conform to gain legitimacy, while at the same time differentiating themselves to gain competitive advantage. We show how entrepreneurs can craft an entrepreneurial narrative to succeed in this task among the user audiences empowered to evaluate their products. Building on theories of categorization, optimal distinctiveness, and cultural entrepreneurship, we propose that entrepreneurs should utilize the narrative's semantic relations with cultural meanings of established products and categories. We measure these semantic relations using machine learning methods for natural language, applied to data on 2901 independent video game proposals compared to 11,651 established games. Our findings reveal that semantically anchoring a product's narrative in the cultural meaning of claimed categories can help to leverage the benefits of differentiation, especially when spanning multiple, atypical categories. When a product focuses on few categories, semantically enriching a narrative with unclaimed categories' cultural meaning makes them more favorable to additional, possibly fragmented audiences that would not have considered them otherwise. Our results point to a key theoretical role of cultural entrepreneurship in shaping audience evaluation of categorization and differentiation by entrepreneurial ventures. It provides guidelines for entrepreneurs for managing the trade-off between differentiation and adherence to established cultural norms.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620306698,From a monopoly to an entrepreneurial field: The constitution of possibilities in South African energy,Panos=Constantinides: panos.constantinides@manchester.ac.uk,"Abstract
In this paper, we draw on a performativity perspective to conceptualize entrepreneurial opportunities as possibilities constituted through discursive-material practices within a field. Based on an analysis of a longitudinal qualitative 
case study
 in the field of South African energy from 2007 to 2018 we develop a process model of how possibilities become constituted over time as entrepreneurial actors enact different sets of discursive-material practices. Our process model contributes to entrepreneurship research by examining the transition process from a heavily regulated and tightly controlled field, to an unsettled and entrepreneurial field. The transition is reflected in the frames that organize field actors' discursive-material practices, starting with a single, closed frame that limits existing possibilities, moving to an emergent frame that introduces complementary possibilities, and then to an open frame that generates both complementary and competing possibilities. We discuss how our process model contributes to research adopting a performativity perspective and conclude with implications for further research.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618305767,Powered by compassion: The effect of loving-kindness meditation on entrepreneurs' sustainable decision-making,Yuval=Engel: y.engel@uva.nl; Anusha=Ramesh: aramesh@willamette.edu,"Abstract
As environmental degradation and 
climate change
 continue to threaten our livelihood, entrepreneurs have a crucial role to play in promoting environmental regeneration and infusing their ventures with sustainable decision-making. Building on advances in research on social and sustainable entrepreneurship, we propose that compassion is an important predictor of entrepreneurial decisions involving an ethical balancing act between concerns for environmental and economic sustainability. We further draw on emerging evidence in psychology, pointing to meditative practice as a powerful and accessible source of compassion. In two experimental studies, we test and find support for a mediation model predicting that, compared to an active control group, entrepreneurs engaging in a brief Loving-Kindness Meditation report an increase in compassion and, in turn, higher sustainable decision-making. On the basis of these findings, we offer contributions to research on the psychological drivers of sustainable entrepreneurship and to the literature about meditation and compassion in entrepreneurship.", November 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620302007,Editorial: Advancing the field of entrepreneurship: The primacy of unequivocal “A” level entrepreneurship journals,Matthew S.=Wood: ms_wood@baylor.edu,"Abstract
In this editorial, I seek to inform entrepreneurship scholars about the significance of unequivocal “A” level entrepreneurship journals for the continued ascent of entrepreneurship as a universally recognized “mainstream” academic field. Drawing insights from research on intellectual movements and the evolution of academic fields, I take stock of entrepreneurship as a community of scholars mobilizing elements of distinctiveness and legitimacy to elevate the status of the field. Doing so, I offer three field level observations on the primacy of unequivocal “A” journals for advancing the field. I then delineate a set of role related implications for members of the community, including authors, senior scholars, and newcomers to the field. Finally, I entertain some common objections to emphasizing journal status as a mechanism in entrepreneurship's upsurge to “mainstream” academic field.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617301775,Debt signaling and outside investors in early stage firms,Mircea=Epure: mircea.epure@upf.edu; Martí=Guasch: m.guasch@uvt.nl,"Abstract
By imposing a market like governance and directing entrepreneurs towards professional management, debt, and especially business debt, can serve as a reliable signal for outside equity investors. Such signals of firm accountability can alleviate the stringent 
information asymmetry
 at the early stages of the firm, and become stronger for bank business debt, in the presence of personal debt, and in high capital 
industries
. Using the Kauffman Firm Survey, we find evidence consistent with our hypotheses. Outside investors can rely on the governance role of debt and its underpinnings such as the bank-firm relationship. We also corroborate that young firms tend to focus on growth rather than profitability.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301326,Entrepreneurial fear of failure: Scale development and validation,Gabriella=Cacciotti: gabriella.cacciotti@wbs.ac.uk; James C.=Hayton: james.hayton@wbs.ac.uk; J. Robert=Mitchell: Rob.Mitchell@colostate.edu,"Abstract
Fear of failure is an important part of the experience of entrepreneurship. Yet past research has mainly investigated fear of failure in entrepreneurship among non entrepreneurs or nascent entrepreneurs and has done so by asking for reactions to hypothetical future failure. This approach to operationalizing the construct limits our capacity for understanding how entrepreneurs actually experience fear of failure while practicing entrepreneurship. In this paper, we conceptualize entrepreneurial fear of failure as a negative affective reaction based in cognitive appraisals of the potential for failure in the uncertain and ambiguous context of entrepreneurship. We use multiple samples to develop and validate a multidimensional, formative measure to assess entrepreneurial fear of failure as a state that is both cognitive and affective in nature. In addition to evidence of the 
psychometric
 properties of the new scale across multiple studies, we present a nomological network analysis with respect to measures of theoretically derived psychological outcomes and perceived behavioral tendencies of entrepreneurial fear of failure. We then discuss the theoretical, methodological, and empirical implications of this new measure of entrepreneurial fear of failure with an eye towards use of this scale in future research.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301429,The commons: A model for understanding collective action and entrepreneurship in communities,Camille=Meyer: camille.meyer@gsb.uct.ac.za,"Abstract
The creation of commons—resources that are shared, accessible, and collectively owned and managed by communities—is increasingly being adopted by social entrepreneurs as a way of contributing to community development and putting value into economic activities. Yet, little research is evident related to the entrepreneurial processes involved in the creation and commercialization of these shared resources. Drawing on the Institutional Analysis and Development framework developed by Ostrom (2005), I explain how commons are entrepreneurially created. Based on a 
comparative study
 of five community banks in Brazil, I derive two ideological principles of collective entrepreneurship that help sustain commercialization of commons without 
commodification
, namely ‘self-organization’ and ‘right to access’. I elucidate how these principles are enacted across venture levels through downward and upward mechanisms of social control facilitated by entrepreneurs who enhance collective action. This article contributes to the 
entrepreneurship theory
 of commons by explaining how commons are entrepreneurially created and by adding the collective entrepreneurship principles and mechanisms that commons of different types need in order to achieve and sustain wealth-creation options without incurring the downsides of 
commodification
.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619302241,Having your cake and eating it too? A two-stage model of the impact of employment and parallel job search on hybrid nascent entrepreneurship,Kim=Klyver: kkl@sam.sdu.dk; Paul=Steffens: paul.steffens@adelaide.edu.au; Carina=Lomberg: calom@dtu.dk,"Abstract
Hybrid entrepreneurship, simultaneous employment and entrepreneurship, is increasingly prevalent. We theorize entrepreneurial entry as one possible outcome of a two-stage new employment search process 1) decision to search for a job, attempt a start-up, or both and 2) outcome of start-up attempts. Stage 2 is critically different for hybrid (employed) nascent entrepreneurs who have greater access to resources and experience lower risk but also more salient alternative employment options. Using a novel longitudinal panel of new employment opportunity seekers, we find that employment status matters and that “parallel search” for a new job is detrimental to successful entrepreneurial entry.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618306906,The artisans' dilemma: Artisan entrepreneurship and the challenge of firm growth,Blake D.=Mathias: bdmathia@indiana.edu,"Abstract
An increasing number of entrepreneurial ventures are growing at exponential rates despite their founders' professed intentions 
not
 to grow their firms. We refer to these individuals as artisan entrepreneurs. Through an inductive, phenomenon-based research approach, we explore how artisan entrepreneurs subscribe to a counter-institutional identity yet engage in a divergent set of behaviors. We discover that artisans' counter-institutional identity contains two sides—promoting the exclusion of ‘who we are not’ (oppositional identity) or providing support for ‘who we are’ (relational identity). We theorize that artisan entrepreneurs' differing views regarding their 
independence
 led to very different approaches to growth. When artisans either do not see forms of external control as impinging on their independence or sense that serving stakeholders is a means to perform relational identity work, they embrace growth. Thus, artisans may find that growth serves stakeholders, but funding growth brings about financial pressures, which may force the artisan down a path of growth.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261830781X,Should business angels diversify their investment portfolios to achieve higher performance? The role of knowledge access through co-investment networks,Charlotta=Sirén: charlotta.siren@unisg.ch; Torben=Antretter: torben.antretter@unisg.ch; Dietmar=Grichnik: dietmar.grichnik@unisg.ch; Joakim=Wincent: joakim.vincent@unisg.ch,"Abstract
This paper investigates the performance effects of 
business angel
 portfolio 
industry
 diversification. Using a unique bi-annual panel dataset of 142 members of a professional angel investment platform and their portfolio returns between 2013 and 2017, we consider the costs and benefits of diversifying investments into various industries. Drawing upon theoretical arguments about distant search, we theorize and find a nonlinear (S-shaped) relationship between portfolio industry diversification and performance. Further, we pay specific attention to a proposed overdiversification effect that takes place at high levels of portfolio industry diversification and show that this effect is moderated by individuals' access to industry knowledge through their co-investment networks. For business angels who have a central position within a diverse network of industry specialists, the overdiversification effect is less pronounced.", September 2020,"Business angels, Distant search, Networks, Portfolio diversification, Syndication",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618301551,The unshackled entrepreneur: Occupational determinants of entrepreneurial effort,Catherine=Laffineur: catherine.laffineur@gredeg.cnrs.fr; Saulo=Dubard Barbosa: barbosa@em-lyon.com; Alain=Fayolle: fayolle@em-lyon.com; Benjamin=Montmartin: Benjamin.montmartin@skema.edu,"Abstract
Entrepreneurial effort triggers action towards business creation and constitutes the ultimate link between intention and action. Although occupations play a significant role in entrepreneurial entry, extant research has not thoroughly investigated primary occupational characteristics as specific antecedents of entrepreneurial effort. We contribute to this line of research by proposing and testing a model in which three occupational characteristics at the occupational level (managerial knowledge, self-accomplishment, and arduousness) are correlated with two cognitive factors at the individual level (effort-performance and instrumentality beliefs) that in turn affect behavior (entrepreneurial effort). We draw upon expectancy theory to motivate our model and combine data from the PSED and O*NET to test our hypotheses. We find compelling evidence that individuals facing arduous working conditions and lacking personal accomplishment in their salaried jobs will be more committed to their new business. In addition, we find that entrepreneurs coming from occupations involving high levels of managerial knowledge tend to put more effort into the new venture.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618304750,Cluster status and new venture creation,Lingli=Luo: lingliluo@zjgsu.edu.cn; Xufei=Ma: xufeima@cityu.edu.hk; Shige=Makino: makino@baf.msmail.cuhk.edu.hk; George A.=Shinkle: g.shinkle@unsw.edu.au,"Abstract
We examine how the social status of a cluster contributes to new venture creation. The key thesis of this paper is that cluster status facilitates new venture creation by providing positive decision cues for entrepreneurs; and it serves as a boundary condition of the relationship between cluster size and new venture creation. Based on a sample of township industrial clusters in China’s Guangdong Province from 2005 to 2013, we demonstrate that a higher-status position of the focal cluster or status spillover from related clusters (i.e., geographically proximate or domain-overlapped clusters) results in higher levels of new venture creation in the focal cluster. We also find that the relationship between cluster size and new venture creation is stronger for lower-status clusters and for clusters with a lower level of status spilled from geographically proximate clusters. Our research has implications for both entrepreneurs and policy makers.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902620302214,Editorial: On submitting economics articles to JBV,Simon C.=Parker: sparker@ivey.ca,"Abstract
This editorial provides guidance to authors considering submitting papers with economics content to 
Journal of Business Venturing
. The aim of the journal is to publish high-impact articles on entrepreneurship which combine methodological rigor with comprehensibility (‘accessibility’). Since many economics articles are technically demanding, accessibility to non-technical readers can be a major challenge for authors. This editorial provides some advice for authors of such articles to make their articles more closely targeted on the core interests of the journal's readership and more accessible to non-technical readers. To this end, the editorial suggests that potential authors might benefit from adopting one of the following ‘3R’ strategies: ‘Remove’, ‘Reduce’ or ‘Relate’. It is hoped that this editorial provides useful and actionable guidance for economics researchers submitting theoretical and empirical papers to 
Journal of Business Venturing.", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618305482,The frugal entrepreneur: A self-regulatory perspective of resourceful entrepreneurial behavior,David J.=Scheaf: David_Scheaf@baylor.edu; Timothy L.=Michaelis: tmichaelis@niu.edu; Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Jon C.=Carr: jon.carr@ncsu.edu,"Abstract
The present research complements extant perspectives of resourcefulness, which assert that resourceful behaviors arise out of responses to environmental constraints, by developing a model illustrating that entrepreneurs self-impose constraints on resource acquisition and deployment for differing reasons. Specifically, we introduce a novel conceptualization of 
frugality
 and differentiate it from self-control to develop a set of hypotheses that frugality predicts resource use behaviors based on long-held preferences (e.g., effectuation and bricolage) and self-control predicts resource use behaviors based on known end states or goals (e.g., causation and pre-commitments). After accumulating evidence of reliability and validity for a new measure of frugality contextualized for entrepreneurship research, the results support our self-regulatory theoretical framework. Our study contributes to research on resourcefulness by making multiple theoretical insights, and we outline numerous future research opportunities for applying the construct of frugality to explain entrepreneurial behavior.", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618308449,Organizational sponsorship and the economics of place: How regional urbanization and localization shape incubator outcomes,Alejandro=Amezcua: aamezcua@syr.edu; Tiago=Ratinho: t.ratinho@ieseg.fr,"Abstract
Organizational sponsorship impacts new venture emergence and survival prospects by shaping the relationship between new ventures and their surrounding environment. While extant literature offers an explanation as to why heterogeneity in the effectiveness of sponsorship emerges based on the sponsor's characteristics, current theorizing largely overlooks how sponsorship interacts with local 
economic conditions
. This study introduces insights from 
urban economics
 to extend organizational sponsorship theory by showing how different types of 
agglomeration economies
 affect the effectiveness of organizational sponsorship. We test our hypotheses with a comprehensive database that includes over 46,000 sponsored and non-sponsored firms in the years 1997–2007. Our results reveal organizational sponsorship delays new venture exit when urbanization levels are low, localization is low, and both urbanization and localization are high.
Executive Summary.
Organizational sponsorship (OS) is an institutional arrangement whereby private or public entities provide assistance to new firm ventures. Since young firms face low survival chances at birth, it is assumed that any assistance such firms receive is to their advantage. However, very little research supports this assumption (
Clayton et al., 2018
; 
Dutt et al., 2016
). It is in this context that we examine the impact of OS in different regional environments. Specifically, we look at the interplay between business incubation, a ubiquitous form of OS, urbanization, the city-scale of the region in which the firm is founded, and localization, the presence of same-industry firms in the region, in determining new venture survival. By exploring this interaction, we identify how the efficacy of OS varies in differing environmental circumstances. Additionally, it provides a better understanding of the specific OS mechanisms that are most likely to promote new venture survival depending on regional characteristics.
For the purposes of our study, we combine insights from OS and agglomeration literatures. Specifically, we look at the interplay between the bridging, buffering and curating functions of OS with the externalities that arise from urbanization and localization. We consider the regional characteristics that provide new ventures with positive agglomeration externalities of input sharing, quick and quality matching with resource providers, and knowledge 
spillovers
. Similarly, we also consider regional characteristics that give rise to negative externalities of rising costs and congestion. Thus, we identify urbanization and localization scenarios in which new ventures are most in need of buffering from competition, in the form of financial aid and subsidies, and scenarios where new ventures need to be bridged or curated with non-monetary resources such as 
accountants
, lawyers, or industry-specific suppliers and investors. That is, we identify founding environments in which OS functions are most valuable.
We test our hypothesis on a population of US business incubators operating between 1997 and 2007. To study the impact of OS at different levels of urbanization and localization, we compare the probability of exit by incubated new ventures with that of a control group of non-incubated new ventures in the same county. We find that incubators are most effective in improving the survival of new ventures when both localization and urbanization in the founding environment are low or when both are high.
By linking OS literature with agglomeration literature our study identifies the conditions under which OS is most effective and finds that it is most effective when mitigating the lows of resource-deprived environments or the highs of a hyper-competitive landscape. We also extend the theoretical link between these two streams of literature by identifying the critical role of the OS function of curating in a highly localized and urbanized environment.
Our study sheds new light on why OS is often met with varying levels of success in promoting new venture survival. We see that specific regional characteristics determine the type of OS mechanisms that are most beneficial. Thus, for instance, simply mimicking successful incubators in one region may not lead to success for incubators in other regions. Furthermore, we see that OS is counterproductive in regions with low urbanization and high localization. Together, these findings suggest that policy-makers need to consider the specific constraints faced by entrepreneurs in different regions before they seek to promote entrepreneurship through OS. It also stresses the need for entrepreneurs to do 
due diligence
 prior to joining an incubator.", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261830627X,Entrepreneurial passion diversity in new venture teams: An empirical examination of short- and long-term performance implications,Melissa S.=Cardon: mcardon@utk.edu; Eva=de Mol: e.de.mol@vu.nl; Bart=de Jong: Bart.deJong@acu.edu.au; Svetlana N.=Khapova: s.n.khapova@vu.nl; Tom=Elfring: Tom.Elfring@liverpool.ac.uk,"Abstract
Empirical evidence is mounting that passion is an important part of entrepreneurship, contributing to behavior and outcomes for entrepreneurs, employees, and ventures. Yet knowledge of the performance implications of passion within new venture teams is sorely lacking. We examine how both the average level of entrepreneurial passion and the diversity of passion within new venture teams contributes to venture performance in both the short- and long-term. We test our model with multi-source, multi-wave data collected from 107 new venture teams participating in an accelerator program. Our findings indicate that average team passion is not significantly related to performance, but passion diversity, particularly intensity separation, is negatively related to performance. These findings have important implications for the literature on passion, new venture teams, and group affective diversity.
Executive summary
While existing studies have substantially improved our understanding of entrepreneurial passion, its sources, and its subsequent impact, insight into this topic remains limited in at least three ways. First, most new ventures are founded and led by teams rather than individuals, yet existing studies predominantly focus on entrepreneurial passion at the individual rather than team level. Second, while there is a prevailing assumption in existing literature that entrepreneurial passion leads to beneficial outcomes consistent with longstanding work in psychology, there is emerging evidence in entrepreneurship that passion may not always be functional and that it can even be dysfunctional. Despite this, we have limited understanding of what types of passion or when or for whom it is dysfunctional. And third, extant work on entrepreneurial passion for individuals and within teams has focused on behavioral or self-report measures of performance (e.g. Cardon and Kirk, 2015; Santos & Cardon, 2019) as well as venture survival, rather than objective team or firm performance in the short- and long-term.
In this paper, we study the influence of team passion on new venture team performance. We draw on theory concerning entrepreneurial passion within venture teams (Cardon et al., 2017) that suggests that different aspects of entrepreneurial passion within teams shape team dynamics and venture outcomes. While generally, theories of passion suggest that entrepreneurial passion is positively related to team outcomes due to the positive emotions it brings about, we find that in teams, the relationships are more complex. While the average level of passion among team members is positively related to team performance when considered alone, this effect is not significant when passion diversity is also considered. Diversity of passion among individual team members has a negative relationship with team performance, including diversity in the level of passion team members experience (intensity separation), as well as diversity in the object of their passion (focus variety). These negatively affect team dynamics due to conflicting emotions and identities among team members associated with passion diversity. We examine these relationships on specific team performance outcomes including evaluation of the business idea in the short-term and venture performance five years after their participation in an accelerator.
The sample used in this study includes 107 
entrepreneurial teams
 that were part of an accelerator program in the Netherlands. Teams were evaluated on the quality of their business ideas at the end of the accelerator program and the amount of investment the team had received five years later. Our results provide no support for positive effects of average team passion on the quality of the business ideas and confirm the negative effects of passion intensity separation on the quality of the business idea and the negative effects of passion focus variety on later venture performance.
This paper makes several contributions. First, we expand the literature on passion in entrepreneurship, specifically adding to our understanding of passion within new venture teams. More specifically, we contribute to the growing body of evidence concerning potential dysfunctions of passion by uncovering a dysfunctional property of team passion diversity that uniquely manifests itself at the team level of analysis. We contribute to the literature on new venture teams by examining team composition in the form of passion diversity, and its relationship with team performance. Finally, our study extends work on the effects of entrepreneurial passion by looking at objective team performance outcomes in both the short- and long-term.
For entrepreneurs, our findings confirm the importance of affect and identity for new venture teams, and specifically our findings indicate that there is a dark side to team passion. While passion is generally positioned as a positive phenomenon, we highlight the negative outcomes that passion can have in the team context. Diversity in the amount of passion team members experience can diminish the quality of the business ideas the team is able to generate in the short-term, while diversity in the focus of team members' passion can diminish the firm's long-term performance. For investors and accelerator communities this research validates the importance of considering entrepreneurial team composition and specifically entrepreneurial passion levels and domains when investing in teams or when supporting venture building.", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618307444,"Short leash or long leash? Parenting style, initial strategic clarity, and the development of venture learning proficiency",Donald F.=Kuratko: dkuratko@indiana.edu; Dean A.=Shepherd: dshephe1@nd.edu; Jeffrey G.=Covin: covin@indiana.edu; Robert P.=Garrett: robert.garrett@louisville.edu,"Abstract
Corporate venture development suggests that internal corporate ventures (ICVs) must become proficient learners if they are to cope successfully with the uncertainty inherent to their operations. Accordingly, the parent corporations in which ICVs operate are challenged to identify and enact appropriate parenting styles that foster their ICVs' learning proficiency. The current research of 145 ICVs in 72 corporations builds on parenting theory to theorize that ICVs demonstrate the greatest learning proficiency when corporate parents give them a “leash length”—indicated via observed levels of top management support and operational decision-making autonomy—depending on the degree of strategic clarity under which the ICV was founded.", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618305081,A total eclipse of the heart: compensation strategies in entrepreneurial nonprofits,Kostas=Alexiou: kalexiou@ut.edu; Abhisekh=Ghosh Moulick: abhisekh@ou.edu; Elena=Dowin Kennedy: ekennedy9@elon.edu; Denise Linda=Parris: deniselparris@ou.edu,"Abstract
We examine how shifting resource dependencies influence compensation strategy during commercial transitions within entrepreneurial nonprofits. Analyzing a longitudinal sample of 4732 organizations, we show how compensation strategies shift non-linearly as nonprofits transition from contributed resource dependence to market-based resource dependence. Dynamic quadratic models unveil a dual threshold of commercialization concerning this transition. Nonprofits at moderate stages of commercialization contend with competing dependencies from both contributed and market-based sources, resulting in a decrease in compensation spending and an increase in part-time employment. At higher stages, contributed resource dependence is eclipsed by market-based dependence, reflected in increasing compensation spending and full-time employment.", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618307055,"Founder passion, neural engagement and informal investor interest in startup pitches: An fMRI study",Scott=Shane: sas46@case.edu; David=Clingingsmith: david.clingingsmith@case.edu; Moran=Cerf: moran@morancerf.com,"Abstract
We explore how variation in entrepreneurs' displayed passion affects informal investor interest in start-up ventures by examining neural responses to entrepreneurs' pitches using functional Magnetic Resonance Imaging (fMRI). We find that founders displaying high passion increase investor neural engagement by 39% and investor interest in the venture by 26% over those displaying low passion. A one 
standard deviation
 increase in neural engagement is associated with an 8% percent increase in investors' interest in investing in a start-up company relative to the mean. Moreover, our findings indicate that neural engagement may account for some of the effect of founder passion on investor interest. Our study has implications for both research on, and the practice of, entrepreneurship.", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301168,How to circumvent adversity? Refugee-entrepreneurs' resilience in the face of substantial and persistent adversity,Joakim=Wincent: joakim.wincent@hanken.fi; Dean A.=Shepherd: Dshepherd@indiana.edu; Fouad Philippe=Saade: philippe.saade@hanken.fi,"Executive summary
People face adverse events in a variety of forms. Some individuals are resilient to adverse events in that they are able to maintain positive functioning while others experience considerable disruption. In explaining heterogeneity in resilience, research has emphasized people's resource endowments and pre-adversity organizing 
prior
 to the adverse events as well as people's cognitive and behavioral responses to such events. Therefore, for most resilience studies, adversity is an event. Although it is critically important to understand resilience to these short- to medium-term adverse events, there is a need to understand resilience over an extended period. In this regard, we focus on Palestine refugees who were born in refugee camps and as adults have known nothing other than being a refugee.
When it comes to substantial and persistent adversity, 
entrepreneurial action
 likely plays a central role in resilience to such adversity. To explore these relationships, we conducted an extensive data-collection effort over 15 months on refugee entrepreneurs (in refugee camps and not in camps), including 110 interviews. We find the importance of direct, indirect, and recursive relationships among actions (i.e., 
entrepreneurial action
 and integration activities), multiple identities, and resilience outcomes under conditions of substantial and persistent adversity. Furthermore, we find important differences between refugee entrepreneurs who live in refugee camps and those who live outside these camps—differences in affiliation, language use, and social capital development—which enable those refugee entrepreneurs living outside the refugee camps to achieve resilience outcomes not accessible to those living inside the camps.
Overall, this study makes a number of contributions to the entrepreneurship literature. First, research has investigated resilience in terms of resources, endowments, and capabilities before an adverse event. The implicit assumptions in this research are that capabilities matter and that adversity has a beginning and subsides over time. In this study, we focus on resilience outcomes in the context of refugees facing substantial adversity over a substantial period and extend the capability argument of resilience in the following ways: (1) the “social” capability for resilience, not as an endowment but created through activities that build a social basis for resilience outcomes, (2) 
social integration
 activities are initiated and facilitated by engaging in entrepreneurial action with non-similar others, and (3) resilience outcomes help individuals both engage in integration activities and build a social capability of resilience. Therefore, in the context of substantial and persistent adversity, refugee entrepreneurs need to act in order to build (rather than simply deploy) their social capability for resilience outcomes.
Second, resilience has been explored as either a process 
or
 as an outcome. In this study, we find that resilience outcomes are both a consequence and an antecedent of entrepreneurial action—a mutually dependent relationship. Specifically, we find the dimensions of resilience outcomes to include proactive problem solving, moral gains as a broader purpose in life, self-reliance, realistic optimism, and multiple sources of belonging. What is interesting is that these outcomes are also important inputs to entrepreneurial action and the resilience process.
Finally, there has been an important stream of research on the role of identity in recovery from adversity. We find that refugee entrepreneurs' actions provide a basis for changing the mix of their multiple identities. Therefore, we enrich the entrepreneurship identity literature through the insight that in this persistently adverse context, the relationship between entrepreneurial action and identity is not one way and static but bidirectional and dynamic. Furthermore, over and above refugee entrepreneurs' prosocial motivation of compassion, we find a new form of prosocial motivation for entrepreneurial action—the motivation to promote solidarity: “You are not alone; we are in this together as part of a broader purpose in life.”", July 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618302908,Poverty and the varieties of entrepreneurship in the pursuit of prosperity,Jonathan=Kimmitt: jonathan.kimmitt@newcastle.ac.uk; Pablo=Muñoz: pmunoz@liverpool.ac.uk; Robert=Newbery: Robert.Newbery@newcastle.ac.uk,"Abstract
In this paper, we revisit the entrepreneurship and poverty relationship under a eudaimonic perspective that brings together conversion factors, and future prosperity expectations. Based on an fsQCA of changes in life circumstances of 166 farm households in rural Kenya, we explore how different combinations of conversion factors enable distinct forms of entrepreneuring in the pursuit of prosperity. Results show that strong entrepreneurship-enabled future prosperity expectations result from three combinations of enabling conversion factors shaping up three varieties of entrepreneurial endeavors: 
family
-
frugal
, 
individual
-
market
, and 
family
-
inwards
, which show a much more diverse and counterintuitive reality. Our research contributes to literature by revealing and theorizing on a split picture portraying the many ways in which farmers, acting as everyday entrepreneurs, exploit real opportunities in seemingly identical impoverished communities. It also reveals a central disconnect between entrepreneurship, life-satisfaction and financial improvements when assessed against expectations of future prosperity. In doing so, this paper responds to calls for a better understanding of the processes whereby entrepreneurship can distinctively improve current and future life circumstances, and the many ways in which this may happen.", July 2020,"Poverty alleviation, future prosperity expectations, conversion factors, fsQCA, Human development, Farming entrepreneurship, Resource-constrained contexts, Kenya",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301594,Editorial: Enhancing the exploration and communication of quantitative entrepreneurship research,Karl=Wennberg: karl.wennberg@liu.se; Brian S.=Anderson: andersonbri@umkc.edu,"Abstract
The purpose of this editorial is to discuss ways to enhance exploratory 
quantitative studies
 in entrepreneurship. We use examples from entrepreneurship research and other scientific fields to illustrate the advantages of graphical data display for both exploratory purposes and post hoc tests. We provide suggestions for authors, reviewers, and editors on ways to enhance the transparency, accuracy, and pedagogical presentation of quantitative data in papers with the explicit purpose of illuminating emerging and important entrepreneurship phenomena. Our hope is that we spark a conversation among entrepreneurship scholars about the state of our empirical work and the possibilities that lie ahead to enhance exploratory entrepreneurship research.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617308741,Entrepreneurship as a vocational choice in contested entrepreneurship communities: The role of entrepreneurs' justification strategies,Sara=Winterstorm Värlander: sara.winterstorm.varlander@hhs.se,"Abstract
Research on the vocational decision to become an entrepreneur highlights how culture justifies such decisions when entrepreneurs align with the dominant cultural norms. Less is known about such justification when entrepreneurship is seen as less culturally appropriate. This 
qualitative study
 explores how entrepreneurs in Santiago, Chile and Nairobi, Kenya use strategies that comply, combine, and defy frames to justify vocational choices. Our framework sheds new light on how entrepreneurs act as purposeful cultural agents and use justification strategies to navigate constraining societal frames.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617309400,How entrepreneurial intentions influence entrepreneurial career choices: The moderating influence of social context,Johan=Wiklund: jwiklund@syr.edu; Azzurra=Meoli: azzurra.meoli@unibo.it; Riccardo=Fini: riccardo.fini@unibo.it; Maurizio=Sobrero: maurizio.sobrero@unibo.it,"Abstract
In this paper, we build on 
social cognitive career theory
 to examine the relation between entrepreneurial intention and new venture creation (i.e., the entrepreneurial career choice). We model how contextual influences at different levels may favor or inhibit the translation of entrepreneurial intention into new venture creation. Using unique longitudinal data from almost the entire population of Italian university graduates, we are able to assess how the immediate (i.e., the influence of relevant others) and larger context (i.e., organizational and environmental influences) affect new venture creation. Our research contributes to the emerging literature of the intention–behavior link in entrepreneurship.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617309072,Are entrepreneurs special? Evidence from board appointments,Olubunmi=Faleye: o.faleye@northeastern.edu; Wilson=Kung: wilson.kung@unsw.edu.au; Jerry T.=Parwada: j.parwada@unsw.edu.au; Gloria Y.=Tian: gloria.tian@uleth.ca,"Abstract
As shown in previous studies, founder-led firms perform better than those run by professional managers. Does this reflect the special relation of founders to their firms or do entrepreneurs possess attributes and experiences that are valuable even at firms not founded by them? Drawing on the resource-based view of the firm, we study this question by evaluating the effect of entrepreneurs who serve as outside directors of other firms. We find that the stock market reacts positively to appointments of outside entrepreneur directors and that firms with these directors have higher long-term value as measured by Tobin's 
q
. Entrepreneur directors are also associated with increased R&D investment and higher sales growth, and their effect on firm value is larger among firms in R&D-intensive and competitive 
industries
. We conclude that outside entrepreneur directors enhance firm value through their propensity to take risk and their ability to anticipate demand patterns and create new markets.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617309448,Does negative feedback impact new ventures' organizational identity? The role of founding teams' human capital and feedback source,Holger=Patzelt: patzelt@tum.de; Anne=Domurath: adomurath@wlu.ca; Andreas=Liebl: liebl@unternehmertum.de,"Abstract
Although a strong organizational identity (OI) is important for venture success, the impact of negative feedback on a new venture's OI is poorly understood. Drawing on 
human capital theory
 we argue that founding teams with more founding and 
industry
 experience can more effectively defend OI after negative feedback. Using literature on intra-group bias we further theorize that these benefits of founding and 
industry
 experience are more pronounced when feedback emerges from sources external rather than internal to the venture. A multi-period research design and data on 1528 survey responses from 598 members of 81 ventures support our model.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902616300477,The double impact of institutions: Institutional spillovers and entrepreneurial activity in the solar photovoltaic industry,Joern=Hoppmann: jhoppmann@ethz.ch,"Abstract
We investigate whether and when institutional 
spillovers
, i.e., institutional effects across national borders, drive domestic 
entrepreneurial activity
. Drawing on data on venture capital (VC) investments in the solar photovoltaic 
industry
, we provide evidence for institutional 
spillovers
 and demonstrate that they are moderated by the presence of domestic institutions and the institutional distance between domestic and 
foreign policy
 schemes. By showing that domestic institutions not only influence 
entrepreneurial activity
 directly, but also facilitate spillovers, our findings demonstrate a double impact of institutions. Overall, we contribute to the literatures on the drivers of VC investments, institutions and entrepreneurship, and environmental entrepreneurship.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617301829,Exploring the multi-level processes of legitimacy in transnational social enterprises,Benson=Honig: bhonig@mcmaster.ca; Daniela=Bolzani: daniela.bolzani@unicatt.it; Selenia=Marabello: selenia.marabello@unibo.it,"Abstract
Transnational entrepreneurship has emerged as a form of migrants' participation in the social, economic, and political lives of both their countries of origin and of residence. Leveraging increasing evidence about migrants' involvment in transnational social 
enterprises
, we examine the multi-level processes through which organizational legitimacy is molded by transnational entrepreneurs to reflect country-level institutional settings, and how organizational-level legitimacy affects entrepreneurs' social status. We longitudinally examine the multi-level processes of 
legitimation
 in a transnational social enterprise operated by Ghanaian migrants across Italy and Ghana. We analyze secondary and ethnographic data for two years, observing how transnational social 
enterprises
 harvest moral and pragmatic legitimacy from the institutional contexts in which they operate. We study how entrepreneurs construe their social status through pragmatic legitimacy obtained from their transnational ventures, and their institutional environments inspired by micro- and 
meso
 legitimacy reconfigurations. We discuss theoretical implications for social and transnational entrepreneurship and practical contributions for policy-making.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618300211,Venture capitalists at work: A diff-in-diff approach at late-stages of the screening process,Raffaello=Bronzini: raffaello.bronzini@bancaditalia.it,"Abstract
In this paper we use a new methodology aimed at identifying only the venture capitalists (VC) treatment effect: we compare a representative sample of firms financed by private VC in the period 2004–2014 with a sample of firms rejected by VC at the very late-stages of the screening process. These firms narrowly lost the contest and are hence very similar, 
before VC financing
, to the VC backed firms; self-selection is specifically taken into account. In line with previous results, Italian startups financed by VC reach a larger size and become more innovative than other startups. On the contrary, sales growth is similar and profitability is worse than firms in the control group. VC-backed companies experience larger rise in labor costs, while the commercialization of their innovative projects takes longer: this explains their worse profitability and the deterioration in their credit score. Both effects tend to disappear after four years from VC financing, when sales increase for VC-backed firms at the same pace as for the control group. Unlike other studies, no differences are detected for the survivorship rates of VC-backed firms in Italy. We also provide new evidence on the impact of VC on firms’ financial structures: VC-backed firms show a much larger increase in equity; this rise is however only half the increase in total assets that is hence not only explained by the injection of VC equity. Another result in this direction is that the effects on firms’ size and innovation hold when we restrict the control group to firms that also increase their equity from investors different from VC; this suggests that VC effects on size and innovation might also be linked to their managerial expertise and network connections. Finally, in line with previous evidence, the effects found in the paper are exclusively driven by independent VC investors compared with captive VC.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617309527,Weaving network theory into effectuation: A multi-level reconceptualization of effectual dynamics,Nicole=Coviello: ncoviello@wlu.ca,"Abstract
This paper positions effectuation as a network-driving and network dependent phenomenon and suggests that understanding networks and network processes is essential to understanding the dynamics of effectuation. We argue that the implementation of effectuation is influenced by the nodal, relational, and structural characteristics of pre-existing and emerging networks, and by the processes through which these networks come about. We use these arguments to develop a multi-level, multi-theoretical reconceptualization of effectuation that provides for distributed agency and collective cognition of network members. We allow for the simultaneous and interactional use of effectual and causal logics, as well as the co-construction of knowledge, identity, and social capital within and across network levels. Our model also addresses changing uncertainty as opportunities develop, nuances of effectual interactions, and evolving market dynamics. Our propositions and reflections offer directions for further studies at the intersection of network and effectuation research.
Executive summary
There is little doubt that effectuation is reshaping how we think about entrepreneurial cognition and behavior. A core argument is that under conditions of uncertainty, entrepreneurs can co-create opportunities by collaborating with other willful agents. This moves us away from classical views of entrepreneurship and positions effectuation as a network-driving and network-dependent phenomenon. Yet, recent debate highlights that effectuation research has paid insufficient attention to the network of external parties involved. As a result, although the extant model of effectuation recognizes the importance of networks, our understanding of the relationship between effectual logic and entrepreneurial networks is far from complete.
Several theoretically important and practically relevant questions arise from this knowledge gap. For example if we think about network development, how are potential stakeholders brought to mind and persuaded to commit if end-points and stakeholder preferences are both unknowable? What are the characteristics (i.e. structure, content and governance) of the networks that emerge through these commitments? Reciprocally, how do the characteristics of the emerging network influence effectual processes and outcomes?
In this paper, we begin to address this line of questioning by considering effectuation not only at the level of the individual but also through lenses reflective of the three levels of analysis commonly adopted in network research: i) dyadic relationships, ii) the entrepreneurial network, and iii) the market more generally. While we attend to pre-existing networks (the constitution of which is likely to affect the probability of adopting effectual logic), our focus is on linking the individual and emerging networks across these levels.
At the level of the individual, we break from prior effectuation research and ascribe new and influential roles to entrepreneurial ideas and instrumental 
mindsets
 in focusing an entrepreneur's attention on particular relationships (i.e. the cognitive activation of a cohesive network involving interested and persuadable individuals). At the level of the dyad, we suggest the very nature of interactions between actors can influence individual choice of logic. We specify that stakeholders will expect signs of process legitimacy (e.g. cognitive flexibility on the part of the entrepreneur) before making effectual commitments. We also move away from assumptions about 
altruistic behavior
 to suggest that power and influence will accrue to stakeholders whose resources are at risk and/or perceived by others to resolve uncertainty. At the level of the entrepreneurial network, we link effectuation to a 
brokerage
 orientation (
tertius iungens)
 that enhances inclusiveness surrounding means and collective cognition. Moreover, we move beyond the narrow view of facilitating and constraining factors portrayed in the effectuation literature to argue that (e.g.) i) with respect to network content, resource specificity will shape possible futures; ii) with respect to governance, trust, supported by social mechanisms will predominate; and, iii) with respect to structure, specific network characteristics will be more supportive of certain aspects of effectuation than others (e.g. cohesive networks are more supportive of collaboration, but may limit the flexibility needed to embrace contingencies). At the market level, we posit that on the one hand, institutions will shape effectual processes. On the other hand, effectual processes are more likely than causal processes to create new institutions and/or supplant existing institutions.
Overall, our study contributes to the understanding of both effectuation and networks by offering a multi-level, multi-theoretical re-conceptualization of the dynamics of effectuation. Our arguments should spur research in at least three interdependent areas: i) uncertainty and individual cognition; ii) network processes surrounding interactions and commitments; and iii) the contingent effects of network characteristics on effectuation. For practitioners, our insights should help shape thoughts about i) who to interact with in the face of uncertainty; ii) what stories to tell and how to deal with image management; iii) what to expect during negotiations; iv) how to broker relationships to enhance the ‘co’ in ‘co-creation’; and moreover, v) what network characteristics might facilitate or constrain their efforts.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617308984,Surviving the emotional rollercoaster called entrepreneurship: The role of emotion regulation,Bart=Clarysse: bclarysse@ethz.ch; Robin=De Cock: robin.decock@ams.ac.be; Lien=Denoo: L.C.I.Denoo@UvT.nl,"Abstract
The entrepreneurial journey is often experienced as an emotional rollercoaster, but we know very little about how entrepreneurs can ride it most effectively to increase their ventures' chances of survival. We investigate how entrepreneurs' habitual use of 
cognitive reappraisal
 and expressive suppression – two well-established types of emotion regulation – impact on the likelihood of their venture surviving. Drawing on a sample of 183 technology ventures, we find that both regulation types are generally associated with a lower survival likelihood, but that these effects depend on the venture's performance. Our study contributes to the literatures on emotions and new venture survival in entrepreneurship and to the emotion regulation literature.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617303567,Bellwether and the herd? Unpacking the u-shaped relationship between prior funding and subsequent contributions in reward-based crowdfunding,Arvin=Sahaym: arvin@wsu.edu; C.S. Richard=Chan: Richard.Chan@stonybrook.edu; Annaleena=Parhankangas: Annaleena.Parhankangas@sdstate.edu; Pyayt=Oo: oo1p@cmich.edu,"Abstract
Building on the insights from 
observational learning
 and other social influence research, this study challenges the existing literature that proposes a linear relationship between prior funding and subsequent contributions in the crowdfunding setting. Instead, we propose a U-shaped relationship, illustrating a 
negative relationship
 between prior funding and subsequent contributions when funding amounts are small and this relationship becomes positive when prior funding amounts are large. Consistent with the rational herding perspective, we assume that individuals do not mindlessly mimic one others' behaviors, but incorporate quality signals into their decision-making. Signals indicating a high quality project such as video quality, as well as the preparedness and passion of the entrepreneur enhance this U-shaped relationship whereas indicators of situational urgency weaken this relationship. Based on a sample of 11,019 daily observations of 333 Kickstarter projects, we find general support for our hypotheses. Our post hoc experiment further supports the mechanisms underlying the U-shaped relationship. This paper extends our understanding of the relationship between past actions and subsequent behavior, and contributes to the literatures of 
observational learning
, crowdfunding, and visual information.
Executive summary
We challenge the extant literature that has proposed, but inconsistently documented, a positive effect of prior funding on subsequent crowdfunding contributions. We argue that such inconsistency is due to the lack of integration of insights from other social influence research, such as 
observational learning
, threshold models, and 
bystander effects
. This research has been limited when postulating that crowdfunding backers simply imitate others' actions in order to mitigate uncertainty producing a linear effect, yet such an effect depends on the intensity of others' actions and may be curvilinear. This research overlooks the fact that backers do not merely passively imitate others' behaviors, but incorporate quality signals sent by entrepreneurs to make such decisions. Thus, it is important to account for potential moderators that may influence the complex relationship between prior funding and subsequent contributions.
Based on 
observational learning
 research and related models, accrued prior funding may be perceived differently by potential backers: individuals may view accrued funding as a sign of a decreased funding need on the part of a campaign's creators, because others are already backing the campaign or, alternatively, they may see it as a cue of high 
product quality
. These conflicting effects may lead to a U-shaped relationship between prior funding and subsequent contributions at a collective level. At low funding levels, prior funding may be negatively associated with subsequent contributions because such levels indicate there is already support, but that the campaign may not be of high quality. At medium levels, prior funding may have no effect on contributions, aside from halfhearted interest of other backers. At high levels, prior funding may be positively related to subsequent contributions as this sends a robust cue of project quality and convinces prospective donors to contribute. Further, we derive a U-shaped relationship which may be moderated by visual media-based quality signals and situational urgency.
To test these hypotheses, we conducted two studies. One was a 
field study
 of 333 Kickstarter projects, with 11,019 daily observations of crowdfunding activities from mid-February 2013 through mid-April 2013. We used the Kicktraq website to track Kickstarter projects and recruited 390 participants via 
Amazon
 
Mechanical Turk
 (MTurk) to evaluate the video pitches on Kickstarter. Our results suggest a 
negative relationship
 between prior funding and subsequent contributions when funding amounts are small. This relationship becomes positive when prior funding amounts are large. Thus, we find a U-shaped relationship between prior funding and subsequent contributions, with an 
inflection point
 when prior funding amounts reach between 72% and 80% of the funding goal. This is strengthened in the presence of visual media-based quality signals, such as video quality, as well as the preparedness and passion of the entrepreneur. However, indicators of situational urgency may weaken this U-shaped relationship.
We followed up with a post hoc experiment to document the two mechanisms by which prior funding influence subsequent contributions. We found that increases in the prior funding amount increased perceived 
product quality
 but decreased perceived urgency. These perceptions were found to jointly influence participants' proposed pledged amounts, supporting an explanation of a complex relationship between prior funding and subsequent contributions.
This study is among the first to offer a more complete picture of the relationship between past actions and subsequent behavior under market and institutional constraints (i.e., when market actors observe the censored behaviors of other actors on crowdfunding platforms) and contributes to the literatures of 
observational learning
, crowdfunding, and visual information.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617309850,Strategic entrepreneurship's dynamic tensions: Converging (diverging) effects of experience and networks on market entry timing and entrant performance,Eric Yanfei=Zhao: ericzhao@indiana.edu; Masakazu=Ishihara: mishihar@stern.nyu.edu; P. Devereaux=Jennings: dev.jennings@ualberta.ca,"Abstract
In this paper, we return to the roots of strategic entrepreneurship research by examining the dynamic tension between opportunity-seeking and advantage-seeking activities and by testing key resources that affect both activities. More specifically, we identify the empirical manifestations of the two activities—market entry timing decisions and entrant performance—and examine the degree to which the type of resources (in particular, experience and networks) that enable firms to enter a new market space early converge with (or diverge from) the type of resources that enhance entrant performance. Through analysis of 78 new market spaces and the associated 6544 entrant games in the U.S. console video game 
industry
 between 1995 and 2012, we find that while some resources—particularly relevant experience—have convergent impacts on entry timing and entrant performance, the impacts of other resources—first-order and second-order embeddedness—on these two outcomes diverge. We demonstrate that this tension in terms of resource impact on the two aspects of strategic entrepreneurship persists as the markets evolve.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261830452X,What signals matter for social startups? It depends: The influence of gender role congruity on social impact accelerator selection decisions,Scott L.=Newbert: scott.newbert@baruch.cuny.edu; Romi=Kher: romi.kher@baruch.cuny.edu; Shu=Yang: shu.yang@baruch.cuny.edu,"Abstract
Social impact accelerators (SIAs) seek to select startups with the potential to generate financial returns and social impact. Through the lenses of signaling theory and gender role 
congruity theory
, we examine 2324 social startups that applied to 123 SIAs globally in 2016 and 2017 and find that SIAs are more likely to accept startups that signal their economic and social credibility. Moreover, while we find that the influence of these signals is strongest when they are congruent with the stereotypes associated with the lead founder's gender, men seem to experience better outcomes from gender incongruity than women.", March 2020,"Gender role congruity theory, Signaling theory, Social entrepreneurship, Social impact accelerators, Social startups",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617308492,Sounds novel or familiar? Entrepreneurs' framing strategy in the venture capital market,Lingling=Pan: lpan@katz.pitt.edu; Xiumei=Li: xl345@drexel.edu; Jianhong=Chen: jianhong.chen@unh.edu; Tianxu=Chen: chen36@pdx.edu,"Abstract
This study offers a theoretical perspective from which to examine entrepreneurial ventures' linguistic strategies. Drawing on the framing perspective, we introduce two concepts—novelty frames and familiarity frames—and examine how the use of these linguistic frames may influence entrepreneurial ventures' ability to obtain funding from venture capitalists (VCs) in different 
industry
 contexts. Based on a sample of 2883 U.S. information technology (IT) ventures and 5849 investment events from 2003 to 2014, we show that novelty and familiarity frames individually and interactively shape the amount of funding. We also found that 
industry
 capital intensity enhances the positive effects of familiarity frames. These findings highlight the role of entrepreneurial ventures' linguistic frames in shaping their funding opportunities.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617305281,Close your eyes or open your mind: Effects of sleep and mindfulness exercises on entrepreneurs' exhaustion,Melissa S.=Cardon: mcardon@utk.edu; Charles Y.=Murnieks: charles.murnieks@oregonstate.edu; Jonathan D.=Arthurs: jonathan.arthurs@oregonstate.edu; Nusrat=Farah: farahn@oregonstate.edu; Jason=Stornelli: jason.stornelli@oregonstate.edu; J.=Michael Haynie: jmhaynie@syr.edu,"Abstract
Exhaustion is a prominent problem in entrepreneurship because it inhibits cognitive functioning, opportunity identification and evaluation, decision-making, and perseverance. We examine the possible benefits of sleep and 
mindfulness
 exercises in reducing the exhaustion experienced by entrepreneurs in the course of launching and growing ventures. Across two studies, we find that both sleep and 
mindfulness
 exercises provide avenues for entrepreneurs to combat exhaustion. More interestingly, we find that these two factors compensate for one another; as the usage of one increases, the efficacy of the other decreases. This has important implications for reducing exhaustion and improving cognitive functioning and motivational energy among entrepreneurs.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619300916,Using fuzzy-set qualitative comparative analysis for a finer-grained understanding of entrepreneurship,Dean A.=Shepherd: dshephe1@nd.edu; Evan J.=Douglas: e.douglas@griffith.edu.au; Catherine=Prentice: cathyjournalarticles@gmail.com,"Abstract
Entrepreneurship theory has largely been developed and tested using symmetrical correlational methods, effectively describing the sample-average respondent and subsuming individual differences. Such methods necessarily limit investigation of asymmetries that are evident in entrepreneurship, and provide only a single explanation that belies the multiple pathways to entrepreneurship observed in practice. This paper employs a case-based approach—fuzzy-set Qualitative Comparative Analysis (fsQCA)—to identify configurations of antecedent attributes of individuals in groups within samples, thereby revealing asymmetries and multiple entrepreneurial pathways that are otherwise hidden in the data. We explain the application of fsQCA to reveal these common issues in entrepreneurship; demonstrate how fsQCA complements correlational methods and offers finer-grained understanding of individual entrepreneurial behavior; and offer a comprehensive research agenda to build new 
entrepreneurship theory
.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617308790,The financing of alliance entrepreneurship,Jieying=Hong: hong@essec.edu,"Abstract
It is popular nowadays for entrepreneurial firms to advance their entrepreneurship outside their boundaries through alliances. This paper studies how the financing of entrepreneurship changes in 
strategic alliances
. We model a financially constrained entrepreneur and a deep-pocket incumbent developing an innovative product through a strategic alliance, which generates externalities on the incumbent. We find that i) in contrast to traditional theories, the entrepreneur's financial constraint can be tightened by an increase in his endowment; ii) an outside investor is introduced as a third party to deal with the free-riding agency problem; and iii) the externalities have a significant effect on the design of financial claims in the alliance contract, and the incentive-compatible financial instruments are consistent with empirical observations.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618304488,Broadening versus reinforcing investor portfolios: Social structure and the search for venture capital investors,Pengfei=Wang: Pengfei.wang@bi.no,"Abstract
This paper highlights the venture capital investor (VC) portfolios of startups, and explores how the portfolios evolve. We emphasize the important trade-off between broadening and reinforcing VC portfolios (i.e., expanding to new VCs versus relying on existing VCs). This is because, to startups, new and existing VCs generate very different opportunities and constraints. Focusing on the social structure of existing VCs, we argue that startups are more likely to opt for new VCs when the internal networks of existing VCs are denser, when the external networks of existing VCs are smaller, and when the status of existing VCs is lower. Additionally, we not only focus on 
whether
 new VCs are on board, but also pay attention to 
which
 new VCs are introduced, by analyzing the 
ex-ante
 
embeddedness
 between existing and newly-introduced VCs. We stress that when new VCs are highly embedded with existing VCs, their involvement makes only a limited contribution to broadening a startup's portfolio and network. We test the hypotheses using a sample of VC financing rounds in the U.S. and find broad support.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261730232X,"Fueling the fire: Examining identity centrality, affective interpersonal commitment and gender as drivers of entrepreneurial passion",Melissa S.=Cardon: mcardon@utk.edu; Charles Y.=Murnieks: charles.murnieks@oregonstate.edu; J.=Michael Haynie: jmhaynie@syr.edu,"Abstract
Research on passion is burgeoning in the entrepreneurial literature, yet we still know little about what factors drive entrepreneurial passion. Recognizing the socially embedded nature of entrepreneurship, we examine identity-related social forces that may fuel the fire of entrepreneurial passion. Employing a lagged design that controls for known antecedents, we find different pathways driving harmonious versus obsessive entrepreneurial passion. We find that harmonious entrepreneurial passion is fueled by entrepreneurial identity centrality whereas obsessive entrepreneurial passion is fueled by affective interpersonal commitment. Interestingly, gender moderates both these relationships.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618300910,Domestic versus foreign listing: Does a CEO's educational experience matter?,Xiaoou=Bai: xiaoou.bai@utdallas.edu,"Abstract
Where to list an initial public offering (IPO) is a critical decision for an entrepreneurial firm. Our study investigates IPO location choice between home country and foreign country by examining a sample consisting of the entire population of 1479 Chinese private issuers during the period from 2005 to 2014. We enrich upper echelons theory by bringing in the insights of imprinting theory. Our results indicate that the sources of imprint − prestigious domestic education and foreign education − influence CEOs' preference for an IPO location. More specifically, CEOs with prestigious domestic degrees tend to list their firms in China whereas CEOs with foreign degrees tend to list outside China. Given that the imprinting effects of education have a lasting influence on CEOs, despite subsequent environmental changes, long tenures allow such effects to be imparted to other top management team members. Another finding is that when the CEOs are also the founders, there are two separate imprinting effects.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617305001,How optimal distinctiveness affects new ventures' failure risk: A contingency perspective,Jan=Goldenstein: jan.goldenstein@uni-jena.de; Michael=Hunoldt: michael.hunoldt@uni-jena.de; Simon=Oertel: simon.oertel@uni-jena.de,"Abstract
In this article, we apply the concept of optimal distinctiveness to test whether category spanning has a nonlinear effect on new ventures' risk to fail. We argue that by being optimally distinct, i.e., by attaining a level of category spanning that allows new ventures to benefit from balancing the competing needs of conformity with and differentiation from competitors, new ventures can improve their survival chances. In addition, we argue that the relevance of optimal distinctiveness varies with a venture's age and a category's density. We tested our hypotheses using data from 1668 metal bands that were founded in the United Kingdom between 1967 and 2005. The results indicate that optimal distinctiveness is relevant to new ventures' failure risk. Moreover, we show that venture age attenuates the relevance of optimal distinctiveness, whereas category density strengthens that factor's relevance.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618301071,Normalizing vs. analyzing: Drawing the lessons from failure to enhance firm innovativeness,Erwin=Danneels: edanneels@usf.edu; Alex=Vestal: vestala@uncw.edu,"Executive summary
The popular business press and academic articles have promoted the virtues of failure, particularly in the pursuit of innovation. Surprisingly, there has been very little systematic empirical study to support this belief. This article distinguishes two organizational approaches to failure: normalizing it (tolerating failure as a necessary part of the innovation process) and analyzing it (purposeful attempts to convert failure experiences into knowledge). A 
longitudinal study
 of 106 U.S. manufacturing firms indeed finds that mere tolerance for failure has no effect on firm product innovativeness. In contrast, firms that make deliberate efforts to analyze past failures introduce more innovative new products. Further, this effect is contingent on a climate of constructive conflict within the firm. Hence, to foster firm innovativeness, organization members need to extract lessons from failure, and such analysis must take place in a climate of constructive conflict that enables open and honest discussion.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617307760,Franchise management capabilities and franchisor performance under alternative franchise ownership strategies,William E.=Gillis: gillis@southalabama.edu; James G.=Combs: James.Combs@ucf.edu; Xiaoli=Yin: Xiaoli.Yin@baruch.cuny.edu,"Abstract
Franchising is a key entrepreneurial growth strategy, but a well-known downside is franchisee free-riding. Drawing upon alliance capabilities research, we describe 
franchise management capabilities
 and suggest that they are one way franchisors reduce free-riding and thus enhance performance. We also submit that these capabilities are especially helpful for “plural form” franchisors who own outlets in parallel with franchisees. Using a sample of 229 franchisors, we show that franchise management capabilities relate positively to franchisor performance among plural form franchisors. For “turnkey” franchisors who franchise all, or almost all, outlets these capabilities relate indirectly to performance through lower opportunism and improved brand reputation. Franchise management capability is therefore an important new theoretical construct linking franchising to franchisor performance.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617304639,The CAGE around cyberspace? How digital innovations internationalize in a virtual world,Noman Ahmed=Shaheer: noman.shaheer@grad.moore.sc.edu,"Abstract
This paper analyzes some salient factors affecting the 
internationalization
 speed of 
digital innovations
 by tracking international penetrations of 127 apps at Apple's app store. Although apps are globally available via online platforms, their international penetration is still subject to cultural, administrative, geographic, and economic (CAGE) distances that act as user adoption barriers to impede app 
internationalization
. App developers may overcome these barriers by employing the demand-side strategies of engaging users in value co-creation. We contribute to an improved understanding of 
internationalization
 process in a digital context and also extend demand-side perspective to inform international entrepreneurship research.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618303434,Sleep and entrepreneurs' abilities to imagine and form initial beliefs about new venture ideas,J.=Jeffrey Gish: jgish@ucf.edu; Denis A.=Grégoire: denis.gregoire@hec.ca; David T.=Wagner: dwagner@uoregon.edu; Christopher M.=Barnes: chris24b@uw.edu,"Abstract
In spite of enthusiastic encouragements, theories of entrepreneurship still poorly explain the influence of physiological resources and dynamics on entrepreneurs' abilities to perform cognitive tasks known to enable 
entrepreneurial action
. To advance research in this area, we develop and test new theoretical notions about sleep's effects on entrepreneurs' abilities to imagine promising new venture ideas, and to form initial beliefs about the attractiveness of such ideas. Results from three studies, including a self-comparison study over time and a randomized 
sleep deprivation
 experiment, show that a good night of sleep positively influences entrepreneurs' abilities to perform cognitive tasks at the very basis of entrepreneurial pursuits, whereas shortchanging sleep can yield suboptimal performance.", November 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618305470,"Seeing parochially and acting locally: Social exposure, problem identification and social entrepreneurship",Sunasir=Dutta: sdutta@umn.edu,"Abstract
Why some communities have greater rates of social entrepreneurship in similar domains is a question of importance to scholars and practitioners alike. Much of the literature in social entrepreneurship begins with a social problem that has been identified, and then analyzes the antecedents of the entrepreneurial process that lead to organizational solutions emerging for those problems. However, why some problems gain traction as being worthy of time and effort in solving, has garnered little attention. We argue that particular problems are more or less salient triggers of action by prospective social entrepreneurs based on the distribution of such problems in the local social environment, rather than aggregate levels of need. Yet, even problems widely experienced as shared, salient, and generally worthy of action might lack the emergence of solutions in fragmented communities, such as those with high levels of residential segregation by race and income. We study this in the context of founding of advocacy and support organizations in the domain of healthcare, and find support for our predictions. We also conducted additional tests to better characterize the findings and test robustness to alternative sources of influence, such as the local pool of potential social entrepreneurs, the role of local ecology, and geographic spillovers from neighboring areas.", November 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618301344,Reputation and new venture performance in online markets: The moderating role of market crowding,Karl=Taeuscher: Karl.Taeuscher@manchester.ac.uk,"Abstract
Reputation represents an important driver of new venture performance. This article shows that the performance benefits of reputation are substantially contingent on ventures' market conditions. My study of 797,087 sales transactions by 5760 new ventures in 119 platform-mediated online markets provides strong evidence that market crowding attenuates the reputation–performance relationship. Ventures benefit 38% to 42% more from a favorable reputation when they compete in an uncrowded (versus crowded) market. By disentangling the underlying mechanisms of reputation, my study allows for more accurate predictions about why, when, and how ventures benefit from reputation.", November 2019,"New venture performance, Reputation, Signaling theory, Resource-based view, Online markets, Platform entrepreneurship",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617309345,Narcissism and learning from entrepreneurial failure,Yiran=Liu: yiran.liu@tju.edu.cn; Yong=Li: yong.li@unlv.edu; Xiling=Hao: xueniabc521@163.com; Yuli=Zhang: ylzhang@nankai.edu.cn,"Abstract
Failure of a prior business provides an opportunity for an entrepreneur to learn in the subsequent entrepreneurial endeavor, but learning from failure is not guaranteed. Why do some entrepreneurs learn less from failure than others? In this study, we propose that a narcissistic personality can create cognitive and motivational obstacles to learning. We further posit that the inhibiting effect of 
narcissism
 will be more salient when the costs of failure, especially social costs, are higher. Our analysis with a survey sample of startups provides the initial empirical evidence about the negative impact of 
narcissism
 on learning from entrepreneurial failure. The study adds to research on learning from failure and 
narcissism
 in entrepreneurship.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618300892,"Violence against women and new venture initiation with microcredit: Self-efficacy, fear of failure, and disaster experiences",Dean A.=Shepherd: dshephe1@nd.edu; Abu Zafar M.=Shahriar: shahriar.abuzafar@monash.edu,"Abstract
Domestic violence is the most prevalent form of gender-based violence that threatens the 
wellbeing
 and dignity of women. In this paper, we examine whether and how exposure to physical or sexual assault by male partners influences women's decision to initiate a new business when they have access to financing. We collected primary data from rural Bangladesh in collaboration with a microfinance institution that provided small collateral-free loans to a group of married women. We conducted a baseline survey before loan disbursement and then conducted a follow-up survey 12 to 15 months later to collect information on loan usage. We find that women who experienced physical or sexual violence by their husband before receiving a loan are less likely to initiate a new business with their loan than those who did not experience such violence. Exposure to domestic violence obstructs the initiation of new businesses through reduced entrepreneurial self-efficacy and increased fear of business failure. The adverse impact of domestic violence is more detrimental for women who recently experienced another potentially traumatic event—an environmental disaster—than for those without such an experience.", November 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618305858,Self-employment and well-being across institutional contexts,Michael=Fritsch: m.fritsch@uni-jena.de; Alina=Sorgner: asorgner@johncabot.edu; Michael=Wyrwich: m.wyrwich@rug.nl,"Abstract
This paper investigates whether the relationship between a person's occupational status and well-being differs across countries with varying institutional contexts. We find that the relationship between job and 
life satisfaction
 of self-employed people as well as of paid employees varies considerably across countries. Our results indicate that entrepreneurship-friendly institutions in a country are conducive to the well-being of those who are self-employed. Remarkably, the quality of entrepreneurial institutions also increases the levels of well-being of paid employees, but the effect is more pronounced for the self-employed.", November 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619300886,Editorial: Enhancing quantitative theory-testing entrepreneurship research,Jeffery S.=McMullen: mcmullej@indiana.edu; Karl=Wennberg: karl.wennberg@liu.se; Brian S.=Anderson: andersonbri@umkc.edu,"Abstract
The purpose of this editorial is to discuss methodological advancements to enhance quantitative theory-testing entrepreneurship research. As the impact of entrepreneurship scholarship accelerates and deepens, our methods must keep pace to continue shaping theory, policy, and practice. Like our sister fields in business, entrepreneurship is coming to terms with the replication and credibility crisis in the social sciences, forcing the field to revisit commonly-held assumptions that limit the promise and prospect of our scholarship. Thus, we provide suggestions for reviewers and editors to identify concerns in empirical work, and to guide authors in improving their analyses and research designs. We hope that our editorial provides useful and actionable guidance for entrepreneurship researchers submitting theory-testing papers to 
Journal of Business Venturing
.", September 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617301672,"Entrepreneurship and well-being: The role of psychological autonomy, competence, and relatedness",Joakim=Wincent: joakim.wincent@hanken.fi; Nadav=Shir: nadav.shir@hhs.se; Boris N.=Nikolaev: borisnikolaev@baylor.edu,"Abstract
Drawing upon the self-determination theory, we develop a two-stage multi-path mediation model in which psychological 
autonomy
 mediates the relationship between 
active engagement
 in entrepreneurship and well-being partially through its effect on psychological competence and relatedness. We test this model on a representative sample of 1837 working individuals (251 early-stage entrepreneurs) from Sweden. We find active engagement in entrepreneurial work tasks to be strongly associated with well-being relative to non-entrepreneurial work. Thus, we highlight the importance of individual 
self
-
organization
—with autonomy at its core—which makes entrepreneurial work more beneficial in terms of basic psychological needs compared to other work alternatives.", September 2019,"Entrepreneurship, Well-being, Self-organization, Psychological needs",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617308376,Accelerating strategic fit or venture emergence: Different paths adopted by corporate accelerators,Raj K.=Shankar: raj01@ediindia.org,"Abstract
Corporate accelerators (CAs) are a fast-emerging form of corporate engagement with startups. Equating them with independent startup accelerators and/or corporate venturing limits our understanding of how and why corporations run CA programs and to what end. In this inductive 
grounded theory
 study, we explore how corporations design and run CAs and to what effect. This study of four CAs reveals that corporations manage accelerators via one of two distinct processes: namely, accelerating strategic fit or accelerating venture emergence. Our inductive models of these corporate acceleration processes provide new insights into how CAs operate within corporations. Strategic posture and investment time horizon influence corporations' choice of acceleration path and their identification of potential ventures for acceleration. Our study deconstructs what comprises the core corporate acceleration processes and explains how the two pathways result in distinct outcomes—nurturing innovations or nurturing ecosystems. We believe these findings can open up rich research opportunities for understanding how corporations engage with entrepreneurial ventures to enhance their entrepreneurialness.", September 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617302598,Institutional quality and market selection in the transition to market economy,Hien Thu=Tran: htran3@uOttawa.ca,"Abstract
This paper investigates the impact of institutional quality on the productivity, profitability and survival of new entrants versus those of incumbent firms in a transitional setting, Vietnam. By integrating economic and institutional perspectives, we emphasize the importance of institutional quality in shaping the evolution of 
industry
 dynamics. We find that poor institutional quality that acts as institutional buffering for incumbents jeopardizes the Schumpeterian market selection process. In particular, despite being more productive and profitable, new entrants are still more likely to exit than incumbents on average. As a consequence, facing poor institutions, only new entrants with sufficiently high productivity and profitability are able to survive. However, improving institutional quality does not enhance new entrants' survival and entrepreneurial performance; rather, it removes the survival advantage of incumbents and thus reduces the differences in performance and exit hazard between new entrants and incumbents. We investigate this seemingly paradoxical relationship using Vietnamese census data from 2006 to 2013.", September 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618301745,Navigating liminality in new venture internationalization,Steven W.=Floyd: sfloyd@isenberg.umass.edu,"Abstract
Prior research describes international expansion as a series of discrete steps and notes that taking them threatens new ventures' survival, especially due to unexpected setbacks. Seen through the lens of social science, the source of such threat becomes clearer. In this paper, we argue that 
internationalization
 in new ventures involves what social anthropologists call a liminal transition – a betwixt-and-between period lying between the 
intent
 to internationalize and the realization of a stable internationalized state. The ambiguous and transitory nature of this liminal transition has the potential to increase the odds of overreach (e.g. a high-cost market entry without sufficient resources). Avoiding the negative influence of liminality – and instead harnessing its positive effect – relies on three sources of support that we refer to as opportunity scaffolding: self-reflective learning, 
peer learning
 and consultative learning. We argue that entrepreneurs with personality profiles high in levels of core self-evaluation (CSE) are more likely to utilize the scaffolding like that available in business incubators effectively. This leads to the development of a more reflective 
mindset
, making capability learning more likely, preventing decisions that lead to overreach and reducing the threat to INV survival. However we also strike a note of caution in that at excessive (hyper) levels of CSE, the internationalizing new venture could become the victim of hubris. Emboldened with unrealistically high self-confidence, hubristic entrepreneurs are more likely to rebuff use of scaffolding, leading to a more reactive 
mindset
, increasing the probability of liminal overreach and threatening INV survival.
Executive summary
Internationalization represents an important pathway to growth for new ventures. At the same time, the burden of 
internationalization
 is considerable since new ventures must learn new capabilities under severe resource constraints to succeed in international markets. Thus we have a tension: 
internationalization
 increases the odds of growing rapidly and lowers the odds of survival for new ventures. Therefore, it is important for new ventures' capability 
learning process
 to be effective through harnessing network ties and entrepreneurial cognition.
However, although we know a lot about what makes international new ventures (INVs) successful, there is a surprising lack of detailed understanding of the 
transition
 that these firms make during the 
internationalization
 process. 
Becoming
 a stable INV involves making sense of new environments and improvising in the face of unexpected setbacks. Previous work has focused more on how INVs fare while pursuing identified opportunities during initial or post-entry internationalization but not as much on how they cope in the transition to becoming a stable INV over time.
To address this deficiency we draw upon an underutilized theoretical lens from 
social anthropology
: liminality. Liminality describes the “betwixt-and-between” condition that is experienced during a transition when one is no longer in the original state but hasn't quite reached the new one. This perspective draws attention to both a vulnerability and an opportunity that are simultaneously heightened during transitions: the novelty of the situation can be cognitively confounding and liberating. If a new venture's entrepreneur is overwhelmed by distorted thinking during this liminal period, he or she may lead the INV to take fatal missteps, including overreaching. On the other hand, if the confusion inherent in this process can be contained and the potential creativity of this stage harnessed, then new capabilities can be learned and the potentially treacherous liminal period successfully navigated. Thus liminality theory helps to distinguish between measured and reckless improvisation.
Liminal theory also helps us to identify opportunity scaffolding as an important way of avoiding liminality's negative effects by facilitating reflective learning, 
peer learning
 and consultative learning in conjunction with mentors. A practical manifestation of such support is the use of business incubators. Where these are not available, entrepreneurs may avail of mentors and peers through other means such as advisory boards or education. Furthermore, entrepreneurial personality in influences entrepreneurs' propensity for using such scaffolding: those with high levels of core self-evaluation (CSE) – confident of their abilities – are more likely to use scaffolding whereas those with low or excessive levels of CSE will tend to rebuff the use of scaffolding.
Overall, our conceptualization complements previous work on capability learning with the notion of “transitioning capability” – which is the ability to harness the creativity of liminality while avoiding its confounding potential. This is a theoretical advance over how INV research views the capability 
learning process
. And it has strong practical implications for how international entrepreneurs can thoughtfully navigate liminality, by taking advantage of opportunity scaffolding, being self-aware of limitations and strengths and avoiding overreach.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618302441,"User entrepreneurs' multiple identities and crowdfunding performance: Effects through product innovativeness, perceived passion, and need similarity",Arvin=Sahaym: arvin@wsu.edu; Pyayt=Oo: oo1p@cmich.edu; Thomas H.=Allison: thomas.allison@wsu.edu; Sakdipon=Juasrikul: sakdipon_jua@utcc.ac.th,"Abstract
This study examines the performance of user entrepreneurs in acquiring financial resources via crowdfunding. User entrepreneurs are thought to have better performance than non-user entrepreneurs, but the theoretical underpinnings of these differences are unclear. We propose a baseline hypothesis that claims of user entrepreneurship serve as a signal of capability and commitment to potential backers. In addition, building on three distinct identities of user entrepreneurs, we argue that user entrepreneurs' perceived passion, product innovativeness, and need similarity with potential backers mediate the relationship between user entrepreneurship and crowdfunding performance. Our results from a 
field study
 using a sample of crowdfunded ventures support these assertions. We validate these results and measures using both survey and 
experimental methods
. This is one of the first studies to develop a multi-theoretical framework for user entrepreneurship, and the first to provide an underlying theoretical explanation for the superior crowdfunding performance of user entrepreneurs.", September 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618300089,Infrastructure investments and entrepreneurial dynamism in the U.S.,Daniel L.=Bennett: bennettecon@gmail.com,"Abstract
Investments in physical infrastructure induce environmental changes that serve both an enabling and disabling function, potentially acting to simultaneously stimulate new business establishment and provoke exit by some incumbent establishments. The opening of a new establishment results in the creation of jobs that did not previously exist. Similarly, the closing of an establishment results in the permanent loss of jobs. I develop a theoretical model that depicts this external enabler/disabler process and test the model's predictions empirically tested using annual state-level data spanning the period 1993–2015. The results from dynamic panel system GMM estimation suggest that public and private infrastructure investments exert opposite effects on dynamism. Whereas private infrastructure investment is positively and significantly associated with the creation of businesses and jobs, public infrastructure investments are associated with the destruction of businesses and jobs. These results point to private infrastructure investment serving primarily an entrepreneurial enabler role and public infrastructure investment an entrepreneurial disabler role.", September 2019,"H54, L26, M13, O18, O43, R53",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618308942,"Entrepreneurship and well-being: Past, present, and future",Johan=Wiklund: jwiklund@syr.edu; Boris=Nikolaev: Boris_Nikolaev@baylor.edu; Nadav=Shir: Nadav.Shir@hhs.se; Maw-Der=Foo: foomd@alum.mit.edu; Steve=Bradley: Steve_Bradley@baylor.edu,"Abstract
Entrepreneurship research typically emphasizes firm-level outcomes such as growth and performance. However, people pursue entrepreneurship for deeply personal, idiosyncratic reasons. Therefore, as in other self-organized human pursuits, how entrepreneurship relates to fulfillment and well-being is of utmost importance. In this paper, we provide an overview of the well-being concept, related research, and its connection to entrepreneurship. We define entrepreneurial well-being as the experience of satisfaction, positive affect, infrequent negative affect, and psychological functioning in relation to developing, starting, growing, and running an entrepreneurial venture. We explain this definition of entrepreneurial well-being and review significant developments in our field and the broader field of well-being. Highlights of social, technological and institutional trends illustrate key areas for future research that can enhance our understanding of these phenomena. The eight papers in this special issue focus on entrepreneurial well-being each offering a specific perspective on how scholars can theorize and study the antecedents and consequences of entrepreneurship related to well-being.", July 2019,"Entrepreneurship, Entrepreneurial well-being, Self-employment, Happiness, Subjective well-being, Eudaimonic well-being, Positive and negative affect, Life satisfaction, Health",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617307024,Well-being effects of self-employment: A spatial inquiry,Maria=Abreu: ma405@cam.ac.uk,"Abstract
Our paper presents an empirical analysis of entrepreneurial well-being using a large-scale longitudinal household survey from the UK that tracks almost 50,000 individuals across seven waves over the period 2009–2017, as well as a number of exploratory 
case studies
. We contribute to the existing literature by investigating how entrepreneurial well-being varies across locations along the urban-rural continuum, and across wealthy-deprived neighbourhoods. We use a Coarsened Exact Matching (CEM) approach to compare the well-being outcomes of individuals who switch into self-employment from waged employment, and show that entrepreneurial well-being, in the form of job satisfaction, is significantly higher for those living in semi-urban locations, relative to those living in urban and rural locations. We argue that semi-urban locations provide an optimal combination of ease of doing business and quality of life. Our results also show that individuals in wealthy neighbourhoods who switch into self-employment experience higher job satisfaction than otherwise comparable individuals living in materially deprived neighbourhoods, although the latter experience greater levels of 
life satisfaction
 following the switch.", July 2019,"L26, I13, R2, P25, R23, E24",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617305669,Can prosocial motivation harm entrepreneurs' subjective well-being?,Ewald=Kibler: ewald.kibler@aalto.fi; Gabriella=Cacciotti: gabriella.cacciotti@wbs.ac.uk; Joakim=Wincent: joakim.wincent@ltu.se; Teemu=Kautonen: teemu.kautonen@aalto.fi; Martin=Obschonka: martin.obschonka@qut.edu.au,"Abstract
Entrepreneurship research on prosocial motivation has outlined its positive impact on well-being, but still little is known about its power, which may have deleterious personal consequences under certain conditions. In this study, we ask whether prosocial motivation can harm entrepreneurs' subjective well-being when they run a commercial venture. Embedded within a contingency perspective informed by self-determination theory, we build on longitudinal survey data to explain the effect of prosocial motivation on entrepreneurs' overall 
life satisfaction
. Our analysis demonstrates that prosocial motivation has a negative effect on entrepreneurs' 
life satisfaction
 due to increased levels of stress. However, our findings show that the negative effect of prosocial motivation dissipates when perceived 
autonomy
 at work is high compared to when it is low. Overall, our research raises questions on the role of prosocial motivation for entrepreneurs' subjective well-being and, in particular, discusses its potential “dark side” in the context of commercial entrepreneurship.
Executive summary
Can there be a “dark side” in helping others? If so, how can we better understand under what conditions it emerges? Entrepreneurship research conventionally presents prosocial motivation as a positive driver for social venture creation and entrepreneurs' well-being. However, we have little knowledge about the consequences of prosocial motivation when we move outside the social entrepreneurship context. When prosocially motivated entrepreneurs lead a commercial venture, they face the difficult task of balancing the desire to help others with the financial requirements of the business. The challenge of simultaneously accomplishing commercial and prosocial goals can result in a stressful experience that is detrimental to the entrepreneur's well-being. In this study, we ask whether and under what circumstances prosocial motivation can harm entrepreneurs' well-being.
Embedded in a contingency perspective informed by self-determination theory, this article expands our knowledge on the effects of prosocial motivation in the context of commercial entrepreneurship. We draw from original longitudinal survey data on 186 entrepreneurs in the United Kingdom to demonstrate that prosocial motivation causes entrepreneurs stress and through that stress has a negative effect on their life satisfaction. We also show that the negative effect of prosocial motivation diminishes when the degree of autonomy entrepreneurs perceive in the pursuit of daily work tasks is high. To explore the uniqueness of the entrepreneurial context, we run a comparative analysis with a sample of 544 employees. This analysis confirms that stress fully mediates the negative relationship between prosocial motivation and subjective well-being, but for employees, this negative effect disappears when their level of intrinsic motivation—the desire to expend effort based on enjoyment of the work itself—is high.
Building on our findings, we generate several important contributions. First, we help develop an understanding of the “dark side” of prosocial motivation by demonstrating that under certain circumstances, the desire to help others can be detrimental to entrepreneurs' subjective well-being. Second, we expand knowledge about the link between prosocial motivation and well-being by considering the boundary conditions (perceived autonomy and intrinsic motivation) that influence the dynamics of their relationship. Third, we set the stage for further investigations that aim to clarify the relationship between motivation and perceived autonomy and its effect on personal outcomes across different work domains.
The key insight of the study is that prosocial motivation creates a dilemma for entrepreneurs when operating a commercial business such that the desire to help others outside the context of immediate work tasks can harm their personal well-being. We also find that the perception of autonomy is key for commercial entrepreneurs to be able to realize their prosocial motivation without creating stressful situations. Extending our understanding of the conditions that shape the relationship between prosocial motivation and well-being among entrepreneurs would help in developing a more holistic notion of prosocial business venturing, one that includes the role of both commercial and social enterprising activities in contributing to personal and societal well-being.", July 2019,"Entrepreneurship, prosocial motivation, subjective well-being",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617306341,Micro-entrepreneurship and subjective well-being: Evidence from rural Bangladesh,Muhammad Faress=Bhuiyan: fbhuiyan@carleton.edu; Artjoms=Ivlevs: a.ivlevs@uwe.ac.uk,"Abstract
Microcredit has long been hailed as a powerful tool to promote livelihoods and reduce poverty through entrepreneurship. However, its impacts on people's subjective well-being remain underexplored. We present a unified theoretical framework for analyzing the effect of microcredit-enabled entrepreneurship on overall 
life satisfaction
 – a key manifestation of subjective well-being. Empirically, we apply an 
instrumental variable
 approach to a unique census-like household survey conducted in three villages of Bangladesh in 2013. In spite of having no direct effects, we find that microcredit borrowing has an indirect negative effect on overall 
life satisfaction
, through increased worry. On a positive note, we find that female micro-borrowers experience an increase in satisfaction with financial security and achievement in life. We also provide evidence that micro-borrowers with higher levels of assets experience an increase in satisfaction with financial security.", July 2019,"Microcredit, Entrepreneurship, Life satisfaction, Happiness, Depression, Worry, Female empowerment, Bangladesh",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617307899,Entrepreneurship and eudaimonic well-being: Five venues for new science,Carol D.=Ryff: cryff@wisc.edu,"Abstract
Researchers in entrepreneurial studies are increasingly interested in the psychological well-being of entrepreneurs. Approaches to well-being tend to be partitioned into hedonic and eudaimonic formulations. Most entrepreneurial studies have focused on hedonic indicators (life satisfaction, happiness, positive affect). The central objective of this essay is to examine the relevance of eudaimonic well-being for understanding 
entrepreneurial experience
. The theoretical background and key dimensions of eudaimonic well-being are described and their relevance for entrepreneurial studies is considered. Illustrative findings from prior well-being studies are examined, also with emphasis on possible extensions to entrepreneurship. Five key venues for the entrepreneurial field are then considered: (1) entrepreneurship and 
autonomy
, viewed both as a motive (self-determination theory) and as an aspect of well-being (eudaimonic well-being theory); (2) varieties of entrepreneurship (opportunity versus necessity) and eudaimonic well-being; (3) 
eudaimonia
 in the entrepreneurial journey (beginning, middle, end); (4) entrepreneurship, well-being and health; and (5) entrepreneurs and the 
eudaimonia
 of others – contrasting virtuous and vicious types. In each topic, extant findings from entrepreneurial studies are considered and new research directions proposed. The overall aim is to be generative regarding the interplay between 
entrepreneurial experience
 and eudaimonic well-being.
Executive summary
Although there is growing research on the psychological well-being of entrepreneurs, most studies to date have focused on hedonic conceptions of well-being. However, key aspects of eudaimonic well-being (e.g., realization of personal potential, purposeful life engagement, effective management of complex environments) have received little attention even though they may be particularly relevant to entrepreneurial pursuits. To address this issue, the theoretical foundation of a widely-used eudaimonic model is briefly described along with its empirical operationalization. Illustrative findings generated with this model are noted, and their relevance for entrepreneurial studies is considered. Shifting to extant entrepreneurial research, five topical venues are then presented, beginning with a call to better distinguish the meaning and measurement of 
autonomy
 (as a core motive from self-determination theory, and as an aspect of well-being from eudaimonic theory) in studies of entrepreneurial experience. The eudaimonic well-being of different types of entrepreneurs is then considered with a primary focus on the distinction between necessity versus opportunity entrepreneurs. These particular types invoke emphasis on 
sociodemographic factors
 (e.g., educational and occupational status, income, wealth) that are known from previous research to matter in accounting for differences in reported levels of well-being. The third venue considers how eudaimonic well-being may matter over the course of entrepreneurial experience, underscoring that certain aspects of well-being may account for who chooses an entrepreneurial path while other aspects may serve as protective resources (buffers) vis-à-vis the stresses attendant to managing a self-initiated business. Still other aspects of well-being may be nurtured by the longer-term journey of business venturing. The health of entrepreneurs is then considered as linked to experiences of well-being. New directions for objective 
health assessments
 (functional health, biomarkers, 
neuroscience
, gene expression) are considered; all have previously been linked in population-based studies to eudaimonic well-being. Finally, the impact of entrepreneurs on the lives of others (co-workers, employees, families, communities, society) is considered via the contrast between benevolent (virtuous) versus malevolent (vicious) entrepreneurs. Promising empirical questions that follow from these observations are detailed.
From a lay perspective, the central importance of bringing eudaimonia to the field of entrepreneurial studies is that the essential core of this type of well-being involves realization of personal talents and potential. Such active pursuit of such personal excellence, in the spirit of Aristotle, is fundamental to entrepreneurship.", July 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000398,Machines augmenting entrepreneurs: Opportunities (and threats) at the Nexus of artificial intelligence and entrepreneurship,Dean A.=Shepherd: dshephe1@nd.edu,"Abstract
Artificial intelligence (AI) refers to machines that are trained to perform tasks associated with 
human intelligence
, interpret external data, learn from that external data, and use that learning to flexibly adapt to tasks to achieve specific outcomes. This paper briefly explains AI and looks into the future to highlight some of AI's broader and longer-term societal implications. We propose that AI can be combined with entrepreneurship to represent a super tool. Scholars can research the nexus of AI and entrepreneurship to explore the possibilities of this potential AI-entrepreneurship super tool and hopefully direct its use to productive processes and outcomes. We focus on specific entrepreneurship topics that benefit from AI's augmentation potential and acknowledge implications for entrepreneurship's dark side. We hope this paper stimulates future research at the AI-entrepreneurship nexus.
Executive summary
Artificial intelligence
 (AI) 
refers to machines that are trained to perform tasks associated with 
human intelligence
, interpret external data, learn from that external data, and use that learning to flexibly adapt to tasks to achieve specific outcomes
. 
Machine learning
 is the most common form of AI and largely relies on supervised learning—when the machine (i.e., AI) is trained with labels applied by humans. 
Deep learning
 and 
adversarial learning
 involve training on unlabeled data, or when the machine (via its algorithms) clusters data to reveal underlying patterns.
AI is simply a tool. Entrepreneurship is also simply a tool. How they are combined and used will determine their impact on humanity. While researchers have independently developed a greater understanding of entrepreneurship and AI, these two streams of research have primarily run in parallel. To indicate the scope of current and future AI, we provide examples of AI (at different levels of development) for four sectors—customer service, financial, healthcare, and tertiary education. Indeed, experts from 
industry
 research and consulting firms suggest many AI-related business opportunities for entrepreneurs to pursue.
Further, we elaborate on several of these opportunities, including opportunities to (1) capitalize on the “feeling economy,” (2) redistribute occupational skills in the economy, (3) develop and use new governance mechanisms, (4) keep humans in the loop (i.e., humans as part of the 
decision making
 process), (5) expand the role of humans in developing AI systems, and (6) expand the purposes of AI as a tool. After discussing the range of business opportunities that experts suggest will prevail in the economy with AI, we discuss how entrepreneurs can use AI as a tool to help them increase their chances of entrepreneurial success. We focus on four up-and-coming areas for entrepreneurship research: a more interaction-based perspective of (potential) entrepreneurial opportunities, a more activities-based micro-foundation approach to 
entrepreneurial action
, a more cognitively hot perspective of entrepreneurial 
decision making
 and action, and a more compassionate and prosocial role of 
entrepreneurial action
. As we discuss each topic, we also suggest opportunities to design an AI system (i.e., entrepreneurs as potential AI designers) to help entrepreneurs (i.e., entrepreneurs as AI users).
AI is an exciting development in the technology world. How it transforms markets and societies depends in large part on entrepreneurs. Entrepreneurs can use AI to augment their decisions and actions in pursuing potential opportunities for productive gains. Thus, we discuss entrepreneurs' most critical tasks in developing and managing AI and explore some of the dark-side aspects of AI. Scholars also have a role to play in how entrepreneurs use AI, but this role requires the hard work of 
theory building
, theory elaboration, theory testing, and empirical theorizing. We offer some AI topics that we hope future entrepreneurship research will explore. We hope this paper encourages scholars to consider research at the nexus of AI and entrepreneurship.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617304494,Switching to self-employment can be good for your health,Milena=Nikolova: m.v.nikolova@rug.nl,"Abstract
Relying on theoretical insights from the Job Demand-Control model, which links occupational characteristics to health, this paper provides the first causal evidence of the physical and mental health consequences of self-employment. I utilize German longitudinal data for the period 2002–2014 and difference-in-differences estimations to study switches from unemployment to self-employment (necessity entrepreneurship) and transitions from regular- to self-employment (opportunity entrepreneurship). I find that necessity entrepreneurs experience improvements in their mental but not physical health, while opportunity entrepreneurship leads to both physical and mental health gains. Importantly, the health improvements cannot be explained by changes in income or working conditions and are not driven by personality and 
risk preferences
 or the local unemployment conditions. As such, the findings highlight an additional non-monetary benefit of self-employment and have implications for 
entrepreneurship theory
 and practice, current and would-be entrepreneurs, as well as policy-makers.", July 2019,"Mental health, Physical health, Self-employment, Difference-in-differences",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261730650X,The Yin and Yang of entrepreneurship: Gender differences in the importance of communal and agentic characteristics for entrepreneurs' subjective well-being and performance,Keith M.=Hmieleski: k.hmieleski@tcu.edu; Leah D.=Sheppard: leah.sheppard@wsu.edu,"Abstract
This research examines 
gender differences
 in the relationships of entrepreneurs' agentic and communal personality characteristics with measures of subjective well-being and new venture performance. Results from a stratified national (USA) random sample of founding CEOs (
N
 = 303) demonstrate the advantages of an agentic characteristic (creativity) for women and a communal characteristic (teamwork) for men, with regard to the respective abilities of such persons to achieve high levels of subjective well-being and new venture performance. These relative advantages for women and men were mediated by perceptions of person-work fit.", July 2019,"Character strengths, Person-environment fit, Person-job fit, Positive organizational behavior, Positive psychology, Gender differences, Subjective well-being",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617304597,Self-employment and allostatic load,Marcus T.=Wolfe: mtwolfe@ou.edu; Trenton Alma=Williams: trenwill@iu.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Self-employment can be stressful and its long-term effects on individual health could be significant; yet, the physiological outcomes of self-employment related stress remain under-explored. Drawing on allostatic load as a long-term biological consequence of physiological wear-and-tear and an indicator of stress response, we use three different studies to provide a more nuanced understanding of the relationship between self-employment and physiological outcomes. In Study 1, based on a sample of 194 self-employed and 1511 employed individuals, we find that self-employment is marginally related to allostatic load and allostatic load marginally mediates the relationship between self-employment and physical, but not mental, health. Study 2, based on a sample of 776 self-employed and 8003 employed individuals, extends these findings, and provides evidence that those who are self-employed for longer periods have a higher allostatic load. Finally, in Study 3 we draw on a sample of 174 twins and, consistent with Study 2, show that those reporting self-employment in two waves (about eight years apart) had a higher allostatic load, however, when leveraging problem-focused coping such individuals experienced lower allostatic load. Taken together, these three studies extend our understanding of the relationship between self-employment and 
wellbeing
.", July 2019,"Allostatic load, Coping, Self-employment, Stress",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619301387,A wakeup call for the field of entrepreneurship and its evaluators,Jeffery S.=McMullen: mcmullej@indiana.edu,"Abstract
In this editorial, I seek to inform administrators and members of promotion and tenure committees about significant developments in the field of entrepreneurship. Using both objective and subjective data, I present a case for why entrepreneurship journals should be considered on par with other, premier management journals, which are widely considered to be unequivocal “A” journals used to assess scholarly contribution and productivity. I entertain and address common objections to equal treatment for entrepreneurship journals, and conclude with a call to action for both entrepreneurship scholars and the field's evaluators.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617305372,Founder retention as CEO at IPO in emerging economies: The role of private equity owners and national institutions,Bruce=Hearn: b.a.hearn@soton.ac.uk; Igor=Filatotchev: Igor.Filatotchev@kcl.ac.uk,"Abstract
We integrate the institutional perspective with research on the governance role of private equity firms in an investigation of Founder-CEO successions in Initial Public Offerings (IPOs) in emerging markets. Using a unique, hand-collected and comprehensive sample of 191 firms having undertaken IPOs in 21 markets across the African continent between January 2000 and August 2016, we apply 
instrumental variable
 (IV) Probit methodology and find that higher levels of private equity ownership are positively associated with the probability of the founder's retention as CEO, especially in the context of low-quality formal institutions. Further, in societies with high tribalism, higher private equity ownership is associated with an increased likelihood of founder retention. Voids in the institutional architecture underscore the importance of the founder as a key organizational resource for the firm and a source of institutionalized legitimacy, which in turn confers on the firm an ability to access required resources.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618301812,Entrepreneurial orientation and start-ups' external financing,Egle=Vaznyte: Egle.Vaznyte@UGent.be; Petra=Andries: Petra.Andries@UGent.be,"ABSTRACT
This study extends the 
Pecking Order Theory
 by investigating the role of start-ups' strategic posture for financial decision-making. Using a 
contingency approach
, it proposes that a start-up's entrepreneurial orientation differently affects the costs and benefits associated with external debt and equity financing, and thereby its use of the respective financing forms; with the strength of these relationships depending on industry-level risk and venture development stage. The study tests and confirms these hypotheses on a sample of 4456 German start-ups. It advances the entrepreneurial 
finance
 literature by taking strategic posture and its contingencies into account, and adds insight in the relationship between entrepreneurial orientation and firm performance. It also provides valuable practical implications for start-up founders and external financiers.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617308273,The emergence of the maker movement: Implications for entrepreneurship research,Steve=Bradley: Steve_Bradley@baylor.edu; Russell E.=Browder: Russell_Browder@baylor.edu; Howard E.=Aldrich: Howard_Aldrich@unc.edu,"Abstract
The maker movement has been touted as a harbinger of the next industrial revolution. Through shared access to tools and digital fabrication technologies, makers can act as producers in the sharing economy and potentially increase entrepreneurship rates, catalyze advanced manufacturing, and spur economic development. We develop a model of the maker movement configured around social exchange, technology resources, and knowledge creation and sharing. We highlight opportunities for studying the conditions under which the movement might foster entrepreneurship outcomes and discuss how research on the maker movement can deepen our understanding of 
entrepreneurial teams
 and 
corporate entrepreneurship
.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261830051X,The co-evolution of social networks and selection system orientations as core constituents of institutional logics of future entrepreneurs at school,Joris J.=Ebbers: j.j.ebbers@uva.nl; Nachoem M.=Wijnberg: n.m.wijnberg@uva.nl,"Abstract
In contexts where a choice between competing institutional logics is possible, the social networks of future entrepreneurs affect their adoption of particular logics. Using a panel data method for studying the co-evolution of social networks and individual actor behavior (SIENA), we study how selection system orientations as core constituents of institutional logics affect, and are affected by, social networks. Our empirical setting is a cohort of film school students, whose social network ties and selection system orientations are measured over a period of three years. We find that students with a strong market selection orientation are less popular among their peers at school, and that the market selection orientation of students is influenced through their social network ties with students from the same cohort.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617302926,Increasing quantity without compromising quality: How managerial framing affects intrapreneurship,J.P.C. (Coen)=Rigtering: J.P.C.Rigtering@uu.nl; G.U. (Utz)=Weitzel: u.weitzel@uu.nl; K. (Katrin)=Muehlfeld: muehlfeld@uni-trier.de,"Abstract
Individual-level opportunity recognition processes are vital to 
corporate entrepreneurship
. However, little is known regarding how managerial communication impacts the effectiveness of idea suggestion systems in stimulating individuals' participation in intrapreneurial ideation. Integrating self-determination theory, creativity, and framing research, we theorize how different ways of inviting employees to submit proposals (opt-out/opt-in registration; provision of examples) affect the number and quality of submitted ideas. Our multi-method study (field experiment, vignette experiment, interviews) shows that (i) opt-out increases employee participation without reducing idea quality and (ii) the provision of examples enhances the usefulness of ideas but decreases novelty and the number of submissions.", March 2019,"M50, M54, M19",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617303348,Knocking at the gate: The path to publication for entrepreneurship experiments through the lens of gatekeeping theory,Regan=Stevenson: rstev@indiana.edu; Matthew A.=Josefy: mjosefy@iu.edu,"Abstract
We draw on 
gatekeeping
 theory to explore the individual and routine-level criticisms that entrepreneurship experimentalists receive during the review process. Using a multi-study approach, we categorize common 
gatekeeping
 themes and present illustrative critiques derived from a unique sample of decision letters and a supplemental survey of entrepreneurship editors. In combination, we extend gatekeeping theory by considering how it applies to the scholarly domain, contribute to the literature by exploring an alternative theoretical explanation as to why entrepreneurship experiments might fail to survive the review process, and finally, provide contextualized recommendations for authors and reviewers of experimental research.", March 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617303130,The effect of a tax training program on tax compliance and business outcomes of starting entrepreneurs: Evidence from a field experiment,Hanskje=Nagel: hw.nagel@belastingdienst.nl; Laura=Rosendahl Huber: laura.rosendahl-huber@ip.mpg.de; Mirjam=Van Praag: mvp.ino@cbs.dk; Sjoerd=Goslinga: s.goslinga@belastingdienst.nl,"Abstract
This paper estimates the long-term impact of a short, partly personalized, mandatory 
tax
 training program on 
tax
 compliance and business outcomes of first-time entrepreneurs. To this end, we combine survey data, audit data and unique register data from the Netherlands' Tax and Customs Administration with a three year long randomized experiment. The results show that the training affects specific domains of 
tax
 compliant behavior. Moreover, it has no impact on business survival, but treated entrepreneurs have significantly higher profits compared to the control group due to lower business costs. These outcomes are partially supportive of our hypotheses developed from theories on 
tax
 compliance and mental accounting.", March 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617303324,Navigating the validity tradeoffs of entrepreneurship research experiments: A systematic review and best-practice suggestions,Denis A.=Grégoire: denis.gregoire@hec.ca; Julia=Binder: julia.binder@epfl.ch; Andreas=Rauch: andreas.rauch@sydney.edu.au,"Abstract
Experimental methods
 provide important advantages for advancing academic understanding of entrepreneurship. Yet, the complex and comingled relationships between some of entrepreneurship's key characteristics pose thorny methodological challenges to entrepreneurship researchers – notably to negotiate important tradeoffs between the ideals of external and 
construct validity
. To facilitate the sound mobilization of experimental methods in entrepreneurship research, we present an overview of critical validity challenges plaguing entrepreneurship research experiments and assess the validation practices mobilized in 144 studies using such methods. Building on these findings, we develop a practical guide of actionable validation strategies to help experimenters navigate the above tradeoffs and conduct entrepreneurship research experiments that are realistic, theoretically meaningful, and that help establish the causal effects of their focal variables. By doing so, we contribute a set of pragmatic means to support the mobilization of experimental methods for advancing entrepreneurship research.
Executive summary
Experimental methods
 hold important advantages for advancing the theoretical and practical understanding of 
entrepreneurial action
. The power of research experiments lies in their ability to yield convincing evidence supporting the causal effects of the factors they investigate.
Unfortunately, entrepreneurship research experiments are often criticized for offering pale copies of 
both
 the realities they attempt to model 
and
 the theoretical constructs they aim to study. The entrepreneurial process and its related activities count many intertwined characteristics – such as radical uncertainty, temporal dynamics, high personal stakes and other constraints – that can prove difficult to integrate in experimental studies. Moreover, these characteristics' comingled relationships raise important tensions with experimental methods' core principle of surgically focusing on the causal effects of a few manipulated variables. As a result, entrepreneurship research must overcome a number of validity challenges and tradeoffs in order to successfully leverage experimental methods and offer findings that convincingly support the causality of their theoretical developments.
Compounding these difficulties, the guidance typically offered in research methods textbooks tends to focus on generic issues that are altogether separate from the specific challenges of conducting valid entrepreneurship research experiments. Because of this, many research manuscripts mobilizing experimental methods arrive at the review process with important shortcomings. This threatens the field's knowledge accumulation and typically calls for authors to refine their work and collect additional data.
To help researchers face these challenges, we offer a three-part compendium focused on bolstering the validity of entrepreneurship research experiments. First, we complement the generic observations of research methods 
monographs
 by presenting an overview of the validity tradeoffs inherent to mobilizing experimental methods in entrepreneurship research – and of strategies for addressing these.
Second, and to demonstrate that overcoming these challenges is not a trivial task, we conduct a structured literature review of the external and construct validation strategies deployed in a comprehensive corpus of 144 relevant articles published in both entrepreneurship-focused journals and broader generalist journals from the applied behavioral and social sciences. Among the most positive elements emerging from our analyses, we note upward trends in the mobilization of pilot tests, in the conduct of multiple experiments within single papers as well as in the use of parallel studies using different data collection methods. We also observe increased efforts to explain the practical relevance of experimental findings. To our surprise, however, our analyses uncover downward trends in the mobilization of pre-tests to examine the research material's external validity and representativeness, as well as the continued publication of studies that do not report empirical evidence regarding their focal manipulations' 
construct validity
. This is concerning. Such practices undermine these experiments' abilities to yield convincing evidence in support of their theorized causal effects – and for what these imply for fostering 
entrepreneurial action
.
Third, and in light of the results obtained, we develop a practical guide of actionable strategies for navigating the validity tradeoffs of entrepreneurship research experiments. Grouping these strategies together allows us to systematize recommendations typically found across various methods 
monographs
, thereby offering an overall scheme to help entrepreneurship researchers navigate the validity tradeoffs inherent to conducting realistic and theoretically meaningful experiments. To make our recommendations as actionable as possible, we develop an extensive step-by-step guide of design and assessment strategies relevant to entrepreneurship research experiments. The guide spans the entire research process – from conceiving an experimental study to collecting, analyzing and reporting the results. The guide also includes a number of relevant exemplars from many different studies we analyzed.
By discussing these entrepreneurship-specific validity tradeoffs and combining that with an overview of strategies for addressing them, our study offers an entrepreneurship-centered synthesis that equips entrepreneurship researchers with the necessary tools for conducting experimental research that advances understanding of the causal effects supporting entrepreneurial action and its related phenomena.", March 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617302847,"“I know I can, but I don't fit”: Perceived fit, self-efficacy, and entrepreneurial intention",Dan K.=Hsu: dkhsu@bsu.edu; Katrin=Burmeister-Lamp: katrin.burmeister-lamp@ebs.edu; Sharon A.=Simmons: simmonsshar@umkc.edu; Maw-Der=Foo: foo@nus.edu.sg; Michelle C.=Hong: mhong@vt.edu; Jesse D.=Pipes: pipesjd@appstate.edu,"Abstract
While extant literature generally suggests a positive relationship between entrepreneurial self-efficacy and entrepreneurial intention, several moderators have been identified – suggesting possible boundary conditions on that relationship. This paper introduces perceived person-entrepreneurship fit to entrepreneurship and shows that it moderates the relationship between entrepreneurial self-efficacy and entrepreneurial intention. Three studies are conducted which illuminate the utility of randomized experiments and methodological approaches to address limitations in the interpretation of empirical results. Studies 1 and 2 are randomized experiments to examine causality; Study 3 contains two correlational surveys to triangulate the results by examining whether the proposed effects withstand the influence of confounding variables in real-life. The findings indicate that when a strong perception of fit with entrepreneurship is achieved, entrepreneurial intention is strongly predicted by entrepreneurial self-efficacy. In contrast, if one perceives a low level of fit or no fit, entrepreneurial intention will be low, regardless of entrepreneurial self-efficacy.", March 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617302227,Entrepreneurial cognition and the quality of new venture ideas: An experimental approach to comparing future-oriented cognitive processes,Arjan J.=Frederiks: a.j.frederiks@rug.nl; Basil G.=Englis: benglis@berry.edu; Michel L.=Ehrenhard: m.l.ehrenhard@utwente.nl; Aard J.=Groen: a.j.groen@rug.nl,"Abstract
In the research reported here, we compared how future-oriented 
cognitive processes
 underpin differences in the quality of new venture ideas (NVIs) generated by respondents. We primed the use of future-oriented 
cognitive processes
 in two experiments. The first experiment shows that prospective thinking leads to NVIs of higher quality in comparison to counterfactual thinking, perspective taking and a control group. The second experiment shows that prospective thinking and perspective taking result in NVIs of higher quality compared to counterfactual thinking and the control group. We also find that 
prior knowledge
 of technology strengthens these effects. Post-hoc analyses show that these effects are present when respondents are prompted to generate NVIs, but not when they spontaneously generate NVIs, and that respondents with more prior business experience are more likely to spontaneously generate NVIs. Finally, we discuss contributions our research makes to the literature on entrepreneurial cognition and opportunity recognition, and to practice.", March 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S2352673418301653,Why believe? The promise of research on the role of religion in entrepreneurial action,Jeffery S.=McMullen: mcmullej@indiana.edu; Brett R.=Smith: smithbr2@miamioh.edu; Michael J.=Conger: michael.conger@miamioh.edu; Mitchell J.=Neubert: mitchell_neubert@baylor.edu,"Abstract
Religion is one of the most pervasive and central topics in society. However, its relative neglect by entrepreneurship research leads to an insufficient understanding of 
entrepreneurial action
. To address this gap, we build on boundary theory and the 
psychology of religion
 to develop a sketch of the role of religion in 
entrepreneurial action
, including its antecedents and outcomes. Finally, we suggest a number of theoretical perspectives (identity, sensemaking, and boundary) and research questions that may further advance research on religion and entrepreneurship.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The focus on religion and its role in entrepreneurial action adds a unique perspective to entrepreneurship research. The theoretical perspectives proposed could pave the way for further exploration in this area.
https://www.sciencedirect.com/science/article/pii/S0883902617303233,Out of control or right on the money? Funder self-efficacy and crowd bias in equity crowdfunding,Regan=Stevenson: rstev@indiana.edu; Michael P.=Ciuchta: michael_ciuchta@uml.edu; Chaim=Letwin: cletwin@suffolk.edu; Jenni M.=Dinger: jdinger@suffolk.edu; Jeffrey B.=Vancouver: vancouve@ohio.edu,"Abstract
Our findings extend the entrepreneurship literature by highlighting the mechanism through which self-efficacy can hinder rather than enhance performance in entrepreneurial settings. Using two complementary experimental studies and a third quasi-experimental 
field study
 on equity crowdfunding decisions, we demonstrate that self-efficacy is negatively related to decision-making performance. This relationship is mediated by reduced searching effort. Our research also indicates that high self-efficacy funders tend to exhibit a “crowd bias” whereby they over-weight the opinions of the crowd, increasing the likelihood that they will fund poor quality ventures when such ventures are favored by the crowd. We introduce the term crowd bias and explore its effects, establishing that social indicators in the form of crowd cues can exasperate the negative effects of self-efficacy.", March 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618301721,Initial coin offerings (ICOs) to finance new ventures,Christian=Fisch: cfisch@uni-trier.de,"Abstract
In an initial coin offering (ICO), new ventures raise capital by selling tokens to a crowd of investors. Often, this token is a 
cryptocurrency
, a 
digital medium
 of value exchange based on the distributed ledger technology. Both the number of ICOs and the amount of capital raised have exploded since 2017. Despite attracting significant attention from ventures, investors, and policy makers, little is known about the dynamics of ICOs. This initial study therefore assesses the determinants of the amount raised in 423 ICOs. Drawing on signaling theory, the study explores the role of signaling ventures' technological capabilities in ICOs. The results show that technical white papers and high-quality source codes increase the amount raised, while patents are not associated with increased amounts of funding. Exploring further determinants of the amount raised, the results indicate that some of the underlying mechanisms in ICOs resemble those found in prior research into entrepreneurial 
finance
, while others are unique to the ICO context. The study's implications are multifold and discussed in detail. Importantly, the results enable investors to more accurately understand crucial determinants of the amount raised (e.g., technical white papers, source code quality, token supply, Ethereum-standard). This reduces the considerable uncertainty that investors 
face
 when investing in ICOs and enables more informed decision-making.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902616300970,Perceived uncertainty and behavioral logic: Temporality and unanticipated consequences in the new venture creation process,Yi=Jiang: yjiang@escpeurope.eu; Erno T.=Tornikoski: erno.tornikoski@grenoble-em.com,"Abstract
In this study, drawing on effectuation theory, we combine analytical strategies for process data to examine inductively and theorize how founder teams' perceptions of uncertainty and behavioral logics develop during new venture creation processes. The results reveal four phases and suggest a possible evolution from a causal conditional relationship between perceived uncertainty and behavioral logics to an integrative relationship. We bring to light the notion of temporality and unanticipated consequences, discuss their central roles in perceived uncertainty, effectuation, and causation, and offer revelatory insights into why and when effectuation is used in relation to uncertainty and 
entrepreneurial action
.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618301484,What's in a logo? The impact of complex visual cues in equity crowdfunding,Ammara=Mahmood: ammahmood@wlu.ca; Jonathan=Luffarelli: j.luffarelli@montpellier-bs.com; Mudra=Mukesh: m.mukesh@westminster.ac.uk,"Abstract
Visual cues are pervasive on 
crowdfunding platforms
. However, whether and how low validity visual cues can impact the behavior of backers remains largely unknown. In this article, we propose a disfluency-based heuristic framework for understanding the influence of low validity visual cues on equity 
crowdfunding platforms
. Drawing on processing fluency theory and visual heuristics, we propose that backers often automatically 
process visual
 cues, and that the subjective experience of ease/difficulty with which backers perceptually process low validity visual cues serves as a heuristic and informs their perceptions of early-stage entrepreneurial ventures. We test our propositions focusing on logos (low validity visual cues that are particularly salient and ubiquitous on equity crowdfunding platforms) and logo complexity (a fundamental characteristic of logo design and established antecedent of processing disfluency). We contend that logo complexity can be interpreted by backers as a signal of venture 
innovativeness
 because more (vs. less) complex logos are more difficult to process, and thus, feel less familiar and more unique, original, and novel to backers. Since backers often value 
innovativeness
, we further contend that logo complexity can positively impact backers' funding decisions. We find support for our framework and propositions using a multimethod approach comprising three studies: one survey, one 
field study
, and one experiment. Theoretical contributions and managerial implications are also discussed.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617300150,Orchestrating boundaries: The effect of R&D boundary permeability on new venture growth,Johan=Wiklund: jwiklund@syr.edu; Robert S.=Nason: robert.nason@concordia.ca; Alexander=McKelvie: mckelvie@syr.edu; Michael=Hitt: mhitt@mays.tamu.edu,"Abstract
While established firms can efficiently manage their resource portfolio, new ventures must construct resource boundaries by assembling resources. In doing so, new ventures are often pushed to utilize resources that are owned by other actors. These inter-organizational relationship strategies do not expand organizational boundaries, but rather create permeable boundaries. We theorize that boundary permeability confers greater access to resources, but limits control over them. Therefore, new ventures 
face
 a risky option: utilize fewer but fully controlled resources or access a broader range of resources under limited control. We examine the effects of R&D boundary permeability across growth dimensions of sales, profitability, and employees using a sample of young knowledge intensive ventures. In doing so, we explore early stage boundary management decisions and reveal opportunities and threats to opening venture boundaries.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902616303925,Early employment expansion and long-run survival,Christina=Günther: christina.guenther@whu.edu; Pernille=Gjerløv-Juel: pgj@business.aau.dk,"Abstract
We investigate under which circumstances early employment growth translates into greater long-run survival. Drawing on Penrose's growth theory, we suggest that the relationship between early employment growth and long-run survival is conditional on employee turnover. We argue that higher employee turnover reduces joint experience in the firm and disrupts the development and eventual exploitation of the firm's productive opportunity set, thereby reducing long-term utilization of early employment expansion. These arguments suggest that the firm's ability to realize long-term benefits of early employment growth is contingent upon low employee turnover following this initial expansion. Using the Danish Integrated Database for 
Labor Market Research
, we show that only when employee turnover is low, will early employment growth lead to higher survival in the long run.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261730472X,The guppy and the whale: Relational pluralism and start-ups' expropriation dilemma in partnership formation,Joris=Knoben: j.knoben@fm.ru.nl; Rene M.=Bakker: rbakker@indiana.edu,"Abstract
Start-ups have a high need for resources yet 
face
 significant risks when forming partnerships with incumbents to access those resources. We propose that a partnership strategy based on relational 
pluralism
, forming multiplex and multifaceted ties with partners, can mitigate these risks. Such ties offer the start-up increased legitimacy and a relational safeguard against resource misappropriation by more powerful partners. However, we propose that there is a limit to the effectiveness of relational 
pluralism
. Its effect is weakened when the start-up becomes entirely dependent on a small set of partners, or when an additional tie yields resources that are redundant. We argue that the start-up only benefits when the gains from relational safeguarding and legitimacy outweigh the costs of dependence and redundancy. We empirically observe the co-evolution of start-ups’ interlocking directorate and strategic alliance networks in the Australian mining industry over a 10-year period. Our results show that start-ups that engage in relational pluralism perform better than both start-ups that form no alliances and start-ups that form stand-alone alliances. Having a very small portfolio of partners or one that skews heavily toward local partners, however, indeed limits the effectiveness of relational pluralism. Intriguingly, we also find that the temporal sequencing of relational pluralism matters. One of our central findings is that the best performing start-ups first form board interlocks with promising partners and add a strategic alliance later. This offers a rare glance at the temporal sequencing in which peripheral start-ups can gain exceptional performance through partnership formation.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617302756,The role of top management teams in transforming technology-based new ventures' product introductions into growth,Andreas=Engelen: andreas.engelen@tu-dortmund.de,"Abstract
The literature highlights the importance of top management teams (TMTs) for technology-based new ventures' success in achieving growth, which is often achieved through product introductions. The 
human capital theory
 suggests that TMT members' skills, which are typically derived from their education and experience, can facilitate the transformation of new product introductions into growth. We also propose that multiple products that must be managed and brought to the marketplace smoothly and flexibly benefit from the lower coordination needs and conflicts that are typical of functionally homogeneous teams. Using a unique, multi-source dataset on 374 US technology-based new ventures during the period from 2005 to 2014, we find that new product introductions help technology-based new ventures grow 
only
 when the TMT has startup experience and is not functionally diverse. Our findings lead us to echo calls in the TMT literature to move away from simple direct-effect models to more situation-dependent analyses of TMT diversity.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261730410X,Socio-cognitive traits and entrepreneurship: The moderating role of economic institutions,Christopher J.=Boudreaux: cboudreaux@fau.edu; Boris N.=Nikolaev: boris_nikolaev@baylor.edu; Peter=Klein: peter_klein@baylor.edu,"Abstract
We examine how country-level institutional context moderates the relationship between three socio-cognitive traits—entrepreneurial self-efficacy, alertness to new business opportunities, and fear of failure—and opportunity entrepreneurship. To do this, we blend 
social cognitive theory
 (SCT) with institutional theory to develop a multi-level model of entrepreneurial entry. We merge data from the Global Entrepreneurship Monitor (GEM) surveys and the Economic Freedom of the World (EFW) index for 45 countries from 2002 to 2012. Our results, which are based on a multi-level fixed-effects model, suggest that entrepreneurs' self-efficacy and alertness to new opportunities promote opportunity entrepreneurship while fear of failure discourages it. However, the strength of these relationships depends on the institutional context, with entrepreneurial self-efficacy and alertness substantially more likely to lead to new opportunity-driven ventures in countries with higher levels of economic freedom. These results provide suggestive evidence that economic freedom not only channels individual effort to productive 
entrepreneurial activities
, but also affects the extent to which individuals' socio-cognitive resources are likely to mobilized and lead to high-growth entrepreneurship.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617305402,Entrepreneurship as a solution to extreme poverty: A review and future research directions,Christopher=Sutter: sutterc@miamioh.edu; Garry D.=Bruton: g.bruton@tcu.edu; Juanyi=Chen: sunniechan1226@163.com,"Abstract
Entrepreneurship is widely argued to be critical for alleviating extreme poverty. However, research on this topic is characterized by diverging perspectives regarding 
poverty alleviation
 and remains fragmented across various research domains. This review examines 77 leading academic journals over the period 1990 to 2017 and identifies over 200 articles on entrepreneurship and 
poverty alleviation
. The analysis of these articles highlights three different underlying perspectives: poverty alleviation through entrepreneurship as remediation (actions that address immediate resource concerns), reform (actions leading to substantive institutional changes), and revolution (actions that change the underlying capitalist-based assumptions of business). The analysis of these articles leads to the development of extensive new insights and opportunities for future research.", January 2019,"Entrepreneurship, Poverty alleviation, Entrepreneurial process, Developing countries, Poverty",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000727,Financing decentralized digital platform growth: The role of crypto funds in blockchain-based startups,Paul P.=Momtaz: momtaz@tum.de,"Abstract
Coordination frictions prevent the efficient adoption and governance of blockchain-based platforms. Crypto funds (CFs) create value by smoothing frictions on decentralized digital platforms (DDPs). CF-backed DDPs obtain higher valuations in the primary token market, outperform their peers after issuing tokens, and benefit from token price appreciation around CF investment disclosure in the secondary market. Primary transaction data from the Ethereum ledger shows that the valuations of DDPs with meager adoption and a higher centralization of token ownership benefit more from CF backing. The positive valuation and performance effects for CF-backed DDPs are more pronounced for CFs that are more central in investor networks.", January 2025,"G24, G32, K22, L26",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000975,Align or perish: Social enterprise network orchestration in Sub-Saharan Africa,Christian=Busch: Christian.Busch@nyu.edu; Harry=Barkema: H.G.Barkema@lse.ac.uk,"Abstract
Previous research has shown that networks are vital for scaling the impact of social 
enterprises
. However, at present, insight into how and why social 
enterprises
 successfully orchestrate networks over time as they scale, particularly in the Sub-Saharan African emerging economy context, is scant. Theoretically sensitized by social network theory, our inductive study of six Kenyan social enterprises analyzed their phase-contingent network orchestration. Our findings show how and why 
entrepreneurial contextual bridging
 and 
circumventing social liability
 are important for initial scaling, whereas 
aligned capacity building
 as well as 
aligning incentives with political actors
 become necessary to develop and navigate social business ecosystems. In sum, we contribute a deeper understanding of how and why agentic network actions help social entrepreneurs achieve success as they scale in an emerging economy context.", March 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902624000272,"Peer effects on passion levels, passion trajectories, and outcomes for individuals and teams",Nicole=Coviello: ncoviello@wlu.ca; Anne=Domurath: adomurath@wlu.ca; Simon=Taggar: staggar@wlu.ca,"Abstract
We consider the influence of inter- and intra-individual team dynamics on entrepreneurial passion change and the relevance of passion change to important outcomes. Drawing on person-environment fit theory, we hypothesize first, that in newly formed teams, the entrepreneurial passion levels of individuals are impacted by their peers' passion (the average passion of their teammates). Second, we expect that individuals' trajectories of passion change are influenced by their perception of fit with the team. Third, passion levels and trajectories are expected to impact entrepreneurial outcomes for both individuals and teams. To examine these temporal dynamics, our hypotheses are tested with data from an accelerator program involving 343 team members nested in 79 newly formed teams. The findings reveal that in new teams, individuals' passion for inventing, founding, and developing are positively (negatively) influenced when teammates have higher (lower) passion for these roles and the association between individual's passion and peers' aggregated passion becomes stronger over time. Over time, positive passion trajectories emerge when an individual perceives higher fit with their team, and entrepreneurial 
intent
 is predicted by both (a) end-state levels of individual passion and (b) passion trajectories for inventing and founding (but not developing). Finally, we find that team passion trajectories predict team performance. Implications of these multi-level findings are discussed.", July 2024,"Entrepreneurial passion, Passion change, Entrepreneurial intent, Entrepreneurial team performance, Person-team fit, New teams",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000691,What is scaling?,Sarah=Bohan: s.bohan4@universityofgalway.ie; Esther=Tippmann: esther.tippmann@universityofgalway.ie; Jonathan=Levie: jonathan.levie@universityofgalway.ie; Josephine=Igoe: josephine.igoe@universityofgalway.ie; Blake=Bowers: b.bowers1@universityofgalway.ie,"Abstract
As ‘scaling’ has gained significant attention from different stakeholders, multiple definitions have emerged, endangering the legitimacy of the area as a distinct field of inquiry. Using a mathematics perspective, we define scaling in the business context as a time-limited process of exponential growth. We then identify drivers of scaling and show that scaling for competitive advantage requires increasing returns to scale in input-output relationships (superlinear scaling). This is followed by the application of graph theory, supported with findings from a 
Delphi study
, to demonstrate why scaling requires internal transformation. Finally, we discuss our definition's uniqueness, how it can be operationalized, and opportunities for future research.", January 2024,"Scaling, Scale-ups, Exponential growth, High growth, Delphi",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000824,Breaking barriers or maintaining status quo? Female representation in decision-making group of venture capital firms and the funding of woman-led businesses,Haemin Dennis=Park: parkhd@utdallas.edu; Lei=Xu: lxy9f@umsl.edu; Amy Y.=Ou: amy-yi.ou@polyu.edu.hk; Han=Jiang: jianghan@cuhk.edu.cn,"Abstract
We examine whether and when 
female representation
 in decision-making groups of venture capital firms affects the firms' decision to fund woman-led businesses. By developing an intra- and inter-group categorization framework for group decision-making, we argue that, in the male-dominated venture capital 
industry
, decision-making groups with higher female representation are less likely to fund woman-led businesses. However, this negative effect is mitigated when the decision-making group has more politically neutral members or when members have more shared prior employment affiliations. Using a longitudinal panel dataset of funding decisions by 151 U.S.-based venture capital firms, the empirical analyses support our theoretical predictions. We also enriched and complemented our empirical findings with qualitative evidence.", January 2024,"Female representation, Social categorization, Decision-making group, Venture capital, Funding of woman-led businesses, Gender equality, Qualitative analysis",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902623000319,Navigating the highs and lows of entrepreneurial identity threats to persist: The countervailing force of a relational identity with God,Brett R.=Smith: Smithbr2@Miamioh.edu,"Abstract
While an economic paradigm has been productive for entrepreneurship, religion has been proposed as an alternative rationality to advance research in our field. To extend a theological turn in entrepreneurship and identity research, our study inductively develops a conceptual model that explains how individuals navigate entrepreneurial identity threats based on the interaction between a relational identity with God (RIG) and an entrepreneurial identity to persist in 
entrepreneurial action
. Our study suggests this can happen when entrepreneurs engage in inter-identity work mechanisms - affirming and humbling - to mitigate these identity threats. Specifically, a relational identity with God acts as a countervailing force to an entrepreneurial identity during times of identity threats to generate inter-identity meaning change, resulting in interidentity stability and entrepreneurial persistence. Through our study, we advance knowledge on the theological turn in entrepreneurship and identity by inductively developing theory on a new religious identity construct (RIG), elaborating theory of inter-identity work by shifting the focus from structural to content changes, and extending theory on entrepreneurial action, persistence, and well-being based on theological rather than economic considerations.", July 2023,"Identity work, Inter-identity work, Entrepreneurial identity, Relational identity, Mental health, Well-being, Religion, Entrepreneurial action, Entrepreneurial persistence, Success, Failure, Theological turn",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000957,Social entrepreneurship and intersectionality: Mitigating extreme exclusion,Babita=Bhatt: babita.bhatt@anu.edu.au; Israr=Qureshi: israr.qureshi@anu.edu.au; Christopher=Sutter: sutterc@miamioh.edu; Dhirendra Mani=Shukla: dhirendra.mani.shukla@iiml.ac.in,"Abstract
As social 
enterprises
 seek to share knowledge, they must navigate social hierarchy. In this study, we examine social enterprises' efforts to share knowledge in rural areas and how they seek to mitigate some of the consequences of women's 
marginalization
 during this process. We use a two-step, multi-method approach. We begin with a 
quantitative study
 that explores outcomes for women, and how caste and patriarchy influence their ability to adopt new practices introduced by social 
enterprises
. We then draw on data from a seven-year qualitative 
case study
 to unpack our quantitative findings and explore the actual mechanisms through which intersectionality shapes the social enterprises' efforts. Our qualitative efforts also uncover how social enterprises' practices, as well as women's activities, can mitigate some of the negative consequences of 
marginalization
, even while the 
social setting
 is largely unchanged. We seek to contribute to theory by exploring how social enterprises can potentially mitigate some of the negative consequences of exclusion due to intersectionality.", March 2023,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000581,Calling Baumol: What telephones can tell us about the allocation of entrepreneurial talent in the face of radical institutional changes,Alina=Sorgner: asorgner@johncabot.edu; Michael=Wyrwich: m.wyrwich@rug.nl,"Abstract
In his seminal contribution, 
Baumol (1990)
 proposes that the direction of entrepreneurial effort towards its productive (e.g., start-up activity) or unproductive (e.g., rent-seeking) use in a society depends on institutions or the “rules of the game”. We focus on an important micro-foundation of Baumol's theory namely that certain individuals change the direction of entrepreneurial efforts with institutional change. Our research contrasts with previous work on the role of institutions, which mostly focuses on the aggregate macro-level, while not observing individual behavior. We analyze who decides to start a venture in East Germany after the fall of the Berlin Wall and find that many individuals who demonstrated commitment to the anti-entrepreneurial 
communist regime
 in the GDR were active in launching new ventures soon after German re-unification. We argue that commitment to 
communism
 among post-communist entrepreneurs reflects rent-seeking. Once institutions change radically, entrepreneurial efforts are directed towards start-up activity. We rely on the German Socio-Economic Panel Study (SOEP) that includes information on whether East German respondents had a telephone before German re-unification, which was one of the most sought-after rewards for commitment to the regime. We find that telephone owners had a higher propensity of becoming successful firm founders. Telephone owners were also more likely to have an entrepreneurship-prone personality profile and value orientation. Our results confirm Baumol's theory and suggest that alertness to entrepreneurial arbitrage opportunities is guiding the redirection of entrepreneurial effort in the face of drastic institutional change.
Executive summary
There is a large body of literature on the effect of institutions on entrepreneurship. A good share of this literature is rooted in the seminal contribution by 
Baumol (1990)
 who argues that the shape of institutions determines whether people direct entrepreneurial effort to productive, unproductive or destructive 
entrepreneurial activities
. Despite the fact that Baumol‘s main argument is at the individual micro-level, most of the literature focuses only on the macro-level implications of his theory. In contrast to most previous studies, we are not focusing on the aggregate level of entrepreneurship but explore the micro-foundations of Baumol's theory and analyze how (drastic) institutional change affects the entrepreneurial choice at the individual level.
In our discussion of Baumol's work, we also introduce Kirzner's concept of individual alertness to arbitrage opportunities which he originally formulated for market economies. We extend Kirzner's insights on the role of alertness to other institutional contexts (e.g., socialism) and forms of arbitrage (e.g., engagement in socialist organizations) other than start-up activity, and highlight the role of institutional change in shaping processes of opportunity formation.
It is important to understand how individuals allocate their entrepreneurial effort in times of major historical shocks and institutional changes for several reasons. First, since entrepreneurship is an important driver of economic growth and development, it is crucial to understand how institutional change affects entrepreneurial behavior at the individual level for designing policy measures targeted at increasing the entrepreneurial propensity of people. Second, the share of people with an entrepreneurial talent in a society is an enormous resource to cope with socio-economic change. Third, it is also important to understand the micro-foundations of Baumol's work as vast empirical evidence on the impact of institutions on entrepreneurial activities that is available at the macro-level relies on the validity of the micro-foundations.
We find that people who demonstrated commitment to one of the most anti-entrepreneurial institutional regimes in history—communism—were more likely to start a firm after transition to a market economy. Our analysis is based on the case of East Germany that saw a sudden shift from an anti-entrepreneurial communist regime that did not reward start-up activities towards an entrepreneurship-facilitating market economy after the fall of the Berlin Wall. Those people who were actively committed to the regime as evidenced by material rewards obtained in the GDR were more likely to become (successful) self-employed after the fall of the Berlin Wall. We also observe that people with an entrepreneurship-prone personality profile and those who put a strong emphasis on entrepreneurial values were more likely to have obtained material rewards in communism that indicate a strong commitment to the system.
We argue that applying and extending Baumol's and also Kirzner's ideas helps understanding this puzzling phenomenon. In essence, regime commitment can be seen as a form of rent-seeking activity, which is a classic example of unproductive entrepreneurial activity discussed by Baumol. Rent-seeking in the context of communism could be expressed, for example, in enthusiastic engagement in public organizations (e.g., party councils, youth organizations, state-owned enterprises) in exchange for specific material rewards. Their pronounced alertness to new arbitrage opportunities may have enabled these same individuals to switch to start-up activity once this option became available to them and if it was more profitable than rent-seeking.
We contribute to the literature by supporting the idea that the institutional framework conditions determine the type of entrepreneurial activity to which entrepreneurially talented people devote their efforts. So far, this claim found support mainly in aggregated macro-level data. Another important insight from our analysis is that entrepreneurs are flexible and agile economic agents who are alert to arbitrage opportunities and able to promptly adapt themselves to even radical changes, such as the 
shock transition
 from a socialist command economy to a market economy. Alertness to opportunities in a market economy context could hardly be learned in an anti-entrepreneurial context. Hence, an immediate re-allocation of entrepreneurial efforts indicates that alertness to arbitrage opportunities emerging in a market economy does not necessarily require experience in a market economy context.
Our assessment also suggests that institutional change is shaping subjective processes of opportunity formation. Hence, the debate on whether opportunities are ‘out there’ or they have to be created should take into consideration how institutions and institutional change set the boundaries for opportunities. In particular, identifying and pursuing new opportunities brought about by institutional change could represent a specific form of “entrepreneurship talent.”", September 2022,"L26, P20, P31",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902622000313,"Obsessive passion and the venture team: When co-founders join, and when they don't",Frédéric=Delmar: delmar@em-lyon.com; Yingzhu=Fu: fenixdx@163.com; Matthias A.=Tietz: matthias.tietz@unisg.ch,"Abstract
We investigate how potential co-founders' perceptions of a founder's obsessive passion (OP) influence the decision to join a venture team. Using a conjoint experiment with a primary sample of 116 founder-entrepreneurs and validating it with an additional sample of 59 founder entrepreneurs, we found that potential co-founders were more likely to join if they perceived that the founder had OP for developing ventures. Potential co-founders were less likely to join if they perceived OP for founding ventures. Further, we found significant interactions between perceived OPs, as well as interactions between perceived OP and potential co-founders' own OP.", July 2022,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000719,"Is blood always thicker than water? Family firm parents, kinship ties, and the survival of spawns",Giuseppe=Criaco: criaco@rsm.nl,"Abstract
We theorize that due to their ability to draw upon the distinctive bonding and bridging social capital resources of their family firm parents, family member spawns have longer early survival times than nonfamily member spawns from family firms, which in turn should have longer early survival times than spawns from nonfamily firm parents. We also predict that the survival enhancing effects of family parent bonding and bridging social capital are conditional on the spatial, cognitive and social proximity between the parent and the spawn. Using a population wide sample of 114,837 spawns founded in Sweden between 2000 and 2007, we find that nonfamily member spawns survive longer than spawns from nonfamily firms, and that this survival enhancing effect is contingent on the spatial and social proximity between the spawn and its parent. We also find that spawns founded by family members, on average, do not survive longer than spawns from family firms founded by nonfamily members, and that greater spatial and cognitive distance even hurt the survival of family member spawns. We discuss the contributions of our research to the spawning, family firm, and entrepreneurship literatures.", November 2021,"Entrepreneurial spawns, Family firms, Survival, Bridging social capital, Bonding social capital, Kinship ties, Proximity",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000471,Configurations for corporate venture innovation: Investigating the role of the dominant coalition,Nadine H.=Kammerlander: nadine.kammerlander@whu.edu; Matthias=Waldkirch: matthias.waldkirch@ebs.edu; Conrad=Wiedeler: conrad.wiedeler@whu.edu,"Abstract
Organizations often create new businesses, so-called corporate ventures (CVs), with the purpose of fostering innovation. However, not all venture initiatives turn out to be innovative. Prior research in particular refers to the ambivalent role of the parent firm's dominant coalition in fostering or hindering innovation in CVs. Using a configurational (fsQCA) approach, we investigate the interplay of five key conditions at the parent firm, the parent firm-venture intersection, and venture levels that potentially drive CV innovation. Building on 62 interviews from 43 corporate ventures, we identify four equifinal configurations and outline four roles that the dominant coalition plays in creating CV innovation. This study contributes to the understanding of which CV configurations drive innovation, extends the role of the dominant coalition in corporate venturing, and shows how dominant coalition involvement can replace 
autonomy
 as a driver of innovation.", September 2021,"Dominant coalition, Innovation, Corporate venturing, Venture autonomy, Fuzzy-set qualitative comparative analysis",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390262100032X,Resourcefulness narratives: Transforming actions into stories to mobilize support,Greg=Fisher: fisherg@indiana.edu; Devin=Burnell: dsburnel@iu.edu; Emily=Neubert: eneubert@iu.edu,"Abstract
Entrepreneurs regularly confront resource constraints as they attempt to bring their ideas to fruition. To overcome resource constraints, they often try to mobilize resources from external resource providers and use 
narratives
 as a critical tool to do so. We theorize that a particular type of narrative – a resourcefulness narrative – will significantly impact an entrepreneur's ability to mobilize support from resource providers. A resourcefulness narrative is a discursive, temporal account of past or ongoing 
entrepreneurial actions
, whereby an entrepreneur is presented as using, assembling, or deploying resources in creative ways in order to overcome an impediment. We argue that a resourcefulness narrative generates positive emotional and cognitive reactions from external resource providers such that they are inclined to support a venture. Furthermore, these effects are contingent on the general level of resource scarcity or 
munificence
 in a venture's environment, the level of uncertainty underpinning the venture, the entrepreneur's experience, and the recency of the actions described within the narrative. By acting resourcefully and transforming that action into a narrative, entrepreneurs can resourcefully mobilize support.", July 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902621000033,The mirroring of intercultural and hybridity experiences: A study of African immigrant social entrepreneurs,Anna=Krzeminska: anna.krzeminska@mq.edu.au; Nkosana=Mafico: nkosana.mafico@monash.edu; Charmine=Härtel: charmine.hartel@monash.edu; Josh=Keller: j.keller@unsw.edu.au,"Abstract
Paradox theory is attracting increasing interest from entrepreneurship scholars seeking to understand how entrepreneurs who operate hybrid organizations such as prosocial ventures can effectively address grand challenges. The organizational paradox literature suggests that differences in actors' approach to paradoxes can occur through the acquisition of different reasoning styles through exposure to different national cultures and cultural resources. We complement the paradox research stream on culture as a resource with the alternative perspective of culture as an experience, which we argue offers additional insight into hybridity within a global context because intercultural experiences are intrinsically paradoxical. Our 18 case studies of immigrant entrepreneurs from the African diaspora operating their prosocial ventures in Western contexts finds that the ways that immigrant entrepreneurs approach tensions in their prosocial ventures mirrors the nature of their intercultural experience. We also find that approaches to paradox vary based on structural barriers such as social exclusion that entrepreneurs faced in their formative years. Overall, our study contributes to research on culture in paradox theory and the prosocial venturing literature by elucidating how entrepreneurs' intercultural experience and the global macro-level systems in which it is embedded inform the degree and configurations of hybridity in prosocial ventures.", May 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618309066,Strategic exits in secondary venture capital markets,Guillaume=Andrieu: g.andrieu@montpellier-bs.com; Alexander=Peter Groh: groh@em-lyon.com,"Abstract
The market for secondary venture 
capital transactions
 provides a way for investors to obtain liquidity if the investee start-up corporation has not yet reached sufficient maturity for an IPO. It also creates 
divestment
 opportunities for badly performing ventures that investors would rather abandon. We analyze the way in which the opportunistic behavior and 
liquidity constraints
 of venture capital funds channel deal flow into the secondary venture capital market. Such opportunistic behavior leads to the 
strategic exit
 of seed financing venture capitalists. These exits enlarge investors' opportunity set of strategies and therefore affect the deal terms with entrepreneurs. In this paper, we show that two contracts are possible in a world with financially constrained venture capital investors, staged investments, and premature 
divestment
 opportunities. Both contracts have their disadvantages. With the first, the venture capitalist will never liquidate a project, even if it is a lemon, but will instead engage in a secondary transaction. With the second contract, although lemons will be systematically abandoned, high-quality ventures may also be liquidated. Entrepreneurs need to consider these effects when aiming to maximize their benefits and must 
trade off
 the contract parameters accordingly. Our model provides guidance to entrepreneurs in this respect, helps to explain deal flow into the secondary venture capital market, and offers several empirical predictions.", March 2021,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902619300606,Does team entrepreneurial passion matter for relationship conflict and team performance? On the importance of fit between passion focus and venture development stage,Petra=Andries: Petra.Andries@UGent.be,"Abstract
This study advances the literature on entrepreneurial passion, which struggles to explain when and how the experience of passion impacts venture-level performance, by shifting the focus to the team level and investigating the mechanisms and contingencies underlying this relationship. Drawing on identity control theory and the literature on new venture life cycle stages, we theorize and test that 
team entrepreneurial
 passion (TEP) affects new venture team performance via relationship conflict, and that this mechanism differs depending on whether the team’s passion focus is aligned with the venture’s development stage. Based on survey data and start-up competition scores from 86 new venture teams, we conclude that a prerequisite for a team to benefit from the experience of TEP, is that its passion focus at least reflects the 
entrepreneurial activities
 that are required for the specific development stage the venture operates in. Implications for research and practice are discussed.", September 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902618308243,The dualistic regulatory effect of passion on the relationship between fear of failure and negative affect: Insights from facial expression analysis,Charlotta=Sirén: charlotta.siren@unisg.ch; Dean A.=Shepherd: dshephe1@nd.edu; Silvia=Stroe: ioanasilvia.stroe@polimi.it; Joakim=Wincent: joakim.wincent@unisg.ch,"Abstract
Across two studies, we theorize and empirically investigate passion as a moderator of the negative affective consequences of fear of failure in early-stage entrepreneurship. We test our hypotheses in two 
field studies
 of naturally occurring affective events—namely, pitching competitions—and we complement self-reported measures of negative affect with physio-psychological measures obtained from analyzing entrepreneurs' facial expressions. The results confirm that in failure-relevant situations, dispositional fear of failure may lead to higher negative affect depending on the dualistic regulatory effect of passion—harmonious passion dampens the influence of fear of failure on negative affect (Studies 1 and 2), while obsessive passion magnifies this effect in Study 1 but dampens it in Study 2, thus showing mixed evidence. Our work is one of the first to investigate how early-stage entrepreneurs experience negative affect during typical entrepreneurial events as a result of their dispositional traits and their type and level of passion.", July 2020,"Harmonious and obsessive passion, Negative affect, Fear of failure, Facial expression analysis, Affective events theory, Early-stage entrepreneurship",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617305530,Is venture capital socially responsible? Exploring the imprinting effect of VC funding on CSR practices,Theodore A.=Khoury: tkhoury@pdx.edu; Ekin=Alakent: ekin.alakent@csueastbay.edu; M. Sinan=Goktan: sinan.goktan@csueastbay.edu,"Abstract
We study how 
corporate social responsibility
 (CSR) is guided by ownership history, specifically whether a company receives venture capital (VC) funding or not. We argue that companies that receive VC funding are less likely to adopt CSR practices due to unique VC imprinting and that temporal and investment orientation moderate this relationship. We find that VC-backed companies have poorer CSR records, which do improve over time, but at a comparatively slower rate than non-VC-backed companies. However, when VC-backed companies receive funding from VC firms that have a responsible investment orientation and a broader stakeholder view, their CSR records are significantly better. This study contributes to our understanding of imprinting boundaries and related repercussions in 
stakeholder management
 strategies.", May 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617303373,"Entrepreneurial visions in founding teams: Conceptualization, emergence, and effects on opportunity development",Nicola=Breugst: nicola.breugst@tum.de; Holger=Patzelt: patzelt@tum.de; Rebecca=Preller: rebecca.preller@tum.de,"Abstract
Prior research on entrepreneurial visions has typically taken a leadership perspective and explored how the founders’ future images of their ventures motivate themselves and followers. Drawing on an upper echelon perspective and longitudinal case studies of eight founding teams, this study finds that founders’ entrepreneurial visions do not only capture the future images of their ventures, but also the future images of the founders’ relationship with it. Taking into account this personal aspect of visions, we show that within a founding team, the members’ visions can be incongruent, i.e., they cannot be realized simultaneously within the current venture. While our data reveal that vision incongruence tends to occurs when all team members perceive to have an equal status, vision congruence emerges when the attributed status in the team is heterogeneous. Founding teams with more congruent visions tend to follow a focused opportunity development path, while those with less congruent visions tend to follow a comprehensive opportunity development path. Depending on the teams’ behaviors in the face of challenging situations either path can lead to successful opportunity commercialization or failure. We discuss the implications of these findings for the literatures on entrepreneurial visions, opportunities, and upper echelons.", March 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617304731,The exemplar enigma: New venture image formation in an emergent organizational category,Greg=Fisher: fisherg@indiana.edu; Shannon=Younger: s.younger@tcu.edu,"Abstract
We examine the process of organizational 
image formation
 for new ventures entering an emerging organizational category. An emerging organizational category is usually initiated by a pioneering venture that adopts a new organizational form. If that venture garners early recognition, it serves as an exemplar, attracting other ventures to enter the emerging category. Those ventures then have to formulate an image that both accounts for and competes with that of the category exemplar. This article describes how ventures form their images in the face of this tension. We examine this tension using qualitative data from eight new U.S. venture accelerators entering the emergent venture accelerator category, which revealed that 
image formation
 in an emerging organizational category involves three basic considerations: (1) emulation, (2) experimentation, and (3) divergence. Through emulation, organizations observe and rely on the exemplar in order to capture legitimacy. Through experimentation, organizations consider who they are beyond the exemplar and how they might change. Through divergence, organizations definitively claim and establish a unique image. From this, a conceptual framework is proposed in which organizational and contextual factors influence image formation actions and decisions.", January 2020,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261730215X,Entrepreneurs meet financiers: Evidence from the business angel market,Angela=Cipollone: acipollone@luiss.it; Paolo E.=Giordani: pgiordani@luiss.it,"Abstract
This paper formalizes and estimates the process of 
search and matching
 between entrepreneurs and financiers in the 
business angel
 (BA) market. Our theoretical model describes the market for entrepreneurial 
finance
 as a fair in which the two sides of the market can meet bilaterally and transform a rough entrepreneurial idea into a real start-up firm. We then collect a new dataset from the BA markets of 17 developed countries for the period 1996–2014, and we estimate the aggregate matching function expressing the number of deals as a function of the number of submitted entrepreneurial projects and of business angels. Empirical findings confirm the technological features assumed in the theoretical literature: positive and decreasing marginal returns to both inputs (
stepping on toes
 effect), technological complementarity across the two inputs (
thick market
 effect) and constant returns to scale. We discuss the theoretical and policy implications of these findings.", September 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617306936,I can't get no sleep—The differential impact of entrepreneurial stressors on work-home interference and insomnia among experienced versus novice entrepreneurs,Julia M.=Kensbock: j.kensbock@maastrichtuniversity.nl,"Abstract
When founding and managing a new business, entrepreneurs are frequently confronted with stressors hampering their daily work. The present study examines how these entrepreneurial stressors affect two important interrelated indicators of entrepreneurs' recovery and well-being—that is, their ability to detach from work during non-work times (work-home interference) and their sleep (insomnia). We introduce prior entrepreneurial experience as an important moderator to these relationships, arguing that due to their different learning and coping experiences and their different interpretations of the entrepreneurial role, experienced versus novice entrepreneurs would react differently to entrepreneurial stressors. In an empirical study with 122 entrepreneurs, we found that among experienced entrepreneurs, entrepreneurial stressors primarily had a direct sleep-impairing effect. Among novice entrepreneurs, the same stressors primarily initiated an indirect effect by leading to increased work-home interference and consequently also increased insomnia. Overall, thus, our study shows that both novice and experienced entrepreneurs suffer from insomnia when encountering entrepreneurial stressors—however, the underlying mechanisms differ. Implications are discussed in terms of both theory and practice.", July 2019,"Stressors, Entrepreneurial experience, Recovery, Insomnia, Work-home interference",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617309096,"Biased and overconfident, unbiased but going for it: How framing and anchoring affect the decision to start a new venture",Brett R.=Smith: smithbr2@miamioh.edu; Saulo=Dubard Barbosa: barbosa@em-lyon.com; Alain=Fayolle: fayolle@em-lyon.com,"Abstract
Cognitive heuristics, biases, and 
overconfidence
 have been suggested as an explanation for entrepreneurial entry. Nevertheless, empirical research on the subject has produced mixed findings and has under-explored the cognitive mechanisms leading to 
overconfidence
 in entrepreneurial settings. In two within-subject experiments, we focus on three cognitive heuristics—reference point framing, outcome salience framing, and anchoring in conjunctive events—and examine their effects on perceived risk, confidence, required and estimated probabilities of success, and the decision to start a new venture. Our findings show that reference point framing and outcome salience framing affect the decision to enter directly and indirectly via risk perception, but do not affect confidence. In addition, the effect of anchoring is contingent on the congruence between its semantic and its numeric influences. Overconfidence only obtains when the numeric and semantic influences of anchoring are aligned and aimed at enhancing the salience of potential positive outcomes, i.e., through high probabilities of success.", May 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S0883902617302987,Why and how do founding entrepreneurs bond with their ventures? Neural correlates of entrepreneurial and parental bonding,Tom=Lahti: tom.lahti@hanken.fi,"Abstract
This paper investigates why and how founding entrepreneurs bond with their ventures. We develop and test theory about the nature of bonding in a functional magnetic resonance imaging (fMRI) study of 42 subjects (21 entrepreneurs and 21 parents). We find that entrepreneurs and parents show similar signs of affective bonding, that self-confidence plays a role in bonding style, and that the degree to which entrepreneurs include their ventures in the self and to which parents include their child in the self influences their ability to make critical assessments. Our findings suggest that bonding is similar for entrepreneurs and parents and that venture stimuli influence reward systems, self-regulatory functions, and mental factors that are associated with judgment.", March 2019,"Bonding, fMRI, Entrepreneurship, Parenting, Self-confidence, Bonding style, Judgment, Neuropsychology",Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S088390261830243X,"Signaling in science-based IPOs: The combined effect of affiliation with prestigious universities, underwriters, and venture capitalists",Silvio=Vismara: Silvio.vismara@unibg.it,"Abstract
This paper studies the combined effect of affiliation with prestigious universities, underwriters, and venture capitalists on the valuation of biotech ventures at IPO and their post-IPO performance. We argue that affiliation to a prestigious university provides the affiliated firm with a quality signal in the scientific domain. The pure quality signaling effect of the affiliation is isolated from the substantive benefits it provides by performing a difference-in-difference approach based on the scientific reputation of scientists in firms' upper echelons. The signal is stronger the weaker is the scientific reputation of scientists of the focal IPO-firm and is additive to those provided by prestigious venture capitalists and underwriters. Results for a sample of 254 European biotech ventures that went through an IPO between 1990 and 2009 confirm our predictions.", January 2019,Not Found,Business Venturing,2025-03-04T00:00:00,0.0,Not Available
https://www.sciencedirect.com/science/article/pii/S2352673424000623,"Self-employment and inflammation in older adults: Examining biomarkers in the survey of health, ageing and retirement in Europe",Pankaj C.=Patel: pankaj.patel@villanova.edu; Marcus T.=Wolfe: Marcus.Wolfe@unt.edu,"Abstract
Previous studies using SHARE data explored self-employment and perceived well-being in older adults, and extending this line of prior studies, this study examines the link between self-employment and inflammation, a key biological pathway related to health and well-being. Incorporating C-reactive protein (CRP) levels from SHARE biomarker data assesses whether perceived self-reports correlate with longer-term biomarkers of well-being. Accounting for demographic, socioeconomic, health, and other biomarker variables, our findings show a non-significant relationship between self-employment and CRP levels, with no evidence of heterogeneity in effects across participants.",June 2025,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,The study does not provide significant practical value for startups or early-stage ventures in Europe.
https://www.sciencedirect.com/science/article/pii/S2352673424000635,Empirical entrepreneurial ecosystem research: A guide to creating multilevel datasets,Sophia=Hess: sophia.hess@eni.uni-stuttgart.de,"Abstract
Entrepreneurial ecosystems (EEs) are multilevel phenomena crucial for understanding and promoting productive entrepreneurship and economic development. The key insight of this study is that there is an actionable path to build and manage multilevel, longitudinal datasets for EE research, facilitating deeper insights into patterns and dynamics across different levels—often missed in single-source and cross-sectional data studies. It guides the integration of data spanning founders, firms, and socio-economic indicators from diverse sources, including archival records and self-reported data. Combining and triangulating these sources fills a significant methodological gap, supporting robust empirical EE analyses and enabling evidence-based policy formulation.",June 2025,"Entrepreneurial ecosystem, Multilevel dataset, Dataset creation, Informed policy, Longitudinal analysis",Business Venturing Insights,2025-03-08T00:00:00,6.0,The actionable path proposed for building and managing datasets for EE research can provide insights for startups and early-stage ventures in Europe.
https://www.sciencedirect.com/science/article/pii/S2352673421000159,Potential pitfalls of startup integrations: An exploratory study,Victor=Tiberius: tiberius@uni-potsdam.de,"Abstract
This paper aims to confirm pitfalls relevant in the integration stage of startup acquisitions mentioned in the literature and to identify new ones. To accomplish this, we conducted a literature review and a multiple 
case study
 with semi-structured, qualitative expert interviews. The results indicate the integration of an acquired startup may be challenged by potential pitfalls relating to acquirers or startups or a lack of their concordance. Unfavorable integration process attributes can also harm the integration success. We identified a lack of national-cultural fit and low performance of the integration team as additional potential pitfalls.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The identification of pitfalls in the integration stage of startup acquisitions is relevant for early-stage ventures, but the practical impact may vary depending on the specific context of the startups."
https://www.sciencedirect.com/science/article/pii/S2352673424000647,The myth of entrepreneurship as a tool: Reorienting business venturing as a goal in itself in a post-growth society,Wim=Naudé: naude@time.rwth-aachen.de,"Abstract
An enduring myth is of entrepreneurship as 
the
 means to the goal of economic growth. With a growing realization that perpetual economic growth and firm growth are not sustainable and violate the planet's biophysical limits, entrepreneurship should focus on contributing to a post-growth society. However, in this paper, we argue that the problems with this are twofold: one, the notions of a post-growth society are not at present compatible with entrepreneurship, and two, such an orientation continues to consider entrepreneurship as a means to a goal - in other words as a tool to fix the problems caused by excessive economic growth. In this light, we call for a de-emphasis on entrepreneurship as a means to economic growth and for more research and policies towards business venturing as a goal. Such a reorientation may also provide a basis for conceptualizing entrepreneurship in a post-growth society.",June 2025,Not Found,Business Venturing Insights,2025-03-08T00:00:00,2.0,The focus on post-growth society and de-emphasizing entrepreneurship's role in economic growth does not offer practical value for European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673424000222,Less is more? Communicating SDG orientation and enterprises' economic performance,Evelize=Culpi Mann: ec111@students.waikato.ac.nz; Narges=Safari: narges.safari@mq.edu.au; John=Oetzel: john.oetzel@waikato.ac.nz; Stuart=Dillon: stuart.dillon@waikato.ac.nz; Amanda Jasmine=Williamson: amanda.williamson@waikato.ac.nz,"Abstract
As the interest in sustainable development increases, businesses can benefit from aligning their orientation with the 
Sustainable Development Goals
 (SDGs). It remains unclear, however, how focusing on a broader or narrower set of SDGs affects enterprises' economic performance. This study examines the impact of a communicated 
SDG orientation
 on the economic performance of social 
enterprises
 and traditional commercial businesses. Using 
natural language processing
 (NLP) techniques to analyse textual content from 661 enterprises' websites, we found a positive relationship between the communication of a narrow set of SDGs and enterprises' economic performance. The extent of this effect is similar between social and traditional commercial enterprises. Therefore, stakeholders may value an enterprise's SDG orientation strategy that focuses on a narrow set of SDGs in distinct purpose-driven institutional contexts.",November 2024,"Sustainability orientation, Sustainable development goals (SDGs), Social enterprises, Economic performance, Natural language processing (NLP)",Business Venturing Insights,2025-03-08T00:00:00,7.0,The study on the impact of SDG orientation on economic performance of enterprises can offer valuable insights for startups and early-stage ventures aligning with sustainable development goals in Europe.
https://www.sciencedirect.com/science/article/pii/S2352673424000295,Campgrounds and climate change: An extreme weather event study for nature-based entrepreneurship,Christopher A.=Craig: ccraig8@murraystate.edu; Leiza=Nochebuena-Evans: lnochebuenaevans@murraystate.edu; Robert=Evans: revans@murraystate.edu,"Abstract
Entrepreneurship researchers have focused primarily on 
climate change
 mitigation. The physical effects of climate and weather on venture performance remain understudied. Accordingly, we introduce climatology to the entrepreneurship literature to quantitatively investigate the impacts of extreme weather events (i.e., tropical stormforced winds) on nature-based entrepreneurial performance. We operationalize our extreme weather event study at three coastal, entrepreneurial 
campgrounds
 that observed 12 tropical storm-forced events between 2007 and 2016. When controlling for institutional and other fixed effects, there were short-term but no long-term performance disruptions. Findings suggest adaptive and mitigative capacities are possible among nature-based entrepreneurial ventures experiencing extreme weather events. Thus, a key insight is the resilience of 
RV
 
campgrounds
 to tropical-storm forced winds, the focal weather extreme.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,The introduction of climatology to investigate the impacts of extreme weather events on nature-based entrepreneurial performance can provide some relevant insights for startups in Europe regarding resilience to such events.
https://www.sciencedirect.com/science/article/pii/S2352673424000301,Beyond local boundaries: Unraveling the spatiality of entrepreneurial ecosystems,Susann=Schäfer: susann.schaefer@uni-jena.de; Bruno=Fischer: bfischer@unicamp.br; Paola=Rücker Schaeffer: paolars@unisinos.br; Alsones=Balestrin: alsonesbalestrin@gmail.com,"Abstract
The underlying rationale of 
Entrepreneurial Ecosystems
 (EE) interactions is essentially attached to geographical space. So far, literature remains largely focused on a shortsighted notion of EE as ‘insular’ systems. In this article we address the spatial dynamics of two ecosystems based on the inflow of venture capital over the last three decades. Drawing from the cases of Tokyo and Bangalore, our key insight is that the EE configurations cannot be properly understood without a clear assessment of its spatial features. i.e., the geographical scope of connections that compose EE. As it turns out, EE present heterogeneous 
spatialities
 – and these evolve along different trajectories. This, we believe, is a key missing piece of the EE theoretical puzzle.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study addresses an important aspect of entrepreneurial ecosystems by focusing on the spatial dynamics of venture capital inflows in Tokyo and Bangalore, providing valuable insights for startups looking to understand geographical scope in ecosystems."
https://www.sciencedirect.com/science/article/pii/S2352673424000283,Healthcare entrepreneurship: An integrative framework for future research,Wiljeana J.=Glover: wjglover@babson.edu,"Abstract
Healthcare entrepreneurship is of growing interest, but the area of research is not well defined and is disparate across disciplines. We take an integrative approach to examine the similarities and differences between the literature for the two parent domains (healthcare management and entrepreneurship). We present findings from an interdisciplinary four-phase 
Delphi study
 and propose a new framework to guide future research. Our proposed healthcare entrepreneurship framework not only reflects variations in key factors, such as actors, activities, processes and outcomes within the parent disciplines, but also suggests gaps, connections and future opportunities for research.
Actionable summary and highlights
Since COVID-19, there has been an influx of healthcare entrepreneurial ventures, but, within a volatile market, mixed success. We find that healthcare entrepreneurship is different from work in healthcare or entrepreneurship alone. For healthcare entrepreneurs to achieve their targeted health outcomes as well as their operational and profitability outcomes, all stakeholders need to work together. For the clinician-turned-entrepreneur and the serial entrepreneur now in healthcare, we provide three actionable insights to address some of the practical challenges in healthcare entrepreneurship.
1.
We advise that venture teams include individuals from both entrepreneurship and healthcare backgrounds to shorten the learning curve, particularly as they develop the evidence base for the offering. Contacting entrepreneurship accelerators or university tech transfer and commercialization offices for which one may have had previous affiliations can be one approach to securing such team members.
2.
Healthcare entrepreneurs should consider how to include end-user or patient participation to create new healthcare solutions. Working with relevant patient advocacy groups can be one approach and may help to increase the relevance and patient-centeredness of the solution.
3.
Healthcare entrepreneurs may need to develop new business models and revenue streams. While healthcare is a human right, it requires financing to sustain offerings. One may strengthen one's “business and calling” 
mindset
 via joining healthcare entrepreneurship organizations for medical professionals, accelerators, and other local programs that support such entrepreneurial engagement in healthcare.
In addition to these insights for healthcare entrepreneurs, we include practical insights for other key actors. Corporations may incentivize partnerships that normalize co-produced innovations. Venture capitalists might develop novel funding mechanisms linked to non-traditional outcomes. Non-profit organizations can serve as interdisciplinary conveners to raise awareness of healthcare entrepreneurship needs. Policy makers might consider ways to create business environments with competitive, yet reasonable, cost and pricing structures.",November 2024,"Healthcare entrepreneurship, Interdisciplinary, Integrative literature review, Delphi study",Business Venturing Insights,2025-03-08T00:00:00,9.0,"The framework proposed for healthcare entrepreneurship offers actionable insights and guidance for entrepreneurs, clinicians, venture teams, and other stakeholders, making it highly relevant and practical for the European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S2352673424000313,Sustaining spontaneous venturing in response to the global refugee crisis,Mohamed=Farhoud: mohamed.farhoud@uni.lu,"Abstract
Spontaneous venturing plays a prominent role in alleviating suffering in limited-term crises. Yet, when crises endure over time, it may become necessary to transition spontaneous ventures into sustained ventures to effectively address persistent needs. In this rapid response paper, we collaborated with a problem owner to investigate five sub-problems associated with the core problem of transitioning from spontaneous to sustained venturing in the context of the global refugee crisis. Using a 
translational research
 approach in entrepreneurship, we suggest answers to the five identified sub-problems grounded in existing evidence from perspectives in the entrepreneurship literature (contextualization, volunteering, community-based organizing, and venture legitimacy). We further synthesize the solutions that can help motivate and structure sustained collective efforts to address endured crises and highlight key implications for the broader community that aspires to address persistent crises.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The research on transitioning spontaneous ventures into sustained ventures in the context of global crises provides some insights that may be applicable to startups facing challenges in long-term sustainability, albeit with a more limited direct impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673424000337,Timing and pricing of micro-acquisitions: A Perspective from effort justification theory,Zahra=Jamshidi: zahra.jamshidi@ucalgary.ca; Mohammad=Keyhani: mkeyhani@ucalgary.ca,"Abstract
Micro-acquisition marketplaces are a recent phenomenon in the world of entrepreneurship that facilitate the matching of buyers and sellers of relatively small-scale startups or pre-startup projects. Unlike traditional acquisitions, in micro-acquisition markets, sellers typically decide on the timing and offset an initial asking price for the deal. However, cognitive biases are likely to interfere with these decisions and lead to suboptimal decisions that prevent efficient matching. We argue that the age of a project at the time of listing can act as a proxy for the time and effort that has been spent by the entrepreneur to develop the project. Building on effort justification and 
cognitive dissonance theories
, we argue that there is a curvilinear relationship between project age and price; and that this relationship is moderated by the level of revenue achieved by the project at the time of listing. Using data from 
Acquire.com
, we find empirical support for these patterns indicating that entrepreneurs may justify a higher price because of higher effort up to a certain threshold, and especially for higher revenue projects.",November 2024,"Micro acquisition, Startup acquisition, Startups marketplace, Effort justification, Cognitive dissonance",Business Venturing Insights,2025-03-08T00:00:00,4.0,"The study on micro-acquisition marketplaces, while interesting, may have a more limited practical value for European early-stage ventures as it focuses on a specific niche within the entrepreneurship landscape."
https://www.sciencedirect.com/science/article/pii/S2352673424000349,Theorizing MacGyver: Entrepreneurial action in the face of environmental turbulence,Matthew L.=Metzger: mmetzger@uccs.edu,"Abstract
Sometimes, entrepreneurial action is driven by necessity. Whether global pandemics, climate change, or the oxygen system failure in Apollo 13, time-constrained and high-stakes decisions increasingly confront entrepreneurs and managers. Yet, our literature tends to favor intendedly rational and practiced approaches to entrepreneurial action in the face of perceived uncertainty. This study views entrepreneurial action from the other side of the mirror – imposed opportunities (not created), high time pressure, and limited resources (no trove access to resources and an inability to leverage contingencies). Using a mixed-methods approach and drawing upon data from the empirical setting of professional chefs and discourse from popular media, we explore these unique forms of entrepreneurial action through the lens of MacGyvering – a term developed from a 1980's hit television show where seemingly impossible odds and idiosyncratic challenges are routinely overcome. Our findings suggest that MacGyvering does not map neatly onto any single established concept of entrepreneurial action. Instead, it integrates some aspects of effectuation, causation, bricolage, and improvisation while explicitly adapting and eschewing others. Our insights can help entrepreneurs and managers act expeditiously to create new value in the face of environmental turbulence.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The exploration of entrepreneurial action driven by necessity, time pressure, and limited resources provides valuable insights for startups facing challenging environmental turbulence, offering alternative perspectives on entrepreneurial approaches."
https://www.sciencedirect.com/science/article/pii/S2352673424000362,Breaking bad? Playing the fool and constructing the ‘bad researcher’ in entrepreneurship,Richard T.=Harrison: r.harrison@ed.ac.uk,"Abstract
How to deal with grand challenges and the crisis of knowledge production and their implications for entrepreneurial research and practice is a topic of growing interest. In this paper we argue that we need to rethink who is involved in entrepreneurship research and how that research is conducted and communicated. This begins by moving beyond the traditional ostensible objective separation of the ‘researcher’ from the ‘research subject’ to adopt a posthuman and post-qualitative inquiry perspective that questions the dominant position of the human subject and challenges the humanistic belief in the essential, conscious and intentional human as the primary source of agency. As such, it adopts a process ontology, stresses hybridity and difference and encourages experimentation. This requires us to become ‘bad researchers’, undertaking subversive research that goes beyond the oppositions of quantitative/qualitative and foundationalist/non-foundationalist. In this we take the ‘fool’ (jester, trickster) as our guide. Historically associated with inversion, usurping authority and putting down the mighty the fool is a liminal character who has the duty to ask all those questions that no one else dares to ask. The paper concludes with suggestions as to how this may inform a re-newed entrepreneurship for the crisis-laden twenty first century.",November 2024,"Entrepreneurship, Posthumanism, Post-qualitative inquiry, Crises, Knowledge production, ‘Bad’ research, The fool/trickster, Administration and heuristic of fear",Business Venturing Insights,2025-03-08T00:00:00,2.0,The abstract focuses more on theoretical concepts and does not provide practical value or impact for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673424000386,Designing effective policies for innovative start-ups: Lessons learned in Italy,Diego=Matricano: diego.matricano@unicampania.it,"Abstract
Supporting the implementation and growth of innovative start-ups to bring innovation to the market and foster local development, in terms of economic and social results, is on the agenda of policymakers worldwide. The latters constantly identify new specific tools, define more focused actions, and – in some cases – enact dedicated policies (local or national laws) in order to push individuals to start entrepreneurship processes.
In this regard, the Italian Start-up Act is worth mentioning since it stands for the first-ever national law, enacted in 2012, promoting and regulating innovative start-ups. Ten years after the enactment of the Italian Start-up Act, it is interesting to assess its impact and evaluate whether and to what extent it succeeds in bringing innovations to the market and fosters local development in Italy. The results of several previous studies – which look at the same sample of start-ups, but from different perspectives – are collected and compared in order to offer a broad overview and a comprehensive evaluation of this law.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The abstract highlights the implementation and impact of a specific national law promoting innovative start-ups, which can have significant practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673424000398,The dawn of geographically unbounded entrepreneurial ecosystems,David B.=Audretsch: daudrets@indiana.edu; Antje=Fiedler: a.fiedler@auckland.ac.nz; Benjamin=Fath: b.fath@auckland.ac.nz; Martie-Louise=Verreynne: m.verreynne@uq.edu.au,"Abstract
Entrepreneurial ecosystems (EEs) that support entrepreneurship are seen as tightly spatially bound, top-down systems. They are exogenous to entrepreneurs but endogenous to the jurisdiction's policymakers and other powerful stakeholders. Taking a knowledge spillover theory approach, this paper offers a new perspective on these systems that better fits the globalized, digitalized, and increasingly geographically unbounded realities of entrepreneurship. Resources and knowledge increasingly harbor synergies across, not just within, the spatial bounds of EEs. We describe geographically unbounded EEs (UEEs) as border-spanning, entrepreneur-centered, and hybrid or digital community-centered. These structures support entrepreneurs in assembling knowledge and resources across multiple geographically bounded EEs. We identify four interrelated dimensions of UEEs, namely, resources provided, inclusiveness, spread of activities, and governance, and show how each varies among geographically bounded EEs. The key insight of our study is that UEEs create conditions where the EE becomes increasingly endogenous to the entrepreneur. Such a shift prompts new theoretical questions about entrepreneurial capabilities and the role of policy.",November 2024,"Endogenous growth, Entrepreneurial ecosystems, Knowledge spillover, Digitalization",Business Venturing Insights,2025-03-08T00:00:00,6.0,"The abstract introduces a new perspective on entrepreneurial ecosystems that can be beneficial for start-ups, but lacks specific actionable insights for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S235267342400043X,No substitute for strong institutions: Impact of accelerators on new venture performance,Pramendra Singh=Tank: phd21pramendrat@iima.ac.in; Dibyendu=Sharma: dibyendu.sharma@gim.ac.in; Divyanshu=Jain: phd21divyanshuj@iima.ac.in,"Abstract
Accelerators are gaining popularity in the entrepreneurship ecosystem for accelerating new ventures by providing benefits such as learning, sorting, and signaling. However, theoretical tension exists about whether these benefits are contingent on quality of institutions. The institutional-void view suggests that accelerator benefits are more pronounced in countries with weak institutions, while the institutional-support view posits the importance of strong institutions for realizing the benefits of accelerators. In this study, we theorize and test the moderating role of institutions in assessing the impact of accelerators on new venture performance using a generalized difference-indifferences technique on a worldwide accelerator database. At the baseline, the findings are consistent with previous literature, which shows a positive impact of accelerators on new ventures performance. More importantly, the key insight of our study is that the positive impact of accelerators is higher in countries with stronger institutions, thus favoring the institutional-support view. These findings contribute to emerging empirical research that assesses the impact of business accelerators on new venture performance.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The abstract explores the role of institutions in the impact of accelerators on new venture performance, which can provide valuable insights for early-stage ventures operating in different institutional contexts."
https://www.sciencedirect.com/science/article/pii/S2352673424000404,"Infrastructure required, skill needed: Digital entrepreneurship in rural and urban areas",Christian=Bergholz: christian.bergholz@thuenen.de; Lena=Füner: lena.fuener@zew.de; Moritz=Lubczyk: ml@rfberlin.com; Rolf=Sternberg: sternberg@wigeo.uni-hannover.de; Johannes=Bersch: johannes.bersch@gmail.com,"Abstract
In this paper, we study the spatial implications of digital entrepreneurship. Leveraging detailed micro-data on the universe of new venture formations in Germany between 2011 and 2018, we illustrate regional determinants of digital entrepreneurship. Unlike conventional entrepreneurship, digital entrepreneurship demonstrates sustained growth rates throughout this time period, highlighting the policy importance of understanding the drivers of digital ventures’ location choices. The key insight of our study is that digital entrepreneurship requires both digital infrastructure and highly-skilled human capital. If both are present, digital entrepreneurship can flourish in rural areas, even if digital venture formations generally concentrate in urban centers.",November 2024,"Digital entrepreneurship, Highly skilled, Rural regions, Urban regions, Digitalization",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The abstract delves into the spatial implications of digital entrepreneurship, emphasizing the importance of digital infrastructure and human capital, which can be valuable for early-stage ventures considering their location choices."
https://www.sciencedirect.com/science/article/pii/S2352673424000428,Learning from Yesterday: Predicting early-stage startup success for accelerators through content and cohort dynamics,Morteza=Zihayat: mzihayat@torontomu.ca,"Abstract
As the demand for seed accelerators grows, so does the complexity of their evaluations of numerous startup applications. This paper introduces a novel two-phase data-driven framework for startup performance prediction. Phase 1 extracts founding team-level and venture-level features applicable to early-stage startups for success prediction. Phase 2 further engineers cohort-level features to predict the success of accelerator-admitted startups. We demonstrate the utility of our framework by leveraging machine learning methods coupled with real-world data of 35,647 startups (accelerator intakes: 763). We achieve high predictive accuracy and produce explainable results. We make methodological contributions to startup competitor detection and industry categorization. The key insight of our study is that member success largely depends on cohort-level features such as shared industries with different members and industry similarity to the accelerator's past portfolio.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The framework proposed in this abstract can have a significant impact on early-stage startups by predicting success and providing valuable insights. The methodology and findings contribute to the field of startup evaluation.
https://www.sciencedirect.com/science/article/pii/S2352673424000416,Innovative yet Costly: The dual role of bricolage in new venture internationalization,Hana=Milanov: hana.milanov@tum.de; Stephanie A.=Fernhaber: sfernhab@butler.edu; Siri=Terjesen: sterjesen@fau.edu; Stefan=Ruehl: stefan.ruehl@tum.de,"Abstract
While emerging evidence suggests that bricolage may contribute to new venture internationalization by helping overcome situations of resource scarcity, the limitations or “dark side” of bricolage have been overlooked. We present a competitive mediation framework, in which bricolage is hypothesized to have both (1) a positive effect on new venture internationalization through innovativeness and international aspirations, as well as (2) a negative effect through operating costs and international aspirations. Using a sample of 344 Australian new ventures from the four-year longitudinal CAUSEE study, the results support our hypotheses. Over time, however, the negative effect dissipates and only the positive mediated effect remains. Our work contributes quantitative evidence of competing mediation mechanisms to largely exploratory research on bricolage and internationalization and answers calls for longitudinal examinations of new venture internationalization. In doing so, we join a broader conversation on the complex relationship between bricolage and new venture outcomes and point out opportunities for further research on new venture internationalization.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study provides valuable insights into the positive and negative effects of bricolage on new venture internationalization. While the findings are interesting, the practical application for startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673424000441,Stars everywhere: Revealing the prevalence of star performers using empirical data published in entrepreneurship research,Kaushik=Gala: kgala@iastate.edu,"Abstract
Scholars have long called for moving beyond a narrow focus on average performance toward a more direct investigation of the variance in performance. While a few studies have evaluated 
star entrepreneurs
, most empirical research continues to focus on average performers. This lacuna has constrained not only the development of theories but also the accumulation of data on the distribution of performance. In response, this study uses simulations and heuristics to extract distributional information from descriptive statistics commonly reported in published research (i.e., mean, standard deviation, and sample size). Applying this approach to studies recently published in high-impact entrepreneurship journals shows that (a) the suggested methodology can provide rough estimates of the skew and shape of performance distributions, and (b) right-skewed, heavy-tailed distributions featuring star performers are ubiquitous in entrepreneurship, thus reinforcing calls for more direct studies of performance distributions in entrepreneurship.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"While the focus on performance distributions in entrepreneurship is important, the practical implications for early-stage ventures may be less direct. The methodology used in this study contributes to theoretical development but may have limited immediate impact on startups."
https://www.sciencedirect.com/science/article/pii/S2352673424000465,Exploring inclusivity in entrepreneurship education provision: A European study,Colette=Henry: Colette.henry@dkit.ie; Wendy=Wu: w.wu2@napier.ac.uk; Kare=Moberg: kaare@ffefonden.dk; Slavica=Singer: singer@efos.hr; Barbara=Gabriel: Barbara.gabriel@ua.pt; Robertt=Valente: robertt@ua.pt; Carolina=Carlos: carolinacarlos@ua.pt; Nick=Fannin: n.fannin@napier.ac.uk,"Abstract
This paper explores inclusivity in entrepreneurship education (EE) provision. This is an important area of research given the growth in EE provision globally and the intention for it to be a discipline and a competence accessible to everyone. Drawing on data from nine European Higher Education Institutions (HEIs) and their respective entrepreneurship programs, our core research question asks: 
how inclusive are European entrepreneurship education programs, and how might their inclusivity be enhanced?
 Answering this question could help raise awareness of the need for inclusive EE, identify specific student cohorts who are potentially excluded and help widen EE participation generally. We contribute to the existing body of literature in this field by underscoring the significance of inclusivity in EE programs, proposing an adapted version of an existing inclusivity-proofing tool as a first step for HEIs on their inclusivity journey and offering insights designed to bolster HEIs' EE inclusivity efforts.",November 2024,"Entrepreneurship education, Inclusivity, Gender, Ethnicity, SDGs, GEET+",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The exploration of inclusivity in entrepreneurship education programs is relevant and important for promoting diversity and accessibility in the field. The recommendations provided can help institutions improve their programs and reach a wider range of students, including those from underrepresented backgrounds."
https://www.sciencedirect.com/science/article/pii/S2352673424000490,Mirror neurons and neuroplasticity: The dyadic neurological foundations bridging entrepreneur-level and enterprise-level capabilities,Vaneet=Kaur: vkaur@kent.edu,"Abstract
The paper bridges the contours of neuroscience and entrepreneurship to unveil the neuronal path to transfigure entrepreneur-level capabilities into enterprise-level capabilities without holding a priori assumptions about serendipity or application of the aggregation principle. It reveals that neural mechanisms through which efforts of entrepreneurs are aggregated and exploited at the enterprise level—mirror neuron system and neuroplasticity—do not represent a fortuity, but conscious endeavors on the parts of both entrepreneurs and the enterprise to bridge these distances. In doing so, this paper explains how the brains of various entrepreneurial actors can be trained like muscles, and how they can achieve bio-behavioral synchrony to facilitate such neurochemical changes in their brain wiring that induce cognitive, affective, and conative aspects of opportunity identification, opportunity exploitation, and successful reconfiguration, which are essential for an entrepreneurial brain. Moreover, the paper demonstrates how mirror neuron system can become the gateway to neuroplasticity and how this cross-modal matching can assist entrepreneurial actors in developing their capabilities. The conceptual framework proposed explains how entrepreneurial actors, and consequently, the enterprise, can move towards a more plastic mode of operation, one that helps disrupt the brain's homeostasis to achieve enterprise plasticity, and ultimately develop robust enterprise-level capabilities.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The integration of neuroscience and entrepreneurship is innovative and offers a unique perspective on entrepreneurial capabilities. However, the practical application of this conceptual framework for European early-stage ventures may be challenging, reducing its immediate impact."
https://www.sciencedirect.com/science/article/pii/S2352673424000489,Supporting refugees: An entrepreneurial resourcefulness approach,Hans=Rawhouser: hans.rawhouser@unlv.edu,"Abstract
This rapid research paper seeks to aid Lighthouse Charities (LC), a Las Vegas-based refugee-sponsoring organization. Rather than channeling all refugees toward entrepreneurship, LC utilizes a two-pronged entrepreneurial resourcefulness approach. LC creates refugee-focused work integration social enterprises (WISEs) and also supports refugee clients as entrepreneurs. While LC helps many refugees with this approach, LC seeks a more systematic lens (versus a trial-and-error approach) to understand and adjust to the limits of using an ER approach. Experts from three theoretical perspectives (trauma exposure, identity adjustment, and entrepreneurial failure) provide theoretically informed insights into how LC can systematically adjust the ER approach to help refugees by 
matching
 resources to opportunities, 
modifying
 existing resources to potential opportunities, and 
transitioning
 away from resourcefulness.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The research focuses on a practical approach to helping refugees through entrepreneurship, providing insights for organizations like Lighthouse Charities in a systematic manner."
https://www.sciencedirect.com/science/article/pii/S2352673424000532,Pitch envisaging: The role of narrative transportation in pitching success,Clinton T.=Purtell: clinton.purtell@unt.edu,"Abstract
How are entrepreneurs able to optimize their ability to persuade angel investors to commit resources? Narrative transportation theory suggests that familiar elements of a story can change an audience's perceptions of, and attitudes about, the opportunity by influencing their cognition. When experiencing the effects of narrative transportation, individuals are “transported” into the story and begin to accept the narrative world as created by the story in lieu of personal knowledge, experiences, or real-world facts. In an entrepreneurship context, we posit that if investors are narratively transported through a familiar pitch narrative, they may envisage a favorable outcome of what is pitched and adapt the opportunity in their minds with the result of, ultimately, committing resources. The findings from our study of investors who watched and reported on multiple pitches suggest that cognitive processes induced by narrative transportation explain the relationship between familiarity and entrepreneurial opportunity adaptation, which—in turn—increase the likelihood of angels' resource commitment. The key insight of our study reveals that when the investors are mentally transported into the story contained within a pitch narrative, they will be more likely to adapt the opportunity and more likely to commit their resources.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study offers valuable insights on how entrepreneurs can persuade angel investors through narrative transportation theory, potentially influencing resource commitment."
https://www.sciencedirect.com/science/article/pii/S2352673424000544,The significance of entrepreneurs’ physical health for venture distress and exit,Johan=Wiklund: jwiklund@syr.edu; Holger=Patzelt: patzelt@tum.de; Mirjam=Knockaert: Mirjam.Knockaert@UGent.be; Yasmine=Van Heghe: Yasmine.Van.Heghe@UGent.be,"Abstract
Although the entrepreneurship literature has extensively examined the mental health of entrepreneurs, there has been a notable lack of focus on entrepreneurs’ physical health. This exploratory study aims at understanding the importance of physical health issues for venture distress, in comparison to other issues, such as mental health concerns. Furthermore, it investigates the extent to which entrepreneurs faced with physical health issues are more or less likely to (in)voluntarily exit their ventures. Particularly, we examine 1752 entrepreneurs in distressed ventures in the Flemish region of Belgium over the period 2016–2019. We find that physical health issues are linked to venture distress, and entrepreneurs in distressed ventures tend to attribute venture distress more to physical rather than mental health issues. Furthermore, entrepreneurs dealing with physical health issues are much more likely to exit their ventures, often involuntarily, rather than continuing to manage them. This research provides important contributions to both the entrepreneurial health and entrepreneurial exit literatures, and practical implications for entrepreneurs, support providers and public policymakers.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study sheds light on the link between physical health issues and venture distress, offering practical implications for entrepreneurs and policymakers."
https://www.sciencedirect.com/science/article/pii/S2352673424000568,We're in it for the long haul: How corporate venture capital helps alleviate financial market frictions in social entrepreneurship,Joseph J.=Cabral: jcabral@lsu.edu; Shane W.=Reid: shanereid@txstate.edu; Reginald=Tucker: reg@ou.edu,"Abstract
The financing of social entrepreneurship is a noted challenge. The scale of problems and potential solutions are daunting, and the time required for solutions to come to fruition often involve investment horizons that are too long for traditional investors. Using an exploratory case study of the energy industry we provide evidence that industry incumbents are one potential solution to help alleviate the market coordination problem inherent to financing social ventures. As a going concern, we find that corporate investors exhibit temporal benevolence and can provide investment horizons necessary for solutions to be developed and diffused. At the same time, commitment from an incumbent brings resource predictability that encourages others in the value chain to engage with social ventures that show promise. In this regard incumbents are able to participate in their industry's evolution while providing an underappreciated role in supporting the social entrepreneurship ecosystem.",November 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The research explores how industry incumbents can help in financing social ventures, providing potential solutions to the challenge of social entrepreneurship funding."
https://www.sciencedirect.com/science/article/pii/S2352673424000581,Time to say goodbye? Exploring the entrepreneurial transition to retirement,Simon=Stephens: simon.stephens@atu.ie,"Abstract
This study presents the experiences of entrepreneurs who are approaching the end of their careers and what society defines as working life. This topic is a significant gap in the literature and existing terms used to describe retirement do not accurately capture the retirement considerations of entrepreneurs. A series of two interviews were conducted with fifteen entrepreneurs, all of whom are within five years of the state defined retirement age. Analysis of the data from the 30 interviews supports the identification of four types of entrepreneurial approach to retirement. Each of the four types will approach retirement differently, depending on their experience as an entrepreneur and factors external to business such as financial and family circumstances. The recognition that there are distinctive aspects to the retirement decisions of entrepreneurs, challenges our established theoretical understanding of the end of working life, creating a multitude of research questions that form an important research agenda within entrepreneurship.",November 2024,"Career, Identity, Push-pull factors, retirement, Work-life balance",Business Venturing Insights,2025-03-08T00:00:00,4.0,"The study addresses a gap in the literature regarding entrepreneurs approaching retirement, highlighting different approaches that can influence retirement decisions."
https://www.sciencedirect.com/science/article/pii/S2352673423000689,Beyond the IPO horizon: Understanding the determinants and consequences of IPO withdrawal,Jarrod=Humphrey: humphreyj5@xavier.edu,"Abstract
Withdrawn IPOs remain an empirically underexplored topic. Between 1997 and 2021, approximately 1 in 6 IPOs attempted on the NASDAQ and NYSE were withdrawn, collectively amounting to hundreds of billions of dollars in unrealized growth capital. For entrepreneurial ventures, the strategic consequences of the withdrawal decision are severe. My findings indicate that withdrawn IPOs face a considerable delay in subsequent attempts to enter public markets, alongside a substantial reduction in total offer proceeds. Crucially, the JOBS Act in 2012 marks a pivotal inflection in the public markets, significantly reducing the incidence of IPO withdrawals and altering the course of financing strategies for emerging growth companies. I argue that an integrated recognition of both withdrawal activity and the regulatory dynamics of the JOBS Act is crucial for a complete understanding of the evolving IPO landscape. Moreover, I examine firm and CEO attributes that correlate with the withdrawal decision and discuss how withdrawal activity presents a fertile ground for future research.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The study on withdrawn IPOs and the impact of regulatory changes is highly relevant and valuable for understanding financing strategies for startups.
https://www.sciencedirect.com/science/article/pii/S2352673424000593,Reimagining entrepreneurship in the Anthropocene through a multispecies relations approach,Bastian=Thomsen: bastian.thomsen@anthro.ox.ac.uk,"Abstract
This article extends the entrepreneurship literature by presenting a multispecies lens that attends to the rights, agency, and welfare of nonhumans in the ecological and climate change crises. It responds to calls for rethinking entrepreneurship beyond anthropocentrism, integrating insights from multispecies studies and philosophical ethology. The multispecies lens framework amalgamates humans and nonhumans as equal partners in entrepreneurial endeavors. Based on seven years of field research, including over 200 interviews, participant observation, and archival data, the article uses meta-ethnographic analysis to synthesize findings from four related multispecies studies and develop a line-of-argument analysis. Three themes showcase how multispecies relations can be reconciled in theory and practice: 1) community engagement and environmental education, 2) the interdependency of species through One Welfare, and 3) organizing for intrinsic value over profit. These themes shape the multispecies lens in entrepreneurship framework, offering a foundation for scholars and practitioners to consider nonhumans as 
equal partners
 within capitalist endeavors. The article concludes with recommendations for fostering equitable multispecies partnerships in entrepreneurship, if it's not already too late given the dire circumstances of the Anthropocene.",November 2024,"Multispecies relations, Posthumanism, Multispecies studies, Philosophical ethology, Regenerative entrepreneurship",Business Venturing Insights,2025-03-08T00:00:00,8.0,The focus on multispecies partnerships in entrepreneurship offers a unique perspective and potential new avenues for collaboration and innovation in startups.
https://www.sciencedirect.com/science/article/pii/S2352673424000453,"A primer to new space business - Beyond “Business in space: The new frontier” (Goodrich, Kitmacher and Amtey, 1987)",Sebastian H.=Fuchs: shfuchs@tec.mx,"Abstract
The purpose of this article is to serve as a primer and gateway to contemporary developments around New Space as an entrepreneurial phenomenon. Despite its media-presence, commercial space activity in Low Earth Orbit (LEO) has been mostly absent from the management literature. We use considerations that Goodrich et al. had voiced in 
Business Horizons
 in 1987 with their piece “Business in Space: The New Frontier” to pick up on earlier thinking around venturing into space, update highlighted themes, and go beyond those. Our article follows the structure set out in 1987 and covers the current state of space commercialization, obstacles to space commercialization, opportunities in space, marketing and managerial implications, and concludes with research avenues. We find that entrepreneurship in space is currently in a phase overcoming many of the previously voiced obstacles, embracing the opportunities that space offers beyond catering to government agencies as main clients. We call this contemporary period for space Transition Space, which is situated between Old government-driven and venture-driven New Space. We argue that space is a critical new context not only for entrepreneurial activity but for entrepreneurship research as well. Our article contributes to the nascent space management literature.",November 2024,"Space management, Space business, Low Earth Orbit, New Space",Business Venturing Insights,2025-03-08T00:00:00,6.0,"The exploration of entrepreneurship in space presents interesting insights, but the practical application to early-stage ventures in Europe may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000653,Crowdfunding and too much choice: A recipe for disappointment,Ramy=Elitzur: elitzu@rotman.utoronto.ca,"Abstract
In this study, we investigate the effects of reward options and their prices on crowdfunding success. Rational economics predicts that the more choice potential contributors have, the more likely it is that they find a reward option that stimulates participation. However, experiments in behavioral economics and marketing show that providing someone with excessive choice (overchoice) might adversely affect participation. Using data collected from Kickstarter, a well-known crowdfunding website, we demonstrate the existence of the overchoice phenomenon in the context of crowdfunding, i.e., an inverted U-shaped relationship between reward options and crowdfunding performance.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"The study on the effects of reward options on crowdfunding success is relevant, but the impact on European early-stage ventures may be moderate."
https://www.sciencedirect.com/science/article/pii/S2352673423000641,How do impact investors leverage non-financial strategies to create value? An impact-oriented value framework,Pola=Nachyła: pola.nachyla@positiongreen.com; Rachida=Justo: rachida.justo@ie.edu,"Abstract
One of the ways to understand the success of 
impact investing
 firms is to examine how they add value to the social 
enterprises
 they invest. Did their investment boost social and/or environmental change? And what type of support, beyond financial capital, can they provide to enhance impact? Drawing on a design-based methodology, we seek to address some of these questions by developing a tool called the Impact Oriented Value Framework. Putting impact at the centre of the funds' purpose, the framework provides actionable solutions to infuse impact into investors’ non-financial support strategies and activities, enhancing their additionality to portfolio companies as well as their contribution to the impact ecosystem.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The development of the Impact Oriented Value Framework provides actionable solutions for impact investing firms, which can be beneficial for European startups focused on social and environmental impact."
https://www.sciencedirect.com/science/article/pii/S2352673423000665,Outlier entrepreneurs: Nonlinear paths and novel ventures,G. Christopher=Crawford: GCrawford@ut.edu; Christian=Linder: Christian.Linder@Skema.edu; Christian=Lechner: CLechner@Luiss.it; Elisa=Villani: E.Villani@Unibo.it,"Abstract
Outliers in entrepreneurship are founders who are markedly different—both quantitatively and qualitatively—relative to the “normal” population. We use a power law perspective to hypothesize that, in order for new ventures to persist, founders with outlier endowments are more likely to have novel expectations about the opportunities they pursue and greater variation in the execution methods they employ, while normal founders are more likely to have much lower expectations and engage in a manner that is confined to fit within the smaller scope of explicit market demand. We leverage data from the Panel Study of Entrepreneurial Dynamics II, a longitudinal 
representative sample
 of 1214 nascent entrepreneurs organizing resources in preparation for startup, and employ 
fuzzy set
 qualitative comparative analysis to investigate our hypothesized relationships. In support, the results suggest that founders need to stay in their lane for their ventures to persist: whereas outlier founders have the option to successfully pursue more ambitious opportunities—those that are innovative, growth-oriented, and international focused—normal founders are primarily resigned to niche opportunities. Even more interesting, ventures are much less likely to persist when there is a misalignment between endowments, expectations, and engagement (i.e., when outlier founders pursue niche opportunities and normal founders pursue aspirational opportunities). This study makes meaningful contributions to the power law perspective, to the growing interest in outliers and exceptionality in entrepreneurship, and to the domain’s aggregated knowledge of new venture persistence.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study on outliers in entrepreneurship offers insights into founder characteristics, but the direct impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000719,Beyond the paradigm of literacy – Developing a research agenda in entrepreneurship,Pia=Arenius: arenius@em-lyon.com; Anna-Katharina=Lenz: lenza@miamioh.edu,"Abstract
Illiteracy, the lack of ability to read and write, affects how people engage with entrepreneurship and the possible outcomes of 
entrepreneurial actions
. Yet entrepreneurship as a discipline has paid little direct attention to illiterate entrepreneurs. We offer a glimpse of what recognition of illiteracy in entrepreneurship research might enable, and how it can challenge researchers to reach beyond our existing knowledge horizons to develop a future of impactful, integrative, and inclusive entrepreneurship scholarship.",June 2024,"Literacy, Illiterate entrepreneur, Entrepreneurial context, Entrepreneurial action",Business Venturing Insights,2025-03-08T00:00:00,4.0,"While addressing illiteracy in entrepreneurship research is important for inclusivity, the practical impact on early-stage ventures might be limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000744,Entrepreneurial ecosystems as multiteam systems: Navigating independence and interdependence in the leadership of startup communities,Philip T.=Roundy: philip-roundy@utc.edu; W.=Randy Evans: randy-evans@utc.edu,"Abstract
Entrepreneurial ecosystem
 (EE) leadership is the orchestration of multiple groups to influence the effectiveness of an EE. Although singular leaders can influence ecosystems, EE leadership rarely works alone. EE leaders often function in interconnected groups from different organizations and are in the unique position of simultaneously leading their organizations (leadership within EEs) while providing leadership to the ecosystem itself (leadership of EEs). However, it is not clear how EE leadership groups work 
independently
 on their respective goals and 
interdependently
 on the superordinate goal of coordinating effective EEs. To address the lack of theory to explain this inherent characteristic of ecosystems, we adapt insights from group dynamics to develop a multi-level model of EEs as multiteam systems. We explain how EE teams devote attention to organizational and ecosystem leadership, identify four EE archetypes produced by different attentional configurations, and discuss how our main insight—effective EEs are multiteam systems—can change how scholars and practitioners view EEs.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"Exploring EE leadership in interconnected groups provides insights, but the direct impact on startups may not be immediate."
https://www.sciencedirect.com/science/article/pii/S2352673423000756,A tale of two impacts: Entrepreneurial action and the gender-related effects of economic policy uncertainty,David M.=Townsend: dtown@vt.edu; Richard A.=Hunt: rickhunt@vt.edu; Parul=Manocha: pmanocha@uab.edu; Maximilian=Stallkamp: mstallkamp@vt.edu,"Abstract
The underlying 
intents
 and long-lasting impacts of economic policies are not only significant drivers of the quantity and productiveness of 
entrepreneurial action
 but also its diversity, equitability, and breadth. Calibrating policies to achieve these varied aims is a persistent challenge, due in no small part to the complex role uncertainty plays in entrepreneurship. While extant research has shown that both too much and too little uncertainty stifles 
entrepreneurial action
, other studies have revealed that policy remedies and interventions themselves are often an important cause of uncertainty by reshaping and redefining the ‘rules of the game’ in unexpected ways. As such, the general importance of 
economic policy uncertainty
 (EPU) is well established, yet little work has been undertaken to identify and explicate its heterogenous impacts on entrepreneurial action. This gap constitutes a material hindrance to the field's ongoing efforts to better align entrepreneurship research with grand social challenges. One of these challenges relates to the long-standing impediments to gender-based fairness and equity. By investigating the differential impacts of EPU on entrepreneurial action among men and women, our findings bring to light the extent to which EPU heterogeneously shapes the experiences and outcomes of female and male entrepreneurs.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"Investigating the impact of economic policy uncertainty on entrepreneurial action, especially considering gender disparities, has practical implications for startups."
https://www.sciencedirect.com/science/article/pii/S2352673424000027,Governing decentralized autonomous organizations as digital commons,Sen=Li: lis23@rpi.edu; Yan=Chen: ychen5@stevens.edu,"Abstract
Effective governance plays a pivotal role in aligning the interests of diverse stakeholders and shaping the strategic directions of organizations. However, the dominant model of 
corporate governance
 often concentrates power among a limited group of directors, leading to concerns about potential 
power imbalances
 that may distort fair representation and compromise decision-making integrity. Decentralized autonomous organizations (DAOs) present an alternative model that distributes power among a broader base of stakeholders, fostering a more democratic approach to 
collective decision making
 and governance. However, the openness and fluidity inherent in DAOs can expose them to coordination challenges, governance complexities, and potential exploitation by malicious entities. In response to possible governance challenges, we consider DAOs as digital commons and adapt Ostrom's eight principles for governing the commons to propose a new 
governance framework
 for DAOs. This 
governance framework
 is designed to foster the collective 
stewardship
 of shared 
digital assets
 and the equitable distribution of decision-making authority in the Web3 era. As DAOs emerge as a novel 
organizational structure
, our governance framework aims to maintain their resilience, inclusiveness, and decentralization, reinforcing their crucial role in the evolving Web3 landscape.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"Proposing a new governance framework for DAOs is innovative, but the immediate impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000768,Under the weight of heavy tails: A power law perspective on the emergence of outliers in entrepreneurship,G. Christopher=Crawford: GCrawford@UT.edu; Harry=Joo: yjoo01@udayton.edu; Herman=Aguinis: haguinis@gwu.edu,"Abstract
A fundamental discovery in entrepreneurship is that firm outcomes do not follow a symmetrical 
Gaussian
 curve. Instead, most are heavily right-skewed distributions in which a few extreme outliers (e.g., rock star firms like Airbnb, Tesla, and Uber) account for a disproportionate amount of the output. Although past research usually described outcome distributions as shaped following the power law, our study asks the following question: 
What other less extreme distributions of generalizable firm outcomes exist in entrepreneurship?
 Our investigation leverages four representative datasets from the U.S., Europe, and Australia, comprising 32 samples with about 22,000 ventures. We implemented a precise data-analytic approach that compares each sample (i.e., empirical distribution) against multiple theoretical distribution shapes to identify the best fit. Results showed that, across nearly all samples, the pure power law was not the dominant distribution. Instead, the annual revenue distribution is shaped as a power law with an exponential cutoff, and the number of employees distribution is shaped lognormally. Combined, these suggest the existence of top-down limitations on the highest performing firms. Accordingly, we offer an agenda for future research focused on (a) identifying and releasing systemic constraints, (b) examining and falsifying the underlying generative mechanisms that cause the emergence of heavy-tailed distributions and the outliers therein, and (c) conducting multi-level, mixed-method studies to investigate how micro-level interactions aggregate into macro-level heavy-tailed distributions. Our paper makes significant contributions to the power law perspective and future efforts to explain and predict the emergence of rock star firms in entrepreneurship.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study provides insights into different distributions of firm outcomes in entrepreneurship, offering potential for future research on systemic constraints and generative mechanisms."
https://www.sciencedirect.com/science/article/pii/S2352673424000015,Entrepreneurship and subjective wellbeing in China: Exploring linkages and potential channels,Quanda=Zhang: q.zhang@federation.edu.au,"Abstract
We analyse the effect of entrepreneurship on subjective 
wellbeing
 in China. To do so, we use four waves of the nationally representative China Family Panel Studies (CFPS) longitudinal survey data. Employing a suite of quasi-experimental analytical procedures, we find that being an entrepreneur increases subjective wellbeing in China. Our estimates suggest that being an entrepreneur results in a 0.46 
standard deviation
 higher subjective wellbeing than not being an entrepreneur. This finding is robust to different quasi-experimental methods. We also find that entrepreneurship enhances subjective wellbeing more among males and rural residents. Results on mediation analysis suggests that social and economic status are important channels through which entrepreneurship influences subjective wellbeing.",June 2024,"Entrepreneurship, Subjective wellbeing, Socioeconomic status, China",Business Venturing Insights,2025-03-08T00:00:00,6.0,"The analysis on the effect of entrepreneurship on subjective wellbeing in China is valuable, but the findings may not have significant practical implications for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673424000039,What is in a [poverty] label? The effect of regional poverty labeling in the Appalachian region of the U.S. and self-employment,Pankaj C.=Patel: pankaj.patel@villanova.edu; R. Gabrielle=Swab: rswab@georgiasouthern.edu,"Abstract
Extending the growing amount of literature on poverty and entrepreneurship, we draw on stereotype threat theory to test whether labels of regional poverty categories, 
controlling for regional GDP
, influence engagement in self-employment. In using the county designations of at-risk, attainment, competitive, distress, or transitional provided by the Appalachian Regional Commission, the County Business Patterns, Business Dynamics Statistics, and Startup 
Cartography
 Project, we find no significant differences in regional entrepreneurial activity among labels. However, in the individual-level analysis using CPS-ASEC two-wave longitudinal data, the findings show that those residing in counties labeled as at-risk counties, relative to attainment counties, had lower odds of being self-employed. These findings at regional and individual levels show stereotype threat may not aggregate to the regional level, but may manifest at the individual level. The findings have implications for stereotype threat based on government-identified regional labels of relative economic standing.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"The study on stereotype threat and regional poverty labels could have limited direct relevance to European early-stage ventures, as it focuses on individual and regional levels rather than broader entrepreneurial trends."
https://www.sciencedirect.com/science/article/pii/S235267342400009X,Family business successions between desire and reality,André=Pahnke: pahnke@ifm-bonn.org; Susanne=Schlepphorst: schlepphorst@ifm-bonn.org; Nadine=Schlömer-Laufen: schloemer@ifm-bonn.org,"Abstract
Family business successions are commonly considered as one of the most critical events of any family business. Yet, despite extensive research, current evidence on the actual extent to which family business owners accomplish, adapt, or even abandon their initial succession plans is astonishingly still lacking. This paper addresses this issue by overcoming some methodological limitations of previous research on family business successions. The results provide robust insights into a wide mismatch between desire and reality regarding family business succession planning. Thus, transgenerational continuation of family businesses should not be taken for granted. A considerable proportion of business owners abandon their initial succession plans, do not realize the succession in the intended timeframe, or close their business ultimately. There is also a remarkable number of unintended business transfers which have received little attention in research to date.",June 2024,"Family business, Succession, Business closure, Worker flows",Business Venturing Insights,2025-03-08T00:00:00,5.0,"The research on family business successions, while important, may not directly impact European early-stage ventures as it focuses on family businesses and succession planning rather than broader entrepreneurship trends."
https://www.sciencedirect.com/science/article/pii/S2352673424000106,Beyond words: How visual imagery shapes collaborative sensemaking in entrepreneurial ecosystems,Bernd=Wurth: bernd.wurth@glasgow.ac.uk; Suzanne=Mawson: s.mawson@strath.ac.uk,"Abstract
Entrepreneurial ecosystems (EEs) are complex social systems dependent on connectivity and shared understanding between diverse actors. An often used, albeit oversimplified view, implies that diverse actors connect, collaborate and contribute to the EE in an almost frictionless way. However, this perspective overlooks the need for deeper forms of communication that can shift actors' perceptions, goals and motivations to trigger meaningful change. Recent research has highlighted the role of conversations, narratives and stories in developing (informal) institutions and shared understandings. What is missing from this discussion, however, are non-verbal forms of communication, which enable interpretation, support meaning-making and help implementation. This paper draws on communicative institutionalism theory and empirical observations from a larger participatory action research project. We discuss how visuals support richer interpretation of ambiguities, different perspectives and collaborative sensemaking. Images act as boundary objects enabling creative associations, revealing assumptions and catalysing explorative dialogue through inherent ambiguity. Representing complex concepts visually facilitates participant engagement over time. The co-creative process of iterative illustration also captures shared meaning as it emerges. Implications highlight visuals’ potential for fostering future-oriented dialogue, reflective practice and embodied institutions fundamental for EEs. From this, we outline suggestions for further research and practice.",June 2024,"Entrepreneurial ecosystems, Entrepreneurship as practice, Collaborative sensemaking, Communicative institutionalism, Visual imagery",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study on the role of visuals in entrepreneurial ecosystems provides valuable insights into communication and institutional development, offering potential strategies for fostering dialogue and shared understanding among diverse actors."
https://www.sciencedirect.com/science/article/pii/S2352673424000118,"Pivot, persist or perish? Knowledge problems and the extraordinarily tight boundary conditions of entrepreneurs as scientists",David M.=Townsend: dtown@vt.edu; Richard A.=Hunt: rickhunt@vt.edu; Daniel A.=Lerner: Daniel.Lerner@ie.edu; Katrina M.=Brownell: kmb00540@marshall.usc.edu,"Abstract
The characterization of entrepreneurs as scientists (EaS) has become increasingly popular among management scholars because it fits neatly with existing theories of 
entrepreneurial action
 grounded in the assumption that entrepreneurs form and test beliefs in an intendedly rational fashion, under conditions of uncertainty, while continually seeking to obtain and process new information. Recent scholarship breathes new life into the EaS paradigm by proposing a framework that builds upon pragmatism in developing a microfoundational perspective concerning causally inferential action and rationality-based heuristics. Yet, the drift towards EaS is not without controversy. Business venturing is rarely analyzable through the lens of natural laws and orderly structures. Moreover, uncertainty is not the only knowledge problem (KP) that entrepreneurs confront. As such, EaS may be ineffective in bringing resolution to these other challenging KPs – ambiguity, complexity, and equivocality – especially when entrepreneurs are entertaining decisions to pivot or persist. In this sense, our work underscores the importance of EaS while also asserting the need for clear boundary conditions.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the discussion on the characterization of entrepreneurs as scientists is interesting, the abstract does not provide clear practical value or impact for early-stage ventures or startups in Europe."
https://www.sciencedirect.com/science/article/pii/S235267342400012X,Slowed by commitment and hastened by obstacles: Exploring patterns of entrepreneur role exit in the EPOP dataset,Douglas R.=Ewing: dewing@bgsu.edu,"Abstract
Empirical understanding of why individuals become former entrepreneurs is not well-established. This investigation draws upon Identity Theory and Role Exit Theory to explore patterns in Entrepreneurship in the Population (EPOP) Survey Project dataset. The key finding is a theory-consistent tension between commitment and obstacles encountered in predicting exit from the entrepreneur role. The likelihood of being a former entrepreneur is decreased by surrogate indicators of commitment such as having a business as primary personal income source. The likelihood is increased by proximal obstacles such as low levels of familial support. These patterns persist after statistical control for a wide swath of demographic and business characteristics. Based on these observed patterns, avenues for future research and implications for entrepreneurs, educators, and policymakers are considered.",June 2024,"Entrepreneur role, Role exit, Identity theory, Commitment, Obstacles, Logistic regression",Business Venturing Insights,2025-03-08T00:00:00,7.0,"Understanding patterns and predictors of former entrepreneurs can provide valuable insights for early-stage ventures in Europe on how to navigate challenges and increase commitment. The implications for entrepreneurs, educators, and policymakers make this abstract relevant."
https://www.sciencedirect.com/science/article/pii/S2352673424000088,Take my word for it! The role of projected certainty signaling and certainty alignment in reward crowdfunding outcomes,Bright=Frimpong: bfrimpong@wlu.edu,"Abstract
Crowdfunding has emerged as a pivotal mechanism for entrepreneurs and innovators to source capital directly from a diverse audience of backers. Our study analyzes the nuanced impact of projected certainty signaling on the success of crowdfunding campaigns. We argue that the degree of certainty conveyed in project descriptions has a curvilinear influence on project success. We underscore the importance of the consensus on this projected certainty being shaped by interactions between founders and backers. Our study has several implications for founders, backers, and platforms by offering valuable insights for enhancing crowdfunding strategies and interactions toward positive outcomes.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"Analyzing the impact of certainty signaling on crowdfunding success can offer actionable insights for European startups looking to launch successful campaigns. The implications for founders, backers, and platforms can directly benefit early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673424000131,"Dopamine and entrepreneurship: Unifying entrepreneur personality traits, psychiatric symptoms, entrepreneurial action and outcomes",Daniel A.=Lerner: Daniel.Lerner@ie.edu; Michael=Freeman: mfreeman.md@berkeley.edu; Andreas=Rauch: arauch@audencia.com,"Abstract
Research conducted over the last three decades confirms that dopaminergic 
personality traits
 (Openness, Extraversion and the Industriousness aspect of Conscientiousness) are prominent among entrepreneurs. We highlight the continuum between dopaminergic traits, dimensions, temperaments, symptoms and 
psychiatric conditions
 (bipolar spectrum conditions, ADHD, substance and 
behavioral addictions
, and OCPD) among entrepreneurs, and how behavioral manifestations of this continuum affect entrepreneurial action. Despite the pathological potential, the connection with some favorable outcomes of dopaminergic traits and psychiatric conditions suggests that atypical dopamine physiology may be one biomarker of the 
neurodiversity
 that distinguishes, empowers and endangers entrepreneurs. By showing the dopaminergic underpinnings of traits, dimensions, symptoms and conditions among entrepreneurs, we offer a unifying framework that contextualizes findings within the construct of dopaminergic differences – a framework that integrates otherwise isolated findings about the 
personality traits
 and psychiatric conditions of entrepreneurs. In other words, the neurodiversity biomarkers and bio-psycho-social characteristics found among entrepreneurs often reflect a polygenic endophenotype that features atypical dopamine physiology.",June 2024,"entrepreneurship, dopamine, personality, clinical symptoms, psychiatric conditions, psychophysiology, neurodiversity, mental health, bipolar spectrum conditions, ADHD, addiction, OCPD, entrepreneurial action",Business Venturing Insights,2025-03-08T00:00:00,6.0,"While the connection between dopaminergic traits and entrepreneurs is intriguing, the abstract focuses more on personality traits and psychiatric conditions rather than practical implications for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673424000167,The future in the mirror and behind it: Scientists and more,Dimo=Dimov: d.p.dimov@bath.ac.uk,"Abstract
This paper argues that the framework of entrepreneurs-
as
-scientists, portraying entrepreneurs as tasked with making precise and reliable inferences, and expressed in certain mathematical language, trivializes entrepreneurial practice. I highlight the challenges that arise from replacing the abstract notations of mathematical language with names from ordinary language of entrepreneurship. Co-opting of ordinary language for mathematical purposes distorts our understanding of business ideas, venture development, and entrepreneurial processes. At stake are different conceptions of the future. One creates the future within language, the other accepts that the future lies outside of language as an untameable realm of perpetual novelty.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"The abstract discusses the challenges of portraying entrepreneurs as scientists and using mathematical language in entrepreneurship. While thought-provoking, the practical impact on European early-stage ventures is not clearly defined."
https://www.sciencedirect.com/science/article/pii/S2352673424000192,"Nurturing neighborhoods, cultivating local businesses: The effects of amenities-to-infrastructure spending on new business licenses in Chicago's wards",Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Based on public choice theory, this study examines how the relative focus on amenities-to-infrastructure spending is associated with the concentration and the subsequent volume of new business licenses. Using data from the Aldermanic Menu Program and business license records in Chicago, the key insight from our study suggests a ""seeding and spreading"" effect, where increased amenities-to-infrastructure spending is associated with a less diverse distribution of new business licenses, but that in turn, is associated with an increase in the overall volume of new businesses licenses in the following period. The effect sizes are small. The study contributes to the literature on 
urban economics
 and entrepreneurship by extending the concept of amenity-focused public spending.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study provides some insight into urban economics and entrepreneurship, but the effect sizes are small and the practical value for European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673424000210,From disastrous heat waves to extreme rains: Effects of weather shocks on entrepreneurship,Johan=Wiklund: jwiklund@syr.edu; Sefa=Awaworyi Churchill: sefa.churchill@rmit.edu.au; Musharavati Ephraim=Munyanyi: munyanyi@iuw.uni-hannover.de; Trong-Anh=Trinh: Trong-Anh.Trinh@monash.edu,"Abstract
Using household panel data from the Household, Income and Labour Dynamics in Australia (HILDA) Survey and satellite re-analysis temperature and rainfall data, we present the first study to examine the impact of weather shocks on entrepreneurship. We measure temperature and rainfall shocks at the postcode level, and find that an increase in weather shocks in the previous period is associated with a decline in the probability of self-employment in the next period. We find suggestive evidence that health, cognitive functioning and economic activity are mechanisms through which temperature shocks transmit to entrepreneurship. The key insight of this study is that it is less likely that those directly affected by climate events will act entrepreneurially, at least in the short run.",June 2024,"Weather, Temperature, Rainfall, Shocks, Self-employment, Entrepreneurship",Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study examines the impact of weather shocks on entrepreneurship which could have relevance for European startups. The findings suggest a decline in self-employment with weather shocks, providing some practical value."
https://www.sciencedirect.com/science/article/pii/S2352673424000234,Entrepreneurship education as first-person transformation: Interiority as an operationalizing mechanism,Kisito F.=Nzembayie: kfutonge@tcd.ie; David=Coghlan: dcoghlan@tcd.ie,"Abstract
The case for repositioning 
entrepreneurship education
 (EE) as first-person transformation in classrooms envisioned as spaces for practical reasoning, has lately received significant scholarly attention. This case aligns with a broader need to generate more impactful learning outcomes that accurately reflect the nature of the entrepreneurship phenomenon. Notwithstanding, how a theory-praxis nexus results in first-person transformation remains underdeveloped. Accordingly, this paper advances 
interiority
 as an operationalizing mechanism for developing entrepreneurship as first-person transformation. Thus, we contribute to shifting the focus of learning from what we know, to how we know in a process of intellectual self-awareness. We then offer a conceptual framework that connects three realms of knowing: practical, relational, and theoretical, with interiority as the fulcrum. We discuss how this approach contributes to impactful entrepreneurial learning, seen through the emergence of entrepreneurial 
mindsets
 in reflective student practice.",June 2024,"Entrepreneurship, Education, Interiority, First-person, Mindset, Practice",Business Venturing Insights,2025-03-08T00:00:00,7.0,The paper suggests a new approach to entrepreneurship education that could contribute to impactful learning outcomes. The focus on developing entrepreneurial mindsets through practical reasoning and theoretical frameworks could be beneficial for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673423000690,"Whatever the problem, entrepreneurship is the solution! Confronting the panacea myth of entrepreneurship with structural injustice",Jan=Keim: jan.keim@bfh.ch; Susan=Müller: susan.mueller@bfh.ch; Pascal=Dey: pascal.dey@bfh.ch,"Abstract
A topic of growing interest in entrepreneurship research is how entrepreneurial ventures address grand challenges. This literature, we argue, tends to produce a panacea myth by suggesting that entrepreneurship is the universal remedy for existing social and environmental ills. Starting from the claim that the persuasive power or ‘stickiness’ of the panacea myth depends not only on what it explicitly says (in terms of ideas and beliefs) but also on what it leaves out, we suggest that the exclusion of explicitly political and holistic explanations of grand challenges such as Iris Marion Young's theory of structural injustice, which we use as an illustrative example, precipitates a ‘constitutive absence’ whose mythic function is to sanitize the image of entrepreneurship as the preferred solution to grand challenges. In an effort to denaturalize the panacea myth, we first identify three ‘figures of thought’ – coined ‘extrapolation fallacy,’ ‘political agnosticism,’ and ‘positive acculturation’ – that define the content of the panacea myth while simultaneously excluding theoretical concepts and frameworks, such as structural injustice, that conceptualize grand challenges as structural, multidetermined, and inherently political problems that are not necessarily amenable to stand-alone 
entrepreneurial approaches
 and solutions. Second, to loosen the grip of the panacea myth, we suggest rethinking entrepreneurship research in terms of who is involved, what methods are used, and how we talk about it. Taken together, these tactics create an opening in entrepreneurship research for a more complexity-sensitive and political understanding of grand challenges that cultivates a more humble and realistic depiction of entrepreneurship's problem-solving capacity.",June 2024,"Entrepreneurship, Structural injustice, Grand challenges, Panacea myth, Analytical myopia",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The paper challenges the panacea myth surrounding entrepreneurship as the solution to grand challenges. By suggesting a more complex and political understanding of entrepreneurship, it provides a valuable perspective for European startups facing societal and environmental issues."
https://www.sciencedirect.com/science/article/pii/S2352673424000064,Unpacking the myth of the entrepreneurial state,Peter Kalum=Schou: peter.k.schou@bi.no,"Abstract
The idea of The Entrepreneurial State, a state that acts as an entrepreneur, creating and shaping markets to solve certain missions, has captured the eye of the public and of scholars. Yet, a number of scholars have voiced critique of The Entrepreneurial State Paradigm, arguing that it leads to policy failure. But simultaneously, other scholars argue that policy failures stem from interpretation and poor implementation, rather than core ideas in The Entrepreneurial State, such as mission-oriented policies. In this paper, I seek to clarify this debate. I argue that the growing reports of mission-oriented policy failures are due to three factors nested in The Entrepreneurial State Paradigm. They are 1) Disregard of the role of private entrepreneurship; 2) Encouraging policy makers to disregard limits to government action, and 3) Extrapolating grand policies from limited results. Thus, I argue that registered policy failures do not stem merely from bad policy making or incorrect interpretations of The Entrepreneurial State Paradigm. They stem directly from this paradigm. Consequently, I argue that scholars and policy makers should move away from The Entrepreneurial State and instead focus on the enabling role of the state.",June 2024,"The entrepreneurial state, Innovation policy, Science commercialization, External enablement",Business Venturing Insights,2025-03-08T00:00:00,7.0,The paper clarifies the debate on The Entrepreneurial State Paradigm and argues for a shift in focus towards the enabling role of the state. This discussion could provide valuable insights for European early-stage ventures navigating government policies and support.
https://www.sciencedirect.com/science/article/pii/S2352673424000076,A long and winding road: The hard graft of scaling social change in complex systems,John=Healy: john.healy@genio.ie; Jeffrey=Hughes: jeffrey.hughes@durham.ac.uk; Gemma=Donnelly-Cox: gdnnllyc@tcd.ie; Amanda=Shantz: amanda.shantz@unisg.ch,"Abstract
Advice abounds on how to implement large-scale social change, much of which emphasizes a simplistic 
linear process
, led by a heroic central actor. Rigorous 
case studies
 have shown that social change is far more complex: it is a reciprocal, iterative, and adaptive process, with multiple stakeholders who work backstage in networked, committed teams. Despite this, the myth of the social entrepreneur as a transformative change maker capable of scaling innovations to a societal level, still holds sway over social innovation support programmes and business school curricula. Using illustrative examples of successful efforts of large-scale social change across three of the most pressing international social challenges: access to medicines, the integration of migrant populations, and reorganizing social care models, we illustrate how conceptualizing social change as driven by iconic individuals is often counter-productive in terms of achieving impact at a societal level. Based on these analyses, we present five insights which illustrate how the mythology of social entrepreneurship and simplistic scaling concepts are often contrary to the practices employed within successful efforts to bring about social impact. Three counteracting principles for those leading, evaluating and funding innovative change efforts within complex systems are discussed and contrasted with the pervasive mythology of social entrepreneurship and linear scaling processes.",June 2024,"Myths, Social innovation, Entrepreneurship, Scaling, Complex systems",Business Venturing Insights,2025-03-08T00:00:00,7.0,"This abstract challenges the myth of the social entrepreneur and provides insights on achieving societal impact, which can be valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673424000052,Community markets and entrepreneurship: A primer,Jeffrey A.=Chandler: jeffrey.chandler@unt.edu; Jeremy C.=Short: jeremy.short@unt.edu; Marcus=Wolfe: marcus.wolfe@unt.edu,"Abstract
An increasing number of popularly frequented, but lightly studied, entrepreneurial events such as farmer's markets, festivals, art walks, night markets, and other seasonal gatherings occur regularly as forms of community meetups worldwide. At these events, individuals strive to create and enhance their communities through a series of often loosely organized gatherings that combine art, entertainment, and entrepreneurial promise. These events are associated with small business owners or hobbyists that sell their wares to a location-based market often searching for goods and services viewed as at least somewhat unique from other mainstream offerings. These events are critical for entrepreneurs as they serve as a vehicle to expand their customer base, build awareness for their products and brands, and even test out new product offerings in their local markets. Building knowledge of these events and the entrepreneurs that fuel such gatherings provides an opportunity to bridge the gap between ‘what we know’ and ‘what we aspire to know’ about these common entrepreneurial activities. Inspired by the notion of ‘thick descriptions’ in the qualitative tradition, we hope to inspire such grounded thinking and detail several community events taking place in the culturally vibrant community of Denton, Texas.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"While the information on entrepreneurial events is interesting, the practical value for startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673424000155,What makes universities build academic spin-offs more successfully? A theory-based triangulation of quantitative studies based on meta-analyses,Kyootai=Lee: kyootai@sogang.ac.kr; Hyun Ju=Jung: hyunju.jung@kaist.ac.kr,"Abstract
In recent decades, quantitative studies on university spinoffs (USOs) have begun to proliferate across disciplines. This study aims to systematically consolidate the measures used in the extant USO research into theoretical constructs, and connect the constructs to the 
entrepreneurial ecosystem
 (EE) perspective. In doing so, this study examines the effect of university-level characteristics on the number of USO establishments and USO performance; it also evaluates measurement validities that can reflect constructs. The 
systematic review
 and thematic coding reveal four groups of 14 constructs from the measures identified in prior studies: university general characteristics, university research characteristics, university entrepreneurial characteristics, and technology transfer office characteristics. Our meta-analyses indicate that the relationships between the constructs and USO outcomes are generally significant, thereby providing evidence of the convergent and nomological validities of the measures. Research design has a limited impact on the relationships, but country moderates several relationships between university characteristics and USO outcomes. Following our meta-analytic review, we explain the contribution to university entrepreneurship ecosystem research and suggest a theoretically triangulated model for future studies.",June 2024,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study on university spinoffs provides insights into the entrepreneurial ecosystem, which may have some relevance but may not be directly applicable to early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673423000380,An opportunity to profit from recent entrepreneurship theory,Jeffery S.=McMullen: mcmullej@indiana.edu; Stratos=Ramoglou: s.ramoglou@soton.ac.uk,"Abstract
We offer a brief rejoinder to a recent critique published in the Journal of Business Venturing Insights. We look past the unprofessional tone of the critique to seek opportunities to clarify the positions we took in our work and to explain the motivations behind them. We do so by articulating seven questions worthy of clarification. We conclude our rejoinder with a discussion about the ludicrous notion of a “secret formula” for publishing novel theory and offer a few words of encouragement to other theorists interested in more constructive endeavors, such as building conceptual foundations for our field",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,The brief rejoinder to a critique does not offer significant practical value or impact on European early-stage ventures or startups.
https://ieeexplore.ieee.org/document/9145558/,A Review of Face Recognition Technology,,"Face recognition technology is a biometric technology, which is based on the identification of facial features of a person. People collect the face images, and the recognition equipment automatically processes the images. The paper introduces the related researches of face recognition from different perspectives. The paper describes the development stages and the related technologies of face recognition. We introduce the research of face recognition for real conditions, and we introduce the general evaluation standards and the general databases of face recognition. We give a forward-looking view of face recognition. Face recognition has become the future development direction and has many potential application prospects.",21 July 2020,"Face recognition, Face, Principal component analysis, Feature extraction, Support vector machines, Machine learning, Biological neural networks, Face Recognition, Facial Recognition Technology, Real Conditions, Facial Features, Face Images, Biometric Technologies, Neural Network, Training Data, Deep Learning, Convolutional Neural Network, Support Vector Machine, Dimensionality Reduction, Performance Of Algorithm, Deep Models, Facial Expressions, Linear Discriminant Analysis, Generative Adversarial Networks, Non-negative Matrix Factorization, Recognition Effect, Face Detection, Scale-invariant Feature Transform, Gabor Filters, Face Recognition Task, AdaBoost Classifier, Non-ideal Conditions, Facial Shape, Artificial Features, Face Position, Face Recognition Performance, Video Surveillance, Face recognition, image processing, neural network, artificial intelligence",IEEE Access,2025-03-17T00:00:00,6.0,"The abstract provides an overview of face recognition technology and its potential applications, which could be relevant for startups working in the biometric or security sectors. However, it lacks specific details or actionable insights for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673423000677,An exploratory look at the role of ownership in initial coin offerings (ICO): Different audiences and ICO success,Serhan=Kotiloglu: skotiloglu@csusm.edu; M. Paola=Ometto: pometto@csusm.edu,"Abstract
Initial coin offering (ICO) is a Web-3 based financing method for ventures, which allows them to use digital assets (e.g., tokens) to raise capital. During an ICO, the entrepreneur has control on ownership; they can choose to issue a very small number of tokens which would allow them to keep “their skin in the game” and retain ownership, or issue all the tokens they hold, which would distribute ownership to investors and have a community-decentralized orientation. While previous literature has identified several factors of ICO success, they have not delved into the role of ownership in ICO success. In this study, we explore whether retaining or distributing ownership during an ICO is more beneficial for raising capital. We find a two-pronged explanation. When looking at ICOs maintaining a higher level of ownership, entrepreneurs are catering to corporate-market logic investors, and we see a U relationship where the optimal percentage in which the entrepreneurs show they have skin in the game at the same time as giving enough to investors. But then, there are ICOs distributing most of its ownership in which entrepreneurs are attracting community-oriented investors, and as such, the higher the distribution the higher the investment. We propose that this is related to how there are different investors audiences’ that will value different practices and ideals and choose differently on what types of projects to invest in. Our research elucidates this new funding source. Nonetheless, future research should investigate these exploratory findings.",June 2024,"ICO, Web3, Exploratory research, Audiences, Performance, Ownership, Institutional logics, Funding",Business Venturing Insights,2025-03-08T00:00:00,6.0,The study on initial coin offerings and ownership in ICO success could be valuable for startups looking into funding options and strategic decision-making.
https://www.sciencedirect.com/science/article/pii/S2352673423000276,Creation of the entrepreneurial personality scale: Removing conceptual and empirical barriers from the study of personality and entrepreneurship,Matt C.=Howard: MHoward@SouthAlabama.edu,"Abstract
The goal of the current article is to address systematic barriers that hamper modern research on Entrepreneurial Personality (EP). We provide conceptual clarity to the meaning of EP, which we conceptualize with the dimensions of innovativeness, risk-taking propensity, 
achievement orientation
, 
proactiveness
, 
locus of control
, self-efficacy, and 
autonomy
 orientation. We also formalize two competing perspectives regarding EP's relations with relevant outcomes; the Pillar Conceptualization proposes that EP produces consistent relations with relevant outcomes, whereas the Wheel Conceptualization proposes that EP produces varying relations that depend on the specific phase of the entrepreneurial process. Then, we develop the Entrepreneurial Personality Scale (EPS) using five samples (total 
n
 = 1877), which include samples of general participants and samples of solely entrepreneurs. We show that the EPS produces appropriate 
psychometric
 and validity evidence across both types of samples, strongly supporting its use in future research. We also show that the EPS dimensions produce varying relations with relevant outcomes, which were determined by the phase of the entrepreneurial process – supporting the Wheel Conceptualization. Via these efforts, future researchers can investigate EP with greater confidence in their theoretical rationale and methodological soundness by applying the EPS. The Wheel Conceptualization is also a promising lens to understand EP moving forward, and a clear future direction for research is to integrate novel temporal theories and frameworks to add nuance to this perspective.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"This abstract addresses systematic barriers in researching Entrepreneurial Personality, offering a scale and insights that can be beneficial for startups in understanding key traits."
https://www.sciencedirect.com/science/article/pii/S2352673423000288,"Mirror, mirror—A gendered lens on female entrepreneurs’ facial attractiveness in reward-based crowdfunding",Benedikt David Christian=Seigner: b.seigner@lmu.de; Hana=Milanov: hana.milanov@tum.de,"Abstract
Scholars investigating women's attractiveness have documented its disadvantages (the “beauty is beastly” effect), especially in male-typed domains, including entrepreneurship. However, reward-based crowdfunding research demonstrates that these platforms reverse gender biases typically found in traditional entrepreneurial 
finance
. Thus, in reward-based crowdfunding, the adverse effect of women's attractiveness needs to be re-examined. In a sample of 7447 Kickstarter projects, we find that facial attractiveness increases funding success for women more than for men and that 
sex differences
 in attractiveness effects are greater in male-typed categories like technology. A post-hoc reveals a surprising attractiveness penalty for men in the technology sector and offers insights for future research.",November 2023,"Gender stereotypes, Facial attractiveness, Reward-based crowdfunding, Entrepreneurial finance, Women's entrepreneurship",Business Venturing Insights,2025-03-08T00:00:00,8.0,The research on reverse gender biases in reward-based crowdfunding and the impact of women's attractiveness in male-typed categories like technology can provide valuable insights for European early-stage ventures and startups looking to secure funding.
https://www.sciencedirect.com/science/article/pii/S2352673423000331,I wasn't expecting that: How engaging with digital platforms can turn leisure passion into entrepreneurial aspirations,Donato=Cutolo: donato.cutolo@ie.edu; Rosa=Grimaldi: rosa.grimaldi@unibo.it,"Abstract
Online digital platforms are rapidly emerging as new avenues for business activities,opening up a plethora of opportunities for aspiring entrepreneurs. These platforms offer a range of resources and incentives that empower passionate users to showcase and cultivate their skills within online communities, creating a platform for these users to transform into producers and entrepreneurs in the digital economy. However, existing research on entrepreneurial passion has neglected the role of leisure passion in shaping entrepreneurial aspirations. This study explores this relationship by analyzing the activities of 20,538 users on YTTalk forum, the largest digital community for YouTubers, from September 2011 through March 2020. Leveraging the Linguistic Inquiry and Word Count (LIWC) software, we propose a novel methodological approach that utilizes language to infer passion. Our findings reveal leisure passion is not directly conducive to entrepreneurship, yet entrepreneurial aspirations materialize when passionate users become cognizant of the positive attention and recognition they receive from other users on the platform, providing them with the impetus to monetize their content and harness the value they generate for others.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The exploration of the relationship between leisure passion and entrepreneurial aspirations on online digital platforms can offer useful perspectives for European startups looking to leverage their skills and resources within digital communities.
https://www.sciencedirect.com/science/article/pii/S2352673423000343,Integrating entrepreneurial and spiritual identities under uncertainty,Richard J.=Arend: richard.arend@maine.edu,"Abstract
This empirical study begins to explore the complex connections between entrepreneurs, spirituality and uncertainty, grounded in the theoretical, even existential, relationships among these elements. Specifically, our contribution consists of a novel analysis and discussion of the interplay between entrepreneurial and spiritual personal identities in uncertain contexts. We consider three related research questions: Does spirituality moderate the relationship between entrepreneurship and comfort 
under decision uncertainty
? Does it in terms of making specific economic choices under uncertainty? And, reciprocally, does entrepreneurship moderate the relationship between spirituality and dealing with uncertainty? Our analysis draws upon survey data of non-naïve respondents, including entrepreneurs. We find that two separate personal identities interact in very different and significant ways even within same context. We also find that identity integration ‘over feelings’ differ from those ‘over decisions’ in the same context, contributing to the affect-rationality debate in entrepreneurial cognition.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study on the interplay between spirituality, entrepreneurship, and uncertainty provides interesting insights that can be beneficial for European entrepreneurs navigating uncertain contexts and seeking identity integration."
https://www.sciencedirect.com/science/article/pii/S2352673423000410,B Corp certification in the age of fast fashion: Using hierarchical clustering and correspondence factor analysis to highlight social entrepreneurial advancement in the fashion industry,Jeremy C.=Short: jeremy.short@unt.edu; Marcus=Wolfe: marcus.wolfe@unt.edu; Stephanie B.=Escudero: stephanie.escudero@uta.edu; Iva=Jestratijevic: Iva.Jestratijevic@unt.edu,"Abstract
To highlight the potential mechanisms heterodox actors use to create meaningful change within established sectors, we examine how B Corps in the fashion industry overcome institutionalized standards of social and environmental mistreatment. Using hierarchical clustering and correspondence factor analysis we provide a content analysis on the self-descriptions of 102 fashion B Corps. We discover that B Corps in the fashion sector focus their social entrepreneurial efforts on their product design, business design, and auxiliary activities to achieve the high standards of social and environmental impact required to obtain B Corp status. Post hoc analysis further distinguishes the foci of B Corps from those of their (non-B Corp) competitors. We discuss the implications of this work for the study of entrepreneurial nonconformism and social entrepreneurship and identify fruitful directions for future research.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The examination of how B Corps in the fashion industry create meaningful change through social entrepreneurship efforts can be inspiring and informative for European early-stage ventures looking to make a positive impact within established sectors.
https://www.sciencedirect.com/science/article/pii/S2352673423000392,Processing preferences and crowdfunding pitch evaluations,C.S. Richard=Chan: Richard.Chan@stonybrook.edu; Manoj=Mahajan: Manoj.Mahajan@stonybrook.edu; Annaleena=Parhankangas: aparhank@gmail.com,"Abstract
We investigate how processing preferences (i.e., individual tendencies for attending to and utilizing different types of information) influence the evaluation of crowdfunding campaigns. We illustrate that a preference for analytical processing may lead to less favorable evaluations, while a preference for heuristic processing or affective processing may result in more favorable evaluations. A randomized correlational study generally supports these predictions, and also pinpoints areas for future research.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,"The study provides insights into how processing preferences influence the evaluation of crowdfunding campaigns, but the practical value for European early-stage ventures is limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000409,"Visions of futures and futures of visions: Entrepreneurs, artifacts, and worlds",Dimo=Dimov: d.p.dimov@bath.ac.uk; Henrik=Berglund: henber@chalmers.se,"Abstract
In a recent effort to develop the individual-opportunity nexus, Ramoglou and McMullen (2022) argue that extant conceptualizations of opportunities fail because they reify opportunities by engaging in “thing-talk”. Their proposed alternative ignores concrete things by reinterpreting the nexus in terms of confident entrepreneurs (who imagine world-states) and world-states (that are possible or not). But, regardless of formulation, the dualistic nexus framework fails to account for the creative aspects of entrepreneurship and places impossible demands on the concept of opportunity. A triadic view of entrepreneurs, artifacts, and worlds transcends the distinction between “thing-talk” and “confidence-talk” as central to an unambiguous scholarly use of opportunity language. Acknowledging artifacts as tangible interfaces between entrepreneurial confidence and real-world conditions also prompts a reevaluation of what Ramoglou and McMullen (2022) term “entrepreneurial work”, calling for an approach that duly acknowledges its creative, artifact-centered, and indeed world-making character.",November 2023,"Entrepreneurship, Opportunities, Possibilities, Artifacts, Design",Business Venturing Insights,2025-03-08T00:00:00,5.0,"The abstract discusses a new perspective on the individual-opportunity nexus in entrepreneurship, which could potentially impact the way opportunities are conceptualized for startups."
https://www.sciencedirect.com/science/article/pii/S2352673423000422,What does AI think of AI as an external enabler (EE) of entrepreneurship? An assessment through and of the EE framework,Per=Davidsson: per.davidsson@ju.se; Muhammad=Sufyan: msufyan@jyu.fi,"Abstract
Recent breakthroughs make Artificial Intelligence (AI) technology a particularly potent enabler of entrepreneurship. Therefore, we use the External Enablement (EE) framework to examine AI’s potentials as enabler of entrepreneurship. In doing so, we involve AI – specifically ChatGPT 4.0 – to enhance the analysis beyond our personal limitations. Through this exercise we provide insights into 1) AI technologies as enablers of entrepreneurship; 2) possible improvements of the EE framework, and 3) ChatGPT’s and similar AI tools’ usefulness for entrepreneurship research more generally.",November 2023,"Entrepreneurship, Environmental change, Artificial intelligence, External enabler",Business Venturing Insights,2025-03-08T00:00:00,8.0,The use of AI technology as an enabler of entrepreneurship and the examination of its potentials through the External Enablement (EE) framework can have significant practical value for European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673423000434,Why do user innovators want to pursue user entrepreneurship? On the influence of the communitarian identity,Xin=Yu: yuxin@cqupt.edu.cn; Ting=Zhang: 1908265238@qq.com; Marcel L.A.M.=Bogers: m.l.a.m.bogers@tue.nl,"Abstract
While users may be an important source of innovation, and even of entrepreneurship, we know little about the exact psychological mechanism that underpins user innovators' transition to user entrepreneurship (UE). In this study, we focus on user innovators' communitarian identity, which is a stable 
mindset
 that values the personalized bonds with a user community. Based on the 
theory of planned behavior
, we hypothesize how this identity affects user innovators' intention regarding UE. We use survey data from 139 user innovators to show that user innovators' communitarian identity strengthens their subsequent attitudes, subjective norms, and perceived behavior control (PBC) regarding UE, and that the attitudes and PBC in turn strengthen their intentions to pursue UE. The findings highlight the direct effect of the communitarian identity on user innovators’ evaluation of UE and its indirect effect on their intention. They also provide insights into the individual factor that alleviates the lack of commercialization of user innovation.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on user innovators' transition to user entrepreneurship provides valuable insights into the psychological mechanisms involved, which could be useful for startups looking to innovate and transition to entrepreneurship."
https://www.sciencedirect.com/science/article/pii/S2352673423000458,Entrepreneurial identity play through cross-cultural experience: Insights from returnees,Anh Tran Tram=Truong: tramanh@due.edu.vn,"Abstract
Entrepreneurial identity plays a crucial role in the entrepreneurial process. Although cross-cultural experience likely shapes entrepreneurial identity in enduring ways, we are not clear on how and why. Returnee entrepreneurs, who move between distinct 
sociocultural contexts
, offer a valuable lens to explore how aspects of cross-cultural experience interact with entrepreneurial identity. Incorporating the concept identity play, we aim to explore how returnees process their cross-cultural experience in ways that shape their entrepreneurial identity when venturing back home. Adopting a qualitative design with 12 cases of returnee entrepreneurs, we develop a three-stage process model of identity play through which returnees navigate the differences between the host and home country to construct their entrepreneurial identity: envisioning, enacting, and refining. We suggest that it is the nexus of cross-cultural experience and entrepreneurial activities that this identity play manifests. We make contributions to the literatures on entrepreneurial identity and cross-cultural experience in entrepreneurship. In addition, we contribute to the meaningful heterodoxies section's call for a better understanding of how entrepreneurs moving between distinct cultures select cultural elements to generate valuable heterodoxies.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"The exploration of how cross-cultural experience shapes entrepreneurial identity among returnee entrepreneurs offers interesting insights, but the direct impact on European early-stage ventures is unclear."
https://www.sciencedirect.com/science/article/pii/S2352673423000495,The unrelenting entrepreneur: Taking stock of research on entrepreneurial persistence and related constructs,Jiaju=Yan: Justin_Yan@baylor.edu; Alan D.=Boss: adboss@ualr.edu; Rhonda K.=Reger: Rhonda.Reger@unt.edu,"Abstract
Entrepreneurial persistence is crucial for venture success and entrepreneurs’ personal growth. Yet, the extant research on entrepreneurial persistence has largely remained disconnected. The current disjointed profusion of constructs and theories which we believe has made progress on understanding this important construct slower than is ideal. To address those issues, we conducted a 
systematic review
 and made explicit the nomological network of antecedents and consequences of entrepreneurial persistence and the related constructs of perseverance and tenacity. Our review identified potential theoretical and empirical issues of the current entrepreneurial persistence research and outlined areas and opportunities for future research.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The systematic review on entrepreneurial persistence has the potential to provide valuable insights for early-stage ventures, but the practical implications for startups are not explicitly mentioned."
https://www.sciencedirect.com/science/article/pii/S2352673423000483,Psychological well-being of hybrid entrepreneurs: A replication and extension study using German panel data,Meike=Stephan: meike.stephan@uni-siegen.de; Cemre=Demir: cemre.demir@student.uni-siegen.de; Frank=Lasch: f.lasch@montpellier-bs.com; Alexander=Vossen: A.Vossen@tilburguniversity.edu; Arndt=Werner: arndt.werner@uni-siegen.de,"Abstract
This study contributes to new debates about how hybrid entrepreneurship is related to specific psychological well-being dimensions (job, life, and leisure time satisfaction). To address this issue, Ardianti, Obschonka, and Davidsson (2022; AOD) published first empirical results in 
JBVInsights
. They provide evidence for different effects on well-being, depending on how individuals have switched from or into hybrid entrepreneurship. By drawing on panel data from Germany, two studies are conducted. While study 1 replicates the original methodological approach, study 2 provides an extension by applying cross-model coefficient comparison tests. In study 1 we were able to replicate some of the original results presented by AOD. In contrast to the original study, we find that the switch from wage employment to hybrid entrepreneurship is negatively related to job and 
life satisfaction
. Also, while AOD show that a switch from hybrid entrepreneurship to full-time entrepreneurship relates significantly to job and 
life satisfaction
, we find no such effects. Finally, in study 2, we provide novel evidence that the effects induced by a job switch to hybrid and full-time entrepreneurship are significantly stronger for job satisfaction when compared to life and leisure time satisfaction.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study on hybrid entrepreneurship and well-being dimensions could have a significant impact on early-stage ventures, especially startups, by providing insights into the effects of different entrepreneurship paths on job and life satisfaction."
https://www.sciencedirect.com/science/article/pii/S2352673423000513,Exceptionality in entrepreneurship: Systematically investigating outlier outcomes,Robert J.=Pidduck: rpidduck@odu.edu; Daniel R.=Clark: dclark@ivey.ca; G. Christopher=Crawford: gcrawford@ut.edu,"Abstract
Entrepreneurship is the study of ordinary people doing extraordinary things: outliers in society, seeing and enacting new venture opportunities, while most others do not. Historically, the field of entrepreneurship has been dominated by competing homogeneity and heterogeneity perspectives. Extending current heterogeneity trends in the domain, this article builds the case for the benefits of examining the exceptional of the exceptional: entrepreneurs that 
produce extraordinary results
. We argue that outlier entrepreneurs are not aberrations or empirical nuisances to be explained away or “fixed” through statistical wizardry. Rather, in most entrepreneurship phenomenon, those extremely high performing and disproportionately influential cases are 
“the goal” of entrepreneurship,
 and exactly where valuable theory-building potential lies. Building on several growing conversations in entrepreneurship research, we introduce why some phenomenological domains share characteristic potential for generating important insights using an outlier approach and present a set of methodological tools to tackle them.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the focus on outlier entrepreneurs is intriguing, the direct practical value and impact on early-stage ventures are not clearly defined in the abstract."
https://www.sciencedirect.com/science/article/pii/S2352673423000550,The formation and role of religious social capital in driving entrepreneurial action,Paul=Steffens: paul.steffens@adelaide.edu.au; Binyam Zewde=Alemayehu: binyam.alemayehu@adelaide.edu.au; Scott R.=Gordon: scott.gordon@adelaide.edu.au,"Abstract
Spiritual capital serves as a unique resource that can contribute to 
entrepreneurial action
. This paper develops the concept of 
religious social capital
, as a distinct component of spiritual capital, and theorizes its role in motivating and supporting entrepreneurial action. This is important because individuals with 
religious affiliations
 are often deeply embedded within a religious community yielding strong and unique forms of social capital; and social capital in general is well established as a key driver of entrepreneurial action. The paper then elaborates the distinctive structural, cognitive and relational dimensions of religious social capital, and theorizes distinctive mechanisms by which these enable effective entrepreneurial action through community attention and community spanning.",November 2023,"Religion and entrepreneurship, Social capital, Entrepreneurial action",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The development of the concept of religious social capital and its role in motivating entrepreneurial action could offer valuable insights for startups with religious affiliations, potentially influencing their success."
https://www.sciencedirect.com/science/article/pii/S2352673423000562,Why are you selling your business? Understanding signaling effects of seller rationale at time of entrepreneurial exit,Kipp A.=Krukowski: kipp.krukowski@colostate.edu; Nicole A.=Flink: nicoleflink@weber.edu; Bryan D.=Edwards: bryan.edwards@okstate.edu,"Abstract
Entrepreneurs eventually face the inevitable in which they must exit their firms. Some choose the entrepreneurial exit path of selling to an unaffiliated individual or company. This type of exit can arise due to a variety of reasons, including life situations, strategic reasons, or other interests. The process of selling a small, privately held company, oftentimes facilitated by business intermediaries, typically begins with introducing the company to potential acquirers through confidential marketing that provides just enough information to pique interest while also preserving the anonymity of the entrepreneur or business. One important element included in the marketing of a business is the entrepreneur's reason to sell. Due to the potential 
information asymmetry
 present in the sale of privately-held businesses, this study proposes that the reason for sale, referred to in this study as the 
communicated exit purpose,
 sends varying signals to potential acquirers impacting the perception of the business opportunity and acquisition price at exit. Utilizing an archival dataset from a popular business-for-sale website, our analysis shows support that the price at exit is affected by the communicated entrepreneur's reason for exit. A separate experiment and 
qualitative study
 provide further insight into the acquirer perceptions of the business opportunity based on the stated reason of entrepreneurial exit. Our paper concludes with strategies to assist entrepreneurs regarding the disclosure of reasons for exiting.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"The study on entrepreneurial exits and the impact of communicated exit purposes on acquisition price provides practical implications for startups looking to sell their firms, offering strategies for entrepreneurs to consider when disclosing reasons for exiting."
https://www.sciencedirect.com/science/article/pii/S2352673423000628,Why don’t you like me? Exploring the social venture funding gap in angel investing,Torben=Antretter: torben.antretter@unisg.ch; Henrik=Wesemann: henrik.wesemann@ie.edu,"Abstract
While many studies on the social venture funding gap have focused on venture-level factors to explain why social ventures receive less funding, the role of investors and their characteristics has received less attention. In this study, we propose that the reason for much of the funding gap is that many 
angel investors
 lack the analytical capabilities required to assess double bottom lines. Drawing on the literature on 
human capital
 in angel investing, we use data on 19,757 investment decisions by 1,428 
angel investors
 from a large angel investment network to investigate the relationship between venture type, angel investor analytical capability, and investment likelihood. We find that the reluctance to invest into social ventures disappears for analytically capable angel investors (those who are relatively educated, experienced, and connected). These findings demonstrate the importance of investor 
human capital
 in social venture funding and closing the funding gap.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study sheds light on the role of angel investors in social venture funding, providing practical implications for startups seeking funding."
https://www.sciencedirect.com/science/article/pii/S2352673423000525,Don't always judge an article by its cover: An examination of proxies for journal impact and citations in entrepreneurship,Jill=Kickul: kickul@marshall.usc.edu; Mark=Griffiths: markgrif@marshall.usc.edu; Malin=Brännback: malin.brannback@abo.fi; Colleen C.=Robb: crobb@fgcu.edu,"Abstract
In many academic circles, promotion and tenure decisions are often driven by the quality of the candidate's research portfolio. In entrepreneurship, as in other disciplines, we tend to judge the quality and impact of our research based on publication in a select few top journals. In our paper, we investigate the incorrect inferences that result from using Journal Impact Factor (JIF) and other rankings as proxies to assess an article's scholarly quality and impact. In doing so, we hope to better understand any discrepancies between journal quality as measured by these proxies and individual article citation rates within both top and non-top entrepreneurship journals. Our results, based upon the average number of citations, show roughly 61% of the top four journals being misidentified as high quality (Type 2 error) and 22% of the remaining journal articles being misidentified as not high quality (Type 1 error). We illustrate the variability within the top entrepreneurship journals that further reinforces the importance of evaluating each article based on its individual merits rather than relying solely on proxies of quality. As such, we avoid neglecting the potential impact and value of articles that may not conform to traditional measures of quality.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study sheds light on the limitations of using Journal Impact Factor to assess the quality and impact of research, which can be valuable for early-stage ventures looking to understand the academic landscape."
https://www.sciencedirect.com/science/article/pii/S2352673423000574,Parental influence and the propensity for entrepreneurship: Evidence from the one-child policy,Mathew=Hayward: mathew.hayward@monash.edu; Haining=Wang: wanghn36@mail.sysu.edu.cn; Zhiming=Cheng: zhiming.cheng@mq.edu.au,"Abstract
Theory and evidence on 
human capital
 suggest that those with more resources have more opportunities to advance their careers. However, entrepreneurship in developing countries may depend more on individuals' resourcefulness than resources. In this article, we investigate the proposition that those who are endowed with more resources from their parents are less resourceful and, therefore, less likely to become entrepreneurs. Our study is situated within the context of China's one-child policy so that we can address concerns that the relationship between the number of siblings one has and the propensity for entrepreneurship is endogenous to parental preferences and fertility conditions. Consistent with this proposition, we find that those with more siblings are more likely to become entrepreneurs. Also, more parental resources and influence weaken such a relationship. While the one-child policy was set up as a means of population control, an unexpected consequence was a diminished propensity for entrepreneurship.",November 2023,"Entrepreneurship, Parental influence, Developmental psychology",Business Venturing Insights,2025-03-08T00:00:00,4.0,"While the study addresses an interesting relationship between parental resources and entrepreneurship in developing countries, the practical implications for European early-stage ventures are limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000501,Exploring objective versus subjective social ties using entrepreneurs’ gmail data,Joseph=Billingsley: josephbillingsleypsych@gmail.com,"Abstract
It is intuitively appealing and common in the literature to describe social ties as one large category that represents multiple constructs which have similar relations across operationalizations. However, that approach does not capture the nuance in the literature and might obscure notable differences between subjective and objective network tie measures, and how those differences extend to relations with venture-level outcomes. Drawing upon novel objective measures of network ties derived from analyses of entrepreneurs’ Gmail data, we offer an empirical assessment of subjective social ties relative to objective social ties. In examining how those assessments relate to multiple metrics of venture performance, we look at both subjective and objective measures. We find that objective network measures predict overall subjective (but not objective) venture performance at an average of 
r
 = .31 (for network size) and 
r
 = .29 (for network engagement). We delve into the implications of our work, and discuss how future research can progress more effectively and efficiently with an eye towards the practical usefulness of our findings for entrepreneurs and entrepreneurship service organizations.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The research on subjective and objective network ties and their impact on venture performance provides practical insights for entrepreneurs and entrepreneurship service organizations, making it highly relevant for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673423000586,Crisis response efficacy: Perceived ability to respond entrepreneurially to crises,Kim=Klyver: kkl@sam.sdu.dk; Paul=Steffens: paul.steffens@adelaide.edu.au; Suna Løwe=Nielsen: sso@sam.sdu.dk,"Abstract
Prior research indicates the importance of entrepreneurial responses to external crises. This article theoretically extends the concept of self-efficacy to the task domain of entrepreneurial response to crisis situations. 
Crisis response efficacy
 is conceptualized as a task-specific (perceived) efficacy, a CEO's beliefs in their firm's skills, knowledge, and readiness to respond effectively to an external crisis – dealing with crisis impacts and responding entrepreneurially to pursue opportunities. We further theorize that crisis response efficacy mediates the relationship between several antecedents and entrepreneurial responses to crises and that the nature of the response varies with the crisis stages. We provide a preliminary empirical illustration of the utility of crisis response efficacy as a construct.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The concept of crisis response efficacy is important, but the practical implications for European early-stage ventures may not be immediate."
https://www.sciencedirect.com/science/article/pii/S2352673423000604,Field dynamics as context – A multi-perspective combined analysis of the effects of context on entrepreneurship,Alex=Alterskye: alex.alterskye@york.ac.uk; Andrea=Caputo: acaputo@lincoln.ac.uk,"Abstract
Addressing the growing need for nuanced understandings of entrepreneurial contexts, this article presents a multifaceted pragmatic framework for scrutinising the ‘field of entrepreneurship’ and its associated dynamics. Drawing on Bourdieu's theory of practice and the institutional logics perspective, we introduce the concept of the field as a mid-level analytical lens—positioned between micro and macro perspectives—that captures the complex interplay of agency and structure in 
entrepreneurial activity
. Our conceptualisation of the field enables the dissection of structural logics and actor dispositions, alongside the institutional processes that shape the entrepreneurial landscape. In response to calls for innovative methodologies in entrepreneurship research, we propose a combined analytical approach to unpack the layered complexities of entrepreneurial contexts, from individual actors to broader institutional influences. The utilisation of this ‘field of entrepreneurship’ concept, with a particular focus on field dynamics, serves as a pragmatic analytical unit, contributing to the broader discourse by balancing simplicity, accuracy, and generalisability. This research consequently offers a novel methodological avenue for exploring what facilitates or impedes entrepreneurial activity within varying contexts.",November 2023,"Entrepreneurship, Context, Field theory",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The framework proposed for analysing the 'field of entrepreneurship' offers a valuable tool for understanding the complex dynamics of entrepreneurial activity, which can be beneficial for European early-stage ventures navigating different contexts."
https://www.sciencedirect.com/science/article/pii/S2352673423000598,The deterioration of self-worth in entrepreneurship,Pablo=Muñoz: pablo.munoz-roman@durham.ac.uk,"Abstract
This paper explores the deterioration of self-worth in entrepreneurship. Using a 15-month participatory action research in the North of England, we found mismatches between expectations and experiences at three interacting levels—purpose, 
autonomy
, and achievement—which surface as entrepreneurs reflect on execution, performance, and fulfillment experiences. Mismatches materialize as incongruence between the ideal states under pursuit and the actual experiences, which compound leading to a diminished sense of control, direction, and worthiness, which in turn further fuels a cycle of negative emotions, involving anxiety, isolation, 
shame
, and guilt. We discuss implications for entrepreneurs’ mental health.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,The study focuses on the mental health of entrepreneurs but lacks specific actionable insights for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S235267342300063X,When the going gets tough: Stressors and purpose in life among social and commercial entrepreneurs,Sean M.=Dwyer: Sean_Dwyer1@baylor.edu; Michael=Lerman: MLerman@iastate.edu; David=Gras: DGras@utk.edu,"Abstract
Described as the presence of significance, meaning, and goal-directedness in one's life, purpose in life has received much attention in psychology and well-being research due to its association with psychological well-being. However, research on the relationship between entrepreneurship and purpose in life remains nascent. In this study, we explore differences in purpose in life between social entrepreneurs and commercial entrepreneurs. We find that social entrepreneurs, on average, exhibit higher levels of purpose in life than commercial entrepreneurs. We further find that social entrepreneurs are more likely to retain purpose in life in the face of hindrance stressors than their commercial entrepreneur counterparts. We discuss theoretical implications for social entrepreneurship and entrepreneurial well-being literatures.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,The research comparing purpose in life between social and commercial entrepreneurs offers valuable insights for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673423000446,Balancing entrepreneurial and learning orientations: A meta-analytic approach to understanding performance variability,Kanhaiya K.=Sinha: sinhak@d.umn.edu; Piers=Steel: piers.steel@haskayne.ucalgary.ca; Chad=Saunders: wsaunder@ucalgary.ca; Hadi=Fariborzi: hfariborzi@mtroyal.ca,"Abstract
The entrepreneurial orientation (EO)-performance correlation varies across firms, traditionally attributed to external moderators. This study introduces a novel perspective, examining the EO and learning orientation (LO) correlation as an internal moderator on the EO-performance relationship. Our meta-analysis of 418 samples from 400 studies and a total of 129,695 firms, reveals a strong positive association between EO and LO, indicating their synergistic potential. The combined effects of EO and LO on performance were found to be significantly greater than their individual impacts. Furthermore, the correlation between EO and LO significantly influences the EO-performance relationship, suggesting that firms with high levels of both EO and LO exhibit higher performance variability. With the right balance between EO and LO, the EO-performance relationship can be almost doubled, providing a strategic lever for managers to enhance firm performance.",November 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The meta-analysis on EO and LO correlation and their impact on firm performance provides strategic insights for managers of early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S235267342300029X,"Everything, all the time: Engaging the social problem of homelessness in entrepreneurship research and practice",Mohamed Hassan=Awad: mawad5@calstatela.edu,"Abstract
Homelessness is one of the most complex and enduring social problems facing many communities. As the research and practice of prosocial venturing flourish, there remains very limited engagement from scholars and entrepreneurs with this profound problem. Emerging innovations around homelessness have focused on desgining new forms of shelters such as the construction of tiny houses and the conversion of shipping containers and other impractical spaces into possible housing. These innovations, while promising, have limited viability and impact on the problem and the lives of those affected by it. This article aims to galvanize future research and practice through providing a thick description of homelessness, highlighting the entanglement of housing with other integral dimensions such as criminalization and mental and physical health provisioning. I enjoin scholars and entrepreneurs to embrace the messiness of homelessness and similar social problems to provide more informative and impactful outputs. I specifically highlight more integrative approaches in stakeholder governance and the process of venture creation.",November 2023,"Homelessness, Prosocial organizing, Complexity, Grand challenges, Agenda, Governance",Business Venturing Insights,2025-03-08T00:00:00,4.0,"While the study highlights the complexity of homelessness, it lacks direct relevance to European early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S2352673423000203,Nascent entrepreneurs during start-up competitions: Between beauty contests and co-created problematization,Bob=Bastian: bob.bastian@unitn.it; Antonella=Zucchella: antonella.zucchella@unipv.it,"Abstract
Problem-oriented research is increasingly gaining currency in entrepreneurship research. In this article, we respond to the need for more action-based perspectives in entrepreneurship. By employing an inductive research design based on 
qualitative interviews
 and participant observations, we discuss empirical evidence about two alternative problem formulation processes in the context of start-up competitions. We find that entrepreneurs may perceive start-up competitions as ‘beauty contests’, with the consequence of overpromised expectations, misaligned goals, and underutilized use of resources. The beauty contest represents a traditional interpretation of start-up competitions because it concentrates mainly on impressions and misses addressing real problems that entrepreneurs 
face
. An alternative model for a new breed of start-up competitions is represented by co-created problematization, which challenges conventional thinking with a joint role for entrepreneurs and academics. We reflect on the mediating role of co-creation in a problem formulation process from joint problem definition toward joint problem solution, describe possible frictions, and highlight the need to re-design start-up competitions and shift towards a co-created setting where a confrontation between practitioners and academics is stimulated.",November 2023,"Problem-solution design, Problematization, Co-creation, Start-up competitions, Legitimacy",Business Venturing Insights,2025-03-08T00:00:00,7.0,"Addresses the need for re-designing start-up competitions towards a co-created setting, which can have a positive impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000543,Scaling the right answers – Creating and maintaining hope through social entrepreneurship in light of humanitarian crises,Ewald=Kibler: ewald.kibler@aalto.fi; Andreas=Kuckertz: andreas.kuckertz@uni-hohenheim.de; Alexander=Bernhard: alexander.bernhard@impacthub.net; Elisabeth S.C.=Berger: elisabeth.berger@jku.at; Ondřej=Dvouletý: ondrej.dvoulety@vse.cz; Rainer=Harms: r.harms@utwente.nl; Sarah=Jack: sarah.jack@hhs.se,"Abstract
Triggered by the Russo–Ukrainian war starting early in 2022 and the subsequent movement of refugees toward various European countries, this rapid response paper provides five reflections on the role of social entrepreneurship in light of humanitarian crises. We validate two problems with the help of a problem owner from social entrepreneurial practice and suggest answers to them grounded in existing evidence documented in the academic literature (translational research approach). First, we show how social entrepreneurs can focus on solving the right problems in chaotic and fast-paced crises, and second, we illustrate measures to scale appropriately. Finally, on a meta-level, hope emerges as an additional answer. Even if social entrepreneurs should not address the “right” problems and even if they scale inappropriately, in light of any humanitarian crises, they still contribute value by creating hope for their societies, their stakeholders, and for themselves.",June 2023,"Social entrepreneurship, Crises, Problem validation, Scaling, Rapid response, Russo–Ukrainian war",Business Venturing Insights,2025-03-08T00:00:00,8.0,"Provides reflections on the role of social entrepreneurship in humanitarian crises, offering practical solutions and fostering hope, which can benefit European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000567,Knowledge problem diagnosis and the fate of corporate entrepreneurship initiatives,David M.=Townsend: dtown@vt.edu; Richard A.=Hunt: rickhunt@vt.edu; Parul=Manocha: parul@vt.edu; Joseph J.=Simpson: jjsimpson@vt.edu,"Abstract
One of the great paradoxes of 
corporate entrepreneurship
 (CE) is that even with good intentions and prodigious resources initiatives supporting the renewal and 
revitalization
 of organizations through 
entrepreneurial action
 are often programmed to fail before they are even launched. The cause of this malady stems from the challenges corporate entrepreneurs 
face
 in accurately diagnosing the state of the marketplace and the needs of their respective companies. 
Misdiagnosis
 is costly, pervasive, and avoidable; yet, the entrepreneurship literature does not offer a comprehensive explanatory model concerning why and how these expensive errors arise with such frequency. To address this gap, we leverage recent advances in realm of knowledge problem scholarship to hone in on the ability and willingness of corporate entrepreneurs to accurately assess ambiguity, equivocality, uncertainty, and complexity in the context of corporate acquisitions. Findings from the study indicate that knowledge problem misdiagnosis has a profoundly negative impact on venturing outcomes. Practitioners exposed to the framework lauded its potential to constructively challenge core company assumptions to avoid expensive mistakes.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"Addresses the challenges faced by corporate entrepreneurs in accurately diagnosing the marketplace, which can indirectly impact early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673422000610,"W(h)ither entrepreneurship? Discipline, legitimacy and super-wicked problems on the road to nowhere",Richard T.=Harrison: r.harrison@ed.ac.uk,"Abstract
The discourse of the twenty first century is increasingly a discourse of crisis – global warming, 
climate change
, environmental degradation, health pandemics, geopolitical instability, poverty, enforced migration and refugee movements, among others. Increasingly these ‘grand challenges’ pose complex environmental and social problems that present radical uncertainty regarding the consequences of current actions and encourage multiple conflicting evaluations. We argue in this paper that in response to this ‘new world’ of super-wicked problems and hyperobjects, there is a unique opportunity for entrepreneurship to take centre stage, given that the entrepreneurial context itself is extreme in terms of uncertainty, time pressures, cognitive load, emotional reactions, and social interactions. However, there is a danger that this opportunity may be compromised by ongoing debates over the status, coherence, identity and legitimacy of entrepreneurship as a discipline. Accordingly, we argue for more problem-oriented research in entrepreneurship, not as an additional focus of attention but as foundational to the nature of the discipline itself. This argument is based on a broader discussion of the nature of scientific disciplines as the increasingly specialised division of knowledge and challenges the drive to establish entrepreneurship as a theory-led scientific discipline in the traditional mode. Commitment to the social 
legitimation
 of disciplinary discourse advocating problem-oriented entrepreneurship avoids the danger that consensus in the discipline is established at the expense of intellectual development, practical relevance and real impact.",June 2023,"Scientific discipline, Academic identity, Problem-oriented research, Super-wicked problems, Hyperobjects",Business Venturing Insights,2025-03-08T00:00:00,5.0,"Discusses the opportunities for entrepreneurship to address complex environmental and social problems, but the focus on broader disciplinary issues limits the direct impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000695,Why we need design science in entrepreneurship research an idiosyncratic perspective based on the experiences and learnings of an ex-practitioner in training to be an entrepreneurship scholar,Shoon=Chan Timothy Hor: shoon.hor@qut.edu.au,"Abstract
For entrepreneurship research to be relevant and impactful, entrepreneurship scholars must start by understanding the problems faced by entrepreneurs.However, problems are different from research questions.As scholars, where do we start, and how do find these problems? And how do we ensure that we do user-inspired research that advances both understanding and practical relevance? Based on my experience and learnings as an 
ex-practitioner in training to be an entrepreneurship scholar
, who took on the Me-search approach in my research to solve a problem in digital entrepreneurship, this essay presents my humble experiences in framing a real-world problem in solution-oriented entrepreneurship research.Given that I have taken a path less traveled, unintentionally, starting with a problem rather than from a theory orientation, I present my informal reflections on why entrepreneurship scholars need to develop both descriptive and prescriptive knowledge.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"Emphasizes the importance of understanding problems faced by entrepreneurs and conducting solution-oriented research, which can enhance practical relevance for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673423000082,Gordian knot uncut: Understanding the problem of founder exit in social ventures,Raja=Singaram: raja.singaram@outlook.com,"Abstract
Eventually, all founders leave their social ventures either on their own accord or because they are compelled to do so. However, there is a high level of uncertainty over how founder exit decisions are made in these firms. In this thick problem description of founder exit in social ventures, we identify the factors that distinguish the social entrepreneurship context through the founder, firm, and ecosystem perspectives. The influence of these factors on founder exit is elaborated. Based on the insights developed, we propose research questions that future studies could pursue to expand our understanding of founder exit, exit routes, and succession in social ventures.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study provides insights into founder exit in social ventures, which can be valuable for startups in understanding this process."
https://www.sciencedirect.com/science/article/pii/S2352673423000197,Rapid problem formulation for Societal Impact: Lessons from a decade-long research-practice partnership,Natalie=Slawinski: nslawinski@uvic.ca; Bruna=Brito: bbrito@uvic.ca; Jennifer=Brenton: jnbrento@umich.edu; Wendy K.=Smith: smithw@udel.edu,"Abstract
Problem-oriented research enables scholars to directly explore increasingly complex societal challenges, yet we still lack in-depth insight into the process of problem formulation. In this paper, we offer insight into this process by examining our 10-year engaged research study of Shorefast, a social 
enterprise
 based on Fogo Island, Canada, whose mission was to revitalize the community. We show how our research-practice collaboration evolved as a recursive process which we label as rapid problem formulation - a quickly shifting recursive process between problem definition and problem solution. By iterating quickly between problem and solution, researchers and practitioners can create greater impact as their understanding of the problem, and their search for solutions, deepens.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The research on problem formulation in social enterprises can offer practical strategies for startups to address complex societal challenges.
https://www.sciencedirect.com/science/article/pii/S2352673422000634,Chasing mythical creatures – A (not-so-sympathetic) critique of entrepreneurship's obsession with unicorn startups,Per=Davidsson: per.davidsson@ju.se; Andreas=Kuckertz: andreas.kuckertz@uni-hohenheim.de; Maximilian=Scheu: maximilian.scheu@uni-hohenheim.de,"Abstract
In recent years, the notion of a unicorn, a startup exceeding a premarket valuation of one billion USD, has become one of the most prominent concepts in the practical discourse of entrepreneurship. Consequently, entrepreneurs aim to build unicorns, investors want to participate in their success, policymakers strive to support their emergence, and educators present them as an ideal-type 
entrepreneurial activity
. We challenge this view with a provocative critique of the positive mainstream perception of unicorns. First, we characterize unicorns as an ambiguous analytical category with little value for research and evidence-based policy. Second, we point to the danger of neglecting the multifaceted nature of entrepreneurship by focusing solely on extreme outliers. Third, we highlight the potentially unethical consequences of entrepreneurship's obsession with unicorns. Finally, we conclude that focusing on unicorns contributes to a biased picture of entrepreneurship that favors valuation (i.e., the unicorn) over value creation (i.e., productive entrepreneurship).",June 2023,"Entrepreneurship, Growth, Startup, Valuation, Unicorn, Value creation",Business Venturing Insights,2025-03-08T00:00:00,3.0,The critique of the unicorn concept may not have direct practical value for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673423000239,Entrepreneurial alertness: A meta-analysis and empirical review,Jintong=Tang: jintong.tang@slu.edu; Masoud=Karami: m.karami@otago.ac.nz; Clécio Falcão=Araujo: clecio.araujo@pucrs.br; Lucas Bonacina=Roldan: Lucas.roldan@pucrs.br; Julia Aita=dos Santos: julia.aita@hotmail.com,"Abstract
Entrepreneurial alertness (EA) has attracted increasing attention in scholarly work, and a multitude of empirical studies have examined the antecedents and outcomes of entrepreneurial alertness. Although there is consistent evidence for significant associations, ambiguities exist concerning the directions and magnitude of the relationships. The purpose of this study is to meta-analytically assess the antecedents and outcomes of EA. A total of 125 empirical studies were analyzed with 597 effect sizes derived from 18 different constructs and a sample of 1,820,331 individuals. We advance understanding of the critical role of alertness in generating entrepreneurial outcomes, its antecedents, and the directions and magnitude of the associations. We also provide several directions for further theorizing the role of alertness in entrepreneurship.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The meta-analysis on entrepreneurial alertness provides valuable insights for startups to understand the critical role of alertness in generating entrepreneurial outcomes.
https://www.sciencedirect.com/science/article/pii/S2352673422000579,Closeness of the future: Influence of language future-time reference on individual behaviour,Francesca=Di Pietro: francesca.dipietro@unimib.it; Vangelis=Souitaris: V.Souitaris@city.ac.uk; Francesca=Masciarelli: f.masciarelli@unich.it; Andrea=Prencipe: aprencipe@luiss.it,"Abstract
This study draws on the linguistics literature, which recognizes the role of language attributes in shaping individual behaviour. We theorize that weak-future languages (e.g., Chinese), which create the perception that the future is closer temporally to the present than do strong-future languages (e.g., English), favour future-oriented behaviours such as investment in crowdfunding of entrepreneurial ventures. To test this thesis, we use a mixed-method approach, combining an original dataset of crowdfunding investments in 53 countries (Study 1) and a randomized experiment examining the investment behaviour of 77 bilingual (English-Chinese) students (Study 2). We find that natives of countries with weak-future languages engage more actively in crowdfunding of entrepreneurial ventures compared to individuals from countries with strong-future languages. We find that this effect dominates the stable effect of national culture. In other words, perceiving the future as closer means that the future assumes greater psychological importance for weak-future speakers and, therefore, they enact more future-oriented behaviours.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,The study on language attributes and crowdfunding investments offers interesting findings that could be relevant for startups seeking crowdfunding.
https://www.sciencedirect.com/science/article/pii/S2352673422000555,Predicting entrepreneurial activity using machine learning,Philipp=Schade: philipp.schade-2@wirtschaft.uni-giessen.de; Monika C.=Schuhmacher: monika.schuhmacher@wirtschaft.uni-giessen.de,"Abstract
This study evaluates the predictability of 
entrepreneurial activity
 using machine learning. We compare different supervised machine learning techniques: decision tree, random forest, artificial 
neural network
, 
k
-nearest neighbor, extreme gradient boosting tree ensemble, and naïve Bayes, as well as run the traditional multiple logistic regression for obtaining a baseline and estimating their relative model prediction performance on a Global Entrepreneurship Monitor dataset of 1,192,818 individuals from 99 countries. By comparing different machine learning techniques, we predict out-of-sample opportunity-motivated 
entrepreneurial activity
 with an overall accuracy ranging from 70.1% to 91.2%. The results demonstrate that the extreme gradient boosting tree ensemble is superior in predicting opportunity-motivated entrepreneurial activity. Finally, a global surrogate model reveals that knowing an entrepreneur, entrepreneurial self-efficacy, and opportunity recognition are the three most important features for predicting opportunity-motivated entrepreneurial activity. For comparison purposes, we perform the same analyses for necessity-motivated entrepreneurial activity. The results reveal that the extreme gradient boosting tree ensemble is also the best-performing technique in predicting this form of entrepreneurial activity with a 96.5% accuracy.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The use of machine learning to predict entrepreneurial activity has practical value for early-stage ventures and startups, providing insights into predicting both opportunity-motivated and necessity-motivated entrepreneurial activities."
https://www.sciencedirect.com/science/article/pii/S2352673422000622,Why narcissists may be successful entrepreneurs: The role of entrepreneurial social identity and overwork,Andrea S.=Gubik: andrea.gubik@uni-miskolc.hu,"Abstract
In this article, we theoretically and empirically examine why and how social identity and overwork/workaholism represent pathways to convey the effect of 
dark triad
 traits – Machiavellianism, 
narcissism
, and 
psychopathy
 – on venture performance. By analyzing the data of 569 university students with their own businesses in the Global University Entrepreneurial Spirit Students’ Survey, we show that compulsive overwork and Darwinian social identity partially mediate the positive effect of 
narcissism
 on venture performance. Thus, our study extends the narcissism literature by exploring the mechanism of the positive impact of narcissism on venture performance and implies that narcissism is not necessarily an adverse personality characteristic in an entrepreneurial context.",June 2023,"Narcissism, Company performance, Darwinian social identity, Overwork",Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the study explores the impact of dark triad traits on venture performance, the practical implications for early-stage ventures and startups are not as direct or clear compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673422000646,Pathways and mechanisms for catalyzing social impact through Orchestration: Insights from an open social innovation project,Johanna=Mair: mair@hertie-school.org; Thomas=Gegenhuber: thomas.gegenhuber@jku.at; Laura=Thäter: laura.thaeter@jku.at; René=Lührsen: rene.luehrsen@leuphana.de,"Abstract
Within the entrepreneurship literature, there is a growing interest in understanding collective 
entrepreneurial approaches
 to tackling societal challenges. In this study, we examine the orchestration of 
collective action
 in an open social innovation project bringing together public administrations, citizens and organized civil society to collaboratively address several societal challenges. Analyzing data generated in-situ and in real-time over the entire duration of the project we show how social impact orchestration can generate impact through four pathways: lead user focus, solution focus, problem focus, and ecosystem focus. For each pathway, we show how orchestration enhanced the impact potential of stakeholders involved by enabling learning and scaling. Our study contributes to the literature on impact entrepreneurship and advances knowledge on orchestrating innovation for social impact.",June 2023,"Impact entrepreneurship, Open social innovation, Impact pathways, Societal challenges, Social enterprise, Social innovation, Collective action",Business Venturing Insights,2025-03-08T00:00:00,9.0,"Understanding collective entrepreneurial approaches for tackling societal challenges is valuable for early-stage ventures, as it provides insights into orchestrating innovation for social impact, which can be relevant for startups focused on social entrepreneurship."
https://www.sciencedirect.com/science/article/pii/S2352673422000658,"CEO duality and tenure, and the adoption of goal ambidexterity in corporate venture capital",Sergey Alexander=Anokhin: sergey.anokhin@menlo.edu,"Abstract
In a study of corporate venture capital investments by 81 corporations during a two-year period, we explore the factors leading to goal ambidexterity, or a balanced pursuit of strategically- and financially-oriented deals, by incumbents. Our results indicate that CEO characteristics play an important role in the adoption of goal ambidexterity by corporate investors. Specifically, CEO duality positively affects the adoption of goal ambidexterity, whereas CEO tenure exerts a negative influence on the likelihood of such adoption.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on corporate venture capital investments and goal ambidexterity offers some insights for early-stage ventures, but the direct applicability to startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S235267342200066X,Should I stay or should I go? The impact of entrepreneurs’ loneliness on business exit intentions through entrepreneurial passion,Wei=Yu: iseyw@nus.edu.sg; Fei=Zhu: fei.zhu@nottingham.edu.cn; Shea X.=Fan: shea.fan@rmit.edu.au; Jason Gabriel=Jonathan: jgj25@bath.ac.uk,"Abstract
Loneliness is a serious source of suffering for entrepreneurs. Although the negative impact of loneliness on entrepreneurs' well-being has been studied, the mechanism through which loneliness affects entrepreneurial outcomes is less known. In this research, instead of examining the negative consequences of loneliness as related to well-being, we focus on its impact on entrepreneurs' business exit intentions. In particular, we identify entrepreneurial passion as one mediating mechanism through which entrepreneurs' loneliness influences business exit intentions. One time-lagged survey using a sample of entrepreneurs from the United Kingdom and an additional survey using a sample of Indonesian entrepreneurs show that high levels of entrepreneurs' loneliness increase their business exit intentions through reducing entrepreneurial passion. Our findings advance research on entrepreneurs' loneliness by identifying a new mechanism and extending its impact from entrepreneurs’ well-being-related outcomes to a business-related outcome.",June 2023,"Entrepreneurs' loneliness, Entrepreneurial passion, Business exit, Self-regulation theory",Business Venturing Insights,2025-03-08T00:00:00,7.0,"Exploring the impact of loneliness on entrepreneurs' business exit intentions through entrepreneurial passion adds to the understanding of entrepreneurial outcomes. While relevant, the practical implications for early-stage ventures and startups may be more indirect compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673422000683,Addressing the entrepreneur in the room: Entrepreneurial exit and impression management tactics in the employment interview context,Jacob A.=Waddingham: jwaddingham@txstate.edu; Alexander B.=Hamrick: azh0125@auburn.edu; Miles A.=Zachary: maz0014@auburn.edu,"Abstract
Despite the recent scholarly attention to the challenges entrepreneurs may 
face
 when attempting to rejoin the traditional workforce, we do not have a clear understanding of how recruiters respond to the various impression management (IM) tactics former entrepreneurs might use during 
employment interviews
. This is important because IM tactics shape how former entrepreneurs are viewed by recruiters and ultimately impact their employment prospects. We examine the effects of IM tactics in an online survey experiment with professional recruiters, finding support for most of our hypotheses. Specifically, we show that former entrepreneurs who exit by selling their venture can benefit from using tactical-assertive IM tactics to positively influence recruiters’ hiring recommendations. We contribute to the literature on entrepreneurial career transitions and hiring decision-making.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"This abstract provides valuable insights into how former entrepreneurs can improve their employment prospects by using impression management tactics during interviews, which can be crucial for early-stage ventures looking to rejoin the workforce."
https://www.sciencedirect.com/science/article/pii/S2352673423000021,"Transitions to entrepreneurship, self-realization, and prolonged working careers: Insights from the English Longitudinal Study of Ageing",Ewald=Kibler: ewald.kibler@aalto.fi; Teemu=Kautonen: teemu.kautonen@uaeu.ac.ae; Cal=Halvorsen: cal.halvorsen@bc.edu; Maria=Minniti: mminniti@syr.edu,"Abstract
This article contributes to our understanding of self-realization as a psychological benefit of entrepreneurship and its consequences on entrepreneurs' careers. By utilizing panel data from the English 
Longitudinal Study
 of Ageing (2002–2019), the analysis shows that individuals aged 50–67 experience an increase in perceived self-realization after starting a business, and this increase mediates the positive effect of transitioning to entrepreneurship on the individuals’ desire to postpone retirement. However, contrary to the dominant view in the literature, the self-realization effect of transitioning to entrepreneurship is short-lived: the perceived level of self-realization returns to the pre-start-up level within four years.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the study on self-realization benefits of entrepreneurship is interesting, the short-lived effect and focus on individuals aged 50-67 may limit its direct impact on European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S235267342300001X,Firm growth and profitability: The role of age and size in shifts between growth–profitability configurations,Susanna=Mansikkamäki: susanna.r.e.mansikkamaki@jyu.fi,"Abstract
To investigate the routes toward profitable growth, this study partially replicates and extends the work of Davidsson et al. (2009) on firm growth–profitability dynamics with multi-industry data on over 66,000 Finnish firms. The results support prior findings on initial profitability being more important than initial growth for achieving high performance in both performance dimensions. Additional investigations on the role of firm age and size reveal further interesting dynamics: Very small young firms 
face
 fewer risks from growing at a low profitability level than other firms, and the benefits of firm size for future performance depend on the firm's current profitability. The results advance the understanding of the reasons and consequences of the different modes (i.e., profitable vs. non-profitable) of firm growth.",June 2023,"Firm performance, Growth, Profitability, Firm age, Firm size, Replication",Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on firm growth and profitability dynamics provides important insights, but the focus on Finnish firms and the repetition of prior findings may limit its direct relevance to European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673423000033,"Different, but same: A power law perspective on how rock star female entrepreneurs reconceptualize “gender equality”",G. Christopher=Crawford: GCrawford@UT.edu; Zahra=Booyavi: zbooyavi@business.rutgers.edu,"Abstract
Prior studies investigating new venture emergence and growth from a gender-based lens have consistently found that, on average, female-founded ventures underperform their male-founded counterparts. In this study, we draw from the power law perspective to suggest that these findings primarily originate from the way researchers treat the outliers, those observations far from the normal. We hypothesize that the best of the best (i.e., the Rock Star) founders and ventures of each gender will have equally stellar performance. Contrary to the majority of entrepreneurship studies that consider outliers as ‘‘problems’’ that must be removed or transformed, the power law perspective assumes that outliers are different, have differential effects by skewing distributions far to the right, and are likely the most interesting and influential cases in the population. We leverage semi-parametric methods on longitudinal data from a representative sample of nascent entrepreneurial ventures to demonstrate the gender effect on outlier vs. non-outlier categories. Our findings suggest that gender does, in fact, negatively affect non-outliers (i.e., “average” entrepreneurs), while having no impact on outliers. We show that compared to the majority of the population, those with outlier 
inputs
—resource endowments, expectations for future growth, and engagement—have a greater likelihood of achieving outlier 
outcomes
, regardless of their gender. Our study contributes to the domain's inclusive understanding of women entrepreneurs and female-led ventures, and to the growing theoretical interest in the emergence of star performers.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"This study on gender effects on entrepreneurial performance, especially the impact of outliers, can help European early-stage ventures understand and leverage gender-related dynamics to achieve exceptional performance."
https://www.sciencedirect.com/science/article/pii/S2352673423000045,Metaverse-enabled entrepreneurship,Jörg=Weking: joerg.weking@qut.edu.au; Kevin C.=Desouza: kevin.desouza@qut.edu.au; Erwin=Fielt: e.fielt@qut.edu.au; Marek=Kowalkiewicz: marek.kowalkiewicz@qut.edu.au,"Abstract
Metaverse is expected to be a trillion-dollar market within this decade and to change the nature of entrepreneurship. However, research on metaverse, its opportunities, and challenges, as well as the nature of entrepreneurship remains scarce. This study lays out a framework to explore metaverse-enabled entrepreneurship with its enablers for supply and demand, and technological and social enablers. We show how metaverse enables transformational pathways, i.e., purely virtual, physical to virtual, virtual to physical, and hybrid, and shapes offerings, ventures, and processes. We discuss the implications for entrepreneurship research and lay out a future research agenda so that research can lead and inform practice.",June 2023,"Metaverse, Blockchain, Non-fungible tokens, Virtual reality, Augmented reality, Entrepreneurship",Business Venturing Insights,2025-03-08T00:00:00,9.0,"With the increasing relevance of the metaverse in entrepreneurship, this study presents a framework and future research agenda that can greatly benefit European early-stage ventures looking to explore metaverse-enabled entrepreneurship opportunities."
https://www.sciencedirect.com/science/article/pii/S2352673423000069,The growth process of IPO firms,Vivien=Lefebvre: vivien.lefebvre@em-strasbourg.eu,"Abstract
This study explores initial public offering (IPO) firms’ growth processes. Building on the idea that going public relaxes financial constraints and thus facilitates growth, this study uses an international sample of European IPO firms matched with comparable non-IPO firms to investigate whether and in which dimensions IPO firms grow faster than non-IPO firms do. Consistent with the Penrosean theory of growth, the results show that IPO firms grow first by acquiring fixed assets immediately after the listing and then by acquiring an additional workforce, corresponding to the resource acquisition stage of growth. The performance-enhancing stage of growth, during which IPO firms grow in sales, occurs later and culminates three years after an IPO. In addition, IPO firms are more likely to experience high-growth episodes in sales, but not in employment, than non-IPO firms. Overall, this study highlights the role of financing decisions in growth processes.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"This study provides valuable insights into the growth processes of IPO firms in Europe, highlighting the role of financing decisions in their growth. The findings can be beneficial for early-stage ventures looking to explore IPO opportunities."
https://www.sciencedirect.com/science/article/pii/S2352673423000057,Public family firms and economic inequality across societies,Jörn H.=Block: block@uni-trier.de,"Abstract
Research and public interest on economic inequality have grown over the last years. Family firms and the concentration of 
wealth
 and power in the hands of a few wealthy entrepreneurial families have been discussed as both a cause and a consequence of economic inequality. Yet, so far, we lack knowledge about the relationship between economic inequality and the prevalence of family firms in an economy. Our study investigates how the share of family-controlled public firms correlates with various measures of income and 
wealth
 inequality. The results show that a higher share of public family-controlled firms leads to more 
income inequality
 in a country. This effect is particularly pronounced for the middle of the income distribution as opposed to the top quantiles. Redistribution only mitigates this effect to some extent, as the effect is significant for market income and disposable income. We also find that a higher share of family-controlled firms contributes to an increase in 
wealth
 inequality. Our results are of economic relevance as, for instance, a one 
standard deviation
 change in the share of family-controlled firms leads to an increase of around 1.3–1.5 percentage points in the 
Gini coefficients
 for market income, disposable income, and 
wealth
.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"This study contributes to the understanding of economic inequality and its relationship with family-controlled public firms. While the findings are informative, the direct impact on early-stage ventures and startups may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000094,The impact of underpricing on newly public firm investments,Joseph J.=Cabral: jcabral@lsu.edu; M.V. Shyam=Kumar: kumarm2@rpi.edu,"Abstract
Going public not only provides access to capital, but it is also an important mechanism through which firms can obtain feedback on opportunities from a wider set of stakeholders and market participants. We develop this argument by examining how feedback from the Initial Public Offering (IPO) process in the form of underpricing influences a firm's subsequent investment decisions. Our results indicate that underpricing is associated with increases in investment spending in R&D and Capex post-IPO. Further, we find that at extreme levels of underpricing these shifts in investments have a detrimental effect on firm outcomes. Our work highlights that going public significantly alters the information environment and shapes the perceived opportunities of newly public firms in important ways. As such, the IPO and underpricing are not simply outcomes, but rather are important contributors to how firms allocate resources and pursue opportunities into the future. Further, findings suggest that effectively interpreting information from markets may be a previously overlooked capability that influences successful transition to public firm status.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study sheds light on how feedback from the IPO process influences a firm's investment decisions, which can be valuable for startups considering going public. The findings offer insights into resource allocation post-IPO."
https://www.sciencedirect.com/science/article/pii/S2352673423000100,Short-term mindfulness meditation training improves antecedents of opportunity recognition,Sebastian=Moder: sebastian.moder@uni.li,"Abstract
Entrepreneurial venture creation hinges on opportunity recognition, which is enabled by malleable cognitive characteristics such as alertness, creativity, and entrepreneurial self-efficacy. Meditation presents a promising strategy for cultivating these antecedents. In two studies, we examined the immediate effects of meditation on the antecedents of opportunity recognition. In Study 1, a 12-min guided meditation was administered to nascent entrepreneurs in a pre-post within-subjects experimental design. In Study 2, a 15-min breath counting task was used to assess how variations in accuracy and breathing rate shaped differences in outcomes. We found that the intervention in Study 1 had a small effect on alertness (
d
 = 0.44), a medium effect on creativity (
d
 = 0.79), and a large effect on entrepreneurial self-efficacy (
d
 = 0.93). Study 2 revealed a more nuanced relationship, whereby faster breathing rates predicted greater counting accuracy and alertness; in contrast, slower breathing rates and more frequent mind-wandering predicted greater uniqueness in the generated ideas. These findings suggest that meditation is useful for nascent entrepreneurs to prime their minds for successful opportunity recognition. The improvement in creativity may not solely be due to meditative practice itself but rather to the periods of mind-wandering that occur during the practice.",June 2023,"Entrepreneurship, Opportunity recognition, Entrepreneurial cognition, Mindfulness meditation, Entrepreneurial alertness",Business Venturing Insights,2025-03-08T00:00:00,9.0,This research on how meditation affects entrepreneurial opportunity recognition provides practical implications for nascent entrepreneurs. It offers a unique perspective on enhancing cognitive characteristics that are crucial for early-stage ventures and startups.
https://www.sciencedirect.com/science/article/pii/S2352673423000124,"Jockeys, horses or teams? The selection of startups by venture capitalists",Tekin=Esen: ae@mgmt.au.dk; Michael S.=Dahl: msd@business.aau.dk; Olav=Sorenson: olav.sorenson@anderson.ucla.edu,"Abstract
How do venture capitalists select startups? Most research to date has focused on the attributes of either the founders (the jockey) or the business idea (the horse) as the determinants of selection. Connecting information from VentureXpert to the Danish registry data allows us to extend this analysis to include information on all employees of startups (the team). To assess the importance of these factors to access to venture capital, our analysis compares startups that received funding to other startups founded at the same time and in the same 
industry
. Consistent with the jockey hypothesis and prior research, we find that firms with more and better educated founders have a higher probability of receiving venture capital. However, high-quality employees appear to matter even more than founders to the probability of being funded.",June 2023,"Venture capital, Entrepreneurs, Experiences, Founding teams, Employee",Business Venturing Insights,2025-03-08T00:00:00,8.0,"By including information on all employees of startups in the analysis, this study adds to the understanding of venture capital selection criteria. The focus on high-quality employees can be beneficial for early-stage ventures seeking funding."
https://www.sciencedirect.com/science/article/pii/S2352673423000136,The impact of independent and heterogeneous corporate venture capital on firm efficiency,Frank P.=Balz: frank.balz@hhl.de,"Abstract
While corporate venture capital funds (CVCs) are commonly analyzed as homogenous units, they display significant heterogeneity across various organizational aspects, which affect them and subsequently their portfolio firms. Using a sample of 383 European portfolio firms from the longitudinal VICO dataset, we first investigate the impact of investor type (independent vs corporate) on firm operating efficiency. We show that firms backed by CVCs suffer reductions in productivity. We then account for CVC heterogeneity and find that these significant reductions in operating efficiency only occur for ventures backed by endoisomorphistic CVCs, which resemble more corporate structures. By contrast, firms backed by exoisomorphistic CVCs, which resemble more independent venture capital structures, do not show significant differences in productivity compared to ventures that receive independent venture capital backing.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study provides insights into the impact of different types of corporate venture capital on firm operating efficiency in European portfolio firms, which can be useful for startups seeking funding."
https://www.sciencedirect.com/science/article/pii/S2352673422000476,Entrepreneurship as an auspicious context for mental health research,Johan=Wiklund: jwiklund@syr.edu; J.=Jeffrey Gish: jgish@ucf.edu; Alexander=McKelvie: mckelvie@syr.edu; Marcus=Wolfe: marcus.wolfe@unt.edu; Daniel A.=Lerner: daniel.lerner@ie.edu; Arjen=van Witteloostuijn: a.van.witteloostuijn@vu.nl,"Abstract
The intersection of entrepreneurship and mental health has spurred many novel lines of scholarly inquiry. In this editorial, we summarize 23 such studies that have been published in 
Journal of Business Venturing Insights
 over the last seven years. In doing so, we emphasize both the differences and similarities among studies in this emerging body of research. Our work illustrates a variety of silos emerging in this growing research domain, as well as potential opportunities for greater theoretical extensions and cumulative knowledge building. We offer several proposals that establish entrepreneurship as a bridging context for mental health inquiries, a context with the potential to unify previously siloed discoveries and shift the knowledge frontier upwards. We conclude with a note for practitioners on the potential virtuous cycle that awaits.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the intersection of entrepreneurship and mental health is important, the summary of existing studies may have limited immediate impact on European early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S2352673423000148,"How entrepreneurial behaviors manifest in non-traditional, heterodox contexts: Exploration of the Daigou phenomenon",Charmaine=Glavas: charmaine.glavas@qut.edu.au; Gary=Mortimer: gary.mortimer@qut.edu.au; Han=Ding: han.ding@utas.edu.au; Louise=Grimmer: louise.grimmer@utas.edu.au; Oscar=Vorobjovas-Pinta: oscar.pinta@utas.edu.au; Martin=Grimmer: martin.grimmer@utas.edu.au,"Abstract
Entrepreneurship is multifaceted and there is considerable acknowledgement of the relevance of human agency and individual behavior – since entrepreneurship has proven fundamentally personal. While entrepreneurial behaviors are traditionally aligned with high growth, start-up firms, an evolving body of research recognizes that entrepreneurial behaviors can manifest in non-traditional, ‘heterodox’ contexts. One such context is the 
Daigou
 phenomenon. Daigou translates to ‘buying on one's behalf’ – Daigou serve as important ‘middlemen’ – connecting Chinese customers with Western brands by deviating from accepted or orthodox standards or beliefs to exploit free-market networks and engage in cross-border exporting. Daigou, in the context of this research functions as a novel heterodox backdrop to probe manifestations of entrepreneurial behavior, thus identifying how entrepreneurial actors behave ‘entrepreneurially’ in heterodox settings. Our review of the literature delivers three meaningful contributions. Firstly, the findings contribute by advancing understanding of entrepreneurial behaviors in non-traditional and heterodox contexts. Secondly, by unveiling and incorporating new insights to the entrepreneurial behavior literature by integrating Daigou as a novel context for advancing understanding of meaningful heterodoxies. And thirdly, contributing back to the marketing literature by integrating insights from entrepreneurial behavior to inform conceptualizations of Daigou.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,"While the study explores entrepreneurial behaviors in a non-traditional context, the Daigou phenomenon may have limited direct relevance or impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673423000173,"The artificially intelligent entrepreneur: ChatGPT, prompt engineering, and entrepreneurial rhetoric creation",Jeremy C.=Short: jeremy.short@unt.edu; Cole E.=Short: cole.short@pepperdine.edu,"Abstract
To better understand the role of artificial intelligence in the development of entrepreneurial rhetoric, we examine how generative language models such as ChatGPT serve as viable tools for content creation. Using an established framework for examining CEO celebrity (Creator, Transformer, Rebel, and Savior), we illustrate how such models can effectively produce and refine elevator pitches, social media pitches, and crowdfunding pitches commonly used in the study of entrepreneurial rhetoric. We demonstrate ChatGPT's ability to mimic each celebrity CEO archetype by prompting language in the style of exemplars, including Elon Musk, Indra Nooyi, Tony Hsieh, and Lisa Su. Implications of prompt engineering—the fine-tuning of inputs fed into language models to produce precise output—for entrepreneurship research and practice are discussed. We conclude by advancing the idea that the emergent and enduring value of generative models is, at its core, dependent on effective prompt engineering.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The research on using generative language models for content creation in entrepreneurial contexts offers practical implications for startups looking to enhance their pitches and communication strategies.
https://www.sciencedirect.com/science/article/pii/S2352673423000185,"Automation vulnerability, voting, and self-employment",Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
We ask whether the prevalence of self-employment is higher among individuals voting right and facing automation vulnerability? Under growing automation vulnerability, those with right-leaning political orientations may be influenced by their stronger beliefs towards free markets, individualism, 
autonomy
, and self-reliance, and may therefore, be more likely to prevail in self-employment. Counter to our expectation, we find those vulnerable to automation and voting mainstream left were less likely to be self-employed. Automation vulnerability was associated with no systematic differences in wage or self-employment prevalence among those voting mainstream right, radical-right or radical left. The findings have implications for research on political values influencing the prevalence of self-employment under growing automation vulnerability.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"The study on self-employment prevalence, automation vulnerability, and political values may have limited direct applicability to European early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S2352673423000161,"Game on! Age, race, and performance in the board game industry",Marcus T.=Wolfe: Marcus.Wolfe@unt.edu; R. Gabrielle=Swab: rswab@georgiasouthern.edu,"Abstract
In this study, we examine age and race as important predictors to entrepreneurial outcomes. Drawing on 
social identity theory
, we examine a phenomenon among entrepreneurs in the board game 
industry
, where our findings are counterintuitive to previous research on age and race in entrepreneurs, suggesting a shift in identity and social norms in the 
industry
. With 69 entrepreneurs surveyed, and over 1000 data points of product play testing feedback, we find games designed by younger, minority entrepreneurs were rated higher by the play testers on innovation and the 
intent
 to buy. Additionally, we find that being a minority attenuated the negative relationship between age and entrepreneurial outcomes, such that older minority entrepreneurs did not experience a similar decline in outcomes as did their white counterparts. We discuss the implications of our findings.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,The examination of age and race as predictors of entrepreneurial outcomes in the board game industry can provide valuable insights for startups in terms of diversity and innovation strategies.
https://www.sciencedirect.com/science/article/pii/S2352673423000240,Explaining the stage of product in pre-seed academic startup ventures: An empirical analysis using monitoring data from a German startup support program,Christoph E.=Mueller: chr.mueller@fz-juelich.de,"Abstract
A central prerequisite for market entry and the subsequent economic performance of academic startup ventures is that the product on which the business model is based must be sufficiently well developed. The present research aims to provide answers in the quest to identify the explanatory factors in the development stage of the product of academic spin-offs in the pre-seed phase of their ventures. This is based on various factors that play a role in the innovation process and the development of new products – including characteristics of the project, characteristics of the R&D work and business model development, previous freelance experience, networking, financing, and technology field. The empirical analysis of data from academic startup ventures enrolled in a large German startup support program – using 
structural equation modeling
 – revealed both direct and indirect statistically significant effects, showing that a large proportion of the selected variables can be employed to explain the development stage of the product. The findings indicate that the R&D work stage has a medium-sized effect, while business model development stage, the degree of networking, project feasibility, and previous freelance experience connected with the product all have small effects.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The research provides valuable insights into the factors influencing the development stage of academic startup ventures, offering practical implications for early-stage European startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000312,The effect of gender fit on crowdfunding success,Yuanqing=Li: yli@dom.edu; Sui=Sui: sui.sui.66@gmail.com,"Abstract
We employed the Attraction-Selection-Attribution perspective to examine the 
effect of gender
 on crowdfunding. Based on the gender of both project founders and backers, we identified two types of fit, superficial and characteristic. Further, based on characteristic fit, we developed a typology of crowdfunding attractions. We then hypothesized that both superficial and characteristic fits can lead to crowdfunding success. We collected and analyzed data to demonstrate how different characteristics may be important to each attraction. Our findings suggest that similarity is positively related to funding intention for all crowdfunding founders. Male crowdfunding founders should demonstrate their credibility (trustworthiness and expertise) in front of their backers. Female crowdfunding founders should focus on their physical attractiveness, friendliness and warmth to attract more funding from their backers.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"This abstract examines the effect of gender on crowdfunding success, offering practical strategies for crowdfunding founders based on gender dynamics, which can be valuable for early-stage ventures seeking funding."
https://www.sciencedirect.com/science/article/pii/S2352673423000252,Why am I so successful? Self-presentation and deliberative attributions of success in entrepreneurship,Susana C.=Santos: santossc@rowan.edu; António=Caetano: antonio.caetano@iscte.pt; Ana=Brochado: ana.brochado@iscte.pt,"Abstract
This study explores the complexities of causes of success mentioned in entrepreneurs' 
narratives
 in a broadcasted context. Building on strategic self-presentation and 
attribution theories
, we employed inductive methods to map the configurations of public 
narratives
 explaining entrepreneurial success. The data analyzed were gathered from 173 reflective interviews featuring entrepreneurs on the United States' National Public Radio, using machine learning techniques for semantic content analysis. The results show that entrepreneurs can adopt three strategic presentation narratives to explain success in entrepreneurship. Significantly different patterns emerge in the three strategic narrative configurations. First, “lucky charming” narratives reflect an ingratiation strategy, mentioning external and uncontrollable causes of success to increase the entrepreneurs’ likability for the audience. Second, “work striving” narratives use self-promotion strategies to push for recognition of accomplishments, efforts, and intellectual abilities. Third, “social connecting” narratives simultaneously make use of ingratiation and exemplification strategies, including capitalizing on the positive signals given by the 
social support
 attracted during their entrepreneurial journey. These three discourse patterns have implications for influencing reputation and driving business- and personal-related outcomes. The findings provide a better understanding of deliberate appearances by entrepreneurs in broadcast contexts and tools for nascent entrepreneurs to leverage their role models among those with acclaimed entrepreneurial success.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study offers a comprehensive analysis of strategic presentation narratives in entrepreneurship, providing practical guidance for startups on influencing reputation and driving business outcomes."
https://www.sciencedirect.com/science/article/pii/S2352673423000264,Opportunity on Mars? roving for theory in the re(a)d dust rather than beyond,Richard J.=Arend: richard.arend@maine.edu,"Abstract
What inspires new entrepreneurial theory? And, what should it be – new entrepreneurial phenomena, new and different scholarly voices, or something else? There is recent evidence that it is a ‘something else’ – something that may be interpreted as unusual-yet-too-familiar – where established voices are stretching fictional stories and language games to get to their preferred models and definitions. While diversity and extension of ideas is more than welcome in our field, perhaps what is even more important is that that emerges from a more diverse and stretched set of authors, pedigrees and schools of thought. So, what is there to do? First, we can show that this current approach is not working through example. Second, we can suggest how to be better inspired. Third, we can consider the commonalities in these examples to comment on what that means for progress in the field as it is, and then to suggest ways for improvement at the field level. We take these three steps with an eye to the scientific 
mindset
 and a set of expectations about what makes good 
entrepreneurship theory",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the abstract discusses the importance of diversity and extension of ideas in entrepreneurship theory, it lacks direct practical value for early-stage European ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000531,"Effectuation, causation, and machine learning in co-creating entrepreneurial opportunities",Daniel=Lupp: daniel.lupp@ruhr-uni-bochum.de,"Abstract
In creating innovative entrepreneurial opportunities, entrepreneurs are characterized by limited 
information processing capabilities
 and local search routines that are immanent to humans. Machine learning (ML) offers the opportunity to overcome these limitations while reshaping the innovation process. It is indisputable that ML alone cannot realize entrepreneurial opportunities, but that close collaboration with the human entrepreneur is required. While entrepreneurs usually act according to the principles of effectuation logic in situations of high uncertainty and according to the principles of causation logic in situations of risk, it remains unclear how co-creation with ML affects the entrepreneur's decision-making behavior. By contrasting the functionalities of four different 
ML paradigms
 with the principles of the two decision logics, it is shown that supervised ML supports causation logic, while unsupervised and reinforcement ML support effectuation logic in their approach. As a fourth, semi-supervised ML is classified somewhere between effectuation and causation. However, in relation to the situational context of different types of uncertainty, ML may also prove limiting for effectuation by transitioning to causation in the medium-term.",June 2023,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The abstract explores the impact of machine learning on entrepreneurial decision-making, offering insights that could benefit startups, but the practical implications are not clearly outlined."
https://www.sciencedirect.com/science/article/pii/S2352673422000233,"“Scaling, blockchain technology, and entrepreneurial opportunities in developing countries”",Arun=Kumaraswamy: akumaras@fiu.edu; Hans=Rawhouser: hans.rawhouser@unlv.edu; Theodore L.=Waldron: theodore.waldron@ttu.edu; Justin W.=Webb: Justin.W.Webb@uncc.edu; Jason=Rodrigues: jason@celo.org; Joseph=Amankwah-Amoah: j.amankwah-amoah@kent.ac.uk; Azucena=Grady: azgrady@ttu.edu,"Abstract
Applications of blockchain technology (BCT) are scaling globally, especially in developing countries, where the opportunities that they exploit are often most prevalent. Achieving scale is vital for BCT ventures, which rely on network effects. BCT ventures seeking to scale employ innovative methods for scaling and also provide interesting insights on entrepreneurial scaling. We draw attention to three approaches that support scaling – promoting technology platforms, leveraging 
collective action
, and navigating institutional contexts– and identify theoretically-grounded strategies for scaling related to these three approaches. We also build from the practical experience of cLabs, a BCT venture seeking to scale Celo, a mobile-first 
cryptocurrency
 blockchain platform focused on the developing world. We examine what BCT proponents like cLabs need to do to scale quickly and synthesize key insights, strategies for BCT ventures in developing contexts, and opportunities for future research.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The abstract presents practical strategies for scaling blockchain technology ventures, with a specific focus on developing countries, which can be beneficial for European early-stage startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000403,The relationship of self-efficacy with entrepreneurial success: A meta-analytic replication and extension,Alexander=Glosenberg: alexander.glosenberg@lmu.edu,"Abstract
The replication of meta-analyses is important for developing stable and accurate insights into entrepreneurship. To that end, we replicate key aspects of the meta-analysis conducted by Miao et al. (2017) on the relationships between entrepreneurial self-efficacy (ESE) and financial measures of firm performance and extend their meta-analysis by considering generalized forms of self-efficacy and non-financial measures of entrepreneurial success. We expand the number of included samples from 27 in Miao et al. (2017) to 159. Overall, we find that the relationship between self-efficacy and success is small (ρ = 0.24) using guidelines from Cohen (1988); however, the relationship between ESE and at least partially financial measures of success was moderate, but larger in size (ρ = 0.44 vs. ρ = 0.31), than that estimated by Miao et al. (2017). We find that effect sizes vary widely depending on the type of success variable—with small to practically insignificant relations between self-efficacy and firm size as measured by the number of employees. In addition, we find stronger relations between ESE and success than generalized self-efficacy. Altogether we find that without properly accounting for the influence of the type of success variable, researchers might draw incorrect conclusions regarding the role of self-efficacy in entrepreneurial dynamics. We discuss the methodological and theoretical implications of our findings.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The replication and extension of a meta-analysis on entrepreneurial self-efficacy and success can provide valuable insights for early-stage ventures and startups to understand the implications of self-efficacy on firm performance.
https://www.sciencedirect.com/science/article/pii/S2352673422000178,Meaningful heterodoxies: Advancing entrepreneurship through engagement with unorthodox phenomena,Robert J.=Pidduck: rpidduck@odu.edu; Reginald=Tucker: regtucker@lsu.edu,"Abstract
Entrepreneurs proactively envision and pursue change, embracing the potential destruction of the status quo to create value by solving meaningful problems. With that, entrepreneurs themselves are the very embodiment of heterodoxy: deviation from accepted or orthodox standards or beliefs. The tensions, paradoxes, and juxtapositions of ideas, people, and resources underpinning heterodox thinking can shed considerable light on the discovery, enactment, evaluation, and exploitation of the opportunities the entrepreneurs of today are pursuing. To achieve this, though, requires directly tackling the real-world heterodoxies entrepreneurs are currently grappling with and developing their ventures within. Advancing knowledge on these critical inputs to entrepreneurship, however, involves entrepreneurship scholars explicitly seeking out and probing what we call 
meaningful heterodoxies
: the socio-cultural settings and/or potentially contentious phenomena entrepreneurs are immersed within that can be influential for generating novel and valuable ways of solving problems. As the “letters” of the field of entrepreneurship, the 
Journal of Business Venturing Insights
 is uniquely placed to tackle this. In this article, we introduce our new ongoing section and unpack several key contexts that we hope will guide submissions within the theme of meaningful heterodoxies.",November 2022,"Heterodoxy, Ideology, Paradox, Theory-building, Otherness, Intercultural dynamics, Unorthodoxy, Taboos, Rule-breaking",Business Venturing Insights,2025-03-08T00:00:00,6.0,"Exploring heterodox thinking in entrepreneurship can offer new perspectives, but the practical application for European early-stage ventures may require further clarification."
https://www.sciencedirect.com/science/article/pii/S235267342200021X,Non-fungible token-enabled entrepreneurship: A conceptual framework,Yanto=Chandra: yanto.chandra@polyu.edu.hk,"Abstract
Non-fungible tokens (NFTs) have taken the world by storm. Initially started as an art/game experiment, the NFT has given rise to a new form of entrepreneurship in the virtual world with massive opportunities and affordances. However, research into the entrepreneurial aspect of NFTs and the role of agency in the process is limited. In this article, I examine the concept of 
NFT-enabled Entrepreneurship (or NFTE)
. I first identify the main characteristics of NFTs, then define NFTE and discuss the related assumptions, and finally propose a conceptual framework for NFTE and investigate its enablers. I conclude by proposing NFTE as a novel domain of entrepreneurship theory and practice with extensive new research opportunities, and the plausibility of using NFT as an alternative mode of knowledge production in which scholars become “NFT creators.”",November 2022,"Non-fungible token, NFT, Entrepreneurship, Virtual, Enabler",Business Venturing Insights,2025-03-08T00:00:00,9.0,The analysis of NFT-enabled Entrepreneurship (NFTE) and the role of agency in the process could hold significant implications for startups looking to explore opportunities in the virtual world with NFTs.
https://www.sciencedirect.com/science/article/pii/S2352673422000208,"“I put in effort, but I am still not passionate”: The fit perceptions of novice entrepreneurs",Fei=Zhu: fei.zhu@nottingham.edu.cn; Imran=Syed: aisyed@bsu.edu; Dan K.=Hsu: dan.hsu@ndsu.edu; Dan=Cohen: cohenda@wfu.edu; Rachel S.=Shinnar: shinnarrs@appstate.edu,"Abstract
Entrepreneurial effort has been found to be an important predictor of entrepreneurial passion. The more effort one devotes to 
entrepreneurial activities
, the more passionate one becomes. Our work, however, extends prior research by offering contrasting empirical evidence. Drawing on fit theory and the person-entrepreneurship fit perspective, we propose that for novice individuals, who do not feel a strong fit with entrepreneurship, engaging in entrepreneurial effort would increase the perception of misfit, thereby reducing their entrepreneurial passion. Results from two experimental studies confirm our hypotheses. Our research contributes to the entrepreneurial passion and the person-entrepreneurship fit literatures.",November 2022,"Entrepreneurial effort, Entrepreneurial passion, Anticipatory person-entrepreneurship fit, Perceived person-entrepreneurship fit, Experiment",Business Venturing Insights,2025-03-08T00:00:00,4.0,"While the research on entrepreneurial effort and passion is interesting, the focus on novice individuals feeling misfit may have limited direct relevance to European early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000245,Two types of entrepreneurship process research revisited: Solidifying the evidence and moving forward,Per=Davidsson: per.davidsson@qut.edu.au; Jan Henrik=Gruenhagen: jan.grunhagen@qut.edu.au,"Abstract
In their review of venture creation process research, Davidsson and Gruenhagen (2021) identified two distinct types of process research: 
process as a journey through qualitative changes in content
 and 
process as a directional and temporal journey toward a goal
. We revisit their findings with more robust methodology and find that these two are indeed distinct, ideal types that capture two centers of gravity in process-oriented research on venture creation. We enrich the picture of these two types of process research and develop ideas for how future research can address their respective weaknesses.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"This abstract offers insights into the distinct types of process research on venture creation, providing valuable information for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000221,What are pre-acceleration programs?,Nitzan=Merguei: nitzan.merguei@maastrichtuniversity.nl; Carla=Costa: c.costa@maastrichtuniversity.nl,"Abstract
In recent years, a new phenomenon emerged in entrepreneurial ecosystems: the pre-acceleration program. Departing from the literature on the entrepreneurship support ecosystem, we define, describe, and compare the main characteristics of these programs. We define pre-accelerators as early-stage entrepreneurship support organizations which are highly structured and with strong educational content, of short duration (generally less than three months), and aim to support aspiring entrepreneurs in speeding the process of venture concept emergence through fast-paced interactions and problem-solution validation. Participants start with (or without) scattered ideas that change and evolve during the program. Most often they can enter individually, and teams are formed from interactions within the cohort.",November 2022,"Pre-acceleration, Entrepreneurship, Entrepreneurship support organizations",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The abstract introduces a new phenomenon in entrepreneurial ecosystems, pre-acceleration programs, which can have a significant impact on early-stage ventures seeking support and guidance."
https://www.sciencedirect.com/science/article/pii/S2352673422000270,"Stress[ed] out, leisure in: The role of leisure crafting in facilitating entrepreneurs’ work stressor— creativity relationship",Alexander B.=Hamrick: azh0125@auburn.edu,"Abstract
Although entrepreneurs' work tends to be highly stressful, it is unclear how specific work stressors influence entrepreneurs' work outcomes. Drawing on the challenge-hindrance stressor framework (CHSF), we examine how both challenge and hindrance stressors influence entrepreneurs' creativity. Additionally, to investigate a more complete view of the entrepreneurial stress process, we integrate the CHSF with theory on leisure crafting to examine how proactively structuring one's leisure might help entrepreneurs deal with stress and maintain creativity. Results from a time-lagged study of 258 entrepreneurs showed that challenge stressors were positively and directly related to entrepreneurs' creativity, whereas hindrance stressors were not. Hindrance stressors increased engagement in leisure crafting, which enhanced creativity, highlighting a positive indirect effect of hindrance stressors on entrepreneurs' creativity. These findings provide generative insights into the nature of stressors and the micro-foundational mechanisms of stress and leisure within entrepreneurship.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"This abstract delves into the impact of stressors on entrepreneurs' creativity, offering practical implications for managing stress and maintaining creativity in early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000282,Venture governance as a syndicate,Dennis=Gan: dennis.gan@sfe.uio.no,"Abstract
Acquisition as a means to achieving growth is a common practice among established firms. Increasingly, we are witnessing start-ups following in the footsteps of these firms, acquiring other start-ups for inorganic growth. This paper analyses this phenomenon from the point of view of the acquiree, seeing venture governance as a syndicate drawing on relational 
pluralism
. In the current study, we conceive of relational pluralism not as a safeguarding mechanism, but as a facilitating one. As such, we regard multiple interlocking board ties as a form of a syndicate and address the mediating role of a portfolio of such ties. That is, we not only show how a portfolio of board interlocking ties contributes to mediate the process of achieving growth by being acquired by another firm, but we also point to a leadership structure facilitating such an inorganic growth mode.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The abstract explores the practice of start-ups acquiring other start-ups for growth, providing insights into venture governance and leadership structures but may have limited immediate practical application for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000324,Confronting when uncertainty-as-unknowability is mismodelled in entrepreneurship,Richard J.=Arend: richard.arend@maine.edu,"Abstract
Uncertainty has been and continues to be misunderstood, in the forms it can take, in its definitions, and in how it and its effects are modelled. That confusion is unhelpful for theorizing in general and, more specifically, it is detrimental for the study of entrepreneurship, given our field’s intimate if not existential connection with uncertainty. When the confusion is caused by a mischaracterization of uncertainty that is represented in mathematical form – eliminating any definitional and operational ambiguities – then that poses a severe problem that requires redress if we are to remain legitimate as a scientific field. The focus of this piece is on a critical assessment of a recent and visible paper that claims to model uncertainty in its equations but we argue does not. We first to critique the example, focusing on uncertainty-related issues (while also considering other modelling problems that make the paper’s insights into uncertainty questionable), and second we consider feedback over our critique itself (so as to identify impediments to clarifying the issues surrounding uncertainty that exist in our field).",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The abstract addresses a theoretical confusion around uncertainty modeling, which may have some impact on early-stage ventures but lacks direct practical implications."
https://www.sciencedirect.com/science/article/pii/S2352673422000336,Why we need normative theories of entrepreneurial learning that go beyond Bayesianism,Nicolai J.=Foss: Njf.si@cbs.dk,"Abstract
Zellweger and Zenger's (ZZ) article
, “
Entrepreneurs as scientists: A pragmatist approach to producing value out of uncertainty,” represents a potentially influential contribution to the understanding of 
decision making under uncertainty
. This short paper points to two major problems in their article: it 1) seeks to reduce uncertainty to risk and ignores the problem of unknown unknowns, and 2) does not identify the key inferential problem of linking the few current data points known by an entrepreneur to her imagination as it pertains to an unknowable future. We point to devising alternative models of learning that have the potential to overcome these problems as a research effort that should be prioritized within the emerging field of entrepreneurial learning.",November 2022,"Entrepreneurial learning, Bayesianism, Knightian uncertainty, Inferential problems",Business Venturing Insights,2025-03-08T00:00:00,7.0,Identifying problems in reducing uncertainty to risk and proposing alternative models of learning can provide valuable insights for early-stage ventures navigating uncertain environments.
https://www.sciencedirect.com/science/article/pii/S2352673422000348,"Unsticking the rationality stalemate: Motivated reasoning, reality, and irrationality",Daniel A.=Lerner: Daniel.Lerner@ie.edu; Rasim Serdar=Kurdoglu: r.s.kurdoglu@bilkent.edu.tr; Nufer Yasin=Ates: nufer.ates@sabanciuniv.edu,"Abstract
Rationality is an elusive and increasingly debated concept in entrepreneurship research. We offer a novel conceptualization of rationality based on reasoning motivations. We posit that logical, probabilistic, and heuristic reasoning logics are motivationally rational because the decision-maker attempts to accurately perceive the external world and problem-solve (even if rapidly and approximately). By contrast, when the reasoning ignores an assessment of reality and accuracy in problem-solving and instead is deluded by psychological (e.g., hedonic) urges that prompt self-serving inferences, we categorize such decisions as motivationally irrational. We develop a theoretical account for how motivational irrationality is adaptive under extreme uncertainty as it enables entrepreneurs to dare action when even heuristic reasoning is inconclusive or entirely ineffective.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The conceptualization of rationality based on reasoning motivations could offer some practical guidance for decision-making in early-stage ventures, although more concrete examples would enhance its impact."
https://www.sciencedirect.com/science/article/pii/S2352673422000385,"Baby, I'm addicted! The pleasure-pain pathway that shifts entrepreneurial passion to entrepreneurial addiction: Pivotal role of dopamine",Rai Siddhant=Sinha: siddhants13fpm@iimk.ac.in,"Abstract
Passionate entrepreneurs often refer to their ventures as their babies; while we know that passion drives 
entrepreneurial action
, research space is unclear about how entrepreneurial passion leads to addiction. This work takes a reductionist approach to explicate how entrepreneurial passion shifts to entrepreneurial addiction by discussing the pleasure-pain pathway that dopamine governs. Such an approach unravels how in a relentless pursuit of pleasure, an individual chases entrepreneurship because they are passionate about it but ends up being addicted to it. Besides contributing to 
entrepreneurship theory
 and practice, I discuss several future directions embedded in neuroentrepreneurship.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"Exploring the transition from entrepreneurial passion to addiction through neuroentrepreneurship creates valuable knowledge for understanding the psychological aspects of entrepreneurship, which can have significant implications for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000373,Transitions and implications of time perspectives: A qualitative study of early-stage entrepreneurs,Unnati=Kapoor: Unnati.Kapoor@dms.iitd.ac.in; Shuchi=Sinha: shuchi@dms.iitd.ac.in,"Abstract
Uncertainty and resource scarcity are usually considered the hallmark of entrepreneurship. Entrepreneurs are required to make quick decisions, develop ideas, implement them, and decide on future goals and courses of action while operating within an uncertain and challenging environment, especially at the early stages of entrepreneurship. Time perspectives offer a lens to identify entrepreneurs' decisions, affect, sense-making, and behavior and influence entrepreneurs' planning, motivation, goal setting, and coping mechanisms; which in turn influence the start-up effort and process. Results from a two-phase 
qualitative study
 capture the implications of these time perspectives for early-stage entrepreneurs. We find that future-oriented, early-stage entrepreneurs are better at planning, implementing, and managing resources than present-hedonistic-oriented entrepreneurs. Future-oriented entrepreneurs are more adaptive and cope better with extreme situations or crises. Findings also support the alterable nature of these time perspectives and reveal the transitions that occur in them. Transitions in time perspectives are influenced by extreme external circumstances like the COVID-19 crisis in our study. Our findings also highlight the importance of 
social support
 in promoting positive transitions in time perspectives.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study on time perspectives and their impact on early-stage entrepreneurs provides practical insights on planning, resource management, and coping mechanisms, especially in extreme situations like the COVID-19 crisis."
https://www.sciencedirect.com/science/article/pii/S2352673422000427,"Entrepreneurial ecosystems: Multiple domains, dimensions and relationships",Simon=Stephens: simon.stephens@atu.ie; Christopher=McLaughlin: cg.mclaughlin@ulster.ac.uk; Leah=Ryan: leah.ryan@ernact.eu; Manuel=Catena: Manuel.Catena@atu.ie; Aisling=Bonner: Aisling.bonner@atu.ie,"Abstract
In this paper we examine the operation of 
entrepreneurial ecosystems
. We use the work of Isenberg (2010) to frame a study of an ecosystem in Ireland. Following a review of the literature and guided by an expert panel (n = 8) we conducted a survey of 
small business owners
 (n = 100). Statistical analysis of the survey data revealed sixteen dimensions with a complex system of interrelationships. In the discussion we explain how and importantly why the dimensions can and should be identified and analysed. We propose that although an entrepreneurial ecosystem will align with an extended version of the six domains proposed by Isenberg (2010) each individual ecosystem must be studied to identify its complex system of unique dimensions. Implications for theory and practice, as well as limitations and future research directions, are discussed. It is envisaged that our approach to modelling ecosystems will serve as the basis for further thought and empiricism.",November 2022,"Entrepreneurial ecosystem, Small business, Dimensions, Isenberg",Business Venturing Insights,2025-03-08T00:00:00,7.0,The study on entrepreneurial ecosystems in Ireland and the identification of unique dimensions can provide valuable insights and practical advice for startups in Europe.
https://www.sciencedirect.com/science/article/pii/S2352673422000415,McBride and Wuebker's Socially Objective Opportunities: Do they move the field forward?,Per=Davidsson: per.davidsson@qut.edu.au,"Abstract
McBride and Wuebker's (2022) “Social Objectivity and Entrepreneurial Opportunities” – published in 
Academy of Management Review
 and hence potentially influential – provides an improved philosophical basis for ‘creation theory’ compared to earlier attempts in that direction, and it undoubtedly reflects a considerable amount of hard work and an honest intent to make a meaningful contribution. Regrettably, it is also characterized by questionable premises, claims, and conclusions. In this article I identify and discuss these issues and explain why McBride and Wuebker may mislead our field rather than guiding it toward more productive knowledge accumulation and dissemination. I argue that much more is known about new venture creation than their narrow lens allows us to see, and that going forward based on their suggestions would lead to lopsided entrepreneurship research and education.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,"The criticism of McBride and Wuebker's work, while potentially influential, does not directly provide practical value for European early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000440,Do bankruptcy laws matter for entrepreneurship? A Synthetic Control Method analysis of a bankruptcy reform in Finland,Ali=Sadeghi: ali.sadeghi@aalto.fi,"Abstract
The design of a 
bankruptcy
 regime can influence the risk perception of entrepreneurs, impacting their growth ambitions as well as their very decision whether to become entrepreneurs. The relationship between bankruptcy legislation and entrepreneurship, therefore, should be of interest to policymakers and entrepreneurs alike. In this paper, we make an attempt to determine the effect of an entrepreneur-friendly bankruptcy reform in Finland, in 2004, on the level of 
entrepreneurial activity
 in the country. Running a 
Synthetic Control Method
 analysis, we find zero effect: the reform had no significant effect on entrepreneurship. We conclude the paper by offering some explanations for the non-finding and discussing its potential implications for policy.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study on the relationship between bankruptcy legislation and entrepreneurship in Finland may offer some insights for policymakers and entrepreneurs, but the zero effect found limits the practical impact for startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000452,How impact investing firms are responding to sustain and grow social economy enterprises in light of the COVID-19 pandemic,Syrus M.=Islam: syrus.islam@aut.ac.nz; Ahsan=Habib: a.habib@massey.ac.nz,"Abstract
The COVID-19-induced disruptions have hardest hit social economy 
enterprises
. While 
impact investing
 is considered a promising vehicle to stimulate and grow social economy enterprises, little is known about how impact investors are actually responding to sustain and grow social economy enterprises amidst the COVID-19 pandemic. We find that impact investors sacrifice additional financial returns in pandemic-focused impact investments where they see the potential for attaining significantly higher than usual social impact by protecting hundreds of vulnerable social economy enterprises and beneficiaries amidst the pandemic. We also find that guarantees are introduced as an innovative impact investment instrument to tackle the pandemic, although they have remained heavily underutilized. Furthermore, debt instruments tend to dominate in pandemic-focused impact investments. Finally, in response to the pandemic, impact investors emphasize developing and strengthening a supportive social impact ecosystem to protect both portfolio and non-portfolio social economy enterprises and their beneficiaries. We also explain how the impact investing market has evolved during pandemic times and how it might evolve post-pandemic to support social economy enterprises.",November 2022,"Impact investing, Social economy enterprise, COVID-19 pandemic, Impact-return trade-off, Social impact ecosystem",Business Venturing Insights,2025-03-08T00:00:00,9.0,The findings on impact investing in social economy enterprises during the COVID-19 pandemic can greatly benefit European startups by showcasing innovative strategies and instruments to sustain and grow businesses in challenging times.
https://www.sciencedirect.com/science/article/pii/S2352673422000464,Psychological factors explaining Ukrainian refugee entrepreneurs’ venture idea novelty,Kim=Klyver: kkl@sam.sdu.dk; Benson=Honig: bhonig@mcmaster.ca; Paul=Steffens: paul.steffens@adelaide.edu.au,"Abstract
In this study we investigate the (relative) importance of four psychological factors previously identify as important for entrepreneurship in adversity. Specifically, we investigate the importance of personal initiative, individual resilience, entrepreneurial self-efficacy and crisis self-efficacy for new venture novelty among Ukrainian refugee entrepreneurs arriving in Denmark in 2022 early after the Russian invasion. We identify and surveyed a sample of Ukrainian refugee entrepreneurs through Google's training program labelled ‘WeStart for Ukrainians’. We found that crisis self-efficacy seems to be the most important psychological factor explaining new venture novelty among refugee entrepreneurs.",November 2022,"Crisis response, Refugees, Venture idea novelty, Personal initiative, Resilience, Entrepreneurial self-efficacy, Crisis self-efficacy",Business Venturing Insights,2025-03-08T00:00:00,7.0,The investigation into psychological factors affecting new venture novelty among Ukrainian refugee entrepreneurs can provide valuable insights for startups in Europe facing adversity and seeking to innovate.
https://www.sciencedirect.com/science/article/pii/S2352673422000506,Passion drove me here: Exploring how types of entrepreneurial passion influence different entrepreneurial intentions,Jordan J.=McSweeney: jjmcsweeney@suffolk.edu; Kevin T.=McSweeney: kevin.mcsweeney@sbs.ox.ac.uk; Justin W.=Webb: justin.w.webb@uncc.edu; Rosalyn G.=Sandoval: rossandoval@csumb.edu,"Abstract
Despite research advancing our understanding of the role of entrepreneurial passion— positive feelings towards entrepreneurial activities—in influencing entrepreneurial intentions, research largely examines one type of passion and one type of intention. Yet, individuals might prefer engaging in some 
entrepreneurial activities
 but not others and can pursue three different entrepreneurial paths to do so (traditional, corporate, social). Hence, questions remain then as to how individuals’ passion for different 
entrepreneurial activities
 (founding, inventing, developing) may differentially influence their traditional, corporate, and social entrepreneurial intentions. Drawing on entrepreneurial passion and intentions research we theorize how different types of passion vary in the extent to which they engender different entrepreneurial intentions. We test our arguments using a sample of 231 individuals participating in a two-year entrepreneurship fellowship program in the U.S. We contribute to prior research by providing a more holistic understanding of the role of entrepreneurial passion in influencing different entrepreneurial intentions.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study provides a more holistic understanding of entrepreneurial passion and its influence on different entrepreneurial intentions, which can be valuable for early-stage ventures exploring various paths."
https://www.sciencedirect.com/science/article/pii/S2352673422000518,"Crowdfund smart, not hard – Understanding the role of online funding communities in crowdfunding success",Ghazwan=Hassna: ghassna@hpu.edu,"Abstract
One of the unique characteristics of crowdfunding is that funding flows from the online community of individuals and organizations who identify with the campaign and are most interested in its viability and success. Most of these online funding communities (OFCs) are built around common shared goals, ideologies, enthusiasm for, or interests in specific funding activities. Despite this uniqueness, we understand little about the role that these communities play in crowdfunding success. Utilizing a rich dataset integrated from one of the most popular crowdfunding platforms in the UK, we explain how targeting an OFC positively influences crowdfunding success. Following a text similarity approach, we also provide evidence that the congruence between the crowdfunding campaign and targeted OFC is associated with higher success rate. We discuss the contribution to the academic literature on entrepreneurial 
finance
 and crowdfunding success as well as the practical implications for entrepreneurs interested in tapping the potential of crowdfunding as an alternative source of financing.",November 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"Understanding the role of online funding communities in crowdfunding success can have practical implications for startups seeking alternative sources of financing, making it highly relevant for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673421000755,Alternative investing as brokering: The embedding process of a Social Impact Bond model in a local context,Sarah=Jack: sarah.jack@hhs.se; Mikhail=Kosmynin: mikhail.kosmynin@nord.no,"Abstract
Social Impact Bonds (SIBs) are gaining traction as a research topic. Using a longitudinal 
case study
 of a Norwegian social venture - Nature Magic - funded through a SIB model, this article explores the embedding process of a SIB model into a local context – diverging from previous research focused on empirical cases from the UK and USA and refining the social aspects of SIBs. We show that the SIB model is embedded through three processes: 1) cultivating opportunity; 2) pulling together; and 3) fostering experimentation and ‘mutation’. We find that these embedding processes were fostered through developing and activating bonding and bridging social capital. This study also extends our understanding of alternative investing by theorizing it as brokering. We find that social investors engage in brokering processes in facilitating collaboration between typically disconnected spheres - such as social ventures and municipalities - through these embedding processes.",June 2022,"Social impact bond, Collaboration, Embedding, Alternative investment, Brokering",Business Venturing Insights,2025-03-08T00:00:00,6.0,"The exploration of Social Impact Bonds and their embedding processes provides insights for social ventures and investors, but may have limited direct practical impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000014,Perceptual factors explaining the gender gap in entrepreneurial propensity: A replication and extension,Jörn H.=Block: block@uni-trier.de,"Abstract
Perceptual factors explain a large part of the gender gap in entrepreneurial propensity. The study by Koellinger et al. (2013) is an influential study in this literature stream. We replicate this study with more recent data and broader country coverage. Our findings show that 
gender differences
 in entrepreneurial propensity still exist (although the effect size has been reduced substantially) and can be attributed to differences in perceptions of entrepreneurial skills. Surprisingly, the negative effect attributed to female respondents becomes positive after taking into account differences in skill perception, meaning that women have a 
higher
 entrepreneurial propensity than men. We discuss the practical and theoretical implications of this surprising and important finding and provide avenues for future research.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,The surprising finding regarding gender differences in entrepreneurial propensity and perceptions of entrepreneurial skills can have significant practical implications for promoting diversity and inclusion in European startups.
https://www.sciencedirect.com/science/article/pii/S2352673422000105,Entrepreneurial orientation as a mediator of ADHD – Performance relationship: A staged quasi-replication study,Galina=Shirokova: gshirokova@hse.ru; Elena=Shakina: eshakina@hse.ru; Violetta=Bacon-Gerasymenko: violetta.gerasymenko@oregonstate.edu; William=Wales: wwales@albany.edu,"Abstract
The entrepreneurship literature has suggested the criticality of replicating findings along with the potential for nuance when examining relationships within emerging market contexts. In this study, we seek to reproduce the findings of Yu et al. (2021) concerning entrepreneurial orientation (EO), attention-deficit/hyperactivity disorder (ADHD), and firm performance using a sample of Russian 
SMEs
. We conduct a quasi-replication study, systematically changing the data, measures, and construct within our empirical models. The results of our study are partly in line with the original study's findings: we did not find a significant relationship between hyperactivity/impulsivity symptoms and EO. However, when we considered different sub-dimensions of EO (innovativeness, 
proactiveness
, and risk-taking), managers with hyperactivity/impulsivity ADHD symptoms exhibited greater innovativeness, 
proactiveness
, and risk-taking, while managers with inattention ADHD symptoms exhibited opposite effects. We discuss the extent to which the effects of ADHD on firm performance in developed economies, as mediated by EO, are generalizable within an emerging economy.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the study offers insights on the relationship between ADHD symptoms and entrepreneurial orientation in an emerging economy context, the direct impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673422000075,Beyond the bubble: Will NFTs and digital proof of ownership empower creative industry entrepreneurs?,Dominic=Chalmers: dominic.chalmers@glasgow.ac.uk,"Abstract
Non-fungible Tokens (NFTs) are blockchain-enabled cryptographic assets that represent proof-of-ownership for digital objects. The use of NFTs has been pioneered by creative industry entrepreneurs who have sought to generate new revenue streams and modes of stakeholder engagement. Despite rapid growth in popularity, concerns have been raised around the legal ownership of NFT assets and the prevalence of speculation and fraud associated with NFT trading. In this rapid response article, we explore the value of NFTs for creative industry entrepreneurs. First, we examine the novel digital affordances of the technology; second, we analyse NFTs through the prism of the recent Initial Coin Offering (ICO) boom and bust; and finally, we take a longer-term historical perspective to consider how past speculative waves inform the present NFT economy. While we identify some potentially valuable artistic and financial opportunities for creative industry entrepreneurs, we conclude that NFTs should be approached with caution.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The exploration of NFTs for creative industry entrepreneurs provides valuable insights into a trending area of interest, highlighting both opportunities and risks."
https://www.sciencedirect.com/science/article/pii/S2352673421000676,Founding team characteristics and the pursuit of social motives: A role theory perspective,Jeffrey A.=Chandler: jeffrey.chandler@unt.edu; Jeremy C.=Short: jeremy.short@unt.edu; Md Kamrul=Hasan: mdkamrul.hasan@unt.edu; Gang=Fan: anders.fan@unt.edu,"Abstract
There is increasing pressure for new ventures to engage in 
social initiatives
. Yet, little is known about the new venture team dynamics that might lead entrepreneurs to commit to 
social engagement
. Using a multinational sample of 5393 new ventures drawn from the Entrepreneurship Database Program, we use social role theory to hypothesize how founding team characteristics hold potential to inspire social motives in their ventures. Specifically, we find that founding teams with more women entrepreneurs, younger founding team members, and founding teams with greater education are positively associated with the pursuit of social motives in new ventures. Post hoc analysis exploring how participation in accelerator programs influences these relationships suggests participation in accelerator programs diminishes the pursuit of social motives by founding teams with more female team members – but has no effect on this pursuit by younger or more educated founding teams. Our findings shed light on how founding team characteristics associated with social roles in society predict the pursuit of social motives in new ventures.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study on new venture team dynamics and social engagement, while interesting, may not directly impact early-stage ventures significantly."
https://www.sciencedirect.com/science/article/pii/S2352673421000640,"A field guide for gazelle hunters: Small, old firms are unlikely to become high-growth firms",Alex=Coad: alex.coad@waseda.jp; Johan=Karlsson: johan.karlsson@ju.se,"Abstract
We map the distribution of High-Growth Firms (HGFs, or “gazelles”) across the dimensions of firm size and firm age using contour plots, where firm size and growth are measured in terms of employees. The analysis is based on Swedish total population data for the period 1990–2016, covering approximately 11, 000, 000 firm-year observations. The results show that the majority of HGFs are small, which partly follows the high representation of small firms in the population. Yet when considering the proportions of HGFs across firm ages and sizes, a distinct feature emerges in that the 
territory
 of small, old firms appears to be almost completely deserted—despite their large overall numbers—where firms in this category have the (by far) lowest chances of becoming HGFs.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"While the mapping of High-Growth Firms is informative, the practical impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673421000664,Perceived warmth and competence in crowdfunding: Which matters more and for whom?,Pyayt P.=Oo: pyayt.oo@uta.edu; Leah D.=Sheppard: leah.sheppard@wsu.edu; Steven A.=Creek: creeksa@appstate.edu,"Abstract
Despite the importance of warmth and competence for social evaluation processes, we do not have a clear understanding of their relevance in entrepreneurial resource acquisition contexts. We examine the effects of cursory impressions of 350 
Kickstarter
 crowdfunding entrepreneurs’ warmth and competence on the performance of their campaigns. Drawing from the stereotype content model and expectancy violation theory, we propose and find support for a model in which different forms of trust mediate the relationships between warmth and competence and crowdfunding performance, with the strength of these pathways differing as a function of entrepreneur gender. Specifically, we show that the crowdfunding performance of women entrepreneurs is uniquely benefited by perceptions of competence and the cognition-based trust that ensues, relative to the performance of men entrepreneurs.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The examination of how warmth and competence influence crowdfunding performance provides relevant insights for entrepreneurs, albeit in a specific context."
https://www.sciencedirect.com/science/article/pii/S2352673421000706,Leveraging smart capital through corporate venture capital: A typology of value creation for new venture firms,Benjamin M.=Bugl: benjamin.bugl@hhl.de,"Abstract
Corporate Venture Capital (CVC) units position themselves as smart capital providers in new venture firm New Venture Firm (NVF) financing. In line with the resource-based view and 
social capital theory
, extant research postulates that CVCs contribute complementary assets beyond capital to their NVFs. However, the non-financial value for NVFs is mainly created through a corporate business unit within the CVC's corporate parent company. As agency theory implies, the strategic agendas of CVCs, NVFs, and corporate business units may not always align and thereby often hamper value creation. Hence, our 
qualitative research
 builds on a cross-industry 
case study
 of eleven CVC units to show how they leverage resources from their corporate sponsors to add value for NVFs. We reveal the mechanism behind CVC value creation holistically by identifying eight design elements that lead to a typology of four distinctive CVC forms. This classification offers a representation of the CVC landscape based on their institutional environment.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,The study on Corporate Venture Capital units adds to the theoretical understanding but may not offer direct practical value for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673421000743,Humility in social entrepreneurs and its implications for social impact entrepreneurial ecosystems,Philip T.=Roundy: philip-roundy@utc.edu; Thomas S.=Lyons: thomas-lyons@utc.edu,"Abstract
Why do some social entrepreneurs embrace the assistance of their social impact 
entrepreneurial ecosystems
 (SIEEs) in creating and scaling social ventures while others go-it-alone and do not capitalize on the resources in their local communities? To explain this difference in social entrepreneurs, we draw from work in leadership and positive organizational scholarship to develop a multi-level theory of humility in SIEEs. We theorize that social entrepreneurs’ humility affects the extent to which they seek and contribute ecosystem resources. The humility-driven resource behaviors of social entrepreneurs, in turn, influence SIEE-level coordination. Our theory of humility in ecosystems contributes to understanding the micro-foundations of SIEEs and has implications for social entrepreneurs and ecosystem builders.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on humility in social impact entrepreneurial ecosystems can provide insights for social entrepreneurs and ecosystem builders, but its practical value might be limited for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673421000731,"Capturing passion expressed in text with artificial intelligence (AI): Affective passion waned, and identity centrality was sustained in social ventures",Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Amanda Jasmine=Williamson: Amanda.Williamson@waikato.ac.nz; Martina=Battisti: martina.battisti@grenoble-em.com,"Abstract
Entrepreneurial passion can influence individual well-being and improve firm-level outcomes, yet little is known about how to rapidly detect a change in passion from entrepreneurs’ communication. We draw on advancements in both the passion literature and artificial intelligence (AI) methods, to capture entrepreneurial passion expressed for founding a venture at different points in time. Specifically, we developed an AI algorithm to recognize identity-based passion (identity centrality) from training data, comprised of 8 h of transcribed interviews with entrepreneurs (achieving 84% accuracy), and detect affective passion (intense positive feelings) with sentiment analysis. Application of these two novel measurement approaches, to longitudinal interview text with early-stage entrepreneurs (
N
 = 11, two time periods) in a six-month social venture accelerator, indicate that intense positive feelings decline while identity centrality varies. We conclude by outlining opportunities for future research.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The use of AI to detect changes in entrepreneurial passion and its impact on individual well-being and firm-level outcomes can have practical implications for early-stage entrepreneurs in understanding their emotions and motivations.
https://www.sciencedirect.com/science/article/pii/S2352673421000718,"Latent profiles of personality, temperament, and eudaimonic well-being: Comparing life satisfaction and health outcomes among entrepreneurs and employees",J.=Jeffrey Gish: jgish@ucf.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu; Maria João=Guedes: mjguedes@iseg.ulisboa.pt; Bárbara G.=Silva: barbara.silva@ucf.edu,"Abstract
Considerable research finds that entrepreneurs enjoy higher subjective well-being than wage-earning employees. At the same time, entrepreneurship is uniquely stressful for founders, who generally have high levels of personal commitment to the business and often higher workloads than wage employees. This highlights a tension in entrepreneurship research where it is unclear how self-employment influences well-being. This research seeks to resolve some existing tensions by tackling complex constellations of well-being profiles among both entrepreneurs and wage employees. Our 
latent profile analysis
 and commentary suggest the multifaceted nature of self-employment experiences, straddling both personal and business goals that may not always be hedonic, as an important consideration for future research on entrepreneurial well-being.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the research on well-being profiles among entrepreneurs and wage employees is relevant, the practical implications for early-stage ventures may be less direct or immediate."
https://www.sciencedirect.com/science/article/pii/S2352673421000779,Let ethics lead your way: The role of moral identity and moral intensity in promoting social entrepreneurial intention,Widya=Paramita: widyaparamita@ugm.ac.id; Nurul=Indarti: nurulindarti@ugm.ac.id; Risa=Virgosita: rina_herani@ugm.ac.id; Rina=Herani: risa.virgosita@ugm.ac.id; Bayu=Sutikno: bayusutikno@ugm.ac.id,"Abstract
There is an ongoing debate whether or not social entrepreneurship is a manifestation of an individual's morality. In particular, it is argued that social entrepreneurship is not necessarily based on moral decisions. This study provides an alternative explanation that possibly can bridge these two opposing arguments by examining social entrepreneurial intention using individual ethical decision-making theory. By surveying 241 samples in Indonesia, this study has found that individuals with higher moral identification judge the act of establishing a social venture as a moral decision; hence, they have a more moral social entrepreneurial intention. However, the influence of moral identity on ethical judgment and social entrepreneurial intention is only significant when individuals perceive psychological proximity with the associated social problems. This study provides theoretical contributions to the literature on social entrepreneurship and ethics. In addition, the research findings have practical implications for 
social marketing
.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study on moral identity and social entrepreneurial intention provides valuable insights for understanding the motivations of social entrepreneurs, potentially benefiting early-stage ventures focusing on social impact."
https://www.sciencedirect.com/science/article/pii/S2352673421000780,“I will not let you die”: The effect of anthropomorphism on entrepreneurs' resilience during economic downturn,Rina=Herani: risa.virgosita@ugm.ac.id,"Abstract
It has been conventional wisdom that entrepreneurs frequently anthropomorphize their businesses by referring them as their “babies” and using biological cycle as metaphors to depict their business development. Building upon the 
Social Cognitive Theory
, this study purports to examine the untapped influence of anthropomorphism on entrepreneur's business decision. Using a sample of Indonesian entrepreneurs, we substantiate the conjecture that anthropomorphism positively affects entrepreneur's resilience. This relationship is explained by an increase in perceived business reputation. Furthermore, we provide evidence that the indirect relationship is attenuated when the business is a family business. The findings of this study have several theoretical contributions and practical implications for policy makers and 
social marketing
 that promote entrepreneur's resilience.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The research on anthropomorphism and its influence on entrepreneur's resilience offers interesting theoretical contributions, but the direct practical implications for early-stage ventures may be moderate."
https://www.sciencedirect.com/science/article/pii/S2352673421000792,Can it be measured? A quantitative assessment of critiques of the entrepreneurship literature,Hana=Milanov: hana.milanov@tum.de; Erik=Lundmark: erik.lundmark@mq.edu.au; Benedikt David Christian=Seigner: benedikt.seigner@tum.de,"Abstract
Recurring critiques of the entrepreneurship literature include that it is steeped in a positive, monetary, and gender-biased discourse. However, these critiques are generally not based on quantitative evidence. We apply computer-aided text analysis to evaluate how the language in the leading entrepreneurship journals compares to that of other corpora. We find that the entrepreneurship journals are more positive in tone and more focused on money than management journals. Entrepreneurship journals, like management journals, are skewed towards male, compared to female, references, but considerably less so than mass media. We discuss these differences in light of the three above-mentioned critiques.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study provides insights into gender bias and tone in entrepreneurship literature, which can impact how startups are perceived and supported."
https://www.sciencedirect.com/science/article/pii/S2352673422000026,Venture governance: CEO duality and new venture performance,Dennis=Gan: dennis.gan@sfe.uio.no,"Abstract
The ‘one person, two jobs’ role (known as CEO duality) has been debated for decades. In this study, we address how the overall leadership structure of new firms relates to their performance. We investigate direct effects as well as conditional effects. Our main finding is that CEO duality is beneficial in the earliest growth stage and that the number of board members is important. Contextualizing the leadership structure, we find that CEO duality is beneficial with smaller boards, and vice versa with larger boards. Implications for theory and practice are discussed.",June 2022,"Venture governance, Corporate governance, Entrepreneurial firms, CEO duality",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The findings about CEO duality and board size can directly influence the leadership structure of early-stage ventures, providing valuable practical implications."
https://www.sciencedirect.com/science/article/pii/S2352673422000038,Blood in the water: An abductive approach to startup valuation on ABC's Shark Tank,Maude=Lavanchy: maude.lavanchy@imd.org,"Abstract
Most negotiations over startup valuation take place behind closed doors. As a result, we lack knowledge about how valuation is negotiated between entrepreneurs and investors. We constructed a dataset by hand to exploit the unique nature of a popular business pitch television show, ABC's Shark Tank, to examine this issue. Our descriptive findings suggest that entrepreneurs who initially offer less of their company to investors are more likely to receive investment offers. We also discovered that startup valuation negotiations tend to take place over the relative equity percentage each party receives rather than investment amount. Finally, although investors are more likely to experience negotiation gains, entrepreneurs who successfully pit sharks against each other receive deal terms closer to their initial ask. These results add to the emerging literature on dynamic process of startup valuation.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"Understanding how startup valuation negotiations work can be crucial for early-stage ventures seeking investment, making this study highly relevant and practical."
https://www.sciencedirect.com/science/article/pii/S2352673422000063,Predicting business failure after crowdfunding success: Are platforms the unsung heroes?,Mari-Liis=Kukk: mari-liis.kukk@taltech.ee,"Abstract
Initial rules introduced in 2016 for 
U.S.
 Regulation Crowdfunding were considered overbearingly strict by 
industry
 insiders, but were argued by regulators to have a pronounced mandate of protecting against investment losses. Five years later the rules were relaxed without much ado. This paper is the first to explore how the uniquely restrictive initial ruleset fared, focusing on business failure as a straightforward measure of investment losses. We empirically test company-, campaign- and platform-level characteristics observable during a campaign against ensuing business failure. We hand-collect a sample of 380 companies that successfully raised crowdfunding between May 16, 2016 and March 30, 2018, and record their operating status as of February 15, 2021. Overall, 17.4% had failed. Our results suggest that filtering by investors may be important, but the role of platforms in protecting investors warrants considerable attention.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The exploration of Regulation Crowdfunding rules may have limited direct impact on European startups, but the findings on investment losses and platform roles could be insightful."
https://www.sciencedirect.com/science/article/pii/S2352673422000051,Framing ideas for new venture resources acquisition in crises: An fsQCA analysis,Charlotta=Sirén: charlotta.siren@unisg.ch; Joakim=Wincent: joakim.wincent@hanken.fi; Silvia=Stroe: silvia.stroe@unisg.ch; Vinit=Parida: vinit.parida@ltu.se,"Abstract
How should new venture ideas be framed in order to acquire human resources and gain support in times of crisis characterized by struggling or failing institutions and 
governmental organizations
? To answer this question, we analyze 316 new venture ideas aimed at alleviating the COVID-19 crisis in 11 countries. We investigate different linguistic framing configurations and test their persuasive power for human resource acquisition. Our fuzzy-set qualitative comparative analysis (fsQCA) and 
linguistic analysis
 reveal that a “common enemy framing” is crucial for obtaining resources in crisis contexts. Non-profit venture ideas, specifically, may acquire resources via two additional paths: adding positive emotional content or using an entrepreneurial hustle framing with concrete calls to action. Our findings provide novel insights into entrepreneurial resource acquisition and idea framing during crises.",June 2022,"New venture ideas, Framing, Resource acquisition",Business Venturing Insights,2025-03-08T00:00:00,8.0,"Analyzing new venture idea framing in crisis contexts can provide valuable guidance for startups seeking support during challenging times, making this study highly relevant."
https://www.sciencedirect.com/science/article/pii/S2352673422000087,Dark Triad traits affecting entrepreneurial intentions: The roles of opportunity recognition and locus of control,Giang=Hoang: giang.hoang@rmit.edu.vn; Tuan Trong=Luu: ttluu@swin.edu.au; Thuy Thu Thi=Le: thuyltt@ftu.edu.vn; Anh Kim Thi=Tran: anhttk@ftu.edu.vn,"Abstract
Our study proposed a research model in which opportunity recognition mediates the relationships between the 
Dark Triad
 
personality traits
 and entrepreneurial intentions, and 
locus of control
 moderates the influence of opportunity recognition on entrepreneurial intentions based on the 
theory of planned behavior
. To test the model, we used data collected from a sample of 962 undergraduate students who were enrolled in nine Vietnamese universities. The results show that opportunity recognition mediates the effects of the Dark Triad traits, namely Machiavellianism, 
psychopathy
, and 
narcissism
, on entrepreneurial intentions. In addition, the influence of opportunity recognition on entrepreneurial intentions was positively moderated by internal 
locus of control
 and negatively moderated by external locus of control. Our results cast light on the mediation and moderation mechanisms of the relationships between Dark Triad traits and entrepreneurial intentions and provide empirical evidence supporting the theory of planned behavior. Furthermore, the study proposes implications for educators to motivate students’ intentions to start a business venture.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study provides insights on the relationships between personality traits and entrepreneurial intentions, which could be useful for educators to motivate students towards entrepreneurship."
https://www.sciencedirect.com/science/article/pii/S2352673422000099,"“Pennies from heaven”? Market failure, circuits of capital and policy support for business angels: The case of cross-border angel investment",Richard T.=Harrison: r.harrison@ed.ac.uk,"Abstract
Angel investment is widely associated with economic development through 
entrepreneurial activities
, and has attracted the attention of policy makers internationally, nationally and regionally, resulting in a range of measures to support the development of the market. In this paper we challenge this policy orientation and identify three key flawed assumptions on which it rests: the presence of market failure in the early stage risk capital market, the complementarity of angel and other sources of early stage 
finance
, and the integration between the angel and venture capital circuits of capital. We develop a framework for the identification of market failure as both a supply-side and a demand-side phenomenon, demonstrate that venture capital and angel 
finance
 are substitutes not complementary funding sources and draw out the association between angel investment and venture underperformance, and build on the ‘circuits of capital’ literature to identify the increasing structural independence of the VC and angel investment markets which has implications for the link between angel financing and local and 
regional economic development
. These issues are discussed in the context that stimulation of cross-border (international) investments by 
angel investors
 has emerged as an important topic of academic analysis and policy debate in Europe, not least on the basis that such investment will support the otherwise constrained growth and scale-up of entrepreneurial ventures. The paper concludes by outlining, in the policy mix concept, a basis for the systemic analysis of the development, implementation and impact of entrepreneurial finance policy.",June 2022,"Market failure, Circuits of capital, Angel finance, Venture capital, Economic development, Internationalisation, Policy mix",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The paper challenges key assumptions in angel investment policy and provides a framework for systemic analysis of entrepreneurial finance policy, with implications for local and regional economic development."
https://www.sciencedirect.com/science/article/pii/S2352673422000117,What's my age again? The association between self-employment and klotho protein,Marcus T.=Wolfe: mtwolfe@ou.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Complementing recent studies supporting a variety of associations between self-employment and biological outcomes associated with stress, physical wear and tear, and aging, we examine the relationship between self-employment and aging. In a sample of 6088 participants from the National 
Health and Nutrition
 Examination Survey (NHANES) data, we find a small but meaningful negative association between self-employment and Klotho levels. Specifically, for self-employed, relative to the employed, the 
geometric mean
 of Klotho was lower by 2% or a 5.51% lower standard deviation from the mean Klotho levels in the sample. Our findings show that self-employment has a small but meaningful association with aging.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study explores the relationship between self-employment and aging, but the association found is small and may not have significant practical implications for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000130,Social impacts of entrepreneurship: Does entrepreneurial ecosystem support reduce homicide?,Michael=McDaniel: mike.mcdaniel@lsus.edu,"Abstract
Although some research has been done on entrepreneurship's positive effects on economic outcomes, much work remains to be done regarding other positive social 
spillover effects
 that may come from entrepreneurship. Grounded in 
expectancy theory
 and 
social support
 theory, this study examines the relationship that 
entrepreneurial ecosystem
 support has with homicide, one of the worst social ills plaguing urban settings. Results indicate that in the largest 200 U.S. cities across five years of data, 
entrepreneurial ecosystem
 support is negatively related to homicide, and that the negative relationship between those two variables is moderated by basic education rates but not by new business creation density. This article contributes to entrepreneurship literature by highlighting the positive social 
spillover effects
 (in the form of reduced homicide) that entrepreneurial ecosystem support can have on society, which have not been considered to the best of our knowledge. It also highlights the amplifying effect of basic education in that relationship, while calling for further research into the effects of new business creation density.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"The research highlights the positive social spillover effects of entrepreneurial ecosystem support on reducing homicide rates, with implications for urban settings and societal well-being."
https://www.sciencedirect.com/science/article/pii/S2352673422000129,Startup team ethnic diversity and investment capital raised,André O.=Laplume: alaplume@ryerson.ca,"Abstract
Extant literature suggests that ethnically diverse work teams can generate both positive and negative outcomes, but it is unclear how startup teams are affected. We seek to help clarify the relationship between startup team ethnic diversity and total investment capital. Using statistical analyses on a dataset of startups that participated in Techstars accelerator programs between 2007 and 2018, our results suggest that startup team ethnic diversity is positively associated with the aggregate amount of investment capital raised by startups. Our study results suggest that ‘diversity as advantage’ theories may be more appropriate for theorizing about startup fundraising than ‘diversity as disadvantage’ theories.",June 2022,"Ethnic diversity, Diversity as advantage, Startup fund-raising, Entrepreneurial team",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study provides valuable insights on how ethnic diversity in startup teams is associated with total investment capital raised, indicating a positive relationship that could be beneficial for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000166,Self-managing on the entrepreneurial rollercoaster: Exploring cycles of self-regulation depletion and recovery,Pia=Arenius: pia.arenius@rmit.edu.au; Andrew=Brough: apbrough@gmail.com,"Abstract
Entrepreneurs apply self-regulation to achieve their entrepreneurial goals and to achieve the best combination of what one has available. Many patterns of self-regulation break down when people are challenged, under stress or fatigued; typical conditions for 
entrepreneurial activity
. Through the adoption of unobtrusive wearable sensors this study makes a methodological contribution by visualizing the depletion and recovery cycles and associating these with the ups and downs of the entrepreneurial journey. We show how the cycles of self-regulation depletion and recovery are impacted by the entrepreneur journey, demonstrating the importance of maintaining self-regulation and potential consequences on performance and 
wellbeing
 when self-regulation is not maintained. We put forward a research agenda for the study of 
entrepreneurial action
, calling on researchers to expand the theory of 
entrepreneurial action
 by adding an entrepreneur centred explanation for entrepreneurial activities.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"The study explores the impact of self-regulation on entrepreneurial performance and wellbeing, providing valuable insights for early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000154,"Got ink, get paid? Exploring the impact of tattoo visibility on crowdfunding performance",Marcus T.=Wolfe: mtwolfe@ou.edu; Jeremy C.=Short: jeremy.short@unt.edu; Paula A.=Kincaid: paula.kincaid@unt.edu,"Abstract
Tattoos reflect an increasingly popular form of creative self-expression and there is an increased prevalence of tattoos among entrepreneurs engaging in crowdfunding. As such, our study is the first to explore how visible displays of tattoos within crowdfunding campaigns relate to campaign performance. Using a creativity perspective, we examine how displaying tattoos differentially impacts two key measures of crowdfunding performance: numbers of backers and funds pledged. We analyze a sample of 1500 crowdfunding campaigns from Kickstarter, and find a positive relationship between visible displays of tattoos and crowdfunding performance. We move the conversation regarding the impact of body art beyond non-entrepreneurial contexts by providing evidence that tattoo visibility does not hinder an entrepreneur's efforts to raise funds for their venture.",June 2022,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"While the study on tattoos and crowdfunding is interesting, its practical value and impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673421000275,Breaking the cycle of crime: Promoting the positive social spillover potential of entrepreneurship,Michael=McDaniel: mike.mcdaniel@lsus.edu,"Abstract
Entrepreneurship can result in many positive economic effects, but is it possible that entrepreneurship can also have positive social 
spillover effects
 such as helping to reduce crime and violence? This paper explores the question in the context of the city of Baltimore, Maryland, which has experienced a significant rise in violent crime in recent years, as well as the efforts of Innovation Works, an incubator that is attempting to educate, mentor, and fund entrepreneurs within this challenging context. Based on that incubator's insights as well as perspectives from the fields of 
sociology
, psychology, and entrepreneurship, this paper suggests that entrepreneurship can have positive social 
spillover effects
 including reduced crime, recidivism, and economic inequality, as well as increased social capital, community trust, and optimism. We examine how incubators can promote positive spillovers, and also provide recommendations for cities and incubators that are struggling in similar contexts to those of Baltimore.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The study on the positive social spillover effects of entrepreneurship is relevant and can provide valuable insights for European early-stage ventures and startups.
https://www.sciencedirect.com/science/article/pii/S235267342100055X,Heterogeneity of entrepreneurial opportunities as design artifacts: A business model perspective,Hessam=Sarooghi: hsaroogh@butler.edu; Seyedeh Elahe=AdelRastkhiz: elahe.adel@ut.ac.ir; Jeffrey=Hornsby: hornsbyj@umkc.edu,"Abstract
While the growing body of knowledge on entrepreneurship as design has provided a fresh perspective on entrepreneurial opportunities by studying their emergence and development as artifacts, we still lack a coherent understanding of what constitutes variance in opportunity artifacts. In this paper, we discuss why studying variance in opportunity artifacts is important and argue that the business model concept is a suitable and promising locus for conceptualizing such variance. We conclude by offering a research program that positions studying variance in the business model of opportunity artifacts within a design view of the entrepreneurship nexus.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The discussion on variance in opportunity artifacts and the business model concept is important, but may have slightly less direct impact on European early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673421000329,Shared problem solving and design thinking in entrepreneurship research,Ari=Hyytinen: ari.hyytinen@hanken.fi,"Abstract
Several scholars have recently conceptualized entrepreneurship as a type of design activity and suggested using design as a novel mode for entrepreneurship research. This paper proposes that by augmenting the design mode of research with the problem-framing and problem-solving approaches from management and entrepreneurship, economics, 
organizational science
 and team research, we obtain a solid foundation for identifying, characterizing, framing, and even solving problems in which both entrepreneurs and scholars are interested. The more we can uncover such shared entrepreneurial problems, the more relevant the design mode of research is for entrepreneurship scholars and the more opportunities there are for engaged scholarship. We also discuss policy problems that scholars have studied and that policy-makers responsible for entrepreneurship and innovation policies 
face
.",November 2021,"Design science, Problem framing, Problem solving, Shared problems",Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the paper discusses the design mode of research in entrepreneurship, its practical implications for European early-stage ventures may be less clear compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S235267342100041X,What Makes Entrepreneurs Happy? Psychological Flexibility and Entrepreneurs' Satisfaction,Joeri=van Hugten: j.g.w.j.van.hugten@vu.nl,"Abstract
This paper investigates entrepreneurs' satisfaction. We conceptually replicate and extend Carree and Verheul’s (2012) Dutch study on the drivers of entrepreneurs' satisfaction with data from Belgian entrepreneurs. Thus, we respond to the need to replicate more in the (social) sciences, including entrepreneurship studies. The ‘extension’ aspect contributes novel theoretical understanding and empirical explanatory power of entrepreneurs' satisfaction. Specifically, the paper introduces psychological flexibility as an important new predictor of entrepreneurs' satisfaction. Indeed, we provide evidence that entrepreneurs with greater psychological flexibility are, on average, more satisfied.",November 2021,"Satisfaction, Entrepreneurs, Psychological flexibility",Business Venturing Insights,2025-03-08T00:00:00,7.0,"This paper provides valuable insights into entrepreneurs' satisfaction and introduces a new predictor, psychological flexibility, contributing to theoretical understanding and empirical knowledge in the field."
https://www.sciencedirect.com/science/article/pii/S235267342100024X,A replication study on growth paths of young firms: Evidence from German administrative data,Arndt=Werner: arndt.werner@uni-siegen.de; Stefan=Schneck: schneck@ifm-bonn.org; Hans-Jürgen=Wolter: wolter@ifm-bonn.org,"Abstract
This replication study contributes to the lively debate about firm-specific growth paths of new firms. Utilizing rich German administrative panel data (i.e., 895,459 young firms that submitted a turnover 
tax
 preregistration form between 2001 and 2011), the study empirically revisits new firms’ growth paths as documented in the JBV Insights paper of Coad et al. (2015). In line with their results, the empirical findings of this study corroborate that (a) growth paths of young firms are erratic, meaning that such growth paths cannot be easily sorted into a meaningful taxonomy and (b) young firms rarely persistently experience comparably high growth in sales over time. In addition, an analysis of the characteristics of persistently growing firms suggests that these tend to invest more in their founding period and are typically founded in the 
manufacturing industry
.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,This study adds to the debate on new firm growth paths but may have limited direct practical implications for European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673421000299,Low-code entrepreneurship: Shopify and the alternative path to growth,Gary=Dushnitsky: gdushnitsky@london.edu,"Abstract
The past decade witnessed a surge in the availability of low-code tools, where software-based solutions can be developed with limited or no need for writing code. One of the most salient examples is Shopify, which enables a layperson to become a fully-functioning online retailer without ever resorting to writing code. We ask: how do low-code tools affect growth trajectory and entrepreneurial success? How do they change the resources required to scale-up and grow? We explore these questions in the context of the e-commerce sector during the 2010s. Several databases were integrated to construct a sample covering about 400 VC-backed startups; including a detailed profile of their financial, human and software tools. The analyses indicate that Shopify-based startups start life with fewer financial and human resources compared to their e-commerce peers. Yet, despite the leaner beginning, they achieve a similar level of successful exits. The value created per employee, and cash-on-cash return for investors, place Shopify-based startups on par with their peers.",November 2021,"Entrepreneurship, Resource assembly, Funding, Low code, Shopify",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The exploration of low-code tools and their impact on growth trajectory and entrepreneurial success provides relevant and actionable information for startups, especially in the e-commerce sector."
https://www.sciencedirect.com/science/article/pii/S2352673421000287,The lingering living dead phenomenon: Distorting venture survival studies?,Christina=Ungerer: cungerer@htwg-konstanz.de; Kevin=Reuther: kevin.reuther@uws.ac.uk; Guido=Baltes: guido.baltes@htwg-konstanz.de,"Abstract
Despite the increased attention dedicated to research on the antecedents and determinants of new venture survival in entrepreneurship, defining and capturing survival as an outcome represents a challenge in quantitative studies. This paper creates awareness for ventures being inactive while still classified as surviving based on the data available. We describe this as the ‘living dead’ phenomenon, arguing that it yields potential effects on the empirical results of survival studies. Based on a 
systematic literature review
, we find that this issue of inactivity has not been sufficiently considered in previous new venture survival studies. Based on a sample of 501 New Technology-Based Firms, we empirically illustrate that the classification of living dead ventures into either survived or failed can impact the factors determining survival. On this basis, we contribute to an understanding of the issue by defining the ‘living dead’ phenomenon and by proposing recommendations for research practice to solve this issue in survival studies, taking the data source, the period under investigation and the sample size into account.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The identification of the 'living dead' phenomenon in new venture survival studies is insightful, but the practical implications for European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673421000305,Badge of honor or tolerable reality? How previous firm failure and experience influences investor perceptions,Ashley Y.=Roccapriore: ashley@vols.utk.edu,"Abstract
Entrepreneurs 
face
 considerable obstacles in accruing funding and other resources when starting a new venture; problems that are likely compounded when starting a new venture after experiencing failure. In particular, it is unclear how early-stage investors react to entrepreneurs with prior failure experiences in terms of how they perceive the entrepreneur's capabilities and how they evaluate the new venture. Leveraging expectancy violation theory, we theorize that prior failure will lead to more negative outcomes than prior success, but more positive outcomes than those with no prior 
entrepreneurial experience
, and that this effect will be further attenuated by whether the entrepreneur learned or not from their 
prior experience
. We test our model using a scenario-based experiment of 828 decisions made by 69 early-stage investors. We contribute to the literature on early stage investor 
decision making
, entrepreneurial failure and learning, and discuss implications and future research directions given our findings.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,This study on how early-stage investors perceive entrepreneurs with prior failure experiences and its impact on new ventures is relevant and can provide valuable insights for European startups seeking funding.
https://www.sciencedirect.com/science/article/pii/S2352673421000342,"Innovation, new ventures, and corruption: Evidence from India",Shoeb=Mohammad: shoeb.mohammad@lakeheadu.ca; Bryan W.=Husted: bhusted@itesm.mx,"Abstract
We investigate the effect of 
corruption
 on product, process, marketing, and 
organizational innovation
 in new ventures. Based on differences in the ability of firms to appropriate economic returns from these types of innovation, we argue that 
corruption
 undermines the formal property protection associated with 
product innovation
, privileging the other kinds of innovation, which are less susceptible to the effects of corruption and thus provide more attractive returns. Furthermore, we argue for a differential impact of corruption on innovation for new ventures relative to incumbent firms. We find that corruption reduces 
product innovation
, but increases process, marketing, and 
organizational innovation
. The impact of corruption on the product innovation of new ventures is more severe relative to that of incumbent firms, while the positive impact of corruption on marketing and 
organizational innovation
 is weaker for new ventures.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The research on the impact of corruption on different types of innovation in new ventures provides valuable insights for startups in Europe.
https://www.sciencedirect.com/science/article/pii/S2352673421000330,When ownership of the venture triggers cofounders’ unethical pro-venture behavior,Dan K.=Hsu: dan.hsu@ndsu.edu; Michelle C.=Hong: michelle.hong@ndsu.edu; Hsing-Er=Lin: hsingerlin@cm.nsysu.edu.tw; Yongchuan=Shi: charney@wzu.edu.cn,"Abstract
This research examines a prevailing yet understudied phenomenon—a cofounder's unethical pro-venture behavior. We identify two antecedents - psychological ownership and equity ownership of a cofounder. Data collected from 139 cofounders show a curvilinear relationship between psychological ownership and unethical pro-venture behavior. More interestingly, the incongruence between psychological ownership and equity ownership, particularly when psychological ownership exceeds equity ownership, increases the likelihood of such behavior.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study on unethical behavior of cofounders has some relevance for early-stage ventures, but may not have a significant practical impact on startups."
https://www.sciencedirect.com/science/article/pii/S2352673421000354,Drivers of success in social innovation: Insights into competition in open social innovation contests,Johanna=Mair: mair@hertie-school.org; Yanto=Chandra: yanto.chandra@polyu.edu.hk; Liang=Shang: echoshang@ln.edu.hk,"Abstract
Social innovation is a fast-growing field of practice that has caught the attention of management and entrepreneurship scholars. The recent excitement surrounding “open social innovation” contests raises the question of what makes social innovation solutions 
successful
 contenders in these ubiquitous contests. We used uniquely assembled data, including data generated from external evaluators, to explore what determines success in an open social innovation contest (n = 150 out of 871 entries) in the field of 
poverty alleviation
. We found that innovators who had networks with corporations and those who had commercial orientations were more likely to succeed in open social innovation contests. We also discovered that the perceived usefulness and innovativeness of social innovation solutions mediated these positive relationships. Our study offers early insights that deepen our understanding of success in the growing practice of open social innovation.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The exploration of success factors in open social innovation contests related to poverty alleviation can be beneficial for European startups focusing on social impact.
https://www.sciencedirect.com/science/article/pii/S2352673421000378,Does the accumulation of self-employment experience impact life satisfaction?,Nicholas=Litsardopoulos: n.litsardopoulos@kingston.ac.uk,"Abstract
This paper investigates the association of 
life satisfaction
 and self-employment experience. Using a large longitudinal dataset from the Understanding Society survey over the period 2009–2019, the paper examines how the allocation of time to wage- or self-employment affects individual 
life satisfaction
. We argue that the typical dichotomous wage-employee/self-employed variable does not fully explain the association over time. Instead, when we measure self-employment experience over time, we identify significant variations. We examine the effects of self-employment experience on overall satisfaction and on a composite life satisfaction metric which combines the satisfaction with job, income, leisure, and health. We find that overall self-employment experience exhibits a positive effect on life satisfaction. However, we identify contrasting effects between the two life-satisfaction metrics in men and women. The results suggest the existence of effects above and beyond work related factors, which affect men and women differently.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The investigation of the association between life satisfaction and self-employment experience can provide some insights for entrepreneurs, but may not directly impact European early-stage ventures significantly."
https://www.sciencedirect.com/science/article/pii/S235267342100038X,All failures are not equal: Degree of failure and the launch of subsequent crowdfunding campaigns,Onochie=Fan-Osuala: fanosuao@uww.edu,"Abstract
Despite the growing importance of crowdfunding as an alternative source of entrepreneurial 
finance
 and in driving innovation, we still have limited understanding of how failure impacts the entrepreneur's subsequent actions and decisions. In this study, we examine how the degree of failure in a crowdfunding campaign affects the entrepreneur's tendency and urgency to launch a subsequent crowdfunding campaign. Using a sample of 63337 entrepreneurs who failed in their initial crowdfunding campaigns and drawing on the near-miss effect, we test a series of hypotheses. Our results suggest that not only does marginal failures increase the likelihood that an entrepreneur will launch a subsequent crowdfunding campaign, it also increases the urgency in which the entrepreneur launches the subsequent crowdfunding campaign. The results reveal that the funding goal size is a moderating factor to the relationship between degree of failure and the launch of a subsequent crowdfunding campaign However, contrary to our expectation, it is such that entrepreneurs whose funding goal size are relatively large are more likely to launch subsequent crowdfunding campaigns.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,The study on how failure in crowdfunding campaigns affects subsequent actions of entrepreneurs is highly relevant for European startups using crowdfunding as a financing option.
https://www.sciencedirect.com/science/article/pii/S2352673421000391,Standing out in crowdfunded microfinance: A topic modeling approach examining campaign distinctiveness and prosocial performance,Marcus T.=Wolfe: mtwolfe@ou.edu; Jeremy C.=Short: jeremy.short@unt.edu; Amanda Jasmine=Williamson: Amanda.Williamson@waikato.ac.nz,"Abstract
We outline the promise of topic modeling as a tool to build knowledge in social entrepreneurship surrounding the role gender plays in prosocial crowdfunding. By leveraging a sample of 340,956 prosocial microfinance campaigns drawn from Kiva, we examine how distinctiveness from the prototypical 
narrative
 in men's and women's campaigns relates to crowdfunding performance. We find that distinctiveness in men's campaigns is associated with faster funding. Conversely, when women's campaigns are distinctive from other women, funding times vary depending on their sector. Our findings suggest that in prosocial microlending, deviating from the normal 
narrative
 of one's gender is advantageous for campaigns led by men, but that among women, it can often hinder prosocial microlending efforts.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study provides valuable insights into gender differences in crowdfunding performance, which can be beneficial for startups looking to raise funds."
https://www.sciencedirect.com/science/article/pii/S2352673421000408,"Does COVID-19 state aid reach the right firms? COVID-19 state aid, turnover expectations, uncertainty and management practices",Jesse=Groenewegen: j.t.groenewegen@uu.nl; Sjoerd=Hardeman: s.hardeman1@uu.nl; Erik=Stam: e.stam@uu.nl,"Abstract
A much debated issue in the discussion about COVID-19 state aid to firms is the extent to which these measures keep non-viable firms afloat. What are the characteristics of firms that receive aid and are they viable in the long term? Based on a survey of 1,151 firms in the Netherlands, mainly SMEs, we find that on average, government support goes to better-managed firms and to those with low turnover expectations and high turnover uncertainty. This suggests that COVID-19 state aid tends to go to firms that are most in need of it now and are more likely to be viable in the long term, as indicated by the quality of their management practices.",November 2021,"COVID-19, State aid, Business support, Management practices, Uncertainty",Business Venturing Insights,2025-03-08T00:00:00,9.0,"The research on COVID-19 state aid to firms can have a significant impact on early-stage ventures, helping them understand the dynamics of government support and viability."
https://www.sciencedirect.com/science/article/pii/S2352673421000421,Should subscription-based content creators display their earnings on crowdfunding platforms? Evidence from Patreon,Paul=Crosby: paul.crosby@mq.edu.au; Jordi=McKenzie: jordi.mckenzie@mq.edu.au,"Abstract
In January 2017, the subscription-based crowdfunding platform Patreon allowed their users (creators) the ability to hide their earnings from existing and potential subscribers. Prior to this, all monthly earnings were visible. We investigate what effect this policy change had on creators’ subscriber numbers over the following six months. Using double-robust and endogenous treatment estimation techniques, we find evidence that creators who removed the visibility of their earnings had more subscribers as a result. This suggests that the provision of social information does not lead to an increase in subscribers.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the study on crowdfunding platform Patreon is interesting, it may have limited practical implications for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673421000457,The missing capital: The case for psychological capital in entrepreneurship research,Chris=Welter: chriswelter@miamioh.edu,"Abstract
Psychological capital has received limited attention in entrepreneurship research despite growing interest in its subconstructs – self-efficacy, hope, optimism, and resilience. We build a case for incorporating psychological capital into entrepreneurship research broadly and then specifically describe how psychological capital could impact opportunity evaluation research. Finally, we highlight how entrepreneurship research can provide new insights into psychological capital.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The exploration of psychological capital can offer valuable insights for startup founders and entrepreneurs, potentially impacting their mindset and decision-making."
https://www.sciencedirect.com/science/article/pii/S2352673421000470,Impact of formal vocational training on the earnings of self-employed individuals in rural India,Indrajit=Bairagya: indrajitisec@gmail.com,"Abstract
The study examines the impact of participation in formal vocational training on the earnings of rural self-employed individuals in 
India
, based on both 
descriptive statistics
 and 2SLS based 
econometric analysis
. The results show that even though formal vocational training helps self-employed individuals earn a higher income and that a great initiative has been taken by the government to promote skill development in recent times, a meagre proportion of rural self-employed has received formal vocational training. Therefore, there is a need for an appropriate policy attention towards enhancing the participation of rural self-employed individuals in the formal vocational training programmes on a grander scale. Moreover, a substantial heterogeneity is observed in terms of the duration of training programmes. A longer duration (12 months or more) training helps enhance the mean earnings significantly as compared to a relatively shorter duration training. Considering that a shorter duration training is cost-effective from the supply-side and entails a lesser opportunity cost for self-employed when it comes to participation, policy should revisit the course structure and curriculum of shorter duration training programmes in order to ensure that these become more effective in terms of fetching higher earnings.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The research on vocational training in India provides important information, but its direct relevance to European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673421000445,The effect of venture capitalists straying from their industry comfort zones,Tyler J.=Hull: tyler.hull@umb.edu,"Abstract
I empirically test and find evidence that venture capital 
industry
 experience is more informative and impactful in venture capital investment when measured at the low non-aggregated 
industry
 level. Additional evidence shows that venture capital investments made outside of a venture capitalist's preferred investment industry suffer from significant decreases in exit success likelihood. This effect becomes stronger the more distant the investment industry is from the venture capitalist's preferred investment industry.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"This study provides valuable insights for European early-stage ventures by highlighting the importance of venture capital industry experience in making successful investments, which can impact startups positively."
https://www.sciencedirect.com/science/article/pii/S2352673421000482,The promise of entrepreneurial passion to advance social entrepreneurship research,Yanto=Chandra: yanto.chandra@polyu.edu.hk; Fandy=Tjiptono: fandy.tjiptono@vuw.ac.nz; Andhy=Setyawan: andhy@staff.ubaya.ac.id,"Abstract
This article aims to advance the theoretical debate on the role of 
entrepreneurial passion
 and paradoxical 
entrepreneurial interests
––two influential concepts of entrepreneurship that have received little empirical validation so far––in predicting social entrepreneurial intention. Drawing on the literature on entrepreneurial passion and pecuniary vs. non-pecuniary interests in entrepreneurship, in particular the tension between money ethics, meaning in life, and public service motivation, we collected survey data from young people who were at the career choice contemplation stage (
N
 = 1021) to test a model of social entrepreneurial intention. 
Structural equation modeling
 and 
mediation analyses
 supported the tested model. This article contributes to the literature by demonstrating the centrality of entrepreneurial passion in predicting social entrepreneurial intention and the complex role of pecuniary and non-pecuniary interests in the relationships.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"While the study contributes to the theoretical debate on entrepreneurial passion and interests, its practical impact on European early-stage ventures may be limited at this stage."
https://www.sciencedirect.com/science/article/pii/S2352673421000500,Start-up subsidies and the sources of venture capital,Hanna=Hottenrott: hanna.hottenrott@tum.de,"Abstract
Research suggests that public subsidies for newly founded firms have a positive effect on follow-on financing, in particular on Venture Capital (VC), through providing certification and early-stage liquidity. This study shows that the various sources of VC value public start-up subsidies differently. It is the first to differentiate between distinct types of investors who pursue different investment strategies. We show for a large sample of knowledge-intensive start-ups that there is indeed a correlation between subsidies and all sources of VC (Government VC, Independent VC, Corporate VC, and Business Angels). However, when accounting for firm characteristics that drive both selection into public subsidies as well as into 
VC financing
 through 
econometric
 matching techniques, subsidies are no longer linked to all types, but mainly to Government VC and Business Angel financing. We discuss possible explanations for this finding and implications for entrepreneurial 
finance
.",November 2021,"Start-up subsidies, Entrepreneurship policy, Entrepreneurial finance, Venture capital, Business angels",Business Venturing Insights,2025-03-08T00:00:00,9.0,"The research on public subsidies and VC financing provides important insights for European early-stage ventures by showcasing the impact of subsidies on securing venture capital, which is crucial for startup growth."
https://www.sciencedirect.com/science/article/pii/S2352673421000536,To reopen or not to reopen? How entrepreneurial alertness influences small business reopening after the COVID-19 lockdown,Jintong=Tang: jintong.tang@slu.edu; Stephen X.=Zhang: stephen.zhang@adelaide.edu.au; Song=Lin: linsong@cufe.edu.cn,"Abstract
COVID-19 
lockdowns
 have been effective in curbing the spread of the virus and saving lives. Government-imposed restrictions and lockdowns have required that businesses close temporarily. While many businesses survived in lockdown, others, particularly small businesses, did not, or were not able to reopen when the lockdowns were relaxed. We sought to study the phenomenon of small businesses still being squeezed and explore the internal drivers for their reopening after the lockdowns. We collected two-wave data from 303 small businesses in China during the COVID-19 pandemic in 2020. Our findings indicated that entrepreneurs with higher level of alertness were less likely to reopen their businesses after the lockdowns were lifted. In addition, the negative relationship between alertness and reopening was attenuated for older firms. Our findings underscore the role of entrepreneurs’ cognitive characteristic in determining the reopening of businesses during the pandemic.",November 2021,"COVID-19, Entrepreneurial alertness, Lockdown, Reopen",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study provides valuable insights into the impact of entrepreneurs' cognitive characteristics on the reopening of businesses during the COVID-19 pandemic, which can be beneficial for early-stage ventures facing similar challenges."
https://www.sciencedirect.com/science/article/pii/S2352673421000548,Natural language processing versus rule-based text analysis: Comparing BERT score and readability indices to predict crowdfunding outcomes,C.S. Richard=Chan: richard.chan@stonybrook.edu; Charuta=Pethe: cpethe@cs.stonybrook.edu; Steven=Skiena: skiena@cs.stonybrook.edu,"Abstract
We explore how 
natural language processing
 can be applied to predict crowdfunding outcomes. Using the 
Bidirectional Encoder Representations from Transformers
 (BERT) technique, we find that crowdfunding projects that use a story section description with a higher average BERT score (indicating a lower quality of writing) tend to raise more funding than those with lower average BERT scores. In contrast, risk descriptions that have higher BERT scores tend to receive less funding and attract fewer backers. These relationships remain consistent after controlling for various traditional 
readability
 indices, highlighting the potential benefits of incorporating 
natural language processing
 techniques in entrepreneurship research.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"The application of natural language processing techniques like BERT to predict crowdfunding outcomes offers practical benefits for startups looking to enhance their fundraising efforts, making it highly relevant and impactful."
https://www.sciencedirect.com/science/article/pii/S2352673421000561,From the theories of financial resource acquisition to a theory for acquiring financial resources - how should digital ventures raise equity capital beyond seed funding,Shoon=Chan Timothy Hor: shoon.hor@qut.edu.au,"Abstract
For many digital ventures, acquiring financial resources in multiple rounds beyond seed funding to grow has become an important part of their entrepreneurial journey. The success rate of raising equity capital beyond their seed investments is, however, very low. Existing entrepreneurship studies on financial resource acquisition have explored separately how entrepreneurs organize their networks, establish venture legitimacy, and decide on funding sources. However, despite being identified as an important subprocess in new venture creation, little is known about why, when, and how entrepreneurs engage potential investors to increase the likelihood of post-seed investments. Hence, this paper synthesizes the literature on financial resource acquisition, theoretical concepts in entrepreneurial financing, and practice knowledge to frame a set of design principles to create a prescriptive process model to increase the likelihood of success in post-seed financial resource acquisition.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The paper addresses the challenges faced by digital ventures in acquiring post-seed funding, providing a theoretical framework and design principles that could be useful for early-stage startups seeking additional financial resources."
https://www.sciencedirect.com/science/article/pii/S2352673421000573,Social support and its effects on self-efficacy among entrepreneurs with disabilities,Alexander=McKelvie: mckelvie@syr.edu; Mirza=Tihic: mtihic@syr.edu; Muris=Hadzic: hadzic@lakeforest.edu,"Abstract
We analyze if various programs for entrepreneurs with disabilities (EWD) positively impact their self-efficacy. We examine if variations in self-efficacy of EWD are related to perceptions of social support, quality assistance from service providers, and perceived barriers to entrepreneurship as a way to evaluate the impact of programs for EWD. We draw upon Critical Disability Theory to understand if service providers act as ‘sites of injustice’ for EWD, creating further barriers, or as ‘sites of justice’ that positively impact their self-efficacy. Using a sample of 127 EWD, we find a positive relationship between the services received from entrepreneurship and disability-specific support programs on self-efficacy. Conversely, we find a strong negative relationship between barriers to entrepreneurship and the self-efficacy of EWD. We contribute by forwarding Critical Disability Theory to the realm of entrepreneurship and shedding new empirical light on EWD.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The analysis of programs for entrepreneurs with disabilities and their impact on self-efficacy sheds new light on this underexplored area, offering insights that can benefit European startups looking to support diversity and inclusion."
https://www.sciencedirect.com/science/article/pii/S2352673421000597,Foreign entrepreneurs engage in less misconduct than native entrepreneurs: Evidence from U.K. director disqualifications,Richard F.J.=Haans: haans@rsm.nl; Koen=van den Oever: koen.vandenoever@ru.nl,"Abstract
Although entrepreneurship is commonly viewed as a positive force for society, entrepreneurs may also engage in harmful activities. We explore whether foreign versus native entrepreneurs have a higher propensity to engage in misconduct, as evidenced by them being formally disqualified from being a director by the government following unfit conduct. Comparing entrepreneurs in the United Kingdom who were solely responsible for their venture and who were disqualified with a matched sample of entrepreneurs who did not engage in such misconduct, we find robust evidence that foreign entrepreneurs are substantially less likely to commit misconduct than native entrepreneurs. We also observe that female entrepreneurs are less likely to engage in misconduct than male entrepreneurs. We discuss the study's contributions to the entrepreneurship and organizational misconduct literatures and examine its practical implications.",November 2021,"Misconduct, Disqualification, Foreign entrepreneurship, Nationality, Gender",Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study comparing foreign and native entrepreneurs' propensity for misconduct offers interesting findings, but the practical implications for early-stage ventures in Europe may be limited as the focus is on misconduct rather than positive entrepreneurial activities."
https://www.sciencedirect.com/science/article/pii/S2352673421000603,Small business in a time of crisis: A five stage model of business grief,Christopher=McLaughlin: cg.mclaughlin@ulster.ac.uk; Simon=Stephens: simon.stephens@lyit.ie; Katrina=McLaughlin: k.mclaughlin@qub.ac.uk,"Abstract
In this paper we examine the implications that a crisis such as that created by COVID-19 has for the psychological well-being of 
small business owners
. We use the psychological literature on grief, specifically, the Kübler-Ross (1969) Five Stage Model of Grief to examine the impacts. Our review of the literature indicates that although there are critics of a stage based approach there are also advocates for the use of stages to help us frame and understand the manifestations of grief. Data was collected from forty small business owners based in Ireland. Data was collected five times over a period of six months (March–September 2020). The outcome is a five-stage model of business grief. The findings provide insights into the emotional relationship between an owner and their small business. We propose that a business closure can cause small business owners to grieve in a manner that aligns with a series of stages and that these stages can be modelled and illustrated.",November 2021,"Business crisis, Kübler-Ross, Business grief, COVID-19",Business Venturing Insights,2025-03-08T00:00:00,6.0,The study on the psychological impacts of a crisis on small business owners can provide valuable insights for entrepreneurs dealing with the aftermath of COVID-19.
https://www.sciencedirect.com/science/article/pii/S2352673421000615,Metacognition and entrepreneurial action: The mediating role of a strategic mindset on promoting effort and innovative behavior in frugal entrepreneurs,Timothy L.=Michaelis: tmichaelis@niu.edu; Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Jon C.=Carr: jccarr@ncsu.edu; Alexander=McKelvie: mckelvie@syr.edu; Xinyu (Judy)=Hu: xhu@rwu.edu,"Abstract
This study tests a situated metacognitive model of 
entrepreneurial action
 to highlight how action (or inaction) during the entrepreneurial process is influenced by both individual traits and one's metacognitive ability, namely one's strategic 
mindset
. Integrating theory on resourcefulness and metacognition, we show how entrepreneurs who are more frugal tend to engage in less action in developing their new venture (i.e., enacting fewer innovative behaviors and putting forth less effort) as compared to less frugal entrepreneurs. However, we explain that this direct (negative) relationship is mediated by one's strategic 
mindset
, such that the indirect effect of 
frugality
 on both innovative behavior and level of effort enacted towards one's new venture is positive (rather than negative). Overall, this study extends the construct of strategic mindset to the entrepreneurship literature and highlights the crucial role that metacognition can play regarding one's socio-cognitive decision-making process and subsequent entrepreneurial behaviors.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The research on entrepreneurial action, individual traits, and metacognitive ability can have a significant impact on how entrepreneurs approach new ventures, offering practical implications for startup strategies."
https://www.sciencedirect.com/science/article/pii/S2352673421000627,How tax incentives slow down positive change in social impact ecosystems and what can we do about it,Pablo=Muñoz: pablo.munoz-roman@durham.ac.uk; Edward N.=Gamble: edward.n.gamble@gmail.com,"Abstract
To advance positive change within social impact ecosystems, policy makers offer tax incentives in return for social value. Some social 
enterprises
 are exempt from paying 
taxes
, with an expectation that they will create positive change in society. Yet, studies have highlighted that there are a growing number of value-detracting issues with tax exemptions, which detract from ecosystems of positive social change. Therefore, spotting and rectifying situations of potential value detraction is paramount. In this paper we offer a two-sided framework called SCAM/MEND, to identify and act upon the ‘dark side’ of tax exemptions in social impact ecosystems. The SCAM side of our framework allows ecosystem actors to spot situations in which negative outcomes are likely to emerge from tax exemptions. The MEND side of our framework offers policy makers and ecosystem actors a new course of action to redirect positive change efforts.",November 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The paper on tax incentives for social enterprises and the SCAM/MEND framework can help policymakers and ecosystem actors address value detracting issues, contributing to positive change in social impact ecosystems."
https://www.sciencedirect.com/science/article/pii/S2352673421000652,A behavioral insights approach to recruiting entrepreneurs for an academic study during the COVID-19 pandemic,Elizabeth M.=Tracy: lizmtracy@gmail.com,"Abstract
What should researchers say when recruiting entrepreneurs to participate in their study? Using a sample of entrepreneurs (
N
 = 1,450) who were being asked to participate in an academic research project, we conducted an experiment to determine recruitment message efficacy. Drawing on best practices from the behavioral insights literature, we developed different email message recruitment statements that were randomly assigned across four phases of our experiment. Results indicate that a message grounded in the “descriptive norms” (i.e., social norms) approach resulted in the highest percentage of participants who clicked on the link to participate in our online survey. We discuss the theoretical as well as practical implications of our work.",November 2021,"Entrepreneur, Participant, Recruitment, Research, Behavioral insights",Business Venturing Insights,2025-03-08T00:00:00,9.0,"The experiment on recruitment message efficacy for entrepreneurs provides practical guidance for researchers engaging with startup founders, offering insights into effective communication strategies to increase participation."
https://www.sciencedirect.com/science/article/pii/S2352673420300676,Social enterprise crowdfunding in an acute crisis,Ewald=Kibler: ewald.kibler@aalto.fi; Siri=Terjesen: sterjesen@fau.edu; Mohamed=Farhoud: mohamed.s.farhoud@utu.fi; Sheeza=Shah: sheeza@theupeffect.com; Pekka=Stenholm: pekka.stenholm@utu.fi; Maija=Renko: maija.renko@depaul.edu,"Abstract
Social 
enterprises
 can play a pivotal role in mitigating the negative effects of major crises if these ventures are able to attract enough funding for their activities. Our research reflects on the experiences of a UK-based 
crowdfunding platform
, 
UpEffect,
 to develop understanding of the key challenges for social enterprise crowdfunding at the time of COVID-19. Specially, we offer and synthesize three perspectives (social enterprises, funding crowd, and crowdfunding platforms) to illuminate key strategies that crowdfunding platforms, like 
UpEffect
, can employ to support social enterprises in enacting solutions for COVID-19 affected people and communities.",June 2021,"Social entrepreneurship, Crowdfunding, Crisis management, Communication, Community, Entrepreneurship policy, Rapid response, COVID-19",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study on crowdfunding challenges for social enterprises during COVID-19 offers valuable insights for startups looking to leverage crowdfunding platforms for support, highlighting key strategies for success."
https://www.sciencedirect.com/science/article/pii/S2352673421000251,On founders and dictators: Does it pay to pay for signals in crowdfunding?,Stefan=Pabst: stefan.pabst@tum.de; Alwine=Mohnen: alwine.mohnen@tum.de,"Abstract
Crowdfunding has become a serious means of financing new ventures. Funders come across numerous, often similar, projects seeking funds, making it difficult for them to decide which project to support. Founders can invest in signals (e.g., filing a patent) to highlight their projects, as signals are a typical communication channel on crowdfunding platforms. We examine how the cost of signaling affects funders' contributions. We modeled a crowdfunding situation using a modified dictator game in the laboratory. Our results illustrate that the higher the founders’ cost of signaling, the more the funders contribute, though not without restrictions; the characteristics of funders matter as reciprocity moderates this effect. Thus, our findings offer new insights for user innovators, entrepreneurs, and institutions, and explain why seemingly identical signals work differently.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"This abstract provides new insights into crowdfunding and its effects on funders' contributions, which can be valuable for European startups seeking financing."
https://www.sciencedirect.com/science/article/pii/S2352673421000032,Venture-level outcomes of juggling and struggling,Robert P.=Garrett: robert.garrett@louisville.edu; Lauren A.=Zettel: lauren.atkinson@louisville.edu,"Abstract
Although the perceived flexibility of being one’s own boss may draw those with significant family responsibilities to entrepreneurship over traditional employment, existing research on the interface between work and family suggests that conflicts between these two domains arise. In other words, while entrepreneurship may seem like an approach for juggling work and home life commitments, theory on work-life conflict indicates that entrepreneurs 
face
 many of the same struggles of the organizationally employed with family responsibilities. In this paper, we examine the impact of family life responsibilities on the ability of nascent entrepreneurs to accomplish important founding milestones over time. The results indicate that family responsibilities may not have the degree of negative impact on venture-level outcomes that existing theory suggests. We consider potential explanations for these findings and propose future research to continue exploring this important topic.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"The research on family responsibilities and entrepreneurship, while important, may not directly impact the practical value or impact on European early-stage ventures as much as other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673421000214,What do they think and feel about growth? Examining small business managers’ attitudes towards growth in the United States,Alexander=McKelvie: mckelvie@syr.edu; Anna=Brattström: anna.brattstrom@fek.lu.se; William J.=Dennis Jr.: Wjdjr43@gmail.com,"Abstract
We replicate the Wiklund et al. (2003) study examining the attitudes towards growth of small business managers. We generalize and extend that study in three important ways: we focus on a different context (United States instead of Sweden), where the conditions and consequences for growth are different, we provide an additional predictor variable – behavioral control – in line with Ajzen’s 
theory of planned behavior
, and with a slightly modified 
dependent variable
. The principal finding is that the strongest perceived consequence affecting attitudes towards growth among U.S.-based small business managers is the ability to increase income and other financial benefits. Change in employee well-being and change in dependence on outside stakeholders also ranked relatively high among eight potential growth consequences. The Wiklund et al. (2003) Swedish study finds, in contrast, that non-economic consequences are the strongest predictor of attitudes towards growth. We attribute these attitudinal differences to variations in institutional context, suggesting that policy and cultural norms are likely to underlie growth motivation. We also find that U.S.-based small business managers are likely to be influenced by the perception that growth is a “realistic” endeavor.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,"While the study provides insights into small business managers' attitudes towards growth, the impact on European early-stage ventures may be limited due to focus on U.S.-based context."
https://www.sciencedirect.com/science/article/pii/S2352673420300664,Unpacking the age at initial internationalization-performance relationship: A meta-analytic investigation,David W.=Williams: dww@utk.edu; T. Russell=Crook: tcrook@utk.edu,"Abstract
The relationship between a firm’s age when it initiates 
internationalization
 and performance has spurred significant theoretical development but also yielded mixed empirical results. Applying the capabilities perspective of age at initial international entry to these mixed empirical results, we use meta-analytic methods leveraging results from 121 studies and find that an earlier age at entry is associated with improved firm performance. Yet, this effect is strongest when firms begin internationalizing at intermediate stages of their development and is mediated by the extent to which firms increase international sales (international intensity). We extend prior research by explaining how and how much age at entry matters as well as when it matters most, unpacking the pathways and timing by which age at entry matters, and we offer avenues to continue advancing work on the capabilities perspective of age at initial international entry.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study offers valuable insights into the relationship between a firm’s age at internationalization and performance, which can help European early-stage ventures in their international expansion strategies."
https://www.sciencedirect.com/science/article/pii/S235267342030069X,A comprehensive review of the global development of initial coin offerings (ICOs) and their regulation,Cristiano=Bellavitis: crbellav@syr.edu,"Abstract
Initial coin offerings (ICOs) represent an innovative and new funding mechanism for new technology ventures. In our comprehensive review of the industry’s evolution, we show that despite its short history, there have been dramatic changes and shifts in the number of ICOs, the amount of money raised, the geographic distribution of ICOs, and their regulation. This dynamism calls into question current research practices and findings. We propose that scholars sort out and differentiate supply of vs. demand for ICO funding, taking 
geography
 and regulation into account with a global perspective.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The comprehensive review of ICOs provides relevant information for startups considering this funding mechanism, but the practical value for European ventures may be limited due to the focus on global perspective."
https://www.sciencedirect.com/science/article/pii/S235267342030072X,Narcissism and entrepreneurship: Evidence from six datasets,Roy=Thurik: thurik@ese.eur.nl,"Abstract
Widespread attention is being paid to the alleged rise of 
narcissism
 in people in general and business leaders in particular. Surprisingly, hardly any studies have focused on the link between 
narcissism
 and entrepreneurship. Using self-reported data from 4798 respondents from three countries, we explore the associations between trait narcissism and six different entrepreneurial aspects that represent the entire entrepreneurial process. Overall, our findings suggest that a positive link exists between narcissism and entrepreneurship that is particularly salient in the early stage of the entrepreneurial process (e.g., entrepreneurial intention) and in the individual aspects of entrepreneurship (e.g., entrepreneurial orientation, well-being of the entrepreneur). Our additional analyses reveal that the adaptive aspect of narcissism (i.e., leadership/authority) is most consistently linked to entrepreneurship and that the links between narcissism and entrepreneurship are predominately linear. Finally, our findings are largely robust when different sets of controls are added.",June 2021,"Narcissism, Entrepreneurship, Well-being, Mental health",Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the study explores the link between narcissism and entrepreneurship, the practical impact on European early-stage ventures may be limited as it focuses more on individual aspects of entrepreneurship."
https://www.sciencedirect.com/science/article/pii/S2352673420300718,The value of knowing what you want: Goal hierarchy and entrepreneurial intentions,Anne R.=van Ewijk: anne.ewijk@adu.ac.ae; Wiebke=Weber: wiebke.weber@upf.edu,"Abstract
Contrary to common hopes and expectations, recent studies dispute the positive relationship between 
entrepreneurship education
 and entrepreneurial intentions. An alternative view is that 
entrepreneurship education
 has a ‘sorting effect’, whereby students become more convinced about whether entrepreneurship is appropriate for them or not. Building on goal-setting theory, this study aims to shed more light on the underlying cognitive mechanism of the sorting effect by investigating whether individuals, who exhibit high ‘motivational self-knowledge’ – MSK (i.e. awareness of personal life goals and motives), make more pronounced decisions for or against entrepreneurship. At the same time, we evaluate whether entrepreneurship courses help build professional identity in the sense that motivational self-knowledge increases during the course. Our results show a positive relationship between MSK and the variance in entrepreneurial intentions; particularly when using a higher threshold for ‘high’ MSK. This finding supports the idea that goal hierarchy can be a valuable addition to dominant intention-models in studies on the formation of entrepreneurial intentions. Unfortunately, there is no significant increase in MSK for entrepreneurship students. Considering the benefits of MSK regardless of career choice, this is disappointing. We discuss possible explanations with suggestions for practitioners and formulate directions for future research.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,The study provides insights into the cognitive mechanisms of entrepreneurial intentions but lacks clear practical implications for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673420300688,Measuring addiction to entrepreneurship,Alexander=McKelvie: mckelvie@syr.edu; April J.=Spivack: aspivack@coastal.edu,"Abstract
We develop and validate a measure of entrepreneurship addiction. Inspired by earlier research on entrepreneurship addiction, we develop multi-item scales to measure six underlying criteria (i.e., 
obsessive thoughts
, withdrawal/engagement, self-worth, tolerance, neglect, and negative outcomes). Via three studies, we refine the measure and investigate its dimensional structure. We also provide estimates of prevalence and identify some antecedents of entrepreneurship addiction. The validated measure helps illuminate entrepreneurship addiction’s role in some “dark side” implications of entrepreneurship.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The development of a measure for entrepreneurship addiction could be valuable for identifying and addressing potential issues in early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673420300743,"Oh, it’s complex to see women here, isn’t it and this seems to take all my attention! A repertory grid approach to capture venture capitalists cognitive structures when evaluating women entrepreneurs",Joakim=Wincent: joakim.wincent@hanken.fi; Tom=Lahti: tom.lahti@hanken.fi; Jeaneth=Johansson: jeaneth.johansson@ltu.se; Malin=Malmström: malin.malmstrom@ltu.se,"Abstract
We introduce 
Personal Construct Theory
 (PCT) and the Repertory Grid methodology to investigate deeper differences in the way government venture capital financiers cognitively process to evaluate 77 investment proposals from women and men entrepreneurs. In our study of financiers’ who are by law forbidden to discriminate, we reveal an underlying cognitive bias when evaluating women entrepreneurs. We find that the difficulty when assessing women’s venture potential, as indicated by the greater thought complexity and the excessive weight financiers place on the person rather than the full business case, can be considered to represent the underlying thought mechanism that affect women’s chances of securing financing. This finding suggests women entrepreneurs are looked upon as being role incongruent: misdirecting attention in evaluations. Evaluating women entrepreneurs is a cognitive challenge, because they deviate from the stereotype of an entrepreneur.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study sheds light on cognitive biases in venture capital evaluation, which may impact early-stage ventures led by women entrepreneurs."
https://www.sciencedirect.com/science/article/pii/S2352673420300767,"Hustlers, hipsters and hackers: Potential employees’ stereotypes of entrepreneurial leaders",Matthias=Baum: matthias.baum@uni-bayreuth.de; Biljana=Rudic: biljana.rudic@uni-bayreuth.de; Sylvia=Hubner: sylvia.hubner@unibz.it,"Abstract
Entrepreneurs’ ability to acquire resources, including human resources, is dependent on others’ beliefs and expectations about what is ‘typical’ in an entrepreneurial context. This paper explores beliefs and expectations of how a typical entrepreneurial leader behaves and looks like, i.e. the ‘entrepreneurial leader stereotype’, from the perspective of potential employees. To analyze and describe those entrepreneurial leader stereotypes, we build on leadership categorization theory and stereotyping literature, and conduct an explorative interview study. Our data suggests that potential employees’ entrepreneurial leader stereotypes are associated with specific leadership behaviors and are cognitively associated with certain groups of individuals. We identify three categories of entrepreneurial leader stereotypes: the ‘hustler’, the ‘hipster’, and the ‘hacker’ – all associated with 
entrepreneurial leadership
, men, and youth. We discuss the implications of our findings for entrepreneurship, recruitment, and leadership research, and for recruiting entrepreneurs.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,Identifying and discussing entrepreneurial leader stereotypes can have practical implications for recruitment and leadership in early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673420300779,Knocked down but not out and fighting to go the distance: Small business responses to an unfolding crisis in the initial impact period,Rachel=Doern: r.doern@gold.ac.uk,"Abstract
This study explores in real time how small businesses adjust to an unfolding crisis in the initial crisis impact period and what kinds of actions they take. A weekly diary study following a group of entrepreneurs in London over the first couple months of the COVID-19 inspired 
lockdown
 across the UK beginning March 23, 2020, found that small businesses were knocked down but not out by events. Small businesses were increasing their chances of survival (
going the distance
) by 1) monitoring business functioning and detecting risks (
checking vitals
), 2) initiating quick defensive moves to absorb damages and defend against additional risks (
blocking
), 3) undertaking more skilful moves to avoid further damages (
deflecting
), and 4) planning the next move and managing expectations (
developing tactical awareness
). While the unfolding crisis does not literally represent a fight, features of how boxers engage in a fight were borrowed to help explain small business responses.",June 2021,"Entrepreneurship, Crises, COVID-19, Coronavirus, Lockdown, Diary study",Business Venturing Insights,2025-03-08T00:00:00,9.0,The study on small businesses' responses to crisis provides valuable insights for early-stage ventures facing challenges like the COVID-19 pandemic.
https://www.sciencedirect.com/science/article/pii/S2352673420300780,Crises and entrepreneurial opportunities: Digital social innovation in response to physical distancing,Katharina=Scheidgen: katharina.scheidgen@leuphana.de,"Abstract
As physical distancing is a core measure of containing the spread of COVID-19, this pandemic is a crisis that has uprooted social interaction. While current research mainly focuses on crises as a challenge for entrepreneurial ventures and potential regulatory response mechanisms, we complement this research by addressing the question of how crises in general—and COVID-19’s physical distancing measures in particular—shape entrepreneurial opportunities for social innovation. Based on two rounds of data collection—desktop research mapping out 95 
entrepreneurial activities
 in Germany and four focus groups—we find first that entrepreneurs are proactive agents in alleviating the negative consequences of the COVID-19 crisis. They do so by creating two types of digital social innovation: digital brokering and digitized services. Second, we note that negative societal consequences of crises can be buffered by shifts in entrepreneurs’ strategic orientation through improvised venturing, rapid pivoting and pro-social product extension. Third, we note variance in the persistence of changes with consequences for entrepreneurial opportunities and social innovation: Whereas some social innovation are rather ephemeral, others might endure and promise long-term impacts. We offer key insights for the literature on crisis, social innovation and hybrid organizing as well as on the implications for entrepreneurship practice and policy.",June 2021,"COVID-19, Crisis, Digitalization, Entrepreneurial opportunities, Social innovation",Business Venturing Insights,2025-03-08T00:00:00,8.0,"This abstract provides valuable insights into how crises, such as COVID-19, shape entrepreneurial opportunities for social innovation, which can have long-term impacts on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673421000019,Technological leadership and firm performance in Russian industries during crisis,Sergey Alexander=Anokhin: sanokhin@stcloudstate.edu,"Abstract
In a sample of 2980 firm-year observations collected from three 
industries
 over the five-year period during the Russian economic crisis of 2013–2017, we demonstrate the relative effectiveness of conservative and aggressive strategies for technological leadership in affecting firm performance. Both the conservative strategy aimed at minimizing firm inputs per the set volume of outputs and the aggressive strategy aimed at maximizing the outputs per the set volume of inputs affect performance positively. Of the two alternatives, the aggressive strategy clearly outperforms the conservative one during times of crisis. Additionally, without a clear commitment to either of the strategies, firms stand to lose. We offer a novel way of assessing a firm’s strategy based on the secondary data utilized in this manuscript that can be implemented by the future research.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the study demonstrates the effectiveness of conservative and aggressive strategies during a crisis, the practical implications for European early-stage ventures are not as direct or clear."
https://www.sciencedirect.com/science/article/pii/S2352673421000020,Do (women’s) words matter? The influence of gendered language in entrepreneurial pitching,Lakshmi=Balachandra: lbalachandra@babson.edu; Candida G.=Brush: cbrush@babson.edu; Katrin=Fischer: ktrnfischer@brandeis.edu,"Abstract
Women entrepreneurs consistently raise far less investor funding than men. In this study, we consider how women’s use of gender-similar language may influence investor decisions on venture pitches. Contrary to theories of communicative style and gender, we find women do 
not
 apply linguistic styles traditionally attributed to women in crafting their pitches. Instead, women entrepreneurs use language similar to their male counterparts when pitching to investors. Consistent with gender role congruity theory, we found that a masculine linguistic style is generally more effective in pitching situations, with limitations. Overly masculine language had a negative impact for both male and female entrepreneurs. Our findings suggest women entrepreneurs have a clear understanding of the power of the spoken language and the impact of the words they use when pitching investors for funding.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"This study on gender-similar language in venture pitches has relevance for women entrepreneurs seeking investor funding, impacting their startup ventures in the European market."
https://www.sciencedirect.com/science/article/pii/S2352673421000093,"Everybody hurts: Self-employment, financial concerns, mental distress, and well-being during COVID-19",Marcus T.=Wolfe: mtwolfe@ou.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Adopting an abductive approach, in this paper we use two studies to examine the relationships between financial worries and well-being amongst the self-employed during the time of the COVID-19 pandemic. In Study 1 of 4806 participants from the Understanding Society’s COVID-19 survey of the UK population, we find that financial worries were associated with higher mental distress for self-employed when facing reduced work hours. In Study 2, in a sample of 1794 participants from the six-country COVID study, we find that higher than expected fall in income mediates the association between self-employment and happiness. The findings have implications for research regarding financial worries, distress, and well-being of the self-employed.",June 2021,"COVID-19, Financial worry, Mental distress, Self-employment",Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on financial worries and well-being among the self-employed during COVID-19 provides some insights that could be relevant for European early-stage ventures, but the impact may not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673421000056,How do internationalizing firms emerge?,Maija=Renko: maija.renko@depaul.edu; Jerome A.=Katz: jerome.katz@slu.edu; Sumit K.=Kundu: kundus@fiu.edu,"Abstract
Entrepreneurship today is truly global: international sources of supplies, services, and customers are available to anyone online, and large-scale operations are no longer required to take advantage of global talent, supply, and distribution networks. Yet we do not have a comprehensive understanding of how international firms emerge. Building on previous research at the intersection of entrepreneurship and international business, we propose a theoretical framework for identifying and examining entrepreneurial emergence that is international from the start. This framework builds on the four well-known qualities of emerging organizations (boundaries, resources, intention, and exchange), and three key aspects of international business operations (speed, scope and intensity of internationalization). The resulting model has the potential to help researchers refocus their attention on everyday forms of emerging international firms that are ubiquitous, yet seldom explored.",June 2021,"Firm emergence, Early internationalization, International entrepreneurship",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The theoretical framework proposed has the potential to help researchers focus on everyday forms of emerging international firms, which can have a practical impact on startups seeking to expand globally."
https://www.sciencedirect.com/science/article/pii/S2352673421000111,Exploring the subjective nature of crowdfunding decisions,Jie=Ren: JRen11@fordham.edu; Viju=Raghupathi: Vraghupathi@brooklyn.cuny.edu; Wullianallur=Raghupathi: Raghupathi@fordham.edu,"Abstract
Project funding performance which determines the rise and fall of the 
crowdfunding platform
, is largely governed by the subjective behavior of investors. Leveraging the perspective of attribute substitution theory, we focus on two factors that affect the subjective funding behaviors of investors: emotional language in the 
project description
 and risky funding choices of prior investors. According to the same theory, we classify the projects as either hedonic or utilitarian, identifying whether the association between the factors and funding success of projects vary for hedonic vs. utilitarian projects. Using Kickstarter data, our analysis shows a positive association between the risk-seeking investor ratio and project success for hedonic projects. In addition, it identifies a positive association between the extent to which arousal words are used in project descriptions and project success for all projects. Thus, both positive associations are stronger for hedonic projects than for utilitarian projects. Our findings suggest that investors in crowdfunding contexts do not always make rational decisions in funding projects. This has implications for how a project is positioned within the crowdfunding solicitation marketplace.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"Understanding the subjective funding behaviors of investors in crowdfunding platforms can provide valuable insights for early-stage ventures looking to secure funding, making it highly relevant and impactful."
https://www.sciencedirect.com/science/article/pii/S235267342100010X,Being alert to new opportunities: It is a matter of time,Jintong=Tang: jintong.tang@slu.edu; Lowell W.=Busenitz: busenitz@ou.edu; Masoud=Karami: m.karami@otago.ac.nz; Ludvig=Levasseur: ludvig.levasseur@iimb.ac.in,"Abstract
Time perspective (TP) has been shown to influence individual behavior and decision-making. Although rarely addressed, we suggest that bringing TP into entrepreneurship is important because of its impact on the search, connection, and evaluation of information surrounding potential opportunities (i.e., entrepreneurial alertness). Employing data collected with Iranian entrepreneurs, we find that entrepreneurs’ future positive TP has a significant positive impact on all three alertness dimensions. This research suggests that entrepreneurs’ psychological time provides an important window into understanding how they function.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The impact of entrepreneurs' time perspective on entrepreneurial alertness can offer practical implications for startups in terms of how they search for and evaluate opportunities.
https://www.sciencedirect.com/science/article/pii/S2352673421000147,After the IPO: Entrepreneurs’ transition to philanthropy,Paige=Clayton: paigeclayton@gatech.edu; Maryann=Feldman: Maryann_Feldman@kenan-flagler.unc.edu; Emily I.=Nwakpuda: emily.nwakpuda@uta.edu,"Abstract
Philanthropy
 by entrepreneurs remains an empirically underexplored topic. Combining datasets on U.S. based IPOs with individual philanthropic gifts, we empirically demonstrate that entrepreneurial harvests indeed trigger entrepreneurs’ philanthropic behavior. Furthermore, we distinguish how entrepreneurs’ approach to philanthropy differs from other individuals who experience the same 
wealth
 creating event. Entrepreneurs are able to transition more quickly to philanthropy compared to non-entrepreneurs, are more likely to invest in university science and technology, and also provide a greater number of gifts.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The exploration of entrepreneurs' philanthropic behavior triggered by entrepreneurial harvests provides some insights, but may have limited practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673421000160,The ramifications of effectuation on biases in entrepreneurship – Evidence from a mixed-method approach,Maw-Der=Foo: mawderfoo@ntu.edu.sg; Stephen X.=Zhang: stephen.x.zhang@gmail.com; Roberto S.=Vassolo: rvassolo@iae.edu.ar,"Abstract
The disconnect between the effectuation literature and the cognitive bias research creates artificial boundaries to inhibit the development of a more integrated understanding of decision-making in entrepreneurship. We analyze the effect of effectuation vis a vis on the biases of 
overconfidence
 and illusion of control. We test the effect in both a field survey with entrepreneurs and an experiment. Unraveling the patterns of relationships between effectuation and biases helps ground the burgeoning effectuation theory to more established 
cognitive science
 theories and advance the scholarly understanding of entrepreneurial decision-making.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"Analyzing the relationship between effectuation theory and cognitive biases can enhance our understanding of entrepreneurial decision-making, offering valuable insights for startups in shaping their strategies."
https://www.sciencedirect.com/science/article/pii/S2352673421000172,"Bringing creativity back to entrepreneurship education: Creative self-efficacy, creative process engagement, and entrepreneurial intentions",Maha=Tantawy: maha.tantawy@unb.ca; Kendall=Herbert: kendall.herbert@rmit.edu.au; Jeffrey J.=McNally: jeff.mcnally@unb.ca; Thomas=Mengel: tmengel@unb.ca; Panagiotis=Piperopoulos: panos.piperopoulos@rmit.edu.au; David=Foord: david.foord@unb.ca,"Abstract
In this paper we explore creativity as an antecedent of entrepreneurial intentions. Drawing from 
social cognitive theory
, we explain and empirically illustrate how creative self-efficacy encourages the development of entrepreneurial intentions. We also examine the mediating roles of attitudes and creative process engagement in the creative self-efficacy and entrepreneurial intentions relationship. Based on a pre-post- survey design, in seven entrepreneurship courses taught in three Canadian universities, our findings support the role of creativity as an antecedent to entrepreneurship, but also hint towards some boundaries/limitations on attitudes as the primary focus of 
entrepreneurship education
 programs. We draw a number of implications for the theory and practice of 
entrepreneurship education
.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The exploration of creativity as an antecedent of entrepreneurial intentions has practical value for early-stage ventures and startups, providing insights for entrepreneurship education programs."
https://www.sciencedirect.com/science/article/pii/S2352673421000196,Self-employment duration during the COVID-19 pandemic: A competing risk analysis,Jasper=Grashuis: grashuisj@missouri.edu,"Abstract
The COVID-19 pandemic has caused hardship to both individuals and businesses. Aggregate data indicate large increases in unemployment and 
bankruptcy
 since the beginning of the pandemic, but it is unclear which individuals and businesses are the most vulnerable. With “work absence”, “wage employment” and “unemployment” as three competing risks or events, we study the relationships of owner characteristics to self-employment duration during the COVID-19 pandemic (January-December 2020) in the United States with data from 19,174 respondents to the 
Current Population Survey
. We find that several owner characteristics relate significantly to self-employment duration during the COVID-19 pandemic. Specifically, young, female, and non-White self-employed individuals 
face
 a relatively high risk of unemployment. These and other findings have profound implications for policymakers.",June 2021,"COVID-19, Coronavirus, Self-employment, Firm survival, Small business",Business Venturing Insights,2025-03-08T00:00:00,9.0,"Studying the impact of the COVID-19 pandemic on self-employment duration provides valuable insights for policymakers and entrepreneurs, especially those who are most vulnerable to economic hardship."
https://www.sciencedirect.com/science/article/pii/S2352673421000202,“One tiny drop changes everything”: Constructing opportunity with words,Irina=Liubertė: iriliu@faculty.ism.lt,"Abstract
This paper uses the theory of speech acts to explore how entrepreneurs use language to construct the opportunities they set out to pursue. We use the case of 
Theranos
 (a journey from inspiring vision to criminal infamy) as a natural setting that draws a sharp contrast between words as the content of speech (“opportunity”) and world as its object (opportunity). Our analysis of communication from the early days of the company highlights locutionary content (framing, filling, connecting, and committing), illocutionary force (statements, claims, feelings, attitudes, vows, pledges), and perlocutionary effects (agitate, inspire, envisage, mobilize, and reassure) as distinct aspects of opportunity construction.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"Analyzing how entrepreneurs construct opportunities through language offers some insights, but the practical implications for early-stage ventures may be limited to specific communication strategies."
https://www.sciencedirect.com/science/article/pii/S2352673421000123,The impact of organizational culture on entrepreneurial orientation: A meta-analysis,Marjolaine=Rostain: rostain@em-lyon.com,"Abstract
The importance of organizational culture (OC) on entrepreneurial orientation (EO) has long been of interest to scholars and practitioners. Nevertheless, there remains contradictory results about the impact of OC on EO. Drawing upon the competing value framework (CVF), I conduct a meta-analysis of 70 papers to better understand this relationship. The result highlights first that, contrary to common thinking, there is not only one particular organizational culture that impacts positively EO. Clan, Market and Adhocracy all have a positive impact on EO. Second, even if each of these OC types has a positive impact on EO, the impact on each dimension of EO (Innovativeness, Risk-taking and Proactiveness) may vary. This result reopens the debate about the uni versus multidimensionality of EO.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The meta-analysis on the impact of organizational culture on entrepreneurial orientation contributes valuable insights for early-stage ventures, highlighting the complexity of this relationship and reopening the debate on this topic."
https://www.sciencedirect.com/science/article/pii/S2352673421000226,Social performance measurement adoption in nascent social enterprises: Refining the institutional model,Shoko=Kato: shoko.kato@camden.rutgers.edu,"Abstract
Based on institutional theory, Lall (2017) established a social performance measurement (SPM) adoption model for nascent social 
enterprises
 and found that internal factors (measuring to improve) are influential, while external factors (measuring to prove) have limited or no effects on the probability of adopting SPM. This finding contradicts the predictions of institutional theory; external factors, such as legitimacy and isomorphism, should exert strong influences on nascent social enterprises’ behavior. Using the same dataset as that used in Lall’s (2017) study, we find the missing influence of external factors, i.e., equity and grant funding-related behavior. This study contributes to entrepreneurship research by 1) refining the institutional SPM adoption model, 2) demonstrating the need for a theoretical SPM adoption model, and 3) highlighting the importance of replication studies.",June 2021,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study contributes to entrepreneurship research by refining the institutional SPM adoption model, but its impact on early-stage ventures is not directly addressed."
https://www.sciencedirect.com/science/article/pii/S2352673421000238,Finding the crowd after exogenous shocks: Exploring the future of crowdfunding,Marcus T.=Wolfe: mtwolfe@ou.edu; Jeffrey A.=Chandler: jeffrey.chandler@unt.edu; Jeremy C.=Short: jeremy.short@unt.edu,"Abstract
As ventures around the world begin to resume operations as the COVID-19 pandemic eases, entrepreneurs face new complexities and challenges especially among crowdfunding efforts. In this paper, we offer research-based insights focused on the three stages in a post-crisis recovery (i.e., business resumption, crisis impact analysis, and future evaluation and modification) to shed light on new trends in the crowdfunding context. The goal of this communication is to offer a forward-looking reflection of how crowdfunding has changed following the COVID-19 pandemic. We also offer recommendations to researchers as they attempt to understand the new landscape of crowdfunding.",June 2021,"Crowdfunding, COVID-19, Entrepreneurship",Business Venturing Insights,2025-03-08T00:00:00,8.0,"Offers research-based insights on post-COVID crowdfunding trends, which can be highly valuable for early-stage ventures navigating new complexities and challenges."
https://www.sciencedirect.com/science/article/pii/S2352673420300263,"Leveraging blockchain’s potential – The paradox of centrally legitimate, decentralized solutions to institutional challenges in Kenya",Alisa=Sydow: asydow@escp.eu; Sanwar A.=Sunny: ssunny@ubalt.edu; Chad D.=Coffman: cdc69c@mail.umkc.edu,"Abstract
Blockchain technologies and business models offer a multitude of decentralized and distributed services, but our understanding of the conditions necessary to reach the emerging technology’s full potential is incomplete. The benefits are perhaps most pronounced in developing economies where high institutional misalignment, or even dysfunction, leaves much room for improvement, but we know even less about these contexts due to a dearth of primary research. In this article, we survey thirteen key entrepreneurs and managers in Kenya to identify and observe the current challenges associated with unlocking the potential of blockchain-enabled services. We identify three conditions that need to be met: sufficient technical capacity, appropriate regulative interventions, and most importantly, the adoption of decentralization logics. To truly leverage blockchain technology, market and institutional actors need to collaborate to overcome the paradox of centrally legitimate, decentralized solutions.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"Examines the conditions necessary for blockchain technologies in developing economies, potentially relevant for early-stage ventures looking to leverage decentralized services."
https://www.sciencedirect.com/science/article/pii/S2352673420300329,Less is more? Evidence for a curvilinear relationship between readability and screening evaluations across pitch competition and crowdfunding contexts,Haemin Dennis=Park: parkhd@utdallas.edu; Annaleena=Parhankangas: aparhank@gmail.com; C.S. Richard=Chan: richard.chan@stonybrook.edu; Julie Y.=Huang: Julie.huang@stonybrook.edu,"Abstract
We explore how the 
readability
 of an investment document influences new venture screening evaluations. Based on two 
field studies
 across pitch competition and crowdfunding contexts, we find that documents of high and low 
readability
 receive more favorable screening evaluations compared with those of medium readability. Our post-hoc experiment illustrates how the effect of readability is mediated by entrepreneurial capability and idea complexity. It appears that highly readable documents are generally valued because they make it easy for investors to process information, whereas less readable documents may be preferred because investors perceive the entrepreneurs to possess greater capability.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While exploring the impact of document readability on investment evaluations, the practical implications for early-stage ventures are limited."
https://www.sciencedirect.com/science/article/pii/S2352673420300305,Entrepreneurial uncertainty during the Covid-19 crisis: Mapping the temporal dynamics of entrepreneurial finance,Ross=Brown: Ross.Brown@st-andrews.ac.uk; Augusto=Rocha: a.rocha@st-andrews.ac.uk,"Abstract
This paper illustrates how chronic uncertainty caused by crisis events affects the availability of entrepreneurial sources of 
finance
 for start-ups and small and medium-sized enterprises (SMEs). To explore this line of argument, this paper examines Crunchbase real-time data examining entrepreneurial 
finance
 investments in China during unfolding Covid-19 crisis. The paper shows that these equity investments slumped dramatically in the immediate aftermath of the Covid-19 virus, resulting in a year on year decrease of 60% in the total volume of investment raised between quarter 1 in 2019 and quarter 1 in 2020. Importantly, the paper found early-stage seed investments falling the steepest, suggesting nascent start-ups are those most heavily affected by the crisis. While the global financial crisis heavily hit debt markets, the relational nature of equity investments may mean entrepreneurial finance is even more susceptible to major upheaval caused by the Covid-19 crisis. Overall, enterprise policy makers need to become better attuned at monitoring real-time data sources to mitigate chronic entrepreneurial uncertainty via strategic policy responses.",November 2020,"Equity investments, Crisis, Covid-19, China, Real-time data, Public policy, Entrepreneurial Finance",Business Venturing Insights,2025-03-08T00:00:00,9.0,"Provides crucial insights into how crisis events affect entrepreneurial finance, specifically highlighting the impact on early-stage start-ups, which can be vital for European ventures seeking funding during uncertain times."
https://www.sciencedirect.com/science/article/pii/S2352673420300317,The other side of the coin: Investor identity and its role in resource provision,Brett R.=Smith: Smithbr2@Miamioh.edu,"Abstract
While research highlights the importance of an entrepreneurial identity in acquiring resources, our exploratory study advances research on identity, entrepreneurship, and resource exchange by highlighting the other side of the coin: the role of an investor identity. Based on our 
qualitative study
, we find that investors engage in sensegiving through organizational identity claims and actions to (re)define their organizational reality about who they are and what they do. They engage in investor identity work to adapt to the strategic changes in a market category and sustain resource provision. Our findings have theoretical implications for identity and entrepreneurship research including the construct of investor identity and its sensegiving function, its dynamism and role in strategic changes, and its role in subjective assessment of investor decision-making.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study advances research on investor identity and its role in resource provision, strategic changes, and decision-making, which can have a significant impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673420300330,Health insurance coverage and sources of advice in entrepreneurship: Gender differences,Agnieszka=Kwapisz: akwapisz@montana.edu,"Abstract
Most of the previous literature examining 
health insurance
 and entrepreneurship focused on the effects of provisions of 
health insurance coverage
 on the decision to start or end self-employment. This paper takes a different approach and investigates the decision to purchase health insurance once self-employed. Using data from the US Federal Reserve Board’s 2016 Survey of Consumer 
Finances
, we found that in 2016 (when full provisions of the Affordable Care Act were in place) the self-employed were less likely to be insured, especially females who in the general population are more likely to be insured. Compared to the general population, the odds of being covered by health insurance were 62% lower for self-employed males and 83% lower for self-employed females. Additionally, self-employed females were less likely to be insured when they reported using friends and family as a source of financial information.",November 2020,"Health insurance, Self-employed, Female entrepreneurship, Networks, Institutions, Survey of consumer finances",Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study provides insights into the likelihood of self-employed individuals purchasing health insurance, which could be relevant for startups but may have limited direct impact on their early stages."
https://www.sciencedirect.com/science/article/pii/S2352673420300342,"An “extra life” for the arcade? Entrepreneurship, hybridization, and industry renewal",Philip T.=Roundy: philip-roundy@utc.edu,"Abstract
Entrepreneurs pursue opportunities in a variety of contexts. Research has focused on opportunity creation and recognition in new and emerging 
industries
. However, how entrepreneurs pursue opportunities in struggling 
industries
 at the end of their lifecycles is not clear. To investigate this phenomenon and induce an empirically grounded theoretical model that explains how it unfolds, this study examined the case of the U.S. arcade industry – an industry that despite precipitous declines has experienced a recent and unexpected rebirth through 
entrepreneurial activity
. The findings contribute to research on entrepreneurship in unmunificent environments and suggest that dying industries contain the seeds for renewal through entrepreneurship and business model hybridization.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,The research on entrepreneurship in struggling industries and the potential for renewal through entrepreneurial activity is highly valuable for early-stage ventures looking to innovate in challenging environments.
https://www.sciencedirect.com/science/article/pii/S2352673420300366,Stairway to heaven? rethinking angel investment policy and practice,Richard T.=Harrison: r.harrison@ed.ac.uk; Adam J.=Bock: bock2@wisc.edu; Geoff=Gregson: ggregson@ualberta.ca,"Abstract
Angel investing has grown globally across economies, accompanied by growth in both academic and policymaking interest. In this paper, we critically analyse the current state of knowledge about the process and impact of angel investment. We use a series of stylised facts to highlight key trends as well as misperceptions about those trends. These include the rise of formal and ad hoc angel groups, the efficiency of early stage risk capital markets, the complex interaction between angel and institutional venture capital, and policymaking to address perceived capital market failures. We review the emerging literature on angel investment returns and draw on a new simulation-based analysis of tax incentives to challenge the rationale for government intervention in angel investing.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The critical analysis of angel investment processes, returns, and policy implications can provide valuable insights for startups seeking early stage risk capital and navigating the investment landscape."
https://www.sciencedirect.com/science/article/pii/S2352673420300391,"Not all paths lead to Rome: Self-employment, wellness beliefs, and well-being",Marcus T.=Wolfe: mtwolfe@ou.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Entrepreneurship research in recent years has developed a meaningful understanding of well-being among self-employed individuals. Moving from the direct and conditional association between self-employment and well-being, we propose a moderated-mediation model based on the mediating effects of wellness beliefs. Wellness beliefs could be an important channel to explaining variations in subjective well-being among the self-employed. The mediation effects of wellness beliefs are conditional on two main demographic factors—gender and ethnicity—widely studied in the entrepreneurship literature. Based on a sample of 5822 participants (5208 employed and 614 self-employed) from the 2015 National 
Health Attitude
 Survey we find that wellness beliefs are an important mediator in realizing higher subjective well-being from self-employment, however, the strength of the mediation does not vary by white vs. non-white, however, there is marginal support for differences in strength of mediation for males relative to females. The effect sizes are small. Our findings unpack the self-employment and well-being association and highlight the important role of wellness beliefs.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on well-being and wellness beliefs among self-employed individuals offers interesting insights, but the direct impact on early-stage ventures may be less significant compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673420300354,"The value of publicly available, textual and non-textual information for startup performance prediction",Ulrich=Kaiser: ulrich.kaiser@business.uzh.ch; Johan M.=Kuhn: johan@epacn.dk,"Abstract
We use administrative textual and non-textual data retrieved from publicly available archives to predict the performance of Danish startups at the time of foundation. The performance outcomes we consider are survival, high employment growth, a return on assets of above 20 percent, new patent applications and participation in an innovation subsidy program. We consider a base specification that includes variables for legal form, region, ownership and 
industry
 in all specifications and add variable sets representing firm names, business purpose statements (BPSs) as well as founder and startup characteristics. To forecast the two innovation-related performance outcomes well, we only need to include a set of variables derived from the BPS texts on top of the base variables while an accurate prediction of startup survival requires the combination of the firm names and the BPS variables along with founder characteristics. An accurate forecast of high employment growth needs the combination of the BPS variables and the founder characteristics. All information our forecasts require is likely to be easily obtainable since the underlying information is mandatory to report upon business registration in many countries. The substantial accuracy of our predictions for survival, employment growth, new patents and participation in innovation subsidy programs indicates ample scope for algorithmic scoring models as an additional pillar of funding and innovation support decisions.",November 2020,"Startup, Performance, Prediction, Text as data, Algorithmic scoring",Business Venturing Insights,2025-03-08T00:00:00,8.0,The use of administrative data to predict startup performance and the potential for algorithmic scoring models offer practical value and impact for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673420300408,Uncovering the affective turmoil during opportunity recognition and exploitation: A nonlinear approach,Susana C.=Santos: santossc@rowan.edu; António=Caetano: antonio.caetano@iscte.pt; Sílvia F.=Costa: s.m.costa@rug.nl; Rita=Rueff Lopes: rita.rueff@esade.edu; Ana Junça=Silva: ana_luisa_silva@iscte-iul.pt; Xaver=Neumeyer: neumeyerx@uncw.edu,"Abstract
This study explores the affective turmoil experienced by nascent entrepreneurs during opportunity recognition and exploitation. Based on the affect circumplex model, we employed nonlinear methods to identify configurations of affect that emerge during these early stages of the entrepreneurial journey. We analyzed data from 50 nascent entrepreneurs using Artificial 
Neural Networks
 (ANNs) trained with twenty affect dimensions as input variables and opportunity recognition and opportunity exploitation as outcomes. Results show that nascent entrepreneurs experience different affect configurations during opportunity recognition and exploitation. While four configurations of affect emerged associated with opportunity recognition and exploitation, their nature and importance to the experienced event are significantly different. Specifically, “active screening” is the most important configuration of affect during opportunity recognition, while “vigilant” is the most important during opportunity exploitation. We posit that nonlinear methods can help to uncover the affective turmoil experienced by entrepreneurs during a particular event. These findings provide new insights on how affect associates differently with cognition during the early stages of entrepreneurship.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on affective turmoil in nascent entrepreneurs provides some insights, but may have limited immediate applicability for startups."
https://www.sciencedirect.com/science/article/pii/S235267342030038X,Beyond profit vs. purpose: Transactional-relational practices in impact investing,Richard T.=Harrison: r.harrison@ed.ac.uk; Suwen=Chen: suwen.chen@ed.ac.uk,"Abstract
The emergence of 
impact investing
 over the past decade has been accompanied by increased interest in impact measurement to understand both social and financial returns. One of the constantly re-occurring themes in the research on impact measurement is the tension between financial return and social/environmental mission. However, we challenge this binary view by addressing the following questions: is the profit/purpose trade-off dilemma an immutable feature of 
impact investing
? And, if so, how are investor-investee relationships negotiated through those tensions to keep the impact measurement process flowing productively? Using an exploratory multi-round 
Delphi Method
 study (15 panellists) and 22 semi-structured interviews, we discover a new set of impact measurement practices, which are relational and non-transactional in nature. These two levels of engagement, the transactional and the relational, occur in sequence and reinforce each other, ultimately creating both instrumental and intrinsic value. In the end, we propose the Transactional-Relational Spiral model and encourage further research and validation.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,The exploration of impact investing and the proposal of a new Transactional-Relational Spiral model offer valuable insights for early-stage ventures seeking funding and impact measurement strategies.
https://www.sciencedirect.com/science/article/pii/S2352673420300421,Revising entrepreneurial action in response to exogenous shocks: Considering the COVID-19 pandemic,Timothy L.=Michaelis: tmichaelis@niu.edu; Kim=Klyver: kkl@sam.sdu.dk; Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Ferran=Giones: ferran.giones@ets.uni-stuttgart.de; Alexander=Brem: alexander.brem@ets.uni-stuttgart.de; Jan=Brinckmann: jan.brinckmann@esade.edu,"Abstract
With regards to the ongoing impact of the COVID-19 pandemic in the domain of entrepreneurship, we offer research-based evidence and associated insights focused on three perspectives (i.e., business planning, 
frugality
, and emotional support) regarding 
entrepreneurial action
 under an exogenous shock. Beyond the initial emergency response that countries around the world have taken, we argue that it is time to revise entrepreneurial action guidance in such a context. Our aim is to highlight ways that entrepreneurs can take action in light of the current COVID-19 pandemic. We position our insights to be relevant to both researchers and practitioners coping with an unprecedented situation that has catastrophic consequences both economically and socially.",November 2020,"COVID-19, Entrepreneurial action, Frugality, Social support, Planning, Corporate accelerator",Business Venturing Insights,2025-03-08T00:00:00,7.0,"The focus on entrepreneurial action during the COVID-19 pandemic provides relevant guidance, but the practical application may vary depending on specific startup contexts."
https://www.sciencedirect.com/science/article/pii/S2352673420300445,The roles of thought and affect on entrepreneurship – A new hope,Richard J.=Arend: richard.arend@maine.edu,"Abstract
We challenge the current, psychology-based model ​of affect’s influences on the entrepreneurial process (and some of its past empirical support). We review the current model and identify its limitations. We analyze the relevance of ’hope’ as a cognitive capability underlying the entrepreneurial process and assess why it has yet to be leveraged in our field. We then use hope and the recent studies on emotional control to argue a new, and more prescriptive model of the role of affect in entrepreneurial cognition and action.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While challenging the current model of affect's influence on entrepreneurship is valuable, the proposed new model may not provide immediate actionable insights for startups."
https://www.sciencedirect.com/science/article/pii/S235267342030041X,Problems with crisis intervention: When the government wants to restrain big banks but punishes small businesses instead,Edward N.=Gamble: edward.n.gamble@gmail.com; Gary=Caton: gary.caton@montana.edu; Kelig=Aujogue: aujogue.kelig@gmail.com; Yen Teik=Lee: bizlytk@nus.edu.sg,"Abstract
Following the 2008 financial crisis, Congress passed the Dodd-Frank Act (DF) with the 
intent
 of reducing systemic risk posed by big banks to the country’s 
financial system
. We empirically show that DF negatively impacted both the numbers and dollar amounts of small business loans issued by small banks. This new finding implies an unintended, counterproductive constraint on American venturing activities, particularly in rural communities. This should be of importance to academics and policymakers alike, considering that 
entrepreneurial activity
 is generally regarded as the 
backbone
 
of the U.S. economy
. Without adequate financing to small ventures, the ultimate health 
of the U.S. economy
 could be stunted. Our findings offer key insights into the fields of entrepreneurial 
finance
, regulation and economic growth.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The impact of Dodd-Frank Act on small business loans issued by small banks has implications for American venturing activities and the economy, making it of importance to policymakers and academics."
https://www.sciencedirect.com/science/article/pii/S2352673420300457,"Oh, the places you’ll go: A schema theory perspective on cross-cultural experience and entrepreneurship",Robert J.=Pidduck: rpidduck@odu.edu; Lowell W.=Busenitz: busenitz@ou.edu; Yejun=Zhang: yejun.zhang@utrgv.edu; Abhisekh=Ghosh Moulick: abhisekh@email.unc.edu,"Abstract
Emerging evidence suggests that there is a meaningful link between overseas experience and 
entrepreneurial activity
. However, we find very limited inquiry at the individual-level into why cross-cultural exposure seems to enhance proclivities to engage in entrepreneurship. Drawing from Schema Theory, we argue that breadth of cross-cultural experience cultivates entrepreneurial intentions through the role of alertness—a set of schematic aptitudes for spotting commercial potential. Using a sample of lay individuals from the U.S. (N ​= ​581) with diverse entrepreneurial and overseas experience, we find support for our model. Our findings help explain why cross-cultural experiences can be so impactful for nascent venturing. The greater the diversity of foreign cultural exposure one attains, the greater it expands scanning and search, association and connection, and evaluation and judgment schemata salient to the pursuit of new venture opportunities.",November 2020,"Cross-cultural experience, Cognition, Schema theory, Entrepreneurial intentions, Alertness",Business Venturing Insights,2025-03-08T00:00:00,9.0,"The study on the link between overseas experience and entrepreneurial activity through Schema Theory provides key insights into why cross-cultural experiences enhance entrepreneurial intentions, impacting nascent venturing significantly."
https://www.sciencedirect.com/science/article/pii/S2352673420300470,Trust-based banking and SMEs’ access to credit,Teemu=Kautonen: teemu.kautonen@aalto.fi; Maria=Minniti: mminniti@syr.edu; Antti=Fredriksson: antfre@utu.fi; Andrea=Moro: andrea.moro@cranfield.ac.uk,"Abstract
Access to credit is crucial for SMEs’ survival. However, due to the opaqueness of publicly available information on SMEs, banks face 
information asymmetry
 that can cause them to ration credit. In this case, trust has been shown to facilitate credit access by bridging the information gap. We contribute to the literature on trust-based banking by using new data to add robustness to extant results, and by discussing two important and still overlooked venues requiring further research. Using two waves of original survey data on 160 Finnish SMEs, our results support findings from prior studies by showing a robust positive relationship between trust and credit access (measured one year apart). We also find support for the hitherto assumed but not explicitly tested substitutability of trust and formal information: trust matters but only when formal information for assessing the SME’s creditworthiness is insufficient. We then identify a future research agenda by highlighting that we do not yet know how banks use qualitative factors such as trust to make lending decisions, nor whether the common implicit assumption of symmetric trust between borrower and lender is realistic. Finally, we discuss how these overlooked areas of research have important theoretical and practical applications.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The research on trust, credit access, and information asymmetry for SMEs provides new data and identifies areas requiring further research, offering practical implications for trust-based banking and credit accessibility."
https://www.sciencedirect.com/science/article/pii/S2352673420300469,The temptation of exaggeration: Exploring the line between preparedness and misrepresentation in entrepreneurial pitches,Brian S.=Anderson: andersonbri@umkc.edu; Griffin W.=Cottle: gcottle@umassd.edu,"Abstract
The prevalence of exaggeration in entrepreneurial pitches is one of the more striking behaviors that entrepreneurs display in their interactions with prospective investors. By viewing such behavior through the lens of interpersonal persuasion and deception theory, we believe that exaggeration’s impact on investor 
decision making
 can be understood by examining its close cognitive relationship to both lying and preparedness. Across three studies we investigate the impact that exaggeration and preparedness have on new venture legitimacy and funding potential, and examine the circumstances in which exaggeration may produce beneficial outcomes. For transparency we posted all data, code and study materials on the 
Open Science
 Framework
, at 
https://bit.ly/2XfwYky
.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"Investigating exaggeration in entrepreneurial pitches and its impact on investor decision making provides insights into new venture legitimacy and funding potential, but the practical application may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673420300494,The Magnetic Value of Entrepreneurial Passion for Potential Employees,Melissa S.=Cardon: mcardon@utk.edu; Trey=Lewis: Trey.Lewis@utk.edu,"Abstract
When new ventures tap into the 
labor market
, they must battle with more established companies to recruit top human capital. We examine how an attribute known to influence new venture funders, entrepreneurial passion, also contributes to the ability of the firm to recruit employees. Through 
conjoint analysis
 of potential employee ratings of the attractiveness of working at a new venture, we demonstrate the importance of perceived passion of founders to potential employees. We show that a founder’s perceived passion for their product and for growth can enhance employer attractiveness when founders are perceived to have high human capital, but more importantly, can also compensate for founders with limited human capital. When considered together, perceived passion for product or passion for growth can compensate for low human capital of founders in attracting employees to new ventures.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"Examining how entrepreneurial passion influences the recruitment of human capital in new ventures through conjoint analysis demonstrates the importance of founder's passion, providing practical implications for attracting top talent."
https://www.sciencedirect.com/science/article/pii/S2352673420300500,Assessing the complex dynamics of entrepreneurial ecosystems: A nonstationary approach,Tim=Haarhaus: tim.haarhaus@tu-dortmund.de; Guido=Strunk: guido.strunk@complexity-research.com; Andreas=Liening: andreas.liening@tu-dortmund.de,"Abstract
The notion of 
entrepreneurial ecosystems
 (EEs) has received growing interest from scientists, practitioners and policy-makers over the past decade. Whereas previous research has predominantly focused on identifying the main components and attributes of different ecosystems, the understanding of how EEs evolve over time is still limited. In this study, we build on recent conceptualizations of EEs as complex adaptive systems and apply three methods from chaos theory, the Pointwise D2 (PD2), the Brock-Dechert-Scheinkman (BDS) test and Local Largest Lyapunov Exponents (LLLEs), to study the nonlinear dynamics of EEs. To illustrate our ideas, we analyze the development of the Singapore entrepreneurial ecosystem (SEE) from 1970 to 2018, using 
time series
 data on the monthly creation of new ventures. Our results suggest that the evolution of an EE can be considered as a nonlinear chaotic process that changes over time. Implications for theory and practice, as well as limitations and future research directions, are discussed.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study provides insights into the evolution of entrepreneurial ecosystems using chaos theory methods, which can be valuable for startups navigating complex environments."
https://www.sciencedirect.com/science/article/pii/S2352673420300561,Exploring the future of startup leadership development,Victor=Tiberius: tiberius@uni-potsdam.de; Lisa=Prommer: lprommer@yahoo.com; Sascha=Kraus: sascha.kraus@zfke.de,"Abstract
Leadership development (LD) is a crucial success factor for startups to increase their 
human capital
, survival rate, and overall performance. However, only a minority of young ventures actively engage in LD, and research rather focuses on large corporations and SMEs, which do not share the typical startup characteristics such as a rather young workforce, flat hierarchies, resource scarcity, and high time pressure. To overcome this practical and theoretical lack of knowledge, we engage in foresight and explore which leadership development techniques will be most relevant for startups within the next five to ten years. To formulate the most probable scenario, we conduct an international, two-stage 
Delphi study
 with 27 projections among 
industry
 experts. According to the expert panel, the majority of startups will engage in leadership development over the next decade. Most startups will aim to develop the leadership capabilities of their workforce as a whole and use external support. The most prominent prospective LD measures in startups include 
experiential learning
 methods, such as action learning, developmental job assignments, multi-rater feedback, as well as digital experiential learning programs, and developmental relationships such as coaching in digital one-to-one sessions. Self-managed learning will play a more important role than formal training.",November 2020,"Startup, Leadership development, Delphi study, Forecasting, Foresight",Business Venturing Insights,2025-03-08T00:00:00,9.0,"Leadership development is crucial for startup success and the study explores future techniques, providing practical guidance for startups to enhance human capital."
https://www.sciencedirect.com/science/article/pii/S2352673420300548,The dark side of sustainability orientation for SME performance,Katariina=Salmela-Aro: katariina.salmela-aro@helsinki.fi; Teemu=Kautonen: teemu.kautonen@aalto.fi; Simon J.D.=Schillebeeckx: simon@smu.edu.sg; Johannes=Gartner: johannes.gartner@aalto.fi; Henri=Hakala: henri.hakala@lut.fi; Kirsi=Snellman: kirsi.snellman@lut.fi,"Abstract
This article examines how a firm’s willingness to make trade-offs that favour sustainability over commercial goals attenuates the relationship between firm-level sustainability orientation and subsequent performance. The hypothesis development draws on 
stakeholder theory
 and the literature on mission and revenue drifts, while the empirical analysis is based on two waves of original survey data on Finnish manufacturing SMEs. We find that sustainability orientation is positively associated with performance only when the willingness to make sustainability trade-offs is low, whereas the relationship becomes negative when the willingness to make such trade-offs is high. Our findings thus suggest that the popular adage of 
doing well by doing good
 might only hold if doing good does not conflict with business interests. The results add to stakeholder theory by showing how conforming to stakeholder expectations can be good for business – but only if doing so does not seriously compromise the pursuit of profits.",November 2020,"Sustainable entrepreneurship, SME, Sustainability orientation, Sustainability trade-offs, Performance",Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study highlights the importance of balancing sustainability with commercial goals, which may have varying impacts on startup performance."
https://www.sciencedirect.com/science/article/pii/S2352673420300512,Being cognizant of the amount of information: Curvilinear relationship between total-information and funding-success of crowdfunding campaigns,Nischal=Thapa: ntvd7@mail.umkc.edu,"Abstract
Fund-seekers launching crowdfunding campaigns must provide information about their product or service to attract potential fund-providers. They usually provide information about their product using text, videos, and images. However, the amount of information that maximizes the likelihood of funding success is unknown. This study amalgamates the communications and crowdfunding literature and argues that the total-information has a curvilinear relationship with the likelihood of funding success. This study collects data from more than two thousand rewards-based crowdfunding campaigns, conducts multiple logit regression analyses, and demonstrates that total-information initially positively and later negatively affects the likelihood of crowdfunding success. Furthermore, this study indicates that fund-seekers should focus on providing information through text and videos rather than images.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The research on crowdfunding campaigns provides insights into optimizing information presentation for funding success, which can be beneficial for startups seeking funding."
https://www.sciencedirect.com/science/article/pii/S2352673420300536,Expanding entrepreneurial solution spaces in times of crisis: Business model experimentation amongst packaged food and beverage ventures,Tua A.=Björklund: tua.bjorklund@aalto.fi; Maria=Mikkonen: maria.mikkonen@aalto.fi; Pauliina=Mattila: pmattila@swin.edu.au; Floris=van der Marel: floris.vandermarel@aalto.fi,"Abstract
Research summary
Times of crisis require entrepreneurial responses to mitigate adverse effects and address new opportunities. This study focuses on how packaged food and drink entrepreneurs in Finland took action to create and capture new value during the Covid-19 crisis. Examining 844 social media posts of 66 ventures between March and May 2020 and interviewing 17 of these ventures, we found ventures to experiment with new business model variations, which not only expanded their set of solutions directly, but resulted in action-based learning leading to longer-term changes and increased capabilities for subsequent value creation. Furthermore, collaborative experiments and prosocial support increased the solution space through developing the capabilities of the ecosystem.
Managerial summary
The global 
lockdown
 measures in response to the 
coronavirus
 pandemic have disrupted supply, production, sales and consumption. Facing these constraints, entrepreneurs can respond quickly and experiment to create new liquidity and opportunities. Our analysis of packaged food and beverage entrepreneurs in Finland during the crisis shows how entrepreneurs leverage existing resources and acquire new ones to create new offerings, operations and partnerships. These initial actions serve as experiments to learn from in creating and revising business models, promoting a virtuous cycle of further action and expanding potential future solutions accessible to entrepreneurs. Importantly, opportunities available to the venture expand through both venture specific learning and through supporting other actors in the ecosystem.",November 2020,"Crisis, Entrepreneurship, Capabilities, Experimentation, Value creation",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The study on entrepreneurial responses during the Covid-19 crisis offers valuable lessons on adapting to challenges and creating new value, providing practical strategies for startups."
https://www.sciencedirect.com/science/article/pii/S2352673420300524,Failing and exiting in social and commercial entrepreneurship: The role of situated cognition,Deniz=Ucbasaran: Deniz.Ucbasaran@wbs.ac.uk; Pablo=Muñoz: pmunoz@liverpool.ac.uk; Gabriella=Cacciotti: Gabriella_Cacciotti@baylor.edu,"Abstract
This paper explores the decision-making process social entrepreneurs go through when faced with a failing venture, in comparison to commercial entrepreneurs. Findings point towards the role of situated cognition. Using a ‘think-aloud’, scenario-based experiment and two assessments of cognitive effort, our research reveals a unique “person-in-situation” decision-making process in failing situations. The entrepreneurs’ sequences of cognitive activities and cognitive effort are distinctively influenced by the nature of the failing venture as they reach the decision to persist or exit, regardless of the entrepreneurs’ baseline motivations. This is counterintuitive against the predominance of explanations emphasizing the relevance of orientation and intentions to address social needs or maximize profit as well as the role of escalation of commitment in the termination/persistence decision.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study provides insights into the decision-making process of social entrepreneurs in failing ventures, which can be valuable for early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673420300597,Trust in blockchains: Algorithmic and organizational,Chetan=Chawla: chetanchawla@gmail.com,"Abstract
The recent emergence of blockchains has reconceptualized our understanding of crowdfunding, platforms, organization, and governance. The disruption, and disintermediation made possible by blockchains has rightfully received increasing attention from entrepreneurs, and entrepreneurship researchers alike. In this article, I broaden these perspectives by paying particular attention to trust in blockchains, and contrasting it with perspectives on trust from 
Transaction Cost Economics
, Agency Theory, and the 
Resource Based View
. In sum, I compare perspectives on trust in these traditional theories to the conception of trust in blockchains – a mix of algorithmic, and organizational – to offer new insights into the implications of the rise of blockchains.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The exploration of trust in blockchains and its implications offers valuable insights for entrepreneurs and researchers, impacting the understanding of crowdfunding and governance."
https://www.sciencedirect.com/science/article/pii/S2352673420300603,Psychometric evaluation of the Ryff’s Scale of psychological wellbeing in self-identified American entrepreneurs,Srikant=Manchiraju: smanchiraju@fsu.edu,"Abstract
In recent years, psychological wellbeing is gaining importance in entrepreneurship research. And, one of the most critical measures of psychological wellbeing is Ryff’s Scales of Psychological Wellbeing (SPWB). The SPWB consists of six dimensions: Autonomy, Environmental mastery, Personal growth, Positive relations with others, Purpose in life, and Self-acceptance. However, previous studies have noted that the 
psychometric
 properties of the SPWB in various contexts as problematic. Thus, the purpose of the present study was to investigate the 
psychometric
 properties of the SPWB – 42 Item version in a sample of self-identified American entrepreneurs. Data from the Midlife Development in the United States (MIDUS) were used to test the SPWB’s psychometric properties. The data were subjected to various statistical analyses, which revealed that the proposed 6-factor structure of the SPWB was conditionally supported in the entrepreneurial context. Based on the psychometric evaluation, suggestions are made for future studies investigating psychological wellbeing in entrepreneurship settings. To date, the present study is the 
first
 to test the psychometric properties of the SPWB in the context of entrepreneurship research.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study focuses on the psychometric properties of a measure of psychological well-being in American entrepreneurs, which may have limited practical implications for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673420300615,Support for social entrepreneurs from disadvantaged areas navigating crisis: Insights from Brazil,Anna-Katharina=Lenz: anna-katharina.lenz@rmit.edu.au; Edgard=Barki: edgard.barki@fgv.br; José Guilherme F.=de Campos: jose.campos@ifsp.edu.br; Jonathan=Kimmitt: jonathan.kimmitt@ncl.ac.uk; Ute=Stephan: Ute.Stephan@kcl.ac.uk; Vivianne=Naigeborin: vivianne.naigeborin@arymax.org.br,"Abstract
When a socioeconomic crisis arises in an emerging economy, it highlights structural social issues facing the country and disproportionally impacts those from disadvantaged areas. Social entrepreneurship may be important as part of the solution to overcome this situation. However, it is often privileged individuals who engage in social entrepreneurship to tackle the problems of those who are disadvantaged. To enable social entrepreneurship in disadvantaged areas, we argue that it is instrumental to overcome a lack of at least three capitals: economic, human, and social and to craft enabling ecosystems. This rapid response paper explores how intermediary organizations might support and foster social entrepreneurs from disadvantaged areas. We discuss challenges and opportunities drawing on insights from micro and macro level perspectives in the entrepreneurship literature and from the challenges faced by ANIP, an organization which brings together actors from different sectors to develop social entrepreneurship in disadvantaged areas of São Paulo, Brazil.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,The examination of social entrepreneurship in disadvantaged areas and the role of intermediary organizations can provide valuable strategies for addressing similar challenges in European startup ecosystems.
https://www.sciencedirect.com/science/article/pii/S2352673420300627,The impact of financial insecurity on the self-employed’s short-term psychological distress: Evidence from the COVID-19 pandemic,Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
The earnings of the self-employed are relatively low and volatile, a risk that exacerbated during the recent COVID-19 pandemic. Using three two-weeks-apart waves of data from the Understanding America Study, we show that relative to wage workers, the self-employed experience greater 
psychological distress
 through self-reported financial insecurity (the chance of running out of money). Using additional cross-sectional data from the COVID-19 Household Impact Survey, we show that the self-reported chance of job loss disproportionally impacts the 
psychological distress
 of the self-employed. Together, these results underscore that the economic uncertainties induced by the COVID-19 pandemic hit the self-employed particularly harsh by deteriorating short-term psychological distress. Moreover, our study is informative about the impact of income uncertainty on psychological distress.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The study on the psychological distress of the self-employed during the COVID-19 pandemic offers important insights for European early-stage ventures facing economic uncertainties.
https://www.sciencedirect.com/science/article/pii/S2352673420300639,Determinants of social entrepreneurial intentions in a developing country context,José Milton de=Sousa-Filho: miltonsousa@unifor.br; Stelvia=Matos: s.matos@surrey.ac.uk; Samara=da Silva Trajano: samara.trajano@hotmail.com; Bruno=de Souza Lessa: brunolessa85@yahoo.com.br,"Abstract
Social entrepreneurial intentions have become a key area of interest in the entrepreneurship discourse. Studies conducted in developed countries have shown that crucial determinants involve previous experience, mediated by empathy, moral obligation, self-efficacy and 
perceived social support
. This paper brings new contributions on such determinants by replicating Hockerts (2017) on a developing country, a rather distinct social reality when compared to other analyses. We successfully replicated the results on social entrepreneurial determinants, except on the effect of empathy and perceived 
social support
, in the case of individuals with very low income. These have important implications for policy and research as it shows the importance of developing incentives considering contextual drivers and the need to explore how theories developed in more privileged scenarios would persist or change under more unstable and challenging environments. We also suggest that the application of items in different contexts goes beyond careful translation and validation, requiring a deeper consideration of the context in which the data is collected, with direct implications for results interpretation and discussions.",November 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The paper provides important insights into social entrepreneurial determinants in a developing country context, highlighting the need for contextual considerations in policy and research."
https://www.sciencedirect.com/science/article/pii/S2352673420300652,To get out of the building or not? That is the question: The benefits (and costs) of customer involvement during the startup process,Scott L.=Newbert: scott.newbert@baruch.cuny.edu; Erno T.=Tornikoski: e.tornikoski@exeter.ac.uk; Jeff=Augugliaro: jeff.augugliaro@baruch.cuny.edu,"Abstract
Nascent entrepreneurs are frequently advised to “get out of the building” and consult with customers before any serious efforts to develop new products or services are undertaken so they can understand what their potential customers really want/need. Despite the intuitive nature of this advice, it lacks theoretical and empirical bases. As such, the worldwide popularity of the movements this approach has spawned, such as Customer Development and Lean Startup, seems to rest on the unfounded assumption that the benefits of involving customers outweighs any costs. Thus, we theorize about the pros and cons of involving customers early on in the startup process and empirically test our model using data from the PSED II. Our findings suggest that while involving customers early will help entrepreneurs create offerings customers are willing to pay for, it also results in potentially costly delays in the launch of those offerings. We also find that these benefits and costs are magnified when innovativeness is high.",November 2020,"Customer development, Customer involvement, Knowledge, Lean startup, Learning",Business Venturing Insights,2025-03-08T00:00:00,9.0,"The study challenges the popular advice given to nascent entrepreneurs regarding involving customers early on in the startup process, providing theoretical and empirical evidence on the costs and benefits of this approach."
https://www.sciencedirect.com/science/article/pii/S2352673419301854,JBVI on its 5th birthday: Reflections on place and journey,Dimo=Dimov: d.p.dimov@bath.ac.uk; Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Pablo=Muñoz: P.Munoz-Roman@liverpool.ac.uk,"Abstract
In this editorial, we take stock of the 
Journal of Business Venturing Insights
 (
JBVI
) as it turns five years old. We reflect on the unique niche that 
JBVI
 fills in the realm of journals focused on research in entrepreneurship and highlight the papers that have gained the most traction within this short period. We reflect on the role that 
JBVI
 can play in the landscape of the entrepreneurship research and outline the types of papers that can drive the journal forward.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,The editorial reflects on the journal's role and impact without providing direct practical insights or implications for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673419300691,Entrepreneurial apologies: The mediating role of forgiveness on future cooperation,Samuel L.=Clarke: sclarke@csusm.edu,"Abstract
Entrepreneurs are expected to seek forgiveness from stakeholders for a transgression. While research has shown that apologies issued by entrepreneurs can be an effective tool for obtaining forgiveness, there is no assurance that an apology leading to stakeholder forgiveness will also necessarily restore future cooperation. We contend that entrepreneurial apologies are an effective mechanism for entrepreneurs to receive forgiveness and that forgiveness mediates the relationship between the apology and the restoration of future cooperation by reducing the amount of retributive 
justice
 sought by stakeholders. Quantitative analysis of data from a questionnaire administered to 268 U.S. university students and 120 U.S. participants on Mechanical Turk supports our contention, with participants found to be significantly more forgiving of an entrepreneurial transgression after receiving an apology and also more willing to engage in future cooperation with the new venture if forgiveness was restored. We also demonstrate the mediating effects of forgiveness on an apology, suggesting that restorative and retributive 
justice
 elements inherent in an apology interact to increase the overall effectiveness. Finally, it was also uncovered that compensation offers were significantly more restorative than non-explicit statements of contrition, explicit statements of contrition, empathy, and responsibility acknowledgements.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The research on entrepreneurial apologies and forgiveness offers practical implications for startups on how to handle transgressions with stakeholders, emphasizing the importance of apologies in restoring future cooperation."
https://www.sciencedirect.com/science/article/pii/S2352673418301094,The higher returns to formal education for entrepreneurs versus employees in Australia,Jolanda=Hessels: hessels@ese.eur.nl,"Abstract
Van Praag et al. (2013) analyze whether the returns to formal education in terms of income differ between entrepreneurs and employees. Using US data (1979–2000), they find that entrepreneurs have higher returns to formal education than employees. They also find evidence that the level of personal control in one’s occupation explains these higher returns. In the present study, we aim to replicate these findings using a dataset from a different country (Australia) and time period (2005–2017). Moreover, we extend the study by Van Praag et al. (2013) by distinguishing between entrepreneurs with and without employees. In accordance with Van Praag et al. (2013), we also find higher returns to education for entrepreneurs compared to employees. However, this finding mainly applies to the entrepreneurs without employees. Moreover, we do not find evidence for a mediating role of personal control in this relationship.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study replicates findings on returns to formal education for entrepreneurs compared to employees in a different country and time period, providing some insights but not significantly impacting early-stage ventures directly."
https://www.sciencedirect.com/science/article/pii/S2352673419300824,Blockchain disruption and decentralized finance: The rise of decentralized business models,Yan=Chen: ychen5@stevens.edu; Cristiano=Bellavitis: c.bellavitis@auckland.ac.nz,"Abstract
Blockchain technology can reduce transaction costs, generate distributed trust, and empower decentralized platforms, potentially becoming a new foundation for decentralized business models. In the financial 
industry
, blockchain technology allows for the rise of decentralized 
financial services
, which tend to be more decentralized, innovative, interoperable, borderless, and transparent. Empowered by blockchain technology, decentralized 
financial services
 have the potential to broaden 
financial inclusion
, facilitate open access, encourage permissionless innovation, and create new opportunities for entrepreneurs and innovators. In this article, we assess the benefits of decentralized 
finance
, identify existing business models, and evaluate potential challenges and limits. As a new area of financial technology, 
decentralized finance
 may reshape the structure of modern 
finance
 and create a new landscape for entrepreneurship and innovation, showcasing the promises and challenges of decentralized business models.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"The abstract discusses the potential benefits of decentralized finance empowered by blockchain technology, which could reshape modern finance and create new opportunities for entrepreneurs. The practical value and impact on early-stage ventures/startups in Europe are significant."
https://www.sciencedirect.com/science/article/pii/S2352673419301295,"What do they think and what do they say? Gender bias, entrepreneurial attitude in writing and venture capitalists’ funding decisions",Joakim=Wincent: joakim.wincent@hanken.fi; Jeaneth=Johansson: jeaneth.johansson@ltu.se; Malin=Malmström: malin.malmstrom@ltu.se; Aija=Voitkane: aija.voitkane@ltu.se,"Abstract
This study shows that women may be at a disadvantage when signaling that they are “entrepreneurial” to venture capitalists. We demonstrate how gender-based disadvantages may arise from role incongruence in entrepreneurship by analyzing multi-source data from 131 venture capital applications, venture capitalists’ cognitions, and their funding decisions. Our analysis indicates that women who signal an 
entrepreneurial attitude
 are more likely to elicit prevention considerations from venture capitalists, whereas men who signal such an attitude are more likely to elicit promotion considerations. We also find that promotion considerations increase the amount of financing, whereas prevention considerations decrease the amount of financing. Our study increases knowledge about the gendered cognitions that underlie implicit bias among investors and knowledge about the effects of regulatory focus on funding outcomes by exploring the interaction between gender and 
entrepreneurial attitude
.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The abstract explores gender-based disadvantages in signaling entrepreneurship to venture capitalists, providing insights on funding outcomes. While the findings are important, the direct impact on European early-stage ventures/startups may not be as immediate or extensive."
https://www.sciencedirect.com/science/article/pii/S2352673419301271,Handle with care: Entrepreneurial reputation-borrowing in an emerging economy,Suresh=Bhagavatula: sureshbh@iimb.ac.in; K.=Kumar: kumark@iimb.ac.in,"Abstract
Owing to the lack of a track record, new ventures, by definition, tend to lack a strong reputation and often resort to reputation borrowing by affiliating with high-reputation actors. We study how entrepreneurial reputation-borrowing works in a context where reputation sources are scarce. We undertook an in-depth field study of a new venture in an emerging economy setting – specifically in Bangalore, India, at a time when a nascent entrepreneurial ecosystem was emerging. We examine the process and consequences of reputation-borrowing for this venture, which forged a relationship with a large Western multinational after entering a prestigious academic incubator. In terms of the process, we highlight the importance of high-status institutional intermediaries such as incubators in reputation-deficient contexts. In relation to the consequences, our study surfaces a tension: since successfully borrowing reputation is relatively rare in emerging economy settings, it may lead to hubris and (subsequent) lapses in judgment vis-à-vis the venture’s own altercentric uncertainty. Given this prospect of a “liability of a good reputation”, entrepreneurial reputation-borrowing in an emerging economy may need to be “handled with care” – in terms of reducing a new venture’s own uncertainty reduction during the process and not letting down its guard after reputation has been borrowed.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The abstract delves into reputation-borrowing by new ventures in emerging economies, highlighting the potential risks and consequences. While the study is insightful, the practical application for European early-stage ventures/startups may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673420300159,Unintended consequences of scaling social impact through ecosystem growth strategy in social enterprise and social entrepreneurship,Syrus M.=Islam: syrus.islam@aut.ac.nz,"Abstract
Scaling social impact is regarded as the main currency in social 
enterprise
 and social entrepreneurship. Many social enterprises scale their social impact through ecosystem growth strategy, under which they indirectly address targeted social problems by growing and/or sustaining a supportive social 
enterprise
 ecosystem through activities such as organising advocacy campaigns and supporting other social enterprises to grow. However, the existing literature is largely biased towards the success stories of ecosystem growth strategy. Countering this “success bias”, this article presents a framework describing how, under certain conditions, scaling social impact through ecosystem growth strategy can create unintended consequences. In doing so, this paper also challenges the prevailing reductionist view of ecosystem growth as a social impact scaling strategy and provides a more reliable and comprehensive account of this scaling strategy. This article hopes to stimulate future research on greater understanding and management of unintended consequences of ecosystem growth strategy in social enterprise, as well as delineating the boundary conditions of this strategy with regard to scaling social impact.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,"The abstract discusses the unintended consequences of scaling social impact through ecosystem growth strategy in social enterprises. While the insights are valuable, the direct impact on European early-stage ventures/startups may not be immediate or applicable to all."
https://www.sciencedirect.com/science/article/pii/S2352673420300226,Can public venture capital support sustainability in the social economy? Evidence from a social innovation fund.,Ellen=Vanderhoven: ellen.vanderhoven@glasgow.ac.uk,"Abstract
The Social Innovation Fund (SIF) - funded by Scottish Government and the 
European Social Fund
 - adopts a ‘public venture capital’ model to support socially innovative organisations. This article critically explores the use of public venture capital programmes to fund and grow the social economy through the 
case study
 of Heavy Sound Community Interest Company. We conclude that, while SIF funding helped Heavy Sound to scale-up an effective intervention in the short term, further significant scaling might undermine the project’s success and long-term sustainability was not assured. We call for further research into the long-term consequences of public venture capital programmes coming to an end, including coordinated evaluation of the SIF.",June 2020,"Social innovation, Social economy, Scaling-up, Sustainability, Public venture capital",Business Venturing Insights,2025-03-08T00:00:00,5.0,"The critical exploration of public venture capital programmes and their impact on social economy organizations provide some insights, but the practical implications for early-stage ventures in Europe might be limited."
https://www.sciencedirect.com/science/article/pii/S2352673420300172,Employees’ decision to participate in corporate venturing: A conjoint experiment of financial and non-financial motivations,Mahshid=Jessri: Mjessri@calstatela.edu,"Abstract
This paper is a replication and extension of a prior study that examines the factors influencing employees’ willingness to participate in corporate ventures. We use a conjoint experiment to build knowledge surrounding the impact of motivating factors beyond financial profit as well as the role of entrepreneurial self-efficacy. Our replication results largely support prior findings and indicate that the extra effort required for participating in a corporate venture is the most important factor driving employees’ decision. Our replication also extends prior findings in two critical ways. First, it shows that independence is essential in developing a comprehensive understanding of the decision-making process for participating in a corporate venture. Second, it demonstrates that entrepreneurial self-efficacy influences the effects of employment risk and expected success on the relationship between profit sharing and employees’ willingness to participate in a corporate venture. Our results suggest that individual-level differences provide additional explanatory power and a fuller understanding of the employees’ decision to participate in corporate ventures. They also yield important practical implications for managers who wish to motivate their employees towards the corporate venturing path.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The abstract replicates and extends a study on factors influencing employees' participation in corporate ventures, emphasizing the importance of motivating factors beyond financial profit. The findings provide valuable insights for managers but may have limited immediate impact on early-stage ventures/startups in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673420300147,Exploring the relation between family involvement and firms’ financial performance: A replication and extension meta-analysis,Jörn H.=Block: block@uni-trier.de; Christopher=Hansen: hansenc@uni-trier.de,"Abstract
This study replicates and extends the meta-analyses on family firm performance by O’Boyle et al. (2012). Based on the empirical findings of 1095 primary studies from 61 countries, we find an economically small but statistically significant positive impact of family influence on firms’ financial performance. This outperformance occurs particularly for large and listed firms, as well as for accounting rather than market performance measures. Furthermore, we investigate the potential moderation effects of different country cultural dimensions, as operationalized by the Hofstede and GLOBE framework. We find higher family firm performance effects for countries with a higher degree of individualism, masculinity, long-term orientation performance orientation, and a lower degree of 
power distance
. We find only small differences in the mean effect sizes of family firm performance across different academic disciplines.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The study provides insights into family influence on firm performance across different countries, which can be valuable for early-stage ventures looking to understand the impact of family dynamics on their financial performance."
https://www.sciencedirect.com/science/article/pii/S2352673420300184,Do the United Nations’ Sustainable Development Goals matter for social entrepreneurial ventures? A bottom-up perspective,Franziska=Günzel-Jensen: frang@mgmt.au.dk; Nicole=Siebold: nicole.siebold@ovgu.de; Arne=Kroeger: arne.kroeger@aalto.fi; Steffen=Korsgaard: stko@sam.sdu.dk,"Abstract
Research on societal grand challenges has become a major theme in management research. Societal grand challenges require joint efforts by private, public, and social sector organizations and are described in the framework of the United Nations’ 
Sustainable Development Goals
 (SDGs). One major contributor to this framework are social entrepreneurial ventures. Aligning their interventions and indicators with the SDGs can provide them with great benefits such as facilitating 
resource mobilization
 and increasing legitimacy among stakeholders. The majority of research on SDGs tends to understand the SDG framework as inherently good, as a powerful compass and 
narrative
 to create social value and take action. However, taking-for-granted that social entrepreneurial ventures readily materialize the SDGs seems to neglect the question of whether they accept the framework and how an utilization may differ among them. Drawing on 
qualitative interviews
 of 15 social entrepreneurial ventures, we address this gap and identify three distinct types of SDG utilization, namely SDG evangelism, SDG opportunism, and SDG denial. Our study contributes to research on the intersection of social entrepreneurship and societal grand challenges by uncovering the roles of resourcefulness and deviance in SDG utilization. Furthermore, we identify trust between the United Nations and social entrepreneurial ventures as a determinat for SDG utilization and provide several practical implications.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"Research on societal grand challenges and the role of social entrepreneurial ventures aligning with SDGs can have a significant impact on European early-stage ventures by providing them with insights on resource mobilization, legitimacy, and SDG utilization strategies."
https://www.sciencedirect.com/science/article/pii/S2352673420300196,Using the HEXACO-100 to measure Individual Entrepreneurial Orientation: Introducing the HEXACO-IEO,Matt C.=Howard: MHoward@SouthAlabama.edu,"Abstract
Individual Entrepreneurial Orientation (IEO) is a three-dimensional conceptualization of 
personality traits
 that influence entrepreneurial outcomes, and it includes risk-taking, innovativeness, and 
proactiveness
. Much is still unknown about IEO, in part due to the relative recency of its conceptualization and subsequent operationalization. Advancing our understanding of IEO could be greatly hastened if an existing, widespread measure was shown to approximate a supported measure of IEO. Existing datasets using this widespread measure could be reanalyzed to derive new inferences regarding IEO, and future authors administering this widespread measure for other purposes could simultaneously study IEO. One such nonproprietary measure that may gauge IEO is the HEXACO-100 (also labeled the HEXACO-PI-R). In the current article, we identify a collection of items from the HEXACO-100 that closely approximate a supported measure of IEO and its three dimensions, as evidenced by the measure’s 
psychometric
 properties as well as convergent and criterion validity. We label this collection of items the HEXACO-IEO. The identification of this measure opens many avenues for future research. The HEXACO-100 has been studied alongside a wide array of constructs – constructs that can now be studied alongside IEO. Also, the current study connects IEO with specific dimensions of the HEXACO. As this framework has been linked with many 
personality theories
, IEO can too be linked with these theories. We specifically suggest that the Situation, Trait, and Outcome Activation (STOA) model may offer notable insights into IEO. Thus, the current article provides many implications for research on entrepreneurship, personality, and their intersection.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,Advancing the understanding of Individual Entrepreneurial Orientation (IEO) and providing a measure like HEXACO-IEO can be beneficial for startups in assessing their entrepreneurial traits and making informed decisions.
https://www.sciencedirect.com/science/article/pii/S2352673420300214,Restorative entrepreneuring: A new cross- disciplinary agenda to support at-risk social groups,Pablo=Muñoz: pmunoz@liverpool.ac.uk; Lee=Wainwright: l.wainwright@liverpool.ac.uk,"Abstract
In this paper we uncover and systematize practical challenges and research priorities at the intersection of entrepreneuring, rehabilitation and at-risk social groups. Our work draws on practical challenges identified by service providers supporting vulnerable individuals in the process of rehabilitation. They reveal long-standing issues in the facilitation of emancipatory work and perspectives on the (actual and potential) role that entrepreneuring may play in the process. Leveraging these ideas we offer the notion of 
restorative entrepreneuring
 and put forward a cross-disciplinary agenda comprised by five spaces and four levels of inquiry. We offer 20 action-oriented research questions, reflecting research priorities that are relevant in both theoretical and practical terms. We propose this practice-based agenda as a way of inspiring our scholarly community to explore in more detail the capacity of and possibilities for a new 
restorative entrepreneuring
 in the support of vulnerable members of our society.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,The concept of restorative entrepreneuring and the research agenda proposed can offer valuable insights for startups working with vulnerable social groups and exploring new opportunities in rehabilitation efforts.
https://www.sciencedirect.com/science/article/pii/S235267342030024X,“Who is an entrepreneur?” is (still) the wrong question,Stratos=Ramoglou: s.ramoglou@soton.ac.uk; William B.=Gartner: wgartner@babson.edu; Eric W.K.=Tsang: ewktsang@utdallas.edu,"Abstract
The idea that there exist undiscovered entrepreneurial endowments fell into disfavor after Gartner's (1988) “‘Who is an entrepreneur?’ is the wrong question”. However, a resurgence of the “question of the entrepreneur” suggests that advances in genetics research may be the key to discovering what makes entrepreneurs distinctive. This paper draws from Wittgensteinian philosophy to offer a novel critique regarding the search for differences between entrepreneurs and non-entrepreneurs. We explain that the idea that entrepreneurs are different gains credence through misleading forms of language that 1) encourage the illusion of some causal interplay between opportunities and potential entrepreneurs, and 2) overshadow the contingent nature of 
entrepreneurial action
. We sidestep misleading forms of thought to suggest that ontological reflection on the nature of entrepreneurial agency shows why we will never discover some “entrepreneurial gene”. Equally important, this Wittgensteinian critique demonstrates the limits of empirical research for problems that fundamentally require conceptual attention – not more determined effort or advanced research methods.",June 2020,Not Found,Business Venturing Insights,2025-03-08T00:00:00,2.0,The abstract focuses on philosophical critique and ontological reflection rather than practical implications for startups.
https://www.sciencedirect.com/science/article/pii/S2352673420300251,Startups in times of crisis – A rapid response to the COVID-19 pandemic,Andreas=Kuckertz: andreas.kuckertz@uni-hohenheim.de,"Abstract
Research summary
The discovery of the 
coronavirus
 (SARS-CoV-2) and the spread of COVID-19 have led many governments to take drastic measures. The 
lockdown
 of large parts of society and economic life has come as an exogenous shock to many economic actors, not least innovative startups. This rapid response research combines a qualitative research design informed by 
entrepreneurial ecosystem
 actors with an analysis of policy measures called for, announced, and reportedly implemented in the international press. Interviews from an entrepreneurial ecosystem offer a first-hand account of the adversity startups 
face
 during a crisis and how by utilizing 
bricolage
 responses they cope, and the analysis of policy measures can serve as an inspiration to design support initiatives to protect startups from the consequences of the current lockdown and to alleviate the effects of future crises.
Managerial summary
The lockdown measures as a response to the spread of the new coronavirus threaten the existence of many innovative startups. Our rapid response research first illustrates the challenges entrepreneurs face as a consequence of the crisis. Second, we illustrate how entrepreneurs are dealing with the effects of the crisis and what they are doing to protect their ventures. Finally, we present measures that could be utilized by policymakers to assist entrepreneurs facing challenges. The research conducted suggests that while startups are successfully leveraging their available resources as a first response to the crisis, their growth and innovation potential are at risk. Therefore, policy measures should not only provide first aid to startups by alleviating the pressure caused by constrained cashflow, but also involve long-term measures embedded in and supported by the wider entrepreneurial ecosystem to ensure rapid recovery and growth.",June 2020,"Bricolage, Coronavirus, COVID-19, Crisis, Entrepreneurship, Policy",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The abstract addresses the impact of COVID-19 lockdown on startups and provides insights into coping strategies and policy measures, which are highly relevant for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673419300216,Sensory processing sensitivity and entrepreneurial intention: The strength of a weak trait,Rainer=Harms: r.harms@utwente.nl; Isabella=Hatak: isabella.hatak@unisg.ch; Manling=Chang: manllian@ms76.hinet.net,"Abstract
Research on entrepreneurial 
personality traits
 has done a commendable job in developing theory and providing evidence for the consistent effects of the entrepreneurial trait profile (ETP) on various entrepreneurial outcomes. While research has established the fit between the extravert, conscientious and open traits and entrepreneurial intention (EI), the view that entrepreneurship may provide an alternative career path for people outside the norm has attracted increasing interest. In this study, we explore a counterweight to the dominant ‘superhero’ personality perspective by arguing that, in entrepreneurship, 
highly sensitive persons
 (HSPs) can attend to their own needs and skills, and turn their weaknesses into strengths. S
ensory processing sensitivity
 (SPS) – a fundamental meta-personality trait – may provide the crucial piece in the personality puzzle related to opportunity recognition ability (ORA) and the intention to act entrepreneurially. We adopt a person-environment fit approach and employ fuzzy-set qualitative comparative analysis (fsQCA). We find that combinations of either SPS or ETP and ORA are sufficient conditions for EI. This study contributes to the literature on entrepreneurial traits by inviting reconsideration of the stereotypical view of extrovert and open entrepreneurs and acknowledging the strength of a ‘weak’ trait.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The abstract explores personality traits in entrepreneurship, offering a different perspective, but the practical implications for startups are not as direct as in other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673419300198,Are transitions to self-employment beneficial?,Briana Sell=Stenard: Stenard_BS@mercer.edu,"Abstract
Much research has been conducted studying entry into self-employment and the corresponding rewards and consequences of self-employment on earnings. The literature finds mixed results regarding whether workers enter self-employment to maximize their pecuniary or their non-pecuniary benefits. This paper suggests that whether workers are able to increase their pecuniary or non-pecuniary benefits in self-employment depends on their motivations for entering self-employment in the first place. This study uses longitudinal NSF SESTAT data on over 28,000 scientists and engineers to track 
employment changes
 and changes in work outcomes over time for the same individuals. The research examines changes in pecuniary and non-pecuniary work outcomes when wage workers transition to self-employment, compared to those who do not change employers, as well as to those who change employers but do not transition to self-employment. This allows a deeper look at the implications of different types of mobility on work outcomes. The findings show that in general those who transition to self-employment experience improvements in their non-pecuniary outcomes but not in their pecuniary outcomes, however the results do differ depending on the motivation for moving. Using job satisfaction as a proxy measure for non-pecuniary benefits, this paper finds that while those who enter self-employment from wage work do generally improve their job satisfaction, job satisfaction rises for all movers, not just for those who enter self-employment.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the study provides insights into self-employment outcomes, the focus on scientists and engineers limits the generalizability to early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S235267341830088X,How much does the “same-gender effect” matter in VCs' assessments of entrepreneurs?,Joakim=Wincent: joakim.wincent@hanken.fi; Jeaneth=Johansson: jeaneth.johansson@ltu.se; Malin=Malmström: malin.malmstrom@ltu.se; Aija=Voitkane: aija.voitkane@ltu.se,"Abstract
Our study uses 
cognitive mapping
 techniques to take into account how the same/opposite gender influences the cognitive evaluations of venture capitalists (VCs). Contrary to what has often been discussed in previous entrepreneurship literature, our results report women VCs evaluate women entrepreneurs more critically, and men VCs evaluate men entrepreneurs more critically. However, overall, the VCs' vaguer processing and lower rating of women's venturing compared to men's indicate a general structure of subordinating women's venturing compared to men's venturing. Ultimately, this contributes with an alternative view to explain what we see on the VC scene: women entrepreneurs are more likely to be rejected. We discuss implications of these results as well as implications for future study.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,"The study on cognitive evaluations by VCs, while interesting, does not directly address practical implications or provide actionable insights for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S235267341930037X,"Money might not make you happy, but can happiness make you money? The value of leveraging subjective well-being to enhance financial well-being in self-employment",Marcus T.=Wolfe: mtwolfe@ou.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
In recent years there has been a growing interest in understanding the relationship between subjective well-being and self-employment. Extending this body of work, we ask whether subjective well-being is associated with financial well-being for self-employed individuals, and whether those with financial skills are better able to leverage subjective well-being to realize higher financial well-being. Using a sample of 332 self-employed individuals in the Consumer Financial Protection Bureau's (CFPB's) National Financial Well-Being Survey, we find that there is a positive association between subjective well-being and financial well-being, and this association is strengthened among those with higher financial skills. These findings highlight the need for assessing the association between different types of well-being from self-employment.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"This abstract provides valuable insights into the association between well-being and financial skills for self-employed individuals, which can be beneficial for startups looking to optimize their financial well-being."
https://www.sciencedirect.com/science/article/pii/S235267341930040X,Minimum wage and transition of non-employer firms intending to hire employees into employer firms: State-level evidence from the US,Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Among the non-employer firms who intend to hire, the higher state-level 
minimum wage
 could dissuade them from becoming employer firms. Using data from Business Formation Statistics in the US, we assess the effect of within-state variation in 
minimum wage
 on three state-level outcomes: count of business applications for Employer Identification Number (EIN) from firms intending to hire employees; count of firms who transition into employer firms after their application; and average time taken by firms to transition into employer firms after application. Based on 1,692 state-quarter observations from 2005 to 2013, higher state minimum wage is negatively associated with a count of applications for EIN and count of applicants transitioning into employer business and slows the transition of applicants into employer businesses. The findings are robust to a placebo test and an alternate specification controlling for common correlation between state and year. Additional analyses on new business activity show that state minimum wage has no association with the portion of the state population starting new businesses or the share of opportunity-based (vs. necessity-based) new businesses in a state. The findings have implications for policymakers considering the relevance of minimum wage in encouraging the transition of non-employer firms intending to hire employees into employer firms.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The findings on the impact of minimum wage on non-employer firms transitioning into employer firms can be relevant for policymakers, but may have limited direct practical value for early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673419300496,Biomimicry: New insights for entrepreneurship scholarship,Stephanie A.=Fernhaber: sfernhab@butler.edu; Alyssa Y.=Stark: alyssa.stark@villanova.edu,"Abstract
While the natural world is argued to serve as a powerful source of knowledge and insight, entrepreneurship scholars have struggled to fully engage with nature. This raises the question of whether the antecedents, mechanisms and consequences of entrepreneurship might look differently if nature’s time-tested patterns were truly considered. This paper reviews the existing linkages between biology and entrepreneurship. The value of 
biomimicry
 in inspiring new insights into entrepreneurial phenomena is then discussed, followed by a biomimicry-based mode of theorizing. Examples and future research directions are provided.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The discussion on how biomimicry can inspire new insights into entrepreneurship is interesting, but the practical implications for European startups are not clearly outlined."
https://www.sciencedirect.com/science/article/pii/S2352673419300630,A diagnostic framework for social impact bonds in emerging economies,Jonathan=Kimmitt: jonathan.kimmitt@newcastle.ac.uk; Pablo=Muñoz: pmunoz@liverpool.ac.uk,"Abstract
A social impact bond (SIB) is a new type of outcome-based social investment mechanism for 
enterprises
 operating in the social economy. They have grown across the developed world, yet its complexity may prevent from fulfilling their promises. This is particularly the case when SIB-pertinent regulatory frameworks, actors and social problems are ill-defined as in the case of emerging economy contexts. In this paper we ask, how can policy agents better identify, prioritize and weight social issues in the early design of a social impact bond? We tackle this issue by applying design methods in the co-development of a SIB diagnostic framework for emerging economies. This is both a conceptual and an actionable artifact. As a conceptual framework, it provides a holistic picture of the contextual circumstances influencing the emergence of a SIB. As a policy tool, it allows policy agents to assess and prioritize social issues and target groups and subsequently guiding policy decisions regarding investment allocation on social economy 
enterprises
.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The development of a SIB diagnostic framework for emerging economies can be highly valuable for early-stage ventures in Europe operating in the social economy, providing actionable guidance for policy agents."
https://www.sciencedirect.com/science/article/pii/S2352673419300885,Back from the brink: The revitalization of inactive entrepreneurial ecosystems,Philip T.=Roundy: philip-roundy@utc.edu,"Abstract
Entrepreneurial ecosystems
 (EEs) are receiving intense attention. However, the 
revitalization
 of inactive EEs in unmunificent contexts is understudied. To investigate this phenomenon, an inductive study was conducted of a once-vibrant EE that became dormant because of an undiversified industrial base and a precipitous decline in its 
regional economy
. The study revealed that the community members working to revitalize the city’s EE (“EE champions”) used a holistic collection of economic, socio-cultural, community, and discursive strategies. The findings have implications for scholars focused on entrepreneurship in extreme and atypical contexts, the micro-foundations of EEs, and EE leadership. The study also generates concrete insights for practitioners seeking to reinvigorate EEs.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study on revitalizing inactive entrepreneurial ecosystems can provide insights into leadership strategies, but the direct impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673419300472,Do small funding amounts lead to reverse herding? A field experiment in reward-based crowdfunding,Jörn H.=Block: block@uni-trier.de; Michael A.=Zaggl: zaggl@mgmt.au.dk,"Abstract
Several biases are known to influence funding decisions in crowdfunding. Among these biases is herding behavior; that is, the tendency to imitate the funding decisions of others. Herding is a very robust phenomenon in crowdfunding and uniformly characterized as a positive reinforcement effect. We challenge this characterization and ask whether the funding decisions of others may in fact have a negative effect and lead to a reduction of follow-up funding decisions if they are very small – a phenomenon to which we refer as 
reverse herding
. We conducted a field experiment at a reward-based crowdfunding platform by randomly contributing small funding amounts to some campaigns while keeping track of a non-manipulated control group. Our findings support the notion of reverse herding. The number and amount of contributions by the crowd following our small funding amounts were fewer and smaller than in the control group. We discuss reverse herding in relation to established crowdfunding concepts and formulate a dilemma of small contributions: Although small contributions are a fundamental part of crowdfunding, they can also cause the detrimental effect of reverse herding. Practical and theoretical implications of reverse herding are discussed and several opportunities for future research are outlined.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The concept of reverse herding in crowdfunding is novel and challenges established ideas, providing insights for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673419300538,Hybrid entrepreneurs’ self-efficacy and persistence change: A longitudinal exploration,Timothy L.=Michaelis: tmichaelis@niu.edu; Jeffrey M.=Pollack: jmpolla3@ncsu.edu; Jon C.=Carr: jon.carr@ncsu.edu; David R.=Marshall: dmarshall1@udayton.edu,"Abstract
Hybrid entrepreneurship—where an individual simultaneously engages in startup activities as well as wage-based employment—is an increasingly common career transition path. Yet, relatively little research has explored entrepreneurial characteristics during these unique career transitions. We provide exploratory insight into the longitudinal relationship between self-efficacy and persistence for hybrid entrepreneurs’ (
N
 = 29) across a twenty-week period during which aspiring entrepreneurs engaged in activities related to venture startup while maintaining wage employment. As such, we propose that entrepreneurial self-efficacy (ESE) and entrepreneurial persistence are malleable concepts that change over time. Using our longitudinal sample, we find evidence that ESE predicts entrepreneurial persistence change over time. Perhaps more importantly, we model how changes in ESE over time affect changes in entrepreneurial persistence for hybrid entrepreneurs. In sum, our work provides a foundation from which future research can examine the longitudinal transition of nascent entrepreneurs moving from an occupational setting as an employee to launching their own venture.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,Exploring the characteristics of hybrid entrepreneurship can offer valuable insights for startups with individuals engaged in multiple career paths.
https://www.sciencedirect.com/science/article/pii/S2352673418301033,Revisiting Covin and Slevin (1989): Replication and extension of the relationship between entrepreneurial orientation and firm performance,Younggeun=Lee: younglee@iastate.edu; Yiming=Zhuang: zhuangy@iastate.edu; Minjoo=Joo: mjjoo@iastate.edu; Tae Jun=Bae: tjbae@hanyang.ac.kr,"Abstract
We replicate and extend the seminal paper of Covin and Slevin (1989) on entrepreneurial orientation (EO) by conducting two studies. Specifically, we examine the impact of a firm’s EO on financial performance under hostile environments using various measurements. Study 1 is a direct replication of Covin and Slevin (1989) in which we utilize data collected from firms in the USA, which adopted the same survey measures of Covin and Slevin (1989). Study 2 is a generalization and extension of Covin and Slevin (1989) in which we implement newly developed objective EO measurement by Miller and Le Breton-Miller (2011) and utilize objective financial data of Chinese public firms. The results of both studies provide evidence that a firm’s EO positively impacts firm performance, especially in hostile environments. Further theoretical implications and contributions based on diverse types of replication studies are discussed.",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The replication and extension studies on entrepreneurial orientation and firm performance provide practical implications for early-stage ventures facing hostile environments.
https://www.sciencedirect.com/science/article/pii/S2352673419300952,Exploring the differences in perceptions of work importance and job usefulness to society between self-employed and employed individuals,Marcus T.=Wolfe: mtwolfe@ou.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
A quintessential bane in the modern workforce is finding meaningful work, or work that is perceived to meaningfully contribute to society. Given that entrepreneurial undertakings are characterized by both fulfillment and challenges, whether self-employed individuals perceive their work to be more important or useful to society than those who are employed is an open question. Using two samples – 33,162 participants from 35 European countries in the 2015 European Work Conditions Survey (EWCS 2015), and 8110 participants from 36 countries in the 2015 International Social Survey Programme (2015 ISSP) – we examine the association between self-employment and the importance and usefulness to society that individuals assign to their work. We find that though there are no substantive differences between self-employed and employed individuals on doubts about the importance of their job (from EWCS 2015 sample), however, self-employed individuals do perceive their jobs to be more useful to society (from 2015 ISSP sample).",November 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"Examining the perceptions of self-employed individuals towards the importance and usefulness of their work can offer some insights, but may have limited practical impact on startups."
https://www.sciencedirect.com/science/article/pii/S2352673419300770,Perceiving entrepreneurs: Job title comparisons in warmth and competence,James W.=Berry: James.Berry@ucl.ac.uk,"Abstract:
Recent research in entrepreneurship and stereotypes have considered how entrepreneurs are evaluated on various factors. Taking a 
social cognition
 approach, we examine entrepreneur stereotypes by identifying patterns in stereotype content dimensions for entrepreneurs and related job titles. The title of entrepreneur is complex incorporating both business and innovation components. Across three studies we compare warmth and competence dimensions of the title of entrepreneur with those of a business leader (CEO), inventor/innovator (scientist), and a role requiring both creativity and business skills (advertiser). We find that while entrepreneurs are consistently seen as less competent than either a CEO or scientist and more so than an advertiser, they tend to be seen as warmer than these professionals.",November 2019,"Stereotypes, Entrepreneur, Job titles, Warmth, Competence, Social cognition",Business Venturing Insights,2025-03-08T00:00:00,6.0,"Analyzing entrepreneur stereotypes provides some understanding of social perceptions, which can be valuable for startups in managing their image and interactions."
https://www.sciencedirect.com/science/article/pii/S2352673418301628,Images of entrepreneurship: Using drawing to explore entrepreneurial experience,Jean S.=Clarke: clarke@em-lyon.com,"Abstract
Entrepreneurship is a generative and transformative process of altering convention where personal/social history, assets, technologies, and trading activity are gathered in organizational form. How entrepreneurs frame this process, and are, in turn, organised by this process, constitutes the entrepreneurial experience. Typically this framing has been researched using narrative methods: how entrepreneurs tell their stories. In this paper we develop an emerging branch of inquiry challenging a sole focus on linguistic narrative in favour of accessing the experience of entrepreneurs by asking them to draw an image of their venture using pencils and paper. Drawing has long been recognised in other social science disciplines as an empirical method for eliciting in-depth and latent information about complex or difficult experiences. In this paper we show some indicative drawings created by entrepreneurs, accompanied by their verbal explanations of what these drawings represent for them, and we highlight how the process was a generative exercise for the entrepreneurs. We focus on two aspects of drawing, which we refer to as “beginnings”, and “traces”, that we feel are particularly relevant to why this medium is valuable for exploring the experience of entrepreneurs.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,"The use of drawing as a method to explore the experiences of entrepreneurs presents a unique and potentially valuable approach to understanding their ventures, which could offer insights for startups in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673419300083,"Entrepreneurial action, creativity, & judgment in the age of artificial intelligence",David M.=Townsend: dtown@vt.edu; Richard A.=Hunt: rickhunt@vt.edu,"Abstract
The rapid advancement of computationally complex systems of artificial intelligence (AI), is the fruit of a decades-long effort to endow machines with cognitive capabilities that equal or even exceed those possessed by human actors. As the growing sophistication of AI algorithms revolutionizes 
entrepreneurial action
 in uncertain environments, these advancements raise an important set of questions for future theory-building in 
entrepreneurial action
, creativity, and decision-making research. In this paper, we take up these critical questions by exploring how advancing AI systems provide novel solutions for resolving the fundamental challenges of modal uncertainty in entrepreneurial decision environments. And in doing so, AI algorithms create new possibilities for future forms of entrepreneurial action. We conclude the paper with a robust discussion of future research at the intersection of AI and entrepreneurship.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,"The intersection of AI and entrepreneurship presents a cutting-edge area with implications for future entrepreneurial actions, creativity, and decision-making, potentially impacting early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673419300174,Bloom where planted: Entrepreneurial catalyzers amidst weak institutions,Lowell W.=Busenitz: busenitz@ou.edu; Abhisekh=Ghosh Moulick: abhisekh@ou.edu; Robert J.=Pidduck: rob.pidduck@odu.edu,"Abstract
Aggregated country-level statistics and regulatory aspects of institutions alone fail to explain the increasing emergence of promising ventures in developing contexts. We argue institutions have multiple dimensions and draw attention to the often overlooked heterogeneities within these institutional dimensions in developing nations. Using data from developed, emerging, and base of pyramid economies we show evidence of unequal endowments across regulatory, cognitive, and normative institutional dimensions. Drawing on exemplar ventures we then illustrate that some founders develop workarounds by compensating for the weaker institutional dimension/s. Thus, rather than waiting for weak institutions to be fixed, entrepreneurial catalyzers go forward by harnessing their weak institutional context, countering a common 
narrative
 in development research.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"Highlighting the importance of institutions and their heterogeneities in developing contexts, this abstract could provide valuable insights for startups navigating different institutional dimensions in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673418301525,The mediating role of self-efficacy on entrepreneurial intentions: Exploring boundary conditions,Michael P.=Ciuchta: Michael_ciuchta@uml.edu; Deborah=Finch: Deborah_finch@uml.edu,"Abstract
Zhao, Seibert and Hills (“ZSH”) developed an important framework in their 2005 article in the Journal of 
Applied Psychology
. Using a sample of MBA students, ZSH found that entrepreneurial self-efficacy mediated the relationship between certain factors and entrepreneurial intentions. In this study, we conduct a “quasi replication” and extension of the ZSH results. Using a sample of adults in the U.S., we both replicate key findings but also find considerable heterogeneity in effect sizes across certain sample sub-groups. Our results offer important insights regarding entrepreneurial processes across different sectors of the population.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"While the quasi replication study offers insights into entrepreneurial processes and self-efficacy across different population sectors, the practical value for early-stage ventures in Europe may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673418301604,“I never needed eyes to see”: Leveraging extreme challenges for successful venture creation,Wilson=Ng: NgW@regents.ac.uk; Félix=Arndt: Felix.Arndt@dmu.ac.uk,"Abstract
Challenge-based entrepreneurship is a nascent research area that has sought to tackle a longstanding issue of how entrepreneurs may overcome extreme challenges. We seek fresh insights into this issue by researching entrepreneurs who face one of the most extreme physical challenges, namely of acute sight loss (“blindness”). While this condition carries social perceptions of extreme physical incapacity and performance limitations, there continue to be notable examples of entrepreneurs with permanent blindness. How do blind entrepreneurs overcome barriers resulting from their impairment? By observing and conversing with two blind serial entrepreneurs, we offer preliminary answers to this question by generating insights into processes of opportunity formation in which ideas are conceived and developed out of the entrepreneurs' challenges. Our chief finding is that our blind entrepreneurs instrumentalized their impairments for commercial or social purposes by creating ventures that leveraged public perceptions of blindness and disability. Accordingly, in their ventures, our entrepreneurs drew on distinctive attributes of their physical and social challenges as a means of exploiting narrow conceptions of disabled people's capabilities. These entrepreneurs therefore overcame their challenges by capitalizing on public conceptions of their limited capabilities. The subsequent 
Discussion
 offers research opportunities in and beyond challenge-based entrepreneurship by considering a number of theoretical and practical implications of the adaptive skills and attributes of our entrepreneurs that have enabled them to engage with popular “ableist” and medical, or “tragic”, perceptions of disability in original and positive ways.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"The exploration of how blind entrepreneurs overcome challenges and leverage public perceptions presents novel and impactful insights that could inspire and inform startups in Europe, making it highly valuable."
https://www.sciencedirect.com/science/article/pii/S2352673418301057,Entrepreneurship and genetics: New Evidence,Boubacar=Diallo: Boubacar.Diallo@qu.edu.qa,"Abstract
This paper seeks to better understand the differences in entrepreneurship rates across administrative regions and countries. Using several measures of entrepeneurship, as well as regional and panel data of countries, it finds that lactase persistence has a significant impact on entrepreneurship. Moreover, it shows that cross-country level variation in the frequency of lactase persistence found in the human body more than 500 years ago explains these observed differences across countries and regions today. Specifically, it finds that a one 
standard deviation
 increase in lactase persistence decreases regional self-employment by 7%. In addition, the estimates show that a one 
standard deviation
 increase in lactase persistence decreases total early-stage 
entrepreneurial activity
 (TEA) and established business ownership (EBO) by 4% and 1.58%, respectively. These findings remain robust to the introduction of the 
econometric
 method to deal with the mismeasurement of our historical variable, lactase persistence, as well as the introduction of several types of control variables such as per-capita GDP growth, education, culture, population density, urbanization, 
genetic diversity
, institutions, geography, disease and banking structure.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,"The study provides valuable insights into the impact of lactase persistence on entrepreneurship rates, offering a unique perspective on historical factors affecting regional self-employment. The robustness of the findings to various control variables adds to its credibility."
https://www.sciencedirect.com/science/article/pii/S2352673419300095,Let's take the entrepreneurial ecosystem metaphor seriously!,Andreas=Kuckertz: andreas.kuckertz@uni-hohenheim.de,"Abstract
The notion of entrepreneurial ecosystems (EEs) has garnered considerable attention in the academic discourse. However, quite often this notion is treated as just a biological metaphor that should not be taken too seriously. I challenge this view and ask in a 
thought experiment
 what could be learned from the management of natural ecosystems to assist the development of EEs. The outcome is a novel, service-based definition of EEs and five suggested principles for the management of EEs that might advance theorizing on them and future empirical analysis.",June 2019,"Entrepreneurial ecosystem, Entrepreneurial ecosystem services, Entrepreneurial ecosystem management",Business Venturing Insights,2025-03-08T00:00:00,7.0,The abstract presents a novel approach to understanding entrepreneurial ecosystems by drawing parallels with natural ecosystems. The proposed principles for managing EEs could contribute to advancing theoretical and empirical analysis in this area.
https://www.sciencedirect.com/science/article/pii/S2352673418300908,Is leadership language ‘rewarded’ in crowdfunding? Replicating social entrepreneurship research in a rewards-based context,Aaron H.=Anglin: a.anglin@tcu.edu; Jeremy C.=Short: Jeremy.Short@ou.edu,"Abstract
Rewards based crowdfunding (where individuals provide funding for a campaign in exchange for a pre-specified reward) represents one of the largest forms of crowdfunding to date. While an emerging stream of research examines how the rhetoric used in crowdfunding campaigns impacts funding success, a number of studies examining language used in crowdfunding have only been explored in the context of social crowdfunding campaigns that rely on very different audiences, funding amounts, and project goals. To build knowledge surrounding the relationship between the rhetoric used in rewards-based crowdfunding and potential campaign success we replicate a number of rhetoric approaches previously examined in social contexts. Specifically, we examine the efficacy of charismatic rhetoric, political rhetoric, entrepreneurial orientation rhetoric, and virtue rhetoric in a sample of 1000 campaigns drawn from Kickstarter. Our replication results reveal relatively little consistency across contexts underscoring the value of replication to understand boundary conditions of important entrepreneurial phenomena.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,"The study on rewards-based crowdfunding and rhetoric analysis provides some insights into campaign success, but the lack of consistency across contexts limits its practical value for early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S2352673418301574,Do social enterprises walk the talk? Assessing microfinance performances with mission statements,Roy=Mersland: roy.mersland@uia.no; Samuel Anokye=Nyarko: samuel.nyarko@ulb.ac.be; Ariane=Szafarz: aszafarz@ulb.ac.be,"Abstract
We study mission drift in social 
enterprises
 by examining whether these organizations stick to the 
actual
 mission enshrined in their mission statements. We use data from 
microfinance
 organizations (MFOs), a 
homogeneous group
 of social enterprises which have been scrutinized—and sometimes criticized—for mission drift. We focus on three publicly recognized and non-mutually-exclusive microfinance social missions identified by previous studies: 
poverty alleviation
, women's empowerment, and rural 
financial inclusion
. Based on hand-collected data from 199 MFOs worldwide, our results suggest strong coherence between social missions and actual practices. Hence, we argue that, with respect to MFOs' own stated social missions, mission drift is no serious concern. The trustworthiness of social mission statements makes them suitable evaluation tools for social enterprises.",June 2019,"Mission statement, Mission drift, Microfinance, Social enterprise, Content analysis",Business Venturing Insights,2025-03-08T00:00:00,8.0,"The examination of mission drift in social enterprises, specifically MFOs, provides practical insights into the alignment of social missions with actual practices. The study's findings suggest that mission drift may not be a significant concern for MFOs, contributing to the evaluation tools for social enterprises."
https://www.sciencedirect.com/science/article/pii/S2352673418301422,Labor of love? The influence of work-conditions among self-employed and work stress,Marcus T.=Wolfe: mtwolfe@ou.edu; Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Self-employment represents work conditions distinct from wage employment. Applying concepts from the Effort-Reward Imbalance model to work characteristics typical to self-employment—autonomy, meaningfulness of work, and physical demands of work—we explore the association between these work conditions and work stress. In a sample of 225 self-employed individuals in the American Working Conditions Survey (AWCS), our results indicate that 
autonomy
 has a positive association with work stress. Furthermore, meaningfulness serves to suppress the relationship between 
autonomy
 and work stress, while physical work demands have no influence on this association. Our findings have implications for the work characteristics of self-employed and their well-being.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,"The study focuses on self-employment work conditions in the US, which may have limited direct impact on European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S235267341830163X,Incorporated entrepreneurship in Norway: Propensity and endurance,Lars=Kolvereid: lars.kolvereid@nord.no; Bjørn-Willy=Åmo: bjorn.w.amo@nord.no,"Abstract
This study concerns the relationship between individual characteristics, the propensity to become owners of incorporated firms, and endurance as business owners. We start with a large sample of non-entrepreneurs in 2004 and identify those individuals in this cohort who became and remained majority owners of incorporated businesses between 2005 and 2016. The results indicate that individual characteristics can explain a significant proportion of the variance in the propensity to become owners of incorporated firms as well as business owner endurance. One important finding is that prior income is strongly positively related to becoming and remaining owners of incorporated firms.",June 2019,"Incorporated entrepreneurship, Entry into business ownership, Ownership endurance, Individual characteristics",Business Venturing Insights,2025-03-08T00:00:00,5.0,The study explores the relationship between individual characteristics and becoming owners of incorporated firms with potential implications for European startups.
https://www.sciencedirect.com/science/article/pii/S235267341830091X,Do government and legal barriers impede entrepreneurship in the U.S.? An exploratory study of perceived vs. actual barriers,Agnieszka=Kwapisz: akwapisz@montana.edu,"Abstract
In this exploratory study, we investigate how the actual and the perceived level of government bureaucracy correlates with nascent ventures' outcomes, a largely understudied topic in entrepreneurship literature. We use data merged (N = 922) from the U.S. Panel Study of Entrepreneurial Dynamics II (PSED II)—which tracked nascent startups over a six-year period—and the Economic Freedom of North America Index from the Fraser Institute. We find no relationship between state-level economic freedom and startups' outcomes and no relationship between the actual and the perceived government bureaucracy. Additionally, government is perceived as a major barrier by only 6% of entrepreneurs (of whom only 54% actually check government regulations), and 1% of entrepreneurs list regulations as the main reason for quitting the startup process. Overall, our results suggest that government and legal barriers are not significantly related to nascent startups’ outcomes and are not major barriers for entrepreneurs.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,6.0,"The study investigates the impact of government bureaucracy on nascent ventures, providing valuable insights for early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S2352673418300842,Back to the roots! Testing Miller's entrepreneurial orientation construct using Sono-Leontief conditions,Didier=Chabaud: Didier.chabaud@univ-paris1.fr; Jean-François=Sattin: Jean-Francois.Sattin@univ-paris1.fr,"Abstract
Using a new database of 391 interviews of French 
SME
 managers, this paper investigates the consistency of the Miller indicator of entrepreneurial orientation by relying on Sono-Leontief conditions. The main results suggest that Miller's construct is impacted by internal effects that cast doubts on its internal reliability, and that multidimensional assessments of entrepreneurial orientation should be preferred in empirical research.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,4.0,The study on the consistency of entrepreneurial orientation indicators in French SMEs may have limited generalizability to European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673418301343,Developing opportunities in digital health: The case of BioBeats Ltd,David=Lopez: d.lopez2@exeter.ac.uk,"Abstract
Departing from established research on entrepreneurship, design-based entrepreneurship places an explicit emphasis on the entrepreneurial process as evolutionary and emergent in which knowledge and understanding of an opportunity are acquired incrementally by means of design and evaluation of alternative solutions. This paper develops a use case of BioBeats Ltd., a UK-based university spin-off which has successfully managed to turn an opportunity in digital health into a commercially viable 
enterprise
. Adopting a design-based paradigm, the company under study started by building a 
technical solution
 informed by a set of design principles which subsequently allowed the company to convert the socio-technical nature of the opportunity into technological artefacts that were further refined and tested by means of real-world experiments with third parties and citizens.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The study on design-based entrepreneurship and the case of BioBeats Ltd. offer practical insights for European startups on turning opportunities into viable enterprises through design principles.
https://www.sciencedirect.com/science/article/pii/S2352673418301185,Personality traits and income attainment of self-employed people—Accounting for model uncertainty,Boris N.=Nikolaev: boris_nikolaev@baylor.edu; Ileana=Maldonado-Bautista: Ileana_MaldonadoBau1@baylor.edu,"Abstract
We examine the robustness of the relationship between income attainment and 
personality traits
 from Tellegen’s three-factor model that map into constructs of positive 
emotionality
 (well-being, social potency, achievement, and social closeness), negative 
emotionality
 (stress reaction, alienation, and aggression), and constraint (control, harm avoidance, and traditionalism). We do so by estimating the sampling distribution of 32,768 models in a sample of self-employed people from the Midlife in the United States (MIDUS) study to account for model uncertainty. We find that only social potency and aggression are robust and positively correlated with income attainment among the self-employed. In contrast, income attainment for organizational employees is positively influenced by social potency and achievement and negatively influenced by traits such as alienation, impulsivity, traditionalism, and control. We find similar results when we examine a sub-group of self-employed people who employ and supervise others. Implications for future research are discussed.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,5.0,The study on income attainment and personality traits among self-employed individuals provides some insights but may have limited practical application for startups.
https://www.sciencedirect.com/science/article/pii/S2352673418301197,Predicting new venture survival: A Twitter-based machine learning approach to measuring online legitimacy,Joakim=Wincent: joakim.wincent@hanken.fi; Torben=Antretter: torben.antretter@unisg.ch; Dietmar=Grichnik: dietmar.grichnik@unisg.ch; Ivo=Blohm: ivo.blohm@unisg.ch,"Abstract
Research indicates that interactions on social media can reveal remarkably valid predictions about future events. In this study, we show that online legitimacy as a measure of social appreciation based on Twitter content can be used to accurately predict new venture survival. Specifically, we analyze more than 187,000 tweets from 253 new ventures’ Twitter accounts using context-specific machine learning approaches. Our findings suggest that we can correctly discriminate failed ventures from surviving ventures in up to 76% of cases. With this study, we contribute to the ongoing discussion on the importance of building legitimacy online and provide an account of how to use machine learning methodologies in entrepreneurship research.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,8.0,The use of social media interactions to predict new venture survival has high practical value and can be beneficial for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673418301264,Is firm growth random? A machine learning perspective,Arjen=van Witteloostuijn: a.van.witteloostuijn@vu.nl,"Abstract
This study contributes to the firm growth debate by applying machine learning. We compare a prominent machine learning technique – random forest analysis (RFA) – to traditional regression in terms of their goodness-of-fit on a dataset of 168,055 firms from Belgium and the Netherlands. For each of these firms, we have one to six years of historical data involving demographic and financial information. The data show high variation in firm growth rates, which is difficult to capture with traditional linear regression (
R
2
 in the range of 0.05–0.06). The RFA fares three to four times better, achieving a much higher goodness-of-fit (
R
2
 of 0.16–0.23). RFA indicates that perhaps firm growth is less random than suggested by traditional regression analysis. Generally, given the modest selection of variables in our dataset, this demonstrates that machine learning can be of value to firm growth research.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,9.0,The application of machine learning techniques to firm growth research and the comparison with traditional regression methods show significant impact and practical value for startups.
https://www.sciencedirect.com/science/article/pii/S2352673418301203,Entrepreneurial impulsivity is not rational judgment,Johan=Wiklund: jwiklund@syr.edu,"Abstract
A recent JBVi article suggests that impulsive behaviors ought to be understood as rational human action. My comment suggests that such a view is at odds with how impulsivity is commonly understood within other fields of research, within current psychology theorizing and among laymen. It is also at odds with theorizing and empirical findings regarding impulsivity in entrepreneurship.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,"The disagreement on impulsivity as rational action may not directly impact early-stage ventures, limiting the practical relevance for startups."
https://www.sciencedirect.com/science/article/pii/S2352673418300775,Accentuating lead user entrepreneur characteristics in crowdfunding campaigns – The role of personal affection and the capitalization of positive events,Christian=Hopp: hopp@time.rwth-aachen.de; Jermain=Kaminski: kaminski@time.rwth-aachen.de; Frank=Piller: piller@time.rwth-aachen.de,"Abstract
This paper investigates how potential backers' perception of user entrepreneur characteristics influences the success of a crowdfunding campaign. We hypothesize that the accentuation of user entrepreneur characteristics is associated with higher crowdfunding success, i.e. with the chance to reach a campaign goal successfully. Data from 963 Kickstarter campaigns provides an ambiguous picture: while trend leadership shows the hypothesized effect, a high benefit expected accentuated in a product campaign is actually detrimental for its performance. Extending the reasoning of affection based models to predict crowdfunding success, we draw on capitalization theory for an explanation. While a high benefit expected may prompt personal positive emotional responses, it may fail to trigger consumer's word of mouth reactions, the sharing of positive events with significant others. Our data reveals that the perception of user entrepreneurship characteristics leads to significantly lower rates of sharing a campaign on Facebook and to fewer user comments on Kickstarter. By highlighting the differential effects that user entrepreneur characteristics exhibit on crowdfunding campaign success, our results have important implications for crowdfunding theory and practice.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The study on how user entrepreneur characteristics influence crowdfunding success provides valuable insights for startups engaging in crowdfunding campaigns.
https://www.sciencedirect.com/science/article/pii/S2352673418300672,Antisocial entrepreneurship: Conceptual foundations and a research agenda,Erik=Lundmark: erik.lundmark@mq.edu.au; Alf=Westelius: alf.westelius@liu.se,"Abstract
Whereas social entrepreneurship has been extensively studied, its antipode—antisocial entrepreneurship—is all but neglected in the literature. This article identifies and elucidates this glaring conceptual and research gap; it provides a conceptual foundation for making sense of antisocial entrepreneurship, demonstrating how it is distinct from related constructs such as illegal and destructive entrepreneurship; and it suggests an agenda for future research on antisocial entrepreneurship. Through studying antisocial entrepreneurship, a broader spectrum of entrepreneurial intentions, actions and outcomes becomes visible, potentially furthering our understanding, not only of antisocial entrepreneurship, but also of other, more commonly studied, facets of entrepreneurship.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,3.0,The concept of antisocial entrepreneurship is interesting but may have limited practical value for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673418300611,Researching Pure Digital Entrepreneurship – A Multimethod Insider Action Research approach,Kisito Futonge=Nzembayie: futonge.kisito@mydit.ie,"Abstract
Knowledge production in Pure Digital Entrepreneurship (PDE) needs to reflect the non-linear nature of a journey defined by digital artifact and platform creation. Accordingly, this paper proposes and offers practical guidance on the use of 
Multimethod Insider 
Action Research
 (MIAR) as a suitable research design for studying the entrepreneurial journey in this context. It argues for integrating first-person 
Reflective Practice
, second-person 
Collaborative Inquiry
 and 
Design Research
 for third-person knowledge production that balances rigour and relevance. While calls for such forms of longitudinal process inquiry have largely gone unanswered due to identified challenges, this paper uses a case 
narrative
 to illustrate the feasibility of conducting them in a PDE context.",June 2019,Not Found,Business Venturing Insights,2025-03-08T00:00:00,7.0,The practical guidance on using MIAR for studying Pure Digital Entrepreneurship has high potential impact for early-stage ventures in Europe.
https://www.sciencedirect.com/science/article/pii/S0950584924002337,Markov model based coverage testing of deep learning software systems,Ying=Shi: shiying2017@buaa.edu.cn; Beibei=Yin: yinbeibei@buaa.edu.cn; Jing-Ao=Shi: Shi_jingao@buaa.edu.cn,"Abstract
Context:
Deep Learning (DL) software systems have been widely deployed in safety and security-critical domains, which calls for systematic testing to guarantee their accuracy and reliability. Objective measurement of test quality is one of the key issues in software testing. Recently, many coverage criteria have been proposed to measure the testing adequacy of Deep Neural Networks (DNNs).
Objective:
Recent research demonstrates that existing criteria have some limitations on interpreting the increasingly diverse behaviors of DNNs or clarifying the relationship between the coverage and the decision logic of DNNs. Moreover, some evaluations argue against the correlation between coverage and defect detection. In this paper, a novel coverage approach is proposed to interpret the internal information of programs.
Methods:
The process of coverage testing is formalized and quantified by constructing Markov models based on critical neurons extracted using Layer-wise Relevance Propagation in the structure of DNNs. The difference in the transition matrix of Markov chains between training and testing data is measured by KL divergence, and it is developed as a coverage criterion.
Results:
The values of the proposed coverage increase as the number of classes increases. The values are different for various test suites, and they become higher with the addition of new samples. Higher coverage values are observed to correlate with an increased fault detection capability.
Conclusion:
The experimental results illustrate that the proposed approach can effectively measure actual diversity and exhibit more adaptability to additional test cases. Furthermore, there is a positive correlation between the proposed coverage and fault detection, which provides support for test case selection guided by coverage.",March 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed novel coverage approach for Deep Neural Networks shows positive correlation with fault detection, which can be beneficial for startups in developing reliable AI-based systems."
https://www.sciencedirect.com/science/article/pii/S0950584924002283,An alternative to code comment generation? Generating comment from bytecode,Yuan=Huang: huangyuan5@mail.sysu.edu.cn,"Abstract
Context:
Due to the importance and necessity of code comments, recent works propose many comment generation models with source code as input. But sometimes there has no access to obtain the source code, only the bytecode, such as many Apps.
Objective:
If there is a way to generate comments for bytecode directly, tasks such as malware detection and understanding closed-source software can benefit from the generated comment because it improves the understandability of the system. Therefore, we propose a novel approach called ByteGen to generate comments from bytecode.
Methods:
Specifically, to extract the structure characteristic of the bytecode, we utilize the control flow graph (CFG) of the bytecode and use a special traversal named enhanced SBT to serialize CFG. The enhanced SBT can completely preserve the structure of the CFG in a sequence. We set up experiments on a dataset with a scale of about 50,000 bytecode-comment pairs collected from Maven.
Results:
Experimental results show that the average BLEU-4 score of ByteGen is 28.67, which outperforms several baselines, and a human study also indicates the effectiveness of ByteGen in generating comments from bytecodes.
Conclusion:
In general, ByteGen performs better than other baselines. Therefore, this also proves the effectiveness of our approach in the code comment generation scenario without source code.",March 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The ByteGen approach for generating comments from bytecode could be useful for tasks like malware detection, but the practical application in startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924002349,Redefining crowdsourced test report prioritization: An innovative approach with large language model,Yuchen=Ling: yuchenling@smail.nju.edu.cn; Shengcheng=Yu: yusc@smail.nju.edu.cn; Chunrong=Fang: fangchunrong@nju.edu.cn; Guobin=Pan: panguobin@cmss.chinamobile.com; Jun=Wang: wangjun@cmss.chinamobile.com; Jia=Liu: liujia@nju.edu.cn,"Abstract
Context:
Crowdsourced testing has gained popularity in software testing, especially for mobile app testing, due to its ability to bring diversity and tackle fragmentation issues. However, the openness of crowdsourced testing presents challenges, particularly in the manual review of numerous test reports, which is time-consuming and labor-intensive.
Objective:
The primary goal of this research is to improve the efficiency of review processes in crowdsourced testing. Traditional approaches to test report prioritization lack a deep understanding of semantic information in textual descriptions of these reports. This paper introduces LLMPrior, a novel approach for prioritizing crowdsourced test reports using large language models (LLMs).
Method:
LLMPrior leverages LLMs for the analysis and clustering of crowdsourced test reports based on the types of bugs revealed in their textual descriptions. This involves using prompt engineering techniques to enhance the performance of LLMs. Following the clustering, a recurrent selection algorithm is applied to prioritize the reports.
Results:
Empirical experiments are conducted to evaluate the effectiveness of LLMPrior. The findings indicate that LLMPrior not only surpasses current state-of-the-art approaches in terms of performance but also proves to be more feasible, efficient, and reliable. This success is attributed to the use of prompt engineering techniques and the cluster-based prioritization strategy.
Conclusion:
LLMPrior represents a significant advancement in crowdsourced test report prioritization. By effectively utilizing large language models and a cluster-based strategy, it addresses the challenges in traditional prioritization approaches, offering a more efficient and reliable solution for app developers dealing with crowdsourced test reports.",March 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The LLMPrior approach for prioritizing crowdsourced test reports using large language models presents a significant advancement in software testing efficiency, which can benefit startups dealing with testing challenges."
https://www.sciencedirect.com/science/article/pii/S0950584924002313,Native cross-platform app development using the SequalsK transpiler,Dominik=Schultes: dominik.schultes@iem.thm.de; Larissa=Schneider: lar.m.sch@gmail.com; Tobias=Heymann: tobiasheymann@outlook.com; Franziska=Wild: wild.franziska@googlemail.com,"Abstract
Context:
Developing two separate versions of an app for iOS and Android requires significant effort. Existing cross-platform development frameworks may reduce this effort, but they also come with tradeoffs such as high tool dependency.
Objective:
To avoid the drawbacks of current methods, we introduce a new approach to cross-platform app development, provide the necessary tools, and conduct a thorough evaluation to demonstrate the feasibility of our proposed approach.
Method:
The central idea of the new 
native cross-platform development
 approach is to actively develop apps in both native programming languages, Kotlin for Android and Swift for iOS, while exchanging considerable parts of the source code in a bidirectional fashion using a deterministic transpiler. As the centerpiece of our proposed development approach, we present such a 
bidirectional
 Swift-Kotlin transpiler, called 
SequalsK
. It supports the majority of the important constructs of both languages and is able to generate syntactically and semantically correct Kotlin code out of Swift code 
and vice versa
.
Results:
In our evaluation, we determined that SequalsK is the sole existing bidirectional transpiler, distinguishing it from other transpilers that support only one direction. For the Kotlin-to-Swift direction, SequalsK emerges as the premier transpiler, while for the reverse direction, it stands among the top transpilers. Through six distinct case studies, we applied our native cross-platform development approach, showcasing its ability to fulfill all goals. Across each study, we successfully generated fully-functional native Android and iOS apps, achieving significant time savings as up to 86 percent of the source code has to be programmed only once and can be transpiled to the other involved programming language automatically.
Conclusion:
At the moment, in particular data structures and business logic can be transpiled successfully. In the future, we expect further improvements by extending the SequalsK transpiler in order to process user-interface parts as well.",March 2025,"Mobile app, Transpilers, Swift, Kotlin, Cross-platform, Mining software repositories",Information and Software Technology,2025-03-18T00:00:00,6.0,"The bidirectional transpiler SequalsK for cross-platform app development shows promise in reducing development effort, but the practical implications and impact on startups might not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924002325,Improving operational decision-making through decision mining - utilizing method engineering for the creation of a decision mining method,Sam=Leewis: sam.leewis@hu.nl,"Abstract
Context
This study addresses the challenge of enhancing the efficiency and agility of decision support software supporting both operational decision-making and software production teams developing decision support software. It centers on creating a method that assists in mining decisions, checking decisions on conformance, and improving decisions, which supports software production teams in developing decision support software.
Objective
The primary objective is to develop an explicit, clear, and structured approach for discovering, checking, and improving decisions using decision support software. The study aims to create a blueprint for software production teams to develop Decision Mining (DM) software, in line with recent advancements in the field. Additionally, it seeks to provide a consolidated, methodical overview of activities and deliverables in the DM research field.
Method
The research employs method engineering principles to construct a method for DM that leverages the existing body of knowledge by utilizing a Systematic Literature Review (SLR). The study focuses on developing individual building blocks and method fragments incorporated into seven DM scenarios.
Results
The study led to the creation of a Decision Mining Method (DMM), which includes 138 method fragments grouped into eleven categories. These fragments were systematically merged to form a comprehensive DMM. The method encapsulates the complexity of DM and provides practical applicability in real-world scenarios, highlighted by the identification of seven distinct scenarios in DM phases. The study also conducted the first SLR in the DM field, providing a comprehensive overview of current practices and outcomes.
Conclusion
The study helps in advancing the DM field by creating a structured approach and a comprehensive method for DM, aligning with recent developments in the field. It successfully aggregated the fragmented DM domain into a cohesive methodological overview, crucial for future research. The study also lays out a detailed agenda for future research, focusing on expanding and validating the DMM, incorporating cross-disciplinary insights, and addressing the challenges in machine learning within DM. The future research directions aim to refine and broaden the applicability of the DMM, ensuring its effectiveness in diverse practical contexts and contributing to a more holistic and comprehensive approach to decision mining.",March 2025,"Decision making, Decision mining, Method engineering, Decision mining method, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,8.0,"The study addresses the challenge of decision support software development, providing a structured approach and method for Decision Mining. It has practical applicability in real-world scenarios and contributes to advancing the field. The comprehensive overview and future research agenda add value to early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924002167,On the road to interactive LLM-based systematic mapping studies,Kai=Petersen: kai.petersen@hs-flensburg.de; Jan M.=Gerken: jan.gerken@hs-flensburg.de,"Abstract
Context:
The research volume is continuously increasing. Manual analysis of large topic scopes and continuously updating literature studies with the newest research results is effort intensive and, therefore, difficult to achieve.
Objective:
To discuss possibilities and next steps for using LLMs (e.g., GPT-4) in the mapping study process.
Method:
The research can be classified as a solution proposal. The solution was iteratively designed and discussed among the authors based on their experience with LLMs and literature reviews.
Results:
We propose strategies for the mapping process, outlining the use of agents and prompting strategies for each step.
Conclusion:
Given the potential of LLMs in literature studies, we should work on a holistic solutions for LLM-supported mapping studies.",February 2025,"Systematic mapping studies, Large language models, GPT",Information and Software Technology,2025-03-18T00:00:00,5.0,"While discussing the use of LLMs in mapping studies is relevant, the abstract lacks a clear indication of practical implementation and impact on early-stage ventures. More concrete strategies and outcomes would increase the score."
https://www.sciencedirect.com/science/article/pii/S0950584924002039,Systematic review on the current state of computer-supported argumentation learning systems,Laura=Sinikallio: laura.sinikallio@helsinki.fi; Lili=Aunimo: Lili.Aunimo@haaga-helia.fi; Tomi=Männistö: tomi.mannisto@helsinki.fi,"Abstract
Context:
Argumentation is a fundamental part of learning, communication and problem-solving not only in software engineering but all education. Teaching argumentation is a long-standing practice, and with the advance of digital learning, it, too, has been transitioning to an online format.
Objective:
As computer-supported argumentation learning progresses, other learning domains have much to learn from it on how to enable argumentation and reasoning in automated and scalable online learning solutions.
Methods:
To review the current state of the field, we conducted a systematic literature review on the last decade of academic research and design on computer-supported argumentation learning systems. We reviewed and summarised the central aspects and approaches of reported systems.
Results:
We reviewed 34 different argumentation learning tools. The review showed that approaches to computer-supported argumentation vary significantly in many aspects, e.g., argumentation theory, learning task types and collaboration status. However, the use of argumentation graphs is quite common. Most modern tools seem to embrace the role of feedback in learning.
Conclusions:
The role of individual learning has risen in computer-supported argumentation learning. This is in opposition to previous predictions and statements on the role of collaborative learning of argumentation. Automated feedback has, on the other hand, become commonplace in collaborative and individual-use argumentation learning tools. The modern generation of argumentation teaching tools is Web-based but recently we have also seen the emergence of mobile-based solutions.",February 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract discusses the role of argumentation in education and learning, highlighting the transition to online formats. The systematic review of argumentation learning systems provides valuable insights. The emphasis on individual learning and feedback aligns with the current trends in education technology."
https://www.sciencedirect.com/science/article/pii/S0950584924002271,Systematic mapping study on requirements engineering for regulatory compliance of software systems,Oleksandr=Kosenkov: oleksandr.kosenkov@bth.se,"Abstract
Context:
As the diversity and complexity of regulations affecting Software-Intensive Products and Services (SIPS) is increasing, software engineers need to address the growing regulatory scrutiny. We argue that, as with any other non-negotiable requirements, SIPS compliance should be addressed early in SIPS engineering—i.e., during requirements engineering (RE).
Objectives:
In the conditions of the expanding regulatory landscape, existing research offers scattered insights into regulatory compliance of SIPS. This study addresses the pressing need for a structured overview of the state of the art in software RE and its contribution to regulatory compliance of SIPS.
Method:
We conducted a systematic mapping study to provide an overview of the current state of research regarding challenges, principles, and practices for regulatory compliance of SIPS related to RE. We focused on the role of RE and its contribution to other SIPS lifecycle process areas. We retrieved 6914 studies published from 2017 (January 1) until 2023 (December 31) from four academic databases, which we filtered down to 280 relevant primary studies.
Results:
We identified and categorized the RE-related challenges in regulatory compliance of SIPS and their potential connection to six types of principles and practices addressing challenges. We found that about 13.6% of the primary studies considered the involvement of both software engineers and legal experts in developing principles and practices. About 20.7% of primary studies considered RE in connection to other process areas. Most primary studies focused on a few popular regulation fields (privacy, quality) and application domains (healthcare, software development, avionics). Our results suggest that there can be differences in terms of challenges and involvement of stakeholders across different fields of regulation.
Conclusion:
Our findings highlight the need for an in-depth investigation of stakeholders’ roles, relationships between process areas, and specific challenges for distinct regulatory fields to guide research and practice.",February 2025,"Requirements engineering, Software engineering, Secondary research, Regulatory requirements engineering, Regulatory compliance, Compliance requirements, Software compliance",Information and Software Technology,2025-03-18T00:00:00,6.0,"The study addresses a pressing need for a structured overview of the state of the art in software RE and its contribution to regulatory compliance of SIPS, which can be valuable for startups in tackling regulatory challenges."
https://www.sciencedirect.com/science/article/pii/S0950584924002003,A family of experiments to quantify the benefits of adopting WebDriverManager and Selenium-Jupiter,Maurizio=Leotta: maurizio.leotta@unige.it,"Abstract
Context:
While test automation offers numerous benefits, it also introduces significant challenges. Two challenges that developers and testers face on a daily basis, particularly when using Selenium WebDriver to test web applications, are driver management (involving tasks such as version identification, download, installation, and maintenance) and management of test lifecycle phases (using specific test libraries, as for example JUnit, and inserting annotations into the code). These manual tasks make test suite development particularly tedious, error-prone, and expensive. Recently, to ease the burden on developers and testers, some Java libraries have been proposed, called 
WebDriverManager
 and 
Selenium-Jupiter
, capable of automatically carrying out the driver management process for Selenium WebDriver and simplifying the development of test suites. These libraries appear to be very promising but until now no one has experimentally evaluated their effectiveness.
Objective:
To investigate the effectiveness of 
WebDriverManager
 and 
Selenium-Jupiter
 in reducing driver management times and boilerplate code.
Method:
We designed and conducted a family of experiments (three for 
WebDriverManager
 and two for 
Selenium-Jupiter
) with 104 master student participants from the University of Genoa, Italy (across academic years 2021/2022 and 2022/2023) and nine professional participants.
Results:
Results indicate that the adoption of Selenium WebDriver with 
WebDriverManager
 significantly reduces setup time for multi-browser test suites from 33% to 50% (depending on the tester experience). Additionally, 
Selenium-Jupiter
 reduces test suite development time significantly (20% on average). Although it also decreases total code length, the reduction is relatively small compared to overall code length.
Conclusion:
WebDriverManager
 and 
Selenium-Jupiter
 can be seen as valuable solutions for enhancing testers’ productivity by shortening the time needed to develop test suites and minimizing the amount of code to write.",February 2025,"E2E testing, Selenium WebDriver, WebDriverManager, Selenium-Jupiter, Family of experiments",Information and Software Technology,2025-03-18T00:00:00,8.0,"The study evaluates the effectiveness of WebDriverManager and Selenium-Jupiter in reducing setup time for test suites, which can significantly benefit early-stage ventures by enhancing testers' productivity."
https://www.sciencedirect.com/science/article/pii/S0950584924001976,Detecting and Explaining Python Name Errors,Jiawei=Wang: jiawei.wang1@monash.edu,"Abstract
Python has become one of the most popular programming languages nowadays but has not received enough attention from the software engineering community. Many errors, either fixed or not yet, have been scattered in the lifetime of Python projects, including popular Python libraries that have already been reused. NameError is among one of those errors that are widespread in the Python community, as confirmed in our empirical study. Yet, our community has not put effort into helping developers mitigate its introductions. To fill this gap, we propose in this work a static analysis-based approach called 
DENE
 (short for 
D
etecting and 
E
xplaining 
N
ame 
E
rrors) to automatically detect and explain name errors in Python projects. To this end, 
DENE
 builds control-flow graphs for Python projects and leverages a scope-aware reaching definition analysis to locate identifiers that may cause name errors at runtime and report their locations. Experimental results on carefully crafted ground truth demonstrate that 
DENE
 is effective in detecting name errors in real-world Python projects. The results also confirm that unknown name errors are still widely presented in popular Python projects and libraries, and the outputs of 
DENE
 can indeed help developers understand why the name errors are flagged as such.",February 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,The proposed approach to detect and explain name errors in Python projects may not provide immediate practical value for early-stage ventures or startups.
https://www.sciencedirect.com/science/article/pii/S0950584924002052,Enabling efficient and low-effort decentralized federated learning with the EdgeFL framework,Hongyi=Zhang: hongyiz@chalmers.se,"Abstract
Context:
Federated Learning (FL) has gained prominence as a solution for preserving data privacy in machine learning applications. However, existing FL frameworks pose challenges for software engineers due to implementation complexity, limited customization options, and scalability issues. These limitations prevent the practical deployment of FL, especially in dynamic and resource-constrained edge environments, preventing its widespread adoption.
Objective:
To address these challenges, we propose EdgeFL, an efficient and low-effort FL framework designed to overcome centralized aggregation, implementation complexity and scalability limitations. EdgeFL applies a decentralized architecture that eliminates reliance on a central server by enabling direct model training and aggregation among edge nodes, which enhances fault tolerance and adaptability to diverse edge environments.
Methods:
We conducted experiments and a case study to demonstrate the effectiveness of EdgeFL. Our approach focuses on reducing weight update latency and facilitating faster model evolution on edge devices.
Results:
Our findings indicate that EdgeFL outperforms existing FL frameworks in terms of learning efficiency and performance. By enabling quicker model evolution on edge devices, EdgeFL enhances overall efficiency and responsiveness to changing data patterns.
Conclusion:
EdgeFL offers a solution for software engineers and companies seeking the benefits of FL, while effectively overcoming the challenges and privacy concerns associated with traditional FL frameworks. Its decentralized approach, simplified implementation, combined with enhanced customization and fault tolerance, make it suitable for diverse applications and industries.",February 2025,"Federated learning, Machine learning, Software engineering, Decentralized architecture, Information privacy",Information and Software Technology,2025-03-18T00:00:00,9.0,"The EdgeFL framework offers a solution for software engineers and companies seeking the benefits of FL, while effectively overcoming challenges, which can have a significant impact on European early-stage ventures looking to deploy FL in dynamic and resource-constrained edge environments."
https://www.sciencedirect.com/science/article/pii/S095058492400209X,A survey on Cryptoagility and Agile Practices in the light of quantum resistance,Lodovica=Marchesi: lodovica.marchesi@unica.it,"Abstract
Context:
Crypto-agility, a name that stems from agile methodologies for software development, means the ability to modify quickly and securely cryptographic algorithms in the event of a compromise. The advent of quantum computing poses existential threats to current cryptography, having the power to breach current cryptography systems.
Objective:
We investigated whether and to what extent agile practices for software development are suited to support crypto-agility, or not. In particular, we discuss their usefulness in the context of substituting current algorithms with quantum-resistant ones.
Method:
First, we analyzed the literature to define a subset of 15 agile practices potentially relevant to cryptographic software development. Then, we developed a questionnaire to assess the suitability of agile practices for obtaining crypto-agility. We performed a Web search of relevant documents about crypto-agility and quantum resistance and sent their authors the questionnaire. We also sent the questionnaire to cybersecurity officers of four Italian firms. We analyzed and discussed the responses to 32 valid questionnaires.
Results:
The respondents’ affiliations are evenly distributed between researchers and developers. Most of them are active, or somehow active, in quantum-resistant cryptography and use agile methods. Most of the agile practices are deemed to be quite useful, or very useful to get crypto-agility, the most effective being Continuous Integration and Coding Standards; the least appreciated is Self-organizing Team.
Conclusion:
According to researchers and developers working in the field, the safe transition of cryptographic algorithms to quantum-resistant ones can benefit from the adoption of many agile practices. Further software engineering research is needed to integrate agile practices in more formal cryptographic software development processes.",February 2025,"Agile methods, Cryptographic agility, Cryptographic algorithms, Quantum resistance",Information and Software Technology,2025-03-18T00:00:00,8.0,The study addresses a critical issue of transitioning cryptographic algorithms amidst quantum computing threats and provides practical insights for agile practices adoption in the field.
https://www.sciencedirect.com/science/article/pii/S0950584924002076,E-code: Mastering efficient code generation through pretrained models and expert encoder group,Yue=Pan: pany@mail.sdu.edu.cn; Chen=Lyu: lvchen@sdnu.edu.cn; Zhenyu=Yang: yangzycs@mail.sdu.edu.cn; Lantian=Li: lilantian@mail.sdu.edu.cn; Qi=Liu: 1642339035@qq.com; Xiuting=Shao: shaoxiuting@126.com,"Abstract
Context:
With the waning of Moore’s Law, the software industry is placing increasing importance on finding alternative solutions for continuous performance enhancement. The significance and research results of software performance optimization have been on the rise in recent years, especially with the advancement propelled by 
L
arge 
L
anguage 
M
odel
s
 (LLMs). However, traditional strategies for rectifying performance flaws have shown significant limitations at the competitive code efficiency optimization level, and research on this topic is surprisingly scarce.
Objective:
This study aims to address the research gap in this domain, offering practical solutions to the various challenges encountered. Specifically, we have overcome the constraints of traditional performance error rectification strategies and developed a 
L
anguage 
M
odel (LM) tailored for the competitive code efficiency optimization realm.
Methods:
We introduced E-code, an advanced program synthesis LM. Inspired by the recent success of expert LMs, we designed an innovative structure called the Expert Encoder Group. This structure employs multiple expert encoders to extract features tailored for different input types. We assessed the performance of E-code against other leading models on a competitive dataset and conducted in-depth ablation experiments.
Results:
Upon systematic evaluation, E-code achieved a 54.98% improvement in code efficiency, significantly outperforming other advanced models. In the ablation experiments, we further validated the significance of the expert encoder group and other components within E-code.
Conclusion:
The research findings indicate that the expert encoder group can effectively handle various inputs in efficiency optimization tasks, significantly enhancing the model’s performance. In summary, this study paves new avenues for developing systems and methods to assist programmers in writing efficient code.",February 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The research introduces a novel language model for code efficiency optimization, offering practical solutions and paving new avenues for programmers to enhance code efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584924002088,Dynamic robustness evaluation for automated model selection in operation,Jin=Zhang: zhang.jin@swjtu.edu.cn; Jingyue=Li: jingyue.li@ntnu.no; Zhirong=Yang: zhirong.yang@ntnu.no,"Abstract
Context:
The increasing use of artificial neural network (ANN) classifiers in systems, especially safety-critical systems (SCSs), requires ensuring their robustness against out-of-distribution (OOD) shifts in operation, which are changes in the underlying data distribution from the data training the classifier. However, measuring the robustness of classifiers in operation with only unlabeled data is challenging. Additionally, machine learning engineers may need to compare different models or versions of the same model and switch to an optimal version based on their robustness.
Objective:
This paper explores the problem of dynamic robustness evaluation for automated model selection. We aim to find efficient and effective metrics for evaluating and comparing the robustness of multiple ANN classifiers using unlabeled operational data.
Methods:
To quantitatively measure the differences between the model outputs and assess robustness under OOD shifts using unlabeled data, we choose distance-based metrics. An empirical comparison of five such metrics, suitable for higher-dimensional data like images, is performed. The selected metrics include Wasserstein distance (WD), maximum mean discrepancy (MMD), Hellinger distance (HL), Kolmogorov–Smirnov statistic (KS), and Kullback–Leibler divergence (KL), known for their efficacy in quantifying distribution differences. We evaluate these metrics on 20 state-of-the-art models (ten CIFAR10-based models, five CIFAR100-based models, and five ImageNet-based models) from a widely used robustness benchmark (
RobustBench
) using data perturbed with various types and magnitudes of corruptions to mimic real-world OOD shifts.
Results:
Our findings reveal that the WD metric outperforms others when ranking multiple ANN models for CIFAR10- and CIFAR100-based models, while the KS metric demonstrates superior performance for ImageNet-based models. MMD can be used as a reliable second option for both datasets.
Conclusion:
This study highlights the effectiveness of distance-based metrics in ranking models’ robustness for automated model selection. It also emphasizes the significance of advancing research in dynamic robustness evaluation.",February 2025,"Artificial neural network classifier, Automated model selection, Robustness, Dynamic evaluation, Distance-based metrics",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study explores dynamic robustness evaluation for automated model selection, offering efficient metrics for comparing ANN classifiers' robustness, contributing to advancements in the field."
https://www.sciencedirect.com/science/article/pii/S0950584924002118,Software aging oriented trustworthiness measurement based on weighted Boltzmann entropy,Hongwei=Tao: hongweitao@zzuli.edu.cn; Han=Liu: hanliu@stu.ecnu.edu.cn; Xiaoxu=Niu: xiaoxuniu2022@163.com; Licheng=Ding: 51184501105@stu.ecnu.edu.cn; Yixiang=Chen: yxchen@sei.ecnu.edu.cn; Qiaoling=Cao: 17839640477@163.com,"Abstract
Context:
With the rapid development of software, various software accidents emerge one after another. The catastrophic consequences caused by these accidents make people realize the importance of software trustworthiness. As an indispensable means to ensure software quality, traditional trustworthiness measurement evaluates the software trustworthiness by studying the trustworthy attributes in a static way. However, most of the factors considered in trustworthy attributes tend to be dynamic with time. The current research often ignores the changes in software after running for some time, and cannot reflect the changes in software trustworthiness at different running times.
Objective:
Our objective in this paper is to study the relationship between running time and software trustworthiness, and design a running time-related software trustworthiness measurement model from the untrustworthy evidence related to software aging.
Method:
We first extract the untrustworthy evidence from the bugs related to software aging in 5 subsystems of 4 public defect databases and 18 well-known software accidents, establish a risk level model, and design metric elements of untrustworthy evidence based on software aging. Then we construct a software aging cause category trustworthiness measurement model based on Boltzmann entropy. Finally, we build a software trustworthiness measurement model based on weighted Boltzmann entropy. For the weight values used in the model, the Brassard Priority Synthesis Analysis method was used to determine them.
Result:
Different from the common resource consumption parameter and performance parameter, a model based on weighted Boltzmann entropy can describe the influence of various parameters on the software’s trustworthiness through risk state. It can reflect the change of system state and describe the system state completely.
Conclusion:
The empirical study shows the effectiveness and practicality of our method for evaluating software dynamic trustworthiness. Meanwhile, it also indicates a promising avenue for future research and application in the field of software trustworthiness measurement.",February 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The paper investigates software trustworthiness over running time, proposing a novel measurement model but lacks practical implementation insights for early-stage European ventures."
https://www.sciencedirect.com/science/article/pii/S095058492400212X,"Energize sustainability: EnSAF for sustainability aware, software intensive energy management systems",Anjana=M.S.: anjanams@am.amrita.edu; Patricia=Lago: p.lago@vu.nl; Aryadevi Remanidevi=Devidas: aryadevird@am.amrita.edu; Maneesha Vinodini=Ramesh: maneesha@amrita.edu,"Abstract
Context:
India’s coal use for electricity jumped 13% in 2021–22. Energy management systems (EnMS) are seen as a solution, but only sustainable EnMS can have a discernable impact on the carbon footprint and the Return On Investment (ROI).
Objective:
Designing a software-intensive sustainable energy management system requires considering technical, environmental, social, and economic factors. This helps evaluate an EnMS’s overall impact and improve its design. We proposed EnSAF for efficient utilization of the energy incurred for the design of sustainability-aware EnMSs.
Method:
In this work, EnMSs in diverse use cases were selected and analyzed in terms of technical, social, environmental, and economic dimensions of sustainability in collaboration with various stakeholders. The set of application-specific design concerns and Quality Attributes (QAs) were addressed by the Sustainability Assessment Framework (SAF) toolkit. The resultant SAF instances of each EnMS, derived through the analysis and discussion with the stakeholders, were then analyzed to advocate the DMs and SQ model for generic EnMSs.
Results:
This study demonstrated the following outcomes (i) technical concerns dominate the existing EnMSs (ii) integration of renewable energy resources reduces dependency to the main power grid and nurtures a sustainable environment by diminishing carbon footprint, and minimizing payback time, in the economic dimension; (iii) extant definitions of quality attributes need significant scrutiny and updates apropos of objectives of EnMSs
Conclusion:
The SAF toolkit was found to be deficient in the representation of relevant design concerns and quality attributes concomitant with sustainable EnMS. Prevailing DMs are inept to factor in stakeholder’s concerns, as the model is ill-equipped to account for spatio-temporal representation of QAs. Pursuant to the insights from the 4 SAF instances, a generic framework, EnSAF, is proposed to tackle the relevant concerns apropos of EnMS sustainability. This work proposed a representation of DMs in the SAF toolkit specifically for sustainability-aware EnMS.",February 2025,"Decision map, Energy management system, Quality attribute, Software impact, Software-intensive system, Sustainability framework",Information and Software Technology,2025-03-18T00:00:00,7.0,"The research focuses on designing sustainable energy management systems, considering technical, environmental, social, and economic factors. It offers a framework for efficient energy utilization but lacks specific impact insights for startups."
https://www.sciencedirect.com/science/article/pii/S0950584924002064,Top-down: A better strategy for incremental covering array generation,Xintao=Niu: niuxintao@nju.edu.cn,"Abstract
Context:
The Incremental Covering Array (ICA) offers a flexible and efficient test schedule for Combinatorial Testing (CT) by enabling dynamic adjustment of test strength. Despite its importance, ICA generation has been under-explored in the CT community, resulting in limited and suboptimal existing approaches.
Objective:
To address this gap, we introduce a novel strategy, namely 
Top-down
, for optimizing ICA generation.
Method:
In contrast to the traditional strategy, named 
Bottom-up
, 
Top-down
 starts with a higher-strength test set and then extracts lower-strength sets from it, thus leveraging test case generation algorithms more effectively.
Results:
We conducted a comparative evaluation of the two strategies across 17 real-world software with 84 total versions. The results demonstrate that compared with 
Bottom-up
, the 
Top-down
 strategy requires less time and generates smaller ICAs while covering more higher-strength interactions. Furthermore, 
Top-down
 outperforms 
Bottom-up
 in early fault detection and code line coverage, while also surpassing the random and direct CA generation strategies.
Conclusion:
The 
Top-down
 strategy not only improved the efficiency of test case generation but also enhanced the effectiveness of fault detection in the incremental testing scenarios.",February 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The research introduces a novel strategy for optimizing ICA generation in Combinatorial Testing, which can significantly improve efficiency and fault detection in testing scenarios."
https://www.sciencedirect.com/science/article/pii/S0950584924002155,"Using AI-based coding assistants in practice: State of affairs, perceptions, and ways forward",Agnia=Sergeyuk: agnia.sergeyuk@jetbrains.com; Yaroslav=Golubev: yaroslav.golubev@jetbrains.com; Timofey=Bryksin: timofey.bryksin@jetbrains.com; Iftekhar=Ahmed: iftekha@uci.edu,"Abstract
Context:
The last several years saw the emergence of 
AI assistants
 for code — multi-purpose AI-based helpers in software engineering. As they become omnipresent in all aspects of software development, it becomes critical to understand their usage patterns.
Objective:
We aim to better understand 
how specifically
 developers are using AI assistants, why they are 
not
 using them in certain parts of their development workflow, and what needs to be improved in the future.
Methods:
In this work, we carried out a large-scale survey aimed at how AI assistants are used, focusing on specific software development activities and stages. We collected opinions of 481 programmers on five broad activities: (a) implementing new features, (b) writing tests, (c) bug triaging, (d) refactoring, and (e) writing natural-language artifacts, as well as their individual stages.
Results:
Our results provide a novel comparison of different stages where AI assistants are used that is both comprehensive and detailed. It highlights specific activities that developers find less enjoyable and want to delegate to an AI assistant, 
e.g.
, writing tests and natural-language artifacts. We also determine more granular stages where AI assistants are used, such as generating tests and generating docstrings, as well as less studied parts of the workflow, such as generating test data. Among the reasons for not using assistants, there are general aspects like trust and company policies, as well as more concrete issues like the lack of project-size context, which can be the focus of the future research.
Conclusion:
The provided analysis highlights stages of software development that developers want to delegate and that are already popular for using AI assistants, which can be a good focus for features aimed to help developers right now. The main reasons for not using AI assistants can serve as a guideline for future work.",February 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study provides insights into the usage patterns of AI assistants in software development, highlighting areas where developers want to delegate tasks, but the practical impact on startups may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584924002301,A software product line approach for developing hybrid software systems,Samuel=Sepúlveda: samuel.sepulveda@ufrontera.cl,"Abstract
Context:
Quantum computing is rapidly emerging as a transformative force in technology. We will soon increasingly encounter hybrid systems that combine quantum technology with classical software. Software engineering techniques will be required to manage the complexity of designing such systems and their reuse.
Objective:
This paper introduces preliminary ideas concerning developing quantum–classical software using a Software Product Line approach.
Method:
This approach addresses the mentioned challenges and provides a feature model and a whole process to manage variability during the design and development of hybrid quantum–classical software. The usage of this approach is illustrated and discussed using an example in the logistics domain.
Results:
The preliminary insights show the feasibility and suitability of applying the proposed approach to develop complex quantum–classical software.
Conclusions:
The main implication of this research is that it can help to manage complexity, maximize the reuse of classical and quantum software components, and deal with the highly changing technological stack in the current quantum computing field.",February 2025,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The paper discusses the use of Software Product Line approach in developing quantum-classical software, offering insights into managing complexity and maximizing reuse, which can be valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924001903,Improving DevOps team performance through context-capability coalignment: Towards a profile for public sector organizations,Olivia H.=Plant: o.h.plant@utwente.nl; Adina=Aldea: a.i.aldea@utwente.nl; Jos=van Hillegersberg: j.vanhillegersberg@utwente.nl,"Abstract
Context
Many IT organizations turn to agile software delivery approaches such as DevOps in order to reduce the number of IT projects that are running behind schedule and above budget. However, the DevOps paradigm calls for an increased set of capabilities that need to be built and aligned with their context in order to ensure superior team performance.
Objective
This research aims to develop a context-capability coalignment profile for DevOps teams in public organizations. This profile and the corresponding design approach may serve as a model for other software production teams seeking to enhance their performance through improved coalignment. The resulting set of design principles places the traditional information systems theories of dynamic capabilities and contingency theory in a modern context.
Method
We adopt a longitudinal action design research approach centered around a DevOps team working in the IT department of a Dutch public organization. A mixed method design including scientific questionnaires, workshops, expert opinions and semi-structured interviews is employed to build and evaluate the profile.
Results
The resulting profile is characterized by technological complexity, a highly regulated environment, departmental interdependencies and high system relevance. The evaluation phase supports the validity of the artifact and suggests moderately improved coalignment of context and team capabilities after the research period, as well as a positive influence of coalignment on team performance.
Conclusion
It is contended that software teams in public organizations can benefit from improved coalignment between context and DevOps capabilities by following the presented approach. We argue that it is important to create a profile which is internally consistent and views coalignment as a continuous process in order to maximize the positive effect on team performance.",February 2025,"Software delivery team performance, DevOps, Team capabilities, Coalignment, Contextual factors, Action design research",Information and Software Technology,2025-03-18T00:00:00,7.0,"The research focuses on developing a context-capability coalignment profile for DevOps teams in public organizations, providing a model for enhancing team performance through improved alignment, which can be beneficial for startups."
https://www.sciencedirect.com/science/article/pii/S0950584924002040,Causal reasoning in Software Quality Assurance: A systematic review,Luca=Giamattei: luca.giamattei@unina.it,"Abstract
Context:
Software Quality Assurance (SQA) is a fundamental part of software engineering to ensure stakeholders that software products work as expected after release in operation. Machine Learning (ML) has proven to be able to boost SQA activities and contribute to the development of quality software systems. In this context, 
Causal Reasoning
 is gaining increasing interest as a methodology to go beyond a purely data-driven approach by exploiting the use of causality for more effective SQA strategies.
Objective:
Provide a broad and detailed overview of the use of causal reasoning for SQA activities, in order to support researchers to access this research field, identifying room for application, main challenges and research opportunities.
Methods:
A systematic review of the scientific literature on causal reasoning for SQA. The study has found, classified, and analyzed 86 articles, according to established guidelines for software engineering secondary studies.
Results:
Results highlight the primary areas within SQA where causal reasoning has been applied, the predominant methodologies used, and the level of maturity of the proposed solutions. Fault localization is the activity where causal reasoning is more exploited, especially in the web services/microservices domain, but other tasks like testing are rapidly gaining popularity. Both causal inference and causal discovery are exploited, with the Pearl’s graphical formulation of causality being preferred, likely due to its intuitiveness. Tools to favor their application are appearing at a fast pace — most of them after 2021.
Conclusions:
The findings show that causal reasoning is a valuable means for SQA tasks with respect to multiple quality attributes, especially during V&V, evolution and maintenance to ensure reliability, while it is not yet fully exploited for phases like requirements engineering and design. We give a picture of the current landscape, pointing out exciting possibilities for future research.",February 2025,"Causal reasoning, Causal discovery, Causal inference, Software quality",Information and Software Technology,2025-03-18T00:00:00,7.0,"The research on causal reasoning for SQA activities presents valuable insights and possibilities for future research, which could benefit early-stage ventures in improving software quality."
https://www.sciencedirect.com/science/article/pii/S0950584924002295,Evaluating the understandability and user acceptance of Attack-Defense Trees: Original experiment and replication,Giovanna=Broccia: giovanna.broccia@isti.cnr.it; Maurice H.=ter Beek: maurice.terbeek@isti.cnr.it; Alberto=Lluch Lafuente: albl@dtu.dk; Paola=Spoletini: pspoleti@kennesaw.edu; Alessandro=Fantechi: alessandro.fantechi@unifi.it; Alessio=Ferrari: alessio.ferrari@isti.cnr.it,"Abstract
Context:
Attack-Defense Trees (ADTs) are a graphical notation used to model and evaluate security requirements. ADTs are popular because they facilitate communication among different stakeholders involved in system security evaluation and are formal enough to be verified using methods like model checking. The understandability and user-friendliness of ADTs are claimed as key factors in their success, but these aspects, along with user acceptance, have not been evaluated empirically.
Objectives:
This paper presents an experiment with 25 subjects designed to assess the understandability and user acceptance of the ADT notation, along with an internal replication involving 49 subjects.
Methods:
The experiments adapt the Method Evaluation Model (MEM) to examine understandability variables (i.e., effectiveness and efficiency in using ADTs) and user acceptance variables (i.e., ease of use, usefulness, and intention to use). The MEM is also used to evaluate the relationships between these dimensions. In addition, a comparative analysis of the results of the two experiments is carried out.
Results:
With some minor differences, the outcomes of the two experiments are aligned. The results demonstrate that ADTs are well understood by participants, with values of understandability variables significantly above established thresholds. They are also highly appreciated, particularly for their ease of use. The results also show that users who are more effective in using the notation tend to evaluate it better in terms of usefulness.
Conclusion:
These studies provide empirical evidence supporting both the understandability and perceived acceptance of ADTs, thus encouraging further adoption of the notation in industrial contexts, and development of supporting tools.",February 2025,"Security requirements, Attack-Defense Trees, Understandability evaluation, Users acceptance, Empirical user study, Internal replication, Method Evaluation Model",Information and Software Technology,2025-03-18T00:00:00,9.0,"The study on Attack-Defense Trees (ADTs) provides empirical evidence supporting their understandability and acceptance, which could be beneficial for startups needing to evaluate security requirements."
https://www.sciencedirect.com/science/article/pii/S0950584924001757,Accessibility of low-code approaches: A systematic literature review,Hourieh=Khalajzadeh: hkhalajzadeh@deakin.edu.au; John=Grundy: john.grundy@monash.edu,"Abstract
Context:
Model-driven approaches are increasingly used in different domains, such as education, finance and app development, in order to involve non-developers in the software development process. Such tools are hugely dependent on visual elements and thus might not be accessible for users with specific challenges, 
e.g.
, visual impairments.
Objectives:
To locate and analyse existing literature on the accessibility of low-code approaches, their strengths and weaknesses and key directions for future research.
Methods:
We carried out a systematic literature review and searched through five leading databases for primary studies. We used both quantitative and qualitative methods for data synthesis.
Results:
After reviewing and filtering 918 located studies, and conducting both backward and forward snowballing, we identified 38 primary studies that were included in our analysis. We found most papers focusing on accessibility of visual languages and block-based programming.
Conclusion:
Limited work has been done on improving low code programming environment accessibility. The findings of this systematic literature review will assist researchers and developers in understanding the accessibility issues in low-code approaches and what has been done so far to develop accessible approaches.",January 2025,"Systematic literature review, Low-code, Visual languages, Block-based programming, Accessibility",Information and Software Technology,2025-03-18T00:00:00,5.0,"While the accessibility of low-code approaches is an important topic, the research findings may not have a direct practical impact on European early-stage ventures and startups compared to the other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924001861,A dual graph neural networks model using sequence embedding as graph nodes for vulnerability detection,Mingwei=Tang: tang4415@126.com,"Abstract
Context:
Detecting critical to ensure software system security. The traditional static vulnerability detection methods are limited by staff expertise and perform poorly with today’s increasingly complex software systems. Researchers have successfully applied the techniques used in NLP to vulnerability detection as deep learning has developed. The existing deep learning-based vulnerability detection models can be divided into sequence-based and graph-based categories. Sequence-based embedding models cannot use structured information embedded in the code, and graph-based embedding models lack effective node representations.
Objective:
To solve these problems, we propose a deep learning-based method, DGVD (Double Graph Neural Network for Vulnerability Detection).
Methods:
We use the sequential neural network approach to extract local semantic features of the code as nodes embedded in the control flow graph. First, we propose a dual graph neural network module (DualGNN) that consists of GCN and GAT. The altered module utilizes two different graph neural networks to obtain the global structural information of the control flow and the relationship between the nodes and fuses the two. Second, we propose a convolution-based feature enhancement module (TC-FE) that uses different convolution kernels of different sizes to capture information at different scales so that subsequent readout layers can better aggregate node information.
Results:
Experiments demonstrate that DGVD outperforms existing models, obtaining 64.23% vulnerability detection accuracy on CodeXGLUE’s real benchmark dataset.
Conclusion:
The proposed DGVD achieves better performance than the state-of-the-art DGVD has a more effective source code feature extraction capability on real-world datasets.",January 2025,"Vulnerability detection, Graph neural network, Sequence embedding",Information and Software Technology,2025-03-18T00:00:00,7.0,"The DGVD method improves vulnerability detection accuracy and feature extraction capabilities, which are crucial for startups dealing with software security. The results show promising advancements in this area."
https://www.sciencedirect.com/science/article/pii/S0950584924001782,Testing infrastructures to support mobile application testing: A systematic mapping study,Pedro Henrique=Kuroishi: phk@ufscar.br; Ana Cristina Ramada=Paiva: apaiva@fe.up.pt; José Carlos=Maldonado: jcmaldon@icmc.usp.br; Auri Marcelo Rizzo=Vincenzi: auri@ufscar.br,"Abstract
Context:
Testing activities are essential for the quality assurance of mobile applications under development. Despite its importance, some studies show that testing is not widely applied in mobile applications. Some characteristics of mobile devices and a varied market of mobile devices with different operating system versions lead to a highly fragmented mobile ecosystem. Thus, researchers put some effort into proposing different solutions to optimize mobile application testing.
Objective:
The main goal of this paper is to provide a categorization and classification of existing testing infrastructures to support mobile application testing.
Methods:
To this aim, the study provides a Systematic Mapping Study of 27 existing primary studies.
Results:
We present a new classification and categorization of existing types of testing infrastructure, the types of supported devices and operating systems, whether the testing infrastructure is available for usage or experimentation, and supported testing types and applications.
Conclusion:
Our findings show a need for mobile testing infrastructures that support multiple phases of the testing process. Moreover, we showed a need for testing infrastructure for context-aware applications and support for both emulators and real devices. Finally, we pinpoint the need to make the research available to the community whenever possible.",January 2025,"Software testing, Software testing cloud, Software testing crowdsourcing, Testbed, Device farm, Mobile testing, Testing infrastructure, Infrastructure, Systematic mapping study, Mapping study",Information and Software Technology,2025-03-18T00:00:00,7.0,"The categorization and classification of testing infrastructures for mobile applications can have practical value for startups in Europe, improving the quality of their products."
https://www.sciencedirect.com/science/article/pii/S0950584924001885,Mapping DevOps capabilities to the software life cycle: A systematic literature review,Ricardo=Amaro: ricardo_amaro@iscte-iul.pt; Rúben=Pereira: ruben.filipe.pereira@iscte-iul.pt; Miguel Mira=da Silva: mms@tecnico.ulisboa.pt,"Abstract
Context:
Many IT organizations are looking towards DevOps to make their software development and delivery processes faster and more reliable, while DevOps revolutionized the industry by emphasizing collaboration between development and operations teams. Nonetheless, there still exist challenges in harmonizing cultural, technical, measurement and process capabilities for its successful adoption.
Objective:
To research improving DevOps adoption, this study explores DevOps Capabilities relevant to the Life Cycle Processes (LCPs) of the IEEE 2675-2021 DevOps standard. Aiming to provide valuable information on increasing efficiency and outcomes by mapping DevOps Capabilities in each phase of the LCPs. Whereas previous research identified and classified 37 DevOps Capabilities, this study aims to determine which capabilities can enhance each of the 30 phases of the LCPs.
Methods:
Out of 102 documents identified in the Systematic Literature Review (SLR), relations among DevOps Capabilities and LCPs have been synthesized and organized. An in-depth analysis of data was conducted over the connections across various categories. The mapping revealed how they relate in terms of their application and impact.
Results:
The SLR shows technical DevOps Capabilities and technical LCPs strongly correlated. DevOps measurement capabilities have a significant impact on agreement processes. Using an impact scale classification, the study identifies eight capabilities that have exceptional impact on LCPs and eleven capabilities that have a very high impact on the supply process, requirements definition, integration process, and validation process.
Conclusion:
The study demonstrates how DevOps Capabilities together with LCPs can improve software delivery, quality, and reliability. It presents a structured approach for improving processes, as well as evidence of DevOps integration in software development and maintenance. The findings help to assess DevOps Capabilities and LCP relations, which is expected to improve successful adoption. Future research should focus on researching practical cases of DevOps integration into LCPs, while overcoming adoption challenges.",January 2025,"DevOps, Metrics, Performance, Adoption, Software development life cycle, Information system",Information and Software Technology,2025-03-18T00:00:00,9.0,The study on DevOps capabilities and their impact on software development processes is highly relevant for European early-stage ventures looking to improve efficiency and outcomes.
https://www.sciencedirect.com/science/article/pii/S0950584924001952,Migration of monolithic systems to microservices: A systematic mapping study,Ana=Martínez Saucedo: anmartinez@uade.edu.ar; Guillermo=Rodríguez: guillermo.rodriguez@isistan.unicen.edu.ar; Fabio=Gomes Rocha: gomesrocha@academico.ufs.br; Rodrigo Pereira dos=Santos: rps@uniriotec.br,"Abstract
Context:
The popularity of microservices architecture has grown due to its ability to address monolithic architecture issues, such as limited scalability, hard maintenance, and technological dependence. Nonetheless, the migration of monolith systems to microservices is complex. Therefore, methodologies and techniques are needed to facilitate migration and support practitioners and software architects.
Objective:
The objective of this study is to investigate cases of application migration, microservices identification techniques, tools used during migration, factors that promote migration, as well as issues and benefits of the migration.
Method:
We have conducted this SMS following the guidelines established by Kitchenham and Petersen. The research objective was defined using part of the Goal-Question-Metric model and the Population, Intervention, and Outcome criteria. From 1546 studies that were retrieved from the search execution, 114 were selected and analyzed to answer the research questions.
Results:
This SMS contributes with (i) a migration process proposal based on migration cases, (ii) a characterization of migration techniques based on different criteria, (iii) an analysis of tools to support migration, (iv) the identification of migration drivers, and (v) an exploration of migration issues as well as benefits.
Conclusion:
This SMS sheds light on the complexity and variability of migrating monolithic systems to microservices, as well as the limited number of migration tools. While scalability and maintenance drive migration, few studies assess them. Key challenges include microservices communication and database migration, with most research focusing primarily on monolith decomposition. Despite these difficulties, migration offers benefits, particularly in scalability and maintainability.",January 2025,"Microservices, Monolith, Migration, Architecture, Systematic Mapping Study",Information and Software Technology,2025-03-18T00:00:00,8.0,The investigation into migration from monolithic systems to microservices can provide valuable insights for startups in Europe facing scalability and maintenance challenges.
https://www.sciencedirect.com/science/article/pii/S0950584924001691,Enhancing logic-based testing with EvoDomain: A search-based domain-oriented test suite generation approach,Akram=Kalaee: a_kalaee@comp.iust.ac.ir; Saeed=Parsa: prasa@iust.ac.ir; Zahra=Mansouri: zahra_mansouri@comp.iust.ac.ir,"Abstract
Context
Effective software testing requires test adequacy criteria. MC/DC, a widely used logic-based testing criterion, struggles to detect domain errors caused by incorrect arithmetic operations. Domain errors occur when test requirement boundaries shift or tilt, causing unpredictable behavior and system crashes.
Objective
To address the inadequacy of MC/DC in detecting domain errors, we present EvoDomain, a search-based testing technique.
Method
EvoDomain uses a memetic algorithm combining genetic and hill-climbing algorithms, along with the DBSCAN clustering algorithm to select diversified boundary test data. The memetic algorithm is designed to efficiently enhance the search process for covering boundary test data. We compared EvoDomain with two logic-based testing approaches, a domain-oriented test suite generation approach, and random testing.
Results
Evaluations on 30 case studies show EvoDomain increases fault detection by 74.44% over MC/DC and 65.06% over RoRG. Additionally, EvoDomain improves support for different fault types by up to 68.89% for MC/DC and 66.33% for RoRG. Compared to COSMOS, which uses static analysis, EvoDomain improves the convergence effectiveness of identifying feasible subdomains by 32%. It offers high accuracy (0.99-1) and F1-score (0.99-1). EvoDomain finds the subdomains in less than 1/3 the time of Random search.
Conclusion
EvoDomain effectively generates domain-oriented test suites, enhancing the accuracy and effectiveness of fault detection.",January 2025,"Software testing, Domain-oriented test suite generation, Logic-based testing, Mutation analysis, MC/DC",Information and Software Technology,2025-03-18T00:00:00,7.0,The introduction of EvoDomain as a search-based testing technique with significant improvements over existing methods can benefit European startups aiming to enhance their software testing processes.
https://www.sciencedirect.com/science/article/pii/S095058492400171X,Graph-based explainable vulnerability prediction,Hong Quy=Nguyen: nguyen.hquy@gmail.com; Thong=Hoang: james.hoang@data61.csiro.au; Hoa Khanh=Dam: hoa@uow.edu.au; Aditya=Ghose: aditya@uow.edu.au,"Abstract
Significant increases in cyberattacks worldwide have threatened the security of organizations, businesses, and individuals. Cyberattacks exploit vulnerabilities in software systems. Recent work has leveraged powerful and complex models, such as deep neural networks, to improve the predictive performance of vulnerability detection models. However, these models are often regarded as “black box” models, making it challenging for software practitioners to understand and interpret their predictions. This lack of explainability has resulted in a reluctance to adopt or deploy these vulnerability prediction models in industry applications. This paper proposes a novel approach, 
G
enetic 
A
lgorithm-based 
Vul
nerability Prediction 
Explainer
, (herein GAVulExplainer), which generates explanations for vulnerability prediction models based on graph neural networks. GAVulExplainer leverages genetic algorithms to construct a subgraph explanation that represents the crucial factor contributing to the vulnerability. Experimental results show that our proposed approach outperforms baselines in providing concrete reasons for a vulnerability prediction.",January 2025,"Graph neural network, Explanation, Vulnerability",Information and Software Technology,2025-03-18T00:00:00,6.0,"The GAVulExplainer provides valuable insights into vulnerability prediction models, which can enhance security measures for startups. Although the improvements are noteworthy, the practical application may be limited by the complexity of the approach."
https://www.sciencedirect.com/science/article/pii/S0950584924001769,Specialized model initialization and architecture optimization for few-shot code search,Fan=Zhang: fanzhang@hnu.edu.cn; Qiang=Wu: wuqiang@hnu.edu.cn; Manman=Peng: pengmanman@hnu.edu.cn; Yuanyuan=Shen: shenyuanyuan@nuc.edu.cn,"Abstract
Context:
Code search aims to find relevant code snippets from a codebase given a natural language query. It not only boosts developer efficiency but also improves the performance of tasks such as code generation and program repair, thus becoming one of the crucial tasks in software engineering.
Objective:
However, recent works are mainly designed for mainstream programming languages with abundant training data. We aim to address the challenges of code search for domain-specific programming languages with limited training data by proposing a novel two-stage, few-shot code search framework named SMIAO.
Method:
SMIAO includes a specialized model initialization and an architecture optimization stage. In the first stage, we first quantitatively identify a mainstream programming language’s dataset that is semantically closest to a target few-shot programming language. Then, we enrich the dataset with hard samples and train an Adapter-GraphCodeBERT model to obtain well-initialized parameters. In the second stage, we first design a search space for the initialized Adapter-GraphCodeBERT model. Then, we employ neural architecture search to optimize the Adapter modules’ positions and quantities in the GraphCodeBERT layers, tailoring for real-world few-shot code search tasks.
Results:
We conduct experiments on a publicly available dataset to demonstrate the effectiveness and rationality of SMIAO. The experimental results show that SMIAO outperforms other state-of-the-art baselines.
Conclusion:
Using mainstream languages’ datasets to initialize Adapter-GraphCodeBERT models, followed by adjusting the quantities and positions of Adapter modules within the GraphCodeBERT layers by neural architecture search, can effectively improve the performance of few-shot code search tasks.",January 2025,"Code search, Code understanding, Information retrieval, Neural architecture search, AI for software engineering",Information and Software Technology,2025-03-18T00:00:00,5.0,"SMIAO tackles the challenges of code search for domain-specific programming languages, which can be beneficial for early-stage ventures with limited resources. However, the impact may be more significant for established companies."
https://www.sciencedirect.com/science/article/pii/S0950584924001368,Extraction and empirical evaluation of GUI-level invariants as GUI Oracles in mobile app testing,Ali Asghar=Yarifard: yarifard@mail.um.ac.ir; Saeed=Araban: araban@um.ac.ir; Samad=Paydar: s-paydar@um.ac.ir; Vahid=Garousi: v.garousi@qub.ac.uk; Maurizio=Morisio: maurizio.morisio@polito.it; Riccardo=Coppola: riccardo.coppola@polito.it,"Abstract
Context
Mobile apps (software) are used in almost all aspects of daily life by billions of people. Given the widespread use of mobile apps in various domains, the demand for systematic testing of their Graphical User Interfaces (GUI) is crucial. Despite the significant advances in automated mobile app testing over the last decade, certain challenges remain, most notably the app-specific GUI test-oracle problem, which can significantly hinder the effective detection of defects in mobile apps. In this study, we introduce the use of GUI-level invariants, referred to as GUI invariants, as app-specific GUI oracles in GUI test cases to address this challenge.
Methods
We propose a semi-automatic solution to extract GUI invariants and use them as app-specific GUI oracles in test cases. We use the mutation testing technique to evaluate the (fault detection) effectiveness of the GUI oracles used. In addition, we evaluate their quality aspects, namely correctness, understandability, and compatibility, from the perspective of human experts using a questionnaire survey.
Results
The empirical results show that the GUI oracles used are effective and helpful, as they improved the fault-detection effectiveness of the empirical test suites ranging from 18% to 32%. These results also highlight the efficacy of GUI oracles used in identifying various defects, including crashing and non-crashing functional issues, and surpassing the performance of existing tools in fault-detection rates. Additionally, the questionnaire survey outcomes indicate that the GUI oracles used are correct, understandable, and compatible.
Conclusions
Based on the empirical results, we can conclude that using GUI invariants as GUI oracles can be useful and effective in mobile app testing.",January 2025,"Graphical user interface (GUI) testing, Test oracle, GUI invariants, Mobile app testing, Empirical study",Information and Software Technology,2025-03-18T00:00:00,8.0,"The use of GUI invariants as oracles in mobile app testing shows significant improvements in fault detection effectiveness. This can be particularly valuable for startups focusing on mobile app development, addressing a crucial testing challenge."
https://www.sciencedirect.com/science/article/pii/S0950584924001733,Software solutions for newcomers’ onboarding in software projects: A systematic literature review,Italo=Santos: italo_santos@nau.edu; Katia Romero=Felizardo: katiascannavino@utfpr.edu.br; Igor=Steinmacher: igor.steinmacher@nau.edu; Marco A.=Gerosa: marco.gerosa@nau.edu,"Abstract
Context:
Newcomers joining an unfamiliar software project face numerous barriers; therefore, effective onboarding is essential to help them engage with the team and develop the behaviors, attitudes, and skills needed to excel in their roles. However, onboarding can be a lengthy, costly, and error-prone process. Software solutions can help mitigate these barriers and streamline the process without overloading senior members.
Objective:
This study aims to identify the state-of-the-art software solutions for onboarding newcomers.
Methods:
We conducted a systematic literature review (SLR) to answer six research questions.
Results:
We analyzed 32 studies about software solutions for onboarding newcomers and yielded several key findings: (1) a range of strategies exists, with recommendation systems being the most prevalent; (2) most solutions are web-based; (3) solutions target a variety of onboarding aspects, with a focus on process; (4) many onboarding barriers remain unaddressed by existing solutions; (5) laboratory experiments are the most commonly used method for evaluating these solutions; and (6) diversity and inclusion aspects primarily address experience level.
Conclusion:
We shed light on current technological support and identify research opportunities to develop more inclusive software solutions for onboarding. These insights may also guide practitioners in refining existing platforms and onboarding programs to promote smoother integration of newcomers into software projects.",January 2025,"Systematic literature review, Software projects, Open source software, Onboarding, Turnover, Tool, Newcomers, Novices",Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study sheds light on technological support for onboarding newcomers in software projects, the impact may be limited to a specific niche within the software industry. The findings may provide insights for practitioners but do not significantly impact a wide range of early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924001770,DeVAIC: A tool for security assessment of AI-generated code,Domenico=Cotroneo: cotroneo@unina.it; Roberta=De Luca: roberta.deluca2@unina.it; Pietro=Liguori: pietro.liguori@unina.it,"Abstract
Context:
AI code generators are revolutionizing code writing and software development, but their training on large datasets, including potentially untrusted source code, raises security concerns. Furthermore, these generators can produce incomplete code snippets that are challenging to evaluate using current solutions.
Objective:
This research work introduces 
DeVAIC
 (Detection of Vulnerabilities in AI-generated Code), a tool to evaluate the security of AI-generated Python code, which overcomes the challenge of examining incomplete code.
Methods:
We followed a methodological approach that involved gathering vulnerable samples, extracting implementation patterns, and creating regular expressions to develop the proposed tool. The implementation of 
DeVAIC
 includes a set of detection rules based on regular expressions that cover 35 Common Weakness Enumerations (CWEs) falling under the OWASP Top 10 vulnerability categories.
Results:
We utilized four popular AI models to generate Python code, which we then used as a foundation to evaluate the effectiveness of our tool. 
DeVAIC
 demonstrated a statistically significant difference in its ability to detect security vulnerabilities compared to the state-of-the-art solutions, showing an 
F
1
 Score and Accuracy of 94% while maintaining a low computational cost of 0.14 s per code snippet, on average.
Conclusions:
The proposed tool provides a lightweight and efficient solution for vulnerability detection even on incomplete code.",January 2025,"Static code analysis, Vulnerability detection, AI-code generators, Python",Information and Software Technology,2025-03-18T00:00:00,9.0,"The research work on DeVAIC introduces a tool that addresses security concerns in AI-generated code, showcasing significant effectiveness with a high F1 Score and low computational cost. This tool has the potential to benefit a wide range of European startups by providing enhanced security measures during code development."
https://www.sciencedirect.com/science/article/pii/S0950584924001988,What helps Agile remote teams to be successful in developing software? Empirical evidence,Carlos=Tam: carlosvai@novaims.unl.pt,"Abstract
Software development firms have specific goals but today's dynamic business environment, especially regarding the use of remote teams, presents great challenges due to uncertainties and multiple risks. This study investigates the facilitators of the success of Agile software development projects delivered by remote teams. We employ a conceptual research model founded on the technology-organization-environment (TOE) framework. The study contributes to the literature by exploring how remote teams affect the success of Agile software development projects. Partial least squares structural equation modeling (PLS-SEM) analysis of the data collected from 198 IT professionals revealed that perceived pressure from government, job performance, and team satisfaction are significant in explaining these projects’ success.",January 2025,"Agile software development project management, Critical success factors, Remote work, TOE framework",Information and Software Technology,2025-03-18T00:00:00,5.0,"The study investigates the success factors of Agile software development projects delivered by remote teams, which is relevant in today's dynamic business environment. While the findings contribute to the literature, the practical impact on early-stage ventures might be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924001940,An intent-enhanced feedback extension model for code search,Haize=Hu: HHZ@gxnu.edu.cn; Mengge=Fang: fmg@stu.gxnu.edu.cn,"Abstract
Context:
Queries and descriptions used for code search not only differ in semantics and syntax, but also in structural features. Therefore, solving the differences between them is of great significance to the study of code search.
Objective:
This study focuses on the improvement of code search accuracy by exploring the expansion of query statements during the search process.
Methods:
To address the disparities between description and query, the paper introduces the Intentional Enhancement and Feedback (QEIEF) query expansion model. QEIEF leverages the written description provided by developers as the source for query expansion. Furthermore, QEIEF incorporates theQEIEF method to enhance the semantic representation of the query. This involves utilizing the query output as the target for intent enhancement and integrating it back into the query.
Results:
To assess the effectiveness of the proposedQEIEF in code search tasks, we conducted experiments using two base models (DeepCS and UNIF) along withQEIEF, as well as baseline models (WordNet and BM25). The experimental results indicate that QEIEF outperforms the baseline models in terms of query expansion accuracy and code search results.
Conclusion:
QEIEF not only enhances the accuracy of query expansion but also substantially improves code search performance. The source code and data associated with our study can be accessed publicly at: The address of our new code and data is 
https://github.com/xiangzheng666/IST-IEFE
.",January 2025,"Code search, Query expansion, Intentional enhancement, Feedback mechanisms",Information and Software Technology,2025-03-18T00:00:00,7.0,"The QEIEF query expansion model proposed in this study aims to improve code search accuracy, showing promising results in comparison to baseline models. While the impact on European early-stage ventures may not be revolutionary, the enhancement in code search performance could benefit startups in streamlining their development processes."
https://www.sciencedirect.com/science/article/pii/S0950584924001964,DFL: A DOM sample generation oriented fuzzing framework for browser rendering engines,Guoyun=Duan: dguoyun@hnu.edu.cn; Hai=Zhao: ha1vk@foxmail.com; Minjie=Cai: caiminjie@hnu.edu.cn; Jianhua=Sun: jhsun@hnu.edu.cn; Hao=Chen: haochen@hnu.edu.cn,"Abstract
The security of web browsers, being fundamental to Internet access infrastructure, has garnered significant attention. Current approaches to identify browser vulnerabilities predominantly rely on code auditing and componentized unit testing. Fuzzing has emerged as an efficient technique for vulnerability discovery. However, adapting this method to browser security testing poses considerable challenges. Recent endeavors in browser vulnerability discovery primarily concentrate on the parsing engine, with limited solutions addressing the rendering engine. Moreover, coverage-guided mutation, a critical aspect, is not prevalent in existing fuzzing frameworks. In this paper, we present a coverage-guided fuzzing framework of DFL, which builds on Freedom and AFL to re-engineer various text generators based on DOM syntax and optimize the efficiency of sample generation. Additionally, serialization and deserialisation methods are developed for the implementation of generator text mutations and the seamless conversion between binary samples and the source DOM tree. When compared with three established DOM fuzzing frameworks in the latest Chromium kernel, DFL has demonstrated an ability to uncover 1.5–3 times more vulnerabilities within a short timeframe. Our research identifies potential avenues for further exploration in browser rendering engine security, specifically focusing on sample generation and path direction.",January 2025,"DOM, Browser security, Gray-box fuzzing, Coverage guided fuzzing, Browser rendering engine",Information and Software Technology,2025-03-18T00:00:00,10.0,The coverage-guided fuzzing framework of DFL presented in this paper demonstrates a significant improvement in vulnerability discovery within browser rendering engines. The research identifies potential avenues for further exploration in browser security and offers tangible benefits to early-stage ventures by enhancing their security testing processes.
https://www.sciencedirect.com/science/article/pii/S0950584924001873,ENZZ: Effective N-gram coverage assisted fuzzing with nearest neighboring branch estimation,Peng=Jia: pengjia@scu.edu.cn; Jiayong=Liu: liujiayong@scu.edu.cn,"Abstract
Fuzzing is a highly effective approach for identifying software bugs and vulnerabilities. Among the various techniques employed, coverage-guided fuzzing stands out as particularly valuable, relying on tracing code coverage information. N-gram coverage is a coverage metric in gray-box fuzz testing, where the value of N determines the sensitivity of the coverage. Block and edge coverage can be represented as 0-gram and 1-gram, respectively. The value of N can range from 0 to infinity. However, the specific methodology for selecting the appropriate value of N is still an area yet to be explored.
This paper proposes an estimation method based on the nearest branch. We initially explained the role of N-gram in the execution paths of programs and elucidated the objective of selecting the value of N, which aims to cover the closest neighboring branches. Subsequently, based on this objective, we proposed a method for calculating N based on the closest neighboring branch and estimated N at the function level. Finally, in this paper, we designed a scheduling mechanism using Adversarial Multi-Armed Bandit model that automatically selects either the seeds generated by N-gram or the original queue seeds for fuzz testing.
We implement our approach in ENZZ based on AFL and compare it with other N-gram coverage fuzzers and the state-of-the-art path coverage-assisted fuzzer PathAFL. We find that ENZZ outperforms other N-gram fuzzers and PathAFL by achieving an average improvement of 5.57% and 4.38% on edge coverage, and it improves the efficiency of path-to-edge discovery by 31.5% and 26.1%, respectively, on 12 Google FuzzBench programs. It also finds more bugs than other N-gram fuzzers and three more real-world bugs than PathAFL.",January 2025,"System security, Software testing, Graybox fuzzing, Vulnerability detection, N-gram",Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposal of an estimation method for selecting the appropriate value of N in N-gram coverage fuzz testing presents a valuable contribution to the field. The implementation in ENZZ and the comparison with other fuzzers demonstrate superior performance, which can have a positive impact on European startups by improving their bug identification processes."
https://www.sciencedirect.com/science/article/pii/S0950584924001897,A search-and-fill strategy to code generation for complex software requirements,Yukun=Dong: dongyk@upc.edu.cn,"Abstract
Context:
The realm of software development has seen significant transformations with the rise of Low-Code Development (LCD) and the integration of Artificial Intelligence (AI), particularly large language models, into coding practices. The proliferation of open-source software also offers vast resources for developers.
Objective:
We aim to combine the benefits of modifying retrieved code with the use of an extensive code repository to tackle the challenges of complex control structures and multifunctional requirements in software development.
Method:
Our study introduces a Search-and-Fill strategy that utilizes natural language processing (NLP) to dissect complex software requirements. It extracts control structures and identifies atomic function points. By leveraging large-scale pre-trained models, the strategy searches for these elements to fill in the automatically transformed program structures derived from descriptions of control structures. This process generates a code snippet that includes program control structures and the implementations of various function points, thereby facilitating both code reuse and efficient development.
Results:
We have validated the effectiveness of our strategy in generating code snippets. For natural language requirements involving multifunctional complex structures, we constructed two datasets: the Basic Complex Requirements Dataset (BCRD) and the Advanced Complex Requirements Dataset (ACRD). These datasets are based on natural language descriptions and Python code that were randomly extracted and combined. For the code snippets to be generated, we achieved the best results with the ACRD dataset, with BLEU-4 scores reaching up to 0.6326 and TEDS scores peaking at 0.7807.
Conclusion:
The Search-and-Fill strategy successfully generates a comprehensive code snippets, integrating essential control structures and functions to streamline the development process. Experimental results substantiate our strategy’s efficacy in optimizing code reuse by effectively integrating preprocessing and selection optimization approach. Future research will focus on enhancing the recognition of complex software requirements and further refining the code snippets.",January 2025,"Low-Code Development, Complex software requirements, Search-and-Fill strategy, Code generation, Natural language processing",Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract introduces a comprehensive strategy for generating code snippets using natural language processing, large-scale pre-trained models, and datasets. The approach aims to optimize code reuse and facilitate efficient software development, which could potentially impact early-stage ventures by saving time and resources."
https://www.sciencedirect.com/science/article/pii/S0950584924002015,Deciphering refactoring branch dynamics in modern code review: An empirical study on Qt,Eman Abdullah=AlOmar: ealomar@stevens.edu,"Abstract
Context:
Modern code review is a widely employed technique in both industrial and open-source projects, serving to enhance software quality, share knowledge, and ensure compliance with coding standards and guidelines. While code review is extensively studied for its general challenges, best practices, outcomes, and socio-technical aspects, little attention has been paid to how refactoring is reviewed and what developers prioritize when reviewing refactored code in the ‘Refactor’ branch.
Objective:
The goal is to understand the review process for refactoring changes in the ‘Refactor’ branch and to identify what developers care about when reviewing code in this branch.
Method:
In this study, we present a quantitative and qualitative examination to understand the main criteria developers use to decide whether to accept or reject refactored code submissions and identify the challenges inherent in this process.
Results:
Analyzing 2154 refactoring and non-refactoring reviews across Qt open-source projects, we find that reviews involving refactoring from the ‘Refactor’ branch take significantly less time to resolve in terms of code review efforts. Additionally, documentation of developer intent is notably sparse within the ‘Refactor’ branch compared to other branches. Furthermore, through thematic analysis of a substantial sample of refactoring code review discussions, we construct a comprehensive taxonomy consisting of 12 refactoring review criteria.
Conclusion:
Our findings underscore the importance of developing precise and efficient tools and techniques to aid developers in the review process amidst refactorings.",January 2025,"Refactoring, Code review, Developer perception, Software quality",Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract delves into the review process for refactoring changes in software development, providing insights into the challenges developers face. While the findings are valuable for improving the review process, the direct impact on early-stage ventures might not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924002027,Better together: Automated app review analysis with deep multi-task learning,Yawen=Wang: yawen2018@iscas.ac.cn; Junjie=Wang: junjie@iscas.ac.cn; Hongyu=Zhang: hyzhang@cqu.edu.cn; Xuran=Ming: xuran2020@iscas.ac.cn; Qing=Wang: wq@iscas.ac.cn,"Abstract
Context:
User reviews of mobile apps provide an important communication channel between developers and users. Existing approaches to automated app review analysis mainly focus on one task (e.g., bug classification task, information extraction task, etc.) at a time, and are often constrained by the manually defined patterns and the ignorance of the correlations among the tasks. Recently, multi-task learning (MTL) has been successfully applied in many scenarios, with the potential to address the limitations associated with app review mining tasks.
Objective:
In this paper, we propose 
MABLE
, a deep MTL-based and semantic-aware approach, to improve app review analysis by exploiting task correlations.
Methods:
MABLE
 jointly identifies the types of involved bugs reported in the review and extracts the fine-grained features where bugs might occur. It consists of three main phases: (1) data preparation phase, which prepares data to allow data sharing beyond single task learning; (2) model construction phase, which employs a BERT model as the shared representation layer to capture the semantic meanings of reviews, and task-specific layers to model two tasks in parallel; (3) model training phase, which enables eavesdropping by shared loss function between the two related tasks.
Results:
Evaluation results on six apps show that 
MABLE
 outperforms ten commonly-used and state-of-the-art baselines, with the precision of 79.76% and the recall of 79.24% for classifying bugs, and the precision of 79.83% and the recall of 80.33% for extracting problematic app features. The MTL mechanism improves the F-measure of two tasks by 3.80% and 4.63%, respectively.
Conclusion:
The proposed approach provides a novel and effective way to jointly learn two related review analysis tasks, and sheds light on exploring other review mining tasks.",January 2025,"App review, Bug classification, Feature extraction, Deep multi-task learning",Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed approach in this abstract, MABLE, offers a novel way to improve app review analysis through multi-task learning. The high precision and recall rates in classifying bugs and extracting app features could benefit startups by enhancing the quality of their mobile apps."
https://www.sciencedirect.com/science/article/pii/S0950584924001927,Architecture decisions in quantum software systems: An empirical study on Stack Exchange and GitHub,Mst Shamima=Aktar: shamima@whu.edu.cn; Peng=Liang: liangp@whu.edu.cn; Muhammad=Waseem: muhammad.m.waseem@jyu.fi; Amjed=Tahir: a.tahir@massey.ac.nz; Aakash=Ahmad: a.ahmad13@lancaster.ac.uk; Beiqi=Zhang: zhangbeiqi@whu.edu.cn; Zengyang=Li: zengyangli@ccnu.edu.cn,"Abstract
Context:
Quantum computing provides a new dimension in computation, utilizing the principles of quantum mechanics to potentially solve complex problems that are currently intractable for classical computers. However, little research has been conducted about the architecture decisions made in quantum software development, which have a significant influence on the functionality, performance, scalability, and reliability of these systems.
Objective:
The study aims to empirically investigate and analyze architecture decisions made during the development of quantum software systems, identifying prevalent challenges and limitations by using the posts and issues from Stack Exchange and GitHub.
Methods:
We used a qualitative approach to analyze the obtained data from Stack Exchange Sites and GitHub projects — two prominent platforms in the software development community. Specifically, we collected data from 385 issues (from 87 GitHub projects) and 70 posts (from 3 Stack Exchange sites) related to architecture decisions in quantum software development.
Results:
The results show that in quantum software development (1) architecture decisions are articulated in six linguistic patterns, the most common of which are 
Solution Proposal
 and 
Information Giving
, (2) the two major categories of architectural decisions are 
Implementation Decision
 and 
Technology Decision
, (3) 
Software Development Tools
 are the most common application domain among the twenty application domains identified, (4) 
Maintainability
 is the most frequently considered quality attribute, and (5) 
Design Issues
 and 
High Error Rates
 are the major limitations and challenges that practitioners face when making architecture decisions in quantum software development.
Conclusions:
Our results show that the limitations and challenges encountered in architecture decision-making during the development of quantum software systems are strongly linked to the particular features (e.g., quantum entanglement, superposition, and decoherence) of those systems. These issues mostly pertain to technical aspects and need appropriate measures to address them effectively.",January 2025,"Architecture decision, Quantum software system, Stack Exchange, GitHub, Empirical study",Information and Software Technology,2025-03-18T00:00:00,4.0,"The study investigates architecture decisions in quantum software development, shedding light on challenges and limitations. While the insights are relevant for the research community, the practical impact on European early-stage ventures might be limited due to the specialized nature of quantum computing."
https://www.sciencedirect.com/science/article/pii/S095058492400199X,Strategic digital product management: Nine approaches,Helena Holmström=Olsson: helena.holmstrom.olsson@mau.se,"Abstract
Context:
The role of product management (PM) is key for building, implementing and managing software-intensive systems. Whereas engineering is concerned with how to build systems, PM is concerned with ‘what’ to build and ‘why’ we should build the product. The role of PM is recognized as critical for the success of any product. However, few studies explore how the role of PM is changing due to recent trends that come with digitalization and digital transformation.
Objectives:
Although there is prominent research on PM, few studies explore how this role is changing due to the digital transformation of the software-intensive industry. In this paper, we study how trends such as DevOps and short feedback loops, data and artificial intelligence (AI), as well as the emergence of digital ecosystems, are changing current product management practices.
Methods:
This study employs a qualitative approach using multi-case study research as the method. For our research, we selected five case companies in the software-intensive systems domain. Through workshop sessions, frequent meetings and interviews, we explore how DevOps and short feedback loops, data and artificial intelligence (AI), and digital ecosystems challenge current PM practices.
Results:
Our study yielded an in-depth understanding of how digital transformation of the software-intensive systems industry is changing current PM practices. We present empirical results from workshops and from interviews in which case company representatives share their insights on how software, data and AI impact current PM practices. Based on these results, we present a framework organized along two dimensions, i.e. a certainty dimension and an approach dimension. The framework helps structure the approaches product managers can employ to select and prioritize development of new functionality.
Contributions:
The contribution of this paper is a framework for ‘Strategic Digital Product Management’ (SDPM). The framework outlines nine approaches that product managers can employ to maximize the return on investment (RoI) of R&D using new digital technologies.",January 2025,"Strategic digital product management, DevOps, Data, Artificial intelligence, Digital ecosystems, Digitalization, Digital transformation",Information and Software Technology,2025-03-18T00:00:00,9.0,"The study on how digital transformation trends impact product management practices in the software-intensive industry offers practical frameworks to maximize return on investment, aligning with the current industry needs."
https://www.sciencedirect.com/science/article/pii/S0950584924001915,Constructing the graphical structure of expert-based Bayesian networks in the context of software engineering: A systematic mapping study,Thiago=Rique: thiago.rique@ifpb.edu.br; Mirko=Perkusich: mirko@virtus.ufcg.edu.br; Kyller=Gorgônio: kyller@virtus.ufcg.edu.br; Hyggo=Almeida: hyggo@virtus.ufcg.edu.br; Angelo=Perkusich: perkusic@virtus.ufcg.edu.br,"Abstract
Context:
In scenarios where data availability issues hinder the applications of statistical causal modeling in software engineering (SE), Bayesian networks (BNs) have been widely used due to their flexibility in incorporating expert knowledge. However, the general understanding of how the graphical structure, i.e., the directed acyclic graph (DAG), of these models is built from domain experts is still insufficient.
Objective:
This study aims to characterize the SE landscape of constructing the graphical structure of BNs, including their potential for causal modeling.
Method:
We conducted a systematic mapping study employing a hybrid search strategy that combines a database search with parallel backward and forward snowballing.
Results:
Our mapping included a total of 106 studies. Different methods are commonly combined to construct expert-based BN structures. These methods span across data gathering & analysis (e.g., interviews, focus groups, literature research, grounded theory, and statistical analysis) and reasoning mechanisms (e.g., using idioms combined with the adoption of lifecycle models, risk-centric modeling, and other frameworks to guide BN construction). We found a lack of consensus regarding validation procedures, particularly critical when modeling cause–effect relationships from knowledge. Additionally, expert-based BNs are mainly applied at the tactical level to address problems related to software engineering management and software quality. Challenges in creating expert-based structures include validation procedures, experts’ availability, expertise level, and structure complexity handling. Key recommendations involve empirical validation, participatory involvement, and balance between adaptation to organizational constraints and model construction requirements.
Conclusion:
The construction of expert-based BN structures in SE varies in rigor, with some methods being systematic while others appear ad hoc. To enhance BN application, reducing expert knowledge subjectivity, enhancing methodological rigor, and clearly articulating the construction rationale is essential. Addressing these challenges is crucial for improving the reliability of causal inferences drawn from these models, ultimately leading to better-informed decisions in SE practices.",January 2025,"Bayesian networks, Bayesian network structure, Expert knowledge, Software engineering, Systematic mapping",Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on constructing expert-based BN structures in software engineering offers insights into challenges and recommendations, but the impact on practical applications may vary depending on the rigor of methodology implementation."
https://www.sciencedirect.com/science/article/pii/S0950584924001526,Don’t forget to change these functions! recommending co-changed functions in modern code review,Chakkrit=Tantithamthavorn: chakkrit@monash.edu,"Abstract
Context:
Code review is effective and widely used, yet still time-consuming. Especially, in large-scale software systems, developers may forget to change other related functions that must be changed together (aka. co-changes). This may increase the number of review iterations and reviewing time, thus delaying the code review process. Based on our analysis of 66 projects from five open-source systems, we find that there are 16%–33% of code reviews where at least one function must be co-changed, but was not initially changed.
Objectives:
This study aims to propose an approach to recommend co-changed functions in the context of modern code review, which could reduce reviewing time and iterations and help developers identify functions that need to be changed together.
Methods:
We propose 
CoChangeFinder
, a novel method that employs a Graph Neural Network (GNN) to recommend co-changed functions for newly submitted code changes. Then, we conduct a quantitative and qualitative evaluation of 
CoChangeFinder
 with 66 studied large-scale open-source software projects.
Results:
Our evaluation results show that our 
CoChangeFinder
 outperforms the state-of-the-art approach, achieving 3.44% to 40.45% for top-k accuracy, 2.00% to 26.07% for Recall@k, and 0.04 to 0.21 for mean average precision better than the baseline approach. In addition, our 
CoChangeFinder
 demonstrates the capacity to pinpoint the functions related to logic changes.
Conclusion:
Our 
CoChangeFinder
 outperforms the baseline approach (i.e., TARMAQ) in recommending co-changed functions during the code review process. Based on our findings, 
CoChangeFinder
 could help developers save their time and effort, reduce review iterations, and enhance the efficiency of the code review process.",December 2024,"Software quality assurance, Modern code review, Machine learning",Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposal of CoChangeFinder to recommend co-changed functions in code review processes shows significant performance improvements over existing approaches, providing a practical solution to reduce reviewing time and enhance efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584924001514,XDrain: Effective log parsing in log streams using fixed-depth forest,Changjian=Liu: driz2t@foxmail.com; Yang=Tian: ytian@gxu.edu.cn; Siyu=Yu: gaiusyu6@gmail.com; Donghui=Gao: dhgao1011@gmail.com; Yifan=Wu: yifanwu@pku.edu.cn; Suqun=Huang: huangsuqun2022@163.com; Xiaochun=Hu: huxch999@163.com; Ningjiang=Chen: chnj@gxu.edu.cn,"Abstract
Logs record rich information that can help operators diagnose system failure 
[1]
. Analyzing logs in log streams can expedite the diagnostic process and effectively mitigate the impact of failures. Log parsing is a prerequisite for automated log analysis, which transforms semi-structured logs into structured logs. However, the effectiveness of existing parsers has only been evaluated on a limited set of logs, which lack sufficient log types. After conducting a more comprehensive evaluation of the existing log parser, we identified the following deficiencies: (1) Variable-starting logs can make some log parsers error-prone. (2) The order of logs in a log stream can have a great impact on the effectiveness. We proposes XDrain to satisfy these challenges by using fixed-depth forest. XDrain first shuffles the order of logs and the order of words within each log a few times. Secondly, XDrain will generate parsing forest for all the logs generated after the shuffling. Finally, the final log template is generated by voting. Evaluation results show that XDrain outperforms existing log parsers on two widely-used accuracy metrics and is immune to inappropriate log order. XDrain only takes about 97.89 s to parse one million logs on average.",December 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"XDrain addresses log parsing challenges, which can be useful for system failure diagnosis, but the impact on European early-stage ventures is not as direct as other abstracts."
https://www.sciencedirect.com/science/article/pii/S095058492400154X,How do software practitioners perceive human-centric defects?,Hourieh=Khalajzadeh: hkhalajzadeh@deakin.edu.au; John=Grundy: john.grundy@monash.edu; Vedant=Chauhan: vedant.chauhan@monash.edu; Chetan=Arora: chetan.arora@monash.edu,"Abstract
Context:
Human-centric software design and development prioritises the way users prefer to complete their jobs, rather than expecting users to adapt to the software. Software users can have different genders, ages, cultures, languages, disabilities, socioeconomic statuses, and educational backgrounds, among many other differences. Due to the inherently varied nature of these differences and their impact on software usage, preferences and issues of users can vary, resulting in user-specific defects that we term as 
‘human-centric defects’ (HCDs)
.
Objective:
This research aims to understand the perception and current management practices of such HCDs by software practitioners, identify key challenges in reporting, understanding and fixing them, and provide recommendations to improve HCDs management in software engineering.
Methods:
We conducted a survey and interviews with software engineering practitioners to gauge their knowledge and experience on HCDs and the defect tracking process.
Results:
We analysed fifty (50) survey- and ten (10) interview-responses from SE practitioners and identified that there are multiple gaps in the current management of HCDs in software engineering practice. There is a lack of awareness regarding human-centric aspects, causing them to be lost or under-appreciated during software development. Our results revealed that handling HCDs could be improved by following a better feedback process with end-users, a more descriptive taxonomy, and suitable automation.
Conclusion:
HCDs, given their diverse end-user base, present a major challenge to software practitioners. In the software engineering domain, research on HCDs has been limited and requires effort from research and practice communities to create awareness and support for human-centric aspects.",December 2024,"Human-centric defects, Software engineering, Information technology, Defect reporting, Software development lifecycle",Information and Software Technology,2025-03-18T00:00:00,5.0,"Understanding and managing human-centric defects can improve user experience for software, but the practical application and impact on early-stage ventures may not be as immediate."
https://www.sciencedirect.com/science/article/pii/S0950584924001654,DCM-GIFT: An Android malware dynamic classification method based on gray-scale image and feature-selection tree,Saihua=Cai: caisaih@ujs.edu.cn,"Abstract
Context:
The boom of Android market makes mobile products more popular and convenient. However, in the face of the complex Android application market, how to efficiently and accurately identify malware has become one of the focuses of research. Various new types of disguised malware lurk in the web pages, links and major application malls. Therefore, people’s privacy and property security have become a major obstacle to the continued development of mobile devices.
Objective:
Most of the existing malware classification methods are fixed on one or several types of characteristics of Android devices, such as static characteristics, dynamic characteristics and traffic characteristics. Single feature detection or fixed feature fusion models limit the dimension of detection software, and also cause imbalanced classification results. This paper proposes an Android Malware Dynamic Classification Method based on Gray-scale Image and Feature-selection Tree (DCM-GIFT), which aims to improve and stabilize the precision of Android software classification and enhance the robustness of malware classification.
Method:
In this paper, we construct gray-scale images for the original Android traffic to retain the characteristics of the time series and spatial structure of the original network traffic. At the same time, we take the dynamic information and static information of Android software as auxiliary features to build a feature selection tree. The feature-selection algorithm helps the classifier dynamically select the optimal feature fusion scheme, and the resulting fusion feature vector will be trained and predicted using machine learning clusters for model training.
Results:
We evaluate the performance of DCM-GIFT on multiple datasets published at the Canadian Institute for Cybersecurity, the area under the accuracy, precision, recall and 
F
1
m
e
a
s
u
r
e
. The results show that the proposed DCM-GIFT model has significantly better prediction performance compared to other software classification models.
Conclusion:
It can be concluded that: (1) In terms of accuracy, precision, recall and 
F
1
m
e
a
s
u
r
e
, the DCM-GIFT model has a higher average value. (2) The DCM-GIFT model effectively solves the problem of imbalanced classification results in Android software. (3) The DCM-GIFT model achieves the goal of dynamic feature fusion and significantly improves the utilization of system resources.",December 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"DCM-GIFT proposes a method to identify Android malware more efficiently, which can significantly benefit early-stage ventures in terms of security and protection of properties."
https://www.sciencedirect.com/science/article/pii/S0950584924000971,Understanding the landscape of software modelling assistants for MDSE tools: A systematic mapping,David=Mosquera: mosq@zhaw.ch,"Abstract
Context
Model Driven Software Engineering (MDSE) and low-code/no-code software development tools promise to increase quality and productivity by modelling instead of coding software. One of the major advantages of modelling software is the increased possibility of involving diverse stakeholders since it removes the barrier of being IT experts to actively participate in software production processes. From an academic and industry point of view, the main question remains: What has been proposed to assist humans in software modelling tasks?
Objective
In this paper, we systematically elucidate the state of the art in assistants for software modelling and their use in MDSE and low-code/no-code tools.
Method
We conducted a systematic mapping to review the state of the art and answer the following research questions: i) how is software modelling assisted? ii) what goals and limitations do existing modelling assistance proposals report? iii) which evaluation metrics and target users do existing modelling assistance proposals consider? For this purpose, we selected 58 proposals from 3.176 screened records and reviewed 17 MDSE and low-code/no-code tools from main market players published by the Gartner Magic Quadrant.
Result
We clustered existing proposals regarding their modelling assistance strategies, goals, limitations, evaluation metrics, and target users, both in research and practice.
Conclusions
We found that both academic and industry proposals recognise the value of assisting software modelling. However, documentation about MDSE assistants’ limitations, evaluation metrics, and target users is scarce or non-existent. With the advent of artificial intelligence, we expect more assistants for MDSE and low-code/no-code software development will emerge, making imperative the need for well-founded frameworks for designing modelling assistants focused on addressing target users’ needs and advancing the state of the art.",September 2024,"Modelling assistance, Model-driven development, Systematic mapping, State of the practice, Low code, No-code",Information and Software Technology,2025-03-18T00:00:00,7.0,"The exploration of assistants for software modelling in MDSE and low-code/no-code tools can bring increased quality and productivity, which could be valuable for European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584924001666,A lot of talk and a badge: An exploratory analysis of personal achievements in GitHub,Fabio=Calefato: fabio.calefato@uniba.it,"Abstract
Context:
GitHub
 has introduced a new gamification element through personal achievements, whereby badges are unlocked and displayed on developers’ personal profile pages in recognition of their development activities.
Objective:
In this paper, we present an exploratory analysis using mixed methods to study the diffusion of personal badges in 
GitHub
, in addition to the effects and reactions to their introduction.
Method:
First, we conduct an observational study by mining longitudinal data from more than 6,000 developers and performed correlation and regression analysis. Then, we conduct a survey and analyze over 300 
GitHub
 community discussions on the topic of personal badges to gauge how the community responded to the introduction of the new feature.
Results:
We find that most of the developers sampled own at least a badge, but we also observe an increasing number of users who choose to keep their profile private and opt out of displaying badges. Additionally, badges are generally poorly correlated with developers’ skills and dispositions such as timeliness and desire to collaborate. We also find that, except for the 
Starstruck
 badge (reflecting the number of followers), their introduction does not have an effect. Finally, the reaction of the community has been in general mixed, as developers find them appealing in principle but without a clear purpose and hardly reflecting their abilities in the current form.
Conclusions:
We provide recommendations to the designers of the 
GitHub
platform on how to improve the current implementation of personal badges as both a gamification mechanism and as sources of reliable cues for assessing the abilities of developers.",December 2024,"Gamification, Achievements, Badges, Social translucence, Signaling theory, Open source software, Mining software repositories",Information and Software Technology,2025-03-18T00:00:00,3.0,"The study on personal badges in GitHub, while interesting, may not directly impact European early-stage ventures in a practical manner compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924001721,REARRANGE: Effort estimation approach for software clustering-based remodularisation,Alvin Jian Jia=Tan: alvin.tan@monash.edu; Chun Yong=Chong: chong.chunyong@monash.edu; Aldeida=Aleti: aldeida.aleti@monash.edu,"Abstract
Context:
Most research in software clustering and remodularisation typically concludes by recommending the refactoring operations without further insight into the practicality of the proposed technique. Developers might be hesitant to follow through with the refactoring suggestions due to the uncertainty in the effort needed.
Objective:
This work aims to address this gap by introducing an effo
R
t 
E
stimation 
A
pp
R
oach fo
R
 softw
A
re clusteri
NG
-based r
E
modularisation (REARRANGE) to close the loop in extant software clustering and remodularisation research by estimating the time required to carry out the suggested refactoring operations based on the history of the evolution of the software. By providing tangible estimates of refactoring effort in person-hours, we can inform developers of complex and time-consuming refactoring operations that will help prioritise refactoring efforts, allowing practitioners to weave in these activities during sprint planning.
Method:
REARRANGE builds a machine learning model to predict effort estimation based on past commit activity which extracts Software Features (lines of code, number of methods), Refactoring Features (refactoring type, source and destination) and Dependency Features (dependencies between classes). REARRANGE is then compared against sanity checks, baseline effort estimation models, and state-of-the-art software estimation models. We also attempt to cross-validate REARRANGE’s effort estimation with software developers.
Results:
Experimented through 25 open-source Java-based projects, the proposed approach estimated the refactoring effort of the test subjects with a Mean Absolute Error (MAE) of 5.47 person-hours against the MAE of the next-best approach of 453.31 person-hours. Based on a survey conducted among software developers, REARRANGE consistently delivers accurate estimates in 93.6% of cases.
Conclusion:
The lack of a direct comparison for REARRANGE highlights the need for a refactoring effort-focused estimation model that provides tangible effort estimates in person-hours for refactoring operations. Only then can developers selectively choose relevant refactoring operations while considering the available time and budget constraints, bridging the gap between software clustering research and real-world application.",December 2024,"Effort estimation, Software remodularisation, Software clustering, Refactoring",Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed REARRANGE approach provides tangible estimates of refactoring effort in person-hours, which can help developers prioritize refactoring efforts during sprint planning. It addresses a practical need in software clustering research and real-world application."
https://www.sciencedirect.com/science/article/pii/S0950584924001563,Sustainable systematic literature reviews,Vinicius=dos Santos: vinicius.dos.santos@icmc.usp.br,"Abstract
Context:
Systematic Literature Reviews (SLR) have been recognized as an important research method for summarizing evidence in Software Engineering (SE). At the same, SLR still presents several problems, such as the high resource consumption (mainly human resources) and lack of effective impact on SE practitioners, although much research has already been done.
Objective:
The main goal of this paper is to explore the concept of sustainability in the SLR area, intending to contribute to understanding better and solving such problems in an integrated way. More specifically, this paper characterizes what sustainable SLR are, their core characteristics, critical factors (i.e., sensitive points in the SLR process), and guidelines for conducting such SLR.
Methods:
We performed a meta-ethnographic study to find key concepts of sustainable software systems and transpose them to sustainable SLR. For this, we systematically selected 16 studies about sustainable software systems and 14 distinguished studies about SLR. Following, we extracted the main keywords and metaphors, determined how both areas are correlated, and transposed them to obtain a set of core characteristics of sustainable SLR as well as critical factors and guidelines. Additionally, we validated them with specialists using the Delphi method.
Results:
We found 15 core characteristics that offer a broad view of sustainable SLR, 15 critical factors in the SLR process that should be carefully addressed when conducting and updating SLR, and also 16 guidelines to manage SLR from the sustainability perspective.
Conclusion:
The concept of sustainability in SLR can contribute to solving SLR problems in a more integrated way, while this work could change the mindset of the SLR community about the need to conduct sustainable SLR.",December 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The exploration of sustainability in Systematic Literature Reviews (SLR) is valuable in understanding and solving problems, but may have limited immediate impact on European early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924001538,In memoriam of professor Guenther Ruhe: Contributions to the software product management research and practice,Andrey=Saltan: andrey.saltan@lut.fi,"Abstract
For many years, Guenther Ruhe was a fellow of the International Software Product Management Association, playing an important role in shaping the academic and practical landscapes of Software Product Management (SPM). This editorial note honors Ruhe's enduring impact on the SPM Body of Knowledge, evaluating his extensive contributions to SPM research and practice, and recognizing his legacy in shaping the future trajectory of the field. By examining Ruhe's academic publications and his role in developing the SPM Body of Knowledge, we highlight key areas of his influence, particularly in release planning and requirements engineering. His integration of empirical research into SPM has notably enhanced the discipline's rigor and relevance. Ruhe's contributions to the SPM Body of Knowledge are profound and far-reaching, establishing his work as a cornerstone for ongoing research and practice in SPM.",December 2024,"Software product management, Release planning, Requirements engineering, ISPMA",Information and Software Technology,2025-03-18T00:00:00,9.0,"The editorial note honoring Guenther Ruhe's impact on Software Product Management (SPM) demonstrates his significant contributions to the field, particularly in release planning and requirements engineering. His work serves as a cornerstone for ongoing research and practice in SPM."
https://www.sciencedirect.com/science/article/pii/S0950584924001587,A socio-technical perspective on software vulnerabilities: A causal analysis,Carlos=Paradis: cvas@acm.org,"Abstract
Context:
Software development organizations are composed of people working together towards a common goal. These people are connected in networks. The effectiveness of these networks seems like it would be an essential consideration for the effectiveness of the organization as a whole, but does network effectiveness actually matter?
Objective:
In this paper, we seek to understand whether causal relationships exist between the maintenance effort spent on files implicated in software vulnerabilities and suboptimal social behaviors – social smells – within that project’s developer community.
Methods:
To gain insight into this question, we chose to study OpenSSL and over 100 of its published vulnerabilities. We performed a socio-technical analysis on OpenSSL to understand whether social smells could be causally linked to the effort to maintain files implicated in vulnerabilities.
Results:
Our results indicate that this is the case: Social smells are, in fact, causally linked to the maintenance effort surrounding files implicated in software vulnerabilities.
Conclusion:
This result has significant implications for the management of software projects. These insights may motivate and help to guide project managers and architects to also focus on team communications, and not merely on technical quality measures such as bug rates or feature velocity. Social interactions among a project’s team members matter, and smells can be measured and monitored.",December 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on social smells and maintenance effort in software development projects provides insights into team dynamics and their impact on project management. While relevant, the practical application to early-stage ventures may not be as immediate as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924001319,A PRISMA-driven systematic mapping study on system assurance weakeners,Alvine B.=Belle: alvine.belle@lassonde.yorku.ca,"Abstract
Context:
An assurance case is a structured hierarchy of claims aiming at demonstrating that a mission-critical system supports specific requirements (e.g., safety, security, privacy). The presence of assurance weakeners (i.e., assurance deficits, logical fallacies) in assurance cases reflects insufficient evidence, knowledge, or gaps in reasoning. These weakeners can undermine confidence in assurance arguments, potentially hindering the verification of mission-critical system capabilities which could result in catastrophic outcomes (e.g., loss of lives). Given the growing interest in employing assurance cases to ensure that systems are developed to meet their requirements, exploring the management of assurance weakeners becomes beneficial.
Objective:
As a stepping stone for future research on assurance weakeners, we aim to initiate the first comprehensive systematic mapping study on this subject.
Methods:
We followed the well-established PRISMA 2020 and SEGRESS guidelines to conduct our systematic mapping study. We searched for primary studies in five digital libraries and focused on the 2012–2023 publication year range. Our selection criteria focused on studies addressing assurance weakeners from a qualitative standpoint, resulting in the inclusion of 39 primary studies in our systematic review.
Results:
Our systematic mapping study reports a taxonomy (map) that provides a uniform categorization of assurance weakeners and approaches proposed to manage them from a qualitative perspective. The taxonomy classifies weakeners in four categories: aleatory, epistemic, ontological, and argument uncertainty. Additionally, it classifies approaches supporting the management of weakeners in three main categories: representation, identification and mitigation approaches.
Conclusion:
Our study findings suggest that the SACM (Structured Assurance Case Metamodel) – a standard specified by the OMG (Object Management Group) – offers a comprehensive range of capabilities to capture structured arguments and reason about their potential assurance weakeners. Our findings also suggest novel assurance weakener management approaches should be proposed to better assure mission-critical systems.",November 2024,"Assurance cases, Assurance deficits, Uncertainty, Logical fallacies, PRISMA, GSN, SACM, Systematic mapping study, Cyber–physical systems, Safety, Reliability, Defeaters",Information and Software Technology,2025-03-18T00:00:00,7.0,"The systematic mapping study on assurance weakeners offers a comprehensive taxonomy and management approaches, which can benefit mission-critical system development, but lacks direct relevance to early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924001460,On meetings involving remote software teams: A systematic literature review,Anielle S.L.=de Andrade: anielle.lisboa@edu.pucrs,"Abstract
Context:
The adoption of remote work models and the global nature of software projects have significantly transformed collaboration and communication within the software development industry. Remote meetings have become a common means of collaboration for software development teams.
Objective:
This study seeks to enhance our understanding of remote meeting practices in software teams. It identifies the benefits of remote meetings, the problems associated with remote meetings, tools used to facilitate remote meetings and provides recommended good practices. The study employs a systematic literature review to assist remote teams in improving their meeting practices and identifying areas for future research.
Methods:
We conducted a systematic literature review that involved searching multiple databases and employing quantitative and qualitative analysis techniques on the identified set of studies to answer our research questions.
Results:
The search yielded 30 papers offering valuable insights into remote meeting practices in software teams. Remote meetings offer advantages over traditional in-person meetings such as increased effectiveness and ease of attendance. However, challenges exist such as technological issues, ineffective collaboration, and reduced team socialization. Identified good practices to mitigate the challenges include inserting breaks in longer meetings, catch-up time at the start of meeting, communicating goals in advance of the meeting, and pre-recording demos.
Conclusion:
The study explored remote meetings in software teams. We identified advantages that remote meetings have in comparison to in-person meetings, challenges to remote meetings, and good practices along with supportive tooling. While the practices help in promoting effective meetings, additional research is required to further improve remote meeting experiences. Researching topics such as investigating different types of meetings common to software development teams along with the potential for novel tools to better support meetings will help identify additional practices and tools that can benefit remote teams.",November 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The study on remote meeting practices in software teams provides practical insights and good practices that can directly benefit early-stage ventures by improving collaboration in remote work settings.
https://www.sciencedirect.com/science/article/pii/S0950584924001289,Fine-tuning and prompt engineering for large language models-based code review automation,Chakkrit=Tantithamthavorn: chakkrit@monash.edu; Chanathip=Pornprasit: chanathip.pornprasit@monash.edu,"Abstract
Context:
The rapid evolution of Large Language Models (LLMs) has sparked significant interest in leveraging their capabilities for automating code review processes. Prior studies often focus on developing LLMs for code review automation, yet require expensive resources, which is infeasible for organizations with limited budgets and resources. Thus, fine-tuning and prompt engineering are the two common approaches to leveraging LLMs for code review automation.
Objective:
We aim to investigate the performance of LLMs-based code review automation based on two contexts, i.e., when LLMs are leveraged by fine-tuning and prompting. Fine-tuning involves training the model on a specific code review dataset, while prompting involves providing explicit instructions to guide the model’s generation process without requiring a specific code review dataset.
Methods:
We leverage model fine-tuning and inference techniques (i.e., zero-shot learning, few-shot learning and persona) on LLMs-based code review automation. In total, we investigate 12 variations of two LLMs-based code review automation (i.e., GPT-3.5 and Magicoder), and compare them with the Guo et al.’s approach and three existing code review automation approaches (i.e., CodeReviewer, TufanoT5 and D-ACT).
Results:
The fine-tuning of GPT 3.5 with zero-shot learning helps GPT-3.5 to achieve 73.17%–74.23% higher EM than the Guo et al.’s approach. In addition, when GPT-3.5 is not fine-tuned, GPT-3.5 with few-shot learning achieves 46.38%–659.09% higher EM than GPT-3.5 with zero-shot learning.
Conclusions:
Based on our results, we recommend that (1) LLMs for code review automation should be fine-tuned to achieve the highest performance.; and (2) when data is not sufficient for model fine-tuning (e.g., a cold-start problem), few-shot learning without a persona should be used for LLMs for code review automation. Our findings contribute valuable insights into the practical recommendations and trade-offs associated with deploying LLMs for code review automation.",November 2024,"Modern code review, Code review automation, Large language models, GPT-3.5, Few-shot learning, Persona",Information and Software Technology,2025-03-18T00:00:00,8.0,"The investigation into leveraging LLMs for code review automation offers practical recommendations and trade-offs for improving code review processes, which can be valuable for early-stage ventures looking to optimize development workflows."
https://www.sciencedirect.com/science/article/pii/S0950584924000387,Multi-objective optimization and integrated indicator-driven two-stage project recommendation in time-dependent software ecosystem,Xin=Shen: shenxinpassion@163.com; Xiangjuan=Yao: yaoxj@cumt.edu.cn; Dunwei=Gong: dwgong@vip.163.com; Huijie=Tu: tb19080008b4@cumt.edu.cn,"Abstract
Context:
Time-dependent software ecosystem is a complex system, where there are many projects and developers. Recommending projects to developers in a time-dependent software ecosystem can improve their quality and development speeds. However, the time-dependence of projects and developers results in an increased difficulty of project recommendation.
Objective:
To better recommend projects to developers in a time-dependent software ecosystem, we propose a method of multi-objective optimization and integrated indicator-driven two-stage project recommendation, which is fulfilled according to the change of developer communities and their projects.
Method:
According to the change of developer communities and their projects, a method of multi-objective optimization and integrated indicator-driven two-stage project recommendation is fulfilled. In the first stage, a constrained multi-objective optimization model for project recommendation to developer communities is established, and an improved NSGA-II algorithm is adopted to solve this model, with the purpose of obtaining the recommended projects to a developer community. For the second stage, an integrated indicator for project recommendation to developers is built to determine the developers of a project.
Results:
The proposed method is applied to project recommendation for nine time-dependent software ecosystems in GitHub, and compared with six state-of-the-art ones. The experimental results show that our method has significant advantages in recommendation accuracy and efficiency.
Conclusion:
According to the experimental results, we conclude that the proposed method can timely and accurately recommend projects to developers in a time-dependent software ecosystem, which reduces the difficulty of solving the problem of project recommendation.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The method of multi-objective optimization for project recommendation in time-dependent software ecosystems is useful, but the direct practical application and impact on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924001290,An exploratory study on just-in-time multi-programming-language bug prediction,Peng=Liang: liangp@whu.edu.cn; Zengyang=Li: zengyangli@ccnu.edu.cn; Jiabao=Ji: jjb_coder@mails.ccnu.edu.cn; Ran=Mo: moran@ccnu.edu.cn; Hui=Liu: hliu@hust.edu.cn,"Abstract
Context:
An increasing number of software systems are written in multiple programming languages (PLs), which are called multi-programming-language (MPL) systems. MPL bugs (MPLBs) refers to the bugs whose resolution involves multiple PLs. Despite high complexity of MPLB resolution, there lacks MPLB prediction methods.
Objective:
This work aims to construct just-in-time (JIT) MPLB prediction models with selected prediction metrics, analyze the significance of the metrics, and then evaluate the performance of cross-project JIT MPLB prediction.
Methods:
We develop JIT MPLB prediction models with the selected metrics using machine learning algorithms and evaluate the models in within-project and cross-project contexts with our constructed dataset based on 18 Apache MPL projects.
Results:
Random Forest is appropriate for JIT MPLB prediction. Changed LOC of all files, added LOC of all files, and the total number of lines of all files of the project currently are the most crucial metrics in JIT MPLB prediction. The prediction models can be simplified using a few top-ranked metrics. Training on the dataset from multiple projects can yield significantly higherAUC than training on the dataset from a single project for cross-project JIT MPLB prediction.
Conclusions:
JIT MPLB prediction models can be constructed with the selected set of metrics, which can be reduced to build simplified JIT MPLB prediction models, and cross-project JIT MPLB prediction is feasible.",November 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The research addresses an important issue in bug prediction for multi-programming-language systems, which can be useful for startups dealing with such complexities."
https://www.sciencedirect.com/science/article/pii/S0950584924001320,Cross-Modal Retrieval-enhanced code Summarization based on joint learning for retrieval and generation,Lixuan=Li: 20224227057@stu.suda.edu.cn; Bin=Liang: bin.liang@cuhk.edu.hk; Lin=Chen: lchen@nju.edu.cn; Xiaofang=Zhang: xfzhang@suda.edu.cn,"Abstract
Context:
Code summarization refers to a task that automatically generates a natural language description of a code snippet to facilitate code comprehension. Existing methods have achieved satisfactory results by incorporating information retrieval into generative deep-learning models for reusing summaries of existing code. However, most of these existing methods employed non-learnable generic retrieval methods for content-based retrieval, resulting in a lack of diversity in the retrieved results during training, thereby making the model over-reliant on retrieved results and reducing the generative model’s ability to generalize to unknown samples.
Objective:
To address this issue, this paper introduces CMR-Sum: a novel Cross-Modal Retrieval-enhanced code Summarization framework based on joint learning for generation and retrieval tasks, where both two tasks are allowed to be optimized simultaneously.
Method:
Specifically, we use a cross-modal retrieval module to dynamically alter retrieval results during training, which enhances the diversity of the retrieved results and maintains a relative balance between the two tasks. Furthermore, in the summary generation phase, we employ a cross-attention mechanism to generate code summaries based on the alignment between retrieved and generated summaries. We conducted experiments on three real-world datasets, comparing the performance of our method with baseline models. Additionally, we performed extensive qualitative analysis.
Result:
Results from qualitative and quantitative experiments indicate that our approach effectively enhances the performance of code summarization. Our method outperforms both the generation-based and the retrieval-enhanced baselines. Further ablation experiments demonstrate the effectiveness of each component of our method. Results from sensitivity analysis experiments suggest that our approach achieves good performance without requiring extensive hyper-parameter search.
Conclusion:
The direction of utilizing retrieval-enhanced generation tasks shows great potential. It is essential to increase the diversity of retrieval results during the training process, which is crucial for improving the generality and the performance of the model.",November 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed CMR-Sum framework enhances code summarization performance significantly, which can have a positive impact on early-stage ventures in improving code comprehension."
https://www.sciencedirect.com/science/article/pii/S0950584924001332,SFIDMT-ART: A metamorphic group generation method based on Adaptive Random Testing applied to source and follow-up input domains,Zhihao=Ying: zhihao.ying2@nottingham.edu.cn; Dave=Towey: Dave.Towey@nottingham.edu.cn; Anthony Graham=Bellotti: Anthony-Graham.Bellotti@nottingham.edu.cn; Tsong Yueh=Chen: tychen@swin.edu.au; Zhi Quan=Zhou: zhiquan.zhou@gmail.com,"Abstract
Context:
The performance of metamorphic testing relates strongly to the quality of test cases. However, most related research has only focused on source test cases, ignoring follow-up test cases to some extent. In this paper, we identify a potential problem that may be encountered with existing metamorphic group generation algorithms. We then propose a possible solution to address this problem. Based on this solution, we design a new algorithm for generating effective source and follow-up test cases.
Objective:
To improve the performance (test effectiveness and efficiency) of metamorphic testing.
Methods:
We introduce the concept of the input-domain difference problem, which is likely to affect the performance of metamorphic group generation algorithms. We propose a new test-case distribution criterion for metamorphic testing to address this problem. Based on our proposed criterion, we further present a new metamorphic group generation algorithm, from a black-box perspective, with new distance metrics to facilitate this algorithm.
Results:
Our algorithm performs significantly better than existing algorithms, in terms of test effectiveness, efficiency and test-case diversity.
Conclusions:
Through experiments, we find that the input-domain difference problem is likely to affect the performance of metamorphic group generation algorithms. The experimental results demonstrate that our algorithm can achieve good test efficiency, effectiveness, and test-case diversity.",November 2024,"Metamorphic testing, Metamorphic group, Metamorphic relation, Adaptive random testing, Input domain",Information and Software Technology,2025-03-18T00:00:00,7.0,The development of a new algorithm for generating effective test cases in metamorphic testing can benefit startups in improving test effectiveness and efficiency.
https://www.sciencedirect.com/science/article/pii/S0950584924001502,FCTree: Visualization of function calls in execution,Ying=Zhao: zhaoying@csu.edu.cn,"Abstract
Function calls in execution contain rich bivariate, hierarchical, and chronological information. Many visualizations have been adopted to analyze function calls in execution for program testing, vulnerability locating, and malware detection. However, we conducted a pilot study and revealed that existing single-viewed function call visualizations fail to present the bivariate, hierarchical, and chronological information comprehensively. A new function call visualization named FCTree is proposed in this work to deal with this situation. Learned from advantages of existing visualizations and iterative discussions with actual users, FCTree uses a compact and aligned hierarchical layout design to present the bivariate and hierarchical information and adopts a glyph design to present the chronological information. Subjective and objective experiments in the laboratory and a field study in a real-world scenario were conducted to evaluate the effectiveness of FCTree.",November 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the FCTree visualization is innovative, its impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924000570,Case study identification with GPT-4 and implications for mapping studies,Kai=Petersen: kai.petersen@hs-flensburg.de,"Abstract
Context:
Rainer and Wohlin showed that 
case studies
 are not well understood by reviewers and authors and thus they say that a given research is a case study when it is not.
Objective:
Rainer and Wohlin proposed a smell indicator (inspired by code smells) to identify 
case studies
 based on the frequency of occurrences of words, which performed better than human classifiers. With the emergence of 
ChatGPT
, we evaluate ChatGPT to assess its performance in accurately identifying case studies. We also reflect on the results’ implications for mapping studies, specifically data extraction.
Method:
We used ChatGPT with the model GPT-4 to identify case studies and compared the result with the smell indicator for precision, recall, and accuracy.
Results:
GPT-4 and the smell indicator perform similarly, with GPT-4 performing slightly better in some instances and the smell indicator (SI) in others. The advantage of GPT-4 is that it is based on the definition of case studies and provides traceability on how it reaches its conclusions.
Conclusion:
As GPT-4 performed well on the task and provides traceability, we should use and, with that, evaluate it on data extraction tasks, supporting us as authors.",July 2024,"Systematic mapping studies, Data extraction, Case study, GPT-4",Information and Software Technology,2025-03-18T00:00:00,8.0,"The study evaluates the performance of ChatGPT in identifying case studies, which could have practical implications for mapping studies. The use of GPT-4 and traceability are valuable for authors in tasks like data extraction."
https://www.sciencedirect.com/science/article/pii/S0950584924001356,An empirical study on compatibility issues in Android API field evolution,Tarek=Mahmud: tarek_mahmud@txstate.edu; Meiru=Che: m.che@cqu.edu.au; Guowei=Yang: guowei.yang@uq.edu.au,"Abstract
Context:
The continuous evolution of the Android operating system requires regular API updates, which may affect the functionality of Android apps. This is becoming increasingly common due to the frequent evolution of the Android platform, which introduces new APIs and deprecates existing ones. Recent studies investigated API evolution to ensure the reliability of Android apps; however, they focused on API methods alone.
Objectives:
This study aims to understand how API fields evolve and how this affects API compatibility in real-world Android apps and their development.
Method:
We perform an empirical study on compatibility issues in Android API field evolution by analyzing the nature and resolution of these issues across 681 open-source Android apps.
Results:
Our experimental results yield interesting findings: (1) On average two API field compatibility issues exist per app in each tag; (2) Although API method evolution and API field evolution are related, current API method-level analysis techniques may fail to detect numerous API field compatibility issues; (3) Different types of checks are preferred when addressing different types of compatibility issues; (4) It takes on average three and a half months for an API field compatibility issue to get fixed since when it is introduced; (5) Developers pay proper attention to API field compatibility issues and address them soon after becoming aware of them in the apps.
Conclusion:
These findings highlight the significance of including API fields in future research on API evolution and can assist developers and researchers in understanding, detecting, and handling compatibility issues in API field evolution.",November 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides valuable insights into API field evolution in Android apps, which can help developers in understanding and addressing compatibility issues."
https://www.sciencedirect.com/science/article/pii/S0950584924001472,A rule-based decision model to support technical debt decisions: A multiple case study of web and mobile app startups,Abdullah=Aldaeej: aaaldaeej@iau.edu.sa,"Abstract
Context
Software startups are immature software organizations that focus on the development of a single software product or service. This organizational context accumulates a lot of technical debt to cope with constraints such as limited resources and product-market fit uncertainty. While some research has explored technical debt in startups, there is no study that investigates how software startups should make technical debt decisions throughout the startup evolution stages.
Objective
The objective of this study is to understand how technical debt decisions are made, and how such decisions should have been made in hindsight.
Method
We conducted a multiple embedded case study to investigate technical debt decisions in five web/mobile app startups. For each case, we interviewed the case founder and developer (a total of 17 participants across cases). In addition, we collected some public documents about the five startups. The data were analyzed using qualitative data analysis techniques.
Results
We developed a rule-based decision model that summarizes the logic to effectively make technical debt decisions throughout the startup evolution stages. In addition, we evaluated the model by conducting follow-up interviews with three participants.
Conclusion
The study provides a decision model that reflects actual practice, and is designed to help software teams in startups when making technical debt decisions throughout the startup evolution stages.",November 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The decision model developed in this study can assist software teams in startups in making technical debt decisions throughout the startup evolution stages, providing practical guidance."
https://www.sciencedirect.com/science/article/pii/S0950584924001344,Qubernetes: Towards a unified cloud-native execution platform for hybrid classic-quantum computing,Vlad=Stirbu: vlad.a.stirbu@jyu.fi,"Abstract
Context:
The emergence of quantum computing proposes a revolutionary paradigm that can radically transform numerous scientific and industrial application domains. The ability of quantum computers to scale computations beyond what the current computers are capable of implies better performance and efficiency for certain algorithmic tasks.
Objective:
However, to benefit from such improvement, quantum computers must be integrated with existing software systems, a process that is not straightforward. In this paper, we propose a unified execution model that addresses the challenges that emerge from building hybrid classical-quantum applications at scale.
Method:
Following the Design Science Research methodology, we proposed a convention for mapping quantum resources and artifacts to Kubernetes concepts. Then, in an experimental Kubernetes cluster, we conducted experiments for scheduling and executing quantum tasks on both quantum simulators and hardware.
Results:
The experimental results demonstrate that the proposed platform Qubernetes (or Kubernetes for quantum) exposes the quantum computation tasks and hardware capabilities following established cloud-native principles, allowing seamless integration into the larger Kubernetes ecosystem.
Conclusion:
The quantum computing potential cannot be realized without seamless integration into classical computing. By validating that it is practical to execute quantum tasks in a Kubernetes infrastructure, we pave the way for leveraging the existing Kubernetes ecosystem as an enabler for hybrid classical-quantum computing.",November 2024,"Quantum software, Hybrid classical-quantum software, Containers, Quantum software development lifecycle, Cloud-native computing",Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed unified execution model for hybrid classical-quantum applications in Kubernetes demonstrates a significant step towards realizing the potential of quantum computing, which can have a transformative impact on various industries."
https://www.sciencedirect.com/science/article/pii/S0950584924001277,GitHub marketplace for automation and innovation in software production,SK. Golam=Saroar: saroar@yorku.ca; Waseefa=Ahmed: waseefa@yorku.ca; Elmira=Onagh: eonagh@yorku.ca; Maleknaz=Nayebi: mnayebi@yorku.ca,"Abstract
Context:
GitHub, renowned for facilitating collaborative code version control and software production in software teams, expanded its services in 2017 by introducing GitHub Marketplace. This online platform hosts automation tools to assist developers with the production of their GitHub-hosted projects, and it has become a valuable source of information on the tools used in the 
Open Source Software
 (OSS) community.
Objective:
In this 
exploratory study
, we introduce GitHub Marketplace as a software marketplace by exploring the Characteristics, Features, and Policies of the platform comprehensively, identifying common themes in production automation. Further, we explore popular tools among practitioners and researchers and highlight disparities in the approach to these tools between industry and academia.
Method:
We adopted the conceptual framework of software app stores from previous studies and used that to examine 8,318 automated production tools (440 Apps and 7,878 Actions) across 32 categories on GitHub Marketplace. We explored and described the policies of this marketplace as a unique platform where developers share production tools for the use of other developers. Furthermore, we conducted a 
systematic mapping
 of 515 research papers published from 2000 to 2021 and compared open-source academic production tools with those available in the marketplace.
Results:
We found that although some of the automation topics in literature are widely used in practice, they have yet to align with the state-of-practice for automated production. We discovered that practitioners often use automation tools for tasks like “Continuous Integration” and “Utilities”, while researchers tend to focus more on “Code Quality” and “Testing”.
Conclusion:
Our study illuminates the landscape of open-source tools for automation production. We also explored the disparities between industry trends and researchers’ priorities. Recognizing these distinctions can empower researchers to build on existing work and guide practitioners in selecting tools that meet their specific needs. Bridging this gap between industry and academia helps with further innovation in the field and ensures that research remains pertinent to the evolving challenges in software production.",November 2024,"Software engineering, Platform-mediated, GitHub marketplace, Automation, GitHub actions, Production",Information and Software Technology,2025-03-18T00:00:00,6.0,"The research sheds light on the disparities between industry and academia in using automation tools, which can be informative for both researchers and practitioners in selecting tools aligned with their needs."
https://www.sciencedirect.com/science/article/pii/S0950584924001083,Analysing the synergies between Multi-agent Systems and Digital Twins: A systematic literature review,Elena=Navarro: elena.navarro@uclm.es,"Abstract
Context
Digital Twins
 (DTs) are used to augment physical entities by exploiting assorted 
computational approaches
 applied to the virtual twin counterpart. A DT is generally described as a physical entity, its virtual counterpart, and the data connections between them. Multi-Agent Systems (MAS) paradigm is alike DTs in many ways. Agents of MAS are entities operating and interacting in a specific environment, while exploring and 
collecting data
 to solve some tasks.
Objective
This paper presents the results of a systematic literature review (SLR) focused on the analysis of current proposals exploiting the synergies of DTs and MAS. This research aims to synthesize studies that focus on the use of MAS to support DTs development and MAS that exploit DTs, paving the way for future research.
Method
A SLR methodology was used to conduct a detailed study analysis of 64 primary studies out of a total of 220 studies that were initially identified. This SLR analyses three research questions related to the synergies between MAS and DT.
Results
The most relevant findings of this SLR and their implications for further research are the following: i) most of the analyzed proposals design digital shadows rather than DT; ii) they do not fully support the properties expected from a DT; iii) most of the MAS properties have not fully exploited for the development of DT; iv) ontologies are frequently used for specifying semantic models of the physical twin.
Conclusions
Based on the results of this SLR, our conclusions for the community are presented in a 
research agenda
 that highlights the need of innovative theoretical proposals and design frameworks that guide the development of DT. They should be defined exploiting the properties of MAS to unleash the full potential of DT. Finally, ontologies for 
machine learning
 models should be designed for its use in DT.",October 2024,"Digital twin, Multi-agent system, MAS, Literature review, Internet of Things",Information and Software Technology,2025-03-18T00:00:00,7.0,"The research addresses the synergies between DTs and MAS, providing insights and future research directions. It can be valuable for early-stage ventures looking to innovate in these areas."
https://www.sciencedirect.com/science/article/pii/S095058492400106X,Reporting case studies in systematic literature studies—An evidential problem,Claes=Wohlin: claes.wohlin@bth.se,"Abstract
Context:
The term and label, “case study”, is not used consistently by authors of primary studies in 
software engineering
 research. It is not clear whether this problem also occurs for systematic literature studies (SLSs).
Objective:
To investigate the extent to which SLSs in/correctly use the term and label, “case study”, when classifying primary studies.
Methods:
We systematically collect two sub-samples (2010–2021 & 2022) comprising a total of eleven SLSs and 79 primary studies. We examine the designs of these SLSs, and then analyse whether the SLS authors and the primary-study authors correctly label the respective primary study as a “case study”.
Results:
76% of the 79 primary studies are misclassified by SLSs (with the two sub-samples having 60% and 81% 
misclassification
, respectively). For 39% of the 79 studies, the SLSs propagate a mislabelling by the original authors, whilst for 37%, the SLSs introduce a new mislabel, thus making the problem worse. SLSs rarely present explicit definitions for “case study” and when they do, the definition is not consistent with established definitions.
Conclusions:
SLSs are both propagating and exacerbating the problem of the mislabelling of primary studies as “case studies”, rather than – as we should expect of SLSs – correcting the labelling of primary studies, and thus improving the body of credible evidence. Propagating and exacerbating mislabelling undermines the credibility of evidence in terms of its quantity, quality and relevance to both practice and research.",October 2024,"Systematic mapping study, Systematic review, Systematic literature review, Case study, Credible evidence",Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on mislabeling of case studies in SLSs may have limited immediate practical impact on early-stage ventures in Europe, but could contribute to the reliability of software engineering research."
https://www.sciencedirect.com/science/article/pii/S0950584924001058,Multi-objective model transformation chain exploration with MOMoT,Martin=Eisenberg: eisenberg.martin@jku.at; Apurvanand=Sahay: a_sahay@blr.amrita.edu; Davide=Di Ruscio: davide.diruscio@univaq.it; Ludovico=Iovino: ludovico.iovino@gssi.it; Manuel=Wimmer: manuel.wimmer@jku.at; Alfonso=Pierantonio: alfonso.pierantonio@univaq.it,"Abstract
Context:
The increasing complexity of modern systems leads to an increasing amount of artifacts that are used along the model-based software and systems 
development lifecycle
. This also includes model transformations, which serve for mapping models between representations, e.g., for verification and validation purposes.
Objectives:
Model repositories
 manage this variety of artifacts and promote 
reusability
, but should also enable the bundling of compatible artifacts. Therefore, model transformations should be reused and arranged into 
transformation chains
 to support more complex transformation scenarios. The resulting transformation should correspond to the user’s interest in terms of quality criteria such as model coverage, transformation coverage, and number of transformation steps, thus assembling such chains becomes a multi-objective problem.
Methods:
A novel multi-objective approach for exploring possible transformation chains residing in model repositories is presented. MOMoT, a model-driven optimization framework, is leveraged to explore the transformation space spanned by the repository. For demonstration, three differently populated repositories are considered.
Results:
We have extended MOMoT with an exhaustive, multi-objective search that explores the entire model transformation space defined by graph 
transformation rules
, allowing all possible transformation chains to be considered as solution. Accordingly, the optimal solutions were identified in the demonstration cases with negligible 
computation time
.
Conclusion:
The approach assists modelers when there are multiple chains for transforming an input model to a specified output model to consider. Our evaluation shows that the approach elicits all legitimate transformation chains, thus enabling the modelers to consider trade-offs in view of multiple criteria selection.",October 2024,"Model-driven optimization, Transformation chain, Multi-objective graph traversal, Model repository",Information and Software Technology,2025-03-18T00:00:00,6.0,"The research on multi-objective model transformation chains could be beneficial for startups involved in model-based software development, offering a new approach for managing complexity."
https://www.sciencedirect.com/science/article/pii/S0950584924001174,SENEM: A software engineering-enabled educational metaverse,Viviana=Pentangelo: vpentangelo@unisa.it; Dario=Di Dario: ddidario@unisa.it; Stefano=Lambiase: slambiase@unisa.it; Filomena=Ferrucci: fferrucci@unisa.it; Carmine=Gravino: gravino@unisa.it; Fabio=Palomba: fpalomba@unisa.it,"Abstract
Context:
The term metaverse refers to a persistent, virtual, three-dimensional environment where individuals may communicate, engage, and collaborate. One of the most multifaceted and challenging use cases of the metaverse is education, where educators and learners may require multiple technical, social, psychological, and interaction instruments to accomplish their learning objectives. While the characteristics of the metaverse might nicely fit the problem’s needs, our research points out a noticeable lack of knowledge into (1) the specific requirements that an educational metaverse should actually fulfill to let educators and learners successfully interact towards their objectives and (2) how to design an appropriate educational metaverse for both educators and learners.
Objective:
In this paper, we aim to bridge this knowledge gap by proposing 
SENEM
, a novel software engineering-enabled educational metaverse. We first elicit a set of functional requirements that an educational metaverse should fulfill.
Method:
In this respect, we conduct a literature survey to extract the currently available knowledge on the matter discussed by the research community, and afterward, we assess and complement such knowledge through semi-structured interviews with educators and learners. Upon completing the 
requirements elicitation
 stage, we then build our prototype implementation of 
SENEM
, a metaverse that makes available to educators and learners the features identified in the previous stage. Finally, we evaluate the tool in terms of learnability, efficiency, and satisfaction through a Rapid Iterative Testing and Evaluation research approach, leading us to the iterative refinement of our prototype.
Results:
Through our survey strategy, we extracted nine requirements that guided the tool development that the study participants positively evaluated.
Conclusion:
Our study reveals that the target audience appreciates the elicited design strategy. Our work has the potential to form a solid contribution that other researchers can use as a basis for further improvements.",October 2024,"Metaverse engineering, Virtual learning environments, Human-centered studies, Software engineering in practice",Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposal of SENEM, an educational metaverse, has high practical value for startups in the education technology space. The detailed methodology and positive evaluation results make it a promising innovation."
https://www.sciencedirect.com/science/article/pii/S0950584924001071,On current limitations of online eye-tracking to study the visual processing of source code,Eva=Thilderkvist: evth1400@student.miun.se; Felix=Dobslaw: felix.dobslaw@miun.se,"Abstract
Context:
Eye-tracking is an increasingly popular instrument to study how programmers process and comprehend 
source code
. While most studies are conducted in controlled environments with lab-grade hardware, it would be desirable to simplify and scale participation in experiments for users sitting remotely, leveraging home equipment.
Objective:
This study investigates the possibility of performing eye-tracking studies remotely using open-source algorithms and consumer-grade webcams. It establishes the technology’s current limitations and evaluates the quality of the 
data collected
 by it. We conclude by recommending ways forward to address the shortcomings and make remote code-reading studies in support of eye-tracking feasible in the future.
Method:
We gathered eye-gaze data remotely from 40 participants performing a code reading experiment on a purpose-built web application. The utilized eye-tracker worked client-side and used ridge regression to generate x- and y-coordinates in real-time predicting the participants’ on-screen gaze points without the need to collect and save video footage. We processed and analysed the collected data according to 
common practices
 for isolating eye-movement events and deriving metrics used in 
software engineering
 eye-tracking studies. In response to the lack of an algorithm explicitly developed for detecting oculomotor fixation events in low-frequency webcam data, we also introduced a dispersion 
threshold algorithm
 for that purpose. The quality of the collected data was subsequently assessed to determine the adequacy and validity of the methodology for eye-tracking.
Results:
The collected data was found to be of varying quality despite extensive calibration and graphical user guidance. We present our results highlighting both the negative and positive observations from which the community hopefully can learn. Both accuracy and precision were low and ultimately deemed insufficient for drawing valid conclusions in a high-precision empirical study. We nonetheless contribute to identifying critical limitations to be addressed in future research. Apart from the overall challenge of vastly diverse equipment, setup, and configuration, we found two main problems with the current webcam eye-tracking technology. The first was the 
absence
 of a validated algorithm to isolate fixations in low-frequency data, compromising the assurance of the accuracy of the data derived from it. The second problem was the lack of algorithmic support for head movements when predicting gaze location. Unsupervised participants do not always keep their heads still, even if instructed to do so. Consequently, we frequently observed spatial shifts that corrupted many collected datasets. Three encouraging observations resulted from the study. Even when shifted, gaze points were consistently dispersed in patterns resembling both the shape and size of the stimuli without extreme deviations. We could also distinguish recognizable reading patterns. Linearity was significantly different when participants were reading source code compared to natural text, and we could detect the expected left-to-right and top-to-bottom reading directions for participants reading natural text snippets.
Conclusion:
The accuracy and precision levels were not sufficient for a word-by-word analysis of code reading but could be adequate for a broader, coarse-grained precision study. Additionally we identified two main issues compromising the collected data validity and contributed a fixation 
detection algorithm
 to approach one of these issues. With suitable solutions to the identified issues, remote eye-tracking studies with webcams on code reading could eventually be feasible.",October 2024,"Eye-tracking, Code comprehension, Webcam, Online experiment, Fixation algorithm",Information and Software Technology,2025-03-18T00:00:00,7.0,"This abstract presents a study on remote eye-tracking using consumer-grade webcams for code reading experiments, highlighting limitations and potential solutions. While the findings have practical implications for software engineering research, the impact on early-stage ventures is moderate."
https://www.sciencedirect.com/science/article/pii/S0950584924001162,Measuring and improving software testability at the design level,Saeed=Parsa: parsa@iust.ac.ir,"Abstract
Context
The quality of software systems is significantly influenced by design testability, an aspect often overlooked during the initial phases of software development. The implementation may deviate from its design, resulting in decreased testability at the integration and unit levels.
Objective
The objective of this study is to automatically identify low-testable parts in object-orientated design and enhance them by refactoring to 
design patterns
. The impact of various design metrics mainly coupling (
e.g.
, fan-in and fan-out) and inheritance (
e.g.
, depth of inheritance tree and number of subclasses) metrics on design testability is measured to select the most appropriate refactoring candidates.
Method
The methodology involves creating a machine learning model for design testability prediction using a large dataset of Java classes, followed by developing an automated refactoring tool. The design classes are vectorized by ten design metrics and labeled with testability scores calculated from a mathematical model. The model computes testability based on code coverage and test suite size of classes that have already been tested via automatic tools. A voting 
regressor
 model is trained to predict the design testability of any class diagram based on these design metrics. The proposed refactoring tool for dependency injection and factory method is applied to various open-source Java projects, and its impact on design testability is assessed.
Results
The proposed design testability model demonstrates its effectiveness by satisfactorily predicting design testability, as indicated by a mean squared error of 0.04 and an R
2
 score of 0.53. The automated refactoring tool has been successfully evaluated on six open-source Java projects, revealing an enhancement in design testability by up to 19.11 %.
Conclusion
The proposed automated approach offers software developers the means to continuously evaluate and enhance design testability throughout the entire software development life cycle, mitigating the risk of testability issues stemming from design-to-implementation discrepancies.",October 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"This abstract introduces an automated approach to identify and refactor low-testable parts in object-oriented design, significantly enhancing design testability. The practical value for early-stage ventures and startups is high as it offers a solution to mitigate risks arising from design-to-implementation discrepancies."
https://www.sciencedirect.com/science/article/pii/S0950584924001228,A vulnerability detection framework by focusing on critical execution paths,Jianxin=Cheng: jianxin@stu.pku.edu.cn; Hanpin=Wang: whpxhy@pku.edu.cn,"Abstract
Context:
Vulnerability detection
 is critical to ensure software security, and detecting vulnerabilities in 
smart contract
 code is currently gaining massive attention. Existing deep learning-based vulnerability detection methods represent the code as a code structure graph and eliminate vulnerability-irrelevant nodes. Then, they learn vulnerability-related code features from the simplified graph for vulnerability detection. However, this simplified graph struggles to represent relatively complete structural information of code, which may affect the performance of existing vulnerability detection methods.
Objective:
In this paper, we present a novel 
V
ulnerability 
D
etection framework based on 
C
ritical 
E
xecution 
P
aths (VDCEP), which aims to improve 
smart contract
 vulnerability detection.
Method:
Firstly, given a code structure graph, we deconstruct it into multiple execution paths that reflect rich structural information of code. To reduce irrelevant code information, a path selection strategy is employed to identify critical execution paths that may contain vulnerable code information. Secondly, a feature extraction module is adopted to learn feature representations of critical paths. Finally, we feed all path feature representations into a classifier for vulnerability detection. Also, the feature weights of paths are provided to measure their importance in vulnerability detection.
Results:
We evaluate VDCEP on a large dataset with four types of smart contract vulnerabilities. Results show that VDCEP outperforms 14 representative vulnerability detection methods by 5.34%–60.88% in F1-score. The ablation studies analyze the effects of our path selection strategy and feature extraction module on VDCEP. Moreover, VDCEP still outperforms 
ChatGPT
 by 34.46% in F1-score.
Conclusion:
Compared to existing vulnerability detection methods, VDCEP is more effective in detecting smart contract vulnerabilities by utilizing critical execution paths. Besides, we can provide interpretable details about vulnerability detection by analyzing the path feature weights.",October 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract presents a novel vulnerability detection framework for smart contract code based on critical execution paths, outperforming existing methods significantly. The impact on European early-stage ventures is substantial as it addresses a critical aspect of software security in the context of blockchain technology."
https://www.sciencedirect.com/science/article/pii/S0950584924001150,SeDPGK: Semi-supervised software defect prediction with graph representation learning and knowledge distillation,Wangshu=Liu: liuws0707@gmail.com,"Abstract
Context:
Constructing an effective 
defect prediction
 model relies on a substantial number of labeled program modules. Unfortunately, program module labeling is often time-consuming and error-prone. Semi-supervised 
software defect
 prediction (SSDP) can alleviate this issue by incorporating some labeled modules and the remaining unlabeled modules from the same project.
Objective:
However, previous SSDP methods ignore the significant influence of dependencies between software modules. The potential of 
knowledge distillation
 in leveraging labeled instances to guide the learning process and effectively utilizing information from unlabeled instances to improve SSDP performance has not been fully investigated.
Method:
We propose a novel approach SeDPGK. Specifically, to exploit the graph-structured knowledge, we first construct the program 
dependence graph
 to extract control and 
data dependencies
 among modules. Then we use 
graph neural networks
 (GNNs) to learn the 
graph representation
 of the module relationships and encode with the statement semantics of abstract syntax 
tree
 and traditional static features for diversity. Second, we integrate multiple GNNs jointly trained as teacher models to ensemble various styles of graph-based networks and generate trustworthy labels for unlabeled modules. Further, to preserve the teacher model’s sufficient structure and 
semantic knowledge
, we adopt a trainable label propagation and multi-layer perception as the student model and mitigate the differences between the teacher and student models using two widespread 
knowledge distillation
 functions.
Results:
We conducted our experiments on 17 real-world projects. The experimental results show that SeDPGK outperforms semi-supervised baselines with an average improvement of 16.9% for 
PD
, 42.5% for 
FAR
, and 8.9% for AUC, respectively. Moreover, the 
performance improvement
 is consistently significant across multiple statistical tests.
Conclusion:
The effectiveness of SeDPGK comes from the aggregation of the different GNNs with heterogeneity. Moreover, the graph structure and 
semantic features
 hidden behind the 
source code
 play a crucial role in the distillation framework.",October 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"This abstract introduces a novel approach SeDPGK for semi-supervised software defect prediction, demonstrating significant performance improvement across real-world projects. The practical value for early-stage ventures is high as it offers an effective solution to improve software quality and reduce manual labeling effort."
https://www.sciencedirect.com/science/article/pii/S095058492400123X,Are your apps accessible? A GCN-based accessibility checker for low vision users,Mengxi=Zhang: zmx19@mails.jlu.edu.cn; Huaxiao=Liu: liuhuaxiao@jlu.edu.cn; Shenning=Song: songsz22@mails.jlu.edu.cn; Chunyang=Chen: chun-yang.chen@tum.de; Pei=Huang: huangpei@stanford.edu; Jian=Zhao: zhaojian@ccu.edu.cn,"Abstract
Context:
Accessibility issues (e.g., small size and narrow interval) in mobile applications (apps) lead to obstacles for billions of low vision users in interacting with Graphical User Interfaces (GUIs). Although GUI accessibility scanning tools exist, most of them perform rule-based check relying on complex GUI hierarchies. This might make them detect invisible redundant information, cannot handle small deviations, omit similar components, and is hard to extend.
Objective:
In this paper, we propose a novel approach, named ALVIN (Accessibility Checker for Low Vision), which represents the GUI as a graph and adopts the 
Graph Convolutional Neural Networks
 (GCN) to label inaccessible components.
Method:
ALVIN removes invisible views to prevent detecting redundancy and uses annotations from low vision users to handle small deviations. Also, the 
GCN model
 could consider the relations between GUI components, connecting similar components and reducing the possibility of omission. ALVIN only requires users to annotate the relevant dataset when detecting new kinds of issues.
Results:
Our experiments on 48 apps demonstrate the effectiveness of ALVIN, with precision of 83.5%, recall of 78.9%, and F1-score of 81.2%, outperforming 
baseline methods
. In RQ2, the usefulness is verified through 20 issues submitted to open-source apps. The RQ3 also illustrates the 
GCN model
 is better than other models.
Conclusion:
To summarize, our proposed approach can effectively detect accessibility issues in GUIs for low vision users, thereby guiding developers in fixing them efficiently.",October 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"This abstract presents ALVIN, a novel approach for detecting accessibility issues in GUIs for low vision users using GCN. While the findings have implications for mobile app development, the direct impact on European early-stage ventures is moderate."
https://www.sciencedirect.com/science/article/pii/S0950584924001204,Feature envy detection based on cross-graph local semantics matching,Dongjin=Yu: yudj@hdu.edu.cn,"Abstract
Context:
As a typical code smell, feature envy occurs when a method exhibits excessive reliance and usage on specific functionalities of another class, which can lead to issues with the 
maintainability
 and extensibility of the code. As such, detecting and avoiding feature envy is critical for software development. Previous research on detecting feature envy has demonstrated significant advantages of deep learning-based approaches over 
static code analysis tools
. However, current deep learning-based approaches still suffer from two limitations: (1) They focus on the functional or overall semantics of the code, which ignores the opportunities for local code semantics matching, making it challenging to identify some more complex cases; (2) Existing feature envy datasets are collected or synthesized using 
static code analysis tools
, which limits feature envy cases to fixed rules and makes it challenging to cover other complex cases in real projects.
Objective:
We are motivated to propose a Siamese 
graph neural network
 based on code local semantics matching and collect feature envy refactoring cases from real projects for experimental evaluation.
Method:
To address the first issue, we propose a cross-graph local semantics 
matching network
, which aims to simulate human intuition or experience to detect feature envy by analyzing the local semantics matching between code graphs. To address the second one, we manually review and collect commits for refactoring feature envy cases on GitHub. Then, we refer to image 
data augmentation
 technology to construct two datasets for identifying feature envy and recommending 
Move Method
 refactorings, respectively.
Results:
Extensive experiments show that our approach outperforms state-of-the-art baselines regarding both tasks’ comprehensive metrics, F1-score and AUC.
Conclusion:
The experimental results indicate that the proposed Siamese 
graph neural network
 based on code local semantics matching is effective. In addition, the provided 
data augmentation
 algorithms can significantly improve model performance.",October 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed Siamese graph neural network addresses existing limitations in detecting feature envy, providing significant advantages over current approaches. The data augmentation techniques also contribute to improving model performance, offering practical value to software development in early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924001216,Product managers in software startups: A grounded theory,Jorge=Melegati: jorge.melegati@unibz.it,"Abstract
Context:
Defining and designing a software product is not merely a technical endeavor, but also a socio-technical journey. As such, its success is associated with human-related aspects, such as the value users perceive. To handle this issue, the product manager role has become more evident in software-intensive companies. A unique, challenging context for these professionals is constituted by software startups, emerging companies developing novel solutions looking for sustainable and scalable business models.
Objective:
This study aims to describe the role of product managers in the context of software startups.
Method:
We performed a Socio-Technical 
Grounded Theory
 study using data from blog posts and interviews.
Results:
The results describe the product manager as a multidisciplinary, general role, not only guiding the product by developing its vision but also as a connector that emerges in a growing company, enabling communication of software development with other areas, mainly business and 
user experience
. The professional performing this role has a background in one of these areas but a broad knowledge and understanding of key concepts of the other areas is needed. We also describe how differences of this role to other lead roles are perceived in practice.
Conclusions:
Our findings represent several implications for research, such as better understanding of the role transformation in growing software startups, practice, e.g., identifying the points to which a professional migrating to this role should pay attention, and the education of future software developers, by suggesting the inclusion of related topics in the education and training of future software engineers.",October 2024,"Product manager, Software startup, Product management, Agile software development, Socio-technical systems, Grounded theory",Information and Software Technology,2025-03-18T00:00:00,5.0,"While describing the role of product managers in software startups is informative, the practical implications for early-stage ventures are limited compared to other abstracts. It offers insights into the multidisciplinary nature of the role but may not directly impact or benefit startups' growth and development significantly."
https://www.sciencedirect.com/science/article/pii/S0950584924001253,CausalOps — Towards an industrial lifecycle for causal probabilistic graphical models,Robert=Maier: robert.maier@othr.de; Andreas=Schlattl: Andreas.Schlattl@efs-techhub.com; Thomas=Guess: Thomas.Guess@efs-techhub.com; Jürgen=Mottok: juergen.mottok@othr.de,"Abstract
Context:
Causal probabilistic graph-based models have gained widespread utility, enabling the modeling of cause-and-effect relationships across diverse domains. With their rising adoption in new areas, such as safety analysis of complex systems, 
software engineering
, and 
machine learning
, the need for an integrated lifecycle framework akin to 
DevOps
 and MLOps has emerged. Currently, such a reference for organizations interested in employing causal engineering is missing. This lack of guidance hinders the incorporation and maturation of causal methods in the context of real-life applications.
Objective:
This work contextualizes causal model usage across different stages and stakeholders and outlines a holistic view of creating and maintaining them within the process landscape of an organization.
Methods:
A novel lifecycle framework for causal model development and application called CausalOps is proposed. By defining key entities, dependencies, and intermediate artifacts generated during causal engineering, a consistent vocabulary and workflow model to guide organizations in adopting causal methods are established.
Results:
Based on the early adoption of the discussed methodology to a real-life problem within the automotive domain, an experience report underlining the practicability and challenges of the proposed approach is discussed.
Conclusion:
It is concluded that besides current technical advancements in various aspects of causal engineering, an overarching lifecycle framework that integrates these methods into organizational practices is missing. Although diverse skills from adjacent disciplines are widely available, guidance on how to transfer these assets into causality-driven practices still need to be addressed in the published literature. CausalOps’ aim is to set a baseline for the adoption of causal methods in practical applications within interested organizations and the causality community.",October 2024,"Causal engineering, Model lifecycle, MLOps, Causal graphical models",Information and Software Technology,2025-03-18T00:00:00,8.0,"The development of a novel lifecycle framework, CausalOps, for causal model usage provides a practical guide for organizations interested in employing causal engineering. The framework's aim to integrate causal methods into organizational practices fills a gap in the field, offering significant value to startups seeking to incorporate causal methods in their processes."
https://www.sciencedirect.com/science/article/pii/S0950584924000946,The impact of human aspects on the interactions between software developers and end-users in software engineering: A systematic literature review,John=Grundy: john.grundy@monash.edu; Hashini=Gunatilake: hashini.gunatilake@monash.edu; Rashina=Hoda: rashina.hoda@monash.edu; Ingo=Mueller: ingo.mueller@monash.edu,"Abstract
Context:
Research on human aspects within the field of 
software engineering
 (SE) has been steadily gaining prominence in recent years. These human aspects have a significant impact on SE due to the inherently interactive and 
collaborative nature
 of the discipline.
Objective:
In this paper, we present a systematic literature review (SLR) on human aspects affecting developer-user interactions. The objective of this SLR is to plot the current landscape of primary studies by examining the human aspects that influence developer-user interactions, their implications, interrelationships, and how existing studies address these implications.
Method:
We conducted this SLR following the guidelines proposed by Kitchenham et al. We performed a comprehensive search in six digital databases, and an exhaustive backward and forward snowballing process. We selected 46 primary studies for data extraction.
Results:
We identified various human aspects affecting developer-user interactions in SE, assessed their interrelationships, identified their positive impacts and 
mitigation strategies
 for negative effects. We present specific recommendations derived from the identified research gaps.
Conclusion:
Our findings suggest the importance of leveraging positive effects and addressing negative effects in developer-user interactions through the implementation of effective mitigation strategies. These insights may benefit software practitioners for effective user interactions, and the recommendations proposed by this SLR may aid the research community in further human aspects related studies.",September 2024,"Systematic literature review, Human aspects, Software developers, Software users, Software engineering",Information and Software Technology,2025-03-18T00:00:00,6.0,"The systematic literature review on human aspects affecting developer-user interactions provides insights that may benefit software practitioners, but the practical application for early-stage ventures is limited."
https://www.sciencedirect.com/science/article/pii/S0950584924000958,Automating modern code review processes with code similarity measurement,Yusuf=Kartal: ykartal@ogu.edu.tr,"Abstract
Context:
Modern code review is a critical component in software development processes, as it ensures security, detects errors early and improves code quality. However, manual reviews can be time-consuming and unreliable. Automated code review can address these issues. Although deep-learning methods have been used to recommend code review comments, they are expensive to train and employ. Instead, information retrieval (IR)-based methods for automatic code review are showing promising results in efficiency, effectiveness, and flexibility.
Objective:
Our main objective is to determine the optimal combination of the 
vectorization
 method and similarity to measure what gives the best results in an automatic code review, thereby improving the performance of IR-based methods.
Method:
Specifically, we investigate different 
vectorization
 methods (Word2Vec, Doc2Vec, Code2Vec, and Transformer) that differ from previous research (TF-IDF and Bag-of-Words), and similarity measures (Cosine, Euclidean, and Manhattan) to capture the semantic similarities between code texts. We evaluate the performance of these methods using standard metrics, such as Blue, Meteor, and Rouge-L, and include the run-time of the models in our results.
Results:
Our results demonstrate that the Transformer model outperforms the state-of-the-art method in all standard metrics and similarity measurements, achieving a 19.1% improvement in providing exact matches and a 6.2% improvement in recommending reviews closer to human reviews.
Conclusion:
Our findings suggest that the Transformer model is a highly effective and efficient approach for recommending code review comments that closely resemble those written by humans, providing valuable insight for developing more efficient and effective automated code review systems.",September 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The investigation into automatic code review using different vectorization methods and similarity measures, with a focus on improving effectiveness and efficiency, has practical implications for software development processes and early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492400096X,The impact of personality and self-efficacy on domain modeling productivity in graphical and textual notations,Santiago=Meliá: santi@dlsi.ua.es,"Abstract
Context
Software development is a complex and human-intensive activity, where human factors can have a significant impact on productivity and quality of results. To address the complexity of software, domain modeling has gained much importance, mainly due to software methodologies such as Model-Driven Engineering and Domain-Driven Design. In particular, domain modeling is an essential task that allows developers to understand and effectively represent the problem domain. However, domain modeling productivity can be affected by several human factors, including developers' personality and self-efficacy.
Objective
The study aims to explore the influence of human factors, specifically developers' personality and self-efficacy, on domain modeling productivity in graphical and textual notations.
Method
An empirical controlled study was conducted with 134 third-year computer science students from the University of Alicante, guided by the definition of a theoretical model based on previous studies. The participants were tasked with creating domain models in both graphical and textual notations. The order in which the notations were used was randomized, and the participants were given different system specifications to model. After modeling, 98 participants completed questionnaires assessing their personality, self-efficacy, and notation satisfaction. The design and evaluation of the experiment employed the Goal, Question, and Metrics framework. Data analysis was performed using a stepwise selection method to select the most appropriate regression model.
Results
The study indicates that personality and self-efficacy have a significant impact on the performance of junior domain model developers. Specifically, it was discovered that while 
neuroticism
 had a 
negative impact
 on efficiency in both notations, developers' ability belief and use of 
graphical notation
 had a positive influence on effectiveness and efficiency in creating domain models.
Conclusions
These findings highlight the importance of considering human factors and notation choice in software development. Developers' personality and self-efficacy emerge as critical considerations for enhancing both productivity and quality in domain modeling.",September 2024,"Human factors, Model productivity, Personality, Self-efficacy, Domain modelling, Empirical software engineering, Model-driven engineering, Domain-driven design",Information and Software Technology,2025-03-18T00:00:00,7.0,"The empirical study on the influence of human factors on domain modeling productivity, specifically personality and self-efficacy, offers practical implications for improving productivity and quality, which could be valuable for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924001046,Boosting fault localization of statements by combining topic modeling and Ochiai,Romain=Vacheret: romain.vacheret@lip6.fr; Francisca=Pérez: mfperez@usj.es; Tewfik=Ziadi: tewfik.ziadi@lip6.fr; Lom=Hillah: lom.hillah@newco-partners.com,"Abstract
Context:
Reducing the cost of maintenance tasks by fixing bugs automatically is the cornerstone of Automated Program Repair (APR). To do this, automated 
Fault Localization
 (FL) is essential. Two families of FL techniques are Spectrum-based 
Fault Localization
 (SBFL) and Information Retrieval Fault Localization (IRFL). In SBFL, the coverage information and execution results of test cases are utilized. Ochiai is one of the most effective and used SBFL strategies. In IRFL, the 
bug report
 information is utilized as well as the identifier names and comments in 
source code files
. 
Latent Dirichlet Allocation
 (LDA) is a generative statistical model and one of the most popular 
topic modeling
 methods. However, LDA has been used at the method level of 
granularity
 as IRFL technique, whereas most existing APR tools are focused on the statement level.
Objective:
This paper presents our approach that combines 
topic modeling
 and Ochiai to boost FL at the statement level.
Method:
We evaluate our approach considering five different projects in Defects4J benchmark. We report the performance of our approach in terms of hit@k and MRR. To study the impact on the results, we compare our approach against five baselines: two SBFL approaches (Ochiai and Dstar), two IRFL approaches (LDA and Blues), and one hybrid approach (SBIR). In addition, we compare the number of bugs that are found by our approach with the baselines.
Results:
Our approach significantly outperforms the baselines in all metrics. Especially, when hit@1, hit@3 and hit@5 are compared. Also, our approach locates more bugs than Ochiai and Blues.
Conclusion:
The results of our approach indicate that the integration of topic modeling with Ochiai boosts FL. This uncovers the potential of topic modeling for FL at statement level, which is valuable for the APR community.",September 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The integration of topic modeling with Ochiai to boost Fault Localization at the statement level has significant practical value for automated program repair, showcasing potential for advancing the APR community."
https://www.sciencedirect.com/science/article/pii/S0950584924000910,"A brief note, with thanks, on the contributions of Guenther Ruhe",Tim=Menzies: timm@ieee.org,"Abstract
Someone once told me that the best we can hope for as academics is to be a footnote in some as-yet-unwritten textbook. Guenther Ruhe’s footnote will surely be very large.",September 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,1.0,The abstract lacks relevance and practical value for European early-stage ventures or startups in the context of technology adoption or software engineering.
https://www.sciencedirect.com/science/article/pii/S0950584924000740,Acceptance behavior theories and models in software engineering — A mapping study,Jürgen=Börstler: jurgen.borstler@bth.se,"Abstract
Context:
The adoption or acceptance of new technologies or ways of working in software development activities is a recurrent topic in the 
software engineering
 literature. The topic has, therefore, been empirically investigated extensively. It is, however, unclear which theoretical frames of reference are used in this research to explain acceptance behaviors.
Objective:
In this study, we explore how major theories and models of acceptance behavior have been used in the software engineering literature to empirically investigate acceptance behavior.
Method:
We conduct a 
systematic mapping study
 of empirical studies using acceptance behavior theories in software engineering.
Results:
We identified 47 primary studies covering 56 theory uses. The theories were categorized into six groups. Technology acceptance models (TAM and its extensions) were used in 29 of the 47 primary studies, innovation theories in 10, and the theories of planned behavior/ reasoned action (TPB/TRA) in six. All other theories were used in at most two of the primary studies. The usage and operationalization of the theories were, in many cases, inconsistent with the underlying theories. Furthermore, we identified 77 constructs used by these studies of which many lack clear definitions.
Conclusions:
Our results show that software engineering researchers are aware of some of the leading theories and models of acceptance behavior, which indicates an attempt to have more theoretical foundations. However, we identified issues related to theory usage that make it difficult to aggregate and synthesize results across studies. We propose 
mitigation actions
 that encourage the consistent use of theories and emphasize the measurement of key constructs.",August 2024,"Acceptance behavior, Technology adoption, Theory use in software engineering, TAM, TPB, TRA, Fitness, Innovation diffusion",Information and Software Technology,2025-03-18T00:00:00,6.0,"The systematic mapping study on acceptance behavior theories in software engineering provides insights into the theoretical foundations of technology adoption, offering potential value for startups looking to understand user acceptance of new technologies."
https://www.sciencedirect.com/science/article/pii/S0950584924000806,A Systematic Literature Review on Software Maintenance Offshoring Decisions,,"Abstract
Context
Over the last decades, the rapid expansion of the internet has prompted an increasing number of organizations that have taken their work global and have outsourced their information technology (IT) activities to specialized suppliers. The longest part of the 
software life cycle
 includes software maintenance, which consumes 60-70% of the total IT budget. Therefore, organizations have adopted offshoring strategies to reduce maintenance costs and free up resources to focus on their 
core competencies
. Offshore outsourcing decision-making involves technical, social, and other influencing factors; however, there is a limited understanding of the key factors associated with offshoring software maintenance within the 
global software development
 context.
Objective
This work presents the factors that have influenced the decision-making process of offshoring software maintenance. Further, this research sheds light on decision-making by identifying the models, frameworks, and 
software tools
 used within this context.
Method
A systematic literature review is conducted, delving into the factors related to the decision-making and analyzing the models, frameworks and tools supporting offshoring software maintenance.
Results
This study identifies the top 10 key factors concerning the decision-making process, namely human communication, cost reduction, organizational and employee maturity, 
project management practices
, IT infrastructure support, language constraints, knowledge-based support, changes in requirements, legal issues and cultural diversity. In addition, the models, frameworks, and tools used in the decision-making process of software maintenance are analyzed, and research gaps are identified.
Conclusion
The findings reveal that the software industry lacks effective and efficient models tailored explicitly for software offshoring within the 
global software development
 landscape. Overall, this study provides valuable insights into the decision-making dynamics of software maintenance offshoring by identifying key factors and research gaps that can pave the way for developing more effective decision 
support systems
.",August 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides valuable insights into decision-making dynamics of software maintenance offshoring, identifying key factors and research gaps that can lead to more effective decision support systems."
https://www.sciencedirect.com/science/article/pii/S0950584924000727,Automatic test cases generation from formal contracts,Samuel Jiménez=Gil: Samuel.Gil@satixfy.com; Manuel I.=Capel: manuelcapel@ugr.es; Gabriel Olea=Olea: gabrieloo@correo.ugr.es,"Abstract
Context:
Software verification
 for 
critical systems
 is facing an unprecedented cost increase due to the large amount of software packed in 
multicore platforms
 generally. A substantial amount of the verification efforts are dedicated to testing. Spark/Ada is a language often employed in safety-critical systems due to its high reliability. Formal contracts are often inserted in Spark’s program specification to be used by a static 
theorem prover
 that checks whether the specification conforms with the implementation. However, this 
static analysis
 has its limitations as certain bugs can only be spotted through software testing.
Objective:
The main goal of our work is to use these formal contracts in Spark as input for a test oracle – whose method we describe – to generate test cases. Subsequent objectives consist of a) arguing about the traceability to comply with safety-critical software standards such as DO-178C for civil avionics and b) embracing the best-established software testing methods for these systems.
Method:
Our test generation method reads Spark formal contracts and applies Equivalence Class Partitioning with Boundary Analysis as a software testing method generating traceable test cases.
Results:
The evaluation, which uses an array of open-source examples of Spark contracts, shows a high level of passed test cases and 
statement coverage
. The results are also compared against a 
random test
 generator.
Conclusion:
The proposed method is very effective at achieving a high number of passed test cases and coverage. We make the case that the effort to create formal specifications for Spark can be used both for proof and (automatic) testing. Lastly, we noticed that some formal contracts are more suitable than others for our test generation.",August 2024,"Automatic test cases generation, Software testing, Formal methods, Software verification",Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed method effectively achieves a high number of passed test cases and coverage, making it valuable for improving software testing methods and complying with safety-critical software standards."
https://www.sciencedirect.com/science/article/pii/S0950584924000788,Automatic build repair for test cases using incompatible Java versions,Ching Hang=Mak: chmakac@connect.ust.hk; Shing-Chi=Cheung: scc@cse.ust.hk,"Abstract
Context:
Bug bisection is a common technique used to identify a revision that introduces a bug or indirectly fixes a bug, and often involves executing multiple revisions of a project to determine whether the bug is present within the revision. However, many legacy revisions often cannot be successfully compiled due to changes in the programming language or tools used in the compilation process, adding complexity and preventing automation in the bisection process.
Objective:
In this paper, we introduce an approach to repair test cases of Java projects by performing dependency minimization. Our approach aims to remove classes and methods that are not required for the execution of one or more test cases. Unlike existing state-of-the-art techniques, our approach performs minimization at source-level, which allows compile-time errors to be fixed.
Methods:
A standalone Java tool implementing our technique was developed, and we evaluated our technique using subjects from Defects4J retargeted against Java 8 and 17.
Results:
Our evaluation showed that a majority of subjects can be repaired solely by performing minimization, including replicating the test results of the original version. Furthermore, our technique is also shown to achieve accurate minimized results, while only adding a small overhead to the bisection process.
Conclusion:
Our proposed technique is shown to be effective for repairing build failures with minimal overhead, making it suitable for use in automated bug bisection. Our tool can also be adapted for use cases such as bug corpus creation and refactoring.",August 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The approach presented is effective for repairing build failures with minimal overhead, suitable for use in automated bug bisection, which can be beneficial for startups dealing with legacy codebases."
https://www.sciencedirect.com/science/article/pii/S0950584924000818,CriticalFuzz: A critical neuron coverage-guided fuzz testing framework for deep neural networks,Tongtong=Bai: btt070619@163.com; Song=Huang: huangsong@aeu.edu.cn; Yifan=Huang: yifan005@e.ntu.edu.so; Xingya=Wang: xingyawang@outlook.com; Chunyan=Xia: xiachunyan@mdjnu.edu.cn; Yubin=Qu: yubinqu@icloud.com; Zhen=Yang: yangzhen@aeu.edu.cn,"Abstract
Context:
Deep neural networks
 (DNN) have been widely deployed in safety-critical domains, such as autonomous cars and healthcare, where error behaviors can lead to serious accidents, testing DNN is extremely important. Neuron coverage-guided 
fuzz testing
 (NCFT) has become an effective whitebox testing approach for testing DNN, which iteratively generates new test cases with the guidance of neuron coverage to explore different logics of DNN, and has found numerous defects. However, existing NCFT approaches ignore that the role of neurons is distinct for the final output of DNN. Given an input, only a fraction of neurons determines the final output of the DNN. These neurons hold the essential logic of the DNN.
Objective:
To ensure the quality of DNN and improve testing efficiency, NCFT should first cover neurons containing major logic of DNN.
Method:
In this paper, we propose the critical neurons that hold essential logic of DNN. In order to prioritize the detection of potential defects of critical neurons, we propose a 
fuzz testing
 framework, named CriticalFuzz, which mainly contains the energy-based test case generation and the critical neuron coverage criteria. The energy-based test case generation has the capability to produce test cases that are more likely to cover critical neurons and involves energy-based seed selection, power schedule, and seed mutation. The critical neuron coverage as a mechanism for providing feedback to guide the CriticalFuzz in prioritizing the coverage of critical neurons. To evaluate the significance of critical neurons and the performance of CriticalFuzz, we conducted experiments on popular DNNs and datasets.
Results:
The experiment results show that (1) the critical neurons have a 100% impact on the output of models, while the non-critical neurons have a lesser effect; (2) CriticalFuzz is effective in achieving 100% coverage of critical neurons and covering 10 classes of critical neurons, outperforming both DeepHunter and TensorFuzz. (3) CriticalFuzz exhibits exceptional 
error detection
 capabilities, successfully identifying thousands of errors across 10 diverse error classes within DNN.
Conclusion:
The critical neurons defined in this paper hold more significant logic of DNN than non-critical neurons. CriticalFuzz can preferentially cover critical neurons, thereby improving the efficiency of the NCFT process. Additionally, CriticalFuzz is capable of identifying a 
greater number
 of errors, thus enhancing the reliability and effectiveness of the NCFT.",August 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"The CriticalFuzz framework demonstrates exceptional error detection capabilities and significantly enhances the efficiency and reliability of testing DNN, which can have a high impact on startups operating in safety-critical domains."
https://www.sciencedirect.com/science/article/pii/S0950584924000569,Understanding and evaluating software reuse costs and benefits from industrial cases—A systematic literature review,Xingru=Chen: xingru.chen@bth.se; Muhammad=Usman: muhammad.usman@bth.se; Deepika=Badampudi: deepika.badampudi@bth.se,"Abstract
Context:
Software reuse
 costs and benefits have been investigated in several primary studies, which have been aggregated in multiple secondary studies as well. However, existing secondary studies on software reuse have not critically appraised the evidence in primary studies. Moreover, there has been relatively less focus on how software reuse costs and benefits were measured in the primary studies, and the aggregated evidence focuses more on software reuse benefits than reuse costs.
Objective:
This study aims to cover the gaps mentioned in the context above by synthesizing and critically appraising the evidence reported on software reuse costs and benefits from industrial cases.
Method:
We used a systematic literature review (SLR) to conduct this study. The results of this SLR are based on a final set of 30 primary studies.
Results:
We identified nine software reuse benefits and six software reuse costs, in which better quality and improved productivity were investigated the most. The primary studies mostly used defect-based and development time-based metrics to measure reuse benefits and costs. Regarding the reuse practices, the results show that software product lines, verbatim reuse, and systematic reuse were the top investigated ones, contributing to more reuse benefits. The quality assessment of the primary studies showed that most of them are either of low (20%) or moderate (67%) quality.
Conclusion:
Based on the number and quality of the studies, we conclude that the strength of evidence for better quality and improved productivity as reuse benefits is high. There is a need to conduct more high quality studies to investigate, not only other reuse costs and benefits, but also how relatively new reuse-related practices, such as InnerSource and 
microservices architecture
, impact software reuse.",July 2024,"Software reuse, Software reuse costs, Software reuse benefits, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study synthesizes evidence on software reuse costs and benefits from industrial cases, highlighting the need for more high-quality studies in the field. The findings contribute to understanding the impact of new reuse-related practices."
https://www.sciencedirect.com/science/article/pii/S0950584924000612,The need for more informative defect prediction: A systematic literature review,Natalie=Grattan: natalie.grattan@postgrad.otago.ac.nz; Daniel=Alencar da Costa: danielcalencar@otago.ac.nz; Nigel=Stanger: nigel.stanger@otago.ac.nz,"Abstract
Context:
Software defect
 prediction is crucial for prioritising quality assurance tasks, however, there are still limitations to the use of defect models. For example, the outputs often do not provide the defect type, severity, or the cause of the defect. Current models are also often complex in implementation (they use low transparency classifiers such as 
random forest
 or support vector machines) and primarily output binary predictions. They lack directly 
actionable outputs
, that is, outputs that provide additional information (e.g., defect severity or defect type) to aid in fixing the defect. One approach is to utilise tools of 
explainable AI
.
Objective:
In order to improve current models and plan the direction for explainability in software 
defect prediction
, we need to understand how explainable current models are.
Methods:
Starting from 861 papers from multiple databases, we investigated a sample of 132 papers in a systematic literature review. We extracted the following information to answer our research questions: (i) information about the outputs (e.g., how informative they were) and explainability methods used, (ii) how explainability and performance is measured and (iii) explainability in future research. Our results were summarised by manually labelling the data so that trends could be analysed across selected papers, along with a thematic analysis.
Results:
We found that 71% of current models used binary outputs, while 68% of models were not yet utilising any explainability techniques. Only 7% of studies considered explainability in their future research suggestions.
Conclusion:
There is still a lack of awareness among researchers for the need for explainability and motivation to invest further research into more explainable and more informative software defect prediction models.",July 2024,"Systematic literature review, Software quality, Software defect prediction, Explainable AI, Machine learning",Information and Software Technology,2025-03-18T00:00:00,6.0,"The study focuses on the lack of explainability in software defect prediction models, highlighting the need for more informative outputs. The findings could lead to improvements in the understandability of defect prediction models."
https://www.sciencedirect.com/science/article/pii/S0950584924000776,Knowledge and research mapping of the data and database forensics domains: A bibliometric analysis,Georgios=Chorozidis: gchorozidis@gmail.com; Konstantinos=Georgiou: konsgeor@csd.auth.gr; Nikolaos=Mittas: nmittas@chem.ihu.gr; Lefteris=Angelis: lef@csd.auth.gr,"Abstract
The field of 
digital forensics
 has undergone rapid development alongside the technological advancements of the latest century. This study focuses in two of its subdomains, namely 
database forensics
 and data forensics. Though the concept of a database is relatively old, there is an academic void when it comes to its research compared to different domains in 
digital forensics
. Data forensics has a myriad of applications, however there appears to be a lack of standardization in regards to the field itself throughout the different disciplines of the forensic field. Our main objectives with this study were to identify the prominent trends, uncover research gaps or further research necessity and to provide a high level outline of the selected domains. To fulfill the objectives, we designed and executed a protocol with predefined phases, steps, and activities that all stem from the principles of 
bibliometric analysis
. The findings of the methodological procedure are presented and the research questions are answered in a concise manner. The two domains have considerable growth, given how recently they emerged in literature. However, there are issues present in the current literature that might hinder the future research and might repulse not only the aspiring but also the current professionals of the forensic field. These issues must be resolved in order to make the selected domains less elusive when it comes to cross-domain applications and when new practitioners are concerned.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study addresses important issues in digital forensics, the practical impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584924000545,Technical risk model of machine learning based software project development - A multinational empirical study using modified Delphi-AHP method,Sun-Jen=Huang: huangsj@mail.ntust.edu.tw,"Abstract
Context
The development of 
machine learning
 (ML) based software projects has increased significantly over the past decade, introducing new technical risks that rarely or never appear in traditional software development projects.
Objective
This research aims to identify and prioritize the technical risk factors that may lead to the failure of ML-based software development projects.
Method
First, a literature review was conducted to compile a preliminary list of technical risk factors for ML-based software project development. Then, two rounds of the modified Delphi process were conducted with 17 ML experts to review and verify the completeness and appropriateness of the preliminary technical risk factors. A hierarchy of five technical risk categories with 22 technical risk factors was concluded for the 
analytic hierarchy process
 (AHP). Then, three rounds of online AHP questionnaires were administered. The consistency ratio (CR) was used to check the respondents’ answers, and the quartile deviation (QD) was applied to assess the consensus on all 96 questions. Finally, we prioritized the technical risk categories and associated technical risk factors.
Results
We found that ""data availability and quality"" ranked as the top technical risk category in terms of severity, probability, and impact rankings of the five technical risk categories. Furthermore, all four technical risk factors within this category also occupied the top four positions of impact ranking.
Conclusion
The 
research results
 highlight the crucial role of the four data availability and quality risk factors for the failure of ML-based software project development. The proposed technical risk model of ML-based software project development with the identified severity and probability priorities may provide practitioners and research community with a clear overview, highlighting areas demanding priority attention to effectively mitigate project failure risks. These findings have broader implications for improving the success rates of ML-based software projects across various domains.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The research on technical risk factors in ML-based software projects has direct relevance to startups and can help improve success rates, making it valuable for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924000478,MSGVUL: Multi-semantic integration vulnerability detection based on relational graph convolutional neural networks,Chao=Pan: kerwinpc@ccut.edu.cn,"Abstract
Software security has drawn extensive attention as software projects have grown increasingly large and complex. Since the traditional manual or equipment 
vulnerability detection
 technology cannot meet today's software development needs, there is a recognized need to create more effective techniques to address security issues. Although various vulnerability detection systems have been proposed, most are based only on serialization or 
graph representation
, to inadequate effect. We propose a system, MSGVUL, that provides superior vulnerability detection using a new multi-semantic approach. MSGVUL uses versatile and efficient code slicing employing a search algorithm based on sensitive data and functions and innovatively constructs an SSVEC model to fully integrate the semantic and structural information into the code. We also developed a novel BAG model, made up of BAP and PAG frameworks, that enables the hierarchical extraction of code vulnerability representations from the graph and sequence levels. The MSGVUL model is evaluated on slice-level and function-level vulnerability datasets, and the results demonstrate that the MSGVUL method outperforms other state-of-the-art methods.",June 2024,"Vulnerability detection, Code representation, Program slicing, Graph convolutional neural networks",Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed MSGVUL system for vulnerability detection offers a new, effective approach to addressing security issues in software projects, which can have a significant impact on improving software security for early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584924000636,"Making vulnerability prediction more practical: Prediction, categorization, and localization",Chongyang=Liu: lcyyy@mail.ustc.edu.cn; Xiang=Chen: xchencs@ntu.edu.cn; Xiangwei=Li: lixw20@mail.ustc.edu.cn; Yinxing=Xue: yxxue@ustc.edu.cn,"Abstract
Context:
Due to the prevalence of software vulnerabilities, 
vulnerability detection
 becomes a fundamental problem in system security.
Objective:
To solve this problem, academics and industries have made great efforts to propose deep-learning-based (DL-based) approaches but these attempts have three main limitations: (1) perform poorly on real-world projects (e.g., Accuracy below 74.33% and F1 below 73.55%); (2) perform poorly in catching vulnerable patterns due to incomplete code representations; (3) mostly perform coarse-grained function-level prediction and lack 
interpretability
 analysis.
Methods:
In this paper, we propose 
VulPCL
, a BLSTM and CodeBERT based approach, which makes the first attempt to perform vulnerability prediction, categorization, and localization automatically within a framework. To alleviate the above-mentioned limitations, our 
VulPCL
 considers multi-dimension (i.e., text-based, sequence-based, and graph-based) representations to catch latent vulnerable patterns and multi-model training to learn high-level semantics.
Results:
Through experiments on four real-world datasets containing 114+ CWE (Common Weakness Enumeration) types spanning from 2005 to 2022, we find that our 
VulPCL
 outperforms the baselines by (1) 13.51%
∼
60.64% and 14.34%
∼
180.23% on Accuracy, and F1 respectively on vulnerability prediction; (2) 10.32%
∼
46.79%, and 10.71%
∼
127.80% on Accuracy, and macro-F1 respectively on vulnerability categorization; (3) 9.23%
∼
36.54% on Top-10 Accuracy on vulnerability localization.
Conclusion:
These results indicate that our 
VulPCL
 is considerably more accurate, effective, fine-grained, and practical than previous studies. Besides, our further analyses show that 
VulPCL
 is indeed capable of capturing all vulnerability lines, and the result of line-level vulnerability localization is consistent with the function-level vulnerability prediction as the increase of predicted lines. Thus making 
VulPCL
 more interpretable than previous studies. Our additional investigation also shows that 
VulPCL
 effectively detects the Most Dangerous 25 CWEs in 2022, which is instructive for security researchers.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The development of VulPCL and its effectiveness in vulnerability prediction can benefit European early-stage ventures by enhancing security measures in software development.
https://www.sciencedirect.com/science/article/pii/S0950584924000624,A declarative approach to detecting design patterns from Java execution traces and source code,Swaminathan=Jayaraman: swaminathanj@am.amrita.edu,"Abstract
Design patterns
 are invaluable for software engineers because they help obtain well-structured and reusable object-oriented software components and contribute towards ease of software comprehension, maintenance, and modification. However, identifying design patterns from an inspection of the 
source code
 is not easy because, in most cases, there are no 
syntactic
 cues that signal their presence. This topic has therefore elicited considerable interest in the field. The novel aspect of our work is that we propose a set of primitives using which we can declaratively specify design patterns based on a combination of static and dynamic information. Our experimental work is carried out in the context of Java: static information is extracted from Java 
source code
, and dynamic information from an execution trace of a program. Each declarative pattern specification is automatically translated into an 
SQL
 query which retrieves all instances of the design pattern present in the program. We illustrate our approach with the well-known Gang-of-Four design patterns and the approach extends to other such design patterns. The experimental results show the efficacy of our approach for representative programs for all GoF patterns in addition to more extensive 
case studies
, JHotDraw, Junit, and QuickUML.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the research on design patterns is valuable for software engineers, its direct impact on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924000582,Hybrid semantics-based vulnerability detection incorporating a Temporal Convolutional Network and Self-attention Mechanism,Jinfu=Chen: jinfuchen@ujs.edu.cn,"Abstract
Context:
Desirable characteristics in vulnerability-detection (VD) systems (VDSs) include both good detection capability (high accuracy, low false positive rate, low 
false negative
 rate, etc.) and low time overheads. The widely used VDSs based on models such as 
Recurrent Neural Networks
 (RNNs) have some problems, such as low time efficiency, failing to learn the vulnerability features better, and insufficient amounts of vulnerability features. Therefore, it is very important to construct an automatic detection model with high detection accuracy.
Objective:
This paper reports on training based on the 
source code
 to analyze and learn from the code’s patterns and structures by deep-learning techniques to generate an efficient VD model that does not require manual feature design.
Method:
We propose a software VD model based on multi-feature fusion and 
deep neural networks
 called AIdetectorX-SP. It first uses a 
Temporal Convolutional Network
 (TCN) and adds a Self-attention Mechanism (SaM) to the TCN to build a model for extracting vulnerability logic features, then transforms the 
source code
 into an image input to a 
Convolutional Neural Network
 (CNN) to extract structural and semantic information. Finally, we use feature-fusion technology to design and implement an improved deep-learning-based VDS, called AIdetectorX Sequence with Picturization (AIdetectorX-SP).
Results:
We report on experiments conducted using publicly-available and widely-used datasets to evaluate the effectiveness of AIdetectorX-SP, with results indicating that AIdetectorX-SP is an effective VDS; that the combination of TCN and SaM can effectively extract vulnerability logic features; and that the pictorial code can extract code structure features, which can further improve the VD capability.
Conclusion:
In this paper, we propose a novel detection model for software vulnerability based on TCNs, SaM, and software picturization. The proposed model solves some shortcomings and limitations of existing VDSs, and obtains a high software-VD accuracy with a high degree of stability.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed VD model addresses shortcomings of existing systems and achieves high accuracy in vulnerability detection, which can significantly impact the security of early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924000715,Search-based co-creation of software models: The case of particle systems for video games,Jorge=Chueca: jchueca@usj.es,"Abstract
Context:
The 
video game
 industry is one of the fastest-growing industries in the world. However, the creation of content is the bottleneck of the industry nowadays.
Objective:
In this paper, we propose a new approach for co-creating content by means of combining an 
evolutionary algorithm
 Map-Elites, and software models. Our approach involves generating a large number of software models and selecting the best ones based on a fitness function. This fitness function is guided by the human, who chooses which content fits their interests best.
Method:
We evaluated this approach in the domain of Particle Systems (PS). PS are a popular type of content used to create visual effects such as explosions, fire, smoke, or rain. Our evaluation also involves industry experts of different roles in the 
video game
 
development process
. Using our approach, they were tasked to create PS for their games. Then, they compared the generated models with handmade ones.
Results:
Our results show that practitioners chose the generated models four out of five times over handmade ones as a better fit for their projects. Furthermore, models created with our approach by non-experts in five minutes are similar in quality to the ones hand-made by an expert in 15 min.
Conclusion:
In conclusion, using human artistic taste to guide the algorithm renders positive results in creative tasks such as content generation for video games. With minor adjustments, the 
generated content
 can be game-ready, accelerating development.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The approach of combining evolutionary algorithms and human guidance for content generation in video games shows promise in accelerating development, which can benefit startups in the industry."
https://www.sciencedirect.com/science/article/pii/S0950584924000752,Guiding the way: A systematic literature review on mentoring practices in open source software projects,Zixuan=Feng: fengzi@oregonstate.edu; Katie=Kimura: kimuraka@oregonstate.edu; Bianca=Trinkenreich: bianca.trinkenreich@oregonstate.edu; Anita=Sarma: Anita.Sarma@oregonstate.edu; Igor=Steinmacher: Igor.Steinmacher@nau.edu,"Abstract
Context:
Mentoring in 
Open Source Software
 (OSS) is important to its project’s growth and sustainability. Mentoring allows contributors to improve their technical skills and learn about the protocols and cultural norms of the project. However, mentoring has its challenges: mentors sometimes feel unappreciated, and mentees may have mismatched interests or lack interpersonal skills. Existing research has investigated the different challenges of mentoring in different OSS contexts, but we lack a holistic understanding.
Objective:
A comprehensive understanding of the current practices and challenges of mentoring in OSS is needed to implement appropriate strategies to facilitate mentoring.
Method:
This study presents a 
systematic literature review
 investigating how literature has characterized mentoring practices in OSS, including their challenges and the strategies to mitigate them. We retrieved 232 studies from four digital libraries. Out of these, 21 were primary studies. Using this, we performed backward and author snowballing, adding another 27 studies. We conducted a 
completeness check
 by reviewing the references of the 4 most relevant primary studies, which resulted in us adding 1 additional study. We then conducted a full-text review and evaluated the studies using a set of criteria; as a result, 10 papers were excluded. We then employed an open-coding approach to analyze, aggregate, and synthesize the selected studies.
Results:
We reviewed 39 studies to investigate the different facets of mentoring in OSS, encompassing motivations, goals, channels, and contributor dynamics. We then identified 13 challenges associated with mentoring in OSS, which fall into three categories: social, process, and technical. We also present a quick-reference strategy catalog to map these strategies to challenges for mitigation.
Conclusions:
Our study serves as a guideline for researchers and practitioners about mentoring challenges and potential strategies to mitigate these challenges.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on mentoring challenges and strategies in OSS provides valuable insights for project growth and sustainability, offering guidance to startups on fostering talent within their teams."
https://www.sciencedirect.com/science/article/pii/S0950584924000491,On the use of contextual information for machine learning based test case prioritization in continuous integration development,Enrique A. da=Roza: enriqueaugroza@gmail.com; Jackson A. do=Prado Lima: japlima@inf.ufpr.br; Silvia R.=Vergilio: silvia@inf.ufpr.br,"Abstract
Context:
In most software organizations, 
Continuous Integration (CI)
 is a 
common practice
 usually subject to some budgets. Consequently, prioritizing test cases to be executed in the CI cycle is fundamental. The idea is first to execute test cases with higher failure-proneness to provide rapid feedback and decrease costs. To perform this task approaches in the literature adopt failure history and 
Machine Learning
 (ML)
. However, in addition to the failure history, it is also important to consider information from the CI context of the organizations and the application domain.
Objective:
For this end, we introduce a contextual information approach for 
ML algorithms
. Such an approach considers information from the testing activity that can be easily collected, such as test case 
execution time
, size, and complexity. We implement the approach by introducing two contextual versions of the algorithms: Multi-Armed Bandit (MAB) and 
Random Forest
 (RF).
Method:
Six systems are used to compare both contextual algorithms and to evaluate their performance regarding their corresponding non-contextual versions, considering three different budgets.
Results:
Contextual algorithms perform better when indicators related to test time reduction are considered, as the contextual information they use is related to 
execution time
. Regarding NAPFD and APFDc, the non-contextual algorithms have better general performance, but both contextual versions obtain competitive results.
Conclusions:
The contextual versions implemented can capture the desired context information in the prioritization without negatively impacting their performance regarding fault-detection.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The contextual ML approach for test case prioritization in CI introduces efficiency but may have limited immediate impact on European early-stage ventures compared to other abstracts.
https://www.sciencedirect.com/science/article/pii/S0950584924000739,Effective test generation using pre-trained Large Language Models and mutation testing,Arghavan Moradi=Dakhel: arghavan.moradi-dakhel@polymtl.ca; Amin=Nikanjam: amin.nikanjam@polymtl.ca; Vahid=Majdinasab: vahid.majdinasab@polymtl.ca; Foutse=Khomh: foutse.khomh@polymtl.ca; Michel C.=Desmarais: michel.desmarais@polymtl.ca,"Abstract
Context:
One of the critical phases in the software development 
life cycle
 is software testing. Testing helps with identifying potential bugs and reducing maintenance costs. The goal of automated test generation tools is to ease the development of tests by suggesting efficient bug-revealing tests. Recently, researchers have leveraged 
Large Language Models
 (LLMs) of code to generate unit tests. While the code coverage of generated tests was usually assessed, the literature has acknowledged that the coverage is weakly correlated with the efficiency of tests in bug detection.
Objective:
To improve over this limitation, in this paper, we introduce 
MuTAP
 (
Mu
tation 
T
est case generation using 
A
ugmented 
P
rompt) for improving the effectiveness of 
test cases generated
 by LLMs in terms of revealing bugs by leveraging mutation testing.
Methods:
Our goal is achieved by augmenting prompts with surviving mutants, as those mutants highlight the limitations of test cases in detecting bugs. 
MuTAP
 is capable of generating effective test cases in the absence of natural language descriptions of the Program Under Test (PUTs). We employ different LLMs within 
MuTAP
 and evaluate their performance on different benchmarks.
Results:
Our results show that our proposed method is able to detect up to 28% more faulty human-written code snippets. Among these, 17% remained undetected by both the current state-of-the-art fully-automated test generation tool (i.e., Pynguin) and zero-shot/few-shot 
learning approaches
 on LLMs. Furthermore, 
MuTAP
 achieves a Mutation Score (MS) of 93.57% on synthetic buggy code, outperforming all other approaches in our evaluation.
Conclusion:
Our findings suggest that although LLMs can serve as a useful tool to generate test cases, they require specific post-processing steps to enhance the effectiveness of the generated test cases which may suffer from 
syntactic
 or functional errors and may be ineffective in detecting certain types of bugs and testing corner cases in 
PUT
s.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The MuTAP approach significantly improves the effectiveness of test cases generated by LLMs, enhancing bug detection capabilities, which could be crucial for startup software development."
https://www.sciencedirect.com/science/article/pii/S095058492400079X,Forward-Oriented Programming: A meta-DSL for fast development of component libraries,Emmanouil=Krasanakis: manios.krasanakis@issel.ee.auth.gr; Andreas=Symeonidis: symeonid@ece.auth.gr,"Abstract
Libraries that implement Domain-Specific Language (DSL) components keep gaining traction when it comes to developing software for 
specific application domains
. However, creating components that can be organically weaved into use cases is an extremely complex task. In this work, we introduce a meta-DSL to assist library development, called Forward-Oriented Programming (FOP). This combines lazy evaluation and aspect-oriented programming principles to align crosscutting 
component configurations
 and alter their execution outcomes depending on usage in subsequent code. Theoretical analysis shows that FOP simplifies component development and makes their combination logic learnable by library users. We realize the paradigm with a Python package, called 
pyfop
, and conduct a 
case study
 that compares it with purely functional and object-oriented library implementations. In the study, 
source code
 quality metrics demonstrate reduced time and effort to write library components, and increased 
comprehensibility
. Configurations are shared without modifying distant code segments.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The introduction of Forward-Oriented Programming (FOP) and pyfop for component development in libraries can significantly reduce time and effort, improving source code quality and comprehensibility in software development."
https://www.sciencedirect.com/science/article/pii/S0950584924000600,Quantum aided efficient resource control for connected support in IRS assisted networks,Ashu=Taneja: ashu.taneja@chitkara.edu.in; Shalli=Rani: shalli.rani@chitkara.edu.in; Meshal=Alharbi: Mg.alharbi@psau.edu.sa; Muhammad=Zohaib: Muhammad.zohaib@lut.fi,"Abstract
Context:
To achieve the vision of all connected world with uninterrupted communication support, 6G technology plays an important role. But the scarce radio spectrum and limited network resources is the main challenge in delivering its promised performance.
Objectives:
This paper presents an IRS-aided cell free 
NOMA
 network model that aims to provide uniform network coverage. The future 6G technology envisions for serving billions of interconnected devices with seamless communication support, data handling capabilities and computational accuracy. But the scarcity of network resources is the main limitation. Thus, the need is to design quantum enabled intelligent and dynamic networks capable of offering extended network capabilities. Proposed work is on intelligent network framework that provides uniform network coverage through efficient resource management for a 6G enabled expanded 
IoT
 network.
Methods:
To enable efficient resource management, a quantum enabled 
resource control
 algorithm is proposed that creates user clusters and associates each AP-IRS pair to each cluster. Each 
AP
 transmits the superimposed signals of its intended cluster against all the user clusters as in conventional 
NOMA
 system. The nodes in each cluster have been assigned unique pilots so as to avoid intracluster interference. The use of 
IRS
 enables desired 
NOMA
 
beamforming
 such that the effect of unfavourable wireless environment is mitigated.
Results:
The performance of the IRS-aided cell-free 
NOMA
 network is evaluated for average sum rate with different 
AP
 transmit power, cluster sizes, 
IRS
 reflecting elements and IRS phase shifts. It is shown that at transmit power per AP of 30dBm, the average sum rate of the system improves by 7.52% with the proposed algorithm using equal power allocation scheme. Further, the comparative performance analysis of three different communication systems is carried out to validate the proposed communication model.
Conclusion:
It is observed that with more number of users per cluster, the average sum rate of the system initially increases for small cluster sizes and then it becomes constant for large cluster sizes. The proposed clustering method outperforms the random clustering approach achieving sum rate of 12.9 bits/s/Hz with 
N
 =300 and 
M
= 8. The comparison of different communication scenarios reveals that the maximum sum rate of 12.2 bits/s/Hz is achieved with the proposed model incorporating proposed clustering mechanism. Further, the energy efficiency analysis suggests that energy efficiency improves with 
N
 and 
P
c
 with proposed clustering approach. The use case scenarios for the integration of 
quantum computing
 with IRS technology are also presented.",July 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The IRS-aided cell-free NOMA network model for 6G technology presents a novel approach to resource management and communication support, but the impact on early-stage ventures may be limited due to the specificity of network technology."
https://www.sciencedirect.com/science/article/pii/S095058492400048X,Prioritisation of code clones using a genetic algorithm,Umberto=Azadi: u.azadi@campus.unimib.it; Bartosz=Walter: bartosz.walter@cs.put.poznan.pl; Francesca Arcelli=Fontana: francesca.arcelli@unimib.it,"Abstract
Context:
Code clones are prevalent, and due to their diverse impact on projects’ quality they require a proper management strategy.
Objectives:
Develop GA-based Refactoring-Aware Detection (RAD) approach for prioritisation of code clones.
Method:
A genetic algorithm (GA) that balances estimated gain and cost/risk of refactoring to select the optimal clone candidate to refactor.
Results:
GA converges on a solution, with diverse variance. The value of fitness function is higher for multi-objective approaches, but they also exhibit higher variance.
Conclusion:
GA can be effectively applied for clone prioritising.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The GA-based Refactoring-Aware Detection (RAD) approach for code clone prioritization provides a useful tool, but its practical impact on European early-stage ventures may be less significant compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924000272,A method of multidimensional software aging prediction based on ensemble learning: A case of Android OS,Beibei=Yin: yinbeibei@buaa.edu.cn,"Abstract
Context:
Software aging refers to the phenomenon of 
performance degradation
, increasing failure rate, or system crash due to resource consumption and error accumulation in software systems running for a long time. It has become the key factor affecting software systems’ 
sustainability
. Due to its complex formation reasons, precisely predicting the aging state in actual execution is hard but crucial for enabling proactive measures before a catastrophic situation. 
Machine learning
 (ML) has been employed on this issue.
Objective:
However, previous ML-based prediction methods are single-threaded in the whole process, posing challenges in delivering the desired performance facing diverse user scenarios. To alleviate this problem, we propose a multidimensional software aging prediction method based on 
ensemble learning
 (MSAP).
Method:
In the framework of MSAP, five dimensions, including datasets, labeling metrics, labeling thresholds, algorithms, and model decisions, are extracted and diversified according to aging characteristics and application situations.
Results:
Plenty of experiments have been conducted on 
Android
 devices from three distinct vendors. When subjected to identical workloads, MSAP demonstrates comparable performance to most unidimensional models. While under varied workloads, MSAP outperforms unidimensional models whose performance drops dramatically, demonstrating enhanced adaptability and 
predictive accuracy
.
Conclusion:
MSAP shows exceptional stability while concurrently upholding outstanding prediction precision across a spectrum of user scenarios. It has better generalization characteristics and application prospects.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The multidimensional software aging prediction method based on ensemble learning (MSAP) addresses a crucial issue in software sustainability and demonstrates enhanced adaptability and predictive accuracy, making it valuable for startups dealing with software systems."
https://www.sciencedirect.com/science/article/pii/S0950584924000399,Inclusion of individuals with autism spectrum disorder in Software Engineering,Gastón=Márquez: gmarquez@ubiobio.cl,"Abstract
Context:
Software Engineering
 is dedicated to the systematic and efficient development of software, which necessitates the active participation of all team members and a recognition of their unique skills and abilities, including those with 
autism spectrum disorders
 (ASD). The inclusion of individuals with ASD presents new perspectives, yet there is a lack of systematic evidence regarding the primary obstacles and 
potential benefits
 associated with their inclusion.
Objective:
This paper aims to identify, characterize, and describe barriers, facilitators, and methodological proposals described by the community to include individuals with ASD in the discipline of 
Software Engineering
.
Methods:
We conducted a comprehensive systematic multivocal mapping study to evaluate the existing evidence on the inclusion of individuals with ASD in Software Engineering.
Results:
We obtained 34 primary studies from which we identified the main facilitators of motivation to learn new skills, attention to detail, and the ability to report and visualize patterns. In contrast, the main barriers detected were communication, a lack of neurodivergent computational thinking, and sensory integration. Additionally, we identified and classified four categories of proposals that allowed the inclusion of individuals with ASD: (i) using virtual reality, (ii) creating more inclusive workspaces, (iii) encouraging neurodivergent computational thinking, and (iv) improving social skills.
Conclusions:
This study identifies the principal elements that ought to be taken into consideration when allocating tasks and roles to individuals with ASD in software development.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This study provides valuable insights into the inclusion of individuals with autism spectrum disorders in Software Engineering, offering new perspectives and proposing methodological proposals for their successful integration."
https://www.sciencedirect.com/science/article/pii/S0950584924000363,UX Research practices related to Long-Term UX: A Systematic Literature Review,Suéllen=Martinelli: suellen.martinelli@estudante.ufscar.br; Larissa=Lopes: larii.albano@gmail.com; Luciana=Zaina: lzaina@ufscar.br,"Abstract
Context:
The software industry has sought to apply 
User eXperience
 (UX) practices that can help maintain a sustainable business. UX practices make it possible to conduct research and make evaluations with users through the application of methods and techniques. But few studies in the literature discuss UX Research practices with Long-Term UX.
Objective:
The objective of this paper is to identify in the literature what UX Research practices are employed by the software industry and their relationship with Long-Term UX.
Methods:
We conducted a 
Systematic Literature Review
 with string applied in search engines, besides selection criteria and quality assessment applied in the papers. We selected 45 papers that were submitted for the qualitative analysis carried out with coding techniques.
Results:
38 UX Research practices were identified and classified between formal and informal practices. We also identified 52 UX methods, techniques, and tools that are used for these UX Research practices. Our findings show that 15 out of 38 practices are related to Long-Term UX.
Conclusion:
We drew up 14 guidelines for conducting UX Research in the software industry, which includes goals, UX methods, and the means of putting them into practice.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The research on UX Research practices and Long-Term UX in the software industry is relevant, but the practical implications might be limited for early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584924000533,VALIDATE: A deep dive into vulnerability prediction datasets,Matteo=Esposito: m.esposito@ing.uniroma2.it; Davide=Falessi: falessi@ing.uniroma2.it,"Abstract
Context:
Vulnerabilities are an essential issue today, as they cause economic damage to the industry and endanger our daily life by threatening critical national security infrastructures. Vulnerability prediction supports software engineers in preventing the use of vulnerabilities by malicious attackers, thus improving the security and reliability of software. Datasets are vital to vulnerability prediction studies, as 
machine learning
 models require a dataset. Dataset creation is time-consuming, error-prone, and difficult to validate.
Objectives:
This study aims to characterise the datasets of prediction studies in terms of availability and features. Moreover, to support researchers in finding and sharing datasets, we provide the first VulnerAbiLty predIction DatAseT rEpository (
VALIDATE
).
Methods:
We perform a 
systematic literature review
 of the datasets of vulnerability prediction studies.
Results:
Our results show that out of 50 primary studies, only 22 studies (i.e., 38%) provide a reachable dataset. Of these 22 studies, only one study provides a dataset in a stable repository.
Conclusions:
Our repository of 31 datasets, 22 reachable plus nine datasets provided by authors via email, supports researchers in finding datasets of interest, hence avoiding reinventing the wheel; this translates into less effort, more reliability, and more reproducibility in dataset creation and use.",June 2024,"Security, Replicability, Vulnerability, Machine learning, Repository, Dataset",Information and Software Technology,2025-03-18T00:00:00,7.0,"The creation of a repository for vulnerability prediction datasets can benefit software engineers by providing easier access to valuable datasets, contributing to improved security and reliability of software."
https://www.sciencedirect.com/science/article/pii/S0950584924000508,Source code expert identification: Models and application,Otávio=Cury: otaviocury@ufpi.edu.br; Guilherme=Avelino: gaa@ufpi.edu.br; Pedro Santos=Neto: pasn@ufpi.edu.br; Marco Túlio=Valente: mtov@dcc.ufmg.br; Ricardo=Britto: rbr@bth.se,"Abstract
Context:
Identifying source code expertise is useful in several situations. Activities like bug fixing and helping newcomers are best performed by knowledgeable developers. Some studies have proposed repository-mining techniques to identify source code experts. However, there is a gap in understanding which variables are most related to code knowledge and how they can be used for identifying expertise.
Objective:
This study explores models of expertise identification and how these models can be used to improve a Truck Factor algorithm.
Methods:
First, we built an oracle with the knowledge of developers from software projects. Then, we use this oracle to analyze the correlation between measures from the development history and source code knowledge. We investigate the use of linear and machine-learning models to identify file experts. Finally, we use the proposed models to improve a Truck Factor algorithm and analyze their performance using data from public and private repositories.
Results:
First Authorship
 and 
Recency of Modification
 have the highest positive and negative correlations with source code knowledge, respectively. Machine learning classifiers outperformed the linear techniques (
F-Score
 = 71% to 73%) in the largest 
analyzed dataset
, but this advantage is unclear in the smallest one. The Truck Factor algorithm using the proposed models could handle developers missed by the previous expertise model with the best average 
F-Score
 of 74%. It was perceived as more accurate in computing the Truck Factor of an industrial project.
Conclusion:
If we analyze 
F-Score
, the studied models have similar performance. However, 
machine learning
 classifiers get higher 
Precision
 while linear models obtained the highest 
Recall
. Therefore, choosing the best technique depends on the user’s tolerance to 
false positives
 and negatives. Additionally, the proposed models significantly improved the accuracy of a Truck Factor algorithm, affirming their effectiveness in precisely identifying the key developers within software projects.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The study on expertise identification in source code and the improvement of the Truck Factor algorithm can be beneficial for startups in enhancing their development processes and identifying key developers within their projects.
https://www.sciencedirect.com/science/article/pii/S0950584924000326,Evaluating the effectiveness of a security flaws prevention tool,Itzhak=Gershfeld: gershitz@post.bgu.ac.il; Arnon=Sturm: sturm@bgu.ac.il,"Abstract
Context:
Securing code is crucial for all software stakeholders. Nevertheless, state-of-the-art tools are imperfect and tend to miss critical errors, resulting in zero-day vulnerabilities. Thus, there is a need for alternatives to mitigate such issues.
Objective:
We aim to facilitate an effective identification mechanism of security flaws in the early stages of development.
Method:
Following our analysis of the root causes of vulnerabilities and examining existing code analyzers, we devise a new Rule-Based Security Flaws Prevention (RbSFP) tool. The tool is based on a set of allow-list rules and consists of the following stages: (1) 
AST
 creation based on the source code and marking critical code areas; (2) Context-based code analysis that further validates the code; (3) Results’ normalization to suggest alerts and warnings. To evaluate the RbSFP tool, we utilized two complementary evaluations. The first refers to the tool’s ability to detect security flaws compared to competing tools by executing them on open-source projects. The second refers to evaluating the tool’s usability and efficiency via a controlled experiment.
Results:
We found that the outcomes were of better quality when using the RbSFP tool, and the differences were statistically significant. Thus, utilizing the new approach and tool has a significant impact as it can eliminate root causes for security flaws at the early stages of development.
Conclusion:
Using an allow-list-based approach can reduce security flaws in the code. However, further analysis and evaluation are needed to provide a more comprehensive solution.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The development of a new Rule-Based Security Flaws Prevention tool that can eliminate root causes for security flaws at the early stages of development has significant practical value and impact on European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S095058492400034X,Prevalence and severity of design anti-patterns in open source programs—A large-scale study,Alan=Liu: alanl200511@gmail.com,"Abstract
Context:
Design anti-patterns can be symptoms of problems that lead to long-term maintenance difficulty. How should development teams prioritize their treatment? Which ones are more severe and deserve more attention? Does the impact of anti-patterns and general maintenance efforts differ with different programming languages?
Objective:
In this study, we assess the prevalence and severity of anti-patterns in different programming languages and the impact of 
dynamic typing
 in Python, as well as the impact scopes of prevalent anti-patterns that manifest the violation of design principles.
Method:
We conducted a large-scale study of anti-patterns using 1717 open-source projects written in Java, C/C++, and Python. For the 288 Python projects, we extracted both explicit and dynamic dependencies and compared how the detected anti-patterns and maintenance costs changed. Finally, we removed anti-patterns involving five or fewer files to assess the impact of trivial anti-patterns.
Results:
The results reveal that 99.55% of these projects contain anti-patterns. Modularity Violation – frequent co-changes among seemingly unrelated files – is most prevalent (detected in 83.54% of all projects) and costly (incurred 61.55% of maintenance effort on average). Unstable Interface and Crossing, caused by influential but unstable files, although not as prevalent, tend to incur severe maintenance costs. Duck typing in Python incurs more anti-patterns, and the churn spent on Python files multiplies that of C/C++ and Java files. Several prevalent anti-patterns have a large portion of trivial instances, meaning that these common symptoms are usually not harmful.
Conclusion:
Implicit and visible dependencies are the most expensive to maintain, and 
dynamic typing
 in Python exacerbates the issue. Influential but unstable files need to be monitored and rectified early to prevent the accumulation of high maintenance costs. The violations of design principles are widespread, but many are not high-maintenance.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on anti-patterns in different programming languages and their impact on maintenance costs provides valuable insights, but the direct practical application on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924000314,Can serious gaming tactics bolster spear-phishing and phishing resilience? : Securing the human hacking in Information Security,Affan=Yasin: affan.yasin@outlook.com; Rubia=Fatima: rubiafatima91@hotmail.com; Zheng=JiangBin: zhengjb@nwpu.edu.cn; Wasif=Afzal: wasif.afzal@mdu.se; Shahid=Raza: shahid.raza@ri.se,"Abstract
Context:
In the digital age, there is a notable increase in fraudulent activities perpetrated by social engineers who exploit individuals’ limited knowledge of digital devices. These actors strategically manipulate human psychology, targeting IT devices to gain unauthorized access to sensitive data.
Objectives:
Our study is centered around two distinct objectives to be accomplished through the utilization of a serious game: (i) The 
primary objective
 entails delivering training and educational content to participants with a focus on 
phishing attacks
; (ii) The secondary objective aims to heighten participants’ awareness regarding the perils associated with divulging excessive information online.
Methodology:
To address these objectives, we have employed the following techniques and methods: (i) A comprehensive literature review was conducted to establish foundational knowledge in areas such as social engineering, game design, learning principles, 
human interaction
, and game-based learning; (ii) We meticulously aligned the game design with the philosophical concept of 
social engineering attacks
; (iii) We devised and crafted an advanced hybrid version of the game, incorporating the use of QR codes to generate game card data; (iv) We conducted an empirical evaluation encompassing surveys, observations, discussions, and URL assessments to assess the effectiveness of the proposed hybrid game version.
Results:
Quantitative data
 and qualitative observations suggest the “PhishDefend Quest” game successfully improved players’ comprehension of phishing threats and how to detect them through an interactive 
learning experience
. The results highlight the potential of serious games to educate people about social engineering risks.
Conclusion:
Through the evaluation, we can readily arrive at the following conclusions: (i) Game-based learning proves to be a viable approach for educating participants about phishing awareness and the associated risks tied to the unnecessary disclosure of 
sensitive information
 online; (ii) Furthermore, game-based learning serves as an effective means of disseminating awareness among participants and players concerning prevalent phishing attacks.",June 2024,"Human factor in security, Phishing attack, Scam, Education, Serious game, Information security",Information and Software Technology,2025-03-18T00:00:00,9.0,The use of serious games to educate participants about phishing awareness and risks presents an innovative approach with high potential impact on European startups dealing with cybersecurity issues.
https://www.sciencedirect.com/science/article/pii/S0950584924000351,Objectivity by design: The impact of AI-driven approach on employees' soft skills evaluation,Itzhak=Aviv: itzhakav@mta.ac.il,"Abstract
Engineers’ team collaboration skills are among software development's most important 
success factors
. Existing 
Artificial Intelligence
 practices for the engineers' soft skills assessment mainly rely on evaluations of subjective data gathered through surveys, interviews, or observations. As a result, the insights gained by these methods are biased because of the subjective data people report. To overcome the challenge of subjectivity, we offer a novel objectivity-by-design approach for continuous AI-driven team collaboration skills analytics. The method analyzes the data from workstreams gathered from data repositories like Jira. Based on the study results, we conclude that this approach enables a continuous assessment of employees' team collaboration skills, provides more accurate insights, eliminates subjective biases, and helps uncover trends and deficits on individual and team levels. Understanding and recognizing employees' strengths and weaknesses can foster an organizational culture of growth and development. An improved organizational climate is expected to result in work satisfaction, engagement, and motivation, thus positively impacting employees, businesses, and society.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The novel objectivity-by-design approach for continuous AI-driven team collaboration skills analytics can provide valuable insights for European early-stage ventures, impacting their team collaboration and success factors."
https://www.sciencedirect.com/science/article/pii/S0950584924000375,Agile software development projects–Unveiling the human-related critical success factors,Carlos=Tam: carlosvai@novaims.unl.pt,"Abstract
Context
Investment in information technology is associated with better business performance when its implementation is successful, but it has high costs in case of failure, especially for large software development projects, which typically have the highest failure rates. Agile methodologies emerged with the expectation of reducing the risk of software development project failure.
Objective
This research aims to answer the following question: What are the human-related critical success factors for agile software development projects to succeed? The research model comprises four explanatory variables (team capability, customer involvement, psychological safety, and team autonomy) and one dependent variable (success of agile software development projects).
Method
A questionnaire-based survey was carried out, resulting in 177 valid responses. A Partial Least Squares (PLS) analysis was performed to test the theoretical model.
Results
The findings indicate that team capability and customer involvement have the strongest effects on the success of agile software development projects. The results also show that psychological safety is a significant indirect success factor and that team autonomy appears to have a competing dynamic with psychological safety on the other two factors.
Conclusion
To the best of our knowledge, this is the first study to examine the direct impact of psychological safety and its indirect effect, mediated by team capability and customer involvement, on the success of agile software development projects. The mediation, moderation, and direct effects are studied, offering theoretical and practical insights.",June 2024,"Agile methodologies, Agile projects, Software development, Critical success factors, People factors, Psychological safety",Information and Software Technology,2025-03-18T00:00:00,8.0,The research on human-related critical success factors for agile software development projects has practical insights for European startups aiming to enhance project success and team dynamics.
https://www.sciencedirect.com/science/article/pii/S0950584924000521,Ensemble effort estimation for novice agile teams,Bashaer=Alsaadi: b.alsaadi@seu.edu.sa,"Abstract
CONTEXT
To establish a reliable 
development plan
, developers should investigate the software being developed. One main challenge for developers is estimating the effort required to develop the software. Agile teams deliver the software in a set of iterations, with each iteration containing user stories. Therefore, unlike traditional development, software development effort estimation (SDEE) in agile should focus on the user stories level. An inaccurate estimation has detrimental consequences for software development such as poor 
resource allocation
 or the delivery of low-quality software. However, limited works have developed new estimation methods for agile projects compared to traditional ones.
OBJECTIVES
This study introduces an ensemble model for estimating efforts in agile user stories development. It also creates a new dataset with 140 user stories, aiming for future research use.
METHODS
This research followed the 
Design Science Research
 methodology (DSR). Six individual models were examined to build the ensemble model. The top three models — Extra Trees, K-Nearest Neighbors, and Multi-Layer 
Perceptron
 — were employed. The model's performance was assessed through 
Mean Absolute Error
 (MAE), 
Mean Squared Error
 (MSE), and 
Root Mean Squared Error
 (RMSE). Additionally, an experiment tested the model's efficacy on real software projects by novice teams.
RESULTS
The results show that the ensemble model outperformed individual models, as it scored 0.78 in MAE, 1.62 in MSE, and 1.15 in RMSE. The experiment results showed that the model outperformed human estimation and proved its effectiveness in improving the accuracy of human estimation.
CONCLUSION
The findings demonstrate the model's success in refining effort estimates for novice Agile teams, leading to fewer errors. Practically, it means enhanced project planning and resource management. Additionally, developers' estimation confidence improved, indicating a positive impact on team dynamics and decision-making.",June 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The ensemble model for estimating effort in agile user stories development proves to be effective for novice Agile teams, leading to enhanced project planning and resource management, which can greatly benefit European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924000557,Studying logging practice in machine learning-based applications,Foutse=Khomh: foutse.khomh@polymtl.ca; Patrick Loic=Foalem: patrick-loic.foalem@polymtl.ca; Heng=Li: heng.li@polymtl.ca,"Abstract
Context:
Logging is a 
common practice
 in traditional software development. There have been multiple studies on the characteristics of logging in traditional software systems such as C/C++, Java, and 
Android applications
. However, logging practices in Machine Learning-based (ML-based) applications are still not well understood. The size and complexity of data and models used in ML-based applications present unique challenges for logging.
Objective:
In this paper, we aim to bridge this knowledge gap and provide insight into the logging practices in ML-based applications, making the first attempt to characterize current logging practices within a large number of open-source ML-based applications.
Method:
We conducted an empirical study on 502 open-source ML applications to understand their logging practices, combining quantitative and qualitative analyses and a survey involving 31 practitioners.
Results:
Our quantitative analysis reveals that logging in ML applications is less common than in traditional software, with info and warn log levels being popular. Top ML-specific logging libraries include MLflow, Tensorboard, Neptune, and W&B. Qualitatively, logging is used for data and model management, especially in model training. Our survey reinforces the importance of logging in experiment tracking, complementing our qualitative findings.
Conclusion:
Our research carries significant implications. It reveals distinctive ML logging practices compared to traditional software. We have highlighted the prevalence of general-purpose logging libraries in ML code, indicating a potential gap in awareness regarding ML-specific logging tools. This insight benefits researchers and developers aiming to enhance ML project reproducibility and sets the stage for exploring ML-specific logging tools’ impact on machine learning system quality and trustworthiness.",June 2024,"Logging practices, ML-based applications, Mining software repositories, Source code analysis",Information and Software Technology,2025-03-18T00:00:00,7.0,"Insights into ML-based applications' logging practices can be valuable for European startups involved in machine learning projects, offering a basis for enhancing project reproducibility and quality."
https://www.sciencedirect.com/science/article/pii/S0950584923001222,A survey on dataset quality in machine learning,Lingzhong=Meng: lingzhong@iscas.ac.cn,"Abstract
With the rise of big data, the quality of datasets has become a crucial factor affecting the performance of 
machine learning
 models. High-quality datasets are essential for the realization of data value. This survey article summarizes the research direction of dataset quality in machine learning, including the definition of related concepts, analysis of quality issues and risks, and a review of dataset quality dimensions and metrics throughout the dataset lifecycle and a review of dataset quality metrics analyzed from a dataset lifecycle perspective and summarized in literatures. Furthermore, this article introduces a comprehensive quality evaluation process, which includes a framework for dataset quality evaluation with dimensions and metrics, computation methods for quality metrics, and assessment models. These studies provide valuable guidance for evaluating dataset quality in the field of machine learning, which can help improve the accuracy, efficiency, and 
generalization ability
 of machine learning models, and promote the development and application of 
artificial intelligence
 technology.",October 2023,"Dataset, Dataset quality, Machine Learning",Information and Software Technology,2025-03-18T00:00:00,7.0,"While the survey article provides valuable insights into dataset quality evaluation in machine learning, its practical impact on startups may be more indirect. The guidance offered can help startups improve the performance and generalization ability of their models, but the direct application may vary."
https://www.sciencedirect.com/science/article/pii/S0950584924000594,Role of quantum computing in shaping the future of 6 G technology,Muhammad Azeem=Akbar: azeem.akbar@ymail.com,"Abstract
Context
The emergence of 6 G technology heralds a groundbreaking era in digital connectivity, envisaging universal and seamless links. To address the intricate computational and security requirements of this revolution, the integration of 
quantum computing
 (QC) into these networks is perceived as a promising solution.
Objective
The objective this study presents a comprehensive investigation into the potential roles and implications of QC within the context of 6 G technology.
Methodology
To address the objectives of this study, firstly, we have conducted literature survey to identify the key applications of using QC in 6 G technology. Secondly, we performed interview study with industry experts to identify the best practices related to the key application of QC in 6 G technology.
Results
Our study unfolds in two distinct stages: firstly, we identify 15 key applications of QC in 6 G technology and segmented into 4 core areas. Secondly, the literature findings were empirically validated by conducting interview study and identified 49 best practices related to one of the identified key applications of QC in 6 G technology.
Conclusion
The outcomes of this research lay a solid foundation for understanding both the pivotal applications of QC in 6 G technology and the effective practices for its implementation, thus providing valuable insights to both academics and industry practitioners.",June 2024,"6 G technology, Quantum computing, Challenges, Opportunities",Information and Software Technology,2025-03-18T00:00:00,6.0,The investigation into the potential roles of quantum computing in 6 G technology provides valuable insights for European early-stage ventures looking to stay at the forefront of technological advancements.
https://www.sciencedirect.com/science/article/pii/S0950584924000193,What does matter in the success of a decentralized application? From idea to development,Apostolos=Ampatzoglou: apostolos.ampatzoglou@gmail.com,"Abstract
Context
With the rise of 
blockchain
, various applications are running in a decentralized manner, covering the needs of various end-users. Decentralized Applications (DApps) are becoming popular in numerous application domains, ranging from 
finance
 to games, and from Non-Fungible Tokens to security mechanisms. The success of a DApp, from a financial perspective, can be perceived as the market fragment that it captures, and the volume of transactions it generates.
Objective
The goal of this study is to investigate the factors that are important for safeguarding (as much as possible) the financial success of a Decentralized Application. In this study, we focus on four management factors that could influence financial success: the context of the DApp (e.g., focusing on 
finance
, games, entertainment), the intensity of development activities (e.g., number of: commits, forks, or branches of the repository), the size of the development team and the existence of project documentation.
Method
We performed a 
case study
 on 122 DApps that were available through an open repository of 
smart contracts
, namely State-of-the-DApps. By mining the repository, we recorded two metrics that capture the financial success of the application (number of users and volume of transactions) and explored their relation to the aforementioned factors.
Results
The findings of the study suggest that the intensity of development activities is the most important factor for its financial success. Similarly, the context (i.e., the application domain) of the decentralized application is also a key-factor since it influences the number of users that the DApp will reach.
Conclusions
Based on the findings, we suggest businesses that want to enter the market of decentralized applications to balance properly between technical and business parameters. For an application to be successful, it requires both an intensive 
development process
, but also a careful consideration of the application domain.",May 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The study on factors influencing the financial success of Decentralized Applications could provide European startups in the blockchain space with valuable guidance on balancing technical and business parameters for success.
https://www.sciencedirect.com/science/article/pii/S0950584924000284,Model driven engineering for machine learning components: A systematic literature review,John=Grundy: john.grundy@monash.edu; Chetan=Arora: chetan.arora@monash.edu; Hira=Naveed: hira.naveed@monash.edu; Hourieh=Khalajzadeh: hourieh.khalajzadeh@deakin.edu.au; Omar=Haggag: omar.haggag@monash.edu,"Abstract
Context:
Machine Learning
 (ML) has become widely adopted as a component in many modern 
software applications
. Due to the large volumes of data available, organizations want to increasingly leverage their data to extract meaningful insights and enhance business profitability. ML components enable predictive capabilities, 
anomaly detection
, recommendation, accurate image and text processing, and informed decision-making. However, developing systems with ML components is not trivial; it requires time, effort, knowledge, and expertise in ML, data processing, and 
software engineering
. There have been several studies on the use of model-driven engineering (MDE) techniques to address these challenges when developing traditional software and cyber–physical systems. Recently, there has been a growing interest in applying MDE for systems with ML components.
Objective:
The goal of this study is to further explore the promising intersection of MDE with ML (MDE4ML) through a systematic literature review (SLR). Through this SLR, we wanted to analyze existing studies, including their motivations, MDE solutions, evaluation techniques, key benefits and limitations.
Method:
Our SLR is conducted following the well-established guidelines by Kitchenham. We started by devising a protocol and systematically searching seven databases, which resulted in 3934 papers. After iterative filtering, we selected 46 highly relevant primary studies for data extraction, synthesis, and reporting.
Results:
We analyzed selected studies with respect to several areas of interest and identified the following: (1) the key motivations behind using MDE4ML; (2) a variety of MDE solutions applied, such as 
modeling languages
, model transformations, tool support, targeted ML aspects, contributions and more; (3) the evaluation techniques and metrics used; and (4) the limitations and directions for future work. We also discuss the gaps in existing literature and provide recommendations for future research.
Conclusion:
This SLR highlights current trends, gaps and future research directions in the field of MDE4ML, benefiting both researchers and practitioners.",May 2024,"Model driven engineering, Software engineering, Artificial intelligence, Machine learning, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,9.0,"The intersection of Model-Driven Engineering with Machine Learning is explored through a systematic literature review, benefiting both researchers and practitioners."
https://www.sciencedirect.com/science/article/pii/S0950584924000156,An empirical study on metamorphic testing for recommender systems,Chengying=Mao: maochy@yeah.net; Jifu=Chen: chenjifu1989@sina.com; Xiaorong=Yi: 757927904@qq.com; Linlin=Wen: wenll97@foxmail.com,"Abstract
Context:
Recommender systems
 are widely used in various fields because they can provide decision-making guidance to users facing an overwhelming set of choices. In previous studies, the accuracy of recommendations has been the focus and has significantly improved. However, the quality issues of these systems have been overlooked. In practical applications, the reliability of recommender systems plays an important role in their acceptance by users.
Objective:
This paper aims to develop a solution for performing metamorphic testing on recommender systems, and then to evaluate their reliability based on the test results.
Methods:
A metamorphic testing framework for recommender systems is first proposed to effectively alleviate the difficulty of the test oracle (i.e., the construction of the expected output of a program). Meanwhile, a set of specific metamorphic relations for recommender systems is also designed, and an empirical analysis is conducted using three open-source recommender libraries: LibRec, PREA, and Surprise.
Results:
The effectiveness of the proposed metamorphic testing solution is confirmed through the experiments, and the comparison analysis of the designed metamorphic relations and the three recommender libraries is also conducted, yielding the rankings of both the metamorphic relations and the program libraries, respectively.
Conclusion:
The study suggests that metamorphic testing is effective in automatically revealing the reliability problems in recommender systems, without requiring test oracles.",May 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study proposes a solution for evaluating the reliability of recommender systems through metamorphic testing, which can have practical implications for system developers."
https://www.sciencedirect.com/science/article/pii/S0950584924000168,Towards sustainable software systems: A software sustainability analysis framework,Hira=Noman: hira.noman@faculty.muet.edu.pk; Naeem=Mahoto: naeem.mahoto@faculty.muet.edu.pk; Sania=Bhatti: sania.bhatti@faculty.muet.edu.pk; Adel=Rajab: adrajab@nu.edu.sa; Asadullah=Shaikh: asshaikh@nu.edu.sa,"Abstract
Context:
In today’s rapidly evolving technological landscape designing sustainable software systems requires considering the software impacts and its long-term viability. For professionals, a significant barrier lies in the need for 
practical guidelines
 and tangible frameworks for effectively incorporating sustainability considerations during 
software design
 and development.
Objective:
The study aims to help software practitioners consider sustainability during 
software design
 and development by providing systematic guidelines. We proposed a framework that enables professionals to do so by allowing them to foresee how and how much impact the software has on sustainability and its dimensions.
Methods:
The study presented a software sustainability analysis framework that helps to derive sustainability goals and extract sustainability improvement features for software systems based on their impacts on sustainability dimensions. The framework’s application is exemplified through two 
Software applications
, and sustainability guidelines have been provided.
Results:
Industry professionals with diverse roles were engaged to validate the framework’s relevance and practicality. Their feedback was collected through discussion, and direct excerpts were reported. Validation results revealed that the framework effectively addresses the key challenges professionals face in integrating sustainability into their practices.
Conclusion:
Professionals acknowledged the importance of considering sustainability aspects in software design and development and appreciated the structured approach provided by the framework.",May 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides systematic guidelines for incorporating sustainability considerations into software design, addressing a significant barrier for professionals in the field."
https://www.sciencedirect.com/science/article/pii/S095058492400017X,Co-evolving scenarios and simulated players to locate bugs that arise from the interaction of software models of video games,Isis=Roca: iroca@usj.es; Óscar=Pastor: opastor@pros.upv.es; Carlos=Cetina: ccetina@usj.es; Lorena=Arcega: larcega@usj.es,"Abstract
Context:
Game 
Software Engineering
 (GSE) is a field that focuses on developing and maintaining the software part of 
video games
. A key component of video game development is the utilization of game engines, with many engines using software models to capture various aspects of the game.
Objective:
A challenge that GSE faces is the localization of bugs, mainly when working with large and intricated software models. Additionally, the interaction between software models (i.e. bosses, enemies, or environmental elements) during gameplay is often a significant source of bugs. In response to this challenge, we propose a co-evolution approach for bug localization in the software models of video games, called CoEBA.
Methods:
The CoEBA approach leverages Search-Based Software Engineering (SBSE) techniques to locate bugs in software models while considering their interactions. We conducted an evaluation in which we applied our approach to a commercial video game, Kromaia. We compared our approach with a state-of-the-art baseline approach that relied on the bug localization approach used by Kromaia’s developers and a random search used as a sanity check.
Results:
Our co-evolution approach outperforms the baseline approach in precision, recall, and F-measure. In addition, to provide evidence of the significance of our results, we conducted a statistical analysis. that shows significant differences in precision and recall values.
Conclusion:
The proposed approach, CoEBA, which considers the interaction between software models, can identify and locate bugs that other bug localization approaches may have overlooked.",May 2024,"Bug localization, Model interaction, Game software engineering, Search-based software engineering, Model-driven engineering",Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed CoEBA approach addresses a significant challenge in game software engineering, showing better performance than baseline approaches, which can have a positive impact on early-stage ventures in the gaming industry."
https://www.sciencedirect.com/science/article/pii/S0950584924000120,Investigating the relationship between personalities and agile team climate: A replicated study,Mirko=Perkusich: mirko@virtus.ufcg.edu.br,"Abstract
Context
A study in 2020 (S1) explored the relationship between 
personality traits
 and team climate perceptions of software professionals working in agile teams. S1 surveyed 43 software professionals from a large 
telecom company
 in Sweden and found that a person's ability to get along with team members (
Agreeableness
) influences significantly and positively the perceived level of team climate. Further, they observed that 
personality traits
 accounted for less than 15 % of the variance in team climate.
Objective
The study described herein replicates S1 using data gathered from 148 software professionals from an industrial partner in Brazil.
Method
We used the same research methods as S1. We employed a survey to gather the personality and climate data, which was later analyzed using correlation and 
regression analyses
. The former aimed to measure the level of association between 
personality traits
 and climate and the latter to estimate team climate factors using 
personality traits
 as predictors.
Results
The results for the correlation analyses showed statistically significant and positive associations between two personality traits - 
Agreeableness
 and 
Conscientiousness
, and all five team climate factors. There was also a significant and positive association between 
Openness
 and 
Team Vision.
 Our results corroborate those from S1, with respect to two personality traits – 
Openness
 and 
Agreeableness
; however, in S1, 
Openness
 was significantly and positively associated with 
Support for Innovation
 (not 
Team Vision
). In regard to 
Agreeableness
, in S1 it was also significantly and positively associated with 
perceived team climate
. Furthermore, our regression models also support S1’s findings - personality traits accounted for less than 15 % of the variance in team climate.
Conclusion
Despite variances in location, sample size, and 
operational domain
, our study confirmed S1′s results on the limited influence of personality traits. 
Agreeableness
 and 
Openness
 were significant predictors for team climate, although the predictive factors differed. These discrepancies highlight the necessity for further research, incorporating larger samples and additional 
predictor variables
, to better comprehend the intricate relationship between personality traits and team climate across diverse cultural and professional settings.",May 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study replicates and confirms previous research findings, providing valuable insights into the relationship between personality traits and team climate in agile software development teams, which can be beneficial for early-stage startups looking to build effective teams."
https://www.sciencedirect.com/science/article/pii/S0950584924000181,A random forest model for early-stage software effort estimation for the SEERA dataset,Rasha=Osman: rosman@ieee.org,"Abstract
Context
Publicly available 
software cost estimation
 datasets are outdated and may not represent current industrial environments. Thus most research has concentrated on the development and evaluation of estimation models with limited evidence of their applicability to industrial practice. Moreover, these datasets and models may not be applicable in (under-represented) technically and economically constrained environments such as the software development environment in Sudan.
Objective
This paper aims to develop a 
machine learning
 model that is suitable for the Sudanese software industry. To demonstrate the suitability of our approach, we evaluate our model using the publicly available SEERA (
S
oftware engin
EER
ing in Sud
A
n) dataset, which is a 
software cost estimation
 dataset from organizations in Sudan.
Method
We demonstrated the suitability of the SEERA dataset for effort estimation by comparing the attributes that had a high correlation with 
actual effort
 and 
actual duration
 to the cost factors identified by (Sudanese) experts. In addition, we developed an early-stage 
Random Forest model
 to estimate project effort and duration from the SEERA dataset. Early-stage estimation is in-line with current Sudanese industrial practice. We investigated the impact of oversampling, feature selection, heterogeneity and local environmental factors on model accuracy.
Results
Our experimental results showed that the 
Random Forest model
 with oversampling and feature selection provided accurate estimates that were better than random guessing (standardized accuracy > 70 %). Our results were similar to accuracies reported in the literature. In addition, we demonstrated that our random forest model provided estimations that were more accurate than (Sudanese) 
expert judgement
.
Conclusion
This study has demonstrated the feasibility of our random forest model for early-stage effort and duration estimation for Sudanese software projects. The results demonstrate the importance of representative models and datasets for non-traditional technical environments. Further research is required to investigate the impact of local environmental factors on software cost estimation.",May 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The development of a machine learning model for software cost estimation in Sudanese software industry shows promise, but further research is needed to fully assess its impact on early-stage ventures in this specific region."
https://www.sciencedirect.com/science/article/pii/S0950584924000302,An exploratory study of software artifacts on GitHub from the lens of documentation,Akhila Sri Manasa=Venigalla: cs19d504@iittp.ac.in; Sridhar=Chimalakonda: ch@iittp.ac.in,"Abstract
Context:
The abundance of software artifacts in open-source repositories has been analyzed by researchers from many perspectives, to address challenges in downstream tasks such as bug localization, code clone detection and so on. However, there is limited exploration of artifacts such as pull-requests and issues from a documentation perspective.
Objective:
We aim to explore the presence of information useful for documentation in different sources within the software projects. We present an exploratory analysis of 1.38M artifacts extracted from 950 GitHub repositories that analyses the content present in multiple software artifacts from a documentation perspective.
Method:
We arrive at a list of documentation types and sources through card-sorting and a developer survey. We apply 
topic modeling
 on the data extracted from 1.38M software artifacts based on these lists and study the extent of documentation-related information present in the software artifacts. The exploratory analysis of the artifacts listed is consolidated into the ‘
DocMine
’ dataset that comprises 50.63M textual sentences spanning across repositories written in four different programming languages.
Results:
We observe that about 28.1% of content extracted from the artifacts contains information related to features and modifications of the project at a higher level, and that 
pull-requests
 and 
issues
 comprise 18.26% and 17.85% of the extracted information.
Conclusion:
The presence of information about the projects in 
pull-requests
 and 
issues
 indicates immense scope in analyzing and processing multiple software artifacts for the purposes of generating 
software documentation
 and beyond. We envision that this study could open up a new line of research in 
software documentation
.",May 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The 'DocMine' dataset and exploratory analysis provide valuable insights into extracting documentation-related information from software artifacts, potentially opening up new research avenues for software documentation, which could benefit early-stage ventures in software development."
https://www.sciencedirect.com/science/article/pii/S0950584924000338,Mashup-oriented API recommendation via pre-trained heterogeneous information networks,Shuangyin=Li: shuangyinli@scnu.edu.cn,"Abstract
Combining different Web APIs to create Mashups has become very popular nowadays. Choosing suitable ones from massive Web APIs is of vital importance for efficient Mashup creations. A number of Mashup-oriented API recommendation methods have been proposed to address this issue, but they have limitations in their ability to exploit the rich attributes and connection data of Web APIs, which impedes their performance. By modeling the API-related data as a heterogeneous information network and using pre-training technology, this paper proposes an accurate API recommendation method, named PHRec. In this method, the meta paths of APIs in the heterogeneous information network are exploited to obtain their 
context semantics
; the method adopts an 
attention mechanism
. Extensive experiments have been conducted with a real Web API dataset to evaluate the proposed method. The experimental results demonstrate that it significantly outperforms the state-of-the-art methods in the Web API recommendation task.",May 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The PHRec method for API recommendation shows significant improvements over existing methods, which can be beneficial for startups looking to efficiently create Mashups using Web APIs, improving their product development process."
https://www.sciencedirect.com/science/article/pii/S0950584923002501,Skills development for software engineers: Systematic literature review,Giovana Giardini=Borges: giovana.giardini@unesp.br,"Abstract
Context
A good software professional must have technical and non-technical skills, that is, hard and soft skills, to deal with the diverse challenges they will encounter throughout their career. To make this possible, such professional must develop these abilities from the undergraduate.
Objective
This research aims to identify the necessary soft skills for future Software Engineers and the teaching methodologies that contribute to developing such skills from the undergraduate, keeping the students motivated. In addition, this study proposes a framework to help educators conduct a teaching-learning process that includes hard and soft skills during the undergraduate of future Software Engineers.
Methodology
A Systematic Literature Review was performed on six databases, resulting in 56 selected articles identifying the soft skills and the teaching methodologies desired to train Software Engineers. These were the base for the proposed framework.
Results
We proposed a grouping of soft skills found in the literature totaling 33 soft skills. Furthermore, since were found, in the literature, definitions for only 23, this study also defined the other ten soft skills addressed. Regarding the most used and indicated methodologies for developing soft skills in undergraduate students, it was possible to organize them by the principal and auxiliary methodologies. Finally, a framework was proposed to assist in the development of hard and soft skills in undergraduate students, focused on Software Engineering, the FraSSD - Framework for Soft Skills Development.
Conclusion
The proposed framework can contribute to educators’ critical thinking about applying the most effective teaching methodologies for developing hard and soft skills in an undergraduate class, improving the teaching-learning process. This study also evidences the most relevant soft skills for Software Engineers, encouraging the constant search to improve their soft skills aligned with their hard skills since graduation.",April 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The proposed framework for developing soft skills in Software Engineers could have a positive impact on early-stage ventures by enhancing the capabilities of team members. However, the focus on undergraduate education may limit its direct applicability to startups."
https://www.sciencedirect.com/science/article/pii/S0950584924000016,Towards a taxonomy of privacy requirements based on the LGPD and ISO/IEC 29100,Edna=Dias Canedo: ednacanedo@unb.br,"Abstract
Context:
Ensuring compliance with current data privacy legislation poses a significant challenge for software development teams, demanding adaptations to processes in order to align with legal requirements.
Objective:
This study proposes a comprehensive taxonomy of privacy requirements, drawing from the Brazilian General 
Data Protection Law
 (LGPD) and ISO/IEC 29100. The aim is to assist software development teams in navigating the complexities of legal compliance.
Method:
To define the research gap, we conducted a systematic literature review (SLR) initially, identifying existing taxonomies of privacy requirements. Subsequently, we applied the Goal-Based Requirements Analysis Method (GBRAM) to extract privacy requirements from LGPD and ISO/IEC 29000. Finally, we implemented the proposed taxonomy in the privacy policies of Brazil’s three largest banks.
Results:
The taxonomy comprises 129 requirements, categorized into 10 distinct groups across 5 contexts. In applying the taxonomy to ISO/IEC 29100, analysis of 63 statements for GDPR+ISO/IEC 29100 yielded 33 requirements, whereas for LGPD+ISO/IEC 29100, 58 statements resulted in 57 requirements. Application of the taxonomy revealed adherence percentages ranging from 40% to 71% concerning the evaluated solutions.
Conclusions:
The outcomes strongly suggest that major corporations are yet to achieve full LGPD compliance. We posit that the proposed taxonomy offers a valuable industry tool for validating LGPD compliance within implemented systems, as exemplified by our successful use case with Brazilian banks.",April 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The comprehensive taxonomy of privacy requirements proposed in this study could directly benefit European early-stage ventures by assisting software development teams in achieving compliance with data privacy legislation. The practical implications and clear industry application make this abstract highly valuable.
https://www.sciencedirect.com/science/article/pii/S0950584923000277,Squeeziness for non-deterministic systems,Alfredo=Ibias: a.ibias@sanoscience.org; Manuel=Núñez: mn@sip.ucm.es,"Abstract
Context:
Failed 
Error Propagation
 greatly reduces the effectiveness of Software Testing by masking faults present in the code. This situation happens when the System Under Test executes a faulty statement, the state of the system is affected by this fault, but the expected output is observed. Therefore, it is a must to assess its impact in the testing process. Squeeziness has been shown to be a useful measure to assess the likelihood of fault masking in deterministic systems.
Objective:
The main goal of this paper is to define a new Squeeziness notion that can be used in a scenario where we may have non-deterministic behaviours. The new notion should be a conservative extension of the previous one. In addition, it would be necessary to evaluate whether the new notion appropriately estimates the likelihood that a component of a system introduces Failed Error Propagation.
Method:
We defined our black-box scenario where non-deterministic behaviours might appear. Next, we presented a new Squeeziness notion that can be used in this scenario. Finally, we carried out different experiments to evaluate the usefulness of our proposal as an appropriate estimation of the likelihood of Failed Error Propagation.
Results:
We found a high correlation between our new Squeeziness notion and the likelihood of Failed Error Propagation in non-deterministic systems. We also found that the extra computation time with respect to the deterministic version of Squeeziness was negligible.
Conclusion:
Our new Squeeziness notion is a good measure to estimate the likelihood of Failed Error Propagation being introduced by a component of a system (potentially) showing non-deterministic behaviours. Since it is a conservative extension of the original notion and the extra computation time needed to compute it, with respect to the time needed to compute the former notion, is very small, we conclude that the new notion can be safely used to assess the likelihood of fault masking in deterministic systems.",June 2023,"Software testing, Failed error propagation, Non-deterministic systems, Information theory",Information and Software Technology,2025-03-18T00:00:00,8.0,The new Squeeziness notion for assessing Failed Error Propagation in non-deterministic systems can have direct practical applications and benefits for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584923002495,Test Code Flakiness in Mobile Apps: The Developer’s Perspective,Filomena=Ferrucci: fferrucci@unisa.it; Fabio=Palomba: fpalomba@unisa.it; Valeria=Pontillo: valeria.pontillo@vub.be,"Abstract
Context:
Test flakiness arises when test cases have a non-deterministic, intermittent behavior that leads them to either pass or fail when run against the same code. While researchers have been contributing to the detection, classification, and removal of flaky tests with several empirical studies and automated techniques, little is known about how the problem of test flakiness arises in mobile applications.
Objective:
We point out a lack of knowledge on: (1) The prominence and harmfulness of the problem; (2) The most frequent root causes inducing flakiness; and (3) The strategies applied by practitioners to deal with it in practice. An improved understanding of these matters may lead the 
software engineering
 research community to assess the need for tailoring existing instruments to the mobile context or for brand-new approaches that focus on the peculiarities identified.
Methods:
We address this gap of knowledge by means of an empirical study into the mobile developer’s perception of test flakiness. We first perform a systematic grey literature review to elicit how developers discuss and deal with the problem of test flakiness in the wild. Then, we complement the systematic review through a survey study that involves 130 mobile developers and that aims at analyzing their experience on the matter.
Results:
The results of the grey literature review indicate that developers are often concerned with flakiness connected to 
user interface elements
. In addition, our survey study reveals that flaky tests are perceived as critical by mobile developers, who pointed out major production code- and source code design-related root causes of flakiness, other than the long-term effects of recurrent flaky tests. Furthermore, our study lets the diagnosing and fixing processes currently adopted by developers and their limitations emerge.
Conclusion:
We conclude by distilling lessons learned, implications, and future research directions.",April 2024,"Test Code Flakiness, Software Testing, Mobile Apps Development, Mixed-Method Research",Information and Software Technology,2025-03-18T00:00:00,3.0,"While the study on test flakiness in mobile applications addresses important issues, such as flaky tests perception by developers, the direct impact on European early-stage ventures may be limited as the focus is more specific to mobile development rather than general software startups."
https://www.sciencedirect.com/science/article/pii/S0950584923002471,Process mining software engineering practices: A case study for deployment pipelines,Ana Filipa=Nogueira: afnog@dei.uc.pt; Mário=Zenha-Rela: mzrela@dei.uc.pt,"Abstract
Context:
In mature software development organizations the 
ci/cd
 pipeline is the only route to deploy software into production. While the workflow of this process seems straightforward, the reality is different since exceptions and deviations are the norm in actual industry practice. In this context, Process Mining appears as a promising technique to uncover deviations and check compliance with standardized 
DevOps
 processes, and highlight bottlenecks and potential improvement areas.
Objective:
This paper presents a 
case study
 designed to assess the potential of using 
Process Mining techniques
 to provide visibility into the deployment pipeline.
Method:
This research uses raw event data extracted from the continuous practices toolchain, which is then used to compute a comprehensive set of DevOps-specific metrics, thus supporting objective monitoring of the quality and efficiency of the deployment workflow. The study focuses on different development units in the Engineering team, each working in a distinct 
business context
 but sharing standard practices.
Results:
We verified that even though there are standards for the deployment pipelines, each team’s workflow denotes local variations with unique points for improvement that are highly coupled to their business unit context. We observed that each team’s pipeline has different temporal profiles that reflect their context and work practices. Additionally, we identified a set of deployment pipeline metrics focusing on process compliance, efficiency, and deployment stability.
Conclusion:
The main contributions of this paper include (1) the description of an actual application of Process Mining to the deployment pipeline of a highly complex e-commerce platform, (2) how this approach provided an objective understanding of the efficiency and quality of the development workflow, (3) how this process-centric view, combined with domain-specific DevOps metrics, supports continuous practices, and (4) how Developers can analyse their workflows by applying Process Mining while using standard tools like GitLab and PM4Py.",April 2024,"ci/cd, DevOps, Process mining, Temporal profiling, Continuous improvement, Software engineering",Information and Software Technology,2025-03-18T00:00:00,8.0,"The case study on using Process Mining techniques to assess the deployment pipeline offers valuable insights for software development organizations, including early-stage ventures. The potential for uncovering improvements and bottlenecks aligns with the needs of startups looking to streamline their development processes."
https://www.sciencedirect.com/science/article/pii/S0950584924000090,A longitudinal study on the temporal validity of software samples,Juan Andrés=Carruthers: jacarruthers@exa.unne.edu.ar,"Abstract
Context
In Empirical 
Software Engineering
, it is crucial to work with 
representative samples
 that reflect the current state of the software 
industry
. An important consideration, especially in rapidly changing fields like software development, is that if we use a sample collected years ago, it should continue to represent the same population in the present day to produce generalizable results. However, it is seldom the case in which a software sample built several years ago accurately depicts the current state of the development 
industry
. Nevertheless, many recent studies rely on rather old datasets (seven or more years of age) to conduct their investigations.
Objective
To analyze the evolution of a population of open-source projects, determine the likelihood of detecting significant differences over time, and study the activity history of the projects.
Method
We performed a longitudinal study with 72 snapshots of quality projects from Github, covering the period between July 1
st
 2017 and June 1
st
 2023. We recorded monthly values of seven repository metrics (contributors, commits, closed pull-requests, merged pull-requests, closed issues, number of stars and forks), encompassing data from a total of 1991 repositories.
Results
We observed significant changes in all the metrics evaluated, with most cases showing negligible to small 
effect sizes
. Notably, merged pull-requests registered medium 
effect sizes
. The evolution was not equal in all the metrics, however, after five years it was unlikely that a sample of projects remained representative for any of the analyzed metrics, showing probabilities below 25%.
Conclusion
Although the temporal validity of a sample depends on the specific data being studied, employing datasets created several years ago does not appear to be a sound strategy if the aim is to produce results that can be extrapolated to the current state of the population.",April 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides valuable insights into the temporal validity of software development datasets, highlighting the importance of up-to-date samples for accurate results, which can impact early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924000107,Automatic smart contract comment generation via large language models and in-context learning,Xiang=Chen: xchencs@ntu.edu.cn; Junjie=Zhao: zhaojunjie225@gmail.com; Guang=Yang: novelyg@outlook.com; Yiheng=Shen: yiheng.s@outlook.com,"Abstract
Context:
Designing effective automatic 
smart contract
 comment generation approaches can facilitate developers’ comprehension, boosting 
smart contract
 development and improving 
vulnerability detection
. The previous approaches can be divided into two categories: fine-tuning paradigm-based approaches and information retrieval-based approaches.
Objective:
However, for the fine-tuning paradigm-based approaches, the performance may be limited by the quality of the gathered dataset for the downstream task and they may have knowledge-forgetting issues, which can reduce the generality of the fine-tuned model. While for the information retrieval-based approaches, it is difficult for them to generate high-quality comments if similar code does not exist in the historical repository. Therefore we want to utilize the domain knowledge related to smart contract code comment generation in 
large language models
 (LLMs) to alleviate the disadvantages of these two types of approaches.
Method:
In this study, we propose an approach SCCLLM based on LLMs and in-context learning. Specifically, in the demonstration selection phase, SCCLLM retrieves the top-
k
 code snippets from the historical corpus by considering syntax, semantics, and 
lexical information
. In the in-context learning phase, SCCLLM utilizes the retrieved code snippets as demonstrations for in-context learning, which can help to utilize the related knowledge for this task in the LLMs. In the LLMs inference phase, the input is the target smart contract code snippet, and the output is the corresponding comment generated by the LLMs.
Results:
We select a large corpus from a smart contract community Etherscan.io as our experimental subject. Extensive experimental results show the effectiveness of SCCLLM when compared with baselines in automatic evaluation and human evaluation. We also show the rationality of our customized demonstration selection strategy in SCCLLM by ablation studies.
Conclusion:
Our study shows using LLMs and in-context learning is a promising direction for automatic smart contract comment generation, which calls for more follow-up studies.",April 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed SCCLLM approach using LLMs and in-context learning shows promising results for automatic smart contract comment generation, offering practical value for startups in the blockchain industry."
https://www.sciencedirect.com/science/article/pii/S0950584924000144,A deep semantics-aware data augmentation method for fault localization,Jian=Hu: jianhu@cqu.edu.cn; Yan=Lei: yanlei@cqu.edu.cn,"Abstract
Context:
Fault localization
 (FL) techniques are employed to identify the relationship between program statements and failures by analyzing runtime information. They rely on the statistics of input data to explore the underlying correlation rooted in it. Consequently, the quality of input data is of 
utmost importance
 for FL. However, in practice, passing tests significantly outnumber failing tests regarding a fault. This leads to a 
class imbalance
 challenge that can adversely affect the effectiveness of FL.
Objective:
To tackle the issue of 
imbalanced data
 in fault localization, we propose 
PRAM
: a dee
P
 semantic-awa
R
e d
A
ta augmentation 
M
ethod to improve the effectiveness of 
FL methods
.
Method:
PRAM
 utilizes program dependencies to enhance the 
semantic context
, thus showing how a failure is caused. Then, 
PRAM
 employs mixup method to synthesize new failing test samples by merging two real 
failing test cases
 with a random ratio to balance the input data. Finally, 
PRAM
 feeds the balanced data consisting of synthesized 
failing test cases
 and original test cases to FL techniques. To evaluate the effectiveness of 
PRAM
, we conducted large-scale experiments on 330 versions of nine large-sized real programs for six state-of-the-art 
FL methods
, two data optimization methods and two 
data augmentation
 methods.
Results:
Our experimental results show that 
PRAM
 outperforms in most cases for Top-K metrics and reduces the number of checked statements from 40.38% to 80.04% compared with the original FL methods. Furthermore, 
PRAM
 reduces the checked statements from 16.92% to 56.98% for data optimization methods and from 12.48% to 26.82% for 
data augmentation
 methods.
Conclusion:
The experimental results show that 
PRAM
 is not only more effective than the original FL methods but also more effective than two representative data optimization methods and two data augmentation methods, which indicates that 
PRAM
 is a universal effective data augmentation method for various FL methods.",April 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"PRAM demonstrates significant improvements in fault localization by addressing the imbalanced data challenge, providing a universal effective data augmentation method that can benefit early-stage ventures in software development."
https://www.sciencedirect.com/science/article/pii/S0950584923002185,Towards the definition of a research agenda on mobile application testing based on a tertiary study,Pedro Henrique=Kuroishi: phk@ufscar.br; José Carlos=Maldonado: jcmaldon@icmc.usp.br; Auri Marcelo Rizzo=Vincenzi: auri@ufscar.br,"Abstract
Context:
Mobile application testing has gained considerable attention in recent years since mobile devices have become increasingly present in our lives. Unlike traditional software, mobile application testing has to deal with peculiarities, such as screen size and densities, different operating systems, and multiple sensors that increase the complexity of testing.
Objective:
This paper summarizes and analyzes the current secondary studies on mobile application testing through a tertiary study.
Method:
We selected and analyzed 21 secondary studies related to mobile application testing.
Results:
We categorized 21 secondary studies according to their main and specific 
research topics
, test objectives, and testing platforms. Furthermore, we analyze 87 gaps and challenges identified by the secondary studies to understand which gaps have already been addressed and which gaps are still uncovered.
Conclusion:
Based on the results, we propose a 
research agenda
 with 15 open challenges related to mobile application testing to help future research.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the research agenda proposed in the study is useful for defining future research directions, the practical impact on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923002264,Vulnerability detection based on federated learning,Yang=Xin: yangxin@bupt.edu.cn,"Abstract
Context:
Detecting 
potential vulnerabilities
 is a key step in defending against network attacks. However, manual detection is time-consuming and requires expertise. Therefore, 
vulnerability detection
 must require automated techniques.
Objective:
Vulnerability detection methods based on 
deep learning
 need to rely on sufficient vulnerable code samples. However, the problem of code islands has not been extensively researched. For example, in the case of multi-party vulnerability data, how to securely combine multi-party data to improve 
vulnerability detection
 performance. From the perspectives of 
data augmentation
 and data security, we propose a 
v
ulnerability 
d
etection framework 
b
ased on 
f
ederated 
l
earning (VDBFL). VDBFL is a new model for vulnerability code detection that combines multi-party data.
Method:
Firstly, VDBFL utilizes the code property graph as a code representation. The code property graph contains various 
semantic dependencies
 of the code. Secondly, VDBFL utilizes 
graph neural networks
 and 
convolutional neural networks
 as the code feature extractor. VDBFL utilizes the jump-structured graph 
attention network
 to aggregate node information of important neighbors. Finally, VDBFL utilizes horizontal 
federated learning
 to train a local vulnerability detection model for the client.
Result:
In the real world, VDBFL improves F1-Score by 37.4% compared to the vulnerability detection method Reveal. Among the 5401 vulnerability samples, VDBFL detected 11.8 times more vulnerabilities than Reveal.
Conclusion:
Under different datasets, VDBFL has shown better performance than advanced vulnerability detection methods in multiple metrics. In addition, the 
federated learning
 stage of VDBFL can be expanded on top of the feature extraction stage of any vulnerable detection method.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The proposed Vulnerability Detection Framework based on Federated Learning shows significant improvement in detecting vulnerabilities. This has practical value for early-stage ventures dealing with network security.
https://www.sciencedirect.com/science/article/pii/S095058492300232X,Relating team atmosphere and group dynamics to student software development teams’ performance,Sherlock A.=Licorish: sherlock.licorish@otago.ac.nz,"Abstract
Context
While the 
software engineering
 community (i.e., those involved with engineering software) is constantly in search of insights into team atmosphere and group dynamics and the way these issues impact team performance, little opportunities typically exist to explore this issue. Student projects offer an opportunity for us to understand these issues, and particularly if these students are on the verge of leaving university for post-study work and using similar practices to those used in 
industry
.
Objective
We explore a range of student software development projects’ data and students’ open-ended responses to five group dynamics categories: communication, 
time management
, commitment, problem analysis and solving, and initiative and involvement.
Method
We analyse both quantitative and qualitative data to study the variation in group dynamics across teams developing different software and how these variations correlated with team satisfaction. We also explore the group dynamics themes that evolve from students’ open responses in relation to the five categories. Furthermore, we relate the prevalence of the themes to various software development performance metrics, before exploring the opportunity of predicting an optimum team dynamics.
Results
We observe variations in the way different teams work, but higher performing teams also committed more to their projects. Various group dynamics themes were evident among functional teams, and specific patterns were more pronounced when teams were productive. Further, while there is no specific group dynamics pattern that predicts project success, successful teams were most organised and reflective.
Conclusion
Competence may set the tone for positive group dynamics and team performance. Also, an achievement-driven orientation is as important as the soft skills and interpersonal aspects.",March 2024,"Team atmosphere, Group dynamics, Software development projects, Team performance",Information and Software Technology,2025-03-18T00:00:00,6.0,"While the study on group dynamics is insightful, it may have limited direct impact on European early-stage ventures or startups as it mainly focuses on student projects."
https://www.sciencedirect.com/science/article/pii/S0950584923002331,"BIGOWL4DQ: Ontology-driven approach for Big Data quality meta-modelling, selection and reasoning",Cristóbal=Barba-González: cbarba@uma.es; Ismael=Caballero: ismael.caballero@uclm.es; Ángel Jesús=Varela-Vaca: ajvarela@us.es; José A.=Cruz-Lemus: joseantonio.cruz@uclm.es; María Teresa=Gómez-López: maytegomez@us.es; Ismael=Navas-Delgado: ismael@uma.es,"Abstract
Context:
Data quality should be at the core of many 
Artificial Intelligence
 initiatives from the very first moment in which data is required for a successful analysis. Measurement and evaluation of the level of quality are crucial to determining whether data can be used for the tasks at hand. Conscientious of this importance, industry and academia have proposed several 
data quality measurements
 and assessment frameworks over the last two decades. Unfortunately, there is no common and shared vocabulary for data quality terms. Thus, it is difficult and time-consuming to integrate data quality analysis within a (Big) Data workflow for performing Artificial Intelligence tasks. One of the main reasons is that, except for a reduced number of proposals, the presented vocabularies are neither machine-readable nor processable, needing human processing to be incorporated.
Objective:
This paper proposes a unified data quality measurement and assessment information model. This model can be used in different environments and contexts to describe data quality measurement and evaluation concerns.
Method:
The model has been developed as an ontology to make it interoperable and machine-readable. For better interoperability and applicability, this ontology, BIGOWL4DQ, has been developed as an extension of a previously developed ontology for describing 
knowledge management
 in 
Big Data analytics
.
Conclusions:
This extended ontology provides a data quality measurement and assessment framework required when designing Artificial Intelligence workflows and integrated reasoning capacities. Thus, BIGOWL4DQ can be used to describe 
Big Data
 analysis and assess the data quality before the analysis.
Result:
Our proposal has been validated with two use cases. First, the semantic proposal has been assessed using an academic use case. And second, a real-world 
case study
 within an Artificial Intelligence workflow has been conducted to endorse our work.",March 2024,"Data quality evaluation and measurement, Data quality information model, Big Data, Ontology, Decision model and notation",Information and Software Technology,2025-03-18T00:00:00,5.0,"The proposal of a unified data quality measurement and assessment information model is relevant for AI initiatives, but its immediate impact on early-stage ventures may be less pronounced."
https://www.sciencedirect.com/science/article/pii/S0950584923002288,Flakiness goes live: Insights from an In Vivo testing simulation study,Morena=Barboni: morena.barboni@unicam.it; Antonia=Bertolino: antonia.bertolino@isti.cnr.it; Guglielmo=De Angelis: guglielmo.deangelis@iasi.cnr.it,"Abstract
Context:
Test flakiness is a topmost concern in software test automation. While conducting pre-deployment testing, those tests that are flagged as flaky are put aside for being either repaired or discarded.
Objective:
We hypothesise that some flaky tests could provide useful insights if run in the field, i.e., they could help identify failures that manifest themselves sporadically during In House testing, but are later experienced in operation.
Method:
We present the first simulation study to investigate the behaviour of flaky tests when moved to the field. The work compares the behaviour of known flaky tests from an open-source library when executed in the development environment vs. when executed in a simulation of the field.
Results:
Our experimentation over 52 test methods labelled as flaky provides a first confirmation that moving from the development environment to the field, the behaviour of tests changes. In particular, the failure frequency of intermittently failing tests can increase, and we could also identify few cases of field failures that would have been hardly detected during In House testing due to the numerous combinations of inputs and states. In most cases, such flakiness was rooted in the design of the test method itself, however we could also identify an actual bug.
Conclusion:
The results of our study suggest that the identification of an intermittently failing behaviour could be a valuable hint for a test engineer, and hence flaky tests should not be dismissed right away.",March 2024,"68-04, 68-U01",Information and Software Technology,2025-03-18T00:00:00,4.0,"Investigating test flakiness behavior may be relevant for software testing practices, but the direct application to early-stage ventures or startups may not be as significant."
https://www.sciencedirect.com/science/article/pii/S0950584923002069,Privacy-Compliant Software Reuse in Early Development Phases: A Systematic Literature Review,Jenny=Guber: jguber@campus.haifa.ac.il,"Abstract
Context
Privacy-compliant software development has received substantial attention in recent years, especially with the growth of digital services and the emergence of privacy regulations and standards. The increasing popularity of open-source software repositories and reuse practices challenges privacy-compliant software development.
Objective
This paper aims to present the state-of-the-art in privacy-compliant 
software reuse
, focusing on early development phases of 
requirements engineering
, domain analysis and 
software design
, as well as to discuss the current challenges that identify directions for future research.
Method
We conducted a Systematic Literature Reviews (SLR) and analyzed 61 papers published in the last two decades, in terms of their business and technological domains, followed reuse approaches, applied privacy strategies, and utilized evaluation approaches.
Results
The reviewed studies vary in terms of business domains (e.g., healthcare, smart objects and finance) and technological domains (e.g., 
IoT
, mobile, cloud and microservices). Most of the studies do not refer to a specific regulation and if so – to 
GDPR
. Their common purpose is to support benign reuse, most notably through patterns, components & libraries and model-driven engineering, but malicious reuse is also researched to a lesser extent. A 
strong emphasis
 is put on integrating privacy strategies whose goal is building trust and transparency (in particular, inform and demonstrate), while other strategies are studied to a limited extent in 
software reuse
 context. Evaluation is commonly performed through analytical, observational and experimental approaches.
Conclusions
The operationalization of privacy compliance practices for existing software artifacts is still challenging. The challenges encompass improving trustworthiness of reused artifacts, ensuring privacy compliance in distributed architectures, bridging the gap between legal regulations and software requirements, enhancing privacy analysis and 
vulnerability detection
, supporting late application of privacy strategies, and developing objective assessments for privacy-compliant software reuse.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The paper addresses the current challenges in privacy-compliant software development, which is a relevant topic for early-stage ventures dealing with data privacy and security."
https://www.sciencedirect.com/science/article/pii/S095058492300246X,License recommendation for open source projects in the power industry,Shuhan=Wu: shuhanwu@sribd.cn,"Abstract
Context:
Establishing secure and appropriate licensing procedures for open-source software is essential in the development of a decentralized renewable energy system within the smart grid industry. Nonetheless, software developers in the power industry encounter obstacles in comprehending and electing licenses on account of factors such as resemblances in terms, intricacies of the law, compatibility of licenses, and the slow development of the open source movement in the power industry.
Objective:
This paper aims to comprehensively examine the licenses of 
open source projects
 in the power industry, which is essential for the completion and popularity of projects. A novel framework consisting of two stages (i.e. data processing and recommendation) is proposed to analyze the current situation of 
open source license
 selection in the power industry.
Method:
By analyzing 274,442 open source repositories related to 40 electricity-related keywords from GitHub, we developed a machine learning-powered license recommendation methodology. We first employed the K-means method to cluster the selected repositories and identified 6 major clusters. Next, we utilized the 
random forest
 method to predict licenses for new repositories based on the 
clustering results
. We evaluated the accuracy of the model by testing it on training and testing datasets and achieved 96% accuracy.
Results:
We found that open source repository clusters in the power industry have distinct licensing preferences reflecting their unique objectives, with MIT being the most popular due to its permissiveness, and GPL-3.0, Apache-2.0, and BSD-3-Clause being favored by clusters valuing copyleft principles, closed-source derivatives protection, and control over software use, respectively. In addition, the study recognizes the content of 
open source projects
 as a meaningful indicator for license recommendation.
Conclusion:
These insights substantially enhance comprehension of the distribution and the selection of open source licenses in the power industry, potentially aiding future research on license recommendation in this field.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The research offers a practical framework and methodology for analyzing open-source licenses in the power industry, providing valuable insights for startups in renewable energy ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923002343,Making ethics practical: User stories as a way of implementing ethical consideration in Software Engineering,Erika=Halme: erika.halme@rejlers.fi,"Abstract
Context:
Shortcomings of 
AI
 systems have recently brought ethics into the spotlight in 
Software Engineering
 (SE) in the form of 
AI
 ethics. However, actually implementing ethics into practice remains a challenge in both AI ethics and SE at large. Translating abstract ethical principles into requirements and features is difficult and lacks established processes, as well as practices and methods.
Objective:
In this study, we explored user stories as a way of implementing ethics in SE. Initially, we simply investigated whether user stories could be utilized for this purpose. After we began to consider this possible, we began to develop the concept of ethical user stories (EUSs) as a specific practice for this purpose.
Method:
We utilized a 
design science research
 (DSR) approach to first explore the use of user stories in implementing ethics, and then to develop the concept of EUS. This process featured three DSR phases through which the concept of EUS was iteratively developed with empirical data.
Results:
Over three DSR iterations, we studied 689 user stories produced in different contexts including both student and industry settings. Based on the data, we defined the concept of EUS and provided empirical validation for it.
Conclusions:
The concept of EUS provides a novel way of tackling ethics in SE. This paper presents the concept in-depth, along with practical suggestions for utilizing EUS.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study introduces a novel concept of ethical user stories for implementing ethics in software engineering practice, which could be beneficial for startups aiming to incorporate ethical considerations in their development process."
https://www.sciencedirect.com/science/article/pii/S0950584923002483,Multi-grained contextual code representation learning for commit message generation,Xiaofang=Zhang: xfzhang@suda.edu.cn; Chuangwei=Wang: 20215227033@stu.suda.edu.cn; Li=Zhang: zhangliml@suda.edu.cn,"Abstract
Commit messages, precisely describing the code changes for each commit in natural language, makes it possible for developers and succeeding reviewers to understand the code changes without digging into implementation details. However, the semantic and structural gap between code and natural language poses a significant challenge for commit message generation. Several researchers have proposed automated techniques to generate commit messages. Nevertheless, the information about the code is not sufficiently exploited. In this paper, we propose multi-grained contextual code 
representation learning
 for commit message generation (COMU). We extract multi-grained information from the changed code at the line and 
AST
 levels (i.e., Code_Diff and AST_Diff). In Code_Diff, we construct global contextual 
semantic information
 about the changed code, and mark whether a line of code has changed with three different tokens. In AST_Diff, we extract the code structure from 
source code
 changes and combine the extracted structure with four types of editing operations to explicitly focus on the detailed information of the changed part. In addition, we build the 
experimental datasets
, since there is still no publicly sufficient dataset for this task. The release of this dataset would contribute to advancing research in this field. We perform an extensive experiment to evaluate the effectiveness of COMU. The experimental evaluation and human study show that our model outperforms the 
baseline model
.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The paper proposes a cutting-edge technique for commit message generation, which can greatly benefit developers in startups by improving code understanding and collaboration."
https://www.sciencedirect.com/science/article/pii/S0950584923002458,Diversity-aware fairness testing of machine learning classifiers through hashing-based sampling,Zhenjiang=Zhao: zhenjiang@disc.lab.uec.ac.jp; Takahisa=Toda: toda@disc.lab.uec.ac.jp; Takashi=Kitamura: t.kitamura@aist.go.jp,"Abstract
Context:
There are growing concerns about algorithmic fairness, as some machine learning (ML)-based algorithms have been found to exhibit biases against protected attributes such as gender, race, age and so on. Individual fairness requires an ML classifier to produce similar outputs for similar individuals. Verification Based Testing (
Vbt
) is a state-of-the-art black-box testing algorithm for individual fairness that leverages constraint solving to generate test cases.
Objective:
Generating diverse test cases is expected to facilitate efficient detection of diverse discriminatory data instances (i.
 
e., cases that violate individual fairness). Hashing-based sampling techniques draw a sample approximately uniformly at random from the set of solutions of given Boolean constraints. We propose 
Vbt
-X, which improves 
Vbt
 with hashing-based sampling, aiming to improve its testing performance.
Method:
We realize hashing-based sampling for 
Vbt
. The challenge is that the off-the-shelf hashing-based sampling techniques cannot be integrated in a straightforward manner because the constraints in 
Vbt
 are generally not Boolean. Moreover, we propose several enhancement techniques to make 
Vbt
-X more efficient.
Results:
To evaluate our method, we conduct experiments, where 
Vbt
-X is compared to 
Vbt
, 
Sg
 and ExpGA (other well-known fairness testing algorithms) over a set of configurations consisting of several datasets, protected attributes, and ML classifiers. The results show that, with each configuration, 
Vbt
-X detects more discriminatory data instances with higher diversity than 
Vbt
 and 
Sg
. 
Vbt
-X detects discriminatory data instances with higher diversity than ExpGA, though the number of discriminatory data instances detected by 
Vbt
-X is lesser than ExpGA.
Conclusion:
Our proposed method performs better than other state-of-the-art black-box fairness testing algorithms, particularly in terms of diversity. Our method can serve to efficiently identify flaws in ML classifiers with respect to individual fairness for subsequent improvements of an ML classifier. On the other hand, although our method is specific to individual fairness, it could work for testing other aspects of a software system such as security and counterfactual explanations with some technical adaptations, which remains for future work.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The research introduces an improved fairness testing algorithm, which is crucial for startups utilizing machine learning algorithms to ensure fairness and non-discrimination in their products or services."
https://www.sciencedirect.com/science/article/pii/S0950584923002355,Unraveling quantum computing system architectures: An extensive survey of cutting-edge paradigms,Xiaolong=Xu: njuxlxu@gmail.com; Lianyong=Qi: lianyongqi@gmail.com,"Abstract
Context:
The convergence of 
physics
 and computer science in the realm of 
quantum computing
 systems has sparked a profound revolution within the computer industry. However, despite such promise, the existing focus on quantum software systems primarily centers on the generation of quantum 
source code
, inadvertently overlooking the 
pivotal role
 of the overall software architecture.
Objectives:
In order to provide comprehensive guidance to researchers and practitioners engaged in quantum software development, employing an architecture-centered development model, an extensive literature review was conducted pertaining to existing research on quantum software architecture. The analysis encompasses a detailed examination of the characteristics exhibited by these studies and the identification of prospective challenges that lie ahead in the field of quantum software architecture.
Methods:
We have closely examined instances of quantum 
software engineering
, quantum 
modeling languages
, quantum 
design patterns
, and 
quantum communication
 security to gain insights into the distinctive attributes associated with various software architecture approaches.
Results:
Our findings underscore the critical significance of prioritizing software architecture in the development of robust and efficient quantum software systems. Through the synthesis of these multifaceted aspects, both researchers and practitioners can devise quantum software solutions that are inherently architecture-centric.
Conclusion:
The software architecture of 
quantum computing
 systems plays a 
pivotal role
 in determining their ultimate success and usability. Given the ongoing advancements in 
quantum computing
 technology, the migration of traditional software architecture development methods to the domain of quantum software development holds significant importance.",March 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract provides comprehensive insights into the importance of software architecture in quantum computing, which can have significant implications for early-stage ventures in the tech industry."
https://www.sciencedirect.com/science/article/pii/S0950584923002057,Deep learning-based software bug classification,Jyoti Prakash=Meher: jpmeher.iitkgp@gmail.com; Sourav=Biswas: bsws.sourav@gmail.com; Rajib=Mall: rajib@cse.iitkgp.ac.in,"Abstract
Context:
Accurate classification of bugs can help accelerate the bug triage process, code inspection, and repair activities. In this context, many 
machine learning techniques
 have been proposed to classify bugs. The 
expressive power
 of 
deep learning
 could be used to further improve classification.
Objective:
We propose a novel deep learning-based bug 
classification approach
.
Methods:
We first build a bug taxonomy with eight bug classes, each characterized by a set of keywords. Subsequently, we heuristically annotate a moderately large set (
∼
1.36M) of software bug resolution reports using an earth-mover distance technique based on the keywords. Finally, we use four attention-based 
classification techniques
 to classify these curated bugs.
Results:
Our experiments on a carefully collected dataset indicate that our proposed technique achieved a mean F1-Score of 84.78% and a mean macro-average ROC of 98.25%.
Conclusion:
Our proposed approach was observed to outperform the existing techniques by 16.88% on an average in terms of F1-Score for the considered dataset.",February 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"The abstract presents a novel deep learning-based bug classification approach with impressive results, which can greatly benefit startups and early-stage ventures involved in software development and bug fixing."
https://www.sciencedirect.com/science/article/pii/S0950584923002094,Why and how bug blocking relations are breakable: An empirical study on breakable blocking bugs,Yanhui=Li: yanhuili@nju.edu.cn,"Abstract
Context:
Blocking bugs prevents other bugs from being fixed, which is difficult to repair and negatively impacts software quality. During software maintenance, developers usually try to break the blocking relationship between blocking and blocked bugs, e.g., propose a temporary fix.
Object:
However, to our knowledge, no studies have investigated why and how blocking relations between bugs are breakable. In this study, we aim to construct an empirical analysis to explore breakable blocking bugs (BBBs).
Method:
Specifically, we employ quantitative and qualitative analysis to study these BBBs from two aspects. One is to investigate the characteristics of these bugs, and the other is to explore why and how developers break the blocking relationship between bugs during software maintenance. We build a dataset on five large-scale open-source projects and classify bugs into three types (BBBs, normal blocking bugs, and other bugs) to compare the differences between BBBs and other types of bugs.
Results:
We observe that BBBs have higher levels of involvement, take longer to fix, and involve more complex 
source code
 than other bugs. Moreover, we summarize four reasons blocking relationships between bugs are broken, i.e., partial association (41.87%), serious influence (26.40%), time pressure (19.73%), and flawed blocking (12.21%), and three measures developers adopt to break these blocking relationships, i.e., quick patch for blocking bugs (41.33%), quick patch for blocked bugs (38.67%), and ignore the blocking relation and fix blocked bugs directly (20.00%).
Conclusion:
Through these analyses, it is meaningful for software maintainers to have a 
deeper understanding
 of the characteristics and repair practices of BBBs, which will help solve these BBBs effectively in the future.",February 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract offers valuable insights into breakable blocking bugs during software maintenance, providing useful information for startups and early-stage ventures involved in software development and bug resolution."
https://www.sciencedirect.com/science/article/pii/S0950584923002203,Improving domain-specific neural code generation with few-shot meta-learning,Zhen=Yang: zhenyang@sdu.edu.cn; Jacky Wai=Keung: Jacky.Keung@cityu.edu.hk; Zeyu=Sun: szy_@pku.edu.cn; Yunfei=Zhao: zhaoyunfei@pku.edu.cn; Ge=Li: lige@pku.edu.cn; Zhi=Jin: zhijin@pku.edu.cn; Shuo=Liu: sliu273-c@my.cityu.edu.hk; Yishu=Li: yishuli5-c@my.cityu.edu.hk,"Abstract
Context:
Neural code generation aims to automatically generate code snippets guided by Natural Language Descriptions (NLDs). In recent years, various neural code generation models for mainstream Programming Languages (PLs), such as Java and Python, have been proposed and demonostrated significant success in prior studies. Nonetheless, due to the scarcity of available training examples for some domain-specific PLs, such as Solidity, Bash, and Clojure, simply adopting previous 
neural models
 may lead to overfitting and inadequate learning.
Objective:
To overcome this challenge, we propose MetaCoder, a novel meta-learning code generation approach that efficiently extracts general-purpose knowledge from a large-scale source language and rapidly adapts to domain-specific scenarios, even with relatively few samples.
Method:
MetaCoder employs MAML, a powerful few-shot meta-learning method, to construct a 
transfer learning
 framework. This framework learns general-purpose knowledge from large-scale source languages and applies it in domain-specific target languages. To acquire more general-purpose knowledge, heterogeneous sub-tasks are constructed from the source language during the pre-training phase of MAML. As such, combining with CodeBERT and K-means, we design an unsupervised category assignment method for code generation samples, thereby exploiting the 
n
-way 
k
-shot rule to construct the heterogeneous sub-tasks. Consequently, MetaCoder can be applied to the code generation field.
Results:
We evaluate MetaCoder with both tree-based (e.g., TreeGen) and sequence-based (e.g., CodeGPT) backbones on two domain-specific PLs, including Solidity and Bash. Extensive experiments demonstrate the superior performance of our approach compared to baselines and verified its capability of code generation visually in practice.
Conclusion:
MetaCoder effectively extracts general-purpose knowledge from large-scale source languages, thereby enhancing model performance. Therefore, we highly recommend MetaCoder as a code generation approach for domain-specific PLs.",February 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"MetaCoder introduces a novel approach to code generation that addresses a specific challenge in domain-specific programming languages, showing superior performance in extensive experiments."
https://www.sciencedirect.com/science/article/pii/S0950584923002227,Understanding the implementation issues when using deep learning frameworks,Chao=Liu: liu.chao@cqu.edu.cn; Runfeng=Cai: crf@cqu.edu.cn; Yiqun=Zhou: zhouyiqun@cqu.edu.cn; Xin=Chen: xinchen@cqu.edu.cn; Haibo=Hu: haibo.hu@cqu.edu.cn; Meng=Yan: mengy@cqu.edu.cn,"Abstract
Context:
Deep Learning
 (DL) frameworks like TensorFlow can help developers implement DL applications (e.g., computer vision) faster and easier. When using DL frameworks, developers encountered a large number of questions and posted them on Stack Overflow (SO).
Objective:
The goal of this paper is to conduct a comprehensive empirical study on the SO questions, summarize the implementation issues, and suggest future opportunities.
Methods:
This paper focuses on three DL frameworks (i.e., TensorFlow, PyTorch, and Theano), groups 2,401 relevant SO questions into various implementation issues, and constructs a taxonomy. We also analyze the popularity and difficulty of these issues under the taxonomy.
Results:
For the identified various implementation issues, we constructed a taxonomy consisting of seven major categories with 63 subcategories. Our analysis reveals that 91.7% of questions are related to the implementation categories of 
data processing
, model setting, model training, and model prediction. Developers frequently address the remaining three categories (i.e., Model evaluation, 
runtime environment
, and visualization), where 
runtime environment
 is the most difficult category. Based on empirical findings, we provide some suggestions for future research.
Conclusion:
In this paper, we summarized the issues of DL implementation and proposed corresponding opportunities for future study. We expect this paper to help developers and researchers understand these issues and design better tools to improve the productivity of DL implementation.",February 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on Deep Learning frameworks implementation issues provides valuable insights for developers and researchers, suggesting future research directions."
https://www.sciencedirect.com/science/article/pii/S0950584923002240,Collaborative software design and modeling in virtual reality,Ivan=Polasek: ivan.polasek@fmph.uniba.sk,"Abstract
Context:
Software engineering
 is becoming more and more distributed. Developers and other stakeholders are often located in different locations, departments, and countries and operating within different time zones. Most online 
software design
 and modeling tools are not adequate for distributed collaboration since they do not support awareness and lack features for effective communication.
Objective:
The aim of our research is to support distributed software design activities in Virtual Reality (VR).
Method:
Using design science research methodology, we design and evaluate a tool for 
collaborative design
 in VR. We evaluate the collaboration efficiency and recall of design information when using the VR software design environment compared to a non-VR software design environment. Moreover, we collect the perceptions and preferences of users to explore the opportunities and challenges that were incurred by using the VR software design environment.
Results:
We find that there is no significant difference in the efficiency and recall of design information when using the VR compared to the non-VR environment. Furthermore, we find that developers are more satisfied with collaboration in VR.
Conclusion:
The results of our research and similar studies show that working in VR is not yet faster or more efficient than working on standard desktops. It is very important to improve the interface in VR (gestures with haptics, keyboard and voice input), as confirmed by the difference in results between the first and second evaluation.",February 2024,"Virtual reality, Collaboration, Immersion, Software development, Software modeling",Information and Software Technology,2025-03-18T00:00:00,6.0,"The research on distributed software design in Virtual Reality highlights user perceptions and preferences, but does not show significant efficiency improvements compared to non-VR environments."
https://www.sciencedirect.com/science/article/pii/S0950584923002276,Automated code-based test case reuse for software product line testing,Seonah=Lee: saleese@gnu.ac.kr,"Abstract
Context
A software product line (SPL) grows in size as a new product is developed. A new product in an SPL should be tested extensively for quality assurance. For the efficient testing, previous studies suggested reusing the existing test cases of a 
product family
. However, either their methods were not efficient because interventions from human experts, specifications, architecture and/or traceabilities for test cases were required.
Objective
To address these limitations, we propose an Automated Code-based Test case reuse for SPLs (ActSPL). ActSPL automatically identifies reusable test cases for new products of a 
product family
 using 
source code
 and test cases.
Method
ActSPL automatically constructs a hash-based 
traceability links
 between test cases and 
source code
 of a product family. Using the 
traceability links
, ActSPL selects reusable test cases for a given new product from existing test cases of the product family.
Results
We evaluated ActSPL in terms of the effectiveness and cost reduction of reusing test cases with five open-source SPLs. The evaluation results showed that ActSPL, on average, achieved 100 % precision and 62 % recall. In addition, ActSPL, on average, saved 47.5 % of time required for testing a new product from scratch.
Conclusion
Our study shows the feasibility of ActSPL reusing SPL test cases based on source code and test cases. Our results can be a basis for successive studies for automated code-based SPL testing.",February 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"ActSPL proposes an automated test case reuse method for software product lines, demonstrating effectiveness and significant time savings in testing new products."
https://www.sciencedirect.com/science/article/pii/S0950584923002252,An empirical study on the performance and energy costs of ads and analytics in mobile web apps,Christos=Petalotis: c.petalotis@student.vu.nl; Luka=Krumpak: l.krumpak@student.vu.nl; Maximilian Stefan=Floroiu: m.floroiu@student.vu.nl; Laréb Fatima=Ahmad: l.f.ahmad@student.vu.nl; Shashank=Athreya: s.m.athreya@student.vu.nl; Ivano=Malavolta: i.malavolta@vu.nl,"Abstract
Context:
As the use of mobile devices has increased immensely through the years, the presence of analytics and advertisements on web and native applications has become prevalent. However, serving ads and analytics comes with costs, as they are associated with additional code and network requests to execute properly. Subsequently, more computing resources are used, having an impact on the energy consumption and the performance of web applications. Previous work has focused only on native Android applications, has used different metrics for performance, or has focused on other aspects of web applications.
Goal:
This paper aims to investigate the costs of including advertisements and analytics in web applications. This is done in terms of energy consumption and performance. For energy, the consumption is measured in Joules. For performance, the following metrics are used: 
first contentful paint
 and 
full page load time
. The results of this study could influence the decisions of web developers and web browser vendors related to ads and analytics usage, while providing the foundation for further research on this topic.
Method:
To collect reliable and population-representative results, the research focused on 9 popular web applications included in the Tranco list. Energy consumption and performance metrics were gathered for 3 versions of each web application — original version with ads and analytics, without ads, and without analytics. A cross-over paired comparison design is conducted. Multiple executions of each run were performed in random order to ascertain rigorous measures. The experiment is carried out on an Android tablet using two browsers, Google Chrome and Opera.
Results:
Ads significantly impact the energy consumption of mobile web apps for both browsers, with a large effect size; analytics have a significant impact on the energy consumption of Chrome (with a medium effect size), but not on Opera. In terms of performance, both ads and analytics do not significantly impact the first contentful paint metric on both browsers; differently, both ads and analytics significantly impact the full page load time of the mobile web apps on both browsers, but with a small effect size.
Conclusions:
This study provides evidence that both ads and analytics can have a significant impact on the energy consumption and performance of mobile web apps loaded either on Opera or Chrome. Depending on the requirements of the mobile web app, it is advisable to limit both ads and analytics in a mobile web app in order to reduce its energy consumption and improve its full page load time. Special attention should be paid to the presence of ads since they resulted to be the most impactful in terms of energy consumption.",February 2024,"Mobile web, Empirical study, Controlled experiment, Energy efficiency, Performance",Information and Software Technology,2025-03-18T00:00:00,7.0,The investigation on the impact of ads and analytics on energy consumption and performance of mobile web apps provides practical insights for web developers and browser vendors.
https://www.sciencedirect.com/science/article/pii/S0950584923002215,Local polynomial software reliability models and their application,Tadashi=Dohi: dohi@hiroshima-u.ac.jp; Siqiao=Li: rel-siqiao@hiroshima-u.ac.jp; Okamura=Hiroyuki: okamu@hiroshima-u.ac.jp,"Abstract
In this paper, we propose local polynomial 
software reliability
 models (SRMs), which can be categorized into a semi-parametric modeling framework. Our models belong to the common non-homogeneous 
Poisson process
 (NHPP)-based SRMs, but possess a flexible structure to approximate an arbitrary mean value function by controlling the polynomial degree. More specifically, we develop two types of local polynomial NHPP-based SRMs; finite-failure (type-I) and infinite-failure (type-II) SRMs, which are substantial extensions of the existing NHPP-based SRMs in the similar categories. We also develop two 
maximum likelihood estimation
 algorithms in both estimation and prediction phases, where the former is used for the testing period experienced in the past, and the latter for the prediction in the future. In numerical experiments with actual 8 software fault count time-interval data sets, we compare our local polynomial NHPP-based SRMs with the well-known existing parametric NHPP-based SRMs in terms of goodness-of-fit and predictive performances. Finally, it can be concluded that our local polynomial NHPP-based SRMs with lower polynomial degrees could outperform the existing NHPP-based SRMs in several cases and should be listed as candidates for the representative NHPP-based SRMs in 
software reliability
 analysis.",February 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract discusses advanced software reliability models, but the practical value for early-stage European ventures or startups is limited."
https://www.sciencedirect.com/science/article/pii/S0950584923001854,The consolidation of game software engineering: A systematic literature review of software engineering for industry-scale computer games,Francisca=Pérez: mfperez@usj.es; Jorge=Chueca: jchueca@usj.es; Carlos=Cetina: ccetina@usj.es; Javier=Verón: jveron@usj.es; Jaime=Font: jfont@usj.es,"Abstract
Context:
Game 
Software Engineering
 (GSE) is a branch of 
Software Engineering
 (SE) that focuses on the development of 
video game
 applications. In past years, GSE has achieved enough volume, differences from traditional software engineering, and interest by the community to be considered an independent scientific domain, veering out from traditional SE.
Objective:
This study evaluates the current state of the art in software engineering for industry-scale computer games identifying gaps and consolidating the magnitude and growth of this field.
Method:
A Systematic Literature Review is performed following best practices to ensure the relevance of the studies included in the review. We analyzed 98 GSE studies to extract the current intensity, topics, methods, and quality of GSE.
Results:
The GSE research community has been growing over the years, producing over four times more research than before the previous GSE survey. However, this community is still very dispersed, with no main venues holding most of the GSE scientific studies. A broader range of topics is covered in this area, evolving towards those of a mature field such as architecture and design. Also, the reviewed studies employ more elaborated empirical research methods, even though the study reports need to be more rigorous in sections related to the critical examination of the work.
Conclusion:
The results of the SLR lead to the identification of 13 potential future research directions for this domain. GSE is an independent, mature, and growing field that presents new ways of software creation where the gap between industry and academia is narrowing. Video games present themselves as powerful tools to push the boundaries of software knowledge.",January 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract analyzes the state of game software engineering, highlighting gaps and future research directions. This information could be valuable for European early-stage ventures in the gaming industry."
https://www.sciencedirect.com/science/article/pii/S0950584923002033,A tertiary study on links between source code metrics and external quality attributes,Jürgen=Börstler: jurgen.borstler@bth.se; Muhammad=Usman: muhammad.usman@bth.se; Umar=Iftikhar: umar.iftikhar@bth.se; Nauman Bin=Ali: nauman.ali@bth.se,"Abstract
Context:
Several secondary studies have investigated the relationship between internal quality attributes, source 
code metrics
 and external quality attributes. Sometimes they have contradictory results.
Objective:
We synthesize evidence of the link between internal quality attributes, source code metrics and external quality attributes along with the efficacy of the prediction models used.
Method:
We conducted a tertiary review to identify, evaluate and synthesize secondary studies. We used several characteristics of secondary studies as indicators for the strength of evidence and considered them when synthesizing the results.
Results:
From 711 secondary studies, we identified 15 secondary studies that have investigated the link between source code and external quality. Our results show : (1) primarily, the focus has been on object-oriented systems, (2) 
maintainability
 and reliability are most often linked to internal quality attributes and source code metrics, with only one secondary study reporting evidence for security, (3) only a small set of complexity, coupling, and size-related source code metrics report a consistent positive link with maintainability and reliability, and (4) group method of data handling (GMDH) based prediction models have performed better than other prediction models for maintainability prediction.
Conclusions:
Based on our results, lines of code, coupling, complexity and the cohesion metrics from Chidamber & Kemerer (CK) metrics are good indicators of maintainability with consistent evidence from high and moderate-quality secondary studies. Similarly, four CK metrics related to coupling, complexity and cohesion are good indicators of reliability, while inheritance and certain cohesion metrics show no consistent evidence of links to maintainability and reliability. Further empirical studies are needed to explore the link between internal quality attributes, source code metrics and other external quality attributes, including functionality, portability, and usability. The results will help researchers and practitioners understand the body of knowledge on the subject and identify future research directions.",January 2024,"Product quality, Quality models, Code quality, Evidence, Tertiary study, Tertiary review",Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract synthesizes evidence on the link between internal quality attributes, source code metrics, and external quality attributes. While insightful, the direct impact on early-stage European ventures may be more indirect."
https://www.sciencedirect.com/science/article/pii/S0950584925000254,Vulnerability detection with feature fusion and learnable edge-type embedding graph neural network,Ge=Cheng: chengge@xtu.edu.cn; Qifan=Luo: 202221632987@smail.xtu.edu.cn; Yun=Zhang: yunzhangcn@outlook.com,"Abstract
Deep learning methods are widely employed in vulnerability detection, and graph neural networks have shown effectiveness in learning source code representation. However, current methods overlook non-relevant noise information in the code property graph and lack specific graph neural networks designed for code property graph. To address these issues, this paper introduces Leev, an automated vulnerability detection method. We developed a graph neural network tailored to the code property graph, assigning iterative vectors to diverse edge types and integrating them into the message passing between nodes to enable the model to extract hidden vulnerability information. In addition, virtual nodes are incorporated into the graph for feature fusion, mitigating the impact of irrelevant features on vulnerability information within the code. Specifically, for the FFMPeg+Qemu, Reveal, and Fan et al. datasets, the F1 metrics exhibited improvements of 7.02%, 21.69%, and 27.74% over the best baseline, correspondingly.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The development of an automated vulnerability detection method using graph neural networks tailored for code property graph with significant improvements in F1 metrics for various datasets could have a practical impact on improving security for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584923001866,Stratified random sampling for neural network test input selection,Zhuo=Wu: wuzhuo@tju.edu.cn; Zan=Wang: wangzan@tju.edu.cn; Junjie=Chen: junjiechen@tju.edu.cn; Hanmo=You: youhanmo@tju.edu.cn; Ming=Yan: yanming@tju.edu.cn; Lanjun=Wang: wang.lanjun@outlook.com,"Abstract
Context:
Testing techniques to ensure the quality of deep 
neural networks
 (DNNs) are essential and crucial. However, the testing process can be inefficient due to a large number of test cases and the manual effort of labeling them. Recent work tackles the above challenge by selecting a small but representative subset of the tests. Such an approach allows us to quickly estimate the accuracy of a DNN with reduced effort, because only a small set of tests are to be manually labeled. However, existing approaches cannot guarantee unbiased results or provide an accurate estimation.
Objectives:
In this work, we leverage a statistical perspective on providing an unbiased estimation of the model accuracy with the smallest estimation variance, named 
Stratified random
 Sampling with Optimum Allocation (SSOA).
Methods:
Our approach first divides the unlabeled test set into strata based on predictive confidences. Then, we design two stratum accuracy variance estimation methods to allocate the given budget assigned to each stratum based on the optimum allocation strategy. Finally, we conduct multiple experiments to evaluate the effectiveness and stability of SSOA by comparing it with 
baseline methods
.
Results:
The results show that SSOA significantly outperforms all compared approaches with average improvements over 26.14% in terms of 
Mean Squared Errors
 (MSE) of estimated accuracy. In addition, the MSE shows a steady downward trend as the budget grows.
Conclusion:
SSOA can assist testers in estimating the accuracy of DNNs, lowering labeling costs, and enhancing the efficiency of DNN testing.",January 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed approach SSOA significantly improves the accuracy estimation for DNNs with reduced effort, which can be valuable for early-stage ventures dealing with deep learning models."
https://www.sciencedirect.com/science/article/pii/S0950584923001921,The impact of knowledge inertia on process tailoring in the dynamic development of software projects in Chinese industries,Chung-Yang=Chen: cychen@mgt.ncu.edu.tw,"Abstract
Context
This paper stresses the importance of continual planning in the dynamic development of software projects and highlights a decisional situation: should teams follow process standards and 
past experiences
 for safety, or should they take different learning paths and innovate the development despite the risk of experimenting with new process solutions.
Objective
To address this situation, we emphasize software process tailoring (SPT), a team-based planning practice in software projects, and utilize knowledge inertia theory to investigate how experience and learning inertia influence the efficiency and effectiveness of conducting SPT given autonomous and knowledge-diverse team environments.
Method
This study employed a split questionnaire design to collect samples. A total of 88 Chinese software teams from 45 firms with software development functions in various 
industries
 participated in the research. In particular, a software team delegated at least two team members who have SPT experience to participate in the survey. The partial least squares (PLS) approach was adopted to analyze the data.
Results
Software teams are found to conveniently adopt and accommodate previous similar process solutions when familiar learning routes are formed (learning inertia), leading teams to make efficient but ineffective tailoring decisions. Experience inertia is found to facilitate effective 
process redesign
. Surprisingly, autonomous software teams tend to follow familiar ways when tailoring development. Knowledge diversity diminishes the effect of learning inertia on SPT effectiveness, reflecting that knowledge-diverse teams rely less on past learning routes and can develop more creative tailoring solutions.
Conclusion
Experience and learning inertia have distinct effects on SPT performance. Team 
autonomy
 and knowledge diversity contextually affect teams’ tailoring experience and learning routines, which subsequently determine SPT outcomes.",January 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on software process tailoring provides insights into how experience and learning inertia affect team decisions, which can be beneficial for startups in improving development processes."
https://www.sciencedirect.com/science/article/pii/S0950584923001945,Cluster-based adaptive test case prioritization,Xiaolin=Wang: wangxiaolin@zjxu.edu.cn,"Abstract
In order to enhance the efficiency of regression testing, test case prioritization (TCP) has been widely implemented, wherein a higher priority test case is executed earlier. Traditional TCP methods focus on improving the prioritization algorithm's efficacy. However, the majority of TCP approaches are characterized by a predetermined sequence of test cases prior to execution. Once established, this sequence remains consistent throughout the entire test execution process. As a result, any execution information generated during current test execution (such as fault-detected information) is unavailable for use in current round of test case prioritization and can only be utilized in subsequent regression testing. To address the issue of lagging utilization of fault-detected information, a cluster-based adaptive test case prioritization approach is proposed, which adds the new adaptive adjustment content in pre-prioritization. First, a new 
clustering criterion
 is defined and designed, by which produces test-case clusters in advance. Second, an adaptive TCP algorithm is proposed, which utilizes fault-detected information to adaptively adjust the order of test cases during the execution process based on the test-case clusters. Finally, one open-source Java program and three industrial-grade Java programs were selected for empirical evaluation. The experimental results demonstrate that the proposed technique not only serves as an enhanced version of pre-prioritization to improve the performance of the corresponding pre-prioritization technique, but also functions as an independent approach that outperforms other TCP techniques, including cluster-based TCPs, and another adaptive TCP. Specifically, when 
step=2
 is applied using our cluster-based adaptive TCP approach, the results are significantly better than those obtained with 
step=1.
 For instance, in 
CT-14
, the median APFD improvement rate for 
step=2
 reaches 17.08 %, which is substantially higher than that achieved with 
step=1
 (5.48 %).",January 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed adaptive test case prioritization approach improves the efficiency of regression testing, which can be useful for early-stage ventures seeking to enhance their testing processes."
https://www.sciencedirect.com/science/article/pii/S095058492300191X,Syntax-aware on-the-fly code completion,Chakkrit=Tantithamthavorn: chakkrit@monash.edu,"Abstract
Context:
Code completion aims to help improve developers’ productivity by suggesting the next code tokens from a given context. Various approaches have been proposed to incorporate 
abstract syntax tree
 (AST) information for model training, ensuring that code completion is aware of the syntax of the programming languages. However, existing syntax-aware code completion approaches are not on-the-fly, as we found that for every two-thirds of characters that developers type, AST fails to be extracted because it requires the syntactically correct source code, limiting its practicality in real-world scenarios. On the other hand, existing on-the-fly code completion does not consider 
syntactic information
 yet.
Objective:
In this paper, we propose PyCoder to leverage token types, a kind of lightweight syntactic information, which is readily available and aligns with the natural order of source code.
Method:
Our PyCoder is trained in a multi-task training manner so that by learning the supporting task of predicting token types during the training phase, the models achieve better performance on predicting tokens and lines of code without the need for token types in the inference phase.
Results:
Comprehensive experiments show that PyCoder achieves the first rank on the CodeXGLUE leaderboard with an accuracy of 77.12% for the token-level predictions, which is 0.43%–24.25% more accurate than baselines. In addition, PyCoder achieves an exact match of 43.37% for the line-level predictions, which is 3.63%–84.73% more accurate than baselines.
Conclusions:
These results lead us to conclude that token type information (an alternative to syntactic information) that is rarely used in the past can greatly improve the performance of code completion approaches, without requiring the syntactically correct source code like AST-based approaches do. Our PyCoder is publicly available on HuggingFace and GitHub.",January 2024,"Code completion, Multi-task learning",Information and Software Technology,2025-03-18T00:00:00,7.0,"PyCoder's approach to code completion using token types shows significant performance improvements, which can be valuable for startups looking to enhance developer productivity in coding tasks."
https://www.sciencedirect.com/science/article/pii/S0950584923001957,Understanding how early-stage researchers leverage socio-technical affordances for distributed research support,Yuchao=Jiang: yuchao.jiang@unsw.edu.au; Boualem=Benatallah: boualem.benatallah@dcu.ie; Marcos=Báez: marcos.baez@hsbi.de,"Abstract
Early-stage researchers (ESRs) are often challenged to learn research skills with sufficient support from a small circle of advisors and colleagues. Meanwhile, emerging socio-technical systems (STSs) are now available for social interactions among the general public and people in particular interest topics, such as research. However, how STSs can effectively support ESRs in developing research skills is not yet well understood. In this paper, we report on a series of interviews and surveys with ESRs. We found that online research communities held the potentials for ESRs to learn from diverse perspectives and experience. But the adoption of research communities for learning was still limited. We identified unmet needs in the design of these systems limiting the adoption. We then provide design implications for future STSs to support learning research skills with socio-technical affordances.",January 2024,"Crowdsourcing, Empirical study, Research skills development, Socio-technical systems",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study addresses the issue of supporting early-stage researchers in developing research skills using online research communities, providing design implications for future systems. This could have a positive impact on European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584923001040,Improving effort-aware defect prediction by directly learning to rank software modules,Xiao=Yu: xiaoyu@whut.edu.cn; Jiqing=Rao: jqrao@whut.edu.cn; Lei=Liu: leiliu_cs@hotmail.com; Guancheng=Lin: gclin@whut.edu.cn; Wenhua=Hu: whu10@whut.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Junwei=Zhou: junweizhou@whut.edu.cn; Jianwen=Xiang: jwxiang@whut.edu.cn,"Abstract
Context:
E
ffort-
A
ware 
D
efect 
P
rediction (EADP) ranks software modules according to the 
defect density
 of software modules, which allows testers to find more bugs while reviewing a certain amount of 
L
ines 
O
f 
C
ode (LOC). Most existing methods regard the EADP task as a regression or classification problem. Optimizing the regression loss or 
classification accuracy
 might result in poor effort-aware performance.
Objective:
Therefore, we propose a method called EALTR to improve the EADP performance by directly maximizing the 
P
roportion 
of
 the found 
B
ugs (PofB@20%) value when inspecting the top 20% LOC.
Method:
EALTR uses the linear regression model to build the EADP model, and then employs the composite 
differential evolution algorithm
 to generate a set of coefficient vectors for the linear regression model. Finally, EALTR selects the coefficient vector that achieves the highest PofB@20% value on the training dataset to construct the EADP model. To further reduce the 
I
nitial 
F
alse 
A
larms (IFA) value of EALTR, we propose a re-ranking strategy in the 
prediction phase
.
Results:
Our experimental results on eleven project datasets with 41 releases show that EALTR can find 5.83%–54.47% more bugs than the 
baseline methods
 whose IFA values are less than 10 and the re-ranking strategy significantly reduces the IFA value by 16.95%.
Conclusion:
Our study verifies the effectiveness of directly optimizing the effort-aware metric (i.e., PofB@20%) to build the EADP model. EALTR is recommended as an effective EADP method, since it can help software testers find more bugs.",January 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed method EALTR improves effort-aware defect prediction by maximizing the proportion of found bugs, which can have practical value for software testers in early-stage ventures. The results show significant improvements over baseline methods."
https://www.sciencedirect.com/science/article/pii/S0950584923002045,QLSN: Quantum key distribution for large scale networks,Shalli=Rani: shallir79@gmail.com; Ahmed=Abdelsalam: ahmed.abdelsalam@lut.fi,"Abstract
Context:
Key management among large-scale networks is still a challenging issue considering the limited information about adversaries (whether quantum or classical). One solution for such an issue is to use quantum-inspired to which refers to a technology, an algorithm, or a strategy that uses conventional computers to execute 
quantum physics
 concepts. These techniques make an effort to imitate particular 
quantum computing
 properties, such as superposition, 
entanglement
, or 
quantum parallelism
, in order to more effectively or creatively handle particular issues. It can provide security against all types of intruders.
Objectives:
In this article, inspired by 
Quantum Key Distribution
, we proposed a key-management protocol for enhancing the security and reliability of the network. Two major objectives have been taken into consideration during the proposal of QLSN (proposed protocol), (i) reduced risk if the network needs to transfer the long keys and (ii) a reliable network to transmit the information safely.
Methods:
(i) QLSN is proposed in the place of the classical Diffie–Hellman key exchange algorithm, which makes it secure against attacks during the transmission of data through the IPSec tunnel. (ii) 
Risk Analysis
 is performed on 1-bit, 2 bits, 15 bits, and 50 bits sizes of data. 
Data transmission
 is tested for risk analysis and the probability of attacks is checked under different scenarios.
Results:
The simulation results illustrated the better performance of the proposed protocol in different scenarios with large-scale networks compared to the existing Diffie–Hellman key exchange used in the IPSec protocol proposed by CISCO. Using 
quantum algorithms
 and processing advantages, quantum adversaries may be able to take advantage of weaknesses in conventional security systems.
Conclusion:
An essential step in determining and validating the viability of proposed protocol inside a 
quantum computing
 framework is the integration of a QLSN protocol into the IBM Qiskit simulator. By addressing pressing concerns, this validation approach clarifies the performance and security consequences of large-scale networks. Looking ahead, the fusion of 
artificial intelligence
 and 
quantum computing
 promises fresh methods for key management that will improve 
network security
. In addition, Turing machines–classical computing tools that bridge the gap between the classical and 
quantum computing
 paradigms–will continue to play crucial roles in the complex world of large-scale networks.",January 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The proposed Quantum Key Management protocol aims to enhance network security and reliability. While the technology is promising, its impact on European early-stage ventures may not be immediate but could be beneficial in the long run."
https://www.sciencedirect.com/science/article/pii/S0950584923002070,Genetic model-based success probability prediction of quantum software development projects,Muhammad Azeem=Akbar: azeem.akbar@lut.fi,"Abstract
Context
Quantum computing
 (QC) holds the potential to revolutionize computing by solving complex problems exponentially faster than classical computers, transforming fields such as cryptography, optimization, and scientific simulations. To unlock the 
potential benefits
 of QC, quantum software development (QSD) enables harnessing its power, further driving innovation across diverse domains. To ensure successful QSD projects, it is crucial to concentrate on key variables.
Objective
This study aims to identify key variables in QSD and develop a model for predicting the success probability of QSD projects.
Methodology
We identified key QSD variables from existing literature to achieve these objectives and collected expert insights using a survey instrument. We then analyzed these variables using an optimization model, i.e., 
Genetic Algorithm
 (GA), with two different prediction methods the Naïve 
Bayes Classifier
 (NBC) and 
Logistic Regression
 (LR).
Results
The results of success probability prediction models indicate that as the QSD process matures, project success probability significantly increases, and costs are notably reduced. Furthermore, the best fitness rankings for each QSD project variable determined using NBC and LR indicated a strong 
positive correlation
 (rs=0.945). The 
t
-test results (
t
 = 0.851, 
p
 = 0.402>0.05) show no significant differences between the rankings calculated by the two methods (NBC and LR).
Conclusion
The results reveal that the developed success probability prediction model, based on 14 identified QSD project variables, highlights the areas where practitioners need to focus more in order to facilitate the cost-effective and 
successful implementation
 of QSD projects.",January 2024,"Quantum computing (QC), Quantum software development (QSD), Variables, Prediction model, Genetic algorithm",Information and Software Technology,2025-03-18T00:00:00,9.0,The study aims to predict the success probability of Quantum Software Development projects by identifying key variables. This can be highly valuable for European early-stage ventures in the emerging field of quantum computing.
https://www.sciencedirect.com/science/article/pii/S0950584923001908,Software Engineering for Systems-of-Systems and Software Ecosystems,,"Abstract
Software Engineering has faced several challenges in the last decade, especially those related to aspects beyond the technical side. As such, technological, organizational and social aspects should be considered altogether in research and practice in the field so that complexity could be handled in order to provide solution to the existing problems from the software industry demands. In this context, systems-of-systems (SoS) and software ecosystems (SECO) emerged as topics that joined researchers and practitioners interested in understanding how to manage and engineer software-intensive systems within modern, complex, distributed, dynamic, and open environments. An SoS comprises independent constituent systems which work together to fulfill missions driven by architectural concerns. In turn, a SECO consists of a set of actors and artifacts, as well as their relationships, to produce value over a common technology platform driven by external contributions. Both classes of systems have a distributed nature, focus on optimizing the cost-benefit trade-off, and aim to reach global markets. In this special section, we introduce extended versions of two papers selected from the 10th IEEE/ACM International Workshop on Software Engineering for Systems-of-Systems and Software Ecosystems (SESoS 2022). These articles provide researchers and practitioners with advances on the development and evolution of complex software-intensive systems.",January 2024,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract introduces systems-of-systems and software ecosystems, which are important topics but may not directly impact European early-stage ventures or startups. The focus on complex systems engineering is valuable but more indirect in practical application."
https://www.sciencedirect.com/science/article/pii/S0950584923001842,Threats to validity in software engineering research: A critical reflection,Patricia=Lago: p.lago@vu.nl; Roberto=Verdecchia: roberto.verdecchia@unifi.it; Emelie=Engström: emelie.engstrom@cs.lth.se; Per=Runeson: per.runeson@cs.lth.se; Qunying=Song: qunying.song@cs.lth.se,"Abstract
Context:
In the contemporary body of 
software engineering
 literature, some recurrent shortcomings characterize how threats to validity (TTV) are considered in studies.
Objective:
With this position paper, we aim to open a discourse on the current use of TTV sections. The goal of our position is to jointly reflect and systematically improve how we, as a research community, consider TTV in our studies.
Methods:
Based on our personal experience as researchers, authors, reviewers, and editors, we critically reflect on the treatment of TTV in current empirical 
software engineering
 literature.
Results:
We discuss the key shortcomings of TTV consideration, including the failure to acknowledge different types of validity categorizations and the tendency to treat threats just as an afterthought. For each identified problem, we propose a vision for an improved state, intending to catalyze thoughtful engagement and improvements the way our community addresses TTV.
Conclusion:
We posit there is an urgent need to reconsider how we approach, document, and evaluate TTV in software engineering research.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract highlights the importance of reconsidering TTV in software engineering research, but the practical implications for early-stage ventures may not be as direct."
https://www.sciencedirect.com/science/article/pii/S0950584923001544,"Synthesizing research on programmers’ mental models of programs, tasks and concepts — A systematic literature review",Ava=Heinonen: ava.heinonen@aalto.fi,"Abstract
Context:
Programmers’ 
mental models
 represent their knowledge and understanding of programs, programming concepts, and programming in general. They guide programmers’ work and influence their task performance. Understanding mental models is important for designing work systems and practices that support programmers.
Objective:
Although the importance of programmers’ mental models is widely acknowledged, research on mental models has decreased over the years. The results are scattered and do not take into account recent developments in 
software engineering
. In this article, we analyze the state of research on programmers’ mental models and provide an overview of existing research. We connect results on mental models from different strands of research to form a more unified knowledge base on the topic.
Method:
We conducted a systematic literature review on programmers’ mental models. We analyzed literature addressing mental models in different contexts, including mental models of programs, programming tasks, and programming concepts. Using nine search engines, we found 3678 articles (excluding duplicates). Of these, 84 were selected for further analysis. Using the snowballing technique, starting from these 84, we obtained a final result set containing 187 articles.
Results:
We show that the literature shares a kernel of shared understanding of mental models. By collating and connecting results on mental models from different fields of research, we provide a comprehensive synthesis of results related to programmers’ mental models.
Conclusion:
The research field on programmers’ mental 
models faces
 many challenges arising from a lack of a shared knowledge base and poorly defined constructs. By creating a unified knowledge base on the topic, this work provides a basis for future work on mental models. We also point to directions for future studies. In particular, we call for studies that examine programmers working with modern practices and tools.",December 2023,"Mental model, Mental representation, Human factors, Program comprehension, Psychology of programming, Programmer, Software developer, Software development, Systematic literature review, Empirical software engineering",Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract provides a comprehensive analysis of programmers' mental models, which can be valuable for designing work systems and practices to support software development in early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492300157X,Software vulnerability prediction: A systematic mapping study,Ilias=Kalouptsoglou: iliaskaloup@uom.edu.gr; Miltiadis=Siavvas: siavvasm@iti.gr; Apostolos=Ampatzoglou: a.ampatzoglou@uom.edu.gr; Dionysios=Kehagias: diok@iti.gr; Alexander=Chatzigeorgiou: achat@uom.edu.gr,"Abstract
Context:
Software security is considered a major aspect 
of software quality
 as the number of discovered vulnerabilities in software products is growing. Vulnerability prediction is a mechanism that helps engineers to prioritize their inspection efforts focusing on vulnerable parts. Despite the recent advancements, current literature lacks a 
systematic mapping study
 on vulnerability prediction.
Objective:
This paper aims to analyze the state-of-the-art of vulnerability prediction focusing on: (a) the goals of vulnerability prediction-related studies; (b) the data collection processes and the types of datasets that exist in the literature; (c) the mostly examined techniques for the construction of the prediction models and their input features; and (d) the utilized evaluation techniques.
Method:
We collected 180 primary studies following a broad search methodology across four popular digital libraries. We mapped these studies to the variables of interest and we identified trends and relationships between the studies.
Results:
The main findings suggest that: (i) there are two major study types, prediction of vulnerable software components and forecasting of the evolution of vulnerabilities in software; (ii) most studies construct their own vulnerability-related dataset retrieving information from 
vulnerability databases
 for real-world software; (iii) there is a growing interest for 
deep learning models
 along with a trend on textual source code representation; and (iv) 
F
1
-score was found to be the most widely used 
evaluation metric
.
Conclusions:
The results of our study indicate that there are several open challenges in the domain of vulnerability prediction. One of the major conclusions, is the fact that most studies focus on within-project prediction, neglecting the real-world scenario of cross-project prediction.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides insights into vulnerability prediction, which is crucial for software security, but lacks immediate practical application for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923001817,Model-based security testing in IoT systems: A Rapid Review,Antonia=Bertolino: antonia.bertolino@isti.cnr.it; Francesca=Lonetti: francesca.lonetti@isti.cnr.it; Felicita=Di Giandomenico: felicita.digiandomenico@isti.cnr.it,"Abstract
Context:
Security testing is a challenging and effort-demanding task in 
IoT
 scenarios. The heterogeneous devices expose different vulnerabilities that can influence the methods and cost of security testing. Model-based security testing techniques support the systematic generation of test cases for the assessment of security requirements by leveraging the specifications of the IoT system model and of the attack templates.
Objective:
This paper aims to review the adoption of model-based security testing in the context of IoT, and then provides the first systematic and up-to-date comprehensive classification and analysis of research studies in this topic.
Method:
We conducted a systematic literature review analyzing 803 publications and finally selecting 17 primary studies, which satisfied our 
inclusion criteria
 and were classified according to a set of relevant analysis dimensions.
Results:
We report the state-of-the-art about the used formalisms, the test techniques, the objectives, the target applications and domains; we also identify the targeted security attacks, and discuss the challenges, gaps and future research directions.
Conclusion:
Our review represents the first attempt to systematically analyze and classify existing studies on model-based security testing for IoT. According to the results, model-based security testing has been applied in core IoT domains. Models complexity and the need of modeling evolving scenarios that include heterogeneous 
open software
 and hardware components remain the most important shortcomings. Our study shows that model-based security testing of IoT applications is a promising research direction. The principal future research directions deal with: extending the existing modeling formalisms in order to capture all peculiarities and constraints of complex and large scale IoT networks; the definition of context-aware and dynamic evolution modeling approaches of IoT entities; and the combination of model-based testing techniques with other security test strategies such as 
penetration testing
 or learning techniques for model inference.",December 2023,"Internet of Things, Model-based testing, Security testing",Information and Software Technology,2025-03-18T00:00:00,8.0,The systematic review of model-based security testing in IoT offers valuable insights and practical implications for startups operating in this industry.
https://www.sciencedirect.com/science/article/pii/S0950584923001829,Application of knowledge graph in software engineering field: A systematic literature review,Lu=Wang: wanglu@xidian.edu.cn; Chenhan=Sun: 21031221792@stu.xidian.edu.cn; Chongyang=Zhang: 21031211699@stu.xidian.edu.cn; Weikun=Nie: 21031211743@stu.xidian.edu.cn; Kaiyuan=Huang: 21031211704@stu.xidian.edu.cn,"Abstract
Context:
Knowledge graphs describe knowledge resources and their carriers through visualization. Moreover, they mine, analyze, construct, draw, and display knowledge and their interrelationships to reveal the dynamic development law of the knowledge field. Furthermore, knowledge graphs provide practical and valuable references for subject research. With the development of 
software engineering
, powerful 
semantic processing
 and organizational interconnection capabilities of knowledge graphs are gradually required. Current research suggests using knowledge graphs for code or 
API
 recommendation, vulnerability mining, and positioning to improve the efficiency and accuracy of development and design. However, 
software engineering
 lacks a 
systematic analysis
 of the knowledge graphs application.
Objective:
This paper explores the construction techniques and application status of knowledge graphs in the field of software engineering, broadens the application prospects of knowledge graphs in this field, and facilitates the subsequent research of researchers.
Methods:
We collected over 100 documents from 2017 to date and selected 55 directly 
related documents
 for 
systematic analysis
. Then, we analyzed the organized knowledge mainly stored in software engineering knowledge graphs, including software architecture, code details, and security reports.
Results:
We studied the emerging research methods in ontology modeling, 
named entity recognition
, and knowledge fusion in 
graph construction
 and found that current knowledge graphs are mainly used in intelligent software development, software vulnerability mining, security testing, and 
API
 recommendation.
Conclusion:
Our research on the innovation of knowledge graph in software engineering and the future construction of integrating open-source community software and developer recommendations with knowledge-driven 
microservice
 O&M aspects can inspire more scholars and knowledge workers to use knowledge graph technology, which is important to solve software engineering problems and promote the development of both fields.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The exploration of knowledge graphs in software engineering presents a promising approach with practical applications for startups in code recommendation, vulnerability mining, and API recommendation."
https://www.sciencedirect.com/science/article/pii/S0950584923000848,Migrating monoliths to cloud-native microservices for customizable SaaS,Espen Tønnessen=Nordli: espen.nordli@tietoevry.com; Sindre Grønstøl=Haugeland: sindre.haugeland@tietoevry.com; Phu H.=Nguyen: phu.nguyen@sintef.no; Hui=Song: hui.song@sintef.no; Franck=Chauvel: franck.chauvel@axbit.com,"Abstract
Context:
It was common that software vendors sell licenses to their clients to use software products, such as 
Enterprise Resource Planning
, which are deployed as a monolithic entity on clients’ premises. Moreover, many clients, especially big organizations, often require software products to be customized for their specific needs before deployment on premises.
Objective:
However, as software vendors are migrating their monolithic software products to Cloud-native Software-as-a-Service (SaaS), they face two big challenges that this paper aims at addressing: (1) How to migrate their exclusive monoliths to multi-tenant Cloud-native SaaS; and (2) How to enable tenant-specific 
customizations
 for multi-tenant Cloud-native SaaS.
Method:
This paper suggests an approach for migrating monoliths to microservice-based Cloud-native SaaS, providing customers with a flexible customization opportunity, while taking advantage of the economies of scale that the Cloud and multi-tenancy provide. We develop two proofs-of-concept to demonstrate our approach on migrating a reference application of Microsoft called SportStore to a customizable SaaS as well as customizing another Microsoft’s microservices reference application called eShopOnContainers.
Results:
We have shown not only the migration to microservices but also how to introduce the necessary infrastructure to support the new services and enable tenant-specific customization.
Conclusions:
Our customization-driven migration approach can guide a monolith to become SaaS having (synchronous and asynchronous) customization power for multi-tenant SaaS. Furthermore, our event-based customization approach can reduce the number of API calls to the main product while enabling different tenant-specific customization services for real-world scenarios.",August 2023,"Microservices, Architecture, Cloud native, Migration, Multi-tenancy, Event-based, Customization",Information and Software Technology,2025-03-18T00:00:00,7.0,"The migration of monolithic software products to Cloud-native SaaS and enabling tenant-specific customizations present challenges that are relevant to software vendors, but the direct impact on European early-stage ventures may require further adaptation and implementation considerations."
https://www.sciencedirect.com/science/article/pii/S0950584923001593,A data-driven approach for understanding invalid bug reports: An industrial case study,Jürgen=Börstler: jurgen.borstler@bth.se; Nauman Bin=Ali: nauman.ali@bth.se; Emelie=Engström: emelie.engstrom@cs.lth.se; Muhammad=Laiq: muhammad.laiq@bth.se,"Abstract
Context:
Bug reports
 created during software development and maintenance do not always describe deviations from a system’s valid behavior. Such invalid bug reports may consume significant resources and adversely affect the prioritization and resolution of valid bug reports. There is a need to identify 
preventive actions
 to reduce the inflow of invalid bug reports. Existing research has shown that manually analyzing invalid bug report descriptions provides cues regarding preventive actions. However, such a manual approach is not cost-effective due to the time required to analyze a sufficiently large number of bug reports needed to identify useful patterns. Furthermore, the analysis needs to be repeated as the underlying causes of invalid bug reports change over time.
Objective:
In this study, we propose and evaluate the use of 
Latent Dirichlet Allocation
 (LDA), a 
topic modeling
 approach, to support practitioners in suggesting preventive actions to avoid the creation of similar invalid bug reports in the future.
Method:
In an industrial 
case study
, we first manually analyzed descriptions of invalid bug reports to identify common patterns in their descriptions. We further investigated to what extent LDA can support this manual process. We used expert-based validation to evaluate the relevance of identified common patterns and their usefulness in suggesting preventive measures.
Results:
We found that invalid bug reports have common patterns that are perceived as relevant, and they can be used to devise preventive measures. Furthermore, the identification of common patterns can be supported with automation.
Conclusion:
Using LDA, practitioners can effectively identify representative groups of bug reports (i.e., relevant common patterns) from a large number of bug reports and analyze them further to devise preventive measures.",December 2023,"Software maintenance, Invalid bug reports, Bug management, Topic modeling, LDA, Bug classification, Software analytics",Information and Software Technology,2025-03-18T00:00:00,8.0,"The use of LDA for identifying common patterns in bug reports is beneficial for reducing invalid bug reports, offering practical value for startups in software development."
https://www.sciencedirect.com/science/article/pii/S0950584923001581,Can an old fashioned feature extraction and a light-weight model improve vulnerability type identification performance?,Hieu Dinh=Vo: hieuvd@vnu.edu.vn; Son=Nguyen: sonnguyen@vnu.edu.vn,"Abstract
Recent advances in automated 
vulnerability detection
 have achieved potential results in helping developers determine vulnerable components. However, after detecting vulnerabilities, investigating to fix vulnerable code is a non-trivial task. In fact, the types of vulnerability, such as 
buffer overflow
 or 
memory corruption
, could help developers quickly understand the nature of the weaknesses and localize vulnerabilities for security analysis. In this work, we investigate the problem of vulnerability type identification (VTI). The problem is modeled as the multi-label 
classification task
, which could be effectively addressed by “
pre-training, then fine-tuning
” framework with deep pre-trained embedding models. We evaluate the performance of the well-known and advanced pre-trained models for VTI on a large set of vulnerabilities. Surprisingly, their performance is not much better than that of the classical baseline approach with an old-fashioned bag-of-word, TF-IDF. Meanwhile, these deep 
neural network approaches
 cost much more resources and require GPU. We also introduce a lightweight independent component to refine the predictions of the baseline approach. Our idea is that the types of vulnerabilities could strongly correlate to certain code tokens (distinguishing tokens) in several crucial parts of programs. The distinguishing tokens for each vulnerability type are statistically identified based on their prevalence in the type versus the others. Our results show that the baseline approach enhanced by our component can outperform the state-of-the-art deep pre-trained approaches while retaining very high efficiency. Furthermore, the proposed component could also improve the 
neural network
 approaches by up to 92.8% in macro-average F1.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The research on vulnerability type identification and the proposed lightweight independent component show practical value for early-stage ventures by improving security analysis efficiently.
https://www.sciencedirect.com/science/article/pii/S0950584923001556,Work and career-related features of technology: A grounded theory study of software professionals,Sushanta Kumar=Mishra: sushantam@iimb.ac.in,"Abstract
For software professionals, work and technology are inseparable. Their work and careers are intertwined with different features of technology. For instance, features such as uncertainty and market dominance influence the career prospects of Software professionals. Despite the 
criticality
 of technology in professionals' lives, studies exploring technology features that influence Software professionals' work and life are, at best, limited. Based on an exploratory approach, we found that Software professionals evaluate technology based on their perceptions and career expectations. The positive or negative evaluation captures the perceived fit/match between their expectations, preferences from technology, and the features of a given technology. Based on the findings, we conceptualized technology from the career perspective of software professionals. We highlighted the implications of the fit/match between the software professionals' preferences and the features/characteristics of a given technology.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"While exploring technology features in software professionals' work is insightful, the impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923001568,CLeBPI: Contrastive Learning for Bug Priority Inference,Wen-Yao=Wang: wenyaowang108@gmail.com; Chen-Hao=Wu: wuchenhao78@gmail.com; Jie=He: hejie1213@126.com,"Abstract
Context:
Automated bug priority inference (BPI) can reduce the time overhead of bug triagers for priority assignments, improving the efficiency of software maintenance.
Objective:
There are two orthogonal lines for this task, i.e., traditional 
machine learning
 based (TML-based) and 
neural network
 based (NN-based) approaches. Although these approaches achieve competitive performance, our observation finds that existing approaches 
face
 the following two issues: 1) TML-based approaches require much manual feature engineering and cannot learn the 
semantic information
 of 
bug reports
; 2) Both TML-based and NN-based approaches cannot effectively address the label imbalance problem because they are difficult to distinguish the semantic difference between 
bug reports
 with different priorities.
Method:
We propose CLeBPI (
C
ontrastive 
Le
arning for 
B
ug 
P
riority 
I
nference), which leverages pre-trained 
language model
 and 
contrastive learning
 to tackle the above-mentioned two issues. Specifically, CLeBPI is first pre-trained on a large-scale bug report corpus in a self-supervised way, thus it can automatically learn contextual representations of bug reports without manual feature engineering. Afterward, it is further pre-trained by a 
contrastive learning
 objective, which enables it to distinguish semantic differences between bug reports, learning more precise contextual representations for each bug report. When finishing pre-training, we can connect a classification layer to CLeBPI and fine-tune it for BPI in a supervised way.
Results:
We choose four baseline approaches and conduct comparison experiments on a public dataset. The experimental results show that CLeBPI outperforms all baseline approaches by 23.86%–77.80% in terms of weighted average F1-score, showing its effectiveness.
Conclusion:
This paper propose CLeBPI, a pre-trained model combining contrastive learning that can automatically predict bug priority. Experimental results show that It achieves new result in BPI and can effectively alleviate label imbalance problem.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed CLeBPI model for bug priority inference addresses efficiency issues in software maintenance, which can have a significant impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492300174X,Warnings: Violation symptoms indicating architecture erosion,Peng=Liang: liangp@whu.edu.cn; Ruiyin=Li: ryli_cs@whu.edu.cn; Paris=Avgeriou: p.avgeriou@rug.nl,"Abstract
Context:
As a software system evolves, its architecture tends to degrade, and gradually impedes software maintenance and evolution activities and negatively impacts the quality attributes of the system. The main root cause behind architecture erosion phenomenon derives from violation symptoms (i.e., various architecturally-relevant violations, such as violations of architecture pattern). Previous studies focus on detecting violations in software systems using architecture conformance checking approaches. However, code review comments are also rich sources that may contain extensive discussions regarding architecture violations, while there is a limited understanding of violation symptoms from the viewpoint of developers.
Objective:
In this work, we investigated the characteristics of architecture violation symptoms in code review comments from the developers’ perspective.
Methods:
We employed a set of keywords Related to violation symptoms to collect 606 (out of 21,583) code review comments from four popular OSS projects in the openStack and qt communities. We manually analyzed the collected 606 review comments to provide the categories and linguistic patterns of violation symptoms, as well as the reactions how developers addressed them.
Results:
Our findings show that: (1) three main categories of violation symptoms are discussed by developers during the 
code review process
; (2) The frequently-used terms of expressing violation symptoms are “
inconsistent
” and “
violate
”, and the most common linguistic pattern is 
Problem Discovery
; (3) Refactoring and removing code are the major measures (90%) to tackle violation symptoms, while a few violation symptoms were ignored by developers.
Conclusions:
Our findings suggest that the investigation of violation symptoms can help researchers better understand the characteristics of architecture erosion and facilitate the development and maintenance activities, and developers should explicitly manage violation symptoms, not only for addressing the existing architecture violations but also preventing future violations.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The investigation of architecture violation symptoms in code review comments provides useful insights, but the direct impact on early-stage ventures may be moderate."
https://www.sciencedirect.com/science/article/pii/S0950584923001623,FrMi: Fault-revealing Mutant Identification using killability severity,Taha=Rostami: taha.rostami@modares.ac.ir; Saeed=Jalili: sjalili@modares.ac.ir,"Abstract
Context:
Mutation testing is a powerful method used in software testing for various activities, such as guidance for test case generation and test suite quality assessment. However, a vast number of mutants, most unrelated to real faults, threaten the scalability and validity of the method. Over the decades, researchers have proposed various approaches to alleviate these problems, most of which have almost the same performance in practice. To overcome this issue, recently predicting a category of mutants named fault-revealing mutants has been proposed, which outperforms other methods in terms of real-fault revelation ability. Although recent research shows the usefulness of targeting this type of mutant, they are scarce, which makes predictions of them with higher accuracy challenging.
Objective:
This paper aims to propose a method that can predict fault-revealing mutants with higher accuracy compared to the state-of-the-art method.
Methods:
To tackle this challenge, a feature representing the difficulty of killing a mutant is added as a new feature to complement the state-of-the-art feature set. Then a method based on 
ensemble learning
 is proposed that uses this feature for fault-revealing mutants’ prediction.
Results:
According to our experimental results, the proposed method outperforms the state-of-the-art method regarding area under a receiver operating characteristic curve (AUC) value on the Codeflaws and CoRBench data sets by 7.09% and 8.97%, respectively.
Conclusion:
It is concluded that the proposed method, which includes a new feature and an ensemble-learning approach, enhances the accuracy of predicting fault-revealing mutants in software testing. This is achieved by incorporating the difficulty of killing a mutant as a feature, which complements the existing feature set used in state-of-the-art methods. The experimental results demonstrate that the proposed method outperforms the state-of-the-art method on two datasets, Codeflaws and CoRBench, indicating that it has the potential to be applied in practical software testing scenarios.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed method for predicting fault-revealing mutants in software testing shows promise, but the impact on early-stage ventures may be slightly limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923001751,Leveraging a combination of machine learning and formal concept analysis to locate the implementation of features in software variants,Hamzeh=Eyal Salman: hamzehmu@mutah.edu.jo,"Abstract
Context:
Recently, software variants are adopted to build software product lines in the industry. In this adoption, the available assets (features, 
source code
, design documents, etc.) are reused to build a software product line rather than building it from scratch. The feature location is the first step in this adoption process. In the literature, numerous approaches were proposed to locate the implementations of features in the 
source code
.
Objective:
However, these approaches are guided using feature-specific information, which is not always available, especially in legacy applications. In this study, a feature location approach is proposed without predefined feature-specific information.
Method:
The proposed approach incorporates a mathematical research technique called formal concept analysis with other proposed algorithms. This combination is empirically evaluated using a benchmark 
case study
.
Results:
The obtained results demonstrate that this combination achieves promising results in terms of well-known used metrics in this area: Recall, Precision, and F-measure.
Conclusion:
Also, the results show that the approach effectively finds features implementation across software variants.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed approach addresses a practical need in software development by improving feature location without predefined information, which can benefit European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923001799,An empirical experiment of a usability requirements elicitation method to design GUIs based on interviews,José Ignacio=Panach: joigpana@uv.es,"Abstract
Context
The usability 
requirements elicitation
 process is a difficult task that lacks methods to guide and help analysts, who are usually not experts at usability.
Objective
This paper conducts an experiment with two replications to evaluate a method that elicits 
usability requirements
 based on structured interviews named 
UREM
 versus an unstructured method. The method consists of guided interviews by the analyst using 
decision trees
. The tree is composed of questions and possible answers. Each question appears when there are different possible design alternatives, and each answer represents one of these alternatives. The tree also recommends the alternative that enhances the usability based on existing usability guidelines.
Method
We have conducted an experiment with two replications with 22 and 26 subjects playing two different roles in a within-subjects design. The analysts used a tree to guide the interview and elicit the requirements while the end users had to explain to the analyst the type of system to develop. During the interview, the analyst must design a 
paper prototype
 to be validated by the end user. For the analyst, the experiment measures the effectiveness of usability requirements elicitation, the effectiveness of the use of the usability guidelines, the efficiency of the 
elicitation process
, and the satisfaction with the entire elicitation process. For the end user, the experiment measures the satisfaction with the designed prototype at the end of the interview.
Results
UREM yielded significantly better results for the effectiveness in the usability requirements elicitation process and for the effectiveness in the use of usability guidelines when compared to unstructured interviews. The use of UREM did not reduce the analysts’ efficiency and both analyst and end user remained the same satisfaction.
Conclusions
Eliciting usability requirements is a difficult task if it is done with unstructured interviews and without usability recommendations.",December 2023,"Usability requirements elicitation, Interviews, Empirical experiment, Guidelines",Information and Software Technology,2025-03-18T00:00:00,8.0,"The UREM method demonstrates significant improvements in usability requirements elicitation, which can have a direct impact on startups developing user-centered products in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584923001787,Systematic reviews in mobile app software engineering: A tertiary study,Samer=Zein: szain@birzeit.edu,"Abstract
Context:
A number of secondary studies in the form of systematic reviews and 
systematic mapping studies
 exist in the area of mobile 
application software
 engineering.
Objective:
The focus of this paper is to provide an overview and analysis of these secondary studies of mobile app 
software engineering
 for researchers and practitioners.
Method:
We conducted a systematic tertiary study following the guidelines by Kitchenham et al. to classify and analyze secondary studies in this area.
Results:
After going through several filtration steps, we identified 24 secondary studies addressing major 
software engineering
 phases, such as initiation, 
requirements engineering
, design, development and testing. The majority of the secondary studies focused on testing and design phases. Specific 
research topics
 addressed by the included studies were: 
usability evaluation
, test automation, context-aware testing, cloud-based development, 
architectural models
, effort and size estimation models, 
defect prediction
, and GUI testing. We found that the trend in secondary studies is towards more specific areas of mobile 
application software
 engineering such as 
architectural design
 models, context-aware testing, testing of non-functional requirements, 
mobile cloud computing
, and intelligent mobile applications. Research directions and some identified practices for practitioners were also identified.
Conclusions:
Mobile application software engineering is an active research area. The area can benefit from additional research in terms of secondary studies targeting evolution, maintenance, 
requirements engineering
, and cross-platform mobile application development. Additionally, some of the secondary studies identify some useful practices for practitioners.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The overview of secondary studies in mobile app software engineering provides valuable insights for researchers and practitioners, but the impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919302216,Practical detection of CMS plugin conflicts in large plugin sets,Marcelo=d’Amorim: damorim@cin.ufpe.br; Igor=Lima: isol2@cin.ufpe.br; Jeanderson=Cândido: j.barroscandido@tudelft.nl,"Abstract
Context
Content Management Systems
 (CMS), such as WordPress, are a very popular category of software for creating web sites and blogs. These systems typically build on top of plugin architectures. Unfortunately, it is not uncommon that the combined activation of multiple plugins in a CMS web site will produce unexpected behavior. Conflict-detection techniques exist but they do not scale.
Objective
This paper proposes 
Pena
, a technique to detect conflicts in large sets of plugins as those present in plugin market places.
Method
Pena
 takes on input a configuration, consisting of a potentially large set of plugins, and reports on output the offending plugin combinations. 
Pena
 uses an iterative divide-and-conquer search to explore the large space of plugin combinations and a staged filtering process to eliminate 
false alarms
.
Results
We evaluated 
Pena
 with plugins selected from the WordPress official repository and compared its efficiency and accuracy against the technique that checks conflicts in all pairs of plugins. Results show that 
Pena
 is 12.4x to 19.6x more efficient than the comparison baseline and can find as many conflicts as it.",February 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The conflict-detection technique for CMS plugins can significantly improve the efficiency and accuracy of detecting conflicts, which can benefit startups using these systems."
https://www.sciencedirect.com/science/article/pii/S0950584923001763,A large-scale exploratory study of android sports apps in the google play store,Bhagya=Chembakottu: bhagya.c@polymtl.ca,"Abstract
Context
Prior studies on mobile app analysis often analyze apps across different categories or focus on a small set of apps within a category. These studies either provide general insights for an entire app store which consists of millions of apps, or provide specific insights for a small set of apps. However, a single app category can often contain tens of thousands to hundreds of thousands of apps. For example, according to AppBrain, there are 46,625 apps in the “Sports” category of Google Play apps. Analyzing such a targeted category of apps can provide more specific insights than analyzing apps across categories while still benefiting many app developers interested in the category.
Objective
This work aims to study a large number of apps from a single category (i.e., the 
sports
 category). Our work can provide two folds contributions: 1) identifying insights that are specific to tens of thousands of sports apps, and 2) providing empirical evidence on the benefits of analyzing apps in a specific category.
Method
We perform an empirical study on over two thousand sports apps in the Google Play Store. We study the characteristics of these apps (e.g., their targeted sports types and main functionalities) through manual analysis, the topics in the user review through 
topic modeling
, as well as the aspects that contribute to the negative opinions of users through analysis of user ratings and sentiment.
Results
We identified sports apps that cover 16 sports types (e.g., Football, Cricket, Baseball) and 15 main functionalities (e.g., Betting, Betting Tips, Training, Tracking). We also extracted 14 topics from the user reviews, among which three are specific to sports apps (
accuracy of prediction, up-to-dateness
, and 
precision of tools
). Finally, we observed that users are mainly complaining about the advertisements and quality (e.g., bugs, content quality, streaming quality) of sports apps.
Conclusion
It is concluded that analyzing a targeted category of apps (e.g., sports apps) can provide more specific insights than analyzing apps across different categories while still being relevant for a large number (e.g., tens of thousands) of apps. Besides, as a rapid-growing and competitive market, sports apps provide rich opportunities for future research, for example, to study the integration of data science or 
machine learning techniques
 in 
software applications
 or to study the factors that influence the competitiveness of the apps.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"Studying a targeted category of apps like sports apps can provide specific insights for app developers, which can be valuable for startups in Europe looking to enter this market."
https://www.sciencedirect.com/science/article/pii/S0950584923001830,A software vulnerability detection method based on deep learning with complex network analysis and subgraph partition,Lipeng=Gao: gaolipeng@nwpu.edu.cn,"Abstract
The increasing size and complexity of software programs have made them an integral part of modern society’s infrastructure, making software vulnerabilities a major threat to 
computer security
. To address this issue, the use of deep learning-based software 
vulnerability detection
 methods has become increasingly popular. Although the effectiveness of the deep learning-based methods has been demonstrated, these methods have faced challenges in scalability and detection performance. To tackle this challenge, we propose a new 
vulnerability detection
 method based on 
deep learning
 with complex 
network analysis
 and subgraph partition that enhances detection accuracy while maintaining scalability. The method uses complex 
network analysis
 theory to convert the CPG into an image-like matrix, and then utilizes TextCNN for vulnerability detection. As a result, our method shows a 6% improvement in accuracy and a 10% reduction in false positive rates compared to state-of-the-art methods. In addition, our approach is able to detect some of the vulnerabilities recently released by CVE.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed vulnerability detection method using deep learning shows improvement in accuracy and scalability, which can benefit European startups in enhancing their software security measures."
https://www.sciencedirect.com/science/article/pii/S095058492300188X,Business-driven technical debt management using Continuous Debt Valuation Approach (CoDVA),Marek G.=Stochel: marek.stochel@motorolasolutions.com; Tomasz=Borek: tomasz.borek@motorolasolutions.com; Mariusz R.=Wawrowski: mariusz.wawrowski@motorolasolutions.com; Piotr=Chołda: piotr.cholda@agh.edu.pl,"Abstract
Context:
Despite the increasing research on Technical Debt Management (TDM), there is still a need for empirical studies that take a comprehensive approach to managing Technical Debt (TD) and consider the business perspective.
Objectives:
We introduce an empirically evaluated methodology called Continuous Debt Valuation Approach (CoDVA), which improves business value, team productivity, and developer morale.
Methods:
CoDVA prioritizes TD against a predicted 
product roadmap
, quantifying 
potential benefits
 based on their impact on the future state of the product and profitability of the investments. This approach enables a relative comparison among TD items and justifies a budget for 
TD repayment
. The methodology was validated through a survey and a three-year-long 
case study
 on TDM practices driven by an engineering team responsible for development and maintenance of a telecommunication software.
Results:
The results of the study show that the CoDVA approach has a positive impact, as the perceived business value from TD refactorings grew by 27%, the engineering team velocity improved by 39%, predictability of the engineering team increased by 60%, the effort spent on product release stabilization decreased by 50%, and overall developer satisfaction increased in 86% of the cases. The majority of the developers found that the applied TDM strategy was beneficial in terms of technical decisions made, the ability to develop a new functionality, and experience while working with the product code.
Conclusion:
The results prove that the approach is expedient across realized business value, 
software engineering team
 productivity, and satisfaction of the engineers responsible for development and maintenance of the software product.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract presents an empirically evaluated methodology (CoDVA) that shows positive impact on business value, team productivity, and developer satisfaction, which are critical aspects for early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584923001726,A reflection on the impact of model mining from GitHub,Gregorio=Robles: gregorio.robles@urjc.es,"Abstract
Context:
Since 1998, the ACM/IEEE 25th International Conference on 
Model Driven Engineering
 Languages and Systems (MODELS) has been studying all aspects surrounding modeling in 
software engineering
, from languages and methods to tools and applications. In order to enable empirical studies, the MODELS community developed a need for having examples of models, especially of models used in real software development projects. Such models may be used for a range of purposes, but mostly related to domain analysis and 
software design
 (at various levels of abstraction). However, finding such models was very difficult. The most used ones had their origin in academic books or student projects, which addressed “artificial” applications, i.e., were not base on real-case scenarios. To address this issue, the authors of this reflection paper, members of the modeling and of the 
mining software repositories
 fields, came together with the aim of creating a dataset with an abundance of modeling projects by mining GitHub. As a scoping of our effort we targeted models represented using the UML notation because this is the 
lingua franca
 in practice for software modeling. As a result, almost 100k models from 22k projects were made publicly available, known as the Lindholmen dataset.
Objective:
In this paper, we analyze the impact of our research, and compare this to what we envisioned in 2016. We draw practical lessons gained from this effort, reflect on the perils and pitfalls of the dataset, and point out promising avenues of research.
Method:
We base our reflection on the 
systematic analysis
 of recent research literature, and especially those papers citing our dataset and its associated publications.
Results:
What we envisioned in the original research when making the dataset available has to a major extent not come true; however, fellow researchers have found alternative uses of the dataset.
Conclusions:
By understanding the possibilities and shortcomings of the current dataset, we aim to offer the research community i) future research avenues of how the data can be used; and ii) raise awareness of the limitations, not only to point out threats to validity of research, but also to encourage fellow researchers to find ideas to overcome them. Our reflections can also be helpful to researchers who want to perform similar mining efforts.",December 2023,"Modeling, UML, Mining software repositories, Empirical research",Information and Software Technology,2025-03-18T00:00:00,5.0,The abstract discusses the creation of a dataset for modeling projects but does not directly address practical value for European early-stage ventures or startups. It focuses more on research impact and lessons learned.
https://www.sciencedirect.com/science/article/pii/S0950584923001738,Revisiting the reproducibility of empirical software engineering studies based on data retrieved from development repositories,Jesus M.=Gonzalez-Barahona: jesus.gonzalez.barahona@urjc.es,"Abstract
Context:
In 2012, our paper “On the reproducibility of empirical 
software engineering
 studies based on data retrieved from development repositories” was published. It proposed a method for assessing the reproducibility of studies based on 
mining software repositories
 (MSR studies). Since then, several approaches have happened with respect to the study of the reproducibility of this kind of studies.
Objective:
To revisit the proposals of that paper, analyzing to which extent they remain valid, and how they relate to current initiatives and studies on reproducibility and validation of 
research results
 in empirical software engineering.
Method:
We analyze the most relevant studies affecting assumptions or consequences of the approach of the original paper, and other initiatives related to the evaluation of replicability aspects of empirical software engineering studies. We compare the results of that analysis with the results of the original study, finding similarities and differences. We also run a reproducibility assessment study on current MSR papers. Based on the comparison, and the applicability of the method to current papers, we draw conclusions on the validity of the approach of the original paper.
Main lessons learned:
The method proposed in the original paper is still valid, and compares well with other more recent methods. It matches the results of relevant studies on reproducibility, and a systematic comparison with them shows that our approach is aligned with their proposals. Our method has practical use, and complements well the current major initiatives on the review of reproducibility artifacts. As a side result, we learn that the reproducibility of MSR studies has improved during the last decade.
Vision:
We propose to use our approach as a fundamental element of a more profound review of the reproducibility of MSR studies, and of the characterization of validation studies in this realm.",December 2023,"Reproducible research, Mining software repositories, Reproducibility, Validation studies, Empirical software engineering",Information and Software Technology,2025-03-18T00:00:00,7.0,"This abstract revisits a previous study on MSR reproducibility and assesses the validity of the proposed method. While not directly related to startups, the focus on reproducibility and validation in research can have implications for early-stage ventures looking to build on existing studies."
https://www.sciencedirect.com/science/article/pii/S0950584923001775,Software design analysis and technical debt management based on design rule theory,Yuanfang=Cai: yuanfang.cai@drexel.edu,"Abstract
In this paper we reflect on our decade-long journey of creating, evolving, and evaluating a number of 
software design
 concepts and technical debt management technologies. These include: a novel 
maintainability
 metric, a new model for representing design information, a suite of design anti-patterns, and a formalized model of design debt. All of these concepts are rooted in options theory, and they all share the objective of helping a software project team quantify and visualize major design principles, and address the very real 
maintainability
 challenges faced by their organizations in practice. The evolution of our research has been propelled by our continuous interactions with industrial collaborators. For each concept, technology, and supporting tool, we embarked on an ambitious program of empirical validation—in “the lab”, with industry partners, and with 
open source projects
. We reflect on the successes of this research and on areas where significant challenges remain. In particular, we observe that improved 
software design
 education, both for students and professional developers, is the prerequisite for our research and technology to be widely adopted. During this journey, we also observed a number of gaps: between what we offer in research and what practitioners need, between management and development, and between debt detection and debt reduction. Addressing these challenges motivates our research moving forward.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The abstract reflects on a decade-long journey of creating design concepts and technical debt management technologies with a focus on practical impact and challenges faced by organizations. This can provide valuable insights for European early-stage ventures and startups.
https://www.sciencedirect.com/science/article/pii/S0950584923001714,Sustainable software engineering: Reflections on advances in research and practice,Colin C.=Venters: c.venters@cern.ch; Rafael=Capilla: rafael.capilla@urjc.es; Elisa Yumi=Nakagawa: elisa@icmc.usp.br; Stefanie=Betz: stefanie.betz@hs-furtwangen.de; Birgit=Penzenstadler: birgitp@chalmers.se; Tom=Crick: thomas.crick@swansea.ac.uk; Ian=Brooks: Ian.Brooks@uwe.ac.uk,"Abstract
Context:
Modern societies
 are highly dependent on complex, large-scale, software-intensive systems that increasingly operate within an environment of continuous availability, which are challenging to maintain, and evolve in response to changes in stakeholder requirements of the system. Software architectures are the foundation of any software system and provide a mechanism for reasoning about core software quality requirements. Their 
sustainability
 – the capacity to endure in changing environments – is a critical concern for software architecture research and practice.
Objective:
The objective of the paper is to re-examine our previous assumptions and arguments in light of advances in the field. This reflection paper provides an opportunity to obtain new insights into the trends in software 
sustainability
 in both academia and industry, from a software architecture perspective specifically and 
software engineering
 more broadly. Given advances in research in the field, the increasing introduction of academic courses on different sustainability topics, and the engagement of companies to cope with sustainability goals, we reflect on advances and maturity about the role sustainability in general plays in today’s society. More specifically, we revisit the trends, open issues and research challenges identified five years ago in our previous paper on software sustainability research and practice from a software 
architecture viewpoint
, which aimed to provide a foundation and roadmap of emerging research themes in the area of sustainable software architectures in order to consider how this paper influenced and motivated research in the intervening years.
Method:
The forward snowballing method was used to establish the methodological basis for our reflection on the state of the art. A total of 234 studies were identified between April 2018 and June 2023 and 102 studies were found to be relevant according to the selection criteria. A further subset was mapped to the primary themes of the original paper including definitions and concepts, reference architectures, measures and metrics, and education.
Vision:
The vision of this reflection paper is to provide a new foundation and road map of emerging research themes in the area of sustainable 
software engineering
 highlighting recent trends, and open issues and research challenges.",December 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The paper provides new insights into software sustainability, reflecting on trends and challenges in the field. It contributes to advancing research in software architecture and engineering, which is valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923001386,AGL: Incorporating behavioral aspects into domain-driven design,Duc-Hanh=Dang: hanhdd@vnu.edu.vn; Duc Minh=Le: duclm20@fe.edu.vn; Van-Vinh=Le: 21028005@vnu.edu.vn,"Abstract
Context:
Domain-driven design (DDD) aims to iteratively develop software around a realistic domain model. Recent research in DDD has been focusing on using annotation-based domain-specific languages (aDSLs) to build the domain model. However, within current approaches behavioral aspects, that are often represented using UML Activity and 
State machine diagrams
, are not explicitly captured in the domain model.
Objective:
The focus of this paper is to introduce a new approach for incorporating behavioral aspects into domain models within the Domain-Driven Design (DDD) approach. The proposed approach involves using a new 
activity graph
 language (
AGL
) as an aDSL for representing behavioral aspects within a unified domain model. This integration of 
AGL
 and the previously developed aDSL (
DCSL
 to represent domain models) aims to achieve three important features of DDD: feasibility, productivity, and 
understandability
.
Method:
Our approach involves building a unified class model in 
DCSL
 within a domain-driven architecture, which uses the annotation attachment feature of the host programming language (such as Java) to attach 
AGL
 activity graphs directly to the activity class of the unified class model, resulting in a unified domain model. In this work, we define the abstract and 
concrete syntax
 of 
AGL
. To demonstrate our method, we use a Java framework called 
jDomainApp
 and evaluate 
AGL
 through a 
case study
 to show that it is expressive and practical for real-world software.
Results:
This paper presents two contributions. Firstly, it proposes a mechanism to include behavioral aspects in a unified domain model by introducing a new aDSL called AGL to represent domain behaviors. Secondly, it presents a unified modeling method for domain-driven software development.
Conclusion:
Our method significantly extends the state-of-the-art in DDD in two important fronts: constructing a unified domain model for both structural and behavioral aspects of domain models and bridging the gaps between model and code.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,Introducing a new approach for incorporating behavioral aspects into domain models within the Domain-Driven Design (DDD) approach is practical and can enhance productivity and feasibility in software development.
https://www.sciencedirect.com/science/article/pii/S0950584923001428,"The impact of stressors on the relationship between personality traits, knowledge collection behaviour and programmer creativity intention in software engineering",Aamir=Amin: Aamir.amin@port.ac.uk,"Abstract
Context
Individual and contextual factors have a profound impact on an individual's creativity. In the first part of this research, we concluded that, for a programmer's creativity intention, individual factors including big 5 
personality traits
 and knowledge collection behaviour play a key role. However, it is important to bring contextual factors into the model to provide a holistic understanding.
Objectives
Hence, the objective of the present research is to expand the earlier work by (i) identifying the software engineering occupational stressors relevant to programmers, and (ii) examining their impact as moderators for the relationship between individual factors (i.e., 
big five personality traits
 and knowledge collection behaviour) and the creativity intention of the programmer.
Methods
To analyse the moderating impact of 6 stressors, the survey questionnaire was used to collect data from 294 programmers working in software companies in Pakistan. The data were analysed using the 
Structural Equation Modelling
 (SEM) – Partial Least Square (PLS) technique.
Results
The findings revealed that in the presence of a moderate level of stress, the relationship between knowledge collection behaviour and creativity intention was strengthened. Furthermore, stressors interacted differently with different 
personality traits
. An overarching statement could be that most of the stressors positively moderated the relationships between different personality traits and creativity intentions. However, contrary to the prior research, the majority of the stressors negatively affected the impact of the openness to experience trait on creativity intention.
Conclusion
The research significantly contributes to the body of knowledge of behavioural software engineering. The findings of this research are novel and intriguing in many aspects and will benefit software organizations to increase innovation, by increasing programmers’ creativity through mitigating stress. The study is also one of the few studies which have attempted to understand the interaction between individual and contextual factors with a programmer's creativity.",November 2023,"Creativity, Stress, Knowledge collection behaviour, Personality traits, Software engineering, Programmer, Componential theory of creativity",Information and Software Technology,2025-03-18T00:00:00,6.0,"The research on individual and contextual factors impacting a programmer's creativity provides valuable insights for software organizations to increase innovation. However, the focus on stressors may have limited direct practical application for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923001374,Overlapping community detection in software ecosystem based on pheromone guided personalized PageRank algorithm,Xiangjuan=Yao: yaoxj@cumt.edu.cn,"Abstract
Context:
Software ecosystem has aroused the interest of numerous researchers and plays an important role in many aspects. According to different participants and their relationships, software ecosystem can be constructed into various types of complex networks. Overlapping community detection in complex networks can help reveal the community structure and find the intersection between communities. However, existing overlapping community 
detection algorithms
 often suffer from reduced applicability or accuracy when applied to networks in software ecosystems.
Objective:
To reveal the overlapping community structure in software ecosystem, we propose an overlapping community detection algorithm by improving the standard personalized PageRank (PPR) algorithm.
Method:
We first construct a developer collaboration network in software ecosystem based on the intensity of cooperation between developers. Then, the similarity between developers is calculated to guide the walking process of the PPR algorithm, making it suitable for weighted networks. Finally, in the proposed algorithm PGPPR, inspired by the idea of using pheromones to guide the walking in 
ant colony
 algorithm, we run the algorithm in multiple rounds and use the results of the previous round to guide the walking process in the current round to reduce redundant diffusion.
Results:
The experimental results on the five real-world networks show that our algorithm is applicable and effective in detecting communities. And in the five developer collaboration networks, PGPPR can effectively detect overlapping community structures with higher stability and accuracy than the four baselines.
Conclusion:
The PGPPR algorithm can find overlapping community structures in weighted networks and effectively reduce the redundant diffusion generated when applying the standard PPR algorithm to community detection. Compared to other algorithms, our algorithm can detect the overlapping communities more accurately and stably when applied to developer collaboration networks in software ecosystem.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed algorithm for overlapping community detection in software ecosystems addresses a specific challenge in software development. It provides a practical solution for enhancing community structure analysis, which can benefit early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923001398,An empirical study on secure usage of mobile health apps: The attack simulation approach,Bakheet=Aljedaani: abhjedaani@uqu.edu.sa,"Abstract
Context
Mobile applications (apps) have proven their usefulness in enhancing service provisioning across a multitude of domains that range from smart healthcare, to mobile commerce, and areas of context-sensitive computing. In smart healthcare context, mobile health (mHealth) apps - representing a specific genre of mobile apps that manage health information - face some critical challenges relating to security and privacy of device and user data. In recent years, a number of empirically grounded, survey-based studies have been conducted to investigate secure usage of mHealth apps. However, such studies rely on self-reported behaviors documented via interviews or survey questions that lack practical approaches that can simulate attack scenario for monitoring users’ actions and behaviors while using mHealth apps.
Objective
Our objective was to conduct an empirical study - engaging participants with attack simulation scenarios and analyze their actions - for investigating the security awareness of 
mHealth app
 users.
Method
We simulated some common security attack scenarios in mHealth context and engaged a total of 105 app users to monitor their actions and analyze their behavior. We analyzed users' data with statistical analysis including correlations test, descriptive analysis, and qualitative data analysis (i.e., thematic analysis method).
Results
Our results indicate that whilst the minority of our participants perceived access permissions positively, the majority had negative views. Users provide their consent, granting permissions, without a careful review of privacy policies that leads to undesired or malicious access to health data. Findings also indicated that 73.3% of our participants had denied at least one access permission, and 36% of our participants preferred no authentication method.
Conclusion
The study complements existing research on secure usage of mHealth apps, simulates security threats to monitor users’ actions, and provides empirically grounded guidelines for secure development and usage of mobile health systems.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study addresses critical security challenges in mHealth apps and provides practical guidelines for secure development, which can have a significant impact on the startup ecosystem."
https://www.sciencedirect.com/science/article/pii/S0950584923001362,Verifying contracts among software components: An ontology-based approach,Francisco-Edgar=Castillo-Barrera: ecastillo@uaslp.mx; Hector A.=Duran-Limon: hduran@cucea.udg.mx,"Abstract
Context:
The goal of Component-Based Software Engineering (CBSE) is the development of software systems in terms of an assembly of pre-fabricated software components. One of the main aims of CBSE is to increase 
software reuse
 whereby a software component becomes part of different software systems. Verification is an important task that ensures contract conformance among components. However, current techniques for verification of component matching are poorly used in industry due to the fact that the use of these techniques is complex since they require specialized expertise. Also, the use of such techniques can be time-consuming.
Objective:
In this paper, we present Moctezuma, a framework for verifying the matching of software components that does not require the user possessing highly specialized skills and is able to check contract conformance of 
functional semantics
 aspects.
Method:
Our approach relies on a core ontology of software components, which captures the concepts, properties, relationships, requirements, and software component functionality. We make use of 
architecture description languages
 (ADLs) to specify configurations of component interconnections. Interface contracts are specified with a customized version of CORBA-IDL. We employ 
ontology reasoning
 engines to check conformance among interface contracts.
Results:
The accuracy evaluation results have shown that our verifier has a high accuracy for detecting 
semantics errors
. The scalability evaluation shows that our framework exhibits almost a linear behavior.
Conclusions:
It is concluded that our framework is suitable for verifying the conformance of interface contracts, involving semantics aspects, along a configuration of component interconnections.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the framework presented is useful for verifying software components, the impact on early-stage ventures may be limited due to the specialized nature of the skills required."
https://www.sciencedirect.com/science/article/pii/S0950584923001441,DeKeDVer: A deep learning-based multi-type software vulnerability classification framework using vulnerability description and source code,Yukun=Dong: dongyk@upc.edu.cn,"Abstract
Context:
Software vulnerabilities have confused software developers for a long time. Vulnerability classification is thus crucial, through which we can know the specific type of vulnerability and then conduct targeted repair. Stack of papers have looked into deep learning-based multi-type vulnerability classification, among which most are based on vulnerability descriptions and some are based on source code. While vulnerability descriptions can sometimes mislead vulnerability classification and source code-based approaches have been rarely explored in multi-type vulnerability classification.
Objective:
We design DeKeDVer (Vulnerability Descriptions and Key Domain based Vulnerability Classifier) with two objectives: (i) to extract more useful information from vulnerability descriptions; (ii) to better utilize the 
information source
 code can reflect.
Method:
In this work, we propose a multi-type vulnerability classifier which combine vulnerability descriptions and source code together. We process vulnerability descriptions and source code of each project separately. For the vulnerability description of a sample, we preprocess it using a specified way we design based on our observations on numerous descriptions and then select text features. After that, Text Recurrent 
Convolutional Neural Network
 (TextRCNN) is applied to learn text information. For source code, we leverage its Code Property Graph (CPG) and extract key domain from it which are then embedded. Acquired feature vectors are then fed into 
Relational Graph
 
Attention Network
 (RGAT). Result vectors gained from TextRCNN and RGAT are combined together as the feature vector of the current sample. A Multi-Layer 
Perceptron
 (MLP) layer is further added to undertake classification.
Results:
We conduct our experiments on C/C++ projects from NVD. Experimental results show that our work achieves 84.49% in weighted F1-measure which proves our work to be more effective.
Conclusion:
Our work utilizes information reflected both from vulnerability descriptions and source code to facilitate vulnerability classification and achieves higher weighted F1-measure than existing vulnerability classification tools.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The integration of vulnerability descriptions and source code for classification can greatly benefit startups in identifying and addressing software vulnerabilities effectively.
https://www.sciencedirect.com/science/article/pii/S095058492300143X,Job satisfaction in agile information systems development: A stakeholder perspective,Veronika=Huck-Fries: veronika.huck-fries@tum.de,"Abstract
Context
Agile 
information systems development
 (ISD) claims to increase employees’ job satisfaction. While previous research acknowledged increased job satisfaction among team members such as software developers, less attention has been paid to stakeholders in agile ISD. Furthermore, we lack evidence about the role of review meetings between team members and stakeholders.
Objective
With the aim to tackle those current shortcomings, we set out to gain a 
deeper understanding
 on how agile ISD practices affect internal stakeholders’ job satisfaction (SJS).
Method
Using a 
mixed methods
 approach, we identify predictors of SJS in an exploratory 
case study
 first. Second, we develop our theoretical model that was evaluated with a survey of agile ISD stakeholders.
Results
Findings of conditional process analysis show that agile practices positively affect SJS via perceived meaningfulness and interaction frequency. Our results provide evidence that collaboration between team members and stakeholders is crucial for enhancing SJS.
Conclusions
We conclude that agile ISD practices have a positive effect on SJS. These findings have several implications for theory and offer a foundation for future research on stakeholders in agile ISD. Practical implications refer to the establishment of agile practices, meaningfulness at work and awareness for agile transformations.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The exploration of how agile ISD practices affect stakeholders' job satisfaction is insightful, but the direct impact on early-stage ventures may be indirect."
https://www.sciencedirect.com/science/article/pii/S0950584923001520,Formal synthesis of neural Craig interpolant via counterexample guided deep learning,Zuohua=Ding: zouhuading@hotmail.com,"Abstract
Context:
Craig interpolation is a significant and efficient application to formal verification and synthesis. However, there still remains a challenge in the synthesis of Craig interpolation for 
nonlinear theory
.
Objective:
For quantifier-free theories of nonlinear arithmetic, this paper proposes a new approach to generate nonlinear Craig 
interpolants
 represented as 
deep neural networks
.
Method:
The approach exploits a CEGIS framework where a 
learner
 yields a neural candidate interpolant satisfying the interpolant conditions against training data sets, and a 
verifier
 adopts computer algebra methods to confirm the correctness of the candidate or to generate counterexamples for further refining the candidate.
Results:
We implement the tool 
SyntheNI
 based on our CEGIS procedure, and assess the performance against a collection of benchmark examples. The tool 
SyntheNI
 performs better than existing methods in the aspect of the 
iteration number
 and the computational time. As an application, the tool 
SyntheNI
 is used to synthesize loop invariants.
Conclusion:
The 
SyntheNI
 can generate nonlinear Craig 
interpolants
 for quantifier free nonlinear real arithmetic. The experimental evaluation confirms the high performance of our 
synthesis method
.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The development of a tool to generate nonlinear Craig interpolants can streamline formal verification processes, benefiting startups working on complex software systems."
https://www.sciencedirect.com/science/article/pii/S0950584923001404,Reflections on Surrogate-Assisted Search-Based Testing: A Taxonomy and Two Replication Studies based on Industrial ADAS and Simulink Models,Shiva=Nejati: snejati@uottawa.ca; Lev=Sorokin: sorokin@fortiss.org; Damir=Safin: safin@fortiss.org; Federico=Formica: formicaf@mcmaster.ca; Mohammad Mahdi=Mahboob: mahbom2@mcmaster.ca; Claudio=Menghi: claudio.menghi@unibg.it,"Abstract
Context:
Surrogate-assisted search-based testing (SA-SBT) aims to reduce the 
computational time
 for testing compute-intensive systems. Surrogates enhance testing techniques by improving test case generation focusing the testing budget on the most critical portions of the input domain. In addition, they can serve as 
approximations
 of the system under test (SUT) to predict 
test results
 instead of executing the tests on compute-intensive SUTs.
Objective:
This article reflects on the existing SA-SBT techniques, particularly those applied to system-level testing and often facilitated using simulators or complex test beds. Recognizing the diversity of 
heuristic algorithms
 and evaluation methods employed in existing SA-SBT techniques, our objective is to synthesize these differences and present a comprehensive view of SA-SBT solutions. In addition, by critically reviewing our previous work on SA-SBT, we aim to identify the limitations in our proposed algorithms and evaluation methods and to propose potential improvements.
Method:
We present a taxonomy that categorizes and contrasts existing SA-SBT solutions and highlights key research gaps. To identify the evaluation challenges, we conduct two replication studies of our past SA-SBT solutions: One study uses industrial 
advanced driver assistance system
 (ADAS) and the other relies on a 
Simulink
 
model benchmark
. We compare our results with those of the original studies and identify the difficulties in evaluating SA-SBT techniques, including the impact of different contextual factors on results generalization and the validity of our 
evaluation metrics
.
Results:
Based on our taxonomy and replication studies, we propose future research directions, including re-considerations in the current 
evaluation metrics
 used for SA-SBT solutions, utilizing surrogates for 
fault localization
 and repair in addition to testing, and creating frameworks for large-scale experiments by applying SA-SBT to multiple SUTs and simulators.",November 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The reflection on existing SA-SBT techniques and the proposal of future research directions can provide valuable insights for startups looking to optimize testing for compute-intensive systems and improve evaluation methods.
https://www.sciencedirect.com/science/article/pii/S0950584923001271,Towards a better understanding of the mechanics of refactoring detection tools,Jonhnanthan=Oliveira: jonhnanthan@copin.ufcg.edu.br; Rohit=Gheyi: rohit@dsc.ufcg.edu.br; Leopoldo=Teixeira: lmt@cin.ufpe.br; Márcio=Ribeiro: marcio@ic.ufal.br; Osmar=Leandro: osmar@copin.ufcg.edu.br; Baldoino=Fonseca: baldoino@ic.ufal.br,"Abstract
Context:
Refactoring is a crucial practice used by many developers, available in popular IDEs, like 
Eclipse
. Moreover, refactoring detection tools, such as 
RefDiff
 and 
RefactoringMiner
, help improve the comprehension of refactoring application changes.
Objective:
In this article, we better understand to what extent refactoring detection tools (
RefDiff
 and 
RefactoringMiner
) identify 
refactoring operations
 that developers apply in practice.
Methods:
We survey with 53 developers of popular Java projects on GitHub. We asked them to identify six refactoring transformations applied to small programs.
Results:
There is no unanimity in all questions of our survey. Refactoring detection tools do not detect many 
refactoring operations
 expected by developers. In 4 out of 6 questions, most developers prefer the 
Eclipse
 refactoring mechanics.
Conclusion:
The results highlight the importance of diving deep into the refactoring mechanics and defining a baseline. Empirical studies focused on mining refactoring operations may be limited by an incomplete or unrepresentative sample of such operations, thus posing a challenge for researchers in this field.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study on refactoring detection tools provides some insights, the practical impact on European early-stage ventures may be limited as it focuses more on the discrepancy between tool detection and developer expectations."
https://www.sciencedirect.com/science/article/pii/S0950584923001180,Use of personas in Requirements Engineering: A systematic mapping study,John=Grundy: john.grundy@monash.edu; Devi=Karolita: devi.karolita@monash.edu; Jennifer=McIntosh: jennifer.mcintosh@unimelb.edu.au; Tanjila=Kanij: tanjila.kanij@monash.edu; Humphrey O.=Obie: humphrey.obie@monash.edu,"Abstract
Context:
Requirements Engineering
 (RE) is one of the crucial activities in software development that requires a high involvement of humans (i.e., stakeholders). The aim of RE-related tasks is to develop the scope of the target software products to ensure they will fulfil its stakeholder needs. In RE, the requirements engineers have to deeply understand the software stakeholders including their needs, motivations, and goals. Attaining this information directly from stakeholders requires regular interaction which needs considerable effort. The persona, as a user representation, is a useful tool that can reduce effort amount by modelling the software users and being the primary source of information.
Objective:
The aim of this work is to systematically review relevant studies that have investigated the use of personas in RE, the benefits of personas, and challenges during the implementation of personas in RE.
Method:
We conduct a 
systematic mapping study
 (SMS) using a formal protocol based on an established guideline. The systematic search result in a total of 904 publications from six databases. After filtering, we select 78 relevant studies for critical appraisal, analysis, synthesis, and reporting.
Results:
We identify methods to create and validate personas (mostly qualitative), map the benefits of using personas in RE (to ensure stakeholders’ satisfaction, support a human-centric RE, and support requirements engineers’ tasks and roles in RE), identify methods used with personas, discover challenges during persona incorporation in RE and their respective 
mitigation strategies
, and recommend potential strategies for unaddressed challenges. We also make recommendations for future research directions.
Conclusion:
The findings of this SMS will help RE researchers and practitioners better understand the use of personas in RE and highlights key research gaps for future research.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The systematic mapping study on the use of personas in RE can offer valuable insights for startups involved in software development, particularly in understanding stakeholders' needs and motivations through personas."
https://www.sciencedirect.com/science/article/pii/S0950584923001210,Antecedents of psychological safety in agile software development teams,Adam=Alami: adal@cs.aau.dk,"Abstract
Context:
Psychological safety continues to inspire researchers’ curiosity in various fields of study. It has been shown to enhance teams’ performance, efficiency, and learning, among other corollaries. Researchers are stretching the boundaries of these early findings to identify further effects of psychological safety. Recent work shows that psychological safety promotes 
knowledge sharing
, norm clarity, and complements agile values.
Objective:
Studies show that psychological safety enhance agile values and practices, and some practitioners went as far as to claim “agile doesn’t work without psychological safety.” Yet, researchers have not explored its antecedents. In this study, we sought to understand how psychological safety materializes in 
agile software development
 teams.
Method:
We opted for a two-phase mixed-methods study; an exploratory qualitative phase (18 interviews) followed by a quantitative phase (survey study, N = 365) to broaden the empirical coverage and test phase one’s findings.
Results:
Our findings show that psychological safety is established in agile software teams when individuals, the team, and the leadership adopt and promote strategies conducive to promoting a psychologically safe workplace. While openness and no blame towards team members are the “butter and bread” of psychological safety, collective-decision making within the team and the leadership ownership remain the pillars of a psychologically safe workplace. Conversely, team 
autonomy
, technical practices providing a safety net and slack time were not found to promote psychological safety.
Conclusion:
To institutionalize psychological safety in agile software teams, individuals, teams, and the leadership should consolidate their effort to adopt no blame, openness, collective decision-making in the team, and assuming the ownership of promoting a psychologically safe workplace.",October 2023,"Agile software development, Psychological safety, Mixed-methods",Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides valuable insights on how to promote psychological safety in agile software teams, which can greatly impact the performance and efficiency of early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923001209,DLRegion: Coverage-guided fuzz testing of deep neural networks with region-based neuron selection strategies,Chuanqi=Tao: taochuanqi@nuaa.edu.cn,"Abstract
Context:
Deep Learning
 (DL) systems have been increasingly applied to safety-critical scenarios, such as autonomous driving or medical diagnoses. However, it often exhibits erroneous behaviors that can cause serious consequences. Therefore, it is important to ensure the quality of the DL systems through systematically testing. Recent 
research works
 have proposed many testing techniques for deep 
neural networks
 (DNNs), among which the coverage-guided fuzz testing has achieved remarkable results. The neuron selection strategy is the key ingredient of the technique. It can affect the technique’s effectiveness. However, current neuron selection strategies did not utilize the output distribution of each neuron on the training data, which can characterize the behavior of the neuron.
Objective:
This paper introduces 
DLRegion
, a coverage-guided fuzz testing technique of DNNs with region-based neuron selection strategies. 
DLRegion
 can expose erroneous behaviors of DNNs while maximizing coverage.
Methods:
DLRegion
 first incorporates a seed selection strategy based on the level of confidence in the classification of the inputs to select seed inputs to mutate. 
DLRegion
 also proposes region-based neuron selection strategies, which utilize the region where the output value of each neuron is in its output distribution to select valuable neurons to activate for covering more internal states.
Results:
Empirical studies on three well-known datasets, guided by five existing criteria demonstrate that: (1) the proposed seed selection strategy very effectively improves coverage and 
defect detection
; (2) selecting neurons in different regions has obvious differences in achieving model coverage and detecting defects; (3) 
DLRegion
 outperforms other existing techniques by coverage under different criteria and effectively identifies the quantity and diversity of defects; (4) the effectiveness of 
DLRegion
 in improving the model robustness.
Conclusion:
DLRegion
 not only can cover more internal logic of the DNNs but also can effectively detect DNNs’ erroneous behaviors. Moreover, 
DLRegion
 can improve the robustness of the model.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"The DLRegion technique addresses a critical need in the field of deep learning by improving testing techniques for DNNs, which is highly relevant for European early-stage ventures utilizing AI technologies."
https://www.sciencedirect.com/science/article/pii/S0950584923001258,METHODS: A meta-path-based method for heterogeneous community detection in the open source software ecosystem,Qing=Qi: qi_ng616@sjtu.edu.cn; Jian=Cao: cao-jian@sjtu.edu.cn,"Abstract
Detecting communities in the 
open source software
 (OSS) ecosystem can help understand the collaborations in the 
open source software
 ecosystem and promote an understanding of the dynamics of the ecosystem. However, most existing community detection methods are designed for homogeneous networks, whereas the OSS ecosystem is a 
heterogeneous network
. Therefore, we propose a meta-path-based method for heterogeneous community detection in the OSS ecosystem (METHODS). METHODS comprises four steps. Firstly, a heterogeneous information network is constructed based on meta-paths. Secondly, the Canopy algorithm is used to obtain the number of initial communities. Thirdly, the skip-gram model is used to identify seed nodes for community detection. Finally, METHODS detects heterogeneous communities around the seed nodes. By defining a series of 
evaluation metrics
 and verifying these on GitHub datasets, METHODS achieves the best performance of all the other methods. Moreover, the 
case studies
 on GitHub also shows METHODS can discover latent communities whose members are potentially relevant.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The community detection method for OSS ecosystem, while valuable, may have less immediate impact on European early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923001246,Detection and filling of functional holes in microservice systems: Method and infrastructure support,Zihang=Su: zhsu@stu.hit.edu.cn; Xiang=He: hexiang@hit.edu.cn; Teng=Wang: 21S003068@stu.hit.edu.cn; Lei=Liu: liulei@stu.hit.edu.cn; Zhiying=Tu: tzy_hit@hit.edu.cn; Zhongjie=Wang: rainy@hit.edu.cn,"Abstract
With the widespread use of 
microservices
 technology, a growing number of Microservice Systems (MSS) have emerged. 
Monolithic applications
 are divided into several small and independent 
microservices
 that provide functions through APIs. These microservices can be orchestrated by service composition to satisfy various user requirements: microservice functionalities are aggregated into coarse-grained solutions to provide 
composite functions
 to users. However, although various service composition approaches have been presented in many works of literature, they failed to solve the situation that no 
feasible solutions
 can be found because of missing functions in MSS, named 
Functional Hole (FH)
. As a result, the system cannot satisfy user requirements and faces 
Quality of Service
 (QoS) declines. In this paper, to reduce the impact of missing functions, we defined the FH to describe the absence of functions for MSS when it cannot satisfy user requirements. Moreover, for the first time, we proposed the 
Detection and Filling Problem of FH (DFPFH)
 in a running MSS. A three-phase algorithm with 
supporting infrastructure
 was developed to solve DFPFH. It detects FHs based on hypergraphs, fills FHs with services from an external service system at runtime, and generates suggestions for thoroughly filling FH to developers. Plenty of experiments were conducted, and the results validate our approaches’ usability, effectiveness, and performance.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed solution for detecting and filling Functional Holes in Microservice Systems can benefit early-stage ventures using microservices, although the impact may not be as immediate as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923001234,PAREI: A progressive approach for Web API recommendation by combining explicit and implicit information,Qiao=Huang: qiaohuang@zjgsu.edu.cn,"Abstract
Context:
Mashup is an application with specific functions by combining Web APIs that can provide services or data on the Internet, thus avoiding the behavior of repeatedly building wheels. Recommending suitable Web APIs in the vast number of Web APIs on the Internet for Mashup developers has become a challenging problem. Previous studies often fail to fully exploit and effectively synthesize various types of information between Web APIs and Mashups.
Objective:
This work proposes a Web API recommendation approach - PAREI by combining both explicit and implicit information to progressively optimize the recommendation results.
Methods:
First, PAREI uses the explicit structural information between Mashups and Web APIs to construct the Call Relationship Network (CRN). Second, PAREI calculates explicit semantic similarities between developer’s requirement and Mashups to obtain candidate Mashup nodes in CRN. Then PAREI further mines the implicit structural information between Mashups. A combined similarity score for each Mashup node is calculated. Finally, PAREI uses CRN to obtain candidate Web APIs related to candidate Mashup nodes, and integrates implicit semantic information of Web APIs with combined scores of corresponding Mashups, so as to obtain Top-K Web APIs.
Results:
Comparison experiments show that PAREI has significantly improved the Recall, Precision, and MAP metrics compared with other approaches. Ablation experiments show that different types of information play various roles in Web API recommendation, and different combination modes have different effects on the recommendation results.
Conclusion:
This work constructs the PAREI model, which combines explicit and implicit information to obtain Web API recommendation results through a progressive strategy. According to the experiment results, we believe that the PAREI approach can help Mashup developers to find demanded Web APIs rapidly and accurately.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The PAREI model proposes a novel approach to Web API recommendation, showing significant improvements in metrics. This can greatly benefit early-stage ventures by facilitating the rapid and accurate discovery of demanded Web APIs, enhancing efficiency and productivity."
https://www.sciencedirect.com/science/article/pii/S095058492300126X,Learning test-mutant relationship for accurate fault localisation,Shin=Yoo: shin.yoo@kaist.ac.kr,"Abstract
Context:
Automated fault localisation aims to assist developers in the task of identifying the root cause of the fault by narrowing down the space of likely fault locations. Simulating variants of the faulty program called mutants, several Mutation Based Fault Localisation (MBFL) techniques have been proposed to automatically locate faults. Despite their success, existing MBFL techniques suffer from the cost of performing mutation analysis after the fault is observed.
Method:
To overcome this shortcoming, we propose a new MBFL technique named SIMFL (Statistical Inference for Mutation-based Fault Localisation). SIMFL localises faults based on the past results of mutation analysis that has been done on the earlier version in the project history, allowing developers to make predictions on the location of incoming faults in a just-in-time manner. Using several statistical inference methods, SIMFL models the relationship between test results of the mutants and their locations, and subsequently infers the location of the current faults.
Results:
The empirical study on 
Defects4J
 dataset shows that SIMFL can localise 113 faults on the first rank out of 224 faults, outperforming other MBFL techniques. Even when SIMFL is trained on the predicted kill matrix, SIMFL can still localise 95 faults on the first rank out of 194 faults. Moreover, removing redundant mutants significantly improves the 
localisation accuracy
 of SIMFL by the number of faults localised at the first rank up to 51.
Conclusion:
This paper proposes a new MBFL technique called SIMFL, which exploits ahead-of-time mutation analysis to localise current faults. SIMFL is not only cost-effective, as it does not need a mutation analysis after the fault is observed, but also capable of localising faults accurately.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"SIMFL introduces a cost-effective and accurate MBFL technique, outperforming existing methods in fault localization. This can have a substantial impact on startups by saving time and resources in identifying faults, leading to more efficient development processes."
https://www.sciencedirect.com/science/article/pii/S0950584923001283,BugRadar: Bug localization by knowledge graph link prediction,Xi=Xiao: xiaox@sz.tsinghua.edu.cn; Renjie=Xiao: xrj20@mails.tsinghua.edu.cn; Qing=Li: liq@pcl.ac.cn; Jianhui=Lv: lvjh@pcl.ac.cn; Shunyan=Cui: cuisy@gditsec.org.cn; Qixu=Liu: liuqixu@iie.ac.cn,"Abstract
Context
: Information Retrieval-based Bug Localization (IRBL) aims to design automatic systems that find buggy files according to 
bug reports
, which can reduce the time consumption to fix bugs for programmers. There has been extensive research on IRBL techniques in recent years. However, these methods cannot make full use of the structure information in 
bug reports
 and source files.
Objective
: In this paper, we propose a novel scheme BugRadar. It combines text features and structure features from bug reports and source files for bug localization. Especially, BugRadar leverages a 
knowledge graph
 to make use of structure features.
Method
: We originally propose a 
knowledge graph
 named TriGraph based on structure features and apply hyperbolic attention embedding to get the link prediction scores. For text features, we propose Partial Text Similarity which improves traditional Text Similarity and Method Level Text Similarity. We also propose Word Collaborative Filtering Score which leverages historical bug reports with more attention on important terms. Finally, we calculate the final suspicious scores based on the structure features, text features, and fixing time information from bug fixing history with a 
neural network
.
Results
: We apply our scheme to four projects (Tomcat, SWT, JDT, and Birt) in a popular dataset and get approving results. BugRadar gets better results than other state-of-the-art methods on three projects out of the four. It achieves a relative improvement of 8.8% in SWT and 9.8% in JDT for 
Mean Average Precision
 compared to the previous best scheme KGBugLocator and 11.4% in Birt compared to Adaptive Regression.
Conclusions
: BugRadar can achieve approving performance on large-scale projects with enough historical bug reports. It verifies that knowledge graphs are capable of representing the structure features for bug localization. The novel Partial Text Similarity and Word Collaborative Filtering Score are both effective improvements for using text features.",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"BugRadar presents a comprehensive scheme for bug localization, achieving superior results compared to state-of-the-art methods. Its effectiveness in improving Mean Average Precision and leveraging knowledge graphs can provide significant value to startups in enhancing bug-fixing efficiency and code quality."
https://www.sciencedirect.com/science/article/pii/S0950584923001350,Robustness assessment of hyperspectral image CNNs using metamorphic testing,Foutse=Khomh: foutse.khomh@polymtl.ca; Rached=Bouchoucha: rached.bouchoucha@polymtl.ca; Houssem Ben=Braiek: houssem.ben-braiek@polymtl.ca; Sonia=Bouzidi: sonia.bouzidi@insat.rnu.tn; Rania=Zaatour: rania.zaatour@fst.utm.tn,"Abstract
Remote sensing
 has proven its utility in many critical domains, such as medicine, military, and ecology. Recently, we have been witnessing a surge in the adoption of deep learning (DL) techniques by the remote sensing community. DL-based classifiers, such as convolutional neural networks (CNNs), have been reported to achieve impressive predictive performances reaching 99% of accuracy when applied to 
hyperspectral images
 (HSIs), a high-dimensional type of remote sensing data. However, these deep learners are known to be highly sensitive to even slight perturbations of their high-dimensional raw inputs. In real-world contexts, concerns can be raised about how robust they really are against corner-case scenarios. When HSI classifiers are applied in safety–critical applications, ensuring an adequate level of robustness is crucial to prevent unexpected system behaviors. Yet, there are few studies dealing with their robustness, nor are RGB-testing methods able to cover the HSI-specific challenges. This led us to propose a systematic testing method to assess the robustness of the CNNs trained to classify HSIs. First, we elaborate domain-specific metamorphic transformations that simulate naturally-occurring distortions of remote sensing HSIs. Then, we leverage metaheuristic search algorithms to optimize the fitness of synthetically-distorted inputs to stress the weaknesses of the on-testing CNN, while remaining in compliance with domain expert requirements, in order to preserve the semantic of the generated inputs. Relying on our metamorphic testing method, we assess the robustness of established and novel CNNs for 
HSI classification
, and demonstrate their failure, on average, in 25% of the produced test cases. Furthermore, we fine-tuned the tested CNNs on training data augmented with these failure-revealing metamorphic transformations. Results show that the fined-tuning successfully fixed at least 90% of the CNN weaknesses, with less than 1% of degradation in the original predictive performance, outperforming the common iterative gradient-based adversarial attack, namely, Projected Gradient Descent (PGD).",October 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The systematic testing method proposed for assessing the robustness of CNNs trained for HSI classification is innovative and crucial for ensuring reliable performance in safety-critical applications. The findings can benefit startups by enhancing the trustworthiness and resilience of their remote sensing solutions.
https://www.sciencedirect.com/science/article/pii/S0950584923001179,Metamorphic testing of chess engines,Manuel=Méndez: manumend@ucm.es; Miguel=Benito-Parejo: mibeni01@ucm.es; Alfredo=Ibias: aibias@ucm.es; Manuel=Núñez: manuelnu@ucm.es,"Abstract
Context:
Chess engines are computer programs that analyse chess positions. The goal of this analysis is to decide which player has an advantage and evaluate how big the advantage is. Using this analysis, chess engines are really powerful players who can consistently beat the best (human) players. Even though these programs are fantastic players, we cannot be sure that the code is fault free because it is very difficult to test them. In particular, we 
face
 the oracle problem: if the chess engine plays better than any potential tester, how can a tester claim that a certain evaluation is wrong or that a suggested move is not the best one?
Objective:
The main goal of our work is to provide a metamorphic testing tool to evaluate chess engines. In particular, we are interested in looking for inconsistent behaviours in the best publicly available chess engine, 
Stockfish
, but we would also like to consider other chess engines.
Methods:
We developed a metamorphic testing solution to validate chess engines. First, we defined metamorphic relations that might reveal inconsistent behaviours. The underlying idea was that the evaluation of 
related
 positions should be the same. For example, if we consider a position and rotate all the pieces with respect to the central axis, then both positions should have the same evaluation. One of our main priorities was to have a fully automatised tool. 
Source inputs
 are obtained from available datasets while 
follow-up inputs
 are automatically computed by applying sound transformations to the source inputs with respect to the corresponding metamorphic rule. In order to assess the usefulness of our work, we applied it to analyse a dataset with more than 40,000 positions.
Results:
Empirical evidence validates the usefulness of our work to analyse the best available chess engine, Stockfish. Our tool revealed non-negligible deviations from the expected behaviour in Stockfish for all the MRs. Additional experiments showed that our tool can be easily used to analyse other chess engines such as Komodo, Houdini and Gull.
Conclusion:
The experiments demonstrate the usefulness of our approach to identify issues in the latest version of the widely recognised to be the best chess engine: Stockfish (version 15, released in April 2022). Our tool is flexible and can be easily extended with metamorphic relations that can be defined in the future by either us or other users. Since all our metamorphic relations are implemented and the code is freely available, users can use them as a pattern to implement new relations.",October 2023,"Software testing, Metamorphic testing, Chess engines",Information and Software Technology,2025-03-18T00:00:00,7.0,The abstract presents a practical tool to evaluate chess engines which can be beneficial for startups or ventures in developing AI-powered applications.
https://www.sciencedirect.com/science/article/pii/S0950584923001052,"Retrieving arXiv, SocArXiv, and SSRN metadata for initial review screening",Rubia=Fatima: rubiafatima91@hotmail.com; Affan=Yasin: affan.yasin@tsinghua.edu.cn; Lin=Liu: linliu@tsinghua.edu.cn; Jianmin=Wang: jimwang@tsinghua.edu.cn; Wasif=Afzal: wasif.afzal@mdh.se,"Abstract
Context:
Researchers around the globe invest a lot of time searching the literature for performing reviews (Systematic Literature Review (SLR), Multivocal Literature Review (MLR)). The steps to performing the review includes inclusion of the grey literature, preprints, and quality assessed non-peer reviewed literature (the purpose is to minimize the publication bias). The 
initial screening
 of the papers takes time and 
bibliographic information
 is only available online for the researcher(s).
Objective:
Objective of our study is to propose, design, and develop a method that will help the research community to download the basic information of the papers (title, abstract, author) for the searched query from arxiv, SSRN, and SocArxiv (Social Science ArXiv).
Method:
We used Web scraping to extract data from the servers and save it in excel file. To retrieve the desired query from the databases, a Python code is used. Two methods have been discussed in the study to download the metadata of the searched query.
Results:
We have used different queries (such as “grey literature”, “testing software”, and “python” etc.) to see the results of our proposed method. Furthermore, we cross-verified the results with the online search results of the databases.
Conclusion:
Initial results from the preliminary pilot evaluations show that it is a viable method to search, download, and shortlist the research articles information (title, abstract etc.) from arXiv,
1
 SSRN,
2
 and SocArXiv.
3
 For external validity more evaluations are needed.",September 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract discusses a method for downloading research papers, which may have limited impact on early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S0950584923001064,Case study identification: A trivial indicator outperforms human classifiers,Claes=Wohlin: claes.wohlin@bth.se,"Abstract
Context:
The definition and term “case study” are not being applied consistently by 
software engineering
 researchers. We previously developed a trivial “smell indicator” to help detect the misclassification of primary studies as case studies.
Objective:
To evaluate the performance of the indicator.
Methods:
We compare the performance of the indicator against human classifiers for three datasets, two datasets comprising classifications by both authors of systematic literature studies and primary studies, and one dataset comprising only primary-study author classifications.
Results:
The indicator outperforms the human classifiers for all datasets.
Conclusions:
The indicator is successful because human classifiers “fail” to properly classify their own, and others’, primary studies. Consequently, reviewers of primary studies and authors of systematic literature studies could use the classifier as a “sanity” check for primary studies. Moreover, authors might use the indicator to double-check how they classified a study, as part of their analysis, and prior to submitting their manuscript for publication. We challenge the research community to both beat the indicator, and to improve its ability to identify true case studies.",September 2023,"Case study, Evaluation, Systematic review, Primary study, Smell indicator",Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract introduces an indicator to evaluate case studies, which could be useful for startups in conducting research or analysis."
https://www.sciencedirect.com/science/article/pii/S0950584923001143,Counter-terrorism in cyber–physical spaces: Best practices and technologies from the state of the art,Giuseppe=Cascavilla: g.cascavilla@tue.nl; Damian A.=Tamburri: d.a.tamburri@tue.nl; Francesco=Leotta: leotta@diag.uniroma1.it; Massimo=Mecella: mecella@diag.uniroma1.it; WillemJan=Van Den Heuvel: w.j.a.m.v.d.heuvel@jads.nl,"Abstract
Context:
The demand for protection and security of physical spaces and urban areas increased with the escalation of terroristic attacks in recent years. We envision with the proposed cyber–physical systems and spaces, a city that would indeed become a smarter 
urbanistic
 object, proactively providing alerts and being protective against any threat.
Objectives:
This survey intend to provide a systematic multivocal literature survey comprised of an updated, comprehensive and timely overview of state of the art in counter-terrorism cyber–physical systems, hence aimed at the protection of cyber–physical spaces. Hence, provide guidelines to 
law enforcement agencies
 and practitioners providing a description of technologies and best practices for the protection of public spaces.
Methods:
We analyzed 112 papers collected from different online sources, both from the academic field and from websites and blogs ranging from 2004 till mid-2022.
Results:
(a) There is no one single bullet-proof solution available for the protection of public spaces. (b) From our analysis we found three major active fields for the protection of public spaces: Information Technologies, Architectural approaches, Organizational field. (c) While the academic suggest best practices and methodologies for the protection of urban areas, the market did not provide any type of implementation of such suggested approaches, which shows a lack of fertilization between academia and 
industry
.
Conclusion:
The overall analysis has led us to state that there is no one 
single solution
 available, conversely, multiple methods and techniques can be put in place to guarantee safety and security in public spaces. The techniques range from 
architectural design
 to rethink the design of public spaces keeping security into account in continuity, to emerging technologies such as 
AI
 and predictive surveillance.",September 2023,"Internet of Things, Cyber physical spaces, Public spaces, Cyber threat intelligence, Topic modeling, Topological data analysis, Protection public spaces, Smart city",Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract addresses the protection of urban areas using cyber-physical systems, offering insights that could be valuable for startups focusing on security technologies."
https://www.sciencedirect.com/science/article/pii/S0950584923000964,An approach for modeling the operational requirements of FaaS applications for optimal deployment,Nafisa=Ahmed: nafisa.abdelmutalab-ali-ahmed@polymtl.ca,"Abstract
FaaS can extend cloud capabilities to local edge devices. They enable composing applications into workflows and distributing their processes between the edge and the cloud. When deploying a FaaS application, the key issue is to define the desired 
operational requirements
 and find a configuration that satisfies them. Both problems are complex and subjective as they differ from one application to another depending on the application structure, run-time model, and optimization requirements. We address these issues using a general multi-criteria optimization approach based on a fuzzy 
analytical hierarchy process
 (AHP). Firstly, the specialists intuitively specify their fuzzy privacy in terms of 
data locality
, cost, and performance requirements. Then, a Fuzzy AHP model is constructed to compare and select the optimal workflow configuration that satisfies the requirements. The work is evaluated using a real FaaS application, where 
AWS
 Cloud and 
AWS
 Greengrass present the cloud and the edge. We assessed the ability of the proposed approach to retrieve the optimal configurations for various scenarios and compared the results to one of the state-of-the-art approaches. Unlike existing hard-coded approaches, our approach is intuitive, modular, extensible, and addresses more 
DevOps
 requirements.",September 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract addresses practical issues related to FaaS applications, providing a new approach based on fuzzy analytical hierarchy process. The real-world evaluation and comparison with existing approaches add value to European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923001076,The yea-paradox: Cognitive bias in technology acceptance surveys,Raffaele F=Ciriello: raffaele.ciriello@sydney.edu.au,"Abstract
Context
Technology acceptance is widely regarded as one of the most established, mature, and continuously relevant streams of 
information systems
 research. Its fundamental assumption is that technology acceptance scores accurately reflect users’ intentions, needs, and emotions toward the technology of interest. However, many studies (including this one) present evidence that challenges this assumption, suggesting that the link between reported scores and actual perception is more complex than often assumed.
Objective
We aim to find out how cognitive biases influence self-reported technology acceptance scores.
Method
We draw on dialogical iterations between an exploratory 
case study
 at Cloud Corp, a 
multinational
 Software-as-a-Service provider and related literature on technology acceptance and cognitive bias.
Findings
Our study reveals a paradoxical relationship between reported acceptance scores and actual perceptions: Despite providing high acceptance scores, users did not actually use the technology. Conversely, users who complained a lot by filing many support tickets were more engaged with the technology.
Conclusion
When yea-saying users meet yea-hearing designers, technology acceptance scores may be spuriously inflated, providing an exaggerated picture of users’ attitudes toward a technology. We call this the ‘yea-paradox’ because of its roots in people's tendency to agree half-heartedly (‘yea’), even when they privately disagree, to avoid more complex and potentially difficult conversations.",September 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the exploration of cognitive biases in technology acceptance scores is interesting, the relevance to practical applications for European early-stage ventures, especially startups, is not as direct compared to the other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923001015,A novel vulnerability severity assessment method for source code based on a graph neural network,Jingwei=Hao: hjwbit@163.com,"Abstract
Context
Vulnerability severity assessment is an important part of 
vulnerability management
 that can help security personnel determine the priority of vulnerability repair work.
Objective
Aiming at the problems of low evaluation efficiency and poor timeliness in the existing method, a vulnerability severity evaluation method combining a function call graph and vulnerability attribute graph is proposed.
Method
This method constructs a function call graph centered on vulnerable functions and uses the call relationship between vulnerable functions and sensitive API functions to reflect the severity of the damage of the vulnerable functions. The graph attention neural network algorithm is used to mine the key vulnerability characteristics in the function call graph and the vulnerability attribute graph to realize the assessment of vulnerability severity.
Results
The ablation experiment results showed that the combined vulnerability attribute graph and function call graph had higher evaluation accuracy than the vulnerability attribute graph or function call graph alone, which increased by 6.85% and 32.90%, respectively. Compared with other existing methods, our method has achieved a better evaluation effect, and the evaluation accuracy has increased by 10%.
Conclusion
The vulnerability severity assessment method incorporating function call graphs and vulnerability property graphs demonstrates an enhancement in the ability to represent the severity of vulnerabilities and increases the efficiency of vulnerability severity evaluation through elimination of the requirement for manual analysis.",September 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed vulnerability severity assessment method is valuable for security personnel and could benefit European early-stage ventures dealing with cybersecurity. The improvement in evaluation accuracy and efficiency is relevant for startups.
https://www.sciencedirect.com/science/article/pii/S0950584923001039,Making existing software quantum safe: A case study on IBM Db2,Lei=Zhang: leizhang@umbc.edu; Andriy=Miranskyy: avm@torontomu.ca,"Abstract
Context:
The 
software engineering
 community is facing challenges from 
quantum computers
 (QCs). In the era of 
quantum computing
, Shor’s algorithm running on QCs can break 
asymmetric encryption
 algorithms that classical computers practically cannot. Though the exact date when QCs will become “dangerous” for practical problems is unknown, the consensus is that this future is near. Thus, the 
software engineering
 community needs to start making software ready for quantum attacks and ensure quantum safety proactively.
Objective:
We argue that the problem of evolving existing software to quantum-safe software is very similar to the Y2K bug. Thus, we leverage some best practices from the Y2K bug and propose our roadmap, called 7E, which gives developers a structured way to prepare for quantum attacks. It is intended to help developers start planning for the creation of new software and the evolution of cryptography in existing software.
Method:
In this paper, we use a 
case study
 to validate the viability of 7E. Our software under study is the IBM Db2 database system. We upgrade the current cryptographic schemes to post-quantum cryptographic ones (using Kyber and Dilithium schemes) and report our findings and lessons learned.
Results:
We show that the 7E roadmap effectively plans the evolution of existing software security features towards quantum safety, but it does require minor revisions. We incorporate our experience with IBM Db2 into the revised 7E roadmap.
Conclusion:
The U.S. Department of Commerce’s National Institute of Standards and Technology is finalizing the post-quantum cryptographic standard. The software engineering community needs to start getting prepared for the quantum advantage era. We hope that our experiential study with IBM Db2 and the 7E roadmap will help the community prepare existing software for quantum attacks in a structured manner.",September 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The focus on evolving software to be quantum-safe is an important issue, but the direct impact on European early-stage ventures, especially startups, might be more long-term. The roadmap proposed could have practical value in the future."
https://www.sciencedirect.com/science/article/pii/S0950584923001155,RoseMatcher: Identifying the impact of user reviews on app updates,Peng=Liang: liangp@whu.edu.cn; Beiqi=Zhang: zhangbeiqi@whu.edu.cn; Tianyang=Liu: til040@ucsd.edu; Chong=Wang: cwang@whu.edu.cn; Kun=Huang: hunk_fe@whu.edu.cn; Maya=Daneva: m.daneva@utwente.nl; Marten=van Sinderen: m.j.vansinderen@utwente.nl,"Abstract
Context:
The release planning of mobile apps has become an area of active research, with most studies centering on app analysis through release notes in the Apple App Store and tracking user reviews via issue trackers. However, the correlation between these release notes and user reviews in App Store remains understudied.
Objective:
In this paper, we introduce 
RoseMatcher
, a novel automatic approach to match relevant user reviews with app release notes, and identify matched pairs with high confidence.
Methods:
We collected 944 release notes and 1,046,862 user reviews from 5 mobile apps in the Apple App Store as research data to evaluate the effectiveness and accuracy of 
RoseMatcher
, and conducted deep content analysis on matched pairs.
Results:
Our evaluation shows that 
RoseMatcher
 can reach a hit ratio of 0.718 for identifying relevant matched pairs, and with the manual labeling and content analysis of 984 relevant pairs, we identify 8 roles that user reviews play in app updates according to the relationship between release notes and user reviews in the relevant matched pairs.
Conclusions:
Our findings indicate that both app development teams and users pay close attention to release notes and user reviews, with release notes typically addressing feature requests, 
bug reports
, and complaints, and user reviews offering positive, negative, and constructive feedback. Overall, the study highlights the importance of the communication between app development teams and users in the release planning of mobile apps, with relevant reviews tending to be posed within a short period before and after the release of release notes, with the average time interval between the post time of release notes and user reviews being approximately one year.",September 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study introduces a novel approach that can help app development teams and users improve communication and understanding in the release planning process, highlighting the importance of user feedback."
https://www.sciencedirect.com/science/article/pii/S0950584923001027,A new combination method based on Pearson coefficient and information entropy for multi-sensor data fusion,Yang=Zhang: zhang.yang@bjtu.edu.cn,"Abstract
Context
When confronted with greatly contradictory evidence, the Dempster-Shafer evidence theory may exhibit certain constraints that lead to fused results which are inconsistent with common understanding. Within the existing 
Internet of Things
 landscape, there are occasions when a small number of sensors may malfunction and contradict each other.
Objective
This study addresses contradictory information by processing the bodies of evidence beforehand. Additionally, an enhanced fusion technique for conflicting evidence is introduced, which employs 
Pearson correlation coefficient
 and information entropy.
Methods
We propose a novel combination approach for multi-sensor 
data fusion
 based on evidence theory. Firstly, the credibility for each piece of evidence is computed through amalgamating correlation measurements with evidence distance between two pieces of evidence. Next, based on the information volume, the credibility is adjusted, resulting in the final weighting factor for the evidence. The reasonable weighted average evidence is then created using the weighting factor of each piece of evidence. Finally, the combined result is obtained by applying Dempster's combination rule, which combines the weighted average evidence 
N
−
1
 times.
Results
Upon comparing the fusion results, it has been observed that the performance of the proposed method surpasses that of other methods. Our method can effectively minimize the ramifications of profoundly conflicting evidence in the fusion process, resulting in more logical fusion results than other methods.
Conclusions
The outcomes of numerical examples expose that the technique put forward in this manuscript can manage highly conflicting evidence, thereby yielding fusion results that are more precise and conducive to making sound decisions.",September 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study proposes a new fusion technique for conflicting evidence in IoT scenarios, which can lead to more logical results and aid in decision-making."
https://www.sciencedirect.com/science/article/pii/S0950584923000836,To group or not to group? Group sizes for requirements elicitation,Luisa=Mich: luisa.mich@unitn.it,"Abstract
Context
Requirement elicitation
 can be done by individuals or by groups. Computer-based system development life-cycle models suggest having people working together for many steps. Also, recommendations about analysis and design methods indicate that some processes could take advantage of group work. In 
requirements engineering
, groups are suggested for requirements elicitation.
Objectives
From the software and the requirements engineering viewpoints, and in turn for companies, a relevant overall research question is “What is a suitable size for a requirements elicitation group?” Our goal was to answer this question, first by looking for available guidelines in textbooks and secondly by investigating requirements elicitation in companies.
Method
To address the research question, we conducted two studies. The first was a review of most widely adopted software and requirements engineering textbooks. The second was a study aimed at identifying factors affecting group size for requirements elicitation, based on an online questionnaire submitted to professional analysts.
Results
The review of the textbooks showed that very few give advice on the number of analysts to involve in requirements elicitation sessions. When they do, guidelines are quite general and not supported by empirical data. According to data gathered from the questionnaire, most companies use and suggest using small groups. Data also allowed identifying four categories of factors useful to make decisions about requirements elicitation group sizes: people, relation, project, and output.
Conclusion
Both the textbook review and the data from the questionnaire say that it is better to aim for small groups than to have individual analysts working separately. The ideal number of analysts for a requirements elicitation session appears to be 2, but large groups are necessary in some cases. Factors in all the four categories have to be considered in deciding the size of groups.",August 2023,"Group work, Individual work, Requirements elicitation, Requirements idea generation, Requirements engineering, Software engineering",Information and Software Technology,2025-03-18T00:00:00,8.0,"The research addresses a practical question relevant to software companies, providing insights on the suitable size for requirements elicitation groups, which can help improve the software development process."
https://www.sciencedirect.com/science/article/pii/S0950584923000769,A mapping study of language features improving object-oriented design patterns,William=Flageol: w_flage@encs.concordia.ca,"Abstract
Context:
Object-Oriented Programming 
design patterns
 are well-known in the industry and taught in universities as part of 
software engineering
 curricula. Many primary studies exist on the impact of 
design patterns
 on software, in addition to secondary studies summarizing these publications. Some primary studies have proposed new 
language features
 and used them to re-implement design patterns as a way to show improvements. While secondary studies exist, they mainly focus on measuring the impact of design patterns on software.
Objectives:
We performed a 
systematic mapping study
 to catalogue 
language features
 in the literature claiming to improve object-oriented design patterns implementations, as well as how primary studies measure these improvements.
Methods:
We performed a search in three databases, yielding a total of 874 papers, from which we obtained 34 relevant papers. We extracted and studied data about the language features claiming to improve design patterns implementations, the most often cited design patterns, the measures used to assess the improvements, and the 
case studies
 and experiments with which these improvements were studied.
Results:
Using the results, we catalogue 18 language features claimed in the literature to improve design patterns and categorize them into paradigms. We find that some design patterns are more prevalent than others, such as Observer and Visitor. Measures related to code size, code scattering and 
understandability
 are preferred. Case studies are done in-vitro, and experiments are rare.
Conclusion:
This catalogue is useful to identify trends and create a road map for research on language features to improve object-oriented design patterns. Considering the prevalence of design patterns, improving their implementation and adding language features to better solve their underlying concerns is an efficient way to improve object-oriented programming. We intend in the future to use this as a basis to research specific language features that may help in improving object-oriented programming.",August 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The systematic mapping study provides valuable insights into language features to improve object-oriented design pattern implementations, offering a roadmap for future research in object-oriented programming."
https://www.sciencedirect.com/science/article/pii/S0950584923000782,StartCards — A method for early-stage software startups,Kai-Kristian=Kemell: kai-kristian.kemell@helsinki.fi,"Abstract
Context:
Software startups are important drivers of economy on a global scale, and have become associated with innovation and high growth. However, the overwhelming majority of startups ends in failure. Many of these startup failures ultimately stem from 
software engineering
 issues, and 
requirements engineering
 (RE) ones in particular. Despite the emphasis placed on the importance of RE activities in the startup context, many startups continue to develop software without a clear market or customer, having never had meaningful contact with their would-be customer.
Objective:
We develop a method aimed at early-stage startups that is intended to help startups through the initial stages of the startup process: StartCards. The method emphasizes the importance of idea and product validation activities in particular in order to tackle anti-patterns related to (a lack of) RE in startups. This method is based on existing literature, both grey and academic literature.
Method:
StartCards was developed using the Canonical 
Action Research
 (CAR) approach, over the course of 4 AR cycles. During the AR process, the method was used by 44 student startup teams in a practical course setting. Data from the use of the method was collected through self-reporting in the form of modified learning diaries, mentoring meetings with the startup teams, and a qualitative survey.
Results:
We consider the current version of StartCards useful for early-stage startups based on the data we have collected. The method can also be used as a pedagogical tool in startup education.
Conclusions:
The paper presents the first published version of the method. While work on the method continues, the method is deemed ready for use.",August 2023,"Software startups, Requirements engineering, Validation, Software engineering method, Action research",Information and Software Technology,2025-03-18T00:00:00,7.0,"The development of StartCards offers a practical method to help early-stage startups improve their validation activities, addressing a common issue in the startup ecosystem."
https://www.sciencedirect.com/science/article/pii/S0950584923000733,HGIVul: Detecting inter-procedural vulnerabilities based on hypergraph convolution,Junfeng=Wang: wangjf@scu.edu.cn,"Abstract
Context:
Detecting source code vulnerabilities is one way to block 
cyber attacks
 from an early stage. Vulnerability-triggered code typically involves one or more function procedures, while current research pays more attention to the code on a single procedure. Due to lacking a comprehensive analysis of multiple vulnerability-related procedures, current methods suffer disorder false-positive and false-negative rates, especially in detecting inter-procedural vulnerability.
Objective:
This paper proposes HGIVul, an inter-procedural 
vulnerability detection
 method for source code based on hypergraph convolution. The key of HGIVul is to derive the syntax-semantic characteristic from multiple procedures in a suitable code information space, which brings more balanced detection.
Methods:
Firstly, the potential vulnerability-related code trace across multiple procedures is located via static analyzer Infer. Then, HGIVul reconstructs the soft inter-procedural 
control flow graph
 (ICFG) from the trace to restore the complex relationship between multiple-procedural codes. Next, HGIVul performs multi-level 
graph convolution
 on the soft ICFG to grasp holistic code characteristics within multiple procedures. Finally, a classifier is applied to the extracted code features for 
vulnerability detection
.
Results:
The experimental results show that HGIVul outperforms in detecting vulnerabilities and identifying vulnerability types, with the F1-measure of 66.33% and 79.58% for detection and identification, respectively. Moreover, the experiment on cross-projects indicates HGIVul has a better detection ability.
Conclusion:
The proposed HGIVul achieves a balanced detection performance than the related state-of-the-art methods, which proves that fusing syntactic–semantic information from multiple procedures benefits inter-procedural vulnerability detection. In addition, the results applied to five actual projects indicate that HGIVul has the feasibility of detection in practical.",August 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"HGIVul presents a novel method for vulnerability detection in source code, with strong experimental results showing its effectiveness, which can have a significant impact on improving cybersecurity for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000770,"Human error management in requirements engineering: Should we fix the people, the processes, or the environment?",Sweta=Mahaju: Sweta.Mahaju@mtsu.edu; Jeffrey C.=Carver: carver@cs.ua.edu; Gary L.=Bradshaw: glb2@psychology.msstate.edu,"Abstract
Context:
Software development is a human-centric activity and hence vulnerable to human error. Human errors are errors in the human thought process. To ensure software quality, it is important for practitioners to understand how to manage these human errors. Organizations often introduce changes into the 
requirements engineering
 process to either 
prevent
 human errors from occurring or to 
mitigate
 the harm caused when those errors do occur. While there are studies on human error management in other disciplines, research on the prevention and mitigation of human errors in 
software engineering
, and 
requirements engineering
 specifically, are limited. The current studies in 
software engineering
 do not provide strong results about the types of changes that are most effective in requirements engineering.
Objective:
The goal of this paper is to develop a taxonomy of human error prevention and 
mitigation strategies
 based on data gathered from requirements engineering professionals.
Methods:
We performed a qualitative 
analysis of data
 from two practitioner surveys on requirements engineering practices to identify and classify strategies for the prevention and mitigation of human errors.
Results:
We organized the human error management strategies into a taxonomy based on whether the changes primarily affect People, Processes, or the Environment. Inside each of these high-level categories, we further organized the strategies into low-level classes. The results show more than 50% of the reported strategies require a change in Process, 23% require a change in Environment, 21% require a change in People, with the remaining 5% too ambiguous to classify. In addition, more than 50% of the strategies focus on Management activities of requirements engineering.
Conclusion:
The Human Error Management Taxonomy provides a systematic classification and organization of strategies for prevention and mitigation of human errors in requirements engineering. This systematic organization provides a foundation upon which research can build.",August 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The Human Error Management Taxonomy provides a systematic classification of strategies for preventing and mitigating human errors in requirements engineering, offering valuable insights for startups to enhance software quality."
https://www.sciencedirect.com/science/article/pii/S0950584923000745,Usefulness and usability of heuristic walkthroughs for evaluating domain-specific developer tools in industry: Evidence from four field simulations,Olaf=Leßenich: olaf.lessenich@wu.ac.at; Stefan=Sobernig: stefan.sobernig@wu.ac.at,"Abstract
Context:
The usage of domain-specific languages (DSLs) is an approach to reduce complexity in software development by expert developers for selected application domains. To support expert developers, a DSL is often combined with a tailored, domain-specific developer tool, offering similar functionality as general-purpose programming environments (IDEs like Eclipse for Java) while integrating with a domain-specific toolchain (e.g., code or documentation generators, simulators). General-purpose development environments have been successfully evaluated for the programmer experience (PX) and for anomalies using heuristic walkthroughs as a mixed review technique combining cognitive walkthroughs and a 
heuristic evaluation
.
Objective:
In this paper, we report on the usefulness and acceptance of heuristic walkthroughs as an PX evaluation technique applied to domain-specific languages and 
IDEs
 in an industry context.
Methods:
Heuristic walkthroughs are used in four interventions (field simulations) to assess the programming experience and usability of domain-specific, Eclipse-based IDEs in a concrete industry setting. Data on the usefulness and acceptance (perceived satisfaction) of the walkthroughs themselves are collected and analysed.
Results:
Our studies show that, in practice, the instrument of walkthroughs is useful for revealing practically relevant PX anomalies, while maintaining acceptance by practitioners participating in the walkthroughs.
Conclusion:
The documented variant of heuristic walkthroughs is eligible to become adopted for future field studies in academic research and for evaluation projects in industry, in support of developing domain-specific developer tooling in an evidence-driven manner.",August 2023,"Domain-specific language, Integrated development environment, User experience, Programmer experience, Review, Heuristic walkthrough",Information and Software Technology,2025-03-18T00:00:00,6.0,"The evaluation of heuristic walkthroughs for assessing domain-specific languages and IDEs contributes to improving developer tooling, but may have a slightly lower impact compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919301636,PrioriTTVs: A process aimed at supporting researchers to prioritize threats to validity and their mitigation actions when planning controlled experiments in SE,Eudis=Teixeira: eot@cin.ufpe.br; Liliane=Fonseca: lss4@cin.ufpe.br; Bruno=Cartaxo: email@brunocartaxo.com; Sergio=Soares: scbs@cin.ufpe.br,"Abstract
Context
Researchers argue that a critical component of any empirical study in 
Software Engineering
 (SE) is to identify, analyze, and mitigate threats to validity.
Objective
We propose PrioriTTVs, a process to support researchers in identifying and prioritizing threats to validity and their corresponding 
mitigation actions
 when planning controlled experiments in SE. We also introduce a tool to support the entire process.
Method
Empirical studies were conducted with six experts and 20 
postgraduate students
 to evaluate the ease of use, learning, and perceptions of satisfaction regarding PrioriTTVs.
Results
So far, participants have considered PrioriTTVs to be useful (83%), significantly contributing to learning (90%), and satisfaction (75%).
Conclusions
We believe both novice and expert users can benefit from the process we propose for addressing threats to validity when conducting SE experiments. We also intend to extend our approach to manage threats specific to different SE experiment contexts.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed process and tool for addressing threats to validity in SE experiments can benefit both novice and expert users in the field, including early-stage ventures conducting controlled experiments."
https://www.sciencedirect.com/science/article/pii/S095058492300085X,Salience-based stakeholder selection to maintain stakeholder coverage in solving the next release problem,I.M.=del Águila: imaguila@ual.es,"Abstract
Context:
The quantification of stakeholders plays a fundamental role in the selection of appropriate requirements, as their judgement is a significant criterion, as not all stakeholders are equally important. The original proposals modelled stakeholder importance using a weighting approach that may not capture all the dimensions of stakeholder importance. Furthermore, actual projects involve a multitude of stakeholders, making it difficult to consider and compute all their weights. These facts lead us to search for strategies to adequately assess the importance concept, reducing the 
elicitation
 effort.
Objective:
We propose grouping strategies as a means of reducing the number of stakeholders to manage in requirement selection while maintaining adequate stakeholder coverage (how selection meets stakeholder demands).
Methods:
Our approach is based on the salience of stakeholders, defined in terms of their power, legitimacy, and urgency. Diverse strategies are applied to select important 
stakeholder groups
. We use 
k-means
, 
k-medoids
, and 
hierarchical
 clustering, after deciding the number of clusters based on validation indices.
Results:
Each technique found a different group of important stakeholders. The number of stakeholder groups suggested experimentally (3 or 4) coincides with those indicated by the literature as definitive, dominant, dependent, and dangerous for 4 groups; or critical, major, and minor for 3 groups. Either for all the stakeholders and for each important group, several requirements selection 
optimisation problems
 are solved. The tests do not find significant differences in coverage when important stakeholders are filtered using clustering, regardless of the technique and number of groups, with a reduction between 66.32% and 87.75% in the number of stakeholders considered.
Conclusions:
Applying 
clustering methods
 to data obtained from a project is useful in identifying the group of important stakeholders. The number of suggested groups matches the stakeholders’ theory, and the stakeholder coverage values are kept in the requirement selection.",August 2023,"Stakeholders theory, Stakeholders selection and quantification",Information and Software Technology,2025-03-18T00:00:00,5.0,"The application of grouping strategies to reduce the number of stakeholders in requirement selection is beneficial, but may have a slightly lower impact compared to other abstracts in terms of practical value."
https://www.sciencedirect.com/science/article/pii/S0950584923001003,A multitype software buffer overflow vulnerability prediction method based on a software graph structure and a self-attentive graph neural network,Yongshan=Liu: 451499304@qq.com,"Abstract
Context
Buffer overflow vulnerabilities are one of the most common and dangerous software vulnerabilities; however, the complexity of software code makes predicting 
buffer overflow
 vulnerabilities in software challenging.
Objective
To accurately predict multiple types of software buffer overflow vulnerabilities, this paper proposes a multitype software buffer overflow vulnerability prediction method called MSVAGraph that is based on the graph structure of software and a self-attentive 
graph neural network
.
Method
First
, by analyzing software buffer overflow type vulnerabilities, a vulnerability feature set GSVFset extraction method based on graph structure is proposed to act as the software's basic unit. 
Second,
 a self-attentive pooling mechanism is used to design a vulnerability feature update mechanism based on a self-attentive graph neural network to transform the graph structure of the vulnerability feature set GSVFset into a feature vector representation. 
Finally
, based on the updated GSVFset feature vector, a time-recursive-based neural network is designed to construct a prediction method for multitype software buffer overflow vulnerabilities.
Results
The method proposed in this paper validates executable programs of four types of buffer overflow vulnerabilities in the Juliet dataset using precision, accuracy, recall and F1 value as evaluation metrics. The prediction results have higher values after introducing the self-attentive pooling mechanism.
Conclusion
The proposed MSVAGraph achieves high precision, accuracy, recall and F1 value, and can better preserve the network topology and node content information of graphs in the software's graph structure.",August 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed MSVAGraph method addresses a critical issue in software development - buffer overflow vulnerabilities - and achieves high precision, accuracy, recall, and F1 value, which can greatly impact the security of European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000861,Soft skills required from software professionals in New Zealand,Matthias=Galster: matthias.galster@canterbury.ac.nz; Antonija=Mitrovic: tanja.mitrovic@canterbury.ac.nz; Sanna=Malinen: sanna.malinen@canterbury.ac.nz; Jay=Holland: jay.holland@canterbury.ac.nz; Pasan=Peiris: pitigalagepasan.peiris@pg.canterbury.ac.nz,"Abstract
Context:
Soft skills (e.g., communication) significantly contribute to software project success.
Objective:
We aim to understand (a) what are relevant soft skills in 
software engineering
, (b) how soft skills relate to characteristics of hiring organizations, and (c) how reliably we can 
automatically
 identify soft skills in job adverts to support their continuous analysis. We focus on soft skills required by organizations in New Zealand, a country with a small but growing software sector characterized by a skills shortage, reliance on offshoring, and embedded in a bi-cultural context.
Method:
We manually analyzed 530 job adverts from New Zealand’s largest portal for technology-related positions. We identified soft skills following an inductive approach, i.e., without pre-defined soft skills. We complemented the manual analysis with an automated analysis using Flexiterm (an approach for term recognition).
Results:
We found explicit references to soft skills in 82% of adverts. Adverts from 
recruitment agencies
 (compared to hiring companies) included fewer soft skills. We identified 17 soft skills and proposed a contextualized software engineering description. Communication-related skills are most in demand. Soft skills related to broader human or societal values (e.g., empathy, cultural awareness) or distributed development are not common. Soft skills do not depend on company size or core business and domain of companies, or whether a company operates globally. Automatically identifying soft skills in adverts is error-prone.
Conclusions:
Employers explicitly ask for soft skills. Our findings support previous studies that highlight the importance of communication. On the other hand, identified soft skills only partially overlap with those reported in other skills classifications. Characteristics specific to New Zealand do not impact the demand for soft skills. Our findings benefit researchers in human aspects of software engineering and to those responsible for staff, curricula and professional development.",August 2023,"Soft skills, Software engineering practice, Job adverts, Exploratory study, Flexiterm",Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on soft skills in software engineering provides valuable insights for hiring organizations in New Zealand, but the impact on European early-stage ventures may not be as direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S095058492300099X,A fault localization approach based on fault propagation context,Shujuan=Jiang: shjjiang@cumt.edu.cn,"Abstract
Context:
Spectrum-based 
fault localization
 (SBFL) performs statistical analysis on the coverage information of failed or passed test cases. It provides the programmer with a guide for 
fault localization
 by generating a sorted list of suspicious elements. Unfortunately, the SBFL technology has a tie problem. Many elements in the list have the same suspicious values, which seriously affects the developer finding faults.
Objective:
Therefore, we aim to solve the tie problem of SBFL techniques by applying the 
fault propagation
 context. In this paper, we propose an approach to boost the performance of fault localization by applying inter-class and intra-class 
fault propagation
 context to weight the suspicious elements.
Methods:
We first apply the SBFL techniques to calculate the initial suspicious values of the statements. Then, we analyze the fault propagation context of the suspicious statements. Finally, we weight the initial suspicious values of the statements to solve the tie problem of SBFL techniques. The weighted suspicious values are sorted in 
descending order
 to generate a list, which is provided to developers for fault localization.
Results:
To evaluate our approach, we experiment on Defects4J, a real-world 
software fault
 benchmark. Experimental results show that the proposed approach outperforms existing fault context-based methods that only use intra-class context and traditional 
SBFL methods
. For example, our approach can locate 129 faults in Top-1, which is 94 more than Ochiai method. Moreover, we provide programmers with the fault propagation context for accurate fault localization.
Conclusion:
Applying fault propagation context can effectively solve the tie problem in SBFL. It is valuable to study how to efficiently utilize the fault propagation context for fault localization.",August 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"Solving the tie problem in Spectrum-based fault localization techniques has a significant practical value for software developers, as shown by the experimental results on real-world software fault benchmark, making it highly impactful for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000794,An empirical comparison of combinatorial testing and search-based testing in the context of automated and autonomous driving systems,Florian=Klück: fklueck@ist.tugraz.at; Yihao=Li: yihao.li@ldu.edu.cn; Jianbo=Tao: Jianbo.Tao@avl.com; Franz=Wotawa: wotawa@ist.tugraz.at,"Abstract
Context:
More automated and 
autonomous systems
 are becoming daily use that implements safety–critical functions, e.g., 
autonomous driving
 or mobile robots. Testing such systems people depend on is challenging because some environmental interactions may not be expected during development but occur when those systems are in operation. Deciding when to stop testing or answering how to ensure sufficient testing is challenging and very expensive.
Objectives:
For generating critical environmental interactions, i.e., critical scenarios, we present and compare two testing solutions focusing on generating critical scenarios utilizing combinatorial and search-based testing, respectively.
Methods:
For combinatorial testing, we suggest using ontologies that describe the environment of an autonomous or highly automated system. For search-based testing, we rely on 
genetic algorithms
. We experimentally compared the two testing approaches using two implementations of an industrial emergency braking function and random testing as the baseline. Furthermore, we compared the approaches qualitatively using several categories.
Results:
From the experiments, we see that the combinatorial testing approach can find all different types of faults listed in Table 5 considering a combinatorial 
strength
 of 3. This is not the case for search-based and random testing in all experiments. Combinatorial testing comes with the highest combinatorial coverage. However, all approaches can reveal faulty behavior utilizing appropriate environmental models.
Conclusion:
We present the results of an in-depth comparison of combinatorial and search-based testing. The be as fair as possible, the comparison relied on the same environmental model and other parameters like the number of 
generated test cases
. The results show that combinatorial testing comes with the highest coverage and can find all different kinds of failures summarized in Table 5 providing a certain strength. Meanwhile, search-based testing is also capable of finding different failures depending on the coverage it can reach. Both approaches seem complementary and of use for the application domain of autonomous and automated driving functions.",August 2023,"Test generation, Ontologies, Combinatorial testing, Search-based testing, Genetic algorithm",Information and Software Technology,2025-03-18T00:00:00,8.0,"The comparison of combinatorial and search-based testing for critical scenario generation in automated systems addresses a crucial aspect of ensuring sufficient testing, which can have a significant impact on the reliability and safety of European early-stage ventures utilizing autonomous systems."
https://www.sciencedirect.com/science/article/pii/S0950584923000824,Test case classification via few-shot learning,Yuan=Zhao: zhaoyuan@smail.nju.edu.cn; Sining=Liu: 181250093@smail.nju.edu.cn; Quanjun=Zhang: quanjun.zhang@smail.nju.edu.cn; Xiuting=Ge: dg20320002@smail.nju.edu.cn; Jia=Liu: jialiu@nju.edu.cn,"Abstract
Context:
Crowdsourced testing can reduce testing costs and improve testing efficiency. However, crowdsourced testing generates massive test cases, requiring testers to select high-quality test cases for execution. Consequently, crowdsourced test cases require much effort to perform labeling due to the costly manual labor and domain knowledge.
Objective:
Existing methods usually fail to consider the crowdsourced testing scenario’s inadequate and 
imbalanced data
 issues. We aim to effectively and efficiently classify many crowdsourced test cases for developers to alleviate manual efforts.
Method:
In this paper, we propose a test case 
classification approach
 based on few-shot learning and test case augmentation to address the limitations mentioned above. The proposed approach generates new test cases by the large pre-trained masked 
language model
 and extracts embedding representation by training 
word embedding
 models. Then a Bidirectional Long Short-Term Memory (BiLSTM)-based classifier is designed to perform test case classification by extracting the in-depth features. Besides, we also apply the 
attention mechanism
 to assign high weights to words that represent the test case category by lexicon matching.
Results:
To verify the effectiveness of the classification framework, we select 1659 test cases from three crowdsourced testing projects to conduct in-usability evaluation experiments. The experimental results show that the proposed approach has a higher accuracy and precision rate than existing classification methods.
Conclusion:
It can be concluded that (1) the proposed approach is an effective test case 
classification technique
 for crowdsourced testing; (2) the proposed approach is practical to help developers select high-quality test cases quickly and effectively.",August 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract offers a practical approach to classifying crowdsourced test cases, which can be beneficial for startups looking to improve testing efficiency and reduce manual efforts."
https://www.sciencedirect.com/science/article/pii/S0950584923000800,On the effectiveness of automated tracing from model changes to project issues,Fabiano=Dalpiaz: f.dalpiaz@uu.nl,"Abstract
Context:
Requirements Traceability (RT) is concerned with monitoring and documenting the lifecycle of requirements. Although researchers have proposed several automated tracing tools, trace 
link establishment
 and maintenance are still prevalently manual activities.
Objective:
In order to foster the adoption of automated tracing tools, we study their empirical effectiveness in the context of model-driven development (MDD). We focus on trace link recovery (TLR) from (i) SVN revisions of MDD models to (ii) JIRA issues that represent requirements and bugs.
Method:
Based on the state-of-the-art in automated TLR, we propose the 
LCDTrace
 tool that uses 131 features to train a 
machine learning
 classifier. Some of these features use specific information for MDD contexts. We conduct three experiments on ten datasets from seven MDD projects. First, we evaluate the effectiveness of three 
ML algorithms
 and four rebalancing strategies using all 131 features, and we derive two optimal combinations for trace link recommendation and for trace maintenance. Second, we investigate whether the MDD-specific features convey higher performance than a version of 
LCDTrace
 that excludes those features. Third, we employ automated feature selection and study whether we can reduce the number of features while keeping similar performance, thereby boosting time and energy efficiency.
Results:
In our experiments, the 
gradient boosting
 models outperform those based on 
random forests
. The best combinations for trace recommendation and maintenance achieve an 
F
2
-score of 61% and F
0.5
-score of 67%, respectively. While MDD-specific features do not provide additional value, automated feature selection succeeds at reducing feature numerosity without compromising performance.
Conclusion:
We provide insights on the effectiveness of state-of-the-art TLR techniques in MDD. Our findings are a baseline for devising and experimenting with alternative TLR approaches.",August 2023,"Requirement Traceability, Trace link recovery, Model-driven development, Low-code development, Machine learning",Information and Software Technology,2025-03-18T00:00:00,9.0,"The abstract presents an empirical study on automated tracing tools in model-driven development, offering practical implications for startups to adopt automated tracing tools effectively."
https://www.sciencedirect.com/science/article/pii/S0950584923000940,A scientific software ecosystem architecture for the livestock domain,Valdemar Vicente Graciano Neto=Not Found: valdemarneto@ufg.br,"Abstract
Context:
In the 
livestock
 domain, technologies are developed to sustainably raise animal production. However, the domain is critical, since animals are very sensitive to variables such as temperature and humidity, which can cause diseases and consequent production losses and discomfort. 
Livestock production systems
 then demand monitoring, reasoning, and acting on the environment so that the levels of those variables are preserved in pre-established intervals and undesired conditions are predicted, avoided, and mitigated with automated actions.
Objective:
The main contribution of this article is presenting E-SECO, a software ecosystem platform, and its evolution that encapsulates a new self-adaptive component to tackle animal production decisions, named e-Livestock architecture.
Method:
Two 
case studies
 were conducted involving a real system derived from the E-SECO platform encompassing a Compost 
Barn
 production system, i.e., the environment and surrounding technology where 
bovine milk
 production takes place.
Results:
Results showed the effectiveness of E-SECO to (i) abstract disruptive technologies based on the 
Internet of Things
 (IoT) and 
Artificial Intelligence
 and accommodate them in a single architecture for that specific domain, (ii) support reuse and derivation of a self-adaptive architecture to support engineering a complex system for a 
livestock
 sub-domain (milk production), and (iii) support empirical studies in a real smart farm towards a future transfer of technology to industry.
Conclusion:
The results showed that the E-SECO platform, which encompasses e-livestock architecture, can support monitoring, reasoning, prediction, and automated actions in a milk production/Compost 
Barn
 environment.",August 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The development of new technologies for sustainable livestock production has practical value for early-stage ventures in the agriculture sector, especially for startups focusing on smart farming."
https://www.sciencedirect.com/science/article/pii/S0950584923000952,Towards optimization of anomaly detection in DevOps,Adha=Hrusto: adha.hrusto@cs.lth.se,"Abstract
Context:
DevOps
 has recently become a mainstream solution for bridging the gaps between development (Dev) and operations (Ops) enabling cross-functional collaboration. The DevOps concept of continuous monitoring may bring a lot of benefits to development teams such as early detection of run-time errors and various performance anomalies.
Objective:
We aim to explore 
deep learning
 (DL) solutions for detection of anomalous 
systems behavior
 based on collected 
monitoring data
 that consists of applications’ and systems’ performance metrics. Moreover, we specifically address a shortage of approaches for evaluating 
DL models
 without any ground truth data.
Methods:
We perform a 
case study
 in a real DevOps environment, following the principles of the design science paradigm. The research activities span from practice to theory and from problem to solution domain, including problem conceptualization, solution design, 
instantiation
, and empirical validation.
Results:
We proposed and implemented a cloud solution for DL model deployment and evaluation empowered by feedback from the development team. The labeled data generated through the feedback was used for evaluation of current and training of new DL models in several iterations. The overall results showed that reconstruction-based models such as 
autoencoders
, are quite robust to any parameter modification and are among the preferred for 
anomaly detection
 in multivariate monitoring data.
Conclusion:
Leveraging raw monitoring data and DL-inspired solutions, DevOps teams may get critical insights into the software and its operation. In our case, this proved to be an efficient way of discovering early signs of production failures.",August 2023,"Microservices, DevOps, Anomaly detection, Deep learning",Information and Software Technology,2025-03-18T00:00:00,4.0,"While the use of deep learning in DevOps environments is interesting, the direct impact on European early-stage ventures, particularly startups, may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000460,Industrial applications of software defect prediction using machine learning: A business-driven systematic literature review,Lech=Madeyski: lech.madeyski@pwr.edu.pl,"Abstract
Context:
Machine learning
 
software defect
 prediction is a promising field of 
software engineering
, attracting a great deal of attention from the research community; however, its industry application tents to lag behind academic achievements.
Objective:
This study is part of a larger project focused on improving the quality and minimising the cost of software testing of the 5G system at Nokia, and aims to evaluate the business applicability of machine learning software 
defect prediction
 and gather lessons learnt.
Methods:
The systematic literature review was conducted on journal and 
conference papers
 published between 2015 and 2022 in popular online databases (ACM, IEEE, Springer, Scopus, Science Direct, and Google Scholar). A quasi-gold standard procedure was used to validate the search, and SEGRESS guidelines were used for transparency, reporting, and replicability.
Results:
We have selected and analysed 32 publications out of 397 found by our automatic search (and seven by snowballing). We have identified highly relevant evidence of methods, features, frameworks, and datasets used. However, we found a minimal emphasis on practical lessons learnt and cost consciousness — both vital from a business perspective.
Conclusion:
Even though the number of machine learning software defect prediction studies validated in the industry is increasing (and we were able to identify several excellent papers on studies performed in vivo), there is still not enough practical focus on the business aspects of the effort that would help bridge the gap between the needs of the industry and academic research.",July 2023,"Software defect prediction, Machine learning, Systematic literature review, Effort and cost minimisation, Real-world, Industry",Information and Software Technology,2025-03-18T00:00:00,4.0,"The study on machine learning software defect prediction, while important for software engineering, may not have a significant immediate impact on European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000459,A systematic literature review of capstone courses in software engineering,Tomi=Männistö: tomi.mannisto@helsinki.fi; Saara=Tenhunen: saaraten@gmail.com; Matti=Luukkainen: matti.luukkainen@helsinki.fi; Petri=Ihantola: petri.ihantola@helsinki.fi,"Abstract
Context:
Tertiary education institutions aim to prepare their computer science and 
software engineering
 students for working life. While much of the technical principles are covered in lower-level courses, team-based capstone courses are a common way to provide students with hands-on experience and teach soft skills.
Objective:
This paper explores the characteristics of project-based software engineering capstone courses presented in the literature. The goal of this work is to understand the pros and cons of different approaches by synthesising the various aspects of software engineering capstone courses and related experiences.
Method:
In a 
systematic literature review
 for 2007–2022, we identified 127 articles describing real-world capstone courses. These articles were analysed based on their presented course characteristics and the reported course outcomes.
Results:
The characteristics were synthesised into a taxonomy consisting of duration, team sizes, client and project sources, project implementation, and 
student assessment
. We found out that capstone courses generally last one semester and divide students into groups of 4–5 where they work on a project for a client. For a slight majority of courses, the clients are external to the course staff and students are often expected to produce a proof-of-concept level software product as the main end deliverable. The courses generally include various forms of student assessment both during and at the end of the course.
Conclusions:
This paper provides researchers and educators with a classification of characteristics of software engineering capstone courses based on previous research. We also further synthesise insights on the reported course outcomes. Our review study aims to help educators to identify various ways of organising capstones and effectively plan and deliver their own capstone courses. The characterisation also helps researchers to conduct further studies on software engineering capstones.",July 2023,"Capstone, Project course, Computer science education, Software engineering education",Information and Software Technology,2025-03-18T00:00:00,6.0,"The exploration of project-based software engineering capstone courses can provide valuable insights for educators and researchers, but the direct impact on early-stage ventures and startups is moderate."
https://www.sciencedirect.com/science/article/pii/S0950584923000526,Applications of statistical causal inference in software engineering,Julien=Siebert: julien.siebert@iese.fraunhofer.de,"Abstract
Context:
The aim of statistical causal inference (SCI) methods is to estimate causal effects from 
observational data
 (i.e., when 
randomized controlled trials
 are not possible). In this context, Pearl’s framework based on causal 
graphical models
 is an approach that has recently gained popularity and allows for explicit reasoning about issues related to spurious correlations.
Objective:
Our primary goal is to understand to which extend and how Pearl’s graphical framework is applied in 
software engineering
 (SE).
Methods:
We performed a 
systematic mapping study
 and analysed a total of 
25
 papers published between 2010 and 2022.
Results:
Our results show that the application of Pearl’s SCI framework in SE is relatively recent and that the corresponding research community is fragmented. Most of the selected papers focus on software quality analysis. There is no clear and widespread 
community of practice
 (yet) on how to implement and evaluate SCI in SE.
Conclusions:
To the best of our knowledge this is the first time such a mapping study is done. We believe that SE practitioners might benefit from such a work, as it both provides an overview of the work and people involved in the application of causal inference methods, but also outlines the potential and limitations of such approaches.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The study on the application of Pearl's graphical framework in software engineering could have a moderate impact on enhancing causal inference methods in early-stage startups.
https://www.sciencedirect.com/science/article/pii/S0950584923000757,"A survey on smart contract vulnerabilities: Data sources, detection and repair",Hanting=Chu: htchu@hhu.edu.cn; Pengcheng=Zhang: pchzhang@hhu.edu.cn; Hai=Dong: hai.dong@rmit.edu.au; Yan=Xiao: dcsxan@nus.edu.sg; Shunhui=Ji: shunhuiji@hhu.edu.cn; Wenrui=Li: wenrui_li@163.com,"Abstract
Smart contracts
 contain many built-in security features, such as non-immutability once being deployed and non-involvement of third parties for contract execution. These features reduce security risks and enhance users’ trust towards smart contracts. However, smart contract security issues still persist, resulting in huge financial losses. Contract publishers cannot fully cover contract vulnerabilities through contract version updating. These security issues affect further development of 
blockchain technologies
. So far, there are many related studies focusing on smart contract security issues and tend to discuss from a particular perspective (e.g., 
development cycle
, vulnerability attack methods, security detection tools, etc.). However, smart contract security is a complicated issue that needs to be explored from a multi-dimensional perspective. In this paper, we explore smart contract security from the perspectives of vulnerability data sources, 
vulnerability detection
, and vulnerability defense. We first analyze the existing security issues and challenges of smart contracts, investigate the existing vulnerability classification frameworks and common 
security vulnerabilities
, followed by reviewing the existing contract 
vulnerability injection
, detection, and repair methods. We then analyze the performance of existing security methods. Next, we summarize the current status of smart contract security-related research. Finally, we summarize the state of the art and future trends of smart contract security-related research. This paper aims to provide 
systematic knowledge
 and references to this research field.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,Exploring smart contract security from multiple perspectives can provide valuable insights for European early-stage ventures working on blockchain technologies.
https://www.sciencedirect.com/science/article/pii/S0950584923000538,Git command recommendations using crowd-sourced knowledge,Haitao=Jia: sz2116123@nuaa.edu.cn; Wenhua=Yang: ywh@nuaa.edu.cn; Chaochao=Shen: ccshen@nuaa.edu.cn; Minxue=Pan: mxp@nju.edu.cn; Yu=Zhou: zhouyu@nuaa.edu.cn,"Abstract
Context:
Git is a fast, scalable, distributed version control system with a rich command set that provides high-level operations and full access to the internals. It has been widely used by millions of developers worldwide. However, due to the flexibility of the usage of Git commands and the scarcity of Git documentation, many developers have experienced difficulties when using Git commands.
Objective:
This paper aims to propose an automatic approach to recommending Git commands for developers given a query described by natural language.
Method:
Our approach makes recommendations by mining the crowd-sourced knowledge related to Git on Stack Overflow. It first constructs a keyword-command mapping database from Git-related posts, then analyzes the similarity between the query given by the developer and the keywords in the database to retrieve the candidate commands, and proposes an algorithm to rank the candidate commands.
Results:
Our approach’s recommendation results significantly outperform the baseline approaches in several metrics (e.g., Top-K accuracy). Meanwhile, the experimental results have shown that the favorable efficiency of our approach can promise its use by developers in real-world scenarios.
Conclusion:
The Git command recommendation approach proposed in this paper is effective and can be helpful for developers to use Git commands for more efficient development.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The automatic approach to recommending Git commands can significantly benefit developers, including those in early-stage ventures, improving efficiency in development processes."
https://www.sciencedirect.com/science/article/pii/S0950584923000502,Studying the challenges of developing hardware description language programs,Foutse=Khomh: foutse.khomh@polymtl.ca; Heng=Li: heng.li@polymtl.ca; Fatemeh=Yousefifeshki: fatemeh.yousefifeshki@polymtl.ca,"Abstract
Context:
Developing domain specific architectures (e.g., Google’s TPU) typically requires writing programs in 
Hardware Description Languages
 (HDLs). Compared to traditional general-purpose programming languages (GPPLs) (e.g., C++, Java, Python), developing programs in HDLs (e.g., VHDL or Verilog) lacks support from our community. Such an imbalance in the support for GPPLs and HDLs will impede future advances in 
computer systems
.
Objective:
We believe that our 
software engineering
 community should pay more attention to supporting HDL development. Thus, we make an initial attempt in this direction to study the challenges of developing programs in HDLs by mining HDL-related questions in technical forums.
Method:
We identified 16,700 HDL-related questions in two Stack Exchange forums: Stack Overflow (SO) and Electrical Engineering (EE) Stack Exchange. Through qualitative analysis, 
topic modeling
, and quantitative analysis, we examined the types of questions, the questions’ topics, and identified the most challenging topics for developers.
Results:
We identified ten types of HDL-related questions, including seven types identified in prior work and three new types more relevant to HDLs (e.g., questions related to code explanation and tool search). We also observed that most of the challenges facing HDL developers are similar to those facing GPPL developers, while some challenges (e.g., lower-level operations such as bit and register operations) are more specific to HDLs. Finally, we observed that HDL-related questions are less likely and take a longer time to get accepted answers than GPPL-related questions, and identified the most challenging topics of questions (e.g., file/memory I/O).
Conclusion:
Our work identified opportunities for different stakeholders in the software and hardware communities to improve the practices of developing 
HDL programs
: 
software engineering
 researchers may leverage their expertise to help in advancing HDL languages and methodology, such as to improving the language abstractions for low-level operations such as bit/register operations or memory/file I/Os; Stack Exchange and its moderators may leverage the community size and expertise in both the SO and EE forums to collectively recommend experts to answer questions related to HDLs; HDL language and library developers may provide more actionable error messages, better documentation and logging support to help HDL developers address their encountered issues; tool developers are encouraged to provide advanced IDEs and testing frameworks to help HDL developers improve their development and testing productivity.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"Studying the challenges of developing programs in HDLs may offer insights, but the practical impact on European early-stage ventures may be limited due to the niche nature of the topic."
https://www.sciencedirect.com/science/article/pii/S0950584923000551,An initial theory to understand and manage requirements engineering debt in practice,Julian=Frattini: julian.frattini@bth.se,"Abstract
Context:
Advances in technical debt research demonstrate the benefits of applying the financial debt metaphor to support decision-making in software development activities. Although decision-making during 
requirements engineering
 has significant consequences, the debt metaphor in requirements engineering is inadequately explored.
Objective:
We aim to conceptualize how the debt metaphor applies to requirements engineering by organizing concepts related to practitioners’ understanding and managing of requirements engineering debt (RED).
Method:
We conducted two in-depth expert interviews to identify key requirements engineering debt concepts and construct a survey instrument. We surveyed 69 practitioners worldwide regarding their perception of the concepts and developed an initial analytical theory.
Results:
We propose a RED theory that aligns key concepts from technical debt research but emphasizes the specific nature of requirements engineering. In particular, the theory consists of 23 falsifiable propositions derived from the literature, the interviews, and survey results.
Conclusions:
The concepts of requirements engineering debt are perceived to be similar to their technical debt counterpart. Nevertheless, measuring and tracking requirements engineering debt are immature in practice. Our proposed theory serves as the first guide toward further research in this area.",July 2023,"Requirements engineering, Requirements engineering debt, Interview study, Online survey, Theory",Information and Software Technology,2025-03-18T00:00:00,6.0,"The exploration of requirements engineering debt concepts can be beneficial for startups in managing software development activities, but the practical implementation may require further research and development."
https://www.sciencedirect.com/science/article/pii/S0950584923000691,Characteristics and generative mechanisms of software development productivity distributions,Magne=Jørgensen: magnej@simula.no,"Abstract
Context
There is considerable variation in the productivity of software developers. Better knowledge about this variation may provide valuable inputs for the design of skill tests and recruitment processes.
Objective
This paper aims to identify properties of software development productivity distributions and gain insight into mechanisms that potentially explain these productivity differences.
Method
Four data sets that contain the results of software developers solving the same programming tasks were collected. The properties of the productivity distributions were analyzed, the fits of different types of distributions to the productivity data were compared, and potential generative mechanisms that would lead to the types of distributions with the best fit to the productivity data were evaluated.
Results
The coefficient of variance of the productivity of the software developers was, on average, 0.55, with the top 50% of developers having average productivity that was 2.44 times higher than the bottom 50% of developers. All productivity samples were right-skewed, with an average skew of 1.79. About 30% of the observed productivity variance was explained by non-systematic, i.e., within-developer, variance. The distributions with the best fit to the empirical productivity data were the lognormal and power-law-with-an-exponential-cutoff distributions. The analysis of the mechanisms leading to productivity differences found no support for the ""rich-getting-richer"" explanation proposed for other disciplines. Instead, it suggests a constant productivity difference with increasing experience.
Conclusion
The substantial difference in productivity among software developers solving programming tasks indicates that a thorough evaluation of skill in the recruitment process can be rewarding. In particular, the long 
tail
 towards higher productivity values demonstrates the large gains that can be achieved by detecting and recruiting developers with very high productivity. More research is needed to understand the mechanisms leading to the large productivity differences.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"This abstract provides insights into the productivity variations among software developers, which can be valuable for early-stage ventures in optimizing recruitment processes. The potential gains from detecting and recruiting highly productive developers demonstrate practical value for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000721,Dev2vec: Representing domain expertise of developers in an embedding space,Arghavan Moradi=Dakhel: arghavan.moradi-dakhel@polymtl.ca; Foutse=Khomh: foutse.khomh@polymtl.ca; Michel C.=Desmarais: michel.desmarais@polymtl.ca,"Abstract
Context:
Accurate assessment of the domain expertise of developers is essential for assigning the proper candidate to contribute to a project, or to attend a job role. Since the potential candidate can come from a large pool, the automated assessment of this domain expertise is a desirable goal. While previous methods have had some success within a single software project, the assessment of a developer’s domain expertise from contributions across multiple projects is more challenging.
Objective:
In this paper, we employ 
doc2vec
 to represent the domain expertise of developers across multiple projects as embedding vectors, and assess expertise level from authored code fragments.
Method:
For this purpose, we derived embedding vectors from different sources that contain evidence of developers’ expertise, such as the description of repositories they contributed, their issue resolving history, and API calls in their commits. We name it dev2vec and demonstrate its effectiveness in representing and assessing the technical specialization of developers.
Results:
Our results indicate that encoding the expertise of developers in an embedding vector outperforms state-of-the-art methods and improves the F1-score up to 21%. Moreover, our findings suggest that the “issue resolving history” of developers is the most informative source of information to represent the domain expertise of developers in embedding spaces.
Conclusion:
Our proposed approach sheds light on the effectiveness of representing the technical expertise of developers in embedding vectors, and it can act as initial filtering for recruiters and project managers.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Automated assessment of domain expertise in developers across multiple projects can significantly benefit startups in assigning suitable candidates to projects. The proposed dev2vec method shows promising results in assessing technical specialization, which can be valuable for recruiters and project managers."
https://www.sciencedirect.com/science/article/pii/S0950584923000678,Effuzz: Efficient fuzzing by directed search for smart contracts,Jian=Dong: dan@hit.edu.cn,"Abstract
Context:
A large number of 
Ethereum
 
smart contracts
 have been deployed on 
blockchain
 to manage assets. Unfortunately, due to the immutable nature of 
blockchain
, 
smart contracts
 cannot be modified after deployment, even if vulnerabilities have been exposed to attackers. Therefore, it is critical to efficiently and thoroughly test smart contracts. Greybox fuzzing is a prosperous technique for detecting smart contract vulnerabilities. However, most existing 
fuzzers
 have a common drawback in that they cannot efficiently satisfy hard-to-cover branch constraints.
Objective:
The goal of this paper is to solve the problem of how to efficiently satisfy hard-to-cover branch constraints. After solving this problem, 
fuzz testing
 can execute more code, and there is a higher probability of executing vulnerabilities.
Method:
We propose an approach for addressing this problem. Specifically, we design an input parameter analysis strategy to selectively mutate a subset of input parameters to reduce invalid mutations. Also, to accelerate the processing of satisfying branch constraints, we design an accelerated multi-objective search strategy to reduce the waste of resources.
Result:
We implemented this approach in a tool called Effuzz and applied it to real-world smart contracts. Experiments show that Effuzz finds more vulnerabilities and is more efficient than existing state-of-the-art 
fuzzers
.
Conclusion:
In this paper, we present an approach to efficiently satisfy hard-to-cover branch constraints. Our approach addresses two main problems, i.e., how to select the subset of input parameters for mutation with considering the characteristic of 
Ethereum
 smart contracts, and how to accelerate the search to satisfy hard-to-cover branch constraints without generating excessive ineffective test cases that waste resources. The experimental results show that our approach is effective.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"Efficiently testing smart contracts is crucial for startups utilizing blockchain technology. The Effuzz tool presented in this abstract offers a solution to efficiently satisfy hard-to-cover branch constraints, leading to the discovery of more vulnerabilities. This has high practical value for early-stage ventures utilizing smart contracts."
https://www.sciencedirect.com/science/article/pii/S095058492300068X,Predicting neural network confidence using high-level feature distance,Jie=Wang: wang_jie@buaa.edu.cn; Jun=Ai: aijun@buaa.edu.cn; Minyan=Lu: lmy@buaa.edu.cn; Jingyu=Liu: liujingyu1@buaa.edu.cn; Zili=Wu: wuzili@buaa.edu.cn,"Abstract
Context:
Neural networks
 have achieved state-of-the-art performance in many fields. However, they are often reported to produce overconfident predictions, especially for 
misclassifications
. Therefore, confidence prediction is vitally important in practical applications to enable models to provide reasonable confidence.
Objective:
The objective of this paper is to address the problem of overconfidence in neural networks. This is achieved by constructing a detector that can predict the probability of incorrect output of the neural network. The goal of the detector is to identify incorrect outputs and adjust their raw confidences to reduce the overconfidence of misclassification.
Method:
The idea of the detector is to learn the relationship between high-level features of inputs and their classification correctness. The high-level feature is the output of the deep hidden layer in the network, and for the 
CNNs
, we chose the last 
convolutional layer
. The training of the detector requires a hold-out validation set, which in practice can be the same set used for hyperparameter tuning. The detector predicts which inputs are likely to be misclassified by neural networks and estimates the probability of misclassification which is then used to adjust the raw softmax confidence, thereby reducing the confidence of misclassification. The detector is learned by deeply mining the 
classification results
 of the validation data produced during the training process of the neural network, no additional data such as disturbance samples needs to be collected.
Results:
Experimental results on the CIFAR-10 dataset and two typical 
neural network structures
, ResNet20 and VGG16, show that our method is effective in reducing the confidence of 
misclassifications
 and maintaining the confidence of correct classifications. The effectiveness of our method is demonstrated on the non-disturbance i.i.d test set and three types of disturbance sets. It outperforms two 
baseline methods
 on all test sets, especially for the i.i.d set, on the misclassification identification task.
Conclusion:
This new method is proven to perform well on both misclassification identification and out-of-distribution detection tasks. In contrast to previous softmax 
calibration methods
 that aim to decrease the confidence of all classifications, the method proposed in this paper innovatively reduces the confidence of misclassification straightforwardly. As a result, it becomes feasible to visually interpret the correctness of classifications using confidence scores. This will lead to a better understanding of the model’s behavior and facilitate more reliable decision-making. Overall, our proposed confidence prediction method represents a promising step towards addressing the overconfidence problem in 
classification tasks
 in 
deep learning
, especially 
image classification
, and is of great value for real-world 
deep learning
 applications.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Addressing the issue of overconfidence in neural networks is crucial for practical applications, including startups utilizing deep learning for image classification. The proposed method in this abstract shows effectiveness in reducing misclassification confidence, which can aid startups in making more reliable decisions based on model behavior."
https://www.sciencedirect.com/science/article/pii/S095058492300054X,Continuous deployment in software-intensive system-of-systems,Helena Holmström=Olsson: helena.holmstrom.olsson@mau.se; Anas=Dakkak: anas.dakkak@ericsson.com; Jan=Bosch: jan.bosch@chalmers.se; David=Issa Mattos: david.mattos@volvocars.com,"Abstract
Context:
While continuous deployment is popular among web-based software development organizations, adopting continuous deployment in software-intensive system-of-systems is more challenging. On top of the challenges arising from deploying software to a single software-intensive embedded system, software-intensive system-of-systems (SiSoS) add a layer of complexity as new software undergoes an extensive field validation applied to individual components of the SiSoS, as well as the overall SiSoS, to ensure that both legacy and new functionalities are working as desired.
Objectives:
This paper aims to study how SiSoS transitions to continuous deployment by exploring how continuous deployment impacts field testing and validation activities, how continuous deployment can be practiced in SiSoS, and to identify the 
success factors
 that companies need to consider when transitioning to continuous deployment.
Method:
We conducted a 
case study
 at Ericsson AB focusing on the 
embedded software
 of the Third Generation 
Radio Access Network
 (3G RAN). The 3G RAN consists of two large-scale software-intensive embedded systems, representing a simple SiSoS composed of two systems. 3G RAN software was the first to transition to continuous deployment and is used as a reference case for other products within Ericsson AB.
Results:
Software deployment, in addition to field testing and validation, have transitioned from being a discrete activity performed at the end of software development to a continuous process performed in parallel to software development. Further, our study reveals an orchestrating approach for software deployment, which allows pre/post validation of legacy behavior and new features in a shorter release and deployment cadence. Furthermore, we identified the essential 
success factors
 that organizations should consider when transitioning to continuous deployment.
Conclusion:
Transition to continuous deployment, in addition to field testing and validation, shall be considered and planned carefully. In this paper, we provide a set of success factors and orchestration technique that helps organization when transitioning to continuous deployment in the software-intensive embedded system-of-systems context.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract provides valuable insights into transitioning to continuous deployment in software-intensive systems-of-systems, offering essential success factors for companies. The practical implications for startups in Europe are significant."
https://www.sciencedirect.com/science/article/pii/S0950584923000514,Transparency and explainability of AI systems: From ethical guidelines to requirements,Nagadivya=Balasubramaniam: nagadivya.balasubramaniam@aalto.fi; Marjo=Kauppinen: marjo.kauppinen@aalto.fi; Antti=Rannisto: antti.rannisto@aalto.fi; Kari=Hiekkanen: kari.hiekkanen@aalto.fi; Sari=Kujala: sari.kujala@aalto.fi,"Abstract
Context and Motivation
Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few 
case studies
 that describe the current state of defining these quality requirements in practice.
Objective
This study consisted of two phases. The first goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and 
explainable AI
 systems and then we investigated how explainability requirements can be defined in practice.
Methods
In the first phase, we analyzed the ethical guidelines in 16 organizations representing different industries and public sector. Then, we conducted an empirical study to evaluate the results of the first phase with practitioners.
Results
The analysis of the ethical guidelines revealed that the importance of transparency is highlighted by almost all of the organizations and explainability is considered as an integral part of transparency. To support the definition of explainability requirements, we propose a model of explainability components for identifying explainability needs and a template for representing explainability requirements. The paper also describes the lessons we learned from applying the model and the template in practice.
Contribution
For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a systematic and structured way to define explainability requirements of AI systems. Furthermore, the results emphasize a set of good practices that help to define the explainability of AI systems.",July 2023,"Transparency, Explainability, Ethical guidelines, Quality requirements, Explainability requirements, AI systems",Information and Software Technology,2025-03-18T00:00:00,6.0,"While transparency and explainability in AI systems are important, this abstract focuses more on guidelines and models rather than practical implementations. It provides valuable insights for researchers but may have limited direct impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000563,Zero-shot learning for requirements classification: An exploratory study,Alessio=Ferrari: alessio.ferrari@isti.cnr.it; Liping=Zhao: liping.zhao@manchester.ac.uk,"Abstract
Context:
Requirements engineering
 (RE) researchers have been experimenting with 
machine learning
 (ML) and 
deep learning
 (DL) approaches for a range of RE tasks, such as requirements classification, requirements tracing, ambiguity detection, and modelling. However, most of today’s ML/DL approaches are based on 
supervised
 learning techniques, meaning that they need to be trained using a large amount of task-specific labelled 
training data
. This constraint poses an enormous challenge to RE researchers, as the lack of labelled data makes it difficult for them to fully exploit the benefit of advanced ML/DL technologies.
Objective:
This paper addresses this problem by showing how a 
zero-shot learning
 (ZSL) approach can be used for requirements classification without using any labelled training data. We focus on the 
classification task
 because many RE tasks can be framed as classification problems.
Methods:
The ZSL approach used in our study employs contextual word-embeddings and transformer-based 
language models
 (LMs). We demonstrate this approach through a series of experiments to perform three classification tasks: (1) FR/NFR — classification functional requirements vs non-functional requirements; (2) 
NFR
 — identification of NFR classes; (3) Security — classification of security vs non-security requirements.
Results:
The study shows that the ZSL approach achieves an F1 score of 0.66 for the FR/NFR task. For the NFR task, the approach yields F1
∼
0
.
72
−
0
.
80
, considering the most frequent classes. For the Security task, F1 
∼
0
.
66
. All of the aforementioned F1 scores are achieved with zero-training efforts.
Conclusion:
This study demonstrates the potential of ZSL for requirements classification. An important implication is that it is possible to have very little or no training data to perform classification tasks. The proposed approach thus contributes to the solution of the long-standing problem of data shortage in RE.",July 2023,"0000, 1111",Information and Software Technology,2025-03-18T00:00:00,9.0,"This abstract introduces a novel approach using zero-shot learning for requirements classification without labeled training data, addressing a significant challenge for RE researchers. The practical implications of this approach can greatly benefit early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584923000575,Enhanced abbreviation–expansion pair detection for glossary term extraction,Hussein=Hasso: hussein.hasso@fkie.fraunhofer.de; Katharina=Großer: grosser@uni-koblenz.de; Iliass=Aymaz: iliass.aymaz@fkie.fraunhofer.de; Hanna=Geppert: hanna.geppert@fkie.fraunhofer.de; Jan=Jürjens: juerjens@uni-koblenz.de,"Abstract
Context:
Providing precise definitions of all project specific terms is a crucial task in 
requirements engineering
. In order to support the glossary building process, many previous tools rely on the assumption that the requirements set has a certain level of quality. Yet, the parallel detection and correction of quality weaknesses in the context of glossary terms is beneficial to requirements definition.
Objective:
In this paper, we focus on detection of uncontrolled usage of abbreviations by identification of abbreviation–expansion pair (AEP) candidates.
Methods:
We compare our feature-based approach (ILLOD+) to other similarity measures to detect AEPs and propose how to extend the glossary term extraction (GTE) and synonym clustering with AEP-specific methods.
Results:
It shows that feature-based methods are more accurate for AEPs than 
syntactic
 and 
semantic similarity measures
. Experiments with PURE data-sets extended with uncontrolled abbreviations show that ILLOD+ is able to extract abbreviations as well as match their expansions viably in a real-world setting and is well suited to augment previous synonym clusters with clusters that combine AEP candidates. AEP clusters generated with ILLOD+ are generally smaller than those based on 
syntactic
 or 
semantic similarity measures
 and have a higher recall.
Conclusion:
In this paper, we present ILLOD+, an extended feature-based approach to AEP detection and propose a workflow for its integration to clustering of glossary term candidates to enhance term consolidation in evolving requirements.",July 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract presents an approach for detecting uncontrolled abbreviations in requirements engineering, providing a valuable method for enhancing glossary building processes. While beneficial, the direct impact on startups may be more limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000290,Application of Deep Learning in Software Defect Prediction: Systematic Literature Review and Meta-analysis,Zuhaira Muhammad=Zain: zmzain@pnu.edu.sa,"Abstract
Context
Despite recent attention given to Software 
Defect Prediction
 (SDP), the lack of any systematic effort to assess existing empirical evidence on the application of 
Deep Learning
 (DL) in SDP indicates that it is still relatively under-researched.
Objective
To synthesize literature on SDP using DL, pertaining to measurements, models, techniques, datasets, and achievements; to obtain a full understanding of current SDP-related methodologies using DL; and to compare the DL models’ performances with those of 
Machine Learning
 (ML) models in classifying software defects.
Method
We completed a thorough review of the literature in this domain. To answer the research issues, results from primary investigations were synthesized. The preliminary findings for DL vs. ML in SDP were verified by using meta-analysis (MA).
Result
We discovered 63 primary studies that passed the systematic literature review quality evaluation. However, only 19 primary studies passed the MA quality evaluation. The five most popular performance measurements employed in SDP were f-measure, recall, accuracy, precision, and Area Under the Curve (AUC). The top five 
DL techniques
 used in building SDP models were 
Convolutional Neural Network
 (CNN), 
Deep Neural Network
 (DNN), Long Short-Term Memory (LSTM), 
Deep Belief Network
 (DBN), and Stacked 
Denoising
 
Autoencoder
 (SDAE). PROMISE and NASA datasets were found to be used more frequently to train and test 
DL models
 in SDP. The MA results show that DL was favored over ML in terms of study and dataset across accuracy, f-measure, and AUC.
Conclusion
The application of DL in SDP remains a challenge, but it has the potential to achieve better 
predictive performance
 when the performance-influencing parameters are optimized. We provide a 
reference point
 for future research which could be used to improve research quality in this domain.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The abstract presents valuable insights on the application of Deep Learning in Software Defect Prediction which can potentially benefit early-stage ventures in the tech industry.
https://www.sciencedirect.com/science/article/pii/S0950584923000307,Requirements engineering for artificial intelligence systems: A systematic mapping study,John=Grundy: john.grundy@monash.edu; Chetan=Arora: chetan.arora@monash.edu; Khlood=Ahmad: ahmadkhl@deakin.edu.au; Mohamed=Abdelrazek: mohamed.abdelrazek@deakin.edu.au; Muneera=Bano: muneera.bano@csiro.au,"Abstract
Context:
In traditional software systems, 
Requirements Engineering
 (RE) activities are well-established and researched. However, building 
Artificial Intelligence
 (AI) based software with limited or no insight into the system’s inner workings poses significant new challenges to RE. Existing literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI).
Objective:
This paper investigates current approaches for specifying requirements for AI systems, identifies available frameworks, methodologies, tools, and techniques used to model requirements, and finds existing challenges and limitations.
Method:
We performed a 
systematic mapping study
 to find papers on current RE4AI approaches. We identified 43 primary studies and analyzed the existing methodologies, models, tools, and techniques used to specify and model requirements in real-world scenarios.
Results:
We found several challenges and limitations of existing RE4AI practices. The findings highlighted that current 
RE applications
 were not adequately adaptable for building AI systems and emphasized the need to provide new techniques and tools to support RE4AI.
Conclusion:
Our results showed that most of the empirical studies on RE4AI focused on autonomous, self-driving vehicles and managing data requirements, and areas such as ethics, trust, and explainability need further research.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the abstract addresses challenges in Requirements Engineering for AI systems, the practical implications for early-stage ventures may be limited compared to the abstracts focusing on software defect prediction."
https://www.sciencedirect.com/science/article/pii/S095058492300023X,Just-in-time code duplicates extraction,Yaroslav=Golubev: yaroslav.golubev@jetbrains.com; Timofey=Bryksin: timofey.bryksin@jetbrains.com; Eman Abdullah=AlOmar: ealomar@stevens.edu; Anton=Ivanov: apivanov_1@edu.hse.ru; Zarina=Kurbatova: zarina.kurbatova@jetbrains.com; Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Le=Nguyen: ln8378@rit.edu; Amit=Kini: ak3328@rit.edu; Aditya=Thakur: at4415@rit.edu,"Abstract
Context:
Refactoring is a critical task in software maintenance, and is usually performed to enforce better design and coding practices, while coping with design defects. The 
Extract Method
 refactoring is widely used for merging duplicate code fragments into a single new method. Several studies attempted to recommend 
Extract Method
 refactoring opportunities using different techniques, including program slicing, program 
dependency graph
 analysis, change history analysis, 
structural similarity
, and feature extraction. However, irrespective of the method, most of the existing approaches interfere with the developer’s workflow: they require the developer to stop coding and analyze the suggested opportunities, and also consider all refactoring suggestions in the entire project without focusing on the development context.
Objective:
To increase the adoption of the 
Extract Method
 refactoring, in this paper, we aim to investigate the effectiveness of 
machine learning
 and 
deep learning algorithms
 for its recommendation while maintaining the workflow of the developer.
Method:
The proposed approach relies on mining prior applied 
Extract Method
 refactorings and extracting their features to train a deep learning classifier that detects them in the user’s code. We implemented our approach as a plugin for IntelliJ IDEA called 
AntiCopyPaster
. To develop our approach, we trained and evaluated various popular models on a dataset of 18,942 code fragments from 13 Open Source Apache projects.
Results:
The results show that the best model is the 
Convolutional Neural Network
 (CNN), which recommends appropriate 
Extract Method
 refactorings with an F-measure of 0.82. We also conducted a qualitative study with 72 developers to evaluate the usefulness of the developed plugin.
Conclusion:
The results show that developers tend to appreciate the idea of the approach and are satisfied with various aspects of the plugin’s operation.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract offers a concrete approach using machine learning and deep learning for recommending code refactoring, which could have a direct impact on the productivity and efficiency of European early-stage software development startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000241,An investigation of causes and effects of trust in Boundary Artefacts,Raquel=Ouriques: raquel.ouriques@bth.se,"Abstract
Context:
Boundary Artefacts (BAs) support software development activities in many aspects because it carries lots of information in the same object that can be used and interpreted by several social groups within an organisation. When the BAs are inconsistent regarding their content, such as many meanings or lack of contextual information, their efficiency is reduced because stakeholders will not trust them.
Objective:
This study aimed to understand the implications of differences in the perception of trust on software projects and their influence on stakeholders’ behaviour.
Methods:
We conducted an exploratory 
case study
 to observe the creation and utilisation of one specific BA and the implications of differences in trust and their influence on stakeholders’ behaviour.
Results
: Our investigation has shown that practitioners adding and adjusting existing content do not entirely understand the stakeholders’ needs. Together with the partial management of the content, trust is impacted. When the content of BAs does not meet the trust factors, specifically reliability and predictability, the stakeholders cannot execute their tasks appropriately, and several implications affect the software development project. Additionally, they create workarounds to supply their needs.
Conclusion:
The differences in trust in BAs affect software projects in different areas of the organisation and interfere with the task execution of various stakeholders. The decrease in trust results from inconsistencies in the content associated with the lack of management of the BA. A structured strategy for representing and managing a BA’s content seems appropriate to increase trust levels and efficiency.",June 2023,"Software development, Boundary Artefact, Trust, Trusting beliefs",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study addresses a critical issue in software development affecting trust levels and efficiency, which can have a significant impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000174,It’s about time: How to study intertemporal choice in systems design,Apostolos=Ampatzoglou: a.ampatzoglou@uom.edu.gr; Alexander=Chatzigeorgiou: achat@uom.edu.gr; Fabian=Fagerholm: fabian.fagerholm@aalto.fi; Andres=De los Ríos: andres.dlr94@gmail.com; Carol=Cárdenas Castro: carolcardenasc@gmail.com; Jenny=Gil: gil.j.jenny@gmail.com; Christoph=Becker: christoph.becker@utoronto.ca,"Abstract
Context:
Decision making
 pervades software and systems engineering. 
Intertemporal
 decisions involve trade-offs among outcomes at different points in time. They play a central role in systems design, as recognised since the inception of the 
software engineering
 (SE) field. They are also crucial for the sustainability of design decisions. However, temporal decision making is not adequately understood in SE. The field of Judgement and Decision Making (JDM) offers important empirical findings and research methods that could be utilised.
Objective:
This article establishes a baseline for studying how software professionals handle intertemporal choices. It examines how temporal distance affects choices in an example scenario, explores in what areas of software development such decisions can be found, and examines how systems design decisions can be characterised and studied as intertemporal.
Method:
We developed a method to study intertemporal choice in SE, based on an initial set of psychological 
theory grounded
 in JDM. We instantiated the method in a study to elicit responses to an intertemporal choice task followed by a 
Cognitive Task Analysis
 (CTA) interview.
Results:
We found that study participants overall tended to discount future outcomes, but individual participants varied wildly in how they valued present vs. future outcomes. They indicated several locations in which intertemporal choices occur in everyday software development. Based on these findings, and by reconciling our initial theory with existing JDM theory and results, we further developed and refined our theory and study method into a framework for studying intertemporal decision making in SE.
Conclusions:
To obtain a basis for more sustainable software systems design decisions, SE research should adopt a more comprehensive, detailed, and empirically consistent way of understanding and studying intertemporal choices. We provide suggestions for how future research could achieve practical methods that address essential characteristics of real-life systems design decisions.",June 2023,"Intertemporal choice, Temporal discounting, Judgement and decision making, Naturalistic decision making, Cognitive task analysis, Psychology, Human factors",Information and Software Technology,2025-03-18T00:00:00,6.0,"The research on intertemporal decision making in software engineering can provide valuable insights, but may have a slightly lower practical impact compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000253,Microservice extraction using graph deep clustering based on dual view fusion,Jing=Li: lijing@nuaa.edu.cn,"Abstract
Context:
With the increasing scale of software, traditional 
monolithic architecture
 applications are challenging to maintain and scale on cloud platforms. Many companies increasingly adopt 
microservices architecture
 as a more flexible choice.
Objective:
However, 
microservice
 migration is still challenging due to the lack of higher-quality 
microservice
 extraction methods. Traditional microservice extraction methods cannot effectively combine the structural dependency and business functions of 
monolithic applications
; thus, their performance warrants improvement.
Method:
This paper proposes a graph deep 
clustering method
 based on dual view fusion (GDC-DVF) for microservice extraction. GDC-DVF constructs a graph of invocation relationships between classes, which is the structural dependency view, using the runtime trace data of a monolithic application. Then the business function view is constructed by the 
random walk
 algorithm and uniform random sampling using the structural dependency view. Next, the fused node feature embedding representations of the two views are learned using a graph encoder based on a graph attention adaptive 
residual network
. Clustering is performed on the fused feature embedding representations to obtain microservice extraction proposals.
Results:
GDC-DVF is tested on four open-source 
monolithic applications
 and achieves better performance compared with comparison methods.
Conclusion:
Experimental results show that GDC-DVF can extract high-quality microservice collections and validate the effectiveness and scalability of the 
graph neural network
 (GNN) for microservice extraction problems.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed GDC-DVF method for microservice extraction addresses a current challenge in software architecture, offering a valuable solution for startups seeking to migrate to microservices."
https://www.sciencedirect.com/science/article/pii/S0950584923000319,Maintainability enhancement based on uncertain model transformations,Youness=Laghouaouta: laghouaouta@inpt.ac.ma; Pierre=Laforcade: pierre.laforcade@univ-lemans.fr,"Abstract
Context:
Managing uncertainty while expressing model transformations is problematic. Indeed, we are constrained to express various transformation specifications implementing the different possibilities. These possibilities are driven by the need to realize the relevance of each scenario to choose the best one (uncertainty on a transformation scenario) or result from the need to propose other alternatives to a given scenario if it is not feasible (uncertainty on the feasibility of a transformation scenario). In both cases, we face 
maintainability
 issues related to handling separated and frequently changed transformation specifications.
Objective:
This paper gives a global overview of our approach to deal with uncertainty in model transformations while focusing on 
maintainability
 aspect.
Methods:
We have proposed a new approach for dealing with uncertainty in model transformations. Basically, our approach makes use of partiality to allow expressing a transformation specification that covers different possibilities. The current paper focuses on the impact of our proposal to enhance changeability. This has been demonstrated by carrying out 
comparative experiments
 involving three other transformation techniques while considering the effort required to implement a change.
Results:
Our experiments show that our approach has proven useful and effective for implementing changes, mainly for complex ones.
Conclusion:
This paper provides an overview of our approach for managing uncertainty within model transformations. Mainly, it focuses on the impact of our proposal to enhance changeability. The experiment results reveal that our proposal allows expressing highly changeable specifications.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The approach for managing uncertainty in model transformations, focusing on maintainability, can be highly beneficial for early-stage ventures facing complex transformation scenarios."
https://www.sciencedirect.com/science/article/pii/S095058492300040X,Towards an understanding of reliability of software-intensive systems-of-systems,Francisco Henrique Cerdeira=Ferreira: francisco.ferreira@uniriotec.br,"Abstract
Context:
Large-scale software-intensive Systems-of-Systems (SoS) have become present in several critical domains and have sometimes depended on diverse trending technologies, such as 
cloud computing
 and 
machine learning
. At the same time, the 
SoS dynamic
 architecture makes it difficult to assure SoS reliability leading to diverse studies with specific solutions, while the need for a shared view of what precisely SoS reliability refers to still exists.
Objective:
The main contribution of this article is to go towards an understanding of SoS reliability. We present a conceptual model whose concepts as well as their definitions and relationships were defined by systematically examining the literature of the field.
Methods:
We surveyed 36 practitioners and researchers regarding ambiguity, 
explanatory power
, parsimony, generality, and utility of our model. Next, we adjusted our model according to their contribution.
Results:
We reach a conceptual model containing 29 concepts and their relationships that help to comprehend SoS reliability. In addition, we provided a glossary with a definition of each concept of our conceptual model. We also proposed a SoS reliability definition grounded on the literature.
Conclusions:
By organizing the knowledge of SoS reliability, this conceptual model makes it possible to expand the body of knowledge in the area and opens several opportunities for further investigations; in particular, this model serves as a basis for novel solutions aiming to assure SoS reliability.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The conceptual model presented in this abstract can help expand the knowledge in the area of SoS reliability, providing opportunities for further investigations and solutions for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000423,Describing the APIs comprehensively: Obtaining the holistic representations from multiple modalities data for different tasks,Yuzhou=Liu: liuyuzhou@jlu.edu.cn,"Abstract
Context:
API (Application Programming Interface) is an important object in software development, and describing them properly is the basis for solving related problems, such as API recommendation. Recently, multimodal data fusing approaches become a hot 
research topic
 in different fields, and they can be used to get comprehensive representations of things by describing them from different angles. This provides us with a new useful way for API representation.
Objective:
In this work, we aim at describing APIs comprehensively by fusing information from multimodal data for supporting different API-related tasks.
Method:
To achieve this goal, we propose a novel approach BDBM (Bimodal Deep Boltzmann Machine) to obtain holistic representations of APIs by fusing the information in text and code modalities, which are the API descriptions and the codes of the products. Then, the BDBM is applied to two typical API tasks (API recommendation and similar API mining) to analyze its performance.
Results and Conclusion:
The results show that the API recommendation based on BDBM outperforms the ones based on unimodal 
API information
, our method’s precisions can reach 0.67, 0.65, 0.61 at top-3, top-5 and top-10, while MAP and MRR are 0.66 and 0.67. Meanwhile, the close representations give similar APIs with similar functionalities as well as similar usage in codes. Thus, we believe that 
multimodal data fusion
 is suitable for describing APIs, and the holistic representations given by BDBM can be used in different API-related tasks.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The approach proposed in this abstract for API representation based on multimodal data fusion can have a significant impact on software development, providing new ways to describe APIs and improve performance in related tasks for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000411,Fault-insertion and fault-fixing behavioural patterns in Apache Software Foundation Projects,Marco=Ortu: marco.ortu@unica.it; Giuseppe=Destefanis: giuseppe.destefanis@brunel.ac.uk; Tracy=Hall: tracy.hall@lancaster.ac.uk; David=Bowes: d.h.bowes@lancaster.ac.uk,"Abstract
Background:
Developers inevitably make human errors while coding. These errors can lead to faults in code, some of which may result in system failures. It is important to reduce the faults inserted by developers as well as fix any that slip through.
Aim:
To investigate the fault insertion and fault fixing activities of developers. We identify developers who insert and fix faults, ask whether code topic ‘experts’ insert fewer faults, and experts fix more faults and whether patterns of insertion and fixing change over time.
Methods:
We perform a time-based analysis of developer activity on twelve Apache projects using 
Latent Dirichlet Allocation
 (LDA), 
Network Analysis
 and 
Topic Modelling
. We also build three models (using Petri-net, 
Markov Chain
 and Hawkes Processes) which describe and simulate developers’ bug-introduction and fixing behaviour.
Results:
We show that: the majority of the projects we analysed have developers who dominate in the insertion and fixing of faults; Faults are less likely to be inserted by developers with code topic expertise; Different projects have different patterns of fault inserting and fixing over time.
Conclusions:
We recommend that projects identify the code topic expertise of developers and use expertise information to inform the assignment of project work.",June 2023,"Faults analysis, LDA, Mining software repositories",Information and Software Technology,2025-03-18T00:00:00,5.0,"While the investigation on fault insertion and fixing activities of developers is relevant, the practical value for startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000320,Automated event extraction of CVE descriptions,Lili=Bo: lilibo@yzu.edu.cn; Bin=Li: lb@yzu.edu.cn,"Abstract
Context:
The dramatically increasing number of vulnerabilities makes manual 
vulnerability analysis
 increasingly more difficult. Automatic extraction of 
vulnerability information
 can help improve 
vulnerability analysis
. However, the existing 
vulnerability information
 extraction methods do not extract from the perspective of events, and the existing 
event extraction
 methods do not consider the unique sentence structure characteristics of vulnerability descriptions, which makes it difficult to extract vulnerability information effectively.
Objective:
To extract vulnerability information, we treat each vulnerability as an event, and propose an approach, 
VE-Extractor
, to automatically perform vulnerability 
event extraction
 from textual descriptions in vulnerability reports for vulnerability analysis, including extraction of vulnerability event trigger (cause) and event arguments (e.g., consequence, operation).
Method:
First, we propose a new labeling method BIOFR (Begin, Inside, Outside, Front, Rear) to construct an event-perspective vulnerability data benchmark. Then, we design a question template based on event trigger, to automatically extract vulnerability event arguments through the 
BERT
 Q&A model.
Results:
Experiments show the effectiveness of 
VE-Extractor
 for automatically extracting events from vulnerability description, with significant 
performance improvement
 over state-of-the-art techniques, e.g., F1-score is increased by 45.12% and 21.02% in vulnerability consequence and operation extraction, respectively.
Conclusion:
The proposed 
VE-Extractor
 achieves a higher precision and accuracy than the state-of-the-art methods. Experiments results show that our approach is effective in extracting vulnerability event information and can be used to assist vulnerability analysis, such as vulnerability classification.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The VE-Extractor approach presented in this abstract can greatly benefit vulnerability analysis, providing a more effective way to automatically extract vulnerability information for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000447,Detecting multi-type self-admitted technical debt with generative adversarial network-based neural networks,Jin=Liu: jinliu@whu.edu.cn,"Abstract
Context:
Developers often introduce the self-admitted technical debt (SATD), i.e., a compromised solution to satisfy the delivery of the current goals, in code comments but do not eliminate them timely in the following software development and maintenance process. Automatically identifying the SATDs to reduce potential harm to software has attracted the attention of researchers. However, existing approaches only identified SATDs at a coarse-grained level, which impacts developers to locate and remove them.
Objective:
This paper proposes a novel model named GCF, which is a 
deep learning
 method to enhance the performance of multi-type SATD classification based on 
generative adversarial network
. Method: The GCF model employs the JSD Generative Adversarial Network to solve the imbalance problem, utilizes CodeBERT to fuse information of code snippets and natural language for initializing the instances as embedding vectors, and introduces the feature extraction module to extract the instance features more comprehensively.
Results:
The experimental results show that, the GCF model obtains better performance compared with the state-of-the-art method. Moreover, experiments on the GCF model variants and others with different GAN models show the superiority of the GCF model.
Conclusion:
Our proposed GCF model effectively solves the problem of imbalanced types of SATD, fuses the information of code snippets and natural language, and extracts key features to achieve outstanding performance in detecting multi-type SATD. Therefore, the GCF model is an effective method for detecting multi-type SATD.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The GCF model proposed in this abstract addresses an important issue in software development (identifying self-admitted technical debt) and shows better performance compared to existing methods, which can be valuable for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000496,User story extraction from natural language for requirements elicitation: Identify software-related information from online news,Daniel=Siahaan: daniel@if.its.ac.id,"Abstract
Context
The user story is a popular artifact in 
agile software development
. Extracting user stories is helpful for process improvement in 
requirements elicitation
, closing limitations such as limited access, and uncovering new and unique domains. Most sources of 
requirements elicitation
 are available in natural language form. However, the approach to extracting user stories from natural language is still limited.
Objective
This study aims to extract user stories from natural language. It includes identifying the aspect of who (stakeholder), aspect of what (stakeholder's wants), and aspect of why (the reason why the aspect of what exists).
Method
This study used online news as a 
case study
 because information related to stakeholders and their needs is available. Aspects of who, what, and why are obtained using a rule-based approach using part-of-speech (POS) chunking, 
named entity recognition
 (NER), 
dependency parsing
, WordNet, and BloomSoft.
Result
We found that online news tends to generate requirements with hard-goals or soft-goals types. In identifying aspects of who, we succeeded in increasing the F-score value by combining stakeholder identification methods according to the characteristics of online news. We also found that PUblic REquirements (PURE), domain specificity, and WordNet lexical names can significantly improve the extraction of software-related information in identifying the aspects of what.
Conclusion
This study demonstrates that information related to software requirements could arise from non-software-related artifacts such as online news.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on extracting user stories from natural language has practical value for agile software development, process improvement, and requirements elicitation, which can benefit early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584919301466,Improving defect prediction with deep forest,Xiaobing=Sun: xbsun@yzu.edu.cn,"Abstract
Context
Software defect
 prediction is important to ensure the 
quality of software
. Nowadays, many supervised learning techniques have been applied to identify defective instances (
e.g.
, methods, classes, and modules).
Objective
However, the performance of these supervised learning techniques are still far from satisfactory, and it will be important to design more advanced techniques to improve the performance of 
defect prediction
 models.
Method
We propose a new deep forest model to build the defect prediction model (
DPDF
). This model can identify more important defect features by using a new cascade strategy, which transforms 
random forest classifiers
 into a layer-by-layer structure. This design takes full advantage of 
ensemble learning
 and 
deep learning
.
Results
We evaluate our approach on 25 
open source projects
 from four public datasets (
i.e.
, NASA, PROMISE, AEEEM and Relink). Experimental results show that our approach increases AUC value by 5% compared with the best traditional 
machine learning algorithms
.
Conclusion
The deep strategy in 
DPDF
 is effective for software defect prediction.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The proposed deep forest model for software defect prediction introduces a new innovative technique that shows significant improvement in performance compared to traditional machine learning algorithms. The evaluation on 25 open source projects demonstrates strong practical value.
https://www.sciencedirect.com/science/article/pii/S0950584923000484,An Abstract Syntax Tree based static fuzzing mutation for vulnerability evolution analysis,Wei=Zheng: wzheng@nwpu.edu.cn; Peiran=Deng: dengpeiran@mail.nwpu.edu.cn; Kui=Gui: guikui@mail.nwpu.edu.cn; Xiaoxue=Wu: xiaoxuewu@yzu.edu.cn,"Abstract
Context:
Zero-day vulnerabilities are highly destructive and sudden. However, traditional static and dynamic testing methods cannot efficiently detect them.
Objective:
In this paper, a static fuzzy mutation method for program code is studied. This method can improve the efficiency of mutation sample generation according to the vulnerability evolution law, thus promoting the development of zero-day 
vulnerability detection
 methods based on 
deep learning techniques
.
Method:
A static fuzzy mutation method based on the 
Abstract Syntax Tree
 (AST) is proposed. Under the guidance of software vulnerability evolution law, potential evolution paths that threaten program security are detected, and mutation samples containing vulnerabilities are generated at the syntax tree level based on the paths. To verify the effectiveness of static fuzzy mutation based on ASTs, this paper starts with Concurrent Use After Free (CUAF) homologous vulnerability. It uses multi-threaded programs to perform vulnerability feature statement insertion processing to infer the optimal 
mutation operator
 execution sequence corresponding to CUAF vulnerabilities triggered by data competition. The Linux kernel code is used to verify whether it can effectively reduce the number of invalid mutation samples.
Results:
In this paper, we filter the code fragments in the Linux kernel public code containing CUAF vulnerability fix commits and perform static fuzzy mutation on the fix versions of the vulnerabilities to reproduce the vulnerabilities of this type triggered by these code fragments on the timeline. We compare the process with the execution of the random 
mutation operator
 in traditional detection methods horizontally and improve the efficiency by 42.4% on average.
Conclusion:
The static fuzzy mutation based on the AST is effective in stages. When this method is explored in more vulnerability-type evolution laws, it is expected to promote the development of the zero-day vulnerability active detection technology framework.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The study on static fuzzy mutation for detecting zero-day vulnerabilities using deep learning techniques has high impact potential for improving security measures in software development, making it valuable for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000472,"Introduction to special issue on Agile UX: challenges, successes and barriers to improvement",Eva-Maria=Schön: eva-maria.schoen@hs-emden-leer.de; Tiago=Silva da Silva: silva.tiago@unifesp.br; Andreas=Hinderks: andreas@hinderks.org; Helen=Sharp: helen.sharp@open.ac.uk; Jörg=Thomaschewski: joerg.thomaschewski@hs-emden-leer.de,"Abstract
The integration of Agile software development and User Experience (UX) has become a growing field of research, as both approaches play critical roles in building digital products and services. In this special issue on Agile UX, the current state of the field is explored through a combination of systematic literature reviews and qualitative and quantitative studies. The special issue provide an overview of the key trends, challenges, and successes in combining Agile and UX, and highlight the importance of involving stakeholders throughout development. The shift from plan-driven approaches to Agile UX approaches has brought a focus on human values and a better understanding of the importance of considering users’ needs. We present recent advances in research and practice, showing that Agile UX is a continuous journey towards changing user behavior by delivering value.",June 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The exploration of Agile UX in building digital products and services is valuable for startups, but the abstract lacks specific implementation details or findings that could directly impact early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000113,Improved measurement of software development effort estimation bias,Magne=Jørgensen: magnej@simula.no,"Abstract
Context
While prior software development effort estimation research has examined the properties of estimation 
error
 measures, there has not been much research on the properties of measures of estimation 
bias
.
Objectives
Improved measurement of software development effort estimation bias.
Methods
Analysis of the extent to which measures of estimation bias meet the criterion that perfect estimates should result in zero bias.
Results
Recommendations for measurement of estimation bias for estimates of the mean, median, and mode software development effort. The results include the recommendation to avoid a commonly used measure of effort estimation bias.
Conclusion
Proper evaluation of estimation bias requires knowledge about the type of estimates evaluated, together with the selection of a measure of estimation bias that gives zero bias for perfect estimates of that type.",May 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,3.0,"While the recommendation for measuring estimation bias in software development is valuable, it may not directly impact European early-stage ventures or startups significantly."
https://www.sciencedirect.com/science/article/pii/S0950584923000198,Finding the best learning to rank algorithms for effort-aware defect prediction,Xiao=Yu: xiaoyu@whut.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Jin=Liu: jinliu@whu.edu.cn; Heng=Dai: daiheng726@163.com; Li=Li: lilicoding@ieee.org; Xiaodong=Gu: xiaodong.gu@sjtu.edu.cn; Kwabena Ebo=Bennin: kwabena.bennin@wur.nl; Fuyang=Li: fyli@whut.edu.cn,"Abstract
Context:
Effort-Aware 
Defect Prediction
 (EADP) ranks software modules or changes based on their predicted number of defects (i.e., considering modules or changes as effort) or 
defect density
 (i.e., considering LOC as effort) by using learning to 
rank algorithms
. Ranking instability refers to the inconsistent conclusions produced by existing empirical studies of EADP. The major reason is the poor 
experimental design
, such as comparison of few 
learning to rank
 algorithms, the use of small number of datasets or datasets without indicating numbers of defects, and evaluation with inappropriate or few metrics.
Objective:
To find a stable ranking of 
learning to rank
 algorithms to investigate the best ones for EADP,
Method:
We examine the practical effects of 34 algorithms on 49 datasets for EADP. We measure the performance of these algorithms using 7 module-based and 7 LOC-based metrics and run experiments under cross-release and cross-project settings, respectively. Finally, we obtain the ranking of these algorithms by performing the Scott-Knott ESD test.
Results:
When module is used as effort, 
random forest
 regression performs the best under cross-release setting, and linear regression performs the best under cross-project setting among the 
learning to rank
 algorithms; (2) when LOC is used as effort, LTR-linear (Learning-to-Rank with the linear model) performs the best under cross-release setting, and Ranking 
SVM
 performs the best under cross-project setting.
Conclusion:
This comprehensive experimental procedure allows us to discover a stable ranking of the studied algorithms to select the best ones according to the requirement of software projects.",May 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The study on stable rankings of learning to rank algorithms for software projects can directly impact European early-stage ventures and startups by improving decision-making processes and efficiency in software development.
https://www.sciencedirect.com/science/article/pii/S0950584923000022,A light-weight data augmentation method for fault localization,Jian=Hu: jianhu@cqu.edu.cn; Yan=Lei: yanlei@cqu.edu.cn; Huan=Xie: huanxie@cqu.edu.cn; Ke=Yu: keyu@cqu.edu.cn,"Abstract
Context:
Fault localization (FL) is essentially a search over the space of program statements to find suspicious entities that might have caused a program failure. However, the input data is high-dimensional and extremely imbalanced since the real-world programs are large in size and the number of failing test cases is much less than that of passing test cases, which limits the effectiveness and efficiency of existing FL methods. The state-of-the-art FL method (Aeneas) solves the imbalanced and high-dimensional problem but in a complex and time-consuming process.
Objective:
Due to the limited effectiveness of original FL methods and the low efficiency of Aeneas, this paper proposes 
Lamont
, a 
L
ight-weight d
a
ta aug
m
entati
on
 me
t
hod to improve the effectiveness of original FL methods and the efficiency of Aeneas.
Methods:
Lamont
 uses revised linear 
discriminant analysis
 (LDA) to reduce the dimensionality of the original coverage matrix and leverage synthetic minority over-sampling (SMOTE) to generate the synthesized failing tests. The balanced coverage matrix with reduced dimensionality is fed into FL methods to obtain the ranked suspicious list of statements. To evaluate the efficiency and effectiveness, we compare 
Lamont
 with six representative FL methods and Aeneas on 458 versions of 10 real-life programs.
Results:
It can be observed that 
Lamont
 outperforms in most cases for Top-K metric and reduces the number of statements that need to be checked from 17.45% to 79.81% compared with the original six FL methods. Furthermore, Lamont saves the time over the state-of-the-art data augmentation method Aeneas from 55.33% to 68.39% with comparable effectiveness.
Conclusion:
This work conducts a large-scale experimental study to investigate the effectiveness and efficiency of 
Lamont
. Two conclusions can be obtained based on the experimental results. First, it shows that 
Lamont
 is more effective than the original FL methods. Second, it shows 
Lamont
 is more efficient than Aeneas with similar effectiveness in six FL methods.",May 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The proposal of Lamont to improve fault localization methods can significantly benefit European early-stage ventures and startups by enhancing the efficiency and effectiveness of their software development processes.
https://www.sciencedirect.com/science/article/pii/S0950584923000186,Automated engineering of domain-specific metamorphic testing environments,Pablo=Gómez-Abajo: Pablo.GomezA@uam.es; Pablo C.=Cañizares: Pablo.Cerro@uam.es; Alberto=Núñez: Alberto.Nunez@pdi.ucm.es; Esther=Guerra: Esther.Guerra@uam.es; Juan=de Lara: Juan.deLara@uam.es,"Abstract
Context:
Testing is essential to improve the correctness of software systems. Metamorphic testing (MT) is an approach especially suited when the system under test lacks oracles, or they are expensive to compute. However, building an MT environment for a particular domain (e.g., cloud simulation, model transformation, machine learning) requires substantial effort.
Objective:
Our goal is to facilitate the construction of MT environments for specific domains.
Method:
We propose a model-driven engineering approach to automate the construction of MT environments. Starting from a meta-model capturing the domain concepts, and a description of the domain execution environment, our approach produces an MT environment featuring comprehensive support for the MT process. This includes the definition of domain-specific metamorphic relations, their evaluation, detailed reporting of the testing results, and the automated search-based generation of follow-up test cases.
Results:
Our method is supported by an extensible platform for Eclipse, called 
Gotten
. We demonstrate its effectiveness by creating an MT environment for simulation-based testing of 
data centres
 and comparing with existing tools; its suitability to conduct MT processes by replicating previous experiments; and its generality by building another MT environment for video streaming APIs.
Conclusion:
Gotten
 is the first platform targeted at reducing the development effort of domain-specific MT environments. The environments created with 
Gotten
 facilitate the specification of metamorphic relations, their evaluation, and the generation of new test cases.",May 2023,"Metamorphic testing, Model-driven engineering, Domain-specific languages, Cloud computing, Simulation",Information and Software Technology,2025-03-18T00:00:00,7.0,The automated construction of Metamorphic Testing environments can benefit European early-stage ventures by reducing development effort and facilitating testing processes in various domains.
https://www.sciencedirect.com/science/article/pii/S0950584923000162,A taxonomy for mining and classifying privacy requirements in issue reports,Hoa Khanh=Dam: hoa@uow.edu.au; Aditya=Ghose: aditya@uow.edu.au; Pattaraporn=Sangaroonsilp: ps642@uowmail.edu.au; Morakot=Choetkiertikul: morakot.cho@mahidol.ac.th; Chaiyong=Ragkhitwetsagul: chaiyong.rag@mahidol.ac.th,"Abstract
Context:
Digital and physical trails of user activities are collected over the use of 
software applications
 and systems. As software becomes ubiquitous, protecting user privacy has become challenging. With the increase of user privacy awareness and advent of privacy regulations and policies, there is an emerging need to implement software systems that enhance the protection of 
personal data
 processing. However, existing data protection and privacy regulations provide key principles in high-level, making it difficult for software engineers to design and implement privacy-aware systems.
Objective:
In this paper, we develop a taxonomy that provides a comprehensive set of privacy requirements based on four well-established 
personal data protection
 regulations and privacy frameworks, the 
General Data Protection Regulation
 (GDPR), ISO/IEC 29100, Thailand Personal 
Data Protection Act
 (Thailand PDPA) and Asia-Pacific Economic Cooperation (APEC) privacy framework.
Methods:
These requirements are extracted, refined and classified (using the goal-based requirements analysis method) into a level that can be used to map with issue reports. We have also performed a study on how two large open-source software projects (Google Chrome and Moodle) address the privacy requirements in our taxonomy through mining their issue reports.
Results:
The paper discusses how the collected issues were classified, and presents the findings and insights generated from our study.
Conclusion:
Mining and classifying privacy requirements in issue reports can help organisations be aware of their state of compliance by identifying privacy requirements that have not been addressed in their software projects. The taxonomy can also trace back to regulations, standards and frameworks that the software projects have not complied with based on the identified privacy requirements.",May 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"Developing a taxonomy for privacy requirements can aid software engineers in designing privacy-aware systems, aligning with the increasing need for data protection regulations in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584923000137,Many-objective optimization of non-functional attributes based on refactoring of software models,Vittorio=Cortellessa: vittorio.cortellessa@univaq.it; Daniele=Di Pompeo: daniele.dipompeo@univaq.it; Vincenzo=Stoico: vincenzo.stoico@graduate.univaq.it; Michele=Tucci: tucci@d3s.mff.cuni.cz,"Abstract
Context:
Software quality estimation is a challenging and time-consuming activity, and models are crucial to 
face
 the complexity of such activity on modern 
software applications
. In this context, software refactoring is a crucial activity within development life-cycles where requirements and functionalities rapidly evolve.
Objective:
One main challenge is that the improvement of distinctive 
quality attributes
 may require contrasting refactoring actions on software, as for trade-off between performance and reliability (or other non-functional attributes). In such cases, multi-objective optimization can provide the designer with a wider view on these trade-offs and, consequently, can lead to identify suitable refactoring actions that take into account independent or even competing objectives.
Method:
In this paper, we present an approach that exploits the 
NSGA-II
 as the 
genetic algorithm
 to search optimal 
Pareto frontiers
 for software refactoring while considering many objectives. We consider performance and reliability variations of a model alternative with respect to an initial model, the amount of performance antipatterns detected on the model alternative, and the architectural distance, which quantifies the effort to obtain a model alternative from the initial one.
Results:
We applied our approach on two 
case studies
: a Train Ticket Booking Service, and 
CoCoME
. We observed that our approach is able to improve performance (by up to 42%) while preserving or even improving the reliability (by up to 32%) of generated model alternatives. We also observed that there exists an order of preference of refactoring actions among model alternatives.
Conclusion:
Based on our analysis, we can state that performance antipatterns confirmed their ability to improve performance of a subject model in the context of many-objective optimization. In addition, the metric that we adopted for the architectural distance seems to be suitable for estimating the refactoring effort.",May 2023,"Multi-objective optimization, Search-based software engineering, Performance, Reliability, Refactoring, Model-driven engineering, Software architecture",Information and Software Technology,2025-03-18T00:00:00,8.0,The approach presented for multi-objective optimization in software refactoring can significantly impact European startups by improving software quality attributes efficiently and effectively.
https://www.sciencedirect.com/science/article/pii/S0950584923000204,A novel detection model for abnormal network traffic based on bidirectional temporal convolutional network,Saihua=Cai: caisaih@ujs.edu.cn,"Abstract
Context:
The increasingly complex and diverse network environment has increased traffic intrusion behaviors, but the traditional machine learning-based model has the problems of time-consuming and low detection accuracy due to the need of manually selecting features. Therefore, it is very important to construct an automatically abnormal network traffic detection model with a high detection accuracy.
Objective:
The goal of this paper is to train the network traffic through 
deep learning
 technology to generate an automatic abnormal network traffic detection model without manual design of features.
Methods:
We propose an abnormal network traffic detection model called BiTCN based on bidirectional time convolution network, it first uses 
temporal convolutional network
 (TCN) model to better grasp the sequence characteristics of network traffic, and then uses Exponential Linear Unit (ELU) 
activation function
 to replace ReLU in the model training stage to avoid the problem of neuron “death” leading to the reduction of detection accuracy, as well as improves the original one-way model to a two-way model to capture the two-way semantic fusion characteristics of network traffic.
Results:
We evaluate the efficiency and effectiveness of the proposed BiTCN model by comparing it with different models on the CTU and USTC-TFC2016 datasets. The experimental results show that the proposed BiTCN model outperforms other models in terms of the precision, accuracy, recall and F1-measure.
Conclusion:
In this paper, we propose a novel detection model for abnormal network traffic based on bidirectional 
temporal convolutional network
 , it solves some shortcomings and limitations of existing models, and obtains a high detection accuracy of abnormal network traffic with a high stability.",May 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The development of an automatic abnormal network traffic detection model using deep learning technology can provide practical value to European startups by enhancing network security measures with high detection accuracy.
https://www.sciencedirect.com/science/article/pii/S095058492200218X,WINE: Warning miner for improving bug finders,Yoon-ho=Choi: yhchoi@handong.ac.kr; Jaechang=Nam: jcnam@handong.edu,"Abstract
Context:
Bug finders have been actively used to efficiently detect bugs. However, developers and researchers found that the bug finders show high false positive rate. The 
false positives
 can be caused by two major reasons: (1) users rejecting warnings and (2) false-positive inducing issues (FPI), i.e., incorrect or incomplete rule implementations.
Objective:
The objective of this study is to reduce warning validation costs for developers of bug finders when they validate the implementation of bug finders to reduce 
false positives
 caused by FPI.
Methods:
To achieve the objective, we propose a novel approach, 
WINE
. The key idea of 
WINE
 is to extract 
representative warnings
 that are structurally equal to other warnings, or structurally contain other warnings from numerous warnings. The rationale behind the approach is that the warnings detected based on structural information and tokens might be equal to each other, or contain other warnings structurally.
Results:
We evaluated our approach with PMD, an open source bug finder, and 1,008 Java 
open source projects
 maintained by Apache Software Foundation. As a result, 
WINE
 extracted just about 2% of all warnings. Among the 2% of warnings, we could find the 28 FPIs of PMD. Among them, ten FPIs were already fixed among them. In addition, we simulated our approach in regression testing of PMD with twelve versions changes of PMD (6.25.0 to 6.37.0). As a result, we observed that 
WINE
 can effectively reduce the inspection costs by removing about 95% changed warnings.
Conclusion:
Based on the results, we suggest that 
WINE
 could be adopted to improve the bug finders in terms of reducing false positives cause by FPI. In addition, 
WINE
 is helpful in the 
development processes
 of bug finders to identify false positives and 
false negatives
, especially in regression testing of bug finders.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed approach of WINE for reducing false positives in bug finders demonstrates effectiveness, which can be beneficial for startups in reducing validation costs and improving bug detection accuracy."
https://www.sciencedirect.com/science/article/pii/S0950584923000034,A system-based view of blockchain governance,Gabriella=Laatikainen: gabriella.laatikainen@jyu.fi,"Abstract
Context
Governance is crucial in achieving the success and sustainability of 
blockchain
 systems. However, 
blockchain
 governance is multi-faceted, complex, dynamic, and challenging due to its decentralized nature and automatically enforced rules and mechanisms.
Objectives
This study aims to advance the theory of blockchain governance and support practitioners to deepen the researchers’ and practitioners’ understanding of blockchain governance.
Methods
The study is a 
systematic literature review
 of 75 articles that applies systems theory to conceptualize blockchain governance as a system and parsimoniously organize its interrelated elements into a conceptual model.
Results
The paper proposes a holistic definition and a conceptual model of blockchain governance. Blockchain governance encompasses technical and social means to make decisions on the different levels (e.g., individual, community, organizational, national, international) related to actors, roles, rights, incentives, responsibilities, rules, and the business, technological, legal, and regulatory aspects of a blockchain system during its whole lifecycle.
Conclusion
The system-based model of blockchain governance can serve as a reference framework and structured foundation for analyzing, discussing, and developing the governance of blockchain systems.",May 2023,"Blockchain governance, Systems theory, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on blockchain governance provides a structured foundation for analyzing and developing governance systems, which can be valuable for startups utilizing blockchain technology."
https://www.sciencedirect.com/science/article/pii/S0950584923000046,DevOps critical success factors — A systematic literature review,Nasreen=Azad: nasren.azad@lut.fi,"Abstract
Context:
DevOps
 is a set of software development and operation practices and a recent addition to a large family of different kinds of software process models. The model emerged out of the observation that 
information systems
 operations and developments should be closely integrated activities to ensure the success of any organization. Thus, DevOps methods are an additive tool for companies to improve overall performance in their software development processes and operations.
Objective:
This paper aims to identify the various critical 
success factors
 (CSFs) of DevOps projects that have been discussed in prior research. In addition, this study proposes a comprehensive framework for depicting how these CSFs impact or drive DevOps success.
Method:
This study consists of a systematic literature review to collect the primary articles for the analysis.
Results:
After searches in four major publication databases and snowballing, we selected 38 primary studies for the analysis. Nearly 100 different CSFs were identified, which were then categorized into 
Technical
, 
Organizational
, and 
Social & Cultural
 dimensions. Based on the results of the literature analysis, a comprehensive framework is proposed that depicts how the CSFs impact or drive DevOps success.
Conclusion:
This paper presents a DevOps framework with various CSFs based on prior literature. The proposed framework will provide collective knowledge of DevOps success factors, which will allow researchers and practitioners to enhance their understanding of CSFs and learn how to handle DevOps issues in organizations. In particular, the paper highlights a number of future research directions related to CSFs.",May 2023,"DevOps, Development and operations, Success factors, Barriers, Literature review",Information and Software Technology,2025-03-18T00:00:00,8.0,The study on DevOps success factors and framework can offer practical insights for startups looking to improve their software development processes and operations.
https://www.sciencedirect.com/science/article/pii/S0950584923000216,The discovery effort worthiness index: How much product discovery should you do and how can this be integrated into delivery?,Stefan=Trieflinger: stefan.trieflinger@reutlingen-university.de,"Abstract
Context
In a world of high dynamics and uncertainties, it is almost impossible to have a long-term prediction of which products, services, or features will satisfy the needs of the customer. To counter this situation, the conduction of Continuous Improvement or Design Thinking for product discovery are common approaches. A major constraint in conducting product discovery activities is the high effort to discover and validate features and requirements. In addition, companies struggle to integrate product discovery activities into their agile processes and iterations.
Objective
This paper aims at suggests a supportive tool, the “Discovery Effort Worthiness (DEW) Index”, for product owners and agile teams to determine a suitable amount of effort that should be spent on Design Thinking activities. To operationalize DEW, proposals for practitioners are presented that can be used to integrate product discovery into product development and delivery.
Method
A case study was conducted for the development of the DEW index. In addition, we conducted an expert workshop to develop proposals for the integration of product discovery activities into the product development and delivery process.
Results
First, we present the ""Discovery Effort Worthiness Index"" in form of a formula. Second, we identified requirements that must be fulfilled for systematic integration of product discovery activities into product development and delivery. Third, we derived from the requirements proposals for the integration of product discovery activities with a company's product development and delivery.
Conclusion
The developed ""Discovery Effort Worthiness Index"" provides a tool for companies and their product owners to determine how much effort they should spend on Design Thinking methods to discover and validate requirements. Integrating product discovery with product development and delivery should ensure that the results of product discovery are incorporated into product development. This aims to systematically analyze product risks to increase the chance of product success.",May 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed tool and methodology for product discovery can help startups optimize their design thinking activities and integrate them into agile processes, contributing to product success."
https://www.sciencedirect.com/science/article/pii/S0950584922002440,Industry-academia collaboration for realism in software engineering research: Insights and recommendations,Per=Runeson: per.runeson@cs.lth.se; Qunying=Song: qunying.song@cs.lth.se,"Abstract
Context:
Effective industry-academia collaboration may increase 
software engineering
 research relevance by increased realism, yet very challenging for reasons like confidentiality concerns, different objectives and priorities.
Objective:
We analyse industry-academia collaboration scenarios based on our own experiences as Ph.D. student and supervisor, and provide insights and recommendations to facilitate future collaborations with 
industry
.
Method:
We first present our industry-academia collaboration experiences that span over two and a half years with different companies. Then, we analyse both facilitators and problems from those scenarios and synthesize recommendations based on that.
Results:
Five different scenarios are analysed, including both success and failure scenarios. Reflections and insights into these experiences as well as some general recommendations are presented.
Conclusion:
We believe such experiences and insights are helpful for academic researchers to pursue industry-academia collaboration. We plan to continuously report our experience and provide our suggestions for effective collaboration with industry.",April 2023,"Software engineering, Industry-academia collaboration",Information and Software Technology,2025-03-18T00:00:00,6.0,The insights and recommendations on industry-academia collaboration can be beneficial for startups looking to collaborate with industry partners to enhance their research relevance.
https://www.sciencedirect.com/science/article/pii/S0950584922002427,Progress on class integration test order generation approaches: A systematic literature review,Shujuan=Jiang: shjjiang@cumt.edu.cn; Yanru=Ding: yrding@cumt.edu.cn; Yanmei=Zhang: ymzhang@cumt.edu.cn; Guan=Yuan: yuanguan@cumt.edu.cn; Wei=Dai: weidai@cumt.edu.cn,"Abstract
Context:
Integration testing is an effective way to detect unit test results and ensure the correct and stable operation of software modules. One of the crucial problems in integration testing is the class integration test order (CITO) generation problem. Its purpose is to reasonably determine the test order of each class in a program to reduce test consumption. In recent years, the CITO generation problem has made a lot of progress but also faces more challenges.
Objective:
The goal of this paper is to provide an overview of the research progress on the CITO generation problem. By summarizing applied techniques, evaluation indicators, and datasets, this paper aims to identify research challenges and suggest future opportunities.
Method:
We conduct a systematic literature review of CITO generation approaches, including the problems investigated, the solutions proposed, the techniques applied, the evaluation indicators used, and the datasets covered.
Results:
Based on research techniques and evaluation indicators, we classified and analyzed 30 papers published between 2011 and 2022. Our analysis reveals that more (47%) of the studies on the CITO generation problem still prefer to use search-based techniques, and the vast majority (90%) of the studies choose to use the stubbing complexity as the indicator to evaluate the stubbing cost of generating CITOs. We have extracted five challenges that the CITO generation problem is facing, corresponding to which we have given suggestions for future research.
Conclusion:
In this paper, we have outlined the research status of CITO generation approaches, summarized the challenges, and proposed corresponding opportunities for future study. We expect this paper to better help software testing workers understand the CITO generation problem and improve efficiency in practical work.",April 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract addresses challenges in integration testing, which could impact startups in the software development industry."
https://www.sciencedirect.com/science/article/pii/S0950584922002543,Digital-twin-based testing for cyber–physical systems: A systematic literature review,Richard J.=Somers: rsomers1@sheffield.ac.uk,"Abstract
Context:
Cyber–physical systems present a challenge to testers, bringing complexity and scale to safety-critical and collaborative environments. 
Digital twins
 enhance these systems through data-driven and simulation based models coupled to 
physical systems
 to provide visualisation, predict future states and communication. Due to the coupling between digital and physical worlds, digital twins provide a new perspective into cyber–physical system testing.
Objective:
The objectives of this study are to summarise the existing literature on digital-twin-based testing. We aim to uncover emerging areas of adoptions, the testing techniques used in these areas and identify future research areas.
Method:
We conducted a systematic literature review which answered the following research questions: What cyber–physical systems are digital twins currently being used to test? How are test oracles defined for cyber–physical systems? What is the distribution of white-box, black-box and grey-box modelling techniques used for digital twins in the context of testing? How are test cases defined and how does this affect test inputs?
Results:
We uncovered 26 relevant studies from 480 produced by searching with a curated search query. These studies showed an adoption of digital-twin-based testing following the introduction of digital twins in industry as well as the increasing accessibility of the technology. The oracles used in testing are the digital twin themselves and therefore rely on both system specification and data derivation. Cyber–physical systems are tested through passive testing techniques, as opposed to either active testing through test cases or predictive testing using digital twin prediction.
Conclusions:
This review uncovers the existing areas in which digital twins are used to test cyber–physical systems as well as outlining future research areas in the field. We outline how the infancy of digital twins has affected their wide variety of definitions, emerging specialised testing and modelling techniques as well as the current lack of 
predictive ability
.",April 2023,"Digital twin, Cyber–physical system, Testing, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract explores digital twin-based testing in cyber-physical systems, a cutting-edge technology that could have significant implications for European startups in tech and IoT sectors."
https://www.sciencedirect.com/science/article/pii/S0950584922002403,Knowledge diffusion trajectories of agile software development research: A main path analysis,Sun-Jen=Huang: huangsj@mail.ntust.edu.tw; Yulianus=Palopak: ypalopak@unai.edu; Wiwit=Ratnasari: ratnasariwiwit@gmail.com,"Abstract
Context
The dramatic growth of agile software development (ASD) research has resulted in a large number of diverse theoretical and empirical publications. The citation relationships among these publications indicate knowledge dissemination across and within academia or scientists.
Objective
This study offers a comprehensive understanding of the ASD literature by exploring the knowledge diffusion path through the citation network of publications that have made significant contributions to its research development.
Method
We employ a quantitative citation-based methodology, main path analysis (MPA), to examine the citation relationship of 1431 scientific articles published in the Web of Science (WoS) between 2001 and 2021 and visualize the MPA results using Pajek software.
Results
Through citation analysis this study discovers knowledge diffusion trajectories of publications concerning ASD method. Our key results present 32 publications identified along the key-route main path as the most influential ones in the trajectories of ASD. There are three phases of ASD research development: introduction, evaluation, and deployment and expansion. Using the multiple-global main path, we further uncover the publication trends from a set of recent papers and reveal four sub-themes: tailoring of agile practices, large-scale agile context, challenges and success factors of large-scale organizations, and agile global software development.
Conclusions
Although there was little academic interest in the initial phase, ASD-related publication and citation trends have consistently increased over time. The historical development of ASD methods was established in three distinct phases of publications in the domain. Each phase presents a narrative of agile methods’ development with different focuses. The most recent trends of ASD publications tend to focus on the agile tailoring and scaling process in the global and distributed environment.",April 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the abstract provides insights into agile software development research, the practical value for early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922002397,Graph-based code semantics learning for efficient semantic code clone detection,Dongjin=Yu: yudj@hdu.edu.cn,"Abstract
Recent studies have shown that high-quality code semantics learning can effectively improve the performance of code clone detection. However, existing approaches suffer from two major drawbacks: (a) insufficient utilization of code representations, leading to inefficient semantics learning, and (b) low efficiency of clone detection, resulting in massive detection time. Therefore, we are motivated to propose an efficient semantics learning method while speeding up the detection process. Specifically, to address the first one, we adopt either CFG (Control Flow Graph) or PDG (Program Dependency Graph) as our initial code representation because of their rich semantic information. Further, we propose a novel graph-based code semantics learning method, which can capture critical information at token, statement, edge, and graph levels. To address the second one, we design a Siamese graph-matching network based on 
attention mechanisms
. It can uniformly generate graph embeddings for code fragments and facilitate parallel detection of semantic clones, thus significantly boosting the speed of semantic clone detection.
We evaluated our approach on two Java benchmark datasets, Google Code Jam and BigCloneBench. The experimental results show that our model outperforms the SOTA (State-Of-The-Art) lightweight models and is over 20x faster in detection. In addition, our model performs on par with the large Bert-based models and is over 110x faster in detection. Our code and dataset are available online at: 
https://github.com/HduDBSI/CodeGraph4CCDetector
.",April 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract presents a novel approach to code clone detection that outperforms existing models and significantly boosts detection speed, which can be valuable for European startups dealing with large codebases."
https://www.sciencedirect.com/science/article/pii/S0950584922002555,A modeling assistant to manage technical debt in coupled evolution,Davide=Di Ruscio: davide.diruscio@univaq.it; Ludovico=Iovino: ludovico.iovino@gssi.it; Alfonso=Pierantonio: alfonso.pierantonio@univaq.it; Amleto=Di Salle: amleto.disalle@univaq.it,"Abstract
Context:
Model-Driven Engineering helps formalize problem domains by using metamodels. Modeling ecosystems consisting of purposely designed editors, transformations, and 
code generators
 are defined on top of the metamodels. Similar to other software artifacts, metamodels can evolve by possibly compromising the validity of existing artifacts. Coupled evolution provides techniques for restoring artifacts’ validity in response to metamodel evolution.
Objective:
In this paper, we propose the adoption of 
deprecation
 in metamodeling to mitigate the difficulties in performing manual model adaptations in response to metamodel evolutions. Moreover, we aim to measure and resolve the 
technical debt
 during the co-evolution, which can be seen as the outcome of procrastinating artifact migrations.
Methods:
We propose a novel approach and supporting tool to manage the concepts of 
deprecation
 and 
technical debt
 in metamodeling.
Results:
We conducted a judgment study using the focus group methodology to assess the proposed approach’s usefulness in migrating models affected by breaking non-resolvable changes completely.
Conclusions:
The proposed approach can identify the technical debt in metamodel evolution. Furthermore, it deals with the coupled evolution problem by assisting the modeler through interactive visualization tools, which highlight and quantify the technical dept of the artifacts under analysis that need to be evolved.",April 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The proposed approach addresses technical debt in metamodel evolution, which can be useful for startups using Model-Driven Engineering, but the impact may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002439,"Composite refactoring: Representations, characteristics and effects on software projects",Silvia R.=Vergilio: silvia@inf.ufpr.br; Ana Carla=Bibiano: abibiano@inf.puc-rio.br; Anderson=Uchôa: andersonuchoa@ufc.br; Wesley K.G.=Assunção: wassuncao@inf.puc-rio.br; Daniel=Tenório: doliveira@inf.puc-rio.br; Thelma E.=Colanzi: thelma@din.uem.br; Alessandro=Garcia: afgarcia@inf.puc-rio.br,"Abstract
Context:
code refactoring
 is a code transformation that aims to improve software quality. A composite refactoring (or, simply, composite) is defined by two or more interrelated refactorings, which is often applied by developers. Each composite needs to be somehow represented and has its own characteristics (e.g., code scope) as well as its effects on software quality. However, these basic elements of composites are rarely studied systematically. The lack of 
systematic knowledge
 also misguides the design of automated support tools for supporting composite refactoring. Thus, researchers might have controversial views about basic elements of composite refactorings. An example of these literature conflicts concerns the effect of composites: while some studies suggest composites more often remove code smells, other studies indicate composites often introduce code smells.
Objective:
in this sense, our study aims at analyzing the technical literature of composite refactoring and building a conceptual framework of the representation models, characteristics, and the effect of composite refactoring.
Method:
we conducted a 
systematic mapping
 with 140 primary empirical studies about refactoring. Our 
systematic mapping
 summarizes the current knowledge on composites and also presents a conceptual framework intended to characterize composite refactoring.
Results:
our conceptual framework presents seven representation models, nine characteristics, and thirteen effects of composites. We found out that studies used multidimensional representations, like graphs, to determine what refactoring(s) may be suggested and combined. On composite characteristics, studies mentioned developers often finish a composite in up to a month. However, these studies do not detail why and when composites span for several weeks. Then, we discussed other existing gaps on the current literature of composites. For instance, while most of the studies report the effect of composites on internal software quality, e.g., code smells, their effect on external software quality is little explored.
Conclusion:
our results can motivate future studies to more deeply investigate composite refactoring applications, and the improvement of tooling support for composite refactorings.",April 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on composite refactoring provides valuable insights into representing, characterizing, and understanding the effects of composites, which can benefit startups looking to improve software quality."
https://www.sciencedirect.com/science/article/pii/S0950584922002518,Negative effects of gamification in education software: Systematic mapping and practitioner perceptions,Anderson=Uchôa: andersonuchoa@ufc.br; Cláuvin=Almeida: almeidaclauvin@gmail.com; Marcos=Kalinowski: kalinowski@inf.puc-rio.br; Bruno=Feijó: bfeijo@inf.puc-rio.br,"Abstract
Context:
While most research shows positive effects of 
gamification
, the focus on its adverse effects is considerably smaller and further understanding of these effects is needed.
Objective:
To provide a comprehensive overview on research reporting negative effects of game design elements and to provide insights into the awareness of developers on these effects and into how they could be considered in practice.
Method:
We conducted a 
systematic mapping study
 of the negative effects of game design elements on education/learning systems. We also held a focus 
group discussion
 with developers of a gamified software, discussing the mapping study results with regard to their awareness and perceptions on the reported negative effects in practice.
Results:
The mapping study revealed 87 papers reporting undesired effects of game design elements. We found that badges, leaderboards, competitions, and points are the game design elements most often reported as causing negative effects. The most cited negative effects were lack of effect, worsened performance, motivational issues, lack of understanding, and irrelevance. The ethical issues of gaming the system and cheating were also often reported. As part of our results, we map the relations between game design elements and the negative effects that they may cause. The focus group revealed that developers were not aware of many of the possible negative effects and that they consider this type of information useful. The discussion revealed their agreement on some of those potential negative effects and also some positive counterparts.
Conclusions:
Gamification, when properly applied, can have positive effects on education/learning software. However, gamified software is also prone to generate harmful effects. Revealing and discussing potentially negative effects can help to make more informed decisions considering their trade-off with respect to the expected benefits.",April 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study on the negative effects of gamification is interesting, its practical impact on European startups may be less direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002531,A systematic mapping study and practitioner insights on the use of software engineering practices to develop MVPs,Silvio=Alonso: smarques@inf.puc-rio.br,"Abstract
Background:
Many startup environments and even traditional software companies have embraced the use of MVPs (Minimum Viable Products) to allow quickly experimenting solution options. The MVP concept has influenced the way in which development teams apply 
Software Engineering
 (SE) practices. However, the overall understanding of this influence of MVPs on SE practices is still poor.
Objective:
Our goal is to characterize the publication landscape on practices that have been used in the context of software MVPs and to gather practitioner insights on the identified practices.
Method:
We conducted a 
systematic mapping study
 using a hybrid search strategy that consists of a database search and parallel forward and backward snowballing. Thereafter, we discussed the mapping study results in two 
focus groups sessions
 involving twelve industry practitioners that extensively use MVPs in their projects to capture their perceptions on the findings of the mapping study.
Results:
We identified 33 papers published between 2013 and 2020. We observed some trends related to MVP ideation (or MVP conception) and evaluation practices. For instance, regarding ideation, we found six different approaches (
e.g.
, Design Thinking, Lean Inception) and mainly informal end-user involvement practices (
e.g.
, workshops, interviews). Regarding evaluation, there is an emphasis on end-user validations based on practices such as 
usability tests
, A/B testing, and usage data analysis. However, there is still limited research related to MVP 
technical feasibility
 assessment and effort estimation. Practitioners of the focus group sessions reinforced the confidence in our results regarding ideation and evaluation practices, being aware of most of the identified practices. They also reported how they deal with the 
technical feasibility
 assessments (involving developers during the ideation and conducting informal experiments) and effort estimation in practice (based on expert opinion and using 
practices common
 to 
agile methodologies
, such as Planning Poker).
Conclusion:
Our analysis suggests that there are opportunities for solution proposals and evaluation studies to address literature gaps concerning technical feasibility assessment and effort estimation. Overall, more effort needs to be invested into empirically evaluating the existing MVP-related practices.",April 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The study on MVP practices in software development can have a significant impact on early-stage ventures by improving product development processes and enhancing the understanding of technical feasibility and effort estimation.
https://www.sciencedirect.com/science/article/pii/S0950584922002257,Burnout in software engineering: A systematic mapping study,Tien Rahayu=Tulili: t.r.tulili@rug.nl; Andrea=Capiluppi: a.capiluppi@rug.nl; Ayushi=Rastogi: a.rastogi@rug.nl,"Abstract
Context:
Burnout is a work-related syndrome that, similar to many occupations, influences most software developers. For decades, studies in software engineering(SE) have explored the causes of burnout and its consequences among IT professionals.
Objective:
This paper is a 
systematic mapping study
 (SMS) of the studies on burnout in SE, exploring its causes and consequences, and how it is studied (e.g., choice of data).
Method:
We conducted a systematic mapping study and identified 92 relevant research articles dating as early as the early 1990s, focusing on various aspects and approaches to detect burnout in software developers and IT professionals.
Results:
Our study shows that early research on burnout was primarily qualitative, which has steadily moved to more quantitative, data-driven in the last decade. The emergence of 
machine learning
 (ML) approaches to detect burnout in developers has become a 
de-facto
 standard.
Conclusion:
Our study summarises what we now know about burnout, how software artifacts indicate burnout, and how machine learning can help its early detection. As a comprehensive analysis of past and present 
research works
 in the field, we believe this paper can help future research and practice focus on the 
grand challenges
 ahead and offer necessary tools.",March 2023,"Burnout, Software engineering, Systematic mapping study",Information and Software Technology,2025-03-18T00:00:00,6.0,"While the study on burnout in software developers is important for the well-being of individuals, its direct impact on early-stage ventures may be limited compared to other topics."
https://www.sciencedirect.com/science/article/pii/S0950584922002373,Machine learning in software defect prediction: A business-driven systematic mapping study,Lech=Madeyski: lech.madeyski@pwr.edu.pl,"Abstract
Context:
Machine learning
 is a valuable tool in 
software engineering
 allowing fair 
defect prediction
 capabilities at a relatively small expense. However, although the practical usage of machine learning in 
defect prediction
 has been studied over many years, there is not sufficient systematic effort to analyse its potential for 
business application
.
Objective:
The following 
systematic mapping study
 aims to analyse the current state-of-the-art in terms of machine learning 
software defect
 prediction modelling and to identify and classify the emerging new trends. Notably, the analysis is done from a business perspective, evaluating the opportunities to adopt the latest techniques and methods in commercial settings to improve software quality and lower the cost of 
development life cycle
.
Method:
We created a broad search universe to answer our research questions, performing an automated query through the Scopus database to identify relevant primary studies. Next, we evaluated all found studies using a 
classification scheme
 to map the extent of 
business adoption
 of machine learning 
software defect
 prediction based on the keywords used in the publications. Additionally, we use PRISMA 2020 guideline to validate reporting.
Results:
After the application of the selection criteria, the remaining 742 primary studies included in Scopus until February 23, 2022 were mapped to classify and structure the research area. The results confirm that the usage of commercial datasets is significantly smaller than the established datasets from NASA and open-source projects. However, we have also found meaningful emerging trends considering business needs in analysed studies.
Conclusions:
There is still a considerable amount of work to fully internalise business applicability in the field. Performed analysis has shown that purely academic considerations dominate in published research; however, there are also traces of in vivo results becoming more available. Notably, the created maps offer insight into future machine learning software defect prediction research opportunities.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The analysis of machine learning applications in software development from a business perspective can provide actionable insights for early-stage ventures looking to adopt new techniques and improve software quality, making it highly valuable."
https://www.sciencedirect.com/science/article/pii/S0950584922002142,An empirical study on bugs in JavaScript engines,Ziyuan=Wang: wangziyuan@njupt.edu.cn,"Abstract
Context:
JavaScript is a prototype-based dynamic type 
scripting language
. The correct running of a JavaScript program depends on the correctness of both the program and the JavaScript engine.
Objective:
An in-depth understanding of the characteristics of bugs in JavaScript engines can help detect and fix them.
Methods:
We conduct an empirical study on the bugs in three mainstream JavaScript engines: V8, SpiderMonkey, and Chakra. Such an empirical study involves 19,019 
bug reports
, 16,437 revisions, 805 test cases, and root causes of randomly selected 540 bugs.
Results:
(1) The Compiler and the 
DOM
 are the most buggy component in V8 and SpiderMonkey, respectively. Most of the source files contain only one bug. (2) The scales of the testing programs that reveal bugs are usually small. Most bug fixes involve only limited modifications since the number of modified source files and lines of code modified are small. (3) Most bugs can be fixed within half a year (80.33% for V8 and 91.9% for SpiderMonkey). Only 4.33% of SpiderMonkey bugs need more than a year to fix. Bugs in SpiderMonkey are usually fixed faster than bugs in V8. (4) High priority tends to be assigned to Infrastructure bugs in V8 and Release Automation bugs in SpiderMonkey. The duration of bugs is not strictly correlated with their priorities. (5) Semantic bugs are the most common root causes of bugs. And among semantic bugs, the processing bugs, missing features bugs and function call bugs are more than others.
Conclusion:
This study deepens our understanding of bugs in JavaScript engines, and empirical results could indicate some potential problems during the detecting and fixing of bugs in JavaScript engines, assist developers of JavaScript engines in improving their development quality, assist maintainers in detecting and fixing bugs more effectively, and suggest users of JavaScript evade potential risks.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study on bugs in JavaScript engines is informative, its practical impact on early-stage ventures may be less immediate compared to studies focusing on development practices or business applications."
https://www.sciencedirect.com/science/article/pii/S0950584922002221,Parallel evolutionary test case generation for web applications,Ruilian=Zhao: rlzhao@mail.buct.edu.cn,"Abstract
Context:
Web applications follow a client–server schema, so it is more appropriate for evolutionary test case generation considering both client and server. However, test cases from the client-side are composed of event sequences, which are quite time-consuming when executed due to the interaction with the browser. Furthermore, premature convergence is a problem for 
evolutionary algorithms
 because of the decline of population diversity. These problems restrict the applicability of 
evolutionary algorithms
 in test case generation for web applications.
Objective:
Parallelization
 has been proven helpful in optimizing test case generation. So, to improve the efficiency and effectiveness of test generation for web applications, this paper proposes a parallel evolutionary test case generation approach where test cases are generated from the client-side behavior model to cover the sensitive paths of server-side code by using a parallel 
genetic algorithm
 based on the island model.
Method:
A parallel execution strategy is presented to drive multi-individuals to execute on multi-browsers simultaneously to shorten the 
execution time
 of populations during evolution. And an island model with a corresponding migration mechanism and subpopulation evolution strategy is well-designed to increase population diversity during evolution. Meanwhile, the server-side code triggered by parallel individuals is identified to guide the evolution process.
Results:
Experiments are conducted on six widely-used web applications, and the results show that compared with the sequential evolutionary test case generation, our approach decreases the iterations and evolution time required by 33.43% and 63.10% on average, respectively. The efficiency of test generation has been greatly enhanced.
Conclusion:
This paper provides a parallel evolutionary test case generation for web applications, where the parallel execution strategy is presented to shorten the 
execution time
 of populations during evolution, increasing test generation efficiency. Moreover, the island model with a migration mechanism is introduced to increase population diversity during evolution, improving the test generation effectiveness.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed approach of parallel evolutionary test case generation for web applications shows significant improvements in efficiency and effectiveness, which can have a high impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002117,Issues-Driven features for software fault prediction,Amir=Elmishali: amirelm@post.bgu.ac.il; Meir=Kalech: kalech@bgu.ac.il,"Abstract
Context:
Software systems are an integral part of almost every modern industry. Unfortunately, the more complex the software, the more likely it will fail. A promising strategy is applying fault prediction models to predict which components may be defective. Since features are essential to the prediction model’s success, extracting significant features can improve the model’s accuracy. Previous research studies used software metrics as features in fault prediction models. One disadvantage of these features is that they measure the code developed rather than the requirements. On the other hand, faults are frequently the result of a mismatch between the software’s behavior and its needs.
Objective:
We present a novel paradigm for constructing features that consider the requirements as well by combining novel requirement metrics, called 
Issues-Driven features
, and traditional 
code metrics
.
Method:
We experimentally compare the performance of 
Issues-Driven features
 and state-of-the-art traditional features on 86 open-source projects from two organizations.
Results:
The results show that 
Issues-Driven features
 are significantly better than state-of-the-art features and achieve an improvement of 6 to 13 percent in terms of AUC.
Conclusions:
The study concludes that integrating the requirements into fault prediction features overcomes the limitations of traditional software metrics that are agnostic to the requirements of the software.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The integration of requirements into fault prediction features shows promising results in improving accuracy, which can be valuable for startups in improving software quality."
https://www.sciencedirect.com/science/article/pii/S0950584922002270,Introduction to Special Issue on Visualization Applied to Software Engineering,,"Abstract
Software visualization is a broad research area whose general goal is to enhance and promote the theory, realization, and evaluation of approaches to visually encode and analyze software systems, including software development practices, evolution, structure, and software runtime behavior. Software visualization is inherently interdisciplinary, drawing on theories and techniques from information visualization and computer graphics and applying these in the software engineering domain.
This special issue on software visualization aims to bring together a community of researchers from software engineering, information visualization, computer graphics, human-computer interaction, and data science to discuss theoretical foundations, algorithms, techniques, tools, and applications related to software visualization. The special issue received 17 submissions of which 6 were accepted for publication (i.e., acceptance rate of 35.3%). Amongst the accepted papers, three correspond to extended versions of papers published in the IEEE Working Conference on Software Visualization (VISSOFT) 2021.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While software visualization is important, this abstract focuses more on academic discussion and community gathering rather than direct impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492200221X,Detecting code smells using industry-relevant data,Lech=Madeyski: lech.madeyski@pwr.edu.pl; Tomasz=Lewowski: tomasz.lewowski@pwr.edu.pl,"Abstract
Context
Code smells are patterns in 
source code
 associated with an increased defect rate and a higher maintenance effort than usual, but without a clear definition. Code smells are often detected using rules hard-coded in detection tools. Such rules are often set arbitrarily or derived from data sets tagged by reviewers without the necessary industrial know-how. Conclusions from studying such data sets may be unreliable or even harmful, since algorithms may achieve higher values of performance metrics on them than on models tagged by experts, despite not being industrially useful.
Objective
Our goal is to investigate the performance of various 
machine learning algorithms
 for automated code smell detection trained on code smell data set(MLCQ) derived from actively developed and industry-relevant projects and reviews performed by experienced software developers.
Method
We assign the severity of the smell to the code sample according to a consensus between the severities assigned by the reviewers, use the Matthews 
Correlation Coefficient
 (MCC) as our main performance metric to account for the entire 
confusion matrix
, and compare the median value to account for non-normal distributions of performance. We compare 6720 models built using eight 
machine learning techniques
. The entire process is automated and reproducible.
Results
Performance of compared techniques depends heavily on analyzed smell. The median value of our performance metric for the best algorithm was 0.81 for Long Method, 0.31 for Feature Envy, 0.51 for Blob, and 0.57 for Data Class.
Conclusions
Random Forest
 and Flexible 
Discriminant Analysis
 performed the best overall, but in most cases the performance difference between them and the median algorithm was no more than 10% of the latter. The performance results were stable over multiple iterations. Although the F-score omits one quadrant of the 
confusion matrix
 (and thus may differ from MCC), in code smell detection, the actual differences are minimal.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The investigation of machine learning algorithms for automated code smell detection provides valuable insights, but the practical implications for startups may not be as direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002233,Boosting input data sequences generation for testing EFSM-specified systems using deep reinforcement learning,Ting=Shu: shuting@zstu.edu.cn; Cuiping=Wu: 202030504154@mails.zstu.edu.cn; Zuohua=Ding: zuohuading@zstu.edu.cn,"Abstract
Context:
Input data sequence (IDS) is an important component of test sequences for testing from the Extended 
Finite State Machine
 (EFSM) model. During test generation, frequent IDS derivation is time-consuming. Therefore, it has become one of the key factors that restrict the efficiency of test sequences generation.
Objective:
To address this issue, this paper introduces 
deep reinforcement learning
 (DRL) to propose a novel approach named IDSG-DRL to accelerate IDS derivation.
Method:
Our method first formalizes the problem of generating IDS for EFSM-based testing as a Markov decision problem. It then incorporates the 
DRL algorithm
 to learn experience from previous input data generation and train a decision-making model to significantly enhance the efficiency of subsequent data derivation for the newly generated test sequences. To improve the convergence of 
DRL algorithm
 and ensure the success rate of data generation, a state representation based on variable deviation and action formulation using adaptive exploration are elaborately designed. Finally, a DRL-based algorithm for efficiently yielding IDS is presented for any subject test sequence.
Results:
We evaluate the proposed approach against the random method, GA-based method as well as a 
particle swarm optimization
 (PSO) based method. Experimental statistics show that IDSG-DRL significantly outperforms the baselines in terms of 
iteration steps
, runtime cost, and the success rate of input data derivation. Specifically, compared to random, GA-based and PSO-based methods, IDSG-DRL can reduce the average number of 
iteration steps
 by up to 87.09%, 78.57%, and 56.35%, respectively. Regarding the average runtime, our approach is about 3.52 and 1.58 times faster than the GA-based and PSO-based methods. Additionally, given a larger input range, we observed that the performance of IDSG-DRL is more stable and its advantages are more significant.
Conclusion:
The experimental results suggest that our method is very promising to speed up IDS generation for EFSM-based testing.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The use of deep reinforcement learning to accelerate IDS derivation in EFSM-based testing shows promising results in efficiency improvement, which can be beneficial for startups in optimizing testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584922002294,Selection of human evaluators for design smell detection using dragonfly optimization algorithm: An empirical study,Sultan M.=Al Khatib: s.al-khatib@bau.edu.jo; Khalid=Alkharabsheh: khalidkh@bau.edu.jo; Sadi=Alawadi: sadi.alawadi@it.uu.se,"Abstract
Context:
Design smell detection is considered an efficient activity that decreases 
maintainability
 expenses and improves software quality. Human context plays an essential role in this domain.
Objective:
In this paper, we propose a search-based approach to optimize the selection of human 
evaluators
 for design smell detection.
Method:
For this purpose, Dragonfly Algorithm (DA) is employed to identify the optimal or near-optimal human evaluator’s profiles. An online survey is designed and asks the evaluators to evaluate a sample of classes for the presence of god class design smell. The Kappa-Fleiss test has been used to validate the proposed approach.
Results:
The results show that the dragonfly optimization algorithm can be utilized effectively to decrease the efforts (time, cost ) of design smell detection concerning the identification of the number and the optimal or near-optimal profile of human experts required for the evaluation process.
Conclusions:
A Search-based approach can be effectively used for improving a god-class design smell detection. Consequently, this leads to minimizing the maintenance cost.",March 2023,"Software quality, Design smell detection, Dragonfly Algorithm, Search-based software engineering, Optimization, God class, Empirical study",Information and Software Technology,2025-03-18T00:00:00,7.0,"This abstract presents a practical approach to optimize the selection of human evaluators for design smell detection, which can lead to cost and time savings in software development."
https://www.sciencedirect.com/science/article/pii/S0950584922002130,Metamorphic testing of Advanced Driver-Assistance System (ADAS) simulation platforms: Lane Keeping Assist System (LKAS) case studies,Tsong Yueh=Chen: tychen@swin.edu.au; Muhammad=Iqbal: mi759@uowmail.edu.au; Jia Cheng=Han: jch458@uowmail.edu.au; Zhi Quan=Zhou: zhiquan@uow.edu.au; Dave=Towey: dave.towey@nottingham.edu.cn,"Abstract
Context:
Simulation-based testing is essential when developing Advanced Driver-Assistance Systems (ADASs) and 
autonomous driving
 (AD) systems, producing fast, high-quality test results, at relatively low cost. Simulation testing relies on the quality of the ADAS simulation platform: If the simulation platform is faulty, then the simulation results may be incorrect, and hence useless. However, because of the lack of suitable test oracles — mechanisms to determine the correctness of the software output or behavior — it can be too difficult (or expensive) to verify or validate ADAS/AD simulation platforms, a situation known as the oracle problem.
Objective:
To alleviate the oracle problem and better understand ADAS simulation software.
Methods:
We develop geometric-transformation-based metamorphic testing approaches, and report on empirical studies conducted on the verification and validation (V&V) of three popular simulation platforms for ADAS development: 
Simulink
, CarMaker and 51Sim-One Cloud. Our examination focused on the platforms’ Lane Keeping Assist Systems (LKASs).
Results:
When tested with ordinary (traditional) test cases, no issues were identified on any simulation platform. However, after applying geometric-transformation-based metamorphic testing, issues were revealed, some of which were later confirmed by the MATLAB and IPG Automotive teams. To the best of our knowledge, this paper is the first to report on real bugs and issues in ADAS simulation platforms.
Conclusion:
Our research shows the simplicity, effectiveness and applicability of the proposed approach for ADAS simulation testing. This paper also provides successful examples of incorporating metamorphic testing into the testing of ADAS standards and protocols, and shows how practitioners can design effective metamorphic relations (MRs) inspired by using the symmetry metamorphic relation pattern.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"This abstract introduces a novel approach to detect real bugs in ADAS simulation platforms, which is crucial for the development of Advanced Driver-Assistance Systems and autonomous driving systems, impacting safety and reliability."
https://www.sciencedirect.com/science/article/pii/S0950584922001689,"Theories in Agile Software Development: Past, Present, and Future Introduction to the XP 2020 Special Section",,"Abstract
Over the last two decades, agile software development has gained popularity among software engineering researchers and practitioners. However, the development and use of theories in agile research remain relatively low. While analyzing publications on agile software development in the Scopus database from the last decade, we found that only 7% of the papers used or developed a theory. This trend seems stable. However, it is promising that most theory-centric studies use or propose theories to address cognitive and behavioral aspects of people working in agile development. We argue that these aspects build fundamental pillars in agile software development. In this special section, we introduce extended versions of four papers selected from the XP2020 Conference. These papers make valuable contributions to aspects of learning and behavior in agile software development. We encourage researchers to be more theory-centric in their future empirical studies of agile methods and practices by familiarizing themselves with existing theories and applying and developing theories. This way, they can contribute to a reliable, evidence-based body of knowledge in our community.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the encouragement for researchers to be more theory-centric in agile software development studies is valuable, the practical impact on European early-stage ventures may be limited as it focuses more on research methodologies than direct application."
https://www.sciencedirect.com/science/article/pii/S0950584922002245,Comparison of multi-criteria decision-making methods for online controlled experiments in a launch decision-making framework,Jie J.W.=Wu: jiewu@gwu.edu,"Abstract
Context
User-intensive software systems such as Web and mobile applications are defined as systems that serve and interact with an increasingly large number of users. Inefficient launch decisions in user-intensive systems in domains such as social media, information retrieval and e-commerce can lead to dramatic loss in the goal metrics of these highly scalable applications, and therefore impact potentially billions of users.
Objective
Due to the complexity of user-intensive systems, engineers rely heavily on A/B testing (i.e., online controlled experiments) to evaluate and measure the impact of new changes. However, little attention has been paid to improve the empirical process of making launch decisions based on the A/B testing results. In this paper, we propose a framework to address this issue.
Method
We propose a Multi-Criteria Decision Making (MCDM) framework that uses A/B testing results to provide launch 
decisions analysis
, as a complementary tool to assist decision making. The framework includes modules for 1) configuration setup, 2) criteria weighting, 3) 
pairwise comparison
 between criteria and alternatives 4) analysis of alternatives using MCDM and produces launch decisions based on the A/B testing results.
Results
Experimental results from publicly available dataset that compares well-known and widely applied MDCM methods shows that a good combination of the Analysis of Alternative method (such as TOPSIS-Vector, MMOORA, and VIKOR) and Criteria Weighting method (such as Standard Deviation) in the framework can effectively assistlaunch decision making.
Conclusion
We formulate the problem of launch decision making using A/B testing results and propose a MCDM based framework for it, as an imperfect first step to address this problem. The experiments suggest that 
MCDM methods
 such as 
TOPSIS
, MMOORA and 
VIKOR
 may be effective at making launch decisions based on A/B testing results.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract proposes a framework to improve launch decisions for user-intensive systems, addressing the need for better decision-making tools in A/B testing, which can have a significant impact on the success of web and mobile applications."
https://www.sciencedirect.com/science/article/pii/S0950584922002385,A probabilistic framework for mutation testing in deep neural networks,Florian=Tambon: florian-2.tambon@polymtl.ca,"Abstract
Context:
Mutation Testing (MT) is an important tool in traditional 
Software Engineering
 (SE) white-box testing. It aims to artificially inject faults in a system to evaluate a test suite’s capability to detect them, assuming that the test suite defects finding capability will then translate to real faults. If MT has long been used in SE, it is only recently that it started gaining the attention of the 
Deep Learning
 (DL) community, with researchers adapting it to improve the 
testability
 of 
DL models
 and improve the trustworthiness of 
DL systems
.
Objective:
If several techniques have been proposed for MT, most of them neglected the 
stochasticity
 inherent to DL resulting from the training phase. Even the latest MT approaches in DL, which propose to tackle MT through a 
statistical approach
, might give inconsistent results. Indeed, as their 
statistic
 is based on a 
fixed set
 of sampled training instances, it can lead to different results across instances set when results should be consistent for any instance.
Methods:
In this work, we propose a Probabilistic Mutation Testing (PMT) approach that alleviates the inconsistency problem and allows for a more consistent decision on whether a mutant is killed or not.
Results:
We show that PMT effectively allows a more consistent and informed decision on mutations through evaluation using three models and eight 
mutation operators
 used in previously proposed 
MT methods
. We also analyze the trade-off between the 
approximation
 error and the cost of our method, showing that relatively small error can be achieved for a manageable cost.
Conclusion:
Our results showed the limitation of current MT practices in 
DNN
 and the need to rethink them. We believe PMT is the first step in that direction which effectively removes the lack of consistency across test executions of previous methods caused by the 
stochasticity
 of 
DNN
 training.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"This abstract presents a new Probabilistic Mutation Testing approach to improve the testability of Deep Learning models, addressing a critical need to enhance the trustworthiness of DL systems, with potential implications for various industries."
https://www.sciencedirect.com/science/article/pii/S0950584922002269,PAFL: Probabilistic Automaton-based Fault Localization for Recurrent Neural Networks,Yuta=Ishimoto: ishimoto@posl.ait.kyushu-u.ac.jp; Masanari=Kondo: kondo@ait.kyushu-u.ac.jp; Naoyasu=Ubayashi: ubayashi@ait.kyushu-u.ac.jp; Yasutaka=Kamei: kamei@ait.kyushu-u.ac.jp,"Abstract
Context:
If 
deep learning
 models in safety–critical systems misbehave, serious accidents may occur. Previous studies have proposed approaches to overcome such misbehavior by detecting and modifying the responsible faulty parts in 
deep learning
 models. For example, 
fault localization
 has been applied to 
deep neural networks
 to detect neurons that cause misbehavior.
Objective:
However, such approaches are not applicable to 
deep learning models
 that have 
internal states
, which change dynamically based on the input 
data samples
 (e.g., 
recurrent neural networks
 (RNNs)). Hence, we propose a new fault localization approach to be applied to RNNs.
Methods:
We propose 
probabilistic automaton-based fault localization (PAFL)
. PAFL enables developers to detect faulty parts even in RNNs by computing 
suspiciousness
 scores
 with fault localization using 
n
-grams. We convert RNNs into 
probabilistic 
finite automata
 (PFAs)
 and localize faulty sequences of 
state transitions
 on PFAs. To consider various sequences and to detect faulty ones more precisely, we use 
n
-grams inspired by 
natural language processing
. Additionally, we distinguish data samples related to the misbehavior to evaluate PAFL. We also propose a novel suspiciousness score, 
average
 
n
-gram suspiciousness (ANS) score
, based on 
n
-grams to distinguish data samples. We evaluate PAFL and ANS scores on eight publicly available datasets on three RNN variants: simple 
recurrent
 neural network, 
gated recurrent units
, and long short-term memory.
Results:
The experiment demonstrates that ANS scores identify faulty parts of RNNs when 
n
 is greater than one. Moreover, PAFL is statistically significantly better and has large 
effect sizes
 compared to state-of-the-art fault localization in terms of distinguishing data samples related to the misbehavior. Specifically, PAFL is better in 66.74% of the experimental settings.
Conclusion:
The results demonstrate that PAFL can be used to detect faulty parts in RNNs. Hence, in future studies, PAFL can be used as a baseline for fault localization in RNNs.",March 2023,"Fault localization, Faults, Recurrent neural networks, n-gram, Probabilistic finite automata",Information and Software Technology,2025-03-18T00:00:00,10.0,"This abstract introduces a new fault localization approach for RNNs, addressing a critical issue in deep learning models with internal states. The proposed method demonstrates significant improvements in detecting faulty parts, which can impact the safety and reliability of deep learning models in safety-critical systems."
https://www.sciencedirect.com/science/article/pii/S095058492200194X,Exploring granular test coverage and its evolution with matrix visualizations,Kaj=Dreef: kdreef@uci.edu; Vijay Krishna=Palepu: Vijay.Palepu@microsoft.com; James A.=Jones: jajones@uci.edu,"Abstract
Context:
Current software-development tools that are used in practice make understanding the test execution of software difficult, for both granular tasks (
e.g.,
 answering questions such as, “which test cases execute this method?”) and global tasks (
e.g.,
 answering questions such as, “what is the proportion of unit tests to system tests?”). Current tools typically support local, file-based views of a project’s test suite and its execution data, and rarely offer a global overview. Even more rarely, do they provide access to historical information of this nature. Such global overviews can provide a larger context for a method’s execution by test cases; help identify other similar, or related methods; and even reveal similarity between individual tests.
Objective:
This work approaches such challenges with a novel, interactive, matrix-based visual interface that provides a global overview of a software project’s test suite, specifically in the context of the methods available in the project’s codebase. Through a series of interactive functions to sort, filter, query, and explore a test-matrix visualization, we evaluate how developers can effectively answer questions about their project’s test suite, and the code executed by such tests.
Method:
We built a dynamic test-suite analysis and software-visualization tool that implements our designed interface to address the challenges of understanding the testing of software systems. With this implementation, we conducted a user study of 20 software developers to assess their ability to understand and report test execution information and measured accuracy and time. Additionally, we present a series of 
case studies
 to demonstrate a number of insights that our tool reveals.
Results:
Our evaluations, performed on 
26
 real-world software systems, show that the interactive visualization assisted developers to answer questions about software tests and the code they execute. Further, the visualization consistently outperforms traditional development tools, both in accuracy and time taken to complete software-engineering tasks.
Conclusion:
Global-overview test matrices offer novel perspectives on test-suite composition, which can guide software development and testing practices.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The research provides a practical tool for software developers to improve understanding of test execution, showing performance improvement over existing methods."
https://www.sciencedirect.com/science/article/pii/S0950584922002154,Lessons learned to improve the UX practices in agile projects involving data science and process automation,Bruna=Ferreira: bruna@exacta.inf.puc-rio.br,"Abstract
Context:
User-Centered Design (UCD) and 
Agile methodologies
 focus on human issues. Nevertheless, agile methodologies focus on contact with contracting customers and generating value for them. Usually, the communication between end users (they use the software and have low decision power) and the agile team is mediated by customers (they have high decision power but do not use the software). However, they do not know the actual problems that end users (may) face in their routine, and they may not be directly affected by software shortcomings. In this context, UX issues are typically identified only after the implementation, during user testing and validation.
Objective:
Aiming to improve the understanding and definition of the problem in agile projects, this research investigates the practices and difficulties experienced by agile teams during the development of data science and process automation projects. Also, we analyze the benefits and the teams’ perceptions regarding user participation in these projects.
Method:
We 
collected data
 from four agile teams, in the context of an academia and industry collaboration focusing on delivering data science and process automation solutions. Therefore, we applied a carefully designed questionnaire answered by developers, scrum masters, and UX designers. In total, 18 subjects answered the questionnaire.
Results:
From the results, we identify practices used by the teams to define and understand the problem and to represent the solution. The practices most often used are prototypes and meetings with stakeholders. Another practice that helped the team to understand the problem was using Lean Inception (LI) ideation workshops. Also, our results present some specific issues regarding data science projects.
Conclusion:
We observed that end-user participation can be critical to understanding and defining the problem. They help to define elements of the domain and barriers in the implementation. We identified a need for approaches that facilitate user-team communication in data science projects to understand the data and its value to the users’ routine. We also identified insights about the need of more detailed requirements representations to support the development of data science solutions.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The research addresses the practical challenges faced by agile teams, providing insights on improving user participation in data science projects, which can benefit early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002191,Becoming an entrepreneur: A study of factors with women from the tech sector,Jussi=Kasurinen: jussi.kasurinen@lut.fi,"Abstract
Context
The gender imbalance in technology, sciences, and engineering is a global problem and according to the statistics, this really has not changed much in the last thirty years. Moreover, there is also a lack of women in tech entrepreneurship; most success stories are about male entrepreneurs, and in Silicon Valley the term describing the start-up culture is called “tech bros” for a reason.
Objective
This paper identifies different factors affecting the women's decision to select a tech sector and become an entrepreneur in the tech sector. In this paper we also aim to identify different pitfalls and problems, which could influence the attractiveness of the tech sector, and specifically technology entrepreneurship, towards the women interested in the science, technology, and engineering domains.
Method
To study the factors affecting women's interest towards entrepreneurship in the technology sector, we conducted a series of surveys and interviews to understand the underlying phenomena. Overall, this study interviewed ten female company founders, and conducted two surveys with women working, interested, or studying towards the tech sector, allowing us to combine and compare the qualitative data from the women who had become entrepreneurs against the quantitative trends and ideas collected from the general audiences.
Results
The most common factors limiting the individuals’ interest towards entrepreneurship such as financial risks or high responsibilities might not be gender-related, but there are also aspects as social acceptance, discrimination, and lack of role models, which affect especially the women interested in the possibilities of becoming an entrepreneur in tech.
Conclusions
In general, the current 
younger generations
 are aware of the option of becoming entrepreneurs, and what becoming one requires. Initiatives, such as adding positive examples of females’ success, or supporting entry-level opportunities towards full-time entrepreneurship, could have a meaningful impact of reducing the gender imbalance in the STEM fields, and in technology entrepreneurship in general.",March 2023,"Women in tech, Entrepreneurship, Affecting factors, Equality, Gender bias",Information and Software Technology,2025-03-18T00:00:00,6.0,"This research identifies important factors affecting women's participation in tech entrepreneurship, but the direct impact on European early-stage ventures is somewhat indirect."
https://www.sciencedirect.com/science/article/pii/S0950584922002282,Understanding and predicting incident mitigation time,Zan=Wang: wangzan@tju.edu.cn; Junjie=Chen: junjiechen@tju.edu.cn; Weijing=Wang: wangweijing@tju.edu.cn; Lin=Yang: linyang@tju.edu.cn; Hongyu=Zhang: hongyu.zhang@newcastle.edu.au,"Abstract
Context:
Incident management plays a significant role in 
online service
 systems. Incidents should be mitigated as soon as possible in order to achieve high service stability. However, available resources tend to be limited, and thus engineers have to schedule their tasks carefully. Time to Mitigate (TTM) refers to the time an incident requires to restore the service availability. Predicting TTM can help better estimate maintenance efforts and provide developers more information when arranging their tasks.
Objective:
Our work aims to predict TTM precisely, which consists of two main steps. First, we perform an empirical study to understand incidents deeply. Then, we design an effective approach for TTM prediction based on the findings from the empirical study.
Methods:
In the empirical study, we used 20 Microsoft 
online service
 systems to investigate the duration of each stage in incident management and the relationship between TTM and incident indicators. Then, we propose TTMPred, a deep-learning-based approach for TTM prediction in the continuous triage scenario based on the features identified from our empirical study. In particular, we improve the generality of TTMPred by extending it to predicting the fixing time of traditional software bugs.
Results:
We investigate the effectiveness of TTMPred on four large-scale online service systems in Microsoft, as well as four widely-used Bugzilla-based projects. The results show that TTMPred performs better than the compared approaches for both incident TTM prediction and bug-fixing time prediction. For example, on average, TTMPred improves the state-of-the-art regression-based approach by 25.66% in terms of MAE (Mean Absolute Error) on the incident data and 42.14% on MAE on the bug data.
Conclusion:
TTMPred can be extended to the bug scenario, and continuously predict accurate bug-fixing time during the triage process.",March 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The predictive model for incident TTM and bug-fixing time can greatly benefit online service systems, startups, and developers in Europe by improving service stability and efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584922001999,Exploring privacy requirements gap between developers and end users,Jianzhang=Zhang: jianzhang.zhang2017@gmail.com; Jinping=Hua: huajinping@stu.hznu.edu.cn; Nan=Niu: nan.niu@uc.edu; Sisi=Chen: chensisi1@stu.hznu.edu.cn; Juha=Savolainen: juha.savolainen@danfoss.com; Chuang=Liu: liuchuang2022@sina.com,"Abstract
Context:
Privacy policies document the privacy requirements guiding developers. Though privacy policies analysis has drawn increasing attention recently, how end users perceive privacy requirements has been less explored.
Objective:
We empirically explore the privacy requirements gap between developers and end users to derive beneficial insights into users’ privacy concerns to support maintenance.
Method:
We present a semi-automatic privacy requirements gap analysis framework based on text mining including information retrieval, 
topic modeling
, and 
computational linguistic
 techniques.
Results:
The preliminary results of applying our framework to Facebook show that: (1) topic comparison reveals that both privacy related reviews and policy statements involve privacy requirements types of collection, usage, and disclosure as well as account security. The retention requirements are almost not mentioned in reviews as they are hard to be directly perceived; (2) content comparisons reveal that though overlapping with the privacy policy statements, reviews are more general, informal, and negative in wording.
Conclusion:
The illustrative example with Facebook demonstrates the potential usage of our framework in informing software maintenance, e.g., privacy relevant testing and privacy 
policy refinement
.",February 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The privacy requirements gap analysis framework is relevant for developers but may have limited direct impact on early-stage ventures in Europe compared to the other abstracts.
https://www.sciencedirect.com/science/article/pii/S0950584922002002,COSMOS: A comprehensive framework for automatically generating domain-oriented test suite,Saeed=Parsa: prasa@iust.ac.ir,"Abstract
Context
Coverage criteria are satisfied by at least one examination of the test target, while many faults are not revealed by one execution. However, despite executing the faulty statement, the test result is correct in certain circumstances. Such coincidentally passing test cases execute the faulty statement but do not cause failures.
Objective
This paper introduces the new concept of domain solver. Domain solvers attempt to detect the domain of inputs rather than a single input satisfying a path constraint. Domain coverage is a new metric to evaluate the relative accuracy of the detected domains. The promising point is that the proposed approach similarly treats nonlinear and 
linear constraints
.
Method
Domain solver splits a path constraint into conjunctions of simple conditions comparing two expressions. Such a splitting simplifies the constraint-solving task to detect regions of the input space satisfying a comparison between two expressions. After finding a region, an improved version of an algorithm, update, is used to determine the domain of variables involved in the comparing expressions.
Results
Our proposed approach, COSMOS, is implemented using the Roslyn compiler. We compared COSMOS with well-known 
constraint solvers
 using various linear/nonlinear constraints. The results show that COSMOS improves the number of supported 
data types
 involved in a constraint and solves100% of the instances in which the other solvers fail. Besides, COSMOS achieves the best relative accuracy of 84% compared to the existing domain-oriented test suite generation approaches. Moreover, our experiment results illustrate that COSMOS improves the fault-finding capability of other existing test coverage criteria by detecting coincidentally correct test cases.
Conclusion
Combining domain coverage and compiler as a service makes a powerful 
constraint satisfaction
 method outperforming the existing 
constraint solvers
 regarding the number of solved linear/nonlinear constraints. Augmenting other structural test coverage criteria with domain coverage reveals the coincidentally correct test cases.",February 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The proposed approach of COSMOS shows significant improvement in solving linear/nonlinear constraints compared to existing solvers. This can have a practical impact on early-stage ventures dealing with constraint-based problems.
https://www.sciencedirect.com/science/article/pii/S0950584922002099,A property specification pattern catalog for real-time system verification with UPPAAL,Thomas=Vogel: thomas.vogel@informatik.hu-berlin.de; Marc=Carwehl: carwehl@informatik.hu-berlin.de,"Abstract
Context:
The goal of specification pattern catalogs for real-time requirements is to mask the complexity of specifying such requirements in a timed temporal logic for verification. For this purpose, they provide frontends to express and translate pattern-based natural language requirements to formulae in a suitable logic. However, the widely used real-time model checking tool UPPAAL only supports a restricted subset of those formulae that focus only on basic and non-nested reachability, safety, and 
liveness properties
. This restriction renders many specification patterns inapplicable. As a workaround, timed observer 
automata
 need to be constructed manually to express sophisticated requirements envisioned by these patterns.
Objective:
In this work, we fill these gaps by providing a comprehensive specification pattern catalog for UPPAAL. The catalog supports qualitative and real-time requirements and covers all corresponding patterns of existing catalogs.
Method:
The catalog we propose is integrated with UPPAAL. It supports the specification of qualitative and real-time requirements using patterns and provides an automated generator that translates these requirements to observer 
automata
 and TCTL formulae. The resulting artifacts are used for verifying systems modeled as 
timed automata
 in UPPAAL. Thus, our catalog enables an automated end-to-end 
verification process
 for UPPAAL based on property specification patterns and observer automata.
Results:
We evaluate our catalog on three UPPAAL system models reported in the literature and mostly applied in an industrial setting. As a result, not only the reproducibility of the related UPPAAL models was possible, but also the validation of an automated, seamless, and accurate pattern- and observer-based 
verification process
.
Conclusion:
The proposed property specification pattern catalog for UPPAAL enables practitioners to specify qualitative and real-time requirements in a pattern-based way – without directly using a temporal logic – and to verify them in UPPAAL while supporting a comprehensive set of patterns.",February 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The catalog for UPPAAL fills a significant gap in supporting a comprehensive set of qualitative and real-time requirements. This can be highly beneficial for startups working on system verification and validation.
https://www.sciencedirect.com/science/article/pii/S0950584922002105,Assessing attitudes towards evidence-based software engineering in a government agency,Sebastián=Pizard: spizard@fing.edu.uy,"Abstract
Context:
Evidence-based practice (EBP) has allowed several disciplines to become more mature by emphasizing the use of evidence from well-designed and well-conducted research in decision-making. Its application in 
SE
, Evidence-based software engineering (EBSE) can help to bridge the gap between academia and 
industry
 by bringing together academic rigor and research of practical relevance. To achieve this, it seems necessary to improve its adoption.
Objective:
We sought both to study the attitudes towards EBSE of stakeholders working in a government agency (GA) and to assess whether knowledge of EBSE would impact their working practices.
Method:
We conducted a multi-stage field investigation in an Uruguayan national GA that is responsible for digital policies. First, we organized an EBSE awareness lecture and we collected and analyzed participants’ perceptions of the value and limitations of EBSE. Sixteen months later, in a second stage, we contacted the agency and asked participants whether they had made use of the information about EBSE we presented to them.
Results:
Initially, participants reported that EBSE seemed useful for tackling challenging problems and, in particular, considered its use appropriate given the agency’s responsibilities. Perceived barriers to EBSE adoption were the need for institutional support, the lack of government practice reports, inadequate skills or motivation, the cost of conducting 
systematic reviews
, and the lack of evidence about emerging issues. In the follow-up survey, although the participants were not undertaking 
systematic reviews
 themselves, many reported improvements in how they searched for and evaluated information to support their work.
Conclusion:
Our study presents some insights to better understand EBSE adoption. With the exception of GA-specific issues, perceived value and barriers to adoption were consistent with those reported in software engineering and other disciplines. Our follow-up study confirms the potential value of evidence in the context of IT regulatory and government bodies.",February 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Studying the attitudes towards EBSE and its impact on working practices provides valuable insights, but the direct practical implications for startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002129,Crowdtesting Practices and Models: An Empirical Approach,Li=Zhang: laridzhang@gmail.com; Shufeng=Hu: hushufeng@msn.com; Zizheng=Fan: 1027174871@qq.com; Qianyu=Wang: by2006163@buaa.edu.cn,"Abstract
Context
Crowdsourced software testing (CST) has received significant attention. After these years, CST has made new progress and changes.
Objective
While current literature lists many CST challenges, this paper analyzes industrial CST practices, finds that many challenges already have practical solutions, summarizes their commonalities, and comes up with new CST models and processes.
Method
We look for well-known CST websites to participate in and take a secret and unobtrusive approach where customers, platform managers, and fellow workers do not know that we are mainly interested in CST research. We then register at selected CST websites, collect any public documents such as whitepapers, open rules, and public training materials, and join as many test tasks as possible.
Results
We analyze the confrontation and collaboration among clients, platforms, and workers in the CST sessions. Clients want to get as much bug information as possible for a small amount of pay, but workers want to get paid as much as possible for a small amount of bug information. We also study the process and method of selecting suitable CST workers. Based on these, this paper proposes three future research directions.
Conclusion
Data security and privacy at CST are paramount. If this problem can be overcome, CST will have wider applications. Additionally, the integration of workers, internal workers, software automation, and 
artificial intelligence
 will be major drivers for CST. It is also critical to develop a standardized CST structure and processes, and this will push the field to grow significantly.",February 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"While the analysis of CST practices and future research directions are interesting, the direct application and impact on European early-stage ventures may not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001938,Visualizations for the evolution of Variant-Rich Systems: A systematic mapping study,Raul=Medeiros: raul.medeiros@ehu.eus; Jabier=Martinez: jabier.martinez@tecnalia.com; Oscar=Díaz: oscar.diaz@ehu.eus; Jean-Rémy=Falleri: falleri@labri.fr,"Abstract
Context:
Variant-Rich Systems (VRSs), such as Software Product Lines or variants created through clone & own, aim at reusing existing assets. The long lifespan of families of variants, and the scale of both the code base and the workforce make VRS maintenance and evolution a challenge. Visualization tools are a needed companion.
Objective:
We aim at mapping the current state of visualization interventions in the area of VRS evolution. We tackle evolution in both functionality and architecture. Three research questions are posed: What sort of analysis is being conducted to assess VRS evolution? (Analysis perspective); What sort of visualizations are displayed? (Visualization perspective); What is the research maturity of the reported interventions? (Maturity perspective).
Methods:
We performed a 
systematic mapping study
 including automated search in digital libraries, expert knowledge, and snowballing.
Results:
The study reports on 41 visualization approaches to cope with VRS evolution. Analysis wise, feature identification and location is the most popular scenario, followed by variant integration towards a Software Product Line. As for visualization, nodelink diagram visualization is predominant while researchers have come up with a wealth of ingenious visualization approaches. Finally, maturity wise, almost half of the studies are solution proposals. Most of the studies provide proof-of-concept, some of them also include publicly available tools, yet very few 
face
 proof-of-value.
Conclusions:
This study introduces a comparison framework where to frame future studies. It also points out distinct research gaps worth investigating as well as shortcomings in the evidence about relevance and contextual considerations (e.g., scalability).",February 2023,"Variant-rich systems, Software product lines, Visualization, Evolution, Maintenance, Mapping study",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on visualization interventions in VRS evolution offers valuable insights, but the immediate practical value for startups may be more long-term compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001987,CADV: A software visualization approach for code annotations distribution,Phyllipe=Lima: phyllipe@unifei.edu.br; Jorge=Melegati: jorge@jmelegati.com; Everaldo=Gomes: everaldogjr@gmail.com; Nathalya Stefhany=Pereira: nathalya.stefhany@gec.inatel.br; Eduardo=Guerra: eduardo.guerra@unibz.it; Paulo=Meirelles: paulo.meirelles@ufabc.edu.br,"Abstract
Context:
Code annotations
 is a widely used feature in Java systems to configure custom metadata on programming elements. Their increasing presence creates the need for approaches to assess and comprehend their usage and distribution. In this context, software visualization has been studied and researched to improve 
program comprehension
 in different aspects.
Objectives:
This study aimed at designing a software visualization approach that graphically displays how code annotations are distributed and organized in a software system and developing a tool, as a reference implementation of the approach, to generate views and interact with users.
Methods:
We conducted an empirical evaluation through questionnaires and interviews to evaluate our visualization approach considering four aspects: (i) effectiveness for 
program comprehension
, (ii) perceived usefulness, (iv) perceived ease of use, and (iv) suitability for the intended audience. The resulting data was used to perform a qualitative and quantitative analysis.
Results:
The tool identifies package responsibilities providing visual information about their annotations at different levels. Using the developed tool, the participants achieved a high correctness rate in the program comprehension tasks and performed very well in questions about the overview of the system under analysis. Finally, participants perceived that the tool is suitable to visualize the distribution of code annotations.
Conclusions:
The results show that the visualization approach using the developed tool is effective in program comprehension tasks related to code annotations, which can also be used to identify responsibilities in the application packages. Moreover, it was evaluated as suitable for newcomers to overview the usage of annotations in the system and for architects to perform a deep analysis that can potentially detect misplaced annotations and abnormal growths on their usage.",February 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The visualization approach and tool developed have practical value for improving program comprehension and identifying code annotations, which can benefit early-stage ventures in software development."
https://www.sciencedirect.com/science/article/pii/S0950584922001951,Increasing the UX maturity level of clients: A study of best practices in an agile environment,"Elaine, E.G.=Buis: elainebuis@gmail.com","Abstract
Context
While multiple studies have attempted to define and measure 
User Experience
 (UX) Maturity — i.e., how familiar organizations are with UX concepts or strategies— more practice-based insight is needed to examine how UX practitioners maneuver in their relationships with low UX Maturity organizations and help these clients become more ‘UX Mature’.
Objective
This study evaluates how UX practitioners work with low UX Maturity clients, what obstacles they face, and how they cope with these obstacles. From these insights, a set of best practices are identified for UX practitioners who work with low UX Maturity clients and wish to increase their clients’ UX maturity in an agile environment.
Method
These best practices were collected in the form of 
case studies
, involving a total of 20 case studies based on interviews with 22 UX practitioners. The case studies reflect on past projects that were conducted for clients with a low UX Maturity level. Data was obtained through semi-structured interviews and analyzed using a grounded theory approach combined with elements of a thematic analysis.
Results
The results help to identify frequently experienced obstacles in working with low UX Maturity organizations, as well as six best practices for increasing the UX Maturity of these clients.
Conclusions
The study results demonstrate that UX practitioners indeed fulfill a significant role in overcoming organizational UX boundaries. A Low UX Maturity Best Practice model was developed, which summarizes how UX practitioners can optimize their impact in working with low UX Maturity clients, while simultaneously contributing to a more user-centered focus on the part of their clients.",February 2023,"Client-UX relationship, Case study, UX maturity, Agile UX, UX practitioners, UX strategy, Best practices",Information and Software Technology,2025-03-18T00:00:00,10.0,"The study provides insights and best practices for UX practitioners working with low UX Maturity clients, which can have a significant impact on early-stage ventures focusing on user experience and product development."
https://www.sciencedirect.com/science/article/pii/S0950584922001963,Service Design Handover to user experience design – a systematic literature review,Aarne=Leinonen: aarne.leinonen@aalto.fi; Virpi=Roto: virpi.roto@aalto.fi,"Abstract
Context:
Knowledge transfer plays an important role in digital Service Creation Projects where information should flow through service design, Agile UX, and software implementation phases. One context for these 
handovers
 exists in projects where the service designers participate in the early phases of exploring and scoping the service, while agile 
user experience
 specialists take over the digital parts of service design and programmers the software implementation.
Objective:
The purpose of this study is to summarise 
scientific knowledge
 into best practices for effective information flow in real world Service Creation Projects. 
Special attention
 is paid on an important and understudied project phase, knowledge handover from service design to software implementation, which is referred as Service Design Handover in this study.
Method:
A 
systematic literature review
 was conducted to analyse the current scientific knowledge on knowledge transfer in digital Service Creation Projects. PRISMA 2020 statement was used for reporting the review, which also influenced planning and execution of the systematic review process. SCOPUS search brought up 773 publications, and the full content analysis was done for the 41 most relevant publications.
Results:
Based on the literature analysis, the best practices for effective knowledge transfer are related to communication quality and quantity, circumventing the need for communication, and verifying successful communication. To provide an overview of effective knowledge transfer, frameworks of Service Creation Project information flow and Service Design Handover are proposed.
Conclusion:
The existing knowledge transfer literature is voluminous, but this literature review is the first to study knowledge transfer in Service Creation Project context. The framework, best practices, and list of potential problem sources in knowledge transfer provide new knowledge for managing the information flow in service creation. The research gaps found in this literature review show the need for future research, such as empirical studies on service creation practice.",February 2023,"Knowledge transfer, Service Design Handover, Systematic literature review, UX design, Agile UX, Design process",Information and Software Technology,2025-03-18T00:00:00,7.0,"The best practices identified for effective knowledge transfer in Service Creation Projects can benefit early-stage ventures, especially startups involved in digital service design and implementation."
https://www.sciencedirect.com/science/article/pii/S0950584922002166,"Does maturity level influence the use of Agile UX methods by digital startups? Evaluating design thinking, lean startup, and lean user experience",Fernando Henrique=Lermen: fernando-lermen@hotmail.com,"Abstract
Context
Agile UX methods such as Design Thinking, 
Lean Startup
, and Lean 
User Experience
 have been employed to deliver customer value and improve organizational performance. However, there is a lack of studies that assess how these tools are used at different stages of maturity of digital startups.
Objective
The present study aims to compare the knowledge of graduated, incubated, and pre-incubated digital startups at university 
incubators
 concerning the use of Agile UX methods so that weaknesses and opportunities can be identified to provide co founders and scholars with new strategic insights.
Method
Six reduced focus groups were conducted with 14 members of the six selected startups via multiple 
case studies
. Answers were registered by researchers and then analyzed using an inductive process and codification.
Results
The results indicated that digital startups had contact with consumers through market research, viability analysis, and product discontinuity. However, except for one startup, deficiencies in co-founders' participation throughout developing products and services projects were identified. As far as the multiple 
case studies
 are concerned, Design Thinking and 
Lean Startup
 were employed by four of the startups, while two of them used the Lean 
User Experience
 method due to its higher maturity level.
Conclusion
Although all Agile UX methods were employed, all six digital startups reported having made adaptations to the methods or to have used them only partially. Finally, it was concluded that the maturity level influences the Agile UX methods of each digital startup according to its nature and its stage of development in the market.",February 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"By comparing Agile UX methods knowledge among different stages of digital startups, this study provides strategic insights that can be valuable for early-stage ventures in improving customer value delivery and organizational performance."
https://www.sciencedirect.com/science/article/pii/S0950584922001872,Community smells—The sources of social debt: A systematic literature review,Jeffrey C.=Carver: carver@cs.ua.edu; Eduardo=Caballero-Espinosa: eduardo.caballero@utp.ac.pa; Kimberly=Stowers: kim.stwrs@gmail.com,"Abstract
Context:
Social debt describes the accumulation of unforeseen project costs (or potential costs) from sub-optimal software 
development processes
. Community smells are sociotechnical anti-patterns and one source of social debt. Because community smells impact software teams, 
development processes
, outcomes, and organizations, we to understand their impact on 
software engineering
.
Objective:
To provide an overview of community smells in social debt, based on published literature, and describe future research.
Method:
We conducted a systematic literature review (SLR) to identify properties, understand origins and evolution, and describe the emergence of community smells. This SLR explains the impact of community smells on teamwork and team performance.
Results:
We include 25 studies. Social debt describes the impacts of poor socio-technical decisions on work environments, people, software products, and society. For each of the 30 community smells identified as sources of social debt, we provide a detailed description, management approaches, organizational strategies, and mitigation effectiveness. We identify five groups of management approaches: organizational strategies, frameworks, models, tools, and guidelines. We describe 11 common properties of community smells. We develop the 
Community Smell Stages Framework
 to concisely describe the origin and evolution of community smells. We then describe the causes and effects for each community smell. We identify and describe 8 types of causes and 11 types of effects related to the community smells. Finally, we provide 8 comprehensive Sankey diagrams that offer insights into threats the community smells pose to teamwork factors and team performance.
Conclusion:
Community smells explain the influence work conditions have on software developers. The literature is scarce and focuses on a small number of community smells. Thus, the community smells still need more research. This review helps by organizing the state of the art about community smells. Our contributions provide motivations for future research and provide educational material for 
software engineering
 professionals.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract provides comprehensive insights into community smells in social debt and offers management approaches, strategies, and frameworks. This can be valuable for early-stage ventures to optimize their software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584922001574,Constrained detecting arrays: Mathematical structures for fault identification in combinatorial interaction testing,Hao=Jin: k-kou@ist.osaka-u.ac.jp; Ce=Shi: shice060@lixin.edu.cn; Tatsuhiro=Tsuchiya: t-tutiya@ist.osaka-u.ac.jp,"Abstract
Context:
Detecting arrays are mathematical structures aimed at fault identification in combinatorial interaction testing. However, they cannot be directly applied to systems that have constraints on the test parameters. These constraints are prevalent in real-world systems.
Objective:
This paper proposes constrained detecting arrays (CDAs), an extension of detecting arrays, which can be used for systems with constraints.
Methods:
The properties and capabilities of CDAs are examined with rigorous arguments. Moreover, two algorithms are proposed for constructing CDAs: one is aimed at generating minimum CDAs, and the other is a heuristic algorithm aimed at fast generation of CDAs. The algorithms were experimentally evaluated using a benchmark dataset.
Results:
Experimental results show that the first algorithm can generate minimum CDAs if a sufficiently long generation time is allowed, and the second algorithm can generate minimum or near-minimum CDAs in a reasonable time.
Conclusion:
CDAs extend the range of application of detecting arrays to systems with constraints. The two proposed algorithms have different advantages with respect to array size and generation time.",January 2023,"Combinatorial interaction testing, Detecting arrays, Constraint handling, Fault identification",Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract introduces constrained detecting arrays as an extension of detecting arrays, which can be useful for systems with constraints. While the topic is relevant, the direct impact on European early-stage ventures might be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922001756,Memorization and generalization in neural code intelligence models,Md Rafiqul Islam=Rabin: mrabin@uh.edu,"Abstract
Context:
Deep Neural Networks
 (DNNs) are increasingly being used in 
software engineering
 and code intelligence tasks. These are powerful tools that are capable of learning highly 
generalizable
 patterns from large datasets through millions of parameters. At the same time, their large capacity can render them prone to 
memorizing
 data points. Recent work suggests that the memorization risk manifests especially strongly when the training dataset is noisy, involving many ambiguous or questionable samples, and memorization is the only recourse.
Objective:
The goal of this paper is to evaluate and compare the extent of memorization and generalization in neural code intelligence models. It aims to provide insights on how memorization may impact the learning behavior of 
neural models
 in code intelligence systems.
Method:
To observe the extent of memorization in models, we add random noise to the original training dataset and use various metrics to quantify the impact of noise on various aspects of training and testing. We evaluate several state-of-the-art neural code intelligence models and benchmarks based on Java, Python, and Ruby codebases.
Results:
Our results highlight important risks: millions of trainable parameters allow the 
neural networks
 to memorize 
anything
, including noisy data, and provide a false sense of generalization. We observed all models manifest some forms of memorization. This can be potentially troublesome in most code intelligence tasks where they rely on rather noise-prone and repetitive 
data sources
, such as code from GitHub.
Conclusion:
To the best of our knowledge, we provide the first study to quantify memorization effects in the domain of 
software engineering
 and code intelligence systems. This work raises awareness and provides new insights into important issues of training 
neural models
 in code intelligence systems that are usually overlooked by software engineering researchers.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract provides insights into the memorization effects in neural code intelligence models, which can be crucial for startups utilizing deep neural networks in software engineering tasks. The findings can help startups optimize their model training processes."
https://www.sciencedirect.com/science/article/pii/S0883902624000910,Regulatory institutions and cross-country differences in high-growth entrepreneurship rates: A configurational approach,Veroniek=Collewaert: veroniek.collewaert@vlerick.com,"Abstract
Regulatory institutions are double-edged swords: stricter regulations can improve entrepreneurs' access to key resources but also constrain their discretion. Past research has focused on the individual and/or independent influence of regulatory institutions, calling for stricter regulation 
or
 deregulation. However, institutional theory suggests that the full configuration of regulatory institutions, including their possibly complex interactions, drives the trade-off between resource access and the constraints imposed by resource providers. Using an inductive approach and fsQCA analysis, we aim to better understand how configurations of regulatory institutions and contextual conditions influence high-growth entrepreneurship (HGE) rates across European countries. We find that three distinct configurations explain high country-level HGE rates, which include different regulatory institutions that sometimes work in opposing ways and do not necessarily work universally across contexts. Overall, this study deepens research at the nexus of institutional theory and high-growth entrepreneurship.",March 2025,Not Found,Business Venturing,2025-03-21T00:00:00,5.0,"The research on regulatory institutions and high-growth entrepreneurship rates provides valuable insights for policymakers and entrepreneurs, highlighting the complex interactions that influence resource access and constraints."
https://www.sciencedirect.com/science/article/pii/S0950584922001768,Exploring the challenges in software testing of the 5G system at Nokia: A survey,Lech=Madeyski: lech.madeyski@pwr.edu.pl,"Abstract
Context:
The ever-growing size and complexity of industrial software products pose significant quality assurance challenges to engineering researchers and practitioners, despite the constant effort to increase knowledge and improve the processes. 5G technology developed by Nokia is one example of such a grand and highly complex system with improvement potential.
Objective:
The following paper provides an overview of the current quality assurance processes used by Nokia to develop the 5G technology and provides insight into the most prominent challenges by an evaluation of perceived importance, urgency, and difficulty to understand the future opportunities.
Method:
Nokia mode of operation, briefly introduced in this paper, has been subjected to extensive analysis by a selected group of experienced test-oriented professionals to define the most critical areas of concern. Secondly, the identified problems were evaluated by Nokia gNB system-level test professionals in a dedicated survey.
Results:
The questionnaire was completed by 312 out of 2935 (10.63%) possible respondents. The challenges are seen as the most important and urgent: customer scenario testing, performance testing, and competence ramp-up. Challenges seen as the most difficult to solve are low occurrence failures, hidden feature dependencies, and hardware configuration-specific problems.
Conclusions:
Our research identified several improvement areas in the quality assurance processes used to develop the 5G technology by determining the most important and urgent problems that at the same time have a low perceived difficulty. Such initiatives are attractive from a business perspective. On the other hand, challenges seen as the most impactful yet difficult may be of interest to the academic research community.",January 2023,"0000, 1111",Information and Software Technology,2025-03-18T00:00:00,7.0,"The research provides valuable insights into quality assurance processes for developing 5G technology by Nokia, highlighting important challenges and improvement areas. This can have a practical impact on early-stage ventures in the tech industry."
https://www.sciencedirect.com/science/article/pii/S0950584922001744,Machine translation-based fine-grained comments generation for solidity smart contracts,Chaochen=Shi: shicha@deakin.edu.au; Yong=Xiang: yong.xiang@deakin.edu.au; Jiangshan=Yu: jiangshan.yu@monash.edu; Keshav=Sood: keshav.sood@deakin.edu.au,"Abstract
Context.
As self-executing programs on 
blockchain
 platforms, 
smart contracts
 can build a trusted environment between multi-parties. However, participants who lack programming knowledge usually have difficulties understanding 
smart contracts
 by reading the 
source code
. It brings them difficulties and risks when interacting with decentralized applications.
Objective.
We aim to translate the smart contract 
source code
 into natural language descriptions as fine-grained in-line comments to help people better understand, learn and operate smart contracts.
Method.
We propose an automated translation approach for smart contracts written in Solidity, termed SolcTrans, based on an Syntax Tree (AST) and formal grammar. We have investigated representative Solidity smart contracts, identified the AST 
parsing
 paths and core attributes used for translation, and proposed corresponding translation templates for special statements. Then, we leveraged 
reinforcement learning
 to train a Probabilistic Context-Free Grammar-based syntax synthesizer used to generate comprehensible English sentences as comments.
Result.
The experimental results show that SolcTrans outperforms four state-of-the-art neural machine 
translation models
 under currently available 
training data
 and is less affected by lengths of code snippets and translation outputs. We also conducted a human evaluation among 20 volunteers and asked them to score the generated comments. The results demonstrate that SolcTrans performs well on three metrics: Accuracy, Readability, and Instructiveness.
Conclusion.
Our approach produces high-quality fine-grained comments for smart contract source code under the small training dataset, which creates a paradigm for future studies.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The approach of translating smart contract source code into natural language descriptions can greatly benefit participants without programming knowledge. This innovation has the potential to improve accessibility and reduce risks for startups in the blockchain industry.
https://www.sciencedirect.com/science/article/pii/S095058492200177X,Integrating DSGEO into test case generation for path coverage of MPI programs,Xiangjuan=Yao: yaoxj@cumt.edu.cn; Dunwei=Gong: dwgong@vip.163.com,"Abstract
Context:
When testing a 
M
essage-
P
assing 
I
nterface (MPI) program composed of multiple processes, the testing cost for each process is different, and those expensive processes restrict the testing efficiency of the entire MPI program.
Objective:
To overcome this limitation, this paper proposes an approach to integrating 
d
istributed-
s
urrogate-
g
uided 
e
volutionary 
o
ptimization (DSGEO) into test case generation for path coverage of MPI programs.
Method:
In the proposed approach, we first determine each expensive process and its input variables, and generate a sample set for the determined process, which is used to train a 
surrogate model
. Then, the fitness components of a test case in those expensive processes are estimated by the corresponding surrogate models, and are then combined with the real fitness components of the test case in cheap processes to form the fitness estimation. Finally, we select a small number of test cases with good fitness estimations to execute the MPI program, and calculate their real fitness to guide the subsequent test case generation.
Results:
We use the proposed approach to seven benchmark MPI programs and compare with four state-of-the-art approaches. The experimental results show that the proposed approach can significantly decrease the cost for test case generation.
Conclusion:
The proposed approach is also applicable to more complex MPI programs, thus supporting the scalability of the proposed approach.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed approach for test case generation in MPI programs shows a significant decrease in testing costs, which can be beneficial for startups working on distributed systems. The scalability of the approach adds to its practical value."
https://www.sciencedirect.com/science/article/pii/S0950584922001884,Mastering scrum with a focus on team maturity and key components of scrum,Maja Due=Kadenic: Maja@btech.au.dk,"Abstract
Context
Several studies contribute with valuable insights into agile teamwork performance. Currently, Scrum is dominating the industrial 
agile software development
 practices. Yet, there is a lack of studies that directly explores the role of team maturity and key components of the Scrum framework on being successful at Scrum.
Objective
We investigate the impact of team maturity and four categories of the Scrum framework (team composition, Scrum values, Scrum roles, and Scrum events) on the perception of being successful at Scrum. Hence, we uncover and provide deeper insights into the characteristics and practices of what makes a team successful at Scrum.
Method
We carry out a large-scale and cross-sectional survey. We conduct 
Pearson's
 chi-square test of independence and 
logistic regression
 analysis for team maturity and the remaining variables on being successful.
Results
After surveying 182 Scrum team members, the results show that being successful at Scrum depends on the team maturity level. Team composition variables (fully allocated, low turnover rates, required skills and expertise, and self-management) and directing work in accordance with Scrum values (openness and courage) have an impact. All three Scrum roles are important. Particularly impactful are the developers’ ability to adapt their plans, the product owners’ mandate to prioritize, and the Scrum masters’ ability to ensure that all events take place. Following all Scrum events has an effect on the perception of being successful at Scrum.
Conclusion
This work constitutes a valuable contribution to agile practitioners and organizations who are already involved in 
agile development
 or plan to pursue agility. Organizations can influence Scrum teams’ journey towards becoming successful at Scrum by ensuring the stability required to allow team maturation and decision-making relevant to team composition variables. This work also provides reflections that are useful for Scrum teams’ practices and internal dynamics related to values, roles, and events.",January 2023,"Agile software development, Scrum teams, team performance, maturity, success",Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on agile teamwork performance and Scrum framework provides insights into team success factors, which can be beneficial for startups adopting agile practices. The focus on team maturity and key components of Scrum can offer guidance for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0883902624000909,"Angel funding and entrepreneurs' well-being: The mediating role of autonomy, competence, and relatedness",Corinna Vera Hedwig=Schmidt: corinna-vera.schmidt@tu-dortmund.de; Patrick Sven=Gaßmann: patrick.gassmann@tu-dortmund.de; Nele=McElvany: nele.mcelvany@tu-dortmund.de; Tessa Christina=Flatten: tessa.flatten@tu-dortmund.de,"Abstract
While external funding is indispensable for most entrepreneurs to scale their ventures, entrepreneurship literature highlights the additional benefits of investors' continued involvement, such as access to their expertise and network. Angel investors, whose primary value-add often emerges through their relationship with the entrepreneurs, generate particularly pronounced benefits. Entrepreneurship research has established that bringing angel investors on board comes at the cost of relinquishing partial equity, which restricts entrepreneurs' control over their ventures; however, the individual-level consequences of funding for entrepreneurs remain largely unexplored. To address this gap, we study how angels' funding and their post-investment involvement in the venture affect entrepreneurs' eudaimonic well-being in the long term. Drawing on self-determination theory, we explore further how the psychological need for autonomy, competence, and relatedness mediates the relationship between angel funding and entrepreneurs' well-being. Self-determination theory states that individuals' verbalized language reflects their needs; accordingly, we use Linguistic Inquiry and Word Count (LIWC) analysis on a unique dataset of almost 125 million words derived from the tweets of 1667 entrepreneurs on X (formerly Twitter). As hypothesized, we find a positive association between angel funding and entrepreneurs' well-being. Autonomy negatively mediates this relationship, while competence and relatedness mediate it positively. We advance research on entrepreneurs' eudaimonic well-being and extend the literature on self-determination theory and individual-level consequences of angel funding.
Executive summary
Entrepreneurs often face a difficult trade-off: They must decide whether to accept funding from angel investors or relinquish some control over their venture. While much research centers on the business implications of this trade-off (Davila et al., 2003; Politis, 2008), the personal impact on entrepreneurs' eudaimonic well-being remains underexplored (Collewaert and Sapienza, 2016). This knowledge gap is concerning because entrepreneurs' well-being closely relates to their ventures' performance (Stephan et al., 2020b; Wach et al., 2016).
Recent calls for research (Stephan et al., 2023) emphasize the need to understand how external factors, like investor involvement, affect entrepreneurs' well-being by influencing the extent to which their psychological needs for autonomy, competence, and relatedness are satisfied, as outlined by self-determination theory (SDT) (
Deci and Ryan, 1985
, 2000). Despite the recognized importance of these factors, the impact of angel investors, who often form close relationships with entrepreneurs and engage deeply in their ventures (Fairchild, 2011; Politis, 2008), has been largely overlooked.
Our study addresses this gap by examining how angel funding and subsequent involvement influence entrepreneurs' eudaimonic long-term well-being. Using a dataset of 125 million words compiled from 1667 entrepreneurs' tweets on Twitter (now X) from 2006 to 2022, we apply Linguistic Inquiry and Word Count (LIWC) analysis to gain insights into the psychological states of these entrepreneurs (Block et al., 2019; Obschonka et al., 2017). This approach aligns with SDT, which posits that psychological needs fulfillment manifests in communication (Vansteenkiste et al., 2020).
Our findings reveal that angel investor involvement can significantly influence entrepreneurs' eudaimonic well-being—positively and negatively—by affecting entrepreneurs' psychological needs fulfillment. Our study thus complements research on entrepreneurs' well-being with longitudinal insights. First, it extends the literature on entrepreneurial well-being by providing a nuanced understanding of how angel funding and involvement, mediated by autonomy, competence, and relatedness, affect entrepreneurs' well-being over time (Stephan et al., 2023). Second, our study contributes to SDT literature by contextualizing investor involvement as an external factor and using large-scale social media data to assess entrepreneurs' psychological needs (Stephan et al., 2020a). Third, our study highlights the importance of the dynamics between angel investors and entrepreneurs, showing that such relationships significantly shape entrepreneurs' personal outcomes (Collewaert and Sapienza, 2016; Politis, 2008).
Beyond academic contributions, our study offers practical insights for entrepreneurs, angel investors, policy-makers, and universities by emphasizing the importance of understanding and managing the entrepreneurs' personal impacts of bringing angel investors on board.",March 2025,"Business angel investors, Entrepreneurs, Well-being, Psychological needs, Tweets, LIWC, Investor–investee relationship",Business Venturing,2025-03-21T00:00:00,9.0,"The study on angel funding, post-investment involvement, and entrepreneurs' well-being offers significant practical implications for European early-stage ventures, providing insights into the personal impact of funding decisions and relationships with investors."
https://www.sciencedirect.com/science/article/pii/S0883902624000922,How environmental awareness and concern affect environmental entrepreneurial intent,Yasmin O.=Schwegler: Yasmin.Schwegler@heig-vd.ch; Jeffrey S.=Petty: Jeffrey.Petty@unil.ch,"Abstract
Environmental awareness and concern are implicit in virtually the entire environmental-entrepreneurship literature but typically not explicitly analyzed. To better understand what makes environmental entrepreneurs start their ventures, we need to understand those omnipresent variables. We therefore deconstruct environmental awareness and concern into different aspects, which we manipulate separately in two experimental studies. Our main finding is that key stakeholders' environmental awareness and concern are drivers of environmental entrepreneurship, as they signal to entrepreneurs that stakeholders are ready to support it. We thus identify a way of increasing environmental entrepreneurial intent in order to transform environmental problems into economic opportunities.
Executive summary
There is a growing belief among scholars and practitioners that environmental entrepreneurs can play a crucial role in addressing global environmental degradation by developing and providing innovative solutions that lead the way toward a more sustainable business world (Dean and McMullen, 2007; Hockerts and Wüstenhagen, 2010; Johnson and Schaltegger, 2019). A growing literature is investigating the drivers of such entrepreneurship (e.g., Muñoz and Cohen, 2018; Schaltegger, 2002; Shepherd et al., 2013; York et al., 2016), but two drivers — environmental awareness and concern — are typically only implicit in this literature, even though they are underlying most drivers that are investigated explicitly (e.g., Cohen and Winn, 2007; Dean and McMullen, 2007; Markman et al., 2019). Explicitly analyzing the role of environmental awareness and concern is crucial to better understand what makes environmental entrepreneurs start their ventures.
In this paper, we deconstruct environmental awareness and concern. The experimental method is ideally suited for that aim (Grégoire et al., 2019; Stevenson et al., 2020; Williams et al., 2019), as it allows us to manipulate several forms of awareness and concern in different experimental groups with slightly different pre-tested articles about an environmental problem. We then measure participants' intent to start a venture that addresses that problem, relative to their intent to start similar ventures that do not address the problem. In this way, we test the effect of the following types of environmental awareness and concern on environmental entrepreneurial intent (EEI): entrepreneurs' personal awareness, awareness of a solution to the problem, and awareness of other entrepreneurs addressing the problem; public awareness; entrepreneurs' own concern; public concern; customers' concern; and investors' concern.
The results indicate that especially customers' and investors' awareness of and concern about environmental problems increase entrepreneurs' intent to start environmental ventures. One explanation is that information about stakeholder concern, customers' willingness to buy from environmental ventures, and investors' willingness to invest in them increases the economic feasibility of such ventures and thus their business potential. This is in line with classic entrepreneurship theory, which postulates that entrepreneurship consists in the exploitation of economic opportunities (Shane and Venkataraman, 2000). Information about the environmental problem intended to raise entrepreneurs' own awareness of and concern about the problem have no effect on EEI in our study, which seemingly is in contrast to previous findings that idealistic motives and personal concern are primary drivers of EEI (Phillips, 2013; Shepherd and Patzelt, 2011; York et al., 2016). The findings can be reconciled by recognizing that our study assesses exclusively the overall effects of the experimental manipulations and controls for the potential entrepreneurs' environmental inclination, which we also find to be an important predictor of EEI. By controlling for it, we show that EEI can also be raised by factors external to the focal entrepreneur, in particular the environmental concern of key stakeholders.
Our findings thus complete the picture of the drivers of EEI by showing that if environmental awareness and concern are experienced not only by potential environmental entrepreneurs but their stakeholders, entrepreneurs' intent to address the relevant environmental problems rises. It also explains why, despite individual environmental awareness and concern, there is still widespread economic inaction in the face of known environmental problems (Heidbreder et al., 2021; York, 2018). According to our study, more EEI could be induced by a more widespread environmental concern, which encompasses both environmental entrepreneurs and their stakeholders.",March 2025,"Environmental entrepreneurship, Entrepreneurial intent, Experiment, Environmental awareness, Environmental concern",Business Venturing,2025-03-21T00:00:00,7.0,The research on environmental entrepreneurship and the role of stakeholders in driving entrepreneurial intent could provide valuable insights for early-stage ventures in Europe looking to address environmental issues and economic opportunities.
https://www.sciencedirect.com/science/article/pii/S0950584922001914,Learning migration models for supporting incremental language migrations of software applications,Matias=Martinez: matias.martinez@uphf.fr,"Abstract
Context:
A Legacy system can be defined as a system that significantly resists modification and evolution. According to the literature, there are two main strategies to migrate a legacy system: (a) to replace the legacy system by a new one, (b) to incrementally migrate parts from the legacy system to the new one. Incremental migration allows developers to better control the risks that may occur during the migration process. However, this strategy is more complex because it requires decomposition of the legacy system into different parts, e.g. a set of files, and to define the order of migration of them along the migration process. To our knowledge, there is no approach to support developers on those activities.
Objective:
This paper presents an approach, named MigrationExp, to support incremental language migrations of applications from one 
source
 language to another 
target
 language. MigrationExp recommends the files that should be migrated first in a particular migration iteration. As a novelty, our approach relies on a ranking model learned, using a 
learning-to-rank
 algorithm, from migrations made by developers.
Method:
We validate our approach in the context of the migrations of 
Android
 apps, from Java to Kotlin, a new 
official language
 for 
Android
. We train our model using migrations of Java code to Kotlin written by developers on open-source applications.
Results:
The results show that, on the task of proposing files to migrate, our approach outperforms a previous migration strategy proposed by Google, in terms of its ability to accurately predict empirically observed migration orders.
Conclusion:
Since most 
Android applications
 are written in Java, we conclude that approaches to support developers such as MigrationExp may significantly impact the development of 
Android applications
.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The approach presented for incremental language migrations of Android apps can have a significant impact on developers working on legacy systems. This can be particularly useful for startups looking to modernize their applications and improve their development processes.
https://www.sciencedirect.com/science/article/pii/S0950584922001926,FRL-MFPG: Propagation-aware fault root cause location for microservice intelligent operation and maintenance,Ningjiang=Chen: chnj@gxu.edu.cn,"Abstract
Context:
Due to the continuous updates and complex dependencies of 
microservices
, the probability of a fault occurrence and the difficulty of doing a diagnosis have increased, making it hard for 
operation and maintenance
 staff to quickly and accurately troubleshoot a fault and locate its root cause.
Objective:
To fulfill the requirements of 
artificial intelligence
 for IT operations, called AIOps, this paper studies microservice fault root cause location technology from two aspects, microservice 
fault propagation
 relationships and fault root cause location.
Method:
First, this paper designs a microservice 
fault propagation
 
graph construction
 method MFPG-FC based on fault correlation. The method effectively depicts the propagation relationship and the scope of influence of microservice faults and improves the accuracy of locating a fault’s root cause. Second, in terms of fault root cause location, this paper proposes a microservice fault root cause location algorithm based on a microservice fault propagation relationship graph called FRL-MFPG. The FRL-MFPG algorithm is designed to improve the globalization, flexibility and accuracy of the 
fault location
 search range and rate. Finally, an AIOps-oriented microservice fault root cause location framework (AIOps-MFRL) is designed.
Results:
The experimental results show that, compared with the traditional method, the method proposed in this paper is more accurate and can locate the root cause of a fault more accurately. After detecting the fault of 
microservices
, it can achieve the goal of locating the root cause of the fault, which is helpful to improve the efficiency of intelligent 
operation and maintenance
.
Conclusion:
The method in this paper can effectively locate the root cause of a fault and identify the root cause indicators of the fault after the fault is detected in the microservice. It has better timeliness and accuracy, reduces troubleshooting time and the losses caused by faults, and improves operation and maintenance efficiency.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The paper proposes a method to improve fault location in microservices, which can enhance the efficiency of operation and maintenance for startups dealing with microservices."
https://www.sciencedirect.com/science/article/pii/S0950584922001975,An optimized case-based software project effort estimation using genetic algorithm,Yousef=Elsheikh: y_elsheikh@asu.edu.jo,"Abstract
Software development companies have long suffered from inaccurate estimation of their software projects. This in turn led to huge losses, especially in the financial resources available for the project as well as the time required to complete it. As a result of this, the research community has developed different methods for estimating effort in software projects in the 
hope
 of achieving high levels of accuracy and efficiency in the use of available resources. Among those methods that have proven to be accurate in estimating the effort of software projects is the use of machine learning (ML) techniques, especially the case-based reasoning technique (CBR). This technique is based on adapting previously successful solutions for similar software projects. However, the CBR technique suffers from a problem which is its multiple parameters that are difficult to be tuned. This justifies the importance of the adaptation and adjustment process as an essential part of CBR to produce accurate and efficient results with least absolute 
estimation error
. In this paper, one of the most efficient multi-objective evolutionary techniques, the 
Genetic Algorithm
 (GA), are used to help find the best set of classical CBR parameters (feature selection, feature weighting, similarity measures, and 
k
 number of nearest neighbors) to produce the most accurate effort estimates for software projects. The proposed CBR-GA model showed the effectiveness of using the GA algorithm to search for the best combination of CBR parameters and thus improve its accuracy. This in turn is beneficial for project managers in the early financial planning phase for effort estimation and thus project cost control. To validate the proposed CBR-GA model, we used a set of public benchmark datasets available on PROMISE data repository, in addition we used a set of reliable 
evaluation metrics
. The obtained results are promising in terms of accuracy and 
significance tests
. This implies the importance of search-based techniques for tuning effort estimation methods.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The research aims to improve effort estimation in software projects using machine learning techniques, which can be beneficial for startups in optimizing resource allocation."
https://www.sciencedirect.com/science/article/pii/S0950584922001902,A systematic literature review of the Design Critique method,Lorans=Alabood: lorans.alabood@ucalgary.ca; Zahra=Aminolroaya: zahra.aminolroaya@ucalgary.ca; Dianna=Yim: dyim@ucalgary.ca; Omar=Addam: okaddam@ucalgary.ca; Frank=Maurer: fmaurer@ucalgary.ca,"Abstract
Context:
The Design Critique (DC) method is becoming more common in Human–Computer Interaction (HCI) and 
User Experience
 (UX) studies as the need for new evaluation methods of emerging technologies is increasing. However, there is an clear lack of guidelines on how to conduct DC studies in the UX context.
Objective:
The goal of this paper is to provide an overview of the DC method in the fields of UX. In addition, this paper aims to propose a 
generic process
 of running DC studies in the same context.
Methods:
We present a systematic literature review of the DC method. Moreover, we conduct a course of thematic analysis on the selected papers to identify the various DC processes and explore the following attributes: participant categories, data collection methods, and data analysis methods in each process.
Results:
We identified three different trends of DC processes: detailed, moderate and minimal. In addition, we proposed a generic DC process consisting of 10 steps divided into three main phases: preparation, conducting design critique, and pro-processing. We found that domain experts represent the majority of studies participants. Using interviews to collect qualitative data and using script coding analysis are the two most common methods of collecting and analyzing data.
Conclusion:
Conducting DC studies can improve overall 
systems usability
 by addressing design flaws at an early stage of development. The process of conducting a DC varies, depending on the project goals and states. The DC method aligns well with the small light-weight steps approach in Agile methods.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The paper provides a generic process for conducting Design Critique studies, which can help startups improve system usability at an early stage of development."
https://www.sciencedirect.com/science/article/pii/S0883902624000934,Fear the loss or welcome the gains? How stock options influence CEO risk-taking in corporate cleantech investments,David=Bendig: dbendig@uni-muenster.de,"Abstract
This study draws on the behavioral agency model to investigate how stock options incentivize CEO risk-taking related to investments in external clean technology (cleantech) ventures. Using longitudinal data from 540 publicly traded firms, we find that current option wealth is negatively associated with corporate cleantech investments while prospective option wealth is positively associated. The results show that founder CEOs, who exhibit different endowment and risk-bearing patterns than hired CEOs, do not perceive cleantech investments as mixed gambles. These findings advance understanding of the interplay between equity-based incentives, CEO characteristics, and incumbents' pursuit of sustainable business practices.",March 2025,"Corporate cleantech investments, Behavioral agency theory, CEO stock options, Founder CEO, Green transformation",Business Venturing,2025-03-21T00:00:00,5.0,"The study on CEO risk-taking related to cleantech ventures, while interesting, may have limited practical relevance for early-stage ventures in Europe compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001732,CodeCity: A comparison of on-screen and virtual reality,David=Moreno-Lumbreras: d.morenolu@alumnos.urjc.es,"Abstract
Context:
Over the past decades, researchers proposed numerous approaches to visualize source code. A popular one is 
CodeCity
, an interactive 3D software visualization representing software system as cities: buildings represent classes (or files) and districts represent packages (or folders). Building dimensions represent values of software metrics, such as number of methods or lines of code. There are many implementations of 
CodeCity
, the vast majority of them running on-screen. Recently, some implementations using virtual reality (VR) have appeared, but the usefulness of 
CodeCity
 in VR is still to be proven.
Aim:
Our comparative study aims to answer the question 
“Is VR well suited for 
CodeCity
, compared to the traditional on-screen implementation?”
Methods:
We performed two experiments with our web-based implementation of 
CodeCity
, which can be used on-screen or in 
immersive VR
. First, we conducted a controlled experiment involving 24 participants from academia and industry. Taking advantage of the obtained feedback, we improved our approach and conducted a second controlled experiment with 26 new participants.
Results:
Our results show that people using the VR version performed the assigned tasks in much less time, while maintaining a comparable level of correctness.
Conclusion:
VR is at least equally well-suited as on-screen for visualizing 
CodeCity
, and likely better.",January 2023,"CodeCity, City metaphor, Software visualization, Software evolution, Reverse engineering, Virtual reality, Web, 3D",Information and Software Technology,2025-03-18T00:00:00,7.0,"The comparative study on using VR for CodeCity visualization can be beneficial for startups exploring innovative ways of presenting source code, potentially improving their development processes."
https://www.sciencedirect.com/science/article/pii/S0950584922001720,A hybrid model for efficient decision-making in self-adaptive systems,Fatma=Kachi: fatma.kachi@univ-constantine2.dz; Chafia=Bouanaka: chafia.bouanaka@univ-constantine2.dz,"Abstract
Context:
Engineering self-adaptive systems to guarantee the required quality properties is challenging and particularly in presence of uncertainties. Such uncertainties may occur in a variety of situations, ranging from variations in the system’s operating environment to ambiguity while selecting the appropriate adaptation option. Formal methods provide a rigorous means to specify and verify the behaviour of self-adaptive systems. They are applied both during system design and at runtime to provide guarantees on the required properties of self-adaptive systems. However, existing approaches generally use exhaustive verification at runtime to pick adaptation options and achieve adaptation objectives, which is time and resource consuming.
Objective:
Aiming to tackle this shortcoming, we target a twofold objective. Firstly, we reduce the adaptation space, and then we predict the impact of each adaptation plan on the rest of system qualities, to assist the decision-making process in determining the most suitable adaptation plans and side effects.
Method:
An Adaptation-space Reducer component is added to the analyser element; it uses 
deep learning
 to reduce the adaptation space. Furthermore, the planner element has been extended with a Decision Impact Predictor component, which employs quantitative analysis to forecast the impact of a decision.
Results:
The DLA4EDM is defined as an approach for providing self-adaptive systems (SASs) with an efficient decision-making process. Our approach is applied on a self-adaptive 
Internet of Things
 application and the obtained results are compared to those of other approaches. Results show that the adaptation space is reduced by 97.57%, and the error rate in the decision-making is very low.
Conclusion:
Reducing the adaptation space and resolving uncertainties to be faced in the decision-making of self-adaptive systems contribute considerably to enhance the efficiency and quality of the adaptation process and hence ensure that the quality requirements are met. Evaluating the impact of the identified adaptation plans on the obtained guarantees ensures that the system is effectively operational.",January 2023,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed approach addresses a significant challenge in engineering self-adaptive systems, showcasing a substantial reduction in adaptation space and decision-making errors. The use of deep learning and quantitative analysis enhances the efficiency and quality of the adaptation process, with practical implications for startups in the early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001483,Uses of business process modeling in agile software development projects,Cielo=González Moyano: c.gonzalez.moyano@hu-berlin.de,"Abstract
Context:
Agile 
methodologies and frameworks
 are widely used in software development projects because of their support for 
continuous change
 and delivery. 
Agile software development
 advocates de-prioritizing aspects such as processes and documentation. In traditional 
software engineering
 methodologies, however, business process models have been extensively used to support these aspects. Up until now, it is unclear to what extent recommendations to focus on code imply that 
conceptual modeling
 should be discontinued.
Objective:
The objective of this study is to investigate this hypothesis. More specifically, we develop a theoretical argument of how business process models are and can be used to support agile software development projects.
Method:
To this end, we use a multi-method study design. First, we conduct a systematic literature review, in which we identify studies on the usage of business process models in agile software development. Second, we apply procedures from thematic synthesis to analyze the connection between these uses and the phases of the 
development cycle
. Third, we use a focus group design with practitioners to systematically reflect upon how these uses can help regarding four categories of challenges in agile software development: management, team, technology, and process.
Results:
From 37 relevant studies, we distill 15 different uses. The results highlight the benefits of process modeling as an instrument to support agile software development projects from different angles and in all project phases. Process modeling appears to be particularly relevant for the first phases of the 
development cycle
, and for management and process issues in agile projects.
Conclusion:
We conclude that business process models indeed provide benefits for agile software development projects. Our findings have practical implications and emphasize the need for future research on modeling and 
agile development
.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"Identifying metrics for GUI-based testing research and formulating a taxonomy for coverage metrics contribute to improving the quality of studies in the domain. The proposed taxonomy can facilitate replication studies and macro-analysis, providing a foundation for future research in the field, which could benefit early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001719,A taxonomy of metrics for GUI-based testing research: A systematic literature review,Riccardo=Coppola: riccardo.coppola@polito.it,"Abstract
Context:
GUI-based testing is a sub-field of software testing research that has emerged in the last three decades. GUI-based testing techniques focus on verifying the functional conformance of the system under test (SUT) through its graphical user interface. However, despite the research domains growth, studies in the field have low reproducibility and 
comparability
. One observed cause of these phenomena is identified as a lack of research rigor and commonly used metrics, including coverage metrics.
Objective:
We aim to identify the most commonly used metrics in the field and formulate a taxonomy of coverage metrics for GUI-based testing research.
Method:
We adopt an evidence-based approach to build the taxonomy through a systematic literature review of studies in the GUI-based testing domain. Identified papers are then analyzed with Open and Axial Coding techniques to identify hierarchical and mutually exclusive categories of metrics with common characteristics, usages, and applications.
Results:
Through the analysis of 169 papers and 315 
metric definitions
, we obtained a taxonomy with 55 codes (common names for metrics), 17 metric categories, and 4 higher level categories: Functional Level, GUI Level, Model Level and Code Level. We measure a higher number of mentions of Model and Code level metrics over Functional and GUI level metrics.
Conclusions:
We propose a taxonomy for use in future GUI-based testing research to improve the general quality of studies in the domain. In addition, the taxonomy is perceived to help enable more replication studies as well as macro-analysis of the current body of research.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The introduction of COR-NSGA-II for variability testing of Software Product Lines addresses an important problem in optimization algorithms. The experiments demonstrate promising results, outperforming existing algorithms, but the practical implications for European early-stage ventures may require further exploration and validation."
https://www.sciencedirect.com/science/article/pii/S0883902624000946,"Coordination, sensemaking, and idea work: How founding teams pivot their venture ideas",Nicola=Breugst: nicola.breugst@tum.de; Eva=Weissenböck: eva.weissenbock@imd.org; Anna=Brattström: ab638@st-andrews.ac.uk,"Abstract
This study offers novel insights into how team structure and flexibility affect pivoting. It details how founding team coordination practices shape individual and collective sensemaking of feedback and efforts to improve a venture idea. Following seven founding teams, we identified how teams with overlapping responsibilities enjoyed the flexibility of both fragmented and holistic sensemaking. This enabled them to pivot when needed but otherwise persevere with their venture idea. In contrast, teams with clear separation of responsibilities engaged in fragmented sensemaking and only persevered with their idea. Our findings advance research on founding team coordination, pivoting, and teams' understanding of their venture ideas.",March 2025,"Pivoting, Founding teams, Spaces, Sensemaking, Idea work",Business Venturing,2025-03-21T00:00:00,6.0,Insights into team structure and pivoting could be beneficial for European startups in understanding how to adapt and persevere with their venture ideas.
https://www.sciencedirect.com/science/article/pii/S0883902624000533,Directors in new technology-based ventures: An empirical inquiry,Sam=Garg: samgarg@essec.edu; Michael=Howard: mdh189@iastate.edu; Emily Cox=Pahnke: eacox@uw.edu,"Abstract
In the emerging literature on venture boards, little research examines the association between different categories of venture directors and strategic firm outcomes. We conduct an empirical inquiry into how founder-directors, venture capitalist investor-directors and corporate venture investor-directors are related to inter-organizational alliances, innovation, and exits. In our longitudinal study based on hand-collected data on 156 medical device ventures in the US, we find that founder-directors are positively associated with patents and negatively associated with supply chain agreements. VC-directors are positively associated with exits but are negatively associated with R&D, supply chain agreements and patents. CVC-directors are negatively associated with patents and first product introductions. Adopting an abductive approach, we suggest potential mechanisms based on interviews with venture directors and CEOs and suggest future directions for venture boards scholarship.
Executive summary
Scandals at private firms such as Theranos and Uber (when it was private) have highlighted both the influence that boards of directors have on these firms and the relative opacity with which they operate. While there is a considerable literature, both theoretical and empirical, on the boards of public companies, there is a relative paucity of research on governance in private firms. At the same time, the distinctive features of private firm governance may limit the applicability of insights from public boards; one difference is that in venture boards, directors often have significant ownership stakes in the companies as founders and representatives of venture capital firms (VCs) or the investment arms of other corporations (CVCs). As part of this special issue on the boards of private firms, we undertake an empirical investigation of the impact that these types of directors have on a variety of firm outcomes.
We build on research on venture investing which hints at, but does not disentangle, the distinct impact of investors that have board seats versus investors that do not. Our analyses explores the impact that three types of venture directors- Founder-directors, VC-directors and CVC directors- have on strategic firm outcomes they are likely to influence in our context: inter-organizational ties, innovation and exit events.
We conduct our study within a sector of the US medical device industry, where both venture-directors and venture-investors are prevalent and where previous research indicates they are likely to impact ventures. We take an abductive approach to analyze hand-collected longitudinal data on the directors of ventures and on the firms in this industry between 1997 and 2018. Overall, the results suggest that different types of directors can be significantly associated with ventures strategic outcomes, with each type of director bringing their unique focus and expertise to the table. For example, the results indicate that founder-directors may focus more on technology development and less on commercial development. For CVC-directors we do not find a significant association with interorganizational tie formation or exits, but are significantly negatively associated with innovation outcomes. Finally, while VC-directors are negatively associated with some kinds of interorganizational ties and patenting, they are significantly positively associated with faster exits via acquisitions and IPOs.
We contribute to the emerging literature on venture boards through an abductive inquiry into how different types of venture directors are associated with some of the most important strategic outcomes involved in the growth, development and exits of ventures. These results control for investor and investment characteristics. The empirical relationships we document suggest a multitude of theoretical explanations that future researchers can build on to test hypotheses. Some of our surprising findings may have implications for key governance theories and their relevance to venture boards. For example, our results suggest that the agency perspective may be applicable to ventures through the 
principal-principal
 model but due to conflicts among different VC-directors, not among VC-directors and CVC-directors. By contrast, the resource dependence perspective can be extended by considering the relevance of 
organizational roles
 of resource providers as directors versus investors (e.g., CVC 
directors
 are neither particularly effective at providing complementary resources nor notably ""shark-like"" in misappropriating ventures) and that ventures may face significant coordination costs in orchestrating resources from different directors. Overall, our study suggests a more nuanced picture of conflict and cooperation in venture boards than has previously been identified and offers an opportunity for scholars to explore a broad array of theoretical explanations, including power and conflict.",March 2025,"Boards of directors, Ventures, Venture capital, Corporate venture capital, Founders",Business Venturing,2025-03-21T00:00:00,8.0,"The examination of different venture directors and their impact on strategic outcomes, especially in the medical device industry, is highly relevant for European early-stage ventures seeking to form alliances and drive innovation."
https://www.sciencedirect.com/science/article/pii/S0950584922001501,Variability testing of software product line: A preference-based dimensionality reduction approach,Silvia R.=Vergilio: silvia@inf.ufpr.br; Thiago=Ferreira: thiagod@umich.edu; Marouane=Kessentini: marouane@umich.edu,"Abstract
Context:
Multi- and many-evolutionary algorithms have been applied to derive products for the variability testing of Software Product Lines (SPLs). This problem refers to the selection of an adequate product set to test a SPL by optimizing some objectives related to the number of products to be tested, testing criteria to be satisfied, and revealed faults. However, some problems emerge when the number of objectives to be optimized increases, for example: the solutions generated by the 
optimization algorithms
 become incomparable, designing a Pareto-front in this context requires a large number of solutions, and the visualization of such solutions requires special techniques. Several techniques are proposed to tackle this problem, such as decomposition and algorithms based on indicators. Among them, algorithms based on dimensionality reduction and user preferences are widely used, but there are no studies in the literature investigating the usage of both in a combined way.
Objective:
In light of this, we introduce COR-NSGA-II (Confidence-based Objective Reduction NSGA-II). COR-NSGA-II defines for each objective a confidence-level calculated with the user preferences provided interactively. The objectives with higher values of confidence are removed from the next algorithm execution.
Method:
For assessing the feasibility of COR-NSGA-II, experiments were conducted by using six different SPLs, seven objectives, two types of 
reference points
 representing the user preferences, and two scenarios to simulate different user profiles.
Results:
COR-NSGA-II is evaluated against four algorithms explored in the literature for the problem, and outperforms most of them according to R-HV and R-IGD. It takes less time to execute and generates a reduced number of solutions, all of them satisfying the user preferences.
Conclusion:
A qualitative analysis performed with 12 potential users shows that the task of selecting a solution generated by COR-NSGA-II is easier than selecting a solution generated by the other algorithms.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The introduction of COR-NSGA-II for software testing optimization shows significant improvement and outperforms existing algorithms, providing practical value for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001525,"Different, Really! A comparison of Highly-Configurable Systems and Single Systems",Raphael Pereira=de Oliveira: raphael.oliveira@academico.ufs.br,"Abstract
Context:
The development of systems that handle configuration options according to a specific environment is considered a hard activity. These kind of systems, Highly-Configurable Systems (HCS) are perceived by researchers and developers as complex and difficult to maintain due to the necessity of handling variation points. Although this perception is reported in the literature, no prior study investigated the differences between HCS and Single Systems (SS).
Objective:
This study investigated similarities and differences between HCS and SS using well known metrics from the literature according to three different perspectives: 
product perspective
 (bug-proneness, complexity, and change size); 
process perspective
 (number of contributors, number of core developers, and accidental contributors); and 
people perspective
 (contributor retention and number of paid contributors).
Method:
To perform this comparison, we 
collected data
 from two surveys and from a mining study (within 15,769 releases of 124 GitHub projects written in C).
Results:
In general, we identified that for the majority of the metrics, the perception of practitioners and researchers about HCS and SS is different from our mining results.
Conclusion:
The identification of similarities and differences of HCS and SS will help to initiate a discussion and further research in this direction.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on Highly-Configurable Systems vs. Single Systems provides insights, but the impact on early-stage ventures is not as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001288,Yet another combination of IR- and neural-based comment generation,Junjie=Wang: junjie@iscas.ac.cn; Qing=Wang: wq@iscas.ac.cn; Yuchao=Huang: yuchao2019@iscas.ac.cn; Moshi=Wei: moshiwei@yorku.ca; Song=Wang: wangsong@eecs.yorku.ca,"Abstract
Background:
Code comment generation techniques aim to generate natural language descriptions for 
source code
. There are two orthogonal approaches for this task, i.e., information retrieval (IR) based and neural-based methods. Recent studies have focused on combining their 
strengths
 by feeding the input code and its similar code snippets retrieved by the IR-based approach to the neural-based approach, which can enhance the neural-based approach’s ability to output low-frequency words and further improve the performance.
Aim:
However, despite the tremendous progress, our pilot study reveals that the current combination is not generalizable and can lead to 
performance degradation
. In this paper, we propose a straightforward but effective approach to tackle the issue of existing combinations of these two comment generation approaches.
Method:
Instead of binding IR- and neural-based approaches statically, we combine them in a dynamic manner. Specifically, given an input code snippet, we first use an IR-based technique to retrieve a similar code snippet from the corpus. Then we use a Cross-Encoder based classifier to decide the comment generation method to be used dynamically, i.e., if the retrieved similar code snippet is a 
true positive
 (i.e., is semantically similar to the input), we directly use the IR-based technique. Otherwise, we pass the input to the neural-based model to generate the comment.
Results:
We evaluate our approach on a large-scale dataset of Java projects. Experiment results show that our approach can achieve 25.45 BLEU score, which improves the state-of-the-art IR-based approach, neural-based approach, and their combination by 41%, 26%, and 7%, respectively.
Conclusions:
We propose a straightforward but effective dynamic combination of IR-based and neural-based comment generation, which outperforms state-of-the-art approaches by a substantial margin.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed dynamic combination of IR-based and neural-based approaches for code comment generation shows substantial improvement and practical value for startups in the software industry.
https://www.sciencedirect.com/science/article/pii/S0950584922001537,"An empirical study on ML DevOps adoption trends, efforts, and benefits analysis",Dhia Elhaq=Rzig: dhiarzig@umich.edu; Foyzul=Hassan: foyzul@umich.edu; Marouane=Kessentini: kessentini@oakland.edu,"Abstract
Context:
Machine Learning
 (ML), including Deep Learning(DL), based systems, have become ubiquitous in today’s solutions to many real-world problems. ML-based approaches are being applied to solve complex problems such as 
autonomous driving
, recommendation systems, etc.
Objective:
To improve the quality and 
deliverability
 of ML-based applications, the software development community is adopting state-of-the-art 
DevOps
 practices within them. However, we currently lack knowledge about the 
DevOps
 adoption trends, maintenance efforts and benefits among ML-based projects, and this work attempts to remedy this knowledge-gap.
Methods:
In this 
research work
, we conducted a large-scale empirical analysis on 4031 ML projects, including 1116 ML Tools and 2915 
ML Applied
 projects to quantify DevOps adoption, maintenance effort and benefits. To characterize the development behaviors, we performed configuration-script-analysis and commit-change-analysis on DevOps 
configuration files
. To compare the characteristics of ML DevOps to those of traditional software projects, we performed the same analysis on 4076 non-ML projects.
Results:
Our analysis identified that ML projects, more specifically ML-Applied projects, have a slower, lower, and less efficient adoption of DevOps tools in general. DevOps 
configuration files
 in ML-Applied projects tended to experience more frequent changes than ML-Tool projects and were less likely to occur in conjunction with build and bug fixes. It’s also evident that adopting DevOps in ML projects correlates with an increase in development productivity, code quality, and a decrease in bug resolution time, especially in ML-Applied projects which have the most to gain by adopting these tools.
Conclusion:
We identified the characteristics and improvement scopes of ML DevOps, such as the slower adoption of DevOps in certain ML projects, and the need for automatic configuration 
synchronization
 tools for these projects. We also identified the improvements the productivity of ML teams and projects associated with DevOps adoption, including better code quality, more frequent code sharing and integration and faster issue resolution.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The analysis of DevOps adoption in ML projects and the identified improvement scopes provide valuable insights for European startups using ML-based systems, contributing significantly to the field."
https://www.sciencedirect.com/science/article/pii/S0950584922001665,Introduction to the special issue on managing software processes using soft computing techniques,Arif Ali=Khan: arif.khan@oulu.fi,"Abstract
The coronavirus outbreak dramatically changed the work culture in the software industry. Most software practitioners began working remotely, which significantly revolutionized the traditional software processes landscape. Software development organizations have begun thinking about automating software processes to cope with the challenges raised by remote work. This special issue presents papers describing soft computing solutions for improving traditional software processes and capabilities. This editorial introduces the accepted papers and reflects on their contributions.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,3.0,"While discussing the impact of the coronavirus outbreak on software processes is relevant, the automation of software processes for remote work may not directly impact early-stage ventures in Europe as significantly."
https://www.sciencedirect.com/science/article/pii/S0950584922001549,Undulate: A framework for data-driven software engineering enabling soft computing,Tomi=Männistö: tomi.mannisto@helsinki.fi; Timo=Asikainen: timo.o.asikainen@helsinki.fi,"Abstract
Context.
Especially web-facing software systems enable the collection of usage data at a massive scale. At the same time, the scale and scope of software processes have grown substantively. Automated tools are needed to increase the speed and quality of controlling software processes. The usage data has great potential as a driver for software processes. However, research still lacks constructs for collecting, refining and utilising usage data in controlling software processes.
Objective.
The objective of this paper is to introduce a framework for data-driven 
software engineering
. The 
Undulate
 framework covers generating, collecting and utilising usage data from software processes and business processes supported by the software produced. In addition, we define the concepts and process of extreme continuous experimentation as an exemplar of a software engineering process.
Method.
We derive requirements for the framework from the research literature, with a focus on papers inspired by practical problems. In addition, we apply a multilevel 
modelling language
 to describe the concepts related to extreme continuous experimentation.
Results.
We introduce the 
Undulate
 framework and give requirements and provide an overview of the processes of collecting usage data, augmenting it with additional 
dimensional data
, aggregating the data along the dimensions and computing different metrics based on the data and other metrics.
Conclusions.
The paper represents significant steps inspired by previous research and practical insight towards standardised processes for data-driven software engineering, enabling the application of soft computing and other methods based on 
artificial intelligence
.",December 2022,"Soft computing, Multilevel modelling, Dimensional database, Continuous experimentation, Data-driven software engineering",Information and Software Technology,2025-03-18T00:00:00,7.0,The framework for data-driven software engineering presented in this abstract could have a significant impact on improving software processes and capabilities for early-stage ventures and startups.
https://www.sciencedirect.com/science/article/pii/S0950584922001690,Agile software development and UX design: A case study of integration by mutual adjustment,Anders=Bruun: bruun@cs.aau.dk,"Abstract
Context
Agility is an overarching ideal for empirically-driven software development processes that embrace change in order to improve quality, economy, and simplicity. While the pursuit of Agility has held prominence in software practice and research for over two decades, 
user experience
 (UX) designers struggle to integrate their work processes with 
agile software development
.
Objective
As empirical processes are constantly evolving, so is this integration struggle for UX designers. We, therefore, present an industrial 
case study
 of how a Danish software company integrates UX design and agile software development.
Method
We conducted a case study involving (a) one iteration of individual interviews with 10 employees (four UX designers, three software developers, two project managers, and one solution architect) and (b) a follow-up iteration consisting of a workshop with 6 employees (three UX designers, two solution architects, and one project manager) two years later. We analyzed how the company's approach to integration with 'upfront design' and 'work in parallel' involve mutual adjustments as opposed to assimilation or separation of UX design and software development.
Results
Our analysis shows how integration through mutual adjustments made distinct contributions to UX designers' and software developers' pursuit of Agility. They experienced notably different work processes that still dealt effectively with change and contributed to quality, economy, or simplicity. Nevertheless, as shown from a follow-up workshop two years after our first interviews, these processes were still susceptible to integration struggles over time.
Conclusion
We conclude that integration based on mutual adjustment potentially makes Agility for UX designers and software developers different and mutually complementary. This integration contrasts with assimilation, which potentially makes their Agility mutually indistinguishably, and with separation, which makes their Agility different and mutually competing.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The industrial case study on integrating UX design and agile software development provides actionable insights for early-stage ventures and startups, making it highly valuable."
https://www.sciencedirect.com/science/article/pii/S0950584922001677,Software defect prediction with semantic and structural information of codes based on Graph Neural Networks,Yan=Xiao: dcsxan@nus.edu.sg; Chunying=Zhou: zcy9838@stu.hubu.edu.cn; Peng=He: penghe@hubu.edu.cn; Cheng=Zeng: zc@hubu.edu.cn,"Abstract
Context:
Most 
defect prediction
 methods consider a series of traditional manually designed static 
code metrics
. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional 
Neural Network
 (CNN) to capture the potential semantic information based on the program’s Syntax 
Trees
 (ASTs). In recent years, leveraging the 
dependency relationships
 between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in 
defect prediction
. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN.
Objective:
This study aims to validate the feasibility and performance of the proposed method in 
software defect
 prediction.
Method:
Abstract Syntax Trees
 and a Class Dependency Network (CDN) are first generated based on the 
source code
. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a 
Graph Convolutional Network
 (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction.
Results:
The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks.
Conclusion:
The proposed method of combining semantic and structural information can improve the performance of 
software defect
 prediction.",December 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed method for software defect prediction utilizing semantic and structural information could benefit early-stage ventures and startups by improving software quality and reliability.
https://www.sciencedirect.com/science/article/pii/S0950584922001707,Guidelines for the development of a critical software under emergency,Silvia=Bonfanti: silvia.bonfanti@unibg.it,"Abstract
Context:
During the first wave of the COVID-19 pandemic, an international and heterogeneous team of scientists collaborated on a social project to produce a mechanical ventilator for intensive care units (MVM). MVM has been conceived to be produced and used also in poor countries: it is open-source, no patents, cheap, and can be produced with materials that are easy to retrieve.
Objective:
The objective of this work is to extract from the experience of the MVM development and software certification a set of lessons learned and then guidelines that can help developers to produce safety–critical devices in similar 
emergency situations
.
Method:
We conducted a 
case study
. We had full access to source code, comments on code, change requests, test reports, every deliverable (60 in total) produced for the software certification (safety concepts, requirements specifications, architecture and design, testing activities, etc.), notes, whiteboard sketches, emails, etc. We validated both lessons learned and guidelines with experts.
Findings:
We contribute a set of validated lessons learned and a set of validated guidelines, together with a discussion of benefits and risks of each guideline.
Conclusion:
In this work we share our experience in certifying software for healthcare devices produced under emergency, i.e. with strict and pressing time constraints and with the difficulty of establishing a heterogeneous development team made of volunteers. We believe that the guidelines will help engineers during the development of critical software under emergency.",December 2022,"Safety–critical systems development, Software certification, Lessons learned, Guidelines, Healthcare",Information and Software Technology,2025-03-18T00:00:00,7.0,"The experience and guidelines shared in certifying software for healthcare devices produced under emergency situations can provide valuable insights for startups working on critical software with limited time constraints, potentially impacting European early-stage ventures in the healthcare sector."
https://www.sciencedirect.com/science/article/pii/S0950584922001331,Predictive maintenance using digital twins: A systematic literature review,Bedir=Tekinerdogan: bedir.tekinerdogan@wur.nl,"Abstract
Context
Predictive maintenance
 is a technique for creating a more sustainable, safe, and profitable industry. One of the key challenges for creating predictive maintenance systems is the lack of failure data, as the machine is frequently repaired before failure. Digital Twins provide a real-time representation of the physical machine and generate data, such as asset degradation, which the predictive maintenance algorithm can use. Since 2018, scientific literature on the utilization of Digital Twins for predictive maintenance has accelerated, indicating the need for a thorough review.
Objective
This research aims to gather and synthesize the studies that focus on predictive maintenance using Digital Twins to pave the way for further research.
Method
A systematic literature review (SLR) using an active learning tool is conducted on published primary studies on predictive maintenance using Digital Twins, in which 42 primary studies have been analyzed.
Results
This SLR identifies several aspects of predictive maintenance using Digital Twins, including the objectives, application domains, Digital Twin platforms, Digital Twin representation types, approaches, abstraction levels, design patterns, communication protocols, twinning parameters, and challenges and solution directions. These results contribute to a Software Engineering approach for developing predictive maintenance using Digital Twins in academics and the industry.
Conclusion
This study is the first SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models.",November 2022,"Systematic literature review, Active learning, Digital twin, Predictive maintenance",Information and Software Technology,2025-03-18T00:00:00,9.0,"The systematic literature review on predictive maintenance using Digital Twins offers valuable insights and solutions for challenges in developing predictive maintenance models, which can have a practical impact on European early-stage ventures looking to enhance their maintenance strategies."
https://www.sciencedirect.com/science/article/pii/S0950584922001318,UX professionals’ learning and usage of UX methods in agile,Åsa=Cajander: asa.cajander@it.uu.se; Marta=Larusdottir: marta@ru.is; Johannes L.=Geiser: jogeiser@icloud.com,"Abstract
Context
The usage of 
User Experience
 (UX) methods has been studied through the years. However, little is known about UX professionals’ 
lifelong learning
 processes related to UX methods in Agile, choosing what UX methods to use, and the enablers and hindrances for using the UX methods.
Objective
The study aims to broaden current knowledge about UX professionals’ lifelong learning practices to understand their work situations better. The paper describes how UX professionals learn about and choose UX methods, their frequency of use, and the enablers and barriers when using the UX methods in Agile.
Method
An interview study was conducted with 13 UX professionals from various industries and two countries working with Agile and UX. We used a qualitative approach, and a thematic analysis was carried out to answer the research questions.
Results
The results show that support from colleagues is an essential component for learning about the methods and how to use UX methods. Time pressure makes UX professionals choose methods they know will deliver their desired results. Prototyping, user testing, user journeys, and workshops are the most frequently used UX methods. Additionally, the results show that UX professionals think that the UX methods are often too complicated and take too long to learn. Additionally, they find it challenging to integrate UX methods into Agile.
Conclusion
These findings indicate that UX methods might work better if designed to be less complicated and deliver results more efficiently. Moreover, collegial and 
peer learning
 is central to UX professionals. The HCI community could be more active in supporting this culture by sharing information and learning. Finally, the usability and UX of the tools affect which UX methods are used.",November 2022,"User experience, UX, Agile development, UX professionals, UX methods, Lifelong learning",Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on UX professionals' lifelong learning practices offers insights into improving UX methods, but the practical impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001276,Detecting relevant app reviews for software evolution and maintenance through multimodal one-class learning,Marcos P.S.=Gôlo: marcosgolo@usp.br; Adailton F.=Araújo: adailton.araujo@usp.br; Rafael G.=Rossi: rafael.g.rossi@ufms.br; Ricardo M.=Marcacini: ricardo.marcacini@icmc.usp.br,"Abstract
Context:
Mobile app reviews are a rich source of information for software evolution and maintenance. Several studies have shown the effectiveness of exploring relevant reviews in the 
software development lifecycle
, such as release planning and 
requirements engineering
 tasks. Popular apps receive even millions of reviews, thereby making manual extraction of relevant information an impractical task. The literature presents several 
machine learning approaches
 to detect relevant reviews. However, these approaches use multi-class learning, implying more user effort for data labeling since users must label a significant set of relevant and irrelevant reviews.
Objective:
This article investigates methods for detecting relevant app reviews considering scenarios with small sets of labeled data. We evaluated unimodal and multimodal representations, different labeling levels, as well as different app review domains and languages.
Method:
We present a one-class multimodal learning method for detecting relevant reviews. Our approaches have two main contributions. First, we use one-class learning that requires only the labeling of relevant app reviews, thereby minimizing the labeling effort. Second, to handle the smaller amount of labeled reviews without harming classification performance, we also present methods to improve feature extraction and reviews representation. We propose the Multimodal 
Autoencoder
 and the Multimodal 
Variational Autoencoder
. The methods learn representations which explore both textual data and visual information based on the density of the reviews. Density information can be interpreted as a summary of the main topics or clusters extracted from the reviews.
Results:
Our methods achieved competitive results even using only 25% of labeled reviews compared to models that used the entire training set. Also, our 
multimodal approaches
 obtain the highest 
F
1
-Score and AUC-ROC in twenty-three out of twenty-four scenarios.
Conclusion:
Our one-class multimodal methods proved to be a competitive alternative for detecting relevant reviews and promising for practical scenarios involving data-driven software evolution and maintenance.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The investigation on detecting relevant app reviews using multimodal learning with minimized labeling effort is highly practical and valuable for software evolution. The competitive results and practical scenarios make this research highly impactful.
https://www.sciencedirect.com/science/article/pii/S095058492200129X,Recruiting credible participants for field studies in software engineering research,Claes=Wohlin: claes.wohlin@bth.se,"Abstract
Context:
Software practitioners are a primary provider of information for 
field studies
 in 
software engineering
. Research typically recruits practitioners through some kind of sampling. But sampling may not in itself recruit the “right” participants.
Objective:
To assess existing guidance on participant recruitment, and to propose and illustrate a framework for recruiting professional practitioners as credible participants in field studies of software engineering.
Methods:
We review 
existing guidelines
, checklists and other advisory sources on recruiting participants for field studies. We develop a framework, partly based on our prior research and on the research of others. We search for and select three exemplar studies (a 
case study
, an interview study and a survey study) and use those to illustrate the framework.
Results:
Whilst existing guidance recognises the importance of recruiting participants, there is limited guidance on how to recruit the “right” participants. The framework suggests the conceptualisation of participants as “research instruments” or, alternatively, as a sampling frame for items of interest. The exemplars suggest that at least some members of the research community are aware of the need to carefully recruit the “right” participants.
Conclusions:
The framework is intended to encourage researchers to 
think differently
 about the involvement of practitioners in field studies of software engineering. Also, the framework identifies a number of characteristics not explicitly addressed by existing guidelines.",November 2022,"Credibility, Validity, Reliability, Data collection, Sampling, Subjects, Participants, Recruitment",Information and Software Technology,2025-03-18T00:00:00,4.0,"While the framework for recruiting professional practitioners in field studies of software engineering is valuable for research methodology, the direct impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922001306,A comprehensive empirical study on bug characteristics of deep learning frameworks,Yilin=Yang: yilin.yang@smail.nju.edu.cn; Yang=Feng: fengyang@nju.edu.cn,"Abstract
Context:
Deep Learning
 (DL) frameworks enable developers to build 
DNN
 models without learning the underlying algorithms and models. While some of these DL-based software systems have been deployed in safety-critical areas, such as self-driving cars and medical diagnostics, for DL frameworks, characterizing their bugs and thus helping researchers to design specific 
quality assurance techniques
 become desperately needed.
Objective:
Our research aims to characterize bugs typical of DL frameworks at the 
source code
 level for an in-depth analysis of bug symptoms, root causes, and bug fixes. In this way, we hope to provide insights for researchers to design automatic 
quality assurance techniques
, such as automatic repair techniques and 
fault location
 techniques, applicable to DL frameworks and DL-based software systems.
Method:
We started by summarizing the DL framework reference architecture and proposing the DL framework bug taxonomy. Then, we mined 1,127 DL framework 
bug reports
 from eight popular DL frameworks and labeled the bug types, root causes, and symptoms. Finally, we discussed the bug characteristics and explored how developers could possibly deal with these bugs.
Results:
Our main findings are: (i) 
DNN
 model building bugs and general type bugs accounted for one-third of the total defects. (ii) DNN model building bugs are more prone to algorithm logic constraints, internal API errors, and data/numerical errors. (iii) Fifteen bug-fixing patterns are summarized, providing reference for common DL framework bug repair and future research on the development of automatic DL framework bug detection tools.
Conclusion:
By analyzing the bug-fixing changes, we characterize the occurrences, root causes, symptoms, and fixing of these bugs. The study results have provided researchers with insights into how to ensure DL framework quality and presented actionable suggestions for DL framework developers to improve their code quality.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The research on characterizing bugs in DL frameworks provides valuable insights for quality assurance techniques, which are crucial in safety-critical areas. The study's outcomes offer practical benefits for developers working with DL frameworks."
https://www.sciencedirect.com/science/article/pii/S0950584922001264,Improving microservices extraction using evolutionary search,Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Khaled=Sellami: khaled.sellami.1@ulaval.ca; Mohamed Aymen=Saied: mohamed-aymen.saied@ift.ulaval.ca; Salah=Bouktif: salahb@uaeu.ac.ae,"Abstract
Context:
Microservices
 constitute a modern style of building 
software applications
 as collections of small, cohesive, and loosely coupled services, 
i.e.
, modules, that are developed, deployed, and scaled independently.
Objective:
The migration from legacy systems towards the microservice-based architecture is not a trivial task. It is still manual, time-consuming, error-prone and subsequently costly. The most critical and challenging issue is the cost-effective identification of microservices boundaries that ensure adequate 
granularity
 and cohesiveness.
Method:
To address this problem, we introduce in this paper a novel approach, named 
MSExtractor
 , that formulates microservices identification as a multi-objective 
optimization problem
. The proposed solution aims at decomposing a legacy application into a set of cohesive, loosely-coupled and coarse-grained services. We employ the Indicator-Based 
Evolutionary Algorithm
 (IBEA) to drive a search process towards optimal microservices identification while considering structural and 
semantic dependencies
 in the source code.
Results:
We conduct an empirical evaluation on a benchmark of seven software systems to assess the efficiency of our approach. Results show that 
MSExtractor
 is able to carry out an effective identification of relevant microservice candidates and outperforms three other existing approaches.
Conclusion:
In this paper, we show that MSExtractor is able to extract cohesive and loosely coupled services with higher performance than three other considered methods. However, we advocate that while automated microservices identification approaches are very helpful, the role of the human experts remains crucial to validate and calibrate the extracted microservices.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed approach addresses a crucial issue in migrating towards microservices and outperforms existing methods, which can benefit early-stage ventures in improving software architecture efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584922001434,Using clarification questions to improve software developers’ Web search,Mia Mohammad=Imran: imranm3@vcu.edu; Kostadin=Damevski: kdamevski@vcu.edu,"Abstract
Context:
Recent research indicates that Web queries written by software developers are not very successful in retrieving relevant results, performing measurably worse compared to general purpose Web queries. Most approaches up to this point have addressed this problem with software engineering-specific automated 
query reformulation
 techniques, which work without 
developer involvement
 but are limited by the content of the original query. In other words, these techniques automatically improve the existing query but cannot contribute new, previously unmentioned, concepts.
Objective:
In this paper, we propose a technique to guide software developers in manually improving their own 
Web search
 queries. We examine a conversational approach that follows unsuccessful queries with a clarification question aimed at eliciting additional query terms, thus providing to the developer a clear dimension along which the query could be improved.
Methods:
We describe a set of clarification questions derived from a corpus of software developer queries and a neural approach to recommending them for a newly issued query.
Results:
Our evaluation indicates that the recommendation technique is accurate, predicting a valid clarification question 80% of the time and outperforms simple baselines, as well as, state-of-the-art Learning To Rank (LTR) baselines.
Conclusion:
As shown in the experimental results, the described approach is capable at recommending appropriate clarification questions to software developers and considered useful by a sample of developers ranging from novices to experienced professionals.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The technique proposed can be useful for software developers to improve their web search queries, but may have limited direct impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001446,The essential competencies of software professionals: A unified competence framework,Nana=Assyne: nana.m.a.assyne@student.jyu.fi,"Abstract
Context
Developing high-quality software requires skilled software professionals equipped with a set of basic and essential software engineering competencies (SEC). These competencies and the satisfaction levels derived from them change over a project's lifecycle, or as software professionals move from one project to another.
Objective
Previous studies suggest a lack of means enabling SEC stakeholders to identify and assess competencies suitable for different projects. Additionally, previous research has mainly portrayed SEC to be static and overlooked their evolution over time and across projects. We investigate how we could effectively identify and match the competencies of software professionals necessary for different projects.
Method
We follow a mixed-method approach to iteratively develop and evaluate a framework for identifying and managing SEC. In so doing, we use the results of an extensive literature review, focus 
group discussions
 with experts from academia and 
industry
, and 
data collected
 through interviews with 138 individuals with a supervisory role in the software industry.
Results
Drawing on the Kano model and Competency Framework for Software Engineers, we propose a Unified Competence Gate for Software Professionals (UComGSP), a framework for identifying and managing SEC. The UComGSP consists of 62 hard competencies, 63 soft competencies, and 25 essential SEC competencies. Additionally, we propose three stakeholders’ satisfaction levels for SEC assessment: basic, performance, and delighter. Furthermore, based on empirical observation, we report 27 competencies not mentioned in the reviewed literature; 11 of them are considered essential competencies.
Conclusion
Competence development involves different stakeholders, including software professionals, educators, and the software industry. The UComGSP framework enables SEC stakeholders to (i) identify SE competencies, (ii) identify the essential SEC, and (iii) assess the satisfaction levels that can be derived from different competencies. Future research is needed to evaluate the effectiveness of the proposed framework across software development projects.",November 2022,"Software engineering, Software development, Competence, Competencies, Kano model",Information and Software Technology,2025-03-18T00:00:00,9.0,The framework introduced for identifying and managing software engineering competencies can be highly valuable for early-stage ventures in optimizing team composition and project success.
https://www.sciencedirect.com/science/article/pii/S0950584922001458,A multi-objective agile project planning model and a comparative meta-heuristic approach,Nilay=Ozcelikkan: nilay.ozcelikkan@gmail.com; Gulfem=Tuzkaya: gulfem.tuzkaya@marmara.edu.tr; Cigdem=Alabas-Uslu: cigdem.uslu@marmara.edu.tr; Bahar=Sennaroglu: bsennar@marmara.edu.tr,"Abstract
Agile software development
 methodologies are used to meet the changing needs in the market. The most popular framework among these methodologies is the Scrum framework. In Scrum planning, the assignment of user stories to sprints requires the consideration of multiple objectives to use the limited resources more effectively. In this paper, a multi-objective mixed-integer programming model is developed which considers three objectives: maximizing the sprint capacity usage, maximizing the assignment of user stories with high priority to primary sprints, and maximizing the assignment of affine user stories to the same sprint. The aim is to contribute to both theory and practice of Scrum planning considering multiple objectives. Additionally, different from the existing literature of Scrum planning, alternative user stories are also taken into account. The proposed model is applied to the small, medium, and big-sized instances of the problem taken from a real-life system. Non-dominated Sorting 
Genetic Algorithm
 (NSGA-II) and Strong Pareto 
Evolutionary Algorithm
 (SPEA2) are used as heuristic approaches since big-sized instances of the problem could not be solved using optimization approaches. To analyze the performances of these algorithms, Hypervolume (HV), Epsilon (
ϵ
), Generational Distance (GD), Inverted Generational Distance (IGD), Inverted Generational Distance Plus (IGD+), and Spread (
Δ
) indicators are used. Results showed that NSGA-II performs better than SPEA2 according to 
ϵ
 indicator for big-sized instance. On the other hand, SPEA2 performs better than NSGA-II according to HV, GD, IGD, IGD+, and 
Δ
 indicators. However, the results are very close to each other for HV, 
ϵ
, IGD, and IGD+ indicators. In conclusion, both algorithms can be used to deal with the multi-objective Scrum planning problem.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The multi-objective approach for Scrum planning contributes to theory and practice, benefiting early-stage ventures in efficient resource allocation, but the direct impact may vary based on the size of the venture."
https://www.sciencedirect.com/science/article/pii/S0950584922001495,Towards a model and methodology for evaluating data quality in software engineering experiments,Carolina=Valverde: mvalverde@fing.edu.uy,"Abstract
Context
Data collected
 during 
software engineering
 experiments might contain quality problems, leading to wrong experimental conclusions.
Objective
We present a 
data quality
 (DQ) model and a methodology specific to 
software engineering
 experiments, which provides a systematic approach in order to analyze and improve 
data quality
 in this domain.
Method
Our proposal considers a multifaceted view of data quality suitable for this context, which enables the discovery of DQ problems that are not generally addressed. We successfully applied the model (DQMoS) and methodology (DQMeS) in four controlled experiments, detecting different quality problems that could impact the experimental results. We present, through a running example, how we applied the DQMoS and DQMeS to one of the four experimental data.
Results
We found that between 55% and 75% of the 
DQ metrics
 applied showed the presence of a DQ problem in all four experiments. In all cases, the experimental results had already been obtained before the DQMeS application. This means that the DQ problems we found, were not discovered by the experimenters during or before making their experiment's analysis. Results yield data quality problems that experimenters did not detect on their own analysis, and that affect the experimental response variables. Our proposal shows a formalized framework that measures and improves the 
quality of software
 engineering experimental data. The results of a survey distributed to the experiments’ responsibles show that they value the improvements introduced by the model and methodology, and that they intend to apply them again in future experiences.
Conclusions
DQMoS and DQMeS are useful to increase the confidence in the quality of data used in software engineering experiments, and improve the trust in experimental results.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The DQ model and methodology introduced can significantly improve the quality of data in software engineering experiments, leading to more reliable results, which can benefit early-stage ventures in decision-making and product development."
https://www.sciencedirect.com/science/article/pii/S095058492200146X,S-DABT: Schedule and Dependency-aware Bug Triage in open-source bug tracking systems,Hadi=Jahanshahi: hadi.jahanshahi@ryerson.ca,"Abstract
Context:
In 
software engineering
 practice, fixing bugs in a timely manner lowers various potential costs in software maintenance. However, manual bug fixing scheduling can be time-consuming, cumbersome, and error-prone.
Objective:
In this paper, we propose the Schedule and Dependency-aware Bug Triage (S-DABT), a bug triaging method that utilizes 
integer programming
 and 
machine learning techniques
 to assign bugs to suitable developers.
Methods:
Unlike prior works that largely focus on a single component of the 
bug reports
, our approach takes into account the textual data, bug fixing costs, and bug dependencies. We further incorporate the schedule of developers in our formulation to have a more comprehensive model for this multifaceted problem. As a result, this complete formulation considers developers’ schedules and the blocking effects of the bugs while covering the most significant aspects of the previously proposed methods.
Results:
Our numerical study on four open-source software systems, namely, ECLIPSEJDT, LIBREOFFICE, GCC, and MOZILLA, shows that taking into account the schedules of the developers decreases the average bug fixing times. We find that S-DABT leads to a high level of developer utilization by a fair distribution of the tasks among the developers and efficient use of the free spots in their schedules. Via the simulation of the issue tracking system, we also show how incorporating the schedule in the model formulation reduces the bug fixing time, improves the assignment accuracy, and utilizes the capability of each developer without much comprising in the model run times.
Conclusion:
We find that S-DABT decreases the complexity of the bug 
dependency graph
 by prioritizing blocking bugs and effectively reduces the infeasible assignment ratio due to bug dependencies. Consequently, we recommend considering developers’ schedules while automating bug triage.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed bug triaging method shows practical value in reducing bug fixing times and increasing developer utilization, with tangible results from numerical studies on open-source software systems."
https://www.sciencedirect.com/science/article/pii/S0950584922001422,Sentiment analysis tools in software engineering: A systematic mapping study,Martin=Obaidi: martin.obaidi@inf.uni-hannover.de; Lukas=Nagel: lukas.nagel@inf.uni-hannover.de; Alexander=Specht: alexander.specht@inf.uni-hannover.de; Jil=Klünder: jil.kluender@inf.uni-hannover.de,"Abstract
Context:
Software development is a collaborative task. Previous research has shown 
social aspects
 within development teams to be highly relevant for the success of software projects. A team’s mood has been proven to be particularly important. It is paramount for project managers to be aware of negative moods within their teams, as such awareness enables them to intervene. 
Sentiment analysis
 tools offer a way to determine the mood of a team based on textual communication.
Objective:
We aim to help developers or stakeholders in their choice of sentiment analysis tools for their specific purpose. Therefore, we conducted a 
systematic mapping study
 (SMS).
Methods:
We present the results of our SMS of sentiment analysis tools developed for or applied in the context of 
software engineering
 (SE). Our results summarize insights from 106 papers with respect to (1) the application domain, (2) the purpose, (3) the used data sets, (4) the approaches for developing sentiment analysis tools, (5) the usage of already existing tools, and (6) the difficulties researchers face. We analyzed in more detail which tools and approaches perform how in terms of their performance.
Results:
According to our results, sentiment analysis is frequently applied to open-source software projects, and most approaches are 
neural networks
 or support-vector machines. The best performing approach in our analysis is 
neural networks
 and the best tool is 
BERT
. Despite the frequent use of sentiment analysis in SE, there are open issues, e.g. regarding the identification of irony or sarcasm, pointing to future research directions.
Conclusion:
We conducted an SMS to gain an overview of the current state of sentiment analysis in order to help developers or stakeholders in this matter. Our results include interesting findings e.g. on the used tools and their difficulties. We present several suggestions on how to solve these identified problems.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The systematic mapping study on sentiment analysis tools provides valuable insights for developers and stakeholders, highlighting the best performing approaches and tools in software engineering."
https://www.sciencedirect.com/science/article/pii/S0950584922001069,On the effectiveness of testing sentiment analysis systems with metamorphic testing,Tsong Yueh=Chen: tychen@swin.edu.au; Mingyue=Jiang: mjiang@zstu.edu.cn; Shuai=Wang: shuaiw@cse.ust.hk,"Abstract
Context:
Metamorphic testing (MT) has been successfully applied to a wide scope of software systems. In these applications, the testing results of MT form the basis for drawing conclusions about the target system’s performance. Therefore, the effectiveness of MT is crucial to the trustfulness of the derived conclusions.
Objective:
However, due to the nature of MT, its effectiveness can be affected by various factors. Despite of MT’s success, it is still important to study its effectiveness under different application contexts.
Method:
To investigate the effectiveness of MT, we focus on an important aspect, namely, false satisfactions (which are satisfactions of metamorphic relations that involve at least one failing execution), and revisit the application of MT to 
sentiment analysis
 (SA) systems. An in-depth analysis of the essence of false satisfactions reveals the situations where they would occur, and how they would affect the effectiveness of MT. Furthermore, 20 metamorphic relations (MRs) are identified for supporting a user-oriented evaluation of SA systems.
Results:
The occurrence rates of false satisfactions are reported with respect to four SA systems. For the majority of MRs, false satisfactions account for about 20% to 50% of all MR satisfactions, suggesting that false satisfactions occur quite frequently in the evaluation of SA systems. It is also demonstrated that such high occurrence rates of false satisfactions adversely affect the users’ selection of SA systems.
Conclusion:
Our analysis reveals that without considering the occurrence of false satisfactions, MT may overestimate the system’s conformance to the relevant MR. Furthermore, our experiments empirically show that conclusions derived from MT can be adversely affected when there are many false satisfactions. Our findings will help the MT community to adopt a more fair and reliable way of using the test outcomes of MT, and can also inspire the development of solid foundations for MT.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Studying the effectiveness of Metamorphic Testing in different application contexts, such as sentiment analysis systems, can provide essential insights for startups looking to ensure the trustworthiness of their software systems, leading to more reliable testing outcomes."
https://www.sciencedirect.com/science/article/pii/S095058492200132X,Collaborative program comprehension via software visualization in extended reality,Alexander=Krause-Glau: akr@informatik.uni-kiel.de,"Abstract
Context:
In software visualization research, various approaches strive to create 
immersive environments
 by employing 
extended reality
 devices. In that context, only few research has been conducted on the effect of collaborative, i.e., multi-user, extended reality environments.
Objective:
We present our journey toward a web-based approach to enable (location-independent) collaborative 
program comprehension
 using desktop, virtual reality, and mobile 
augmented reality
 devices.
Method:
We designed and implemented three multi-user modes in our web-based live trace visualization tool ExplorViz. Users can employ desktop, mobile, and virtual reality devices to collaboratively explore software visualizations. We conducted two preliminary user studies in which subjects evaluated our VR and AR modes after solving common program comprehension tasks.
Results:
The VR and AR environments can be suitable for collaborative work in the context of program comprehension. The analyzed feedback revealed problems regarding the usability, e.g., readability of visualized entities and performance issues. Nonetheless, our approach can be seen as a blueprint for other researchers to replicate or build upon these modes and results.
Conclusions:
ExplorViz’s multi-user modes are our approach to enable heterogeneous 
collaborative software
 visualizations. The preliminary results indicate the need for more research regarding effectiveness, usability, and acceptance. Unlike related work, we approach the latter by introducing a multi-user augmented reality environment for software visualizations based on off-the-shelf mobile devices.",November 2022,"Program comprehension, Software visualization, City metaphor, Extended reality, Virtual reality, Augmented reality",Information and Software Technology,2025-03-18T00:00:00,6.0,"The web-based approach for collaborative program comprehension using extended reality devices presents an interesting concept for software visualization research, despite needing more research on usability and acceptance."
https://www.sciencedirect.com/science/article/pii/S0950584922001471,Automatically repairing tensor shape faults in deep learning programs,Dangwei=Wu: wudangwei@sjtu.edu.cn; Beijun=Shen: bjshen@sjtu.edu.cn; Yuting=Chen: chenyt@sjtu.edu.cn; He=Jiang: jianghe@dlut.edu.cn; Lei=Qiao: fly2moon@163.com,"Abstract
Context:
Software developers frequently invoke 
deep learning
 (DL) APIs to incorporate 
artificial intelligence
 solutions into software systems. However, misuses of these APIs can cause various DL faults, such as 
tensor shape faults
. Tensor shape faults occur when restriction conditions of operations are not met; they are prevalent in practice, leading to many system crashes. Meanwhile, researchers and engineers still face a strong challenge in detecting tensor shape faults — static techniques incur heavy overheads in defining detection rules, and the only dynamic technique requires human engineers to rewrite APIs for tracking shape changes.
Objective:
This paper introduces a novel technique that leverages 
machine learning
 to detect tensor shape faults, and as well uses patterns to repair faults detected.
Methods:
We first construct SFData, a set of 146 buggy programs with 
crashing tensor shape faults
 (i.e., those causing programs to crash). We also conduct an empirical study on crashing tensor shape faults, categorizing them into four types and revealing twelve repair patterns. Then we propose Tensfa2, an automated approach to detecting and repairing crashing tensor shape faults. Tensfa2 employs a 
machine learning method
 to learn from crash messages and 
decision trees
 to detect tensor shape faults. Next, Tensfa2 tracks shape properties by a customized Python 
debugger
, analyzes their 
data dependences
, and uses the twelve patterns to generate patches. Tensfa2 is an extended version of Tensfa—our previous approach presented at ISSRE’21. Its performance is enhanced by two techniques: a search-based method for repairing shape value faults, and a bundle of three ranking strategies for prioritizing the repair patterns.
Results:
Tensfa2 is evaluated on SFData and IslamData (another dataset of tensor shape faults). The results show the effectiveness of Tensfa2. In particular, Tensfa2 achieves an F1-score of 96.88% in detecting the faults and repairs 82 out of 146 buggy programs in SFData.
Conclusion:
We believe that repair patches generated by our approach will help engineers fix their 
deep learning
 programs much more efficiently, saving their time and efforts.",November 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The novel technique leveraging machine learning to detect and repair tensor shape faults in deep learning programs shows significant impact in improving efficiency for software developers, with impressive results in fault detection and program repairs."
https://www.sciencedirect.com/science/article/pii/S0950584922001033,Find potential partners: A GitHub user recommendation method based on event data,Huaxiao=Liu: liuhuaxiao@jlu.edu.cn,"Abstract
Context:
GitHub has attracted much popularity among a large number of software developers around the world and introduced the social function 
follow
 to strengthen the relationship among developers. Like other social networks, GitHub users usually follow others who are popular in the community, co-workers, or friends in real life. However, according to our investigation, more than half of GitHub users prefer to follow recently like-minded developers other than their traditional networks for communicating with timely feedback, discovering niche repositories, and attracting more active contributors to cooperate, while these users are hard to find.
Objective:
Our objective in this paper is to leverage recent activities-
Event Data
 of GitHub users and conduct a recommendation approach to help them match some recently like-minded developers to follow or reach out.
Methods:
As a first step, we conduct one empirical research—an online survey to investigate and analyze the opinions of GitHub users whether they are willing to follow others with similar recent events and which kind of events they will focus on during the follow process. Regarding the results from our survey, we partition 12 types of events focused by participants into three 
Event
 sets of 
Communication
, 
Exploration
, and 
Cooperation
. As a second step, we collect 
Event Data
 of 12,713 GitHub users who participated in repositories written in python and build a time-based multi-dimensional recommendation approach based on a calculating vector-similarity method, a 
clustering approach
, and a 
deep learning model
.
Results and Conclusion:
The experimental results show that our approach achieves an improvement of 607.64%, 564.59%, and 599.19% on average compared with two baselines in terms of 
P
r
e
c
i
s
i
o
n
@
N
, 
R
e
c
a
l
l
@
N
, and 
F
1
−
S
c
o
r
e
@
N
. Such a series of experiments have proved that our method is effective and feasible.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The recommendation approach for matching like-minded developers on GitHub can potentially benefit early-stage ventures by improving communication and cooperation, but the focus on GitHub users may limit its impact."
https://www.sciencedirect.com/science/article/pii/S0950584922000994,How higher order mutant testing performs for deep learning models: A fine-grained evaluation of test effectiveness and efficiency improved from second-order mutant-classification tuples,Lin=Chen: lchen@nju.edu.cn,"Abstract
Context:
Given the prevalence of 
Deep Learning
 (DL) models in 
daily life
, it is crucial to guarantee their reliability by 
DL
 testing. Recently, researchers have adapted mutation testing into 
DL
 testing to measure the test power of test sets. The bottleneck of DL mutation testing is the expensive costs of generating a large number of mutants.
Objective:
We want to study whether the traditional ideology of “Higher Order” and “Strongly Subsuming” in Higher Order Mutant Testing is still applicable for DL mutation testing, i.e., whether they can be used to optimize DL mutation testing by reducing the number of mutants.
Method:
We propose a new mutation testing framework supporting a fine-grained evaluation of test power, called mutant-classification tuples which consist of mutants and classification categories. Based on mutant-classification tuples, we construct First Order (FOTs) and Higher (Second) Order Tuples (HOTs) by applying 
mutation operators
 twice, and search for “Strongly Subsuming” HOTs (SSHOTs) from HOTs.
Results:
The experimental results conducted on four widely used datasets and five DL model structures tell us that (1) we can find a considerable number of SSHOTs (from 720 to 25,840 in five models) which can greatly reduce the 
original set
 of FOTs (with the reduction ratio from 28.69% to 91.97% in our studied DL models). (2) The reduced tuples by SSHOTs can perform very well in test case selection, since the selected test set is almost the same effective (i.e., with almost the same mutation score) and much more efficient (i.e., with a smaller test size, which is more than 50% reduced) for most studied DL models.
Conclusions:
Our study shows that “Higher Order” and “Strongly Subsuming” are useful to optimize DL mutation testing, i.e., SSHOTs can be introduced to reduce the number of mutants and test cases.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Optimizing DL mutation testing using 'Higher Order' and 'Strongly Subsuming' concepts can have practical implications for early-stage ventures working with DL models, potentially improving efficiency and effectiveness in testing."
https://www.sciencedirect.com/science/article/pii/S0950584922001082,An empirical study of IoT security aspects at sentence-level in developer textual discussions,Gias=Uddin: gias.uddin@ucalgary.ca,"Abstract
Context:
IoT
 is a rapidly emerging paradigm that now encompasses almost every aspect of our modern life. As such, ensuring the security of 
IoT devices
 is crucial. 
IoT
 devices can differ from traditional computing (e.g., low power, storage, computing), thereby the design and implementation of proper security measures can be challenging in 
IoT devices
. We observed that IoT developers discuss their security-related challenges in developer forums like Stack Overflow (SO). However, we find that IoT security discussions can also be buried inside non-security discussions in SO.
Objective:
In this paper, we aim to understand the challenges IoT developers face while applying security practices and techniques to IoT devices. We have two goals: (1) Develop a model that can automatically find security-related IoT discussions in SO, and (2) Study the model output (i.e., the security discussions) to learn about IoT developer security-related challenges.
Methods:
First, we download all 53K posts from StackOverflow (SO) that contain discussions about various IoT devices, tools, and techniques. Second, we manually labeled 5,919 sentences from 53K posts as 1 or 0 (i.e., whether they contain a 
security aspect
 or not). Third, we then use this benchmark to investigate a suite of 
deep learning
 transformer models. The best performing model is called SecBot. Fourth, we apply SecBot on the entire 53K posts and find around 30K sentences labeled as security. Fifth, we apply 
topic modeling
 to the 30K security-related sentences labeled by SecBot. Then we label and categorize the topics. Sixth, we analyze the evolution of the topics in SO.
Results:
We found that (1) SecBot is based on the retraining of the 
deep learning model
 RoBERTa. SecBot offers the best F1-Score of .935, (2) there are six error categories in misclassified samples by SecBot. SecBot was mostly wrong when the keywords/contexts were ambiguous (e.g., ‘gateway’ can be a 
security gateway
 or a simple gateway), (3) there are 9 security topics grouped into three categories: Software, Hardware, and Network, and (4) the highest number of topics belongs to software security, followed by 
network security
 and hardware security.
Conclusion:
IoT researchers and vendors can use SecBot to collect and analyze security-related discussions from developer discussions in SO. The analysis of nine security-related topics can guide major IoT stakeholders like IoT Security Enthusiasts, Developers, Vendors, Educators, and Researchers in the rapidly emerging IoT ecosystems.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Developing a model like SecBot to automatically identify security-related IoT discussions in developer forums can significantly benefit startups in ensuring the security of IoT devices, providing valuable insights into challenges faced by IoT developers."
https://www.sciencedirect.com/science/article/pii/S095058492200101X,Approaches to manage the user experience process in Agile software development: A systematic literature review,Jörg=Thomaschewski: joerg.thomaschewski@hs-emden-leer.de; Andreas=Hinderks: andreas.hinderks@iwt2.org; Francisco José=Domínguez Mayo: fjdominguez@us.es; María José=Escalona: mjescalona@us.es,"Abstract
Context:
Software development companies use Agile methods to develop their products or services efficiently and in a goal-oriented way. But this alone is not enough to satisfy user demands today. It is much more important nowadays that a product or service should offer a great 
user experience
 — the user wants to have some positive user experience while interacting with the product or service.
Objective:
An essential requirement is the integration of user experience methods in 
Agile software development
. Based on this, the development of positive user experience must be managed. We understand management in general as a combination of a goal, a strategy, and resources. When applied to UX, user experience management consists of a UX goal, a UX strategy, and UX resources.
Method:
We have conducted a systematic literature review (SLR) to analyse suitable approaches for managing user experience in the context of Agile software development.
Results:
We have identified 49 relevant studies in this regard. After analysing the studies in detail, we have identified different primary approaches that can be deemed suitable for UX management. Additionally, we have identified several UX methods that are used in combination with the primary approaches.
Conclusions:
However, we could not identify any approaches that directly address UX management. There is also no general definition or common understanding of UX management. To successfully implement UX management, it is important to know what UX management actually is and how to measure or determine successful UX management.",October 2022,"User experience management, UX process, User experience, UX, Usability, HCI, Agile methods, Agile, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,7.0,"This abstract addresses the importance of integrating user experience methods in Agile software development, which can have a significant impact on European early-stage ventures by improving user satisfaction and product quality."
https://www.sciencedirect.com/science/article/pii/S0950584922000921,The role of awareness and gamification on technical debt management,Yania=Crespo: yania@infor.uva.es; Carlos=López-Nozal: clopezno@ubu.es; Raúl=Marticorena-Sánchez: rmartico@ubu.es; Margarita=Gonzalo-Tasis: marga@infor.uva.es; Mario=Piattini: Mario.Piattini@uclm.es,"Abstract
Context:
Managing technical debt and developing easy-to-maintain software are very important aspects for technological companies. Integrated development environments (IDEs) and static measurement and analysis tools are used for this purpose. Meanwhile, 
gamification
 also is gaining popularity in professional settings, particularly in software development.
Objective:
This paper aims to analyse the improvement in technical debt indicators due to the use of techniques to raise developers’ awareness of technical debt and the introduction of 
gamification
 into technical debt management.
Method:
A quasi-experiment that manipulates a training environment with three different treatments was conducted. The first treatment was based on training in the concept of technical debt, bad smells and refactoring, while using multiple plugins in IDEs to obtain reports on quality indicators of both the code and the tests. The second treatment was based on enriching previous training with the use of 

 to continuously raise awareness of technical debt. The third was based on adding a 
gamification
 component to technical debt management based on a contest with a top ten ranking. The results of the first treatment are compared with the use of 

 for continuously raising developers’ awareness of technical debt; while the possible effect of 
gamification
 is compared with the results of the previous treatment.
Results:
It was observed that continuously raising awareness using a technical debt management tool, such as 

 , significantly improves the technical debt indicators of the code developed by the participants versus using multiple code and test quality checking tools. On the other hand, incorporating some kind of competition between developers by defining a contest and creating a ranking does not bring about any significant differences in the technical debt indicators.
Conclusion:
Investment in staff training through tools to raise developers’ awareness of technical debt and incorporating it into continuous integration pipelines does bring improvements in technical debt management.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract explores the use of gamification and tools to raise developers' awareness of technical debt, which can benefit startups in improving software quality and maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584922001185,Can test input selection methods for deep neural network guarantee test diversity? A large-scale empirical study,Xiang=Chen: xchencs@ntu.edu.cn; Chunyu=Zhao: 2010320004@stmail.ntu.edu.cn; Yanzhou=Mu: 2019218009@tju.edu.cn; Jingke=Zhao: ke1206371563@gmail.com; Xiaolin=Ju: ju.xl@ntu.edu.cn; Gan=Wang: wg_98@tju.edu.cn,"Abstract
Context:
Recently, various methods on test input selection for deep 
neural network
 (TIS-DNN) have been proposed. These methods can effectively reduce the labeling cost by selecting a subset from the original test inputs, which can still accurately estimate the performance (such as accuracy) of the target 
DNN models
.
Objective:
Previous studies on TIS-DNN mainly focused on the performance on all the classes. However, the selected subset may miss the coverage of some classes or decrease the performance on some classes, which will reduce the test diversity of the original test inputs.
Methods:
Therefore, we conducted a large-scale empirical study to investigate whether previous TIS-DNN methods can guarantee test diversity in the subset. In our study, we selected five state-of-the-art TIS-DNN methods: SRS, 
CSS
, CES, DeepReduce and PACE. Then we selected 18 pairs of 
DNN models
 and the corresponding test inputs from seven popular DNN datasets.
Results:
Our experimental results can be summarized as follows. (1) Previous TIS-DNN methods can guarantee the performance on all the classes. However, these methods have a 
negative impact
 on the test diversity and the performance on each class is not satisfactory. (2) Reducing the performance 
estimation error
 on each class can help reduce the 
estimation error
 on the test adequacy of the original inputs based on DNN-based coverage criteria (especially for the criterion NC and the criterion TKNC). (3) There still exists great room for 
performance improvement
 (i.e., 7.637% improvement on all the classes and 12.833% improvement on each class) after comparing the TIS-DNN method PACE with approximately optimal solutions.
Conclusion:
The above experimental findings implicate there is still a long way for the TIS-DNN issue to go. Given this, we present observations about the road ahead for this issue.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on test input selection for deep neural networks provides insights into improving performance estimation, but it may not have a direct practical impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001203,A three-stage transfer learning framework for multi-source cross-project software defect prediction,Jingdong=Jia: jiajingdong@buaa.edu.cn,"Abstract
Context
Transfer learning techniques have been proved to be effective in the field of Cross-project defect prediction (CPDP). However, some questions still remain. First, the conditional distribution difference between source and target projects has not been considered. Second, facing multiple source projects, most studies only rarely consider the issues of source selection and multi-source data utilization; instead, they use all available projects and merge multi-source data together to obtain one final dataset.
Objective
To address these issues, in this paper, we propose a three-stage weighting framework for multi-source 
transfer learning
 (3SW-MSTL) in CPDP. In stage 1, a source selection strategy is needed to select a suitable number of source projects from all available projects. In stage 2, a transfer technique is applied to minimize marginal differences. In stage 3, a multi-source data utilization scheme that uses conditional distribution information is needed to help guide researchers in the use of multi-source transferred data.
Method
First, we have designed five source selection strategies and four multi-source utilization schemes and chosen the best one to be used in stage 1 and 3 in 3SW-MSTL by comparing their influences on prediction performance. Second, to validate the performance of 3SW-MSTL, we compared it with four multi-source and six single-source CPDP methods, a baseline within-project defect prediction (WPDP) method, and two unsupervised methods on the data from 30 widely used open-source projects.
Results
Through experiments, bellwether and weighted vote are separately chosen as a source selection strategy and a multi-source utilization scheme used in 3SW-MSTL. And, our results indicate that 3SW-MSTL outperforms four multi-source, six single-source CPDP methods and two unsupervised methods. And, 3SW-MSTL is comparable to the WPDP method.
Conclusion
The proposed 3SW-MSTL model is more effective for considering the two issues mentioned before.",October 2022,"Transfer learning, Cross-project defect prediction, Source selection, Multi-source utilization, 3SW-MSTL",Information and Software Technology,2025-03-18T00:00:00,9.0,The proposed three-stage weighting framework for multi-source transfer learning in Cross-project defect prediction can greatly benefit European early-stage ventures by improving prediction performance and addressing key issues.
https://www.sciencedirect.com/science/article/pii/S0950584922000878,Alternatives for testing of context-aware software systems in non-academic settings: results from a Rapid Review,,"Abstract
Context
Context-awareness challenges the engineering of contemporary software systems and jeopardizes their testing. The variation of context represents a relevant behavior that deepens the limitations of available software testing practices and technologies. However, such software systems are mainstream. Therefore, researchers in non-academic settings also face challenges when developing and testing contemporary software systems.
Objective
To understand how researchers deal with the variation of context when testing context-aware software systems developed in non-academic settings.
Method
To undertake a secondary study (
Rapid Review
) to uncover the necessary evidence from primary sources describing the testing of context-aware software systems outside academia.
Results
The current testing initiatives in non-academic settings aim to generate or improve test suites that can deal with the context variation and the sheer volume of test input possibilities. They mostly rely on modeling the systems' dynamic behavior and increasing computing resources to generate test inputs to achieve this. We found no evidence of test results aiming at managing context variation through the testing lifecycle process.
Conclusions
So far, the identified testing initiatives and strategies are not ready for mainstream adoption. They are all domain-specific, and while the ideas and approaches can be reproduced in distinct settings, the technologies are to be re-engineered and tailored to the context-awareness of contemporary software systems in different problem domains. Further and joint investigations in academia and experiences in non-academic settings can evolve the body of knowledge regarding the testing of contemporary software systems in the field.",September 2022,"Context-aware software systems, Software testing, Rapid review, Contemporary software systems",Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract discusses challenges in testing context-aware software systems, but the identified testing initiatives are not ready for mainstream adoption. The focus on testing practices may have limited immediate practical value for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001197,System and software architecting harmonization practices in ultra-large-scale systems of systems: A confirmatory case study,Paris=Avgeriou: p.avgeriou@rug.nl; Héctor=Cadavid: h.f.cadavid.rengifo@rug.nl; Vasilios=Andrikopoulos: v.andrikopoulos@rug.nl; P. Chris=Broekema: broekema@astron.nl,"Abstract
Context:
The challenges posed by the architecting of System of Systems (SoS) has motivated a significant number of research efforts in the area. However, literature is lacking when it comes to the interplay between the disciplines involved in the 
architecting process
, a key factor in addressing these challenges.
Objective:
This paper aims to contribute to this line of research by confirming and extending previously characterized architecting harmonization practices from Systems and 
Software Engineering
, adopted in an ultra-large-scale SoS.
Methods:
We conducted a confirmatory 
case study
 on the Square-Kilometre Array (SKA) project to evaluate and extend the findings of our exploratory case on the LOFAR/LOFAR2.0 radio-telescope projects. In doing so, a pre-study was conducted to map the findings of the previous study with respect to the SKA context. A survey was then designed, through which the views of 46 SKA engineers were collected and analyzed.
Results:
The study confirmed in various degrees the four practices identified in the exploratory case, and provided further insights about them: (1) the friction between disciplines caused by long-term 
system requirements
, and how they can be ameliorated through intermediate, short-term requirements; (2) the way design choices with a cross-cutting impact on multiple agile teams have an indirect impact on the 
system architecture
; (3) how these design choices are often caused by the criteria that guided early system decomposition; (4) the seemingly 
recurrent
 issue with the lack of details about the dynamic elements of the interfaces; and (5) the use of machine-readable 
interface specifications
 for aligning hardware/software development processes.
Conclusions:
The findings of this study and its predecessor support the importance of a cross-disciplinary view in the Software Engineering 
research agenda
 in SoS as a whole, not to mention their value as a convergence point for research on SoS architecting from the Systems and Software Engineering standpoints.",October 2022,"Systems of systems, SoS architecting, Confirmatory case study, Empirical software engineering, Scientific instruments, Qualitative research",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on architecting practices in System of Systems contributes valuable insights, but the practical impact on European early-stage ventures may be limited without direct implementation strategies."
https://www.sciencedirect.com/science/article/pii/S0950584922001215,Keyword-guided abstractive code summarization via incorporating structural and contextual information,Wuyan=Cheng: wuyanc@mails.ccnu.edu.cn; Po=Hu: phu@mail.ccnu.edu.cn; Shaozhi=Wei: wsz@mails.ccnu.edu.cn; Ran=Mo: moran@mail.ccnu.edu.cn,"Abstract
Context:
Source code
 summarization is a crucial yet far from settled task for describing structured code snippets in natural language. High-quality code summaries could effectively facilitate 
program comprehension
 and software maintenance. A good code summary is supposed to have the following characteristics: complete information, correct meaning, and consistent description. In recent years, numerous approaches have been proposed for code summarization, but it is still very challenging for developers to automatically learn the complex semantics from the source code and generate complete, correct and consistent code summaries.
Objective:
In this paper, we propose 
KGCodeSum
, a novel keyword-guided abstractive code summarization approach that incorporates structural and contextual information.
Methods:
To improve summaries’ quality, we leverage both the structural 
information embedded
 in code itself and the contextual information from related code snippets. Meanwhile, we make use of keywords to guide summaries’ generation to guarantee the code summaries contain key information. Finally, we propose a new dynamic vocabulary strategy which can effectively resolve the UNK problems in code summaries.
Results:
Through our evaluation on the large-scale benchmark datasets with 2.1 million java method-comment pairs and 1.1 million C/C++ function-summary pairs, We have observed that our approach could generate better code summaries than existing state-of-the-art approaches in terms of completeness, correctness and consistency. In addition, we also find that incorporating the dynamic vocabulary strategy into our approach could significantly save time and space in the model training process.
Conclusion:
Our 
KGCodeSum
 approach could effectively generate code summaries.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The KGCodeSum approach addresses a crucial task in software development, improving the quality of code summaries. The incorporation of structural and contextual information, along with a dynamic vocabulary strategy, results in better code summaries than existing approaches. This has a practical value for developers in understanding and maintaining code."
https://www.sciencedirect.com/science/article/pii/S0950584922001252,Test case recommendation based on balanced distance of test targets,Chunrong=Fang: fangchunrong@nju.edu.cn; Xingya=Wang: xingyawang@outlook.com; Quanjun=Zhang: quanjun.zhang@smail.nju.edu.cn; Ziyuan=Wang: wangziyuan@njupt.edu.cn; Weisong=Sun: weisongsun@smail.nju.edu.cn; Yuchen=Chen: yuc.chen@outlook.com,"Abstract
Context:
Unit testing has been widely regarded as an effective technique to ensure software quality. Writing unit test cases is time-consuming and requires developers to have abundant knowledge and experience. Automated test case generation, a promising technology for liberating developers and improving test efficiency, currently performs not satisfactory in real-world projects. As a complement, test case recommendation (TCR) has been receiving the attention of researchers. TCR can improve the efficiency of test case writing by recommending test case code to developers for their reference and reuse. The overarching idea of TCR techniques is that two similar test targets can reuse each other’s test cases.
Objective:
Existing TCR techniques either fail to recommend relevant test cases for a given test target or are vulnerable to the mismatch of test target signatures. Our objective is to effectively and robustly recommend relevant test cases for test targets given by developers.
Method:
In this paper, we propose a novel TCR technique that measures the similarity of test targets based on a balanced distance. The balanced distance integrates the distances on code snippets and comments, making the measurement of test target similarity more accurate and robust. In particular, we take the distance on control flows into account to compensate for the shortcomings in measuring the similarity only based on the literal text of code snippets. As a proof-of-concept application, we implement a test case recommender named BDTCR.
Results:
We construct a test case corpus containing more than 13,000 test cases collected from GitHub. Based on this corpus, we conduct comprehensive experiments to evaluate the effectiveness and usefulness of BDTCR. The experimental results show that BDTCR can effectively recommend relevant test cases and outperform the state-of-the-art techniques.
Conclusion:
It can be concluded that (1) BDTCR is an effective TCR technique; (2) BDTCR is a robust TCR technique that can effectively resist the interference of the mismatch of test target signatures; (3) BDTCR is practical to help developers write test cases quickly and effectively.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The BDTCR technique aims to recommend relevant test cases for developers, improving test efficiency. By measuring the similarity of test targets based on a balanced distance, BDTCR outperforms existing techniques. This has a moderate impact on improving software quality by facilitating test case writing."
https://www.sciencedirect.com/science/article/pii/S0950584922001240,Microservice extraction based on knowledge graph from monolithic applications,Jianjie=Wu: wujianjie@hust.edu.cn; Yuan=Li: lyjingmen@sina.com,"Abstract
Context
Re-architecting monolithic systems with microservice architecture is a common trend. However, determining the ""optimal"" size of individual services during microservice extraction has been a challenge in software engineering. Common limitations of the literature include not being reasonable enough to be put into practical application; relying too much on human experience; neglection of the impact of hardware environment on the performance.
Objective
To address these problems, this paper proposes a novel method based on knowledge-graph to support the extraction of microservices during the initial phases of re-architecting existing applications.
Method
According to the microservice extraction method based on the AKF principle which is a widely practiced microservice design principle in the industry, four kinds of entities and four types of entity-entity relationships are designed and automatically extracted from specification and design artifacts of the monolithic application to build the knowledge graph. A constrained Louvain algorithm is proposed to identify microservice candidates.
Results
Our approach is tested based on two open-source projects with the other three typical methods: the domain-driven design-based method, the similarity calculation-based method, and the graph clustering-based method . Conducted experiments show that our method performs well concerning all the evaluation metrics.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The proposed method based on knowledge-graph for microservice extraction addresses a common challenge in software engineering. By automating the extraction of microservices, the method is practical and aims to overcome limitations of existing techniques. This has a moderate impact on improving software architecture."
https://www.sciencedirect.com/science/article/pii/S0950584922001239,A comparative study on vectorization methods for non-functional requirements classification,Pattara=Leelaprute: pattara.l@ku.ac.th; Sousuke=Amasaki: amasaki@cse.oka-pu.ac.jp,"Abstract
Context:
Identifying non-functional requirements (NFRs) and their categories at the early phase is crucial for analysts to design software systems and recognize constraints. Automatic non-functional requirements classification methods have been studied for reducing the costs of that labor-intensive task. Our previous study focused on the differences among 
vectorization
 methods that converted requirements written in natural language into numerical vectors for classification. It had some limitations regarding the number of datasets used, the types of 
vectorization
 methods supporting pre-trained data, and the performance evaluation procedure.
Objective:
To examine whether different vectorization methods lead to differences in the classification performance of NFRs and their categories with extended settings.
Methods:
Comparative experiments
 were conducted with five 
open data
. Nine vectorization methods, including ones with pre-trained data and four 
supervised classification
 methods, were supplied. Performance was evaluated with AUC and Scott-Knott 
ESD
 test.
Results:
Some advanced methods could achieve better performance than traditional ones when combined with some classifiers. The use of pre-trained data was useful for some categories.
Conclusion:
It is beneficial to consider using some combinations of vectorization methods and classifiers for classifying non-functional requirements categories.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on classifying non-functional requirements based on vectorization methods provides insights into improving the efficiency of requirement classification. While the findings are beneficial, the impact on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001021,The journey to technical excellence in agile software development,Adam=Alami: adaa@itu.dk,"Abstract
Context:
Technical excellence is a nebulous term in 
agile software development
. This vagueness is risky because it may lead to misunderstandings and to agile implementations that may overlook a key principle of 
agile development
.
Objective:
This study investigates how agile practitioners interpret the concept of technical excellence brought up in Principle 9 of the 
Agile manifesto
. Moreover, we investigate how agile practitioners put the concept into practice and what conditions facilitate putting technical excellence into practice.
Methods:
We conducted semi-structured interviews with twenty agile practitioners, coded the data inductively, and performed two sessions to validate the emerging findings.
Results:
We find that technical excellence is first and foremost a mindset that is underpinned by continuous attention to sustainable code, continuous learning, and teamwork. Fostering technical excellence requires the adoption of design and development practices, such as continuous architecting, and is supported by continuous learning. We also identify three enabling conditions for technical excellence: Leadership support, customer buy-in, and psychological safety. These enablers provide teams with leeway to nurture their pursuit of technical excellence.
Conclusion:
Our findings highlight the key role of people-based strategies in promoting technical excellence in agile software development. They show that the attainment of technical excellence does not only involve technical practices. On the contrary, it relies on social and 
organizational support
 and, most importantly, a mindset.",October 2022,"Agile software development, Software development methods, Technical excellence, Agile principles",Information and Software Technology,2025-03-18T00:00:00,4.0,"The investigation on technical excellence in agile software development offers valuable insights into fostering a mindset of continuous attention to sustainable code. While important for software development, the practical impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922001094,Taxonomy of bug tracking process smells: Perceptions of practitioners and an empirical analysis,Khushbakht Ali=Qamar: ali.qamar@bilkent.edu.tr; Emre=Sülün: emre.sulun@bilkent.edu.tr; Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr,"Abstract
Context:
While there is no consensus on a formally specified bug tracking process, some certain rules and best practices for an optimal bug tracking process are accepted by many companies and open-source software (OSS) projects. Despite slight variations between different platforms, the primary aim of all these rules and practices is to perform a more efficient bug tracking process. Practitioners’ non-compliance with the best practices not only impedes the benefits of the bug tracking process but also negatively affects the other phases of 
software development life cycle
.
Objective:
The goal of this study is to gain a better knowledge of the bad practices that occur during the bug tracking process (
bug tracking process smells
) and to perform quantitative analysis to show that these process smells exist in 
bug tracking systems
. Moreover, we want to know the perception of software practitioners related to these process smells and also observe the impact of process smells on the bug tracking process.
Methods:
Based on the results of a multivocal literature review, we analyzed 60 sources in academic and gray literature and propose a taxonomy of 12 bad practices in the bug tracking process. To quantitatively analyze these process smells, we inspected 
bug reports
 collected from eight projects which use Jira, Bugzilla, and GitHub Issues. To get an idea about the perception of practitioners about the taxonomy of bug tracking process smells, we conducted a targeted survey with 30 software practitioners. Moreover, we statistically analyzed the impact of bug tracking process smells on the resolution time and reopening count of bugs.
Results:
We observed from our empirical results that a considerable amount of bug tracking process smells exist in all projects and some of the process smell categories have statistically significant impacts on quality and speed. Survey results shows that the majority of software practitioners agree with the proposed taxonomy of BT process smells.
Conclusion:
The statistical analysis reveals that bug tracking process smells have an impact on OSS projects. The proposed taxonomy may serve as a foundation for best practices and tool support for detecting and avoiding bug tracking process smells.",October 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides insights into bad practices in bug tracking processes that have a significant impact on software quality and speed, offering a proposed taxonomy to improve practices and tool support, which can benefit early-stage ventures by enhancing development efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584922001227,Trace visualization within the Software City metaphor: Controlled experiments on program comprehension,Veronika=Dashuber: veronika.dashuber@qaware.de; Michael=Philippsen: michael.philippsen@fau.de,"Abstract
Context:
Especially with the rise of 
microservice architectures
, software is hard to understand when just the static dependencies are known. The actual call paths and the dynamic 
behavior
 of the application are hidden behind network communication. To comprehend what is going on in the software the vast amount of runtime data (traces) needs to be reduced and visualized.
Objective:
This work explores more effective visualizations to support 
program comprehension
 based on runtime data. The pure 
DynaCity
 visualization supports understanding normal behavior, while 
DynaCity


rc
 supports the comprehension of faulty behavior.
Method:
DynaCity
 uses the city metaphor for visualization. Its novel trace visualization displays dynamic dependencies as arcs atop the city. To reduce the number of traces, 
DynaCity
 aggregates all requests between the same two components into one arc whose brightness reflects both the number and the total duration of the requests. 
DynaCity
 also encodes dynamic trace data in a heatmap that it uses to light up the building: the brighter a building is, the more active it is, i.e., the more and the longer the requests are that it receives and/or spawns. An additional color scheme reflects any error/status codes among the aggregated traces. In a controlled experiment, we compare our approach with a traditional trace visualization built into the same Software City but showing all dependencies (without aggregation) as individual arcs and also disabling the heatmap. We also report on a second study that evaluates if an error-based coloring of only the arcs is sufficient or if the buildings should also be colored. We call this extension 
DynaCity


rc
 as it is meant to support 
r
oot 
c
ause analyses. The 
source code
 and the raw data of the 
quantitative evaluations
 are available from 
https://github.com/qaware/dynacity
.
Results:
We show quantitatively that a group of professional software developers who participated in a controlled experiment solve typical software comprehension tasks more correctly (11.7%) and also saved 5.83% of the total allotted time with the help of 
DynaCity
 and that they prefer it over the more traditional dynamic trace visualization. The color scheme based on HTTP error codes in 
DynaCity


rc
 supports developers when performing 
root cause analyses
, as the median of them stated that the visualization helped them 
much
 in solving the tasks. The evaluation also shows that subjects using 
DynaCity


rc
 with colored arcs and buildings find the responsible component 26.2% and the underlying root cause 33.3% more correctly than the group with just colored arcs. They also ranked it 40% more helpful to color both.
Conclusion:
The 
DynaCity
 visualization helps professional software engineers to understand the dynamic behavior of a software system better and faster. The color encoding of error codes in 
DynaCity


rc
 also helps them with 
root cause analyses
.",October 2022,"Trace visualization, Software city, Program comprehension, Aggregation, Heatmap, Root cause analysis",Information and Software Technology,2025-03-18T00:00:00,9.0,"The visualization techniques introduced in this work have shown to help professional software developers understand software systems better and faster, demonstrating improvements in comprehension tasks and root cause analyses, which can be valuable for early-stage ventures for efficient troubleshooting and development."
https://www.sciencedirect.com/science/article/pii/S0950584922001057,Consolidating a common perspective on Technical Debt and its Management through a Tertiary Study,Helvio Jeronimo=Junior: jeronimohjr@cos.ufrj.br; Guilherme Horta=Travassos: ght@cos.ufrj.br,"Abstract
Context
Technical Debt
 (TD) contextualizes the technical decisions on shortcuts and workarounds during software development, positively and negatively influencing software evolution. However, TD still seems to confound with any issue occurring during software development, impacting its proper understanding and management in software projects.
Goal
To synthesize evidence regarding the conceptualization, characteristics, and management of TD in software projects.
Method
To undertake a tertiary study to strengthen the knowledge of TD using the principles of Grounded Theory to support qualitative analysis.
Results
Nineteen secondary studies provide evidence on TD and its management. They provided information regarding the TD's understanding (definitions and characteristics) and management (actions and technologies). Some causes, such as project constraints, technical decisions, and team members, promote different types of TD in software projects. The secondary studies also supported identifying the impacts of TD regarding project management, team members, the 
organization's business
, and internal software quality. Besides helping identify TD challenges, such studies contributed to integrating a conjectured conceptual model of TD that can support future discussions and investigations regarding TD's understanding and management.
Conclusions
The set of evidence regarding TD's understanding, actions, and technologies to manage TD can aid software practitioners in their software projects. However, it is observable an interpretation overload regarding its definition, inducing to classify any issue occurring during the software development as TD. Therefore, further discussions and investigations still represent essential steps towards consolidating a common perspective on TD and its management.",September 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The synthesis of evidence regarding Technical Debt (TD) and its management in software projects provides valuable insights for software practitioners, although there may still be challenges in defining and managing TD, the study offers a conceptual model that could guide future discussions and investigations, which can be beneficial for startups in managing technical decisions and addressing software evolution issues."
https://www.sciencedirect.com/science/article/pii/S095058492200088X,ST-TLF: Cross-version defect prediction framework based transfer learning,Yawen=Wang: wangyawen@bupt.edu.cn,"Abstract
Context:
Cross-version 
defect prediction
 (CVDP) is a practical scenario in which 
defect prediction
 models are derived from defect data of historical versions to predict potential defects in the current version. Prior research employed defect data of the latest historical version as the training set using the empirical recommended method, ignoring the concept drift between versions, which undermines the accuracy of CVDP.
Objective:
We customized a 
S
elected 
T
raining set and 
T
ransfer 
L
earning 
F
ramework (ST-TLF) with two objectives: a) to obtain the best training set for the version at hand, proposing an approach to select the training set from the 
historical data
; b) to eliminate the concept drift, designing a transfer strategy for CVDP.
Method:
To evaluate the performance of ST-TLF, we investigated three research problems, covering the generalization of ST-TLF for 
multiple classifiers
, the accuracy of our training set matching methods, and the performance of ST-TLF in CVDP compared against state-of-the-art approaches.
Results:
The results reflect that (a) the eight classifiers we examined are all boosted under our ST-TLF, where 
SVM
 improves 49.74% considering 
MCC
, as is similar to others; (b) when performing the best training set matching, the accuracy of the method proposed by us is 82.4%, while the experience recommended method is only 41.2%; (c) comparing the 12 
control methods
, our ST-TLF (with BayesNet), against the best contrast method P15-NB, improves the average 
MCC
 by 18.84%.
Conclusions:
Our framework ST-TLF with various classifiers can work well in CVDP. The training set selection method we proposed can effectively match the best training set for the current version, breaking through the limitation of relying on experience recommendation, which has been ignored in other studies. Also, ST-TLF can efficiently elevate the CVDP performance compared with 
random forest
 and 12 
control methods
.",September 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract studies the impact of magic literals in source code, providing qualitative and quantitative insights. The findings can potentially help improve source code comprehension and maintenance, which could benefit European early-stage ventures in software development."
https://www.sciencedirect.com/science/article/pii/S0950584922000908,What do developers consider magic literals? A smalltalk perspective,N.=Anquetil: nicolas.anquetil@inria.fr,"Abstract
Context:
Literals are 
constant values
 (numbers, strings, etc.) used in the source code. 
Magic literals
 are such values used without an explicit explanation of their meaning. Such undocumented values may hinder source-code comprehension, negatively impacting maintenance. Relatively little literature can be found on the subject beyond the usual (and very old) recommendation of avoiding literals and preferring named constants. Yet, magic literals are still routinely found in source code.
Objective:
We studied literal values in source code to understand when they should be considered magic or not (i.e., acceptable).
Methods:
First, we perform a 
qualitative
 study of magic literals, to establish why and under which conditions they are considered harmful. We formalize hypotheses about the reasoning behind how literals are considered magic. Second, we perform a 
quantitative
 study on seven real systems ranging from small (a few classes) to large (thousands of classes). We report the literals’ types (number, string, Boolean, …), their 
grammatical function
 (e.g., argument in a call, operand in an expression, value assigned, …), or the purpose of the code in which they appear (test methods, regular code). Third, we report on another study involving 26 programmers who analyzed about 24,000 literals, to understand which ones they consider magic. Finally, we evaluate the 
hypotheses
 defining specific conditions under which literals are acceptable.
Results:
We show that (1) literals still exist and are relatively frequent (found in close to 50% of the methods considered); (2) they are more frequent in test methods (in 80% of test methods); (3) to a large extent, they were considered acceptable (only 25% considered magic); and (4) the hypotheses concerning acceptable literals are valid to various degrees.
Conclusion:
We thus pave the way to future research on magic literals, for example, with tools that could help developers deciding if a literal is acceptable.",September 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract addresses the issue of systematic labeling bias in task assignment datasets and proposes a debiasing method. The results show significant improvements in task assignment techniques, which could directly impact the performance of software development tasks in European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001008,Cleaning ground truth data in software task assignment,Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr; K. Ayberk=Tecimer: ayberk.tecimer@tum.de; Cansu=Moran: cansu.moran@ug.bilkent.edu.tr; Hakan=Erdogmus: hakane@andrew.cmu.edu,"Abstract
Context:
In the context of 
collaborative software development
, there are many 
application areas
 of task assignment such as assigning a developer to fix a bug, or assigning a code reviewer to a pull request. Most task assignment techniques in the literature build and evaluate their models based on datasets collected from real projects. The techniques invariably presume that these datasets reliably represent the “ground truth”. In a project dataset used to build an automated task assignment system, the recommended assignee for the task is usually assumed to be the best assignee for that task. However, in practice, the task assignee may not be the best possible task assignee, or even a sufficiently qualified one.
Objective:
We aim to clean up the ground truth by removing the samples that are potentially problematic or suspect with the assumption that removing such samples would reduce any systematic labeling bias in the dataset and lead to 
performance improvements
.
Method:
We devised a debiasing method to detect potentially problematic samples in task assignment datasets. We then evaluated the method’s impact on the performance of seven task assignment techniques by comparing the Mean Reciprocal Rank (MRR) scores before and after debiasing. We used two different task assignment applications for this purpose: Code Reviewer Recommendation (CRR) and Bug Assignment (BA).
Results:
In the CRR application, we achieved an average MRR improvement of 18.17% for the three learning-based techniques tested on two datasets. No significant improvements were observed for the two optimization-based techniques tested on the same datasets. In the BA application, we achieved a similar average MRR improvement of 18.40% for the two learning-based techniques tested on four different datasets.
Conclusion:
Debiasing the ground truth data by removing suspect samples can help improve the performance of learning-based techniques in software task assignment applications.",September 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract presents a debiasing method to improve the ground truth data in task assignment applications, leading to performance improvements in learning-based techniques. This research could contribute to enhancing software task assignment processes in European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000891,A literature review on optimization techniques for adaptation planning in adaptive systems: State of the art and research directions,Elia=Henrichs: elia.henrichs@uni-hohenheim.de; Veronika=Lesch: veronika.lesch@uni-wuerzburg.de; Martin=Straesser: martin.straesser@uni-wuerzburg.de; Samuel=Kounev: samuel.kounev@uni-wuerzburg.de; Christian=Krupitzer: christian.krupitzer@uni-hohenheim.de,"Abstract
Context:
Recent developments in modern IT systems including 
internet of things
, edge/fog computing, or cyber–physical systems support intelligent and seamless interaction between users and systems. This requires a reaction to changes in their environment or the system. Adaptive systems provide mechanisms for these reactions.
Objective:
To implement this functionality, several approaches for the planning of adaptations exist that rely on rules, 
utility functions
, or advanced techniques, such as 
machine learning
. As the adaptation space with possible options is often extensively huge, optimization techniques might support efficient determination of the adaptation space and identify the system’s optimal configuration. With this paper, we provide a 
systematic review
 of adaptation planning as the optimization target.
Method:
In this paper, we review which optimization techniques are applied for adaptation planning in adaptive systems using a systematic literature review approach.
Results:
We reviewed 115 paper in detail out of an initial search set of 9,588 papers. Our analysis reveals that learning techniques and 
genetic algorithms
 are by far dominant; in total, heuristics (anytime learning) are more frequently applied as exact algorithms. We observed that around 57% of the approaches target multi-objectiveness and around 30% integrate 
distributed optimization
. As last dimension, we focused on situation-awareness, which is only supported by two approaches.
Conclusion:
In this paper, we provide an overview of the current state of the art of approaches that rely on optimization techniques for planning adaptations in adaptive systems and further derive 
open research
 challenges, in particular regarding the integration of 
distributed optimization
 and situation-awareness.",September 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The systematic review of adaptation planning using optimization techniques provides insights into the current state of the art, but the practical impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922000672,An empirical study of emoji use in software development communication,Iftekhar=Ahmed: iftekha@uci.edu; Shiyue=Rong: shiyuer@uci.edu; Weisheng=Wang: weishew@uci.edu; Umme Ayda=Mannan: mannanu@oregonstate.edu; Eduardo Santana=de Almeida: esa@rise.com.br; Shurui=Zhou: shuruiz@ece.utoronto.ca,"Abstract
Context:
Similar to 
social media platforms
, people use emojis in software development related communication to enrich the context and convey additional emotion. With the increasing emoji use in software development-related communication, it has become important to understand why software developers are using emojis and their impact.
Objective:
Gaining a 
deeper understanding
 is essential because the intention of emoji usage might be affected by the demographics and experience of developers; also, frequency and the distribution of emoji usage might change depending on the activity, stage of the development, and nature of the conversation, etc.
Methods:
We present a large-scale empirical study on the intention of emoji usage conducted on 2,712 
Open Source Software
 (OSS) projects. We build a 
machine learning
 model to automate classifying the intentions behind emoji usage in 39,980 posts. We also surveyed 60 open-source software developers from 17 countries to understand developers’ perceptions of why and when emojis are used.
Results:
Our results show that we can classify the intention of emoji usage with high accuracy (AUC of 0.97). In addition, the results indicate that developers use emoji for varying intentions, and emoji usage intention changes throughout a conversation.
Conclusion:
Our study opens a new avenue in 
Software Engineering
 research related to automatically identifying the intention of the emoji use that can help improve the communication efficiency and help project maintainers monitor and ensure the quality of communication. Another thread of future research could look into what intentions of emoji usage or what kind of emojis are more likely to attract users and how that is associated with emoji usage diffusion in different levels (threads, projects, etc.)",August 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides insights into the intention of emoji usage in software development, potentially improving communication efficiency and project quality."
https://www.sciencedirect.com/science/article/pii/S0950584922000854,Self-adaptive systems: A systematic literature review across categories and domains,Terence=Wong: terence.wong@adelaide.edu.au; Markus=Wagner: markus.wagner@adelaide.edu.au; Christoph=Treude: christoph.treude@unimelb.edu.au,"Abstract
Context:
Championed by IBM’s vision of 
autonomic computing
 paper in 2003, the 
autonomic computing
 research field has seen increased research activity over the last 20 years. Several conferences (SEAMS, SASO, ICAC) and workshops (SISSY) have been established and have contributed to the 
autonomic computing
 
knowledge base
 in search of a new kind of system — a self-adaptive system (SAS). These systems are characterized by being context-aware and can act on that awareness. The actions carried out could be on the system or on the context (or environment). The underlying goal of a SAS is the sustained achievement of its goals despite changes in its environment.
Objective:
Despite a number of literature reviews on specific aspects of SASs ranging from their requirements to 
quality attributes
, we lack a systematic understanding of the current state of the art.
Method:
This paper contributes a 
systematic literature review
 into self-adaptive systems using the dblp computer science 
bibliography
 as a database. We filtered the records systematically in successive steps to arrive at 293 relevant papers. Each paper was critically analyzed and categorized into an attribute matrix. This matrix consisted of five categories, with each category having multiple attributes. The attributes of each paper, along with the summary of its contents formed the basis of the literature review that spanned 30 years (1990–2020).
Results:
We characterize the maturation process of the research area from theoretical papers over practical implementations to more holistic and generic approaches, frameworks, and exemplars, applied to areas such as networking, web services, and robotics, with much of the recent work focusing on 
IoT
 and 
IaaS
.
Conclusion:
While there is an ebb and flow of application domains, domains like bio-inspired approaches, security, and cyber–physical systems showed promise to grow heading into the 2020s.",August 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The systematic literature review on self-adaptive systems provides a comprehensive understanding of the field over 30 years, which can be highly valuable for startups looking to implement such systems."
https://www.sciencedirect.com/science/article/pii/S0950584922000660,Combining multiple granularity variability in a software product line approach for web engineering,Jose-Miguel=Horcas: horcas@lcc.uma.es; Alejandro=Cortiñas: alejandro.cortinas@udc.es; Lidia=Fuentes: lff@lcc.uma.es; Miguel R.=Luaces: miguel.luaces@udc.es,"Abstract
Context:
Web engineering involves managing a high diversity of artifacts implemented in different languages and with different levels of 
granularity
. Technological companies usually implement variable artifacts of Software Product Lines (SPLs) using annotations, being reluctant to adopt hybrid, often complex, approaches combining composition and annotations despite their benefits.
Objective:
This paper proposes a combined approach to support fine and coarse-grained variability for web artifacts. The proposal allows web developers to continue using annotations to handle fine-grained variability for those artifacts whose variability is very difficult to implement with a composition-based approach, but obtaining the advantages of the composition-based approach for the coarse-grained variable artifacts.
Methods:
A combined approach based on feature modeling that integrates annotations into a generic composition-based approach. We propose the definition of compositional and annotative variation points with custom-defined semantics, which is resolved by a scaffolding-based derivation engine. The approach is evaluated on a real-world web-based SPL by applying a set of variability metrics, as well as discussing its quality criteria in comparison with annotations, compositional, and combined existing approaches.
Results:
Our approach effectively handles both fine and coarse-grained variability. The mapping between the feature model and the web artifacts promotes the traceability of the features and the uniformity of the variation points regardless of the 
granularity
 of the web artifacts.
Conclusions:
Using well-known techniques of SPLs from an architectural point of view, such as feature modeling, can improve the design and maintenance of variable web artifacts without the need of introducing complex approaches for implementing the underlying variability.",August 2022,"Annotations, Composition, Feature models, SPL, Variability, Web engineering",Information and Software Technology,2025-03-18T00:00:00,7.0,"The combined approach proposed for handling fine and coarse-grained variability in web artifacts can be beneficial for web developers, but the practical impact on European early-stage ventures may vary."
https://www.sciencedirect.com/science/article/pii/S0950584922000763,Improving Stack Overflow question title generation with copying enhanced CodeBERT model and bi-modal information,Xiao=Yu: xiaoyu@whut.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Fuyang=Li: fyli@whut.edu.cn; Fengji=Zhang: zhangfengji@whu.edu.cn; Zhiwen=Xie: xiezhiwen@whu.edu.cn; Zhen=Yang: zhyang8-c@my.cityu.edu.hk; Caoyuan=Ma: macaoyuan@whu.edu.cn; Zhimin=Zhang: zhangzhimin@whu.edu.cn,"Abstract
Context:
Stack Overflow is very helpful for software developers who are seeking answers to programming problems. Previous studies have shown that a growing number of questions are of low quality and thus obtain less attention from potential answerers. Gao et al. proposed an LSTM-based model (i.e., BiLSTM-CC) to automatically generate question titles from the code snippets to improve the question quality. However, only using the code snippets in the question body cannot provide sufficient information for title generation, and LSTMs cannot capture the long-range dependencies between tokens.
Objective:
This paper proposes CCBERT, a 
deep learning
 based novel model to enhance the performance of question title generation by making full use of the bi-modal information of the entire question body.
Method:
CCBERT follows the encoder–decoder paradigm and uses CodeBERT to encode the question body into hidden representations, a stacked Transformer decoder to generate predicted tokens, and an additional copy attention layer to refine the output distribution. Both the encoder and decoder perform the multi-head self-attention operation to better capture the long-range dependencies. This paper builds a dataset containing around 200,000 high-quality questions filtered from the data officially published by Stack Overflow to verify the effectiveness of the CCBERT model.
Results:
CCBERT outperforms all the 
baseline models
 on the dataset. Experiments on both code-only and low-resource datasets show the superiority of CCBERT with less 
performance degradation
. The human evaluation also shows the excellent performance of CCBERT concerning both readability and correlation criteria.
Conclusion:
CCBERT is capable of automatically capturing the bi-modal 
semantic information
 from the entire question body and 
parsing
 the long-range dependencies to achieve better performance. Therefore, CCBERT is an effective approach for generating Stack Overflow question titles.",August 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"CCBERT model shows superior performance in question title generation on Stack Overflow dataset, which can be valuable for startups seeking to enhance the quality of questions and user engagement on similar platforms."
https://www.sciencedirect.com/science/article/pii/S0950584922000775,How ReadMe files are structured in open source Java projects,Yuyang=Liu: yuyang@cs.toronto.edu; Ehsan=Noei: e.noei@utoronto.ca; Kelly=Lyons: kelly.lyons@utoronto.ca,"Abstract
Context:
Recent studies on 
open source platforms
, such as GitHub, provide insights into how developers engage with software artifacts such as 
ReadMe
 files. Since 
ReadMe
 files are usually the first item users interact with in a repository, it is important that 
ReadMe
 files provide users with the information needed to engage with the corresponding repository.
Objective:
We investigate and compare 
ReadMe
 files of open source Java projects on GitHub in order to (i) determine the degree to which 
ReadMe
 files are aligned with the official guidelines, (ii) identify the common patterns in the structure of 
ReadMe
 files, and (iii) characterize the relationship between 
ReadMe
 file structure and popularity of associated repositories.
Method:
We apply statistical analyzes and 
clustering methods
 on 14,901 Java repositories to identify structural patterns of 
ReadMe
 files and the relationship of 
ReadMe
 file structure to repository stars.
Results:
While the majority of 
ReadMe
 files do not align with the GitHub guidelines, repositories whose 
ReadMe
 files follow the GitHub guidelines tend to receive more stars. We identify 32 clusters of common 
ReadMe
 file structures and the features associated with each structure. We show that projects with 
ReadMe
 files that contain project name, usage information, installation instructions, license information, code snippets, or links to images tend to get more stars.
Conclusion:
ReadMe
 file structure shares a statistically significant relationship with popularity as measured by number of stars; however, the most frequent 
ReadMe
 file structures are associated with less popular repositories on GitHub. Our findings can be used to understand the importance of 
ReadMe
 file structures and their relationship with popularity.",August 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on GitHub ReadMe files provides insights into the relationship between file structure and repository popularity, which may be helpful for startups to understand how to format their ReadMe files for better engagement."
https://www.sciencedirect.com/science/article/pii/S0950584922000787,Preventing technical debt with the TAP framework for Technical Debt Aware Management,Marion=Wiese: marion.wiese@uni-hamburg.de; Paula=Rachow: paula.rachow@uni-hamburg.de; Matthias=Riebisch: matthias.riebisch@uni-hamburg.de; Julian=Schwarze: schwarze.julian@guj.de,"Abstract
Context:
Technical Debt (TD) is a metaphor for technical problems that are not visible to users and customers but hinder developers in their work, making future changes more difficult. TD is often incurred due to tight project deadlines and can make future changes more costly or impossible. Project Management usually focuses on customer benefits and pays less attention to their IT systems’ internal quality. TD prevention should be preferred over 
TD repayment
 because subsequent refactoring and re-engineering are expensive.
Objective:
This paper evaluates a framework focusing on both TD prevention and 
TD repayment
 in the context of agile-managed projects. The framework was developed and applied in an IT unit of a publishing house. The unique contribution of this framework is the integration of TD management into project management.
Method:
The evaluation was performed as a comparative 
case study
 based on ticket statistics and two structured surveys. The surveys were conducted in the observed IT unit using the framework and a comparison unit not using the framework. The first survey targeted team members, the second one IT managers.
Results:
The evaluation shows that in this IT unit the TAP framework led to a raised awareness for the incurrence of TD. Decisions to incur TD are intentional, and TD is repaid timelier. Unintentional TD incurred by unconscious decisions is prevented. Furthermore, better communication and better planning of the project pipeline can be observed.
Conclusion:
We provide an insight into practitioners’ ways to identify, monitor, prevent and repay TD. The presented framework includes a feasible method for TD prevention despite tight timelines by making TD repayment part of project management.",August 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The framework for TD prevention and repayment in agile-managed projects shows tangible benefits in raising awareness and improving communication and planning.
https://www.sciencedirect.com/science/article/pii/S0950584922000039,Multi-objective integer programming approaches to Next Release Problem — Enhancing exact methods for finding whole pareto front,Yinxing=Xue: yxxue@ustc.edu.cn; Shi=Dong: dongshi@mail.ustc.edu.cn; Sjaak=Brinkkemper: s.brinkkemper@uu.nl,"Abstract
Context:
Project planning is a crucial part of software engineering, it involves selecting requirements to develop for the next release. How to make a good release plan is an optimization problem to maximize the goal of revenue under the condition of cost, time, or other aspects, namely Next Release Problem (NRP). 
Genetic
 and exact algorithms are used since it was proposed.
Objective:
We model NRP as bi-objective (revenue, cost) and tri-objective (revenue, cost, urgency) form, and investigate whether exact methods could solve bi-objective and tri-objective instances more efficiently.
Methods:
The state-of-art integer linear programming (ILP) approach to the bi-objective NRP is 
ε
-constraint for finding all non-dominate solutions. To improve its efficiency, we employ CWMOIP (Constrained Weighted Multi-Objective Integer Programming) and I-EC (improved 
ε
-constraint) for solving bi-objective instances. In tri-objective form, we introduce SolRep, an ILP method that optimizes the 
reference points
 from sampling, for finding solutions subset within a short time. NSGA-II is implemented as the 
evolutionary algorithm
 for the comparison with former methods and it adopts the seeding mechanism.
Results
: I-EC can find all non-dominated solutions with better performance than both 
ε
-constraint and CWMOIP on all instances except for one. I-EC reduces solving time by 19.7% (large instances) and 91.5% (small instances) on average separately compared with 
ε
-constraint. SolRep can find evenly distributed solutions and exceed NSGA-II illustrated by several indicators (such as HyperVolume) on tri-objective instances. And each method has its merit in the aspect of speed and number of the solutions.
Conclusion:
(1) The I-EC can solve all non-dominated solutions with better performance than the state-of-art exact method. (2) SolRep solves large tri-objective instances with more non-dominated solutions and solves small instances with less time compared with seeded NSGA-II. (3) Seeded NSGA-II shows its advantage on the number of non-dominated solutions on smaller tri-objective instances.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on optimizing the Next Release Problem presents improved methods, although the practical application impact is slightly unclear."
https://www.sciencedirect.com/science/article/pii/S0950584922000556,A DQN-based agent for automatic software refactoring,Hamidreza=Ahmadi: h_ahmadi@comp.iust.ac.ir; Mehrdad=Ashtiani: m_ashtiani@iust.ac.ir; Mohammad Abdollahi=Azgomi: azgomi@iust.ac.ir; Raana=Saheb-Nassagh: r_sahebnassagh@comp.iust.ac.ir,"Abstract
Context
Nowadays, technical debt has become a very important issue in 
software project management
. The main mechanism to repay this debt is through refactoring. Refactoring software projects usually comes at a high cost. As a result, researchers have always looked for ways to minimize this cost, and a good potential candidate to reduce the cost of a process is to automate it.
Objective
One of the automatic software refactoring methods that recently has received a lot of attention is based on search-based software engineering (SBSE) methods. Although because of comprehensiveness and versatility 
SBSE
 is considered an appropriate method for automatic refactoring, it has its downsides, the most important of which are the uncertainty of the results and the exponential execution time.
Method
In this research, a solution is proposed inspired by search-based refactoring while taking advantage of exploitation in 
reinforcement learning
 techniques. This work aims to solve the uncertainty problems and execution time for large programs. In the proposed approach, the problem of uncertainty is solved by targeting the selection of refactoring actions used in the search-based approach. Also, due to the reduction of the dependency between the choice of the appropriate refactoring and its execution time, the time problem in large software refactoring has been greatly improved.
Results
Amongst the performed evaluations and specifically for the refactoring of the largest 
case study
, the proposed approach managed to increase the accuracy to more than twice of the 
SBSE
 refactoring approaches, while reducing the execution time of refactoring by more than 98%.
Conclusion
The results of the tests show that with increasing the volume and size of the software, the performance of the proposed approach also improves compared to the methods based on SBSE, both in terms of reducing technical debt and speeding up the 
refactoring process
.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The research proposes a solution to automate software refactoring using a combination of search-based methods and reinforcement learning, significantly improving accuracy and reducing execution time, which can have a high practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000532,API-m-FAMM: A focus area maturity model for API Management,Michiel=Overeem: michiel.overeem@afas.nl; Max=Mathijssen: max.mathijssen@afas.nl; Slinger=Jansen: slinger.jansen@uu.nl,"Abstract
Context:
Organizations are increasingly connecting 
software applications
 using 
Application Programming Interfaces
 (APIs) to share data, services, functionality, and even complete business processes. However, the creation and management of APIs is non-trivial. Aspects such as traffic management, community engagement, documentation, and version management are often rushed afterthoughts.
Objective:
In this research, we present and evaluate a focus area maturity model for API Management (API-m-FAMM). A focus area maturity model can be used to establish the maturity level of an organization in a specific functional domain described through a number of areas. The API-m-FAMM addresses the areas 
Lifecycle Management
, Security, Performance, Observability, Community, and Commercial.
Method:
The model is constructed using established methods for the design of a focus area maturity model. It is grounded in literature and practice, and was developed and evaluated through a 
systematic literature Review
, eleven expert interviews, and five 
case studies
 at software producing organizations.
Result:
The model is described in detail, and its application is illustrated by six 
case studies
.
Conclusions:
The evaluations are reported on, and show that the API-m-FAMM is an efficient tool for aiding organizations in gaining a better understanding of their current implementation of API management practices, and provides them with guidance towards higher levels of maturity. The detailed description of the construction of the API-m-FAMM gives researchers an example to further support the available methodologies, specifically how to combine design science research with these methodologies. Additionally, this study’s unique case study design shows that maturity models can be successfully deployed in practice with minimal involvement of researchers. The focus area maturity model for API Management is maintained on 
www.maturitymodels.org
, allowing practitioners to benefit from its useful insights.",July 2022,"API Management, Maturity model, Focus area maturity models",Information and Software Technology,2025-03-18T00:00:00,7.0,"The focus area maturity model for API management can aid organizations in understanding and improving their API practices, which is relevant for startups working on software applications leveraging APIs."
https://www.sciencedirect.com/science/article/pii/S0950584922000544,Aligned metric representation based balanced multiset ensemble learning for heterogeneous defect prediction,Haowen=Chen: hwc_zzu@126.com; Yuming=Zhou: zhouyuming@nju.edu.cn; Bing=Li: bingli@whu.edu.cn; Baowen=Xu: bwxu@nju.edu.cn,"Abstract
Context:
Heterogeneous 
defect prediction
 (HDP) refers to the 
defect prediction
 across projects with different metrics. Most existing HDP methods map source and target data into a common metric space where each dimension has no actual meaning, which weakens their 
interpretability
. Besides, HDP always suffers from the 
class imbalance problem
.
Objective:
For deficiencies of current HDP methods, we intend to propose a novel HDP approach that can reduce the heterogeneity of source and target data and deal with 
imbalanced data
 while retaining the actual meaning for each dimension of constructed common metric space.
Method:
We propose an Aligned Metric Representation based Balanced Multiset 
Ensemble learning
 (BMEL+ AMR) approach for HDP. AMR consists of shared, source-specific, and target-specific metrics. It is built by learning the translation from shared to specific metrics and reducing the distribution difference. To deal with 
imbalanced data
, we design BMEL that constructs multiple balanced subsets for source data and produces an aggregated classifier for predicting labels of target data.
Result:
Experimental results on 22 public projects indicate that (1) among all competing methods, BMEL+AMR achieves the best performance on all indicators except 
Popt
, followed by AMR; (2) compared with AMR, the introduction of BMEL improves the performance on non-effort-aware indicators statistically significantly except 
F1-score
; compared with BMEL, the introduction of AMR improves the performance throughout all indicators statistically significantly.
Conclusion:
BMEL+AMR can effectively improve HDP performance by eliminating heterogeneity and dealing with imbalanced data, and AMR is helpful to explain the prediction model.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The novel HDP approach addresses the interpretability and class imbalance issues in defect prediction, which can be beneficial for startups dealing with software quality and maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584922000507,"SE
M: A model for software effort estimation using pre-trained embedding models",Eliane Maria=De Bortoli Fávero: elianedb@utfpr.edu.br; Dalcimar=Casanova: dalcimar@utfpr.edu.br; Andrey Ricardo=Pimentel: andrey@inf.ufpr.br,"Abstract
Context:
Software effort estimation from requirements texts, presents many challenges, mainly in getting viable features to infer effort. The most recent 
Natural Language Processing
 (NLP) initiatives for this purpose apply context-less embedding models, which are often not sufficient to adequately discriminate each analyzed sentence. Contextualized pre-trained embedding models have emerged quite recently and have been shown to be far more effective than context-less models in representing textual features.
Objective:
This paper proposes evaluating the effectiveness of pre-trained embedding models, to explore a more effective technique for representing textual requirements, which are used to infer effort estimates by analogy.
Method:
Generic pre-trained models went through a fine-tuning process for both approaches — context-less and contextualized. The generated models were used as input in the applied 
deep learning
 architecture, with linear output. The results were very promising, realizing that contextualized pre-trained embedding models can be used to estimate software effort based only on requirements texts.
Results:
We highlight the results obtained to apply the contextualized pre-trained model 
BERT
 with fine-tuning, applied in a single repository containing different projects, whose 
Mean Absolute Error
 (MAE) value is 4.25 and the standard deviation is only 0.17. This represents a result very positive when compared to similar works.
Conclusion:
The main advantages of the proposed estimation method are reliability, the possibility of generalization, speed, and low computational cost. Such advantages are provided by the fine-tuning process, enabling to infer effort estimation for new or existing requirements.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The evaluation of pre-trained embedding models for software effort estimation shows promising results, offering reliability, generalization, and low computational cost, which can be highly valuable for startups in resource-constrained environments."
https://www.sciencedirect.com/science/article/pii/S095058492200060X,Locality-based security bug report identification via active learning,Chunrong=Fang: fangchunrong@nju.edu.cn; Xiuting=Ge: dg20320002@smail.nju.edu.cn; Meiyuan=Qian: mf20320109@smail.nju.edu.cn; Yu=Ge: 920397425@qq.com; Mingshuang=Qing: qingms@mails.swust.edu.cn,"Abstract
Context:
Security 
bug report
 (SBR) identification is a crucial way to eliminate security-critical vulnerabilities during software development.
Objective:
In recent years, many approaches have utilized supervised machine learning (SML) techniques in the SBR identification. However, such approaches often require a large number of labelled bug reports, which are often hard to obtain in practice. Active learning is a potential approach to reducing the manual labelling cost while maintaining 
good performance
. Nevertheless, the existing active learning-based SBR identification approach still yields poor performance due to ignoring the locality in bug reports.
Method:
To address the above problems, we propose locality-based SBR identification via active learning. Our approach recommends a small part of instances based on locality in bug reports, asks for their labels, and learns the SBR classifier. Specifically, our approach relies on the locality to construct the initial training set, which is designed to address how to start during active learning. Moreover, our approach applies the locality into the query process, which is designed to improve which instance should be queried next during active learning.
Result:
We conduct experiments on large-scale bug reports (nearly 125K) from six real-world projects. In comparison with three state-of-the-art SML-based and active learning-based SBR identification approaches, our approach can obtain the maximum values of F-Measure (0.8176) and AUC (0.8631). Moreover, our approach requires 16.60% to 71.40% of all bug reports when achieving the 
optimal performance
 in these six projects, which improves three approaches from 9.82% to 64.19% on average.
Conclusion:
As shown from the experimental results, our approach can be more effective and efficient to identify SBRs than the existing approaches.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The locality-based SBR identification approach through active learning demonstrates improved performance and efficiency in identifying security bug reports, which can be critical for startups focused on software security."
https://www.sciencedirect.com/science/article/pii/S0950584922000611,Mind the product owner: An action research project into agile release planning,Konsta=Kantola: konsta.kantola@finago.com,"Abstract
Context:
This paper studies agile release planning in a software development organization with 13 development teams. It is important for software development organizations to be able to plan work in an efficient way that supports development work.
Objective:
The research aims to understand issues within agile release planning in the studied organization, and to make some improvement to the agile release planning practices there.
Method:
The study followed canonical 
action research
 methodology completing one cycle of diagnosis, action planning, intervention, evaluation, and learning. Qualitative methods were used during these phases to identify preliminary issues, to support the choice of action, and the evaluation of those actions.
Results:
The research identified issues of strain on the role of Product Owners. Sources of strain in the organization include changing priorities, the effort required to build up domain competence for new projects, and external pressure to push out new features. Additionally, there was difficulty for people participating in agile release planning to suggest improvements to the used practices due in part to the complexity and scale of planning practices in a multi-team development organization. The actions taken as part of the research provided ways for Product Owners to share knowledge between themselves, to better affect the working practices in the organization, and promoted a sense of team spirit between the Product Owners.
Conclusion:
Organizations should be mindful of their Product Owners when looking at their release planning practices. Problems for Product Owners are problems in planning for the whole organization. Having an active, collective, and structured channel for continuous improvement for Product Owners can help drive improvements to agile release planning.",July 2022,"Canonical action research, Agile release planning, Product owner",Information and Software Technology,2025-03-18T00:00:00,5.0,"The research provides insights into agile release planning practices, particularly focusing on issues related to Product Owners. This can be valuable for software development organizations but doesn't introduce groundbreaking solutions."
https://www.sciencedirect.com/science/article/pii/S0950584922000635,Continuous verification of system of systems with collaborative MAPE-K pattern and probability model slicing,Jiyoung=Song: jysong@se.kaist.ac.kr,"Abstract
The phenomenon of cooperation among independent systems to achieve common goals has been growing. In this regard, the concept of 
system of systems
 (SoS), wherein numerous independent systems cooperate with each other, has been proposed. The key characteristic of an SoS is the 
operational and managerial (O/M) independence
 of each 
constituent system
 (CS). Each CS of a 
collaborative SoS
 with high O/M independence provides different levels of 
internal-knowledge
 sharing and is entitled to voluntary participation in the SoS (
i.e.
, 
dynamic reconfiguration
). To increase goal-achievement rate, we need to verify SoS considering the knowledge-sharing and 
dynamic reconfiguration
 constraints.
The 
dynamic reconfiguration
 of SoSs can be managed using 
continuous verification
, which involves environment monitoring, modeling systems for operation in changing environments, and verifying the model runtimes. However, O/M independence introduces the following challenges: (1) the low knowledge-sharing level causes inaccurate modeling, which leads to inaccurate verification results, and (2) dynamic reconfiguration requires frequent re-verification at runtime, which incurs high verification costs.
In this paper, we propose a continuous-verification-of-SoS (CVSoS) approach to solve these two challenges. To address the low knowledge-sharing level, we propose the 
collaborative MAPE-K
 pattern. The key to collaborative MAPE-K is the retrieval of knowledge from the other collaborating CSs. To address dynamic reconfiguration, we propose a new slicing algorithm for SoS models. This algorithm promotes 
synchronization
 dependence
, which is essential for representing interactions between CSs. Furthermore, we demonstrate the accuracy of this algorithm.
We evaluated CVSoS across multiple SoS domains, which revealed that the SoS goal-achievement rate increases by up to 64% using the collaborative MAPE-K pattern and that slicing the benchmark and SoS models improved the verification time by an average of 67%.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposal of a continuous-verification-of-SoS approach to improve system of systems collaboration and achieve higher goal-achievement rates could have significant practical value for early-stage ventures by enhancing operational efficiency and effectiveness.
https://www.sciencedirect.com/science/article/pii/S0950584922000593,The practical roles of enterprise architecture artifacts: A classification and relationship,Svyatoslav=Kotusev: kotusev@kotusev.com,"Abstract
Context
Enterprise architecture (EA) is a description of an enterprise from an integrated business and IT perspective. EA is typically defined as a comprehensive blueprint of an organization covering its business, data, applications and technology domains and consisting of diverse EA artifacts. EA has numerous potential stakeholders and 
usage scenarios
 in organizations. However, the existing EA literature does not offer any consistent theories explaining the practical roles of individual EA artifacts and fails to explain how exactly different types of EA artifacts are used in practice.
Objective
This study intends to explore the roles of different EA artifacts in organizations and develop a generic descriptive theory explaining these roles. The theory purports to cover various properties of EA artifacts as well as the relationships between them.
Method
The research method of this study follows two consecutive phases: theory construction and theory validation. First, theory construction is based on the qualitative in-depth analysis of five case organizations with established EA practices. Next, theory validation includes confirmatory interviews with ten EA experts.
Results
This study develops a descriptive theory explaining the roles of different EA artifacts in an EA practice. The resulting theory defines six general types of EA artifacts (Considerations, Standards, Visions, Landscapes, Outlines and Designs, CSVLOD) and explains their type-specific practical roles, including their 
informational contents
, typical usage, ensuing organizational benefits and interrelationships with each other.
Conclusions
This study presents the first systematic theory describing the usage of EA artifacts in organizations. Our theory facilitates better theoretical understanding of the concept of EA and also provides evidence-based solutions to the commonly reported practical problems with EA. This study suggests that the EA research community should focus on studying individual EA artifacts instead of studying EA in general and calls for further research on EA artifacts and their usage as part of EA practices.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The exploration of different EA artifacts and the development of a theory explaining their practical roles could provide valuable insights for organizations looking to optimize their enterprise architecture. This can have a positive impact on early-stage ventures' scalability and integration strategies.
https://www.sciencedirect.com/science/article/pii/S0950584922000647,CASMS: Combining clustering with attention semantic model for identifying security bug reports,Yishu=Li: yishuli5-c@my.cityu.edu.hk; Xiao=Yu: xiaoyu@whut.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Zhen=Yang: zhyang8-c@my.cityu.edu.hk; Xiaoxue=Ma: xiaoxuema3-c@my.cityu.edu.hk; Hao=Zhang: hzhang339-c@my.cityu.edu.hk,"Abstract
Context:
Inappropriate public disclosure of security 
bug reports
 (SBRs) is likely to attract malicious attackers to invade software systems; hence being able to detect SBRs has become increasingly important for software maintenance. Due to the 
class imbalance problem
 that the number of non-security 
bug reports
 (NSBRs) exceeds the number of SBRs, insufficient training information, and weak performance robustness, the existing techniques for identifying SBRs are still less than desirable.
Objective:
This prompted us to overcome the challenges of the most advanced SBR detection methods.
Method:
In this work, we propose the CASMS approach to efficiently alleviate the imbalance problem and predict bug reports. CASMS first converts bug reports into weighted 
word embeddings
 based on 
t
f
−
i
d
f
 and 
w
o
r
d
2
v
e
c
 techniques. Unlike the previous studies selecting the NSBRs that are the most dissimilar to SBRs, CASMS then automatically finds a certain number of diverse NSBRs via the Elbow method and 
k
-means clustering algorithm. Finally, the selected NSBRs and all SBRs train an effective Attention CNN–BLSTM model to extract contextual and sequential information.
Results:
The experimental results have shown that CASMS is superior to the three baselines (i.e., FARSEC, SMOTUNED, and LTRWES) in assessing the overall performance (
g
-measure) and correctly identifying SBRs (
recall
), with improvements of 4.09%–24.26% and 10.33%–36.24%, respectively. The best results are easily obtained under the limited ratio ranges of the two-class training set (1:1 to 3:1), with around 20 experiments for each project. By evaluating the robustness of CASMS via the standard deviation indicator, CASMS is more stable than LTRWES.
Conclusion:
Overall, CASMS can alleviate the data imbalance problem and extract more semantic information to improve performance and robustness. Therefore, CASMS is recommended as a practical approach for identifying SBRs.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The CASMS approach addressing the imbalance problem in security bug report detection and demonstrating superior performance over existing techniques provides a practical solution that can significantly benefit early-stage ventures by enhancing software security and maintenance.
https://www.sciencedirect.com/science/article/pii/S0950584922000659,Successful combination of database search and snowballing for identification of primary studies in systematic literature studies,Katia Romero=Felizardo: katiascannavino@utfpr.edu.br; Claes=Wohlin: claes.wohlin@bth.se; Marcos=Kalinowski: kalinowski@inf.puc-rio.br; Emilia=Mendes: emilia.mendes@bth.se,"Abstract
Background:
A good search strategy is essential for a successful systematic literature study. Historically, database searches have been the norm, which was later complemented with snowball searches. Our conjecture is that we can perform even better searches if combining these two search approaches, referred to as a hybrid search strategy.
Objective:
Our main objective was to compare and evaluate a hybrid search strategy. Furthermore, we compared four alternative hybrid search strategies to assess whether we could identify more cost-efficient ways of searching for relevant primary studies.
Methods:
To compare and evaluate the hybrid search strategy, we replicated the search procedure in a 
systematic literature review
 (SLR) on industry–academia collaboration in 
software engineering
. The SLR used a more “traditional” approach to searching for relevant articles for an SLR, while our replication was executed using a hybrid search strategy.
Results:
In our evaluation, the hybrid search strategy was superior in identifying relevant primary studies. It identified 30% more primary studies and even more studies when focusing only on peer-reviewed articles. To embrace individual viewpoints when assessing research articles and minimise the risk of missing primary studies, we introduced two new concepts, 
wild cards
 and 
borderline articles
, when performing systematic literature studies.
Conclusions:
The hybrid search strategy is a strong contender for being used when performing systematic literature studies. Furthermore, alternative hybrid search strategies may be viable if selected wisely in relation to the start set for snowballing. Finally, the two new concepts were judged as essential to cater for different individual judgements and to minimise the risk of excluding primary studies that ought to be included.",July 2022,"Systematic literature reviews, Hybrid search, Snowballing, Scopus",Information and Software Technology,2025-03-18T00:00:00,7.0,The comparison and evaluation of a hybrid search strategy for systematic literature studies and the introduction of new concepts like wild cards and borderline articles could offer valuable guidance for early-stage ventures in conducting more comprehensive and efficient literature reviews.
https://www.sciencedirect.com/science/article/pii/S0950584921001944,Towards cost-effective API deprecation: A win–win strategy for API developers and API users,Chia Hung=Kao: chkao@nttu.edu.tw,"Abstract
API
 deprecation, which enables 
API
 developers to assist API users in 
migration tasks
, has been widely employed in API removal management. However, mismanaged API deprecation will cause unnecessary cost and bring negligible benefit to API users. Cost-effective investments in API deprecation become challenges for API developers. In this work, an iterative model for cost-effective investments in API deprecation is developed. The model provides a data-driven mechanism for API developers to iteratively make investments in API deprecation. A tool named 
AWARE
 (
A
 
W
in–win 
A
ssistant for API 
RE
moval management) is also developed for API developers to accurately assess the benefit from the perspective of API 
usage statistics
. Based on the prioritized benefit, API developers can allocate appropriate resources on API deprecation. A 
case study
 is performed to evaluate the effectiveness of the iterative model with AWARE. The evaluation result shows that the cost paid by API developers can be reduced significantly while the benefit brought to API users can be increased. A win–win strategy for API deprecation can be achieved.",February 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The development of an iterative model for cost-effective investments in API deprecation can have a significant impact on European early-stage ventures by reducing costs and increasing benefits, making it practical and valuable for startups."
https://www.sciencedirect.com/science/article/pii/S0950584922000581,Quantum computing challenges in the software industry. A fuzzy AHP-based approach,Usama=Awan: usama.awan@lut.fi,"Abstract
Context
The current technology revolution has posed unexpected challenges for the software 
industry
. In recent years, the field of 
quantum computing
 (QC) technologies has continued to grow in influence and maturity, and it is now poised to revolutionise 
software engineering
. However, the evaluation and prioritisation of QC challenges in the software industry remain unexplored, relatively under-identified and fragmented.
Objective
The purpose of this study is to identify, examine and prioritise the most critical challenges in the software industry by implementing a fuzzy 
analytic hierarchy process
 (F-AHP).
Method
First, to identify the key challenges, we conducted a systematic literature review by drawing data from the four relevant digital libraries and supplementing these efforts with a forward and backward snowballing search. Second, we followed the F-AHP approach to evaluate and rank the identified challenges, or barriers.
Results
The results show that the key barriers to QC adoption are the lack of technical expertise, information accuracy and organisational interest in adopting the new process. Another critical barrier is the lack of standards of secure communication techniques for implementing QC.
Conclusion
By applying F-AHP, we identified institutional barriers as the highest and organisational barriers as the second highest global weight ranked categories among the main QC challenges facing the software industry. We observed that the highest-ranked local barriers facing the software technology industry are the lack of resources for design and initiative while the lack of organisational interest in adopting the new process is the most significant organisational barrier. Our findings, which entail implications for both academicians and practitioners, reveal the emergent nature of QC research and the increasing need for interdisciplinary research to address the identified challenges.",July 2022,"Fuzzy analytic hierarchy process (F-AHP), Software process automation, Multiple-criteria decision-making (MCDM), Quantum software requirement, Quantum computing",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on identifying challenges in quantum computing for the software industry can have a significant impact on the future of software engineering and technological innovation, benefiting European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000568,Toward successful DevSecOps in software development organizations: A decision-making framework,Muhammad Azeem=Akbar: azeem.akbar@lut.fi; Kari=Smolander: kari.smolander@lut.fi; Sajjad=Mahmood: smahmood@kfupm.edu.sa; Ahmed=Alsanad: aasanad@ksu.edu.sa,"Abstract
Context
Development and Operations (DevOps) is a methodology that aims to establish collaboration between programmers and operators to automate the continuous delivery of new software to reduce the 
development life cycle
 and produce quality software. Development, Security, and Operations (DevSecOps) is developing the DevOps concept, which integrates security methods into a 
DevOps process
. DevSecOps is a software development process where security is built in to ensure application confidentiality, integrity, and availability.
Objective
This paper aims to identify and prioritize the challenges associated with implementing the DevSecOps process.
Method
We performed a multivocal literature review (MLR) and conducted a questionnaire-based survey to identify challenges associated with DevSecOps-based projects. Moreover, interpretive structure modeling (ISM) was applied to study the relationships among the core categories of the challenges. Finally, we used the fuzzy technique for 
order preference
 by similarity to an ideal solution (TOPSIS) to prioritize the identified challenges associated with DevSecOps projects.
Results
We identified 18 challenges for the DevSecOps process and mapped them to 10 core categories. The ISM results indicate that the “standards” category has the most decisive influence on the other nine core categories of the identified challenges. Moreover, the fuzzy TOPSIS indicates that “lack of secure coding standards,” “lack of automated testing tools for security in DevOps,” and “ignorance in static testing for security due to lack of knowledge” are the highest priority challenges for the DevSecOps paradigm.
Conclusion
Organizations using DevOps should consider the identified challenges in developing secure software.",July 2022,"DevOps, DevSecOps, Challenges, Multivocal literature review, Fuzzy analytical hierarchy process",Information and Software Technology,2025-03-18T00:00:00,8.0,"Identifying challenges in implementing DevSecOps can improve the security and quality of software development processes, which is crucial for startups dealing with sensitive data and information."
https://www.sciencedirect.com/science/article/pii/S0950584922000428,An end-to-end deep learning system for requirements classification using recurrent neural networks,Irfan=Ahmad: irfan.ahmad@kfupm.edu.sa,"Abstract
Context:
Existing requirements 
classification approaches
 mainly use lexical and syntactical features to classify requirements using both traditional 
machine learning
 and 
deep learning
 approaches with promising results. However, the existing techniques depend on word and sentence structures and employ preprocessing and feature engineering techniques to classify requirements from textual natural language documents. Moreover, existing studies deal with requirements classification as binary or 
multiclass classification
 problems and not as multilabel classification, although a given requirement can belong to multiple classes at the same time.
Objective:
The objective of this study is to classify requirements into functional and different non-functional types with minimal preprocessing and to model the task as a multilabel classification problem.
Method:
In this paper, we use Bidirectional Gated 
Recurrent Neural Networks
 (BiGRU) to classify requirements using raw text. We investigated two different approaches: (i) using word sequences as tokens and (ii) using character sequences as tokens.
Results:
Experiments conducted on the publicly available PROMISE and 
EHR
 datasets show the effectiveness of the presented techniques. We achieve state-of-the-art results on most of the tasks using word sequences as tokens.
Conclusion:
Requirements can be effectively classified into functional and different non-functional categories using the presented recurrent neural networks-based deep 
learning system
, which involves minimal text prepossessing and no feature engineering.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on classifying requirements using deep learning techniques can contribute to more efficient software development processes, potentially benefiting startups by optimizing resource allocation."
https://www.sciencedirect.com/science/article/pii/S0950584922000350,Defining adaptivity and logical architecture for engineering (smart) self-adaptive cyber–physical systems,Ana=Petrovska: ana.petrovska@tum.de; Stefan=Kugele: stefan.kugele@thi.de; Thomas=Hutzelmann: t.hutzelmann@tum.de; Theo=Beffart: theo.beffart@tum.de; Sebastian=Bergemann: sebastian.bergemann@tum.de; Alexander=Pretschner: alexander.pretschner@tum.de,"Abstract
Context:
Modern cyber–physical systems (CPSs) are embedded in the physical world and intrinsically operate in a continuously changing and uncertain environment or 
operational context
. To meet their business goals and preserve or even improve specific adaptation goals, besides the variety of run-time uncertainties and changes to which the CPSs are exposed—the systems need to self-adapt.
Objective:
The current literature in this domain still lacks a precise definition of what self-adaptive systems are and how they differ from those considered non-adaptive. Therefore, in order to answer 
how
 to engineer self-adaptive CPSs or self-adaptive systems in general, we first need to answer 
what
 is adaptivity, correspondingly self-adaptive systems.
Method:
In this paper, we first formally define the notion of adaptivity. Second, within the frame of the formal definitions, we propose a logical architecture for engineering decentralised self-adaptive CPSs that operate in dynamic, uncertain, and partially observable operational contexts. This logical architecture provides a structure and serves as a foundation for the implementation of a class of self-adaptive CPSs.
Results:
First, our results show that in order to answer if a system is adaptive, the right framing is necessary: the system’s adaptation goals, 
its context
, and the time period in which the system is adaptive. Second, we discuss the benefits of our architecture by comparing it with the MAPE-K conceptual model.
Conclusion:
Commonly accepted definitions of adaptivity and self-adaptive systems are necessary for work in this domain to be compared and discussed since the same terms are often used with different semantics. Furthermore, in modern self-adaptive CPSs, which operate in dynamic and uncertain contexts, it is insufficient if the adaptation logic is specified during the system’s design, but instead, the adaptation logic itself needs to adapt and “learn” during run-time.",July 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The research on self-adaptive systems in cyber-physical systems can have implications for innovative technologies, but the practical impact on early-stage ventures may be more indirect and long-term."
https://www.sciencedirect.com/science/article/pii/S0950584920300707,A feedback-directed method of evolutionary test data generation for parallel programs,Tian=Tian: tian_tiantian@126.com,"Abstract
Context:
 
Genetic algorithms
 can be utilized for automatic test data generation. Test data are encoded as individuals which are evolved for a number of generations using genetic operators. Test data of a parallel program include not only the program input, but also the communication information between each pair of processes. Traditional genetic algorithms, however, do not make full use of information provided by a population’s evolution, resulting in a low efficiency in generating test data. 
Objective:
 This paper emphasizes the problem of test data generation for parallel programs, and presents a feedback-directed genetic algorithm for generating test data of path coverage. 
Method:
 Information related to a schedule sequence is exploited to improve genetic operators. Specifically, a scheduling sequence is evaluated according to how well an individual covers the target path. The probability of the crossover and 
mutation points
 being located in the region is determined based on the evaluation result, which prevents a good schedule sequence from being destroyed. If crossover and mutation are performed in the scheduling sequence, the location of crossover and 
mutation points
 is further determined according to the relationship between nodes to be covered and the scheduling sequence. In this way, the population can be evolved in a narrowed 
search space
. 
Results:
 The proposed algorithm is applied to test 11 parallel programs. The experimental results show that, compared with the genetic algorithm without utilizing information during the population evolution, the proposed algorithm significantly reduces the number of generations and the time consumption. 
Conclusion:
 The proposed algorithm can greatly improve the efficiency in evolutionary test data generation.",August 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The proposed algorithm for test data generation in parallel programs shows improved efficiency, but may have limited practical impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921002457,Tailoring the Scrum framework for software development: Literature mapping and feature-based support,Luciano A.=Garcia: lucianogarcia11@hotmail.com; Edson=OliveiraJr: edson@din.uem.br; Marcelo=Morandini: m.morandini@usp.br,"Abstract
Context:
Literature faces the lack of studies relating which characteristics of the Scrum framework are adapted. Understanding such variations is useful for prospective software development projects and guiding teams at conducting Scrum 
customizations
.
Objective:
We aimed at identifying how the Scrum framework has been adapted to the context of 
Agile software development
 projects and how adaptations might be represented to aid researchers and practitioner at analyzing Scrum processes deployed or to be deployed.
Method:
We carried out a 
systematic mapping study
 in five electronic sources, 11 journals and 15 conferences/workshops. We submitted the 281 returned studies to various filters, which resulted in 50 studies with data extracted, analyzed, and quality evaluated.
Results:
SMS provides a panorama on the Scrum characteristics adapted to roles, events, and artifacts. We decided to adopt feature models for hierarchically accommodating found Scrum adaptations as it supports adaptations in the form of variability. We evaluated the resulting feature model with practitioners from different companies in the perspective of Perceived Usefulness and Perceived Ease of Use considering the Technology Acceptance Model (TAM). Therefore, we demonstrated the produced feature model aids users to better visualize and understand the documented Scrum adaptations.
Conclusions:
The panorama on Scrum adaptations and the problems during Scrum adoption are discussed to providing a means to practically understand and tailor (configure) such adaptations. Such adaptations are an essential source of information on the variety of Scrum elements, thus researchers and practitioners may take the results of this work as a guide to understand how different adaptations occur in different contexts during software development. In addition, the conceived feature model is an important asset to guide such users at selecting Scrum characteristics and respective adaptations to perform. The feature model also promotes reuse of knowledge gathered up from several different 
information sources
.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"Understanding adaptations of the Scrum framework can help agile software development projects, providing insights for startups on how to customize their processes more effectively."
https://www.sciencedirect.com/science/article/pii/S0950584922000246,Detecting privacy requirements from User Stories with NLP transfer learning models,Carmine=Gravino: gravino@unisa.it; Francesco=Casillo: fcasillo@unisa.it; Vincenzo=Deufemia: deufemia@unisa.it,"Abstract
Context:
To provide privacy-aware software systems, it is crucial to consider privacy from the very beginning of the development. However, developers do not have the expertise and the knowledge required to embed the legal and social requirements for data protection into software systems.
Objective:
We present an approach to decrease privacy risks during 
agile software development
 by automatically detecting privacy-related information in the context of user story requirements, a prominent notation in agile 
Requirement Engineering
 (RE).
Methods:
The proposed approach combines 
Natural Language Processing
 (NLP) and linguistic resources with 
deep learning algorithms
 to identify privacy aspects into User Stories. NLP technologies are used to extract information regarding the semantic and 
syntactic
 structure of the text. This information is then processed by a pre-trained 
convolutional neural network
, which paved the way for the implementation of a 
Transfer Learning
 technique. We evaluate the proposed approach by performing an empirical study with a dataset of 1680 user stories.
Results:
The experimental results show that 
deep learning algorithms
 allow to obtain better predictions than those achieved with conventional (shallow) 
machine learning methods
. Moreover, the application of 
Transfer Learning
 allows to considerably improve the accuracy of the predictions, ca. 10%.
Conclusions:
Our study contributes to encourage 
software engineering
 researchers in considering the opportunities to automate privacy detection in the early phase of design, by also exploiting transfer learning models.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Automatically detecting privacy-related information in agile software development is a useful contribution, but the impact may be slightly lower compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922000209,Featherweight assisted vulnerability discovery,David=Binkley: binkley@cs.loyola.edu,"Abstract
Predicting vulnerable 
source code
 helps to focus the attention of a developer, or a program analysis technique, on those parts of the code that need to be examined with more scrutiny. Recent work proposed the use of function names as semantic cues that can be learned by a 
deep neural network
 (DNN) to aid in the hunt for vulnerability of functions.
Combining identifier splitting, which we use to split each function name into its constituent words, with a novel frequency-based algorithm, we explore the extent to which the words that make up a function’s name can be used to predict potentially vulnerable functions. In contrast to the 
lightweight
 prediction provided by a DNN considering only function names, avoiding the need for a DNN provides 
featherweight
 prediction. The underlying idea is that function names that contain certain “dangerous” words are more likely to accompany vulnerable functions. Of course, this assumes that the frequency-based algorithm can be properly tuned to focus on truly dangerous words.
Because it is more transparent than a DNN, which behaves as a “black box” and thus provides no insight into the rationalization underlying its decisions, the frequency-based algorithm enables us to investigate the inner workings of the DNN. If successful, this investigation into what the DNN does and does not learn will help us train more effective future models.
We empirically evaluate our approach on a heterogeneous dataset containing over 73
 
000 functions labeled vulnerable, and over 950
 
000 functions labeled benign. Our analysis shows that words alone account for a significant portion of the DNN’s classification ability. We also find that words are of greatest value in the datasets with a more homogeneous vocabulary. Thus, when working within the scope of a given project, where the vocabulary is unavoidably homogeneous, our approach provides a cheaper, potentially complementary, technique to aid in the hunt for source-code vulnerabilities. Finally, this approach has the advantage that it is viable with orders of magnitude less 
training data
.",June 2022,"Model interpretability, Vulnerability prediction, Identifier splitting, Source code vocabulary, Software security",Information and Software Technology,2025-03-18T00:00:00,9.0,"The approach of predicting vulnerable source code using a frequency-based algorithm provides a transparent alternative to DNNs, which can be highly impactful for startups in need of cost-effective ways to improve code security."
https://www.sciencedirect.com/science/article/pii/S0950584922000258,An empirical study on self-admitted technical debt in modern code review,Yutaro=Kashiwa: kashiwa@ait.kyushu-u.ac.jp,"Abstract
Technical debt is a sub-optimal state of development in projects. In particular, the type of technical debt incurred by developers themselves (e.g., comments that mean the implementation is imperfect and should be replaced with another implementation) is called self-admitted technical debt (SATD). In theory, technical debt should not be left for a long period because it accumulates more cost over time, making it more difficult to process. Accordingly, developers have traditionally conducted code reviews to find technical debt. In fact, we observe that many SATD comments are often introduced during modern code reviews (MCR) that are light-weight reviews with web applications. However, it is uncertain about the nature of SATD comments that are introduced in the review process: impact, frequency, characteristics, and triggers. Herein, this study empirically examines the relationship between SATD and MCR.
Our 
case study
 of 156,372 review records from the Qt and OpenStack systems shows that (i) review records involving SATD are about 6%–7% less likely to be accepted by reviews than those without SATD; (ii) review records involving SATD tend to require two to three more revisions compared with those without SATD; (iii) 28–48% of SATD comments are introduced during code reviews; (iv) SATD during reviews works for communicating between authors and reviewers; and (v) 20% of the SATD comments are introduced due to reviewers’ requests.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on self-admitted technical debt during code reviews provides insights into the relationship between SATD and MCR, but the practical impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922000349,A checklist for the evaluation of software process line approaches,Halimeh=Agh: agh.halime@gmail.com,"Abstract
Context
A Software 
Process Line
 (SPrL) can help organisations to construct bespoke software development processes for specific project situations by reusing core assets. However, as there are diverse approaches for SPrL Engineering (SPrLE), this necessitates proper assistance to organisations in selecting the SPrL approach best suited to their needs.
Objective
This paper aims to identify an 
evaluation checklist
 that can be used for evaluating SPrLs.
Method
The checklist was constructed in five stages: first, relevant aspects for managing process variability in the context of SPrLs were identified; based on these, research questions were then formed in the second stage. In the third stage, to answer the research questions, a literature review was conducted that focused on analysing 39 primary studies. In the fourth stage, the checklist was built by synthesising the literature results. In the fifth stage, the checklist was applied to two SPrL approaches as a 
proof of concept
.
Results
The checklist includes seven main aspects, including the 
modelling language
 used, the type of the approach based on the number of artefacts produced, the language constructs provided for 
variability modelling
, the process perspectives covered, the tool used for supporting the SPrL approach, the variability-specific features provided to support process variability throughout the SPrL lifecycle, and the empirical evaluation conducted to evaluate the approach.
Conclusion
The checklist can be used by organisations to compare SPrLs and then select the most suitable SPrL approach; furthermore, it can be used by researchers to propose novel SPrL approaches that consider important aspects for variability management throughout the SPrL lifecycle. Although we have provided an example of the use of the checklist to compare SPrLs, an empirical evaluation of the checklist is required to get feedback from the organisations regarding the strengths and weaknesses of the checklist.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The development of an evaluation checklist for Software Process Lines can be valuable for organisations looking to select the best approach, but the impact on startups may not be as immediate as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922000210,Predicting the precise number of software defects: Are we there yet?,Xiao=Yu: xiaoyu@whut.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Yan=Xiao: dcsxan@nus.edu.sg; Heng=Dai: daiheng726@163.com; Fuyang=Li: fyli@whut.edu.cn; Shuo=Feng: shuofeng5-c@my.cityu.edu.hk,"Abstract
Context:
Defect Number Prediction (DNP) models can offer more benefits than classification-based 
defect prediction
. Recently, many researchers proposed to employ regression algorithms for DNP, and found that the algorithms achieve low 
Average Absolute Error
 (AAE) and high Pred(0.3) values. However, since the defect datasets generally contain many non-defective modules, even if a DNP model predicts the number of defects in all modules as zero, the AAE value of the model will be low and Pred(0.3) value will be high. Therefore, the 
good performance
 of the regression algorithms in terms of AAE and Pred(0.3) may be questioned due to the imbalanced distribution of the number of defects.
Objective:
To revisit the impact of regression algorithms for predicting the precise number of defects.
Method:
We examine the practical effects of 12 widely-used regression algorithms, two data resampling algorithm (SmoteR and ROS), and three 
ensemble learning algorithms
 (gradient boosting regression, 
AdaBoost
.R2, and Bagging), one feature selection method (information gain) and one parameter optimization method (grid search) for predicting the precise number of defects on the 18 PROMISE datasets. We propose to evaluate the AAE and Pred(0.3) values for the modules with different numbers of defects separately.
Results:
The AAE values for defective modules are very high and the Pred(0.3) values are very low, i.e., the regression algorithms are very inaccurate for predicting the precise number of defects in defective modules.
Conclusion:
The problem of predicting the precise number of defects via regression algorithms is far from being solved. We recommend that software testers use regression algorithms to rank modules for testing 
resource allocation
, rather than predict the precise number of defects to evaluate the 
software reliability
 and maintenance effort. In addition, most existing DNP studies employing the whole AAE and Pred(0.3) values of all modules as the 
evaluation metrics
 for the proposed DNP algorithms should be revisited.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,3.0,"The research focuses on defect prediction using regression algorithms, which may not have a direct practical value for most European early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S0950584922000404,A Delphi study to recognize and assess systems of systems vulnerabilities,Antonia=Bertolino: antonia.bertolino@isti.cnr.it; Francisco José=Domínguez Mayo: fjdominguez@us.es; María José=Escalona: mjescalona@us.es; Miguel A.=Olivero: molivero@us.es; Ilaria=Matteucci: ilaria.matteucci@iit.cnr.it,"Abstract
Context
System of Systems (SoS) is an emerging paradigm by which independent systems collaborate by sharing resources and processes to achieve objectives that they could not achieve on their own. In this context, a number of emergent behaviors may arise that can undermine the security of the 
constituent systems
.
Objective
We apply the Delphi method with the aims to improve our understanding of SoS security and related problems, and to investigate their possible causes and remedies.
Method
Experts on SoS expressed their opinions and reached consensus in a series of rounds by following a structured questionnaire.
Results
The results show that the experts found more consensus in disagreement than in agreement about some SoS characteristics, and on how SoS vulnerabilities could be identified and prevented.
Conclusions
From this study we learn that more work is needed to reach a shared understanding of SoS vulnerabilities, and we leverage expert feedback to outline some future research directions.",June 2022,"Delphi, Expert judgment, Security, Systems of systems",Information and Software Technology,2025-03-18T00:00:00,5.0,The study addresses security issues in System of Systems (SoS) which could have practical implications for early-stage ventures dealing with cybersecurity.
https://www.sciencedirect.com/science/article/pii/S0950584922000362,Towards privacy compliance: A design science study in a small organization,Ze Shi=Li: lize@uvic.ca,"Abstract
Context:
Complying with privacy regulations has taken on new importance with the introduction of the EU’s 
General Data Protection Regulation
 (GDPR) and other privacy regulations. Privacy measures are becoming a paramount requirement demanding software organizations’ attention as recent 
privacy breaches
 such as the Capital One data breach affected millions of customers. Software organizations, however, struggle with achieving privacy compliance. In particular, there is a lack of research into the organizational practices and challenges involved in compliance, particularly for 
small and medium enterprises
 (SMEs), which represent a sizeable portion of organizations. Many SMEs use a continuous 
software engineering
 (CSE) approach, which introduces additional adoption and application challenges. For example, the fast pace of CSE makes it harder for SMEs that are already more resource constrained to prioritize non-functional requirements such as privacy.
Objective:
This paper aims to fill a gap in the under-researched area of continuous compliance with privacy requirements in practice, by investigating how a continuous practicing SME dealt with GDPR compliance.
Method:
Using design science, we conducted an in-depth ethnographically informed study over the span of 16 months and iteratively developed two artifacts to help address the organization’s challenges in addressing GDPR compliance.
Results:
We identified 3 main challenges that our collaborating organization experienced when trying to comply with the GDPR. To help mitigate the challenges, we developed two design science artifacts, which include a list of privacy requirements that operationalized the GDPR principles for automated verification, and an automated testing tool that helps to verify these privacy requirements. We validated these artifacts through close collaboration with our partner organization and applying our artifacts to the partner organization’s system.
Conclusions:
We conclude with a discussion of opportunities and obstacles in leveraging CSE to achieve continuous compliance with the GDPR. We also highlight the importance of building a shared understanding of privacy non-functional requirements and how 
risk management
 plays an important role in an organization’s GDPR compliance.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The research on continuous compliance with GDPR requirements is highly relevant to startups and SMEs in Europe, providing valuable insights and practical solutions."
https://www.sciencedirect.com/science/article/pii/S0950584922000398,Leveraging execution traces to enhance traceability links recovery in BPMN models,Francisca=Pérez: mfperez@usj.es; Óscar=Pastor: opastor@pros.upv.es; Carlos=Cetina: ccetina@usj.es; Raúl=Lapeña: rlapena@usj.es,"Abstract
Context:
Traceability Links
 Recovery has been a topic of interest for many years, resulting in techniques that perform traceability based on the linguistic clues of the software artifacts under study. However, 
BPMN
 models tend to present an overall lack of linguistic clues when compared to code-based artifacts or code generation models. Hence, TLR becomes a harder task when performed among requirements and 
BPMN
 models.
Objective:
This paper proposes a novel approach, called METRA, that leverages the execution traces of BPMN to expand the BPMN models. The expansion of the BPMN models enhances their linguistic clues, bridging the language between BPMN models and other software artifacts, and improving the TLR process between requirements and BPMN models.
Methods:
The proposed approach is evaluated through a real-world industrial 
case study
, comparing its outcomes against two state-of-the-art baselines, TLR and LORE. The paper also evaluates the combination of METRA with LORE against the rest of the approaches, including standalone METRA. The evaluation process generates a report of measurements (precision, recall, f-measure, and MCC), over which a statistical analysis is conducted.
Results:
Results show that approaches based on METRA maintain the excellent precision results obtained by baseline approaches (74.2% for METRA, 78.8% for METRA+LORE), whilst also improving the recall results from the unacceptable values obtained by the baselines to good values (72.4% for METRA, 73.9% for METRA+LORE). Moreover, according to the statistical analysis, the differences in the results obtained by the evaluated approaches are statistically significant.
Conclusions:
This paper opens a novel field of work in TLR by analyzing the improvement of the TLR process through the inclusion of linguistic clues present in execution traces, and discusses ideas for further research that can delve into this promising direction explored by our work.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed approach for improving traceability links between requirements and BPMN models could benefit startups in terms of software development efficiency and quality.
https://www.sciencedirect.com/science/article/pii/S095058492200026X,Context2Vector: Accelerating security event triage via context representation learning,Runzi=Zhang: runzi_zhang@163.com,"Abstract
Context:
Security teams are overwhelmed by thousands of alerts and events everyday, which are comprehensively collected for threat analysis in 
security operations center
. Although methods based on rules, intelligence and data mining are utilized, the alert fatigue situation is still a challenging problem, slowing down the overall threat investigation process.
Objective:
‘Event polysemy’ phenomenon broadly exists in large-scale event dataset, which means that events of the same category can reveal different purposes in different contexts. This paper aims at exploring, revealing and evaluating the latent patterns embedding in the event contexts, to gain insight on context semantics and reduce manual intervention in event triage tasks.
Method:
A context 
representation learning
 based method, named Context2Vector, is proposed. Contexts are extracted from multiple behavioral views. Then, both dense event representations and sparse topic representations are learnt at the same time and in the same space. A human-in-the-loop topic annotation process is involved and finally, a context deviation detection based method is integrated to generate explainable and informative labels for automated context semantic decoding.
Results:
Various experiments are conducted on a enterprise-scale event dataset. The topic annotation, context related feature importance and top-N event ranking evaluation results show that Context2Vector outperforms traditional methods on the high-risk event identification problems, improving the attacker recall rate by up to 2.25 times within limited events to be investigated.
Conclusion:
It is concluded that event contexts imply practicable and abundant information in regard to behaviors and intents of real threat actors. More precise profiling of network entities can be extracted from contexts, compared to rules, intelligence, and 
anomaly detectors
 used in practice.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The research on event polysemy and context representation learning for threat analysis can provide valuable insights for startups dealing with security operations and alert fatigue.
https://www.sciencedirect.com/science/article/pii/S0950584922000180,An evaluation of the effectiveness of personalization and self-adaptation for e-Health apps,Patricia=Lago: p.lago@vu.nl; Ivano=Malavolta: i.malavolta@vu.nl; Eoin Martino=Grua: e.m.grua@vu.nl; Martina=De Sanctis: martina.desanctis@gssi.it; Mark=Hoogendoorn: m.hoogendoorn@vu.nl,"Abstract
Context.
There are many e-Health mobile apps on the apps store, from apps to improve a user’s lifestyle to mental coaching. Whilst these apps might consider user context when they give their interventions, prompts, and encouragements, they still tend to be rigid 
e.g.,
 not using user context and experience to tailor themselves to the user.
Objective.
To better engage and tailor to the user, we have previously proposed a Reference Architecture for enabling self-adaptation and 
AI
 personalization in e-Health mobile apps. In this work we evaluate the end users’ perception, usability, performance impact, and energy consumption contributed by this Reference Architecture.
Method.
We do so by implementing a Reference Architecture compliant app and conducting two experiments: a user study and a measurement-based experiment.
Results.
Although limited in the number of participants, the results of our user study show that usability of the Reference Architecture compliant app is similar to the control app. Users’ perception was found to be positively influenced by the compliant app when compared to the control group. Results of our measurement-based experiment showed some differences in performance and energy consumption measurements between the two apps. The differences are, however, deemed minimal.
Conclusions.
Our experiments show promising results for an app implemented following our proposed Reference Architecture. This is preliminary evidence that the use of personalization and self-adaptation techniques can be beneficial within the domain of e-Health apps.",June 2022,"Self-adaptive systems, Personalization, Reference architecture, Mobile apps, e-Health",Information and Software Technology,2025-03-18T00:00:00,8.0,The research on enabling self-adaptation and personalization in e-Health mobile apps shows promising results that could have a significant impact on the user experience and effectiveness of such apps.
https://www.sciencedirect.com/science/article/pii/S0950584922000416,Prioritization of model smell refactoring using a covariance matrix-based adaptive evolution algorithm,Amjad=AbuHassan: amjad.abuhassan@najah.edu; Mohammad=Alshayeb: alshayeb@kfupm.edu.sa; Lahouari=Ghouti: lghouti@psu.edu.sa,"Abstract
Context
The 
refactoring process
 enhances the 
software design
 by modifying the structure of design parts impaired with 
model smells
 without altering the overall software behavior. However, handling these smells without proper prioritization will not produce the anticipated effects.
Objective
In this paper, we solve the prioritization of the model smell refactoring using a multi-objective optimization (MOO) algorithm called the multi-objective (MO) 
covariance matrix
 adaptation evolution strategy (MO
CMA-ES). Our formulation relies on the refactoring of 
unified modeling language
 (UML) 
class diagrams
 to mitigate the negative effect of design smells.
Method
We treat the prioritization problem as a real-valued MOO where we propose novel data encoding procedures. We use two conflicting objectives, quality, and 
maintainability
, to balance the refactoring. We first build a new solution representation that guarantees smell fixing and eliminates the rejection limitation. Furthermore, we suggest a custom mapping scheme to properly encode real-valued quantities using unique representations. For performance evaluation purposes, we developed a large custom dataset with more than 30,000 class records, using seven popular open-source software projects. A novel relative coverage metric is proposed to mitigate the limitations associated with the standard coverage. For benchmarking purposes, we also consider an improved version of the nondominated sorting 
genetic algorithm
 (NSGA-II(.
Results
The reported performance scores confirm the superiority of the MO
CMA-ES algorithm over NSGA-II. The former successfully identified the refactoring sequences that lead to the best improvements in software quality and 
maintainability
 while it is able to fix all identified design smells. These improvements are quantified in terms of hypervolume, coverage, spacing metrics, and 
execution time
.
Conclusion
The MO
CMA-ES attained the highest average maximum quality score of 1149 while keeping the average 
maintainability
 at the lowest score of 13.8. In all experiment settings, the proposed solution leads to longer refactoring sequences at no additional computational cost.",June 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"The use of a multi-objective optimization algorithm for model smell refactoring in UML class diagrams demonstrates a high practical value and potential impact on software quality and maintainability, making it highly valuable for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000179,Short communication: Evolution of secondary studies in software engineering,David=Budgen: david.budgen@durham.ac.uk; Pearl=Brereton: o.p.brereton@keele.ac.uk,"Abstract
Context:
Other disciplines commonly employ secondary studies to address the needs of practitioners and policy-makers. Since being adopted by 
software engineering
 in 2004, many have been undertaken by researchers.
Objective:
To assess how the role of secondary studies in software engineering has evolved.
Methods:
We examined a sample of 131 secondary studies published in a set of five major software engineering journals for the years 2010, 2015 and 2020. These were categorised by their 
type
 (e.g. mapping study), their 
research focus
 (quantitative/qualitative and practice/methodological), as well as the experience of the first authors.
Results:
Secondary studies are now a well-established research tool. They are predominantly qualitative and there is extensive use of mapping studies to profile research in particular areas. A significant number are clearly produced as part of postgraduate study, although experienced researchers also conduct many secondary studies. They are sometimes also used as part of a multi-method study.
Conclusion:
Existing guidelines
 largely focus upon quantitative 
systematic reviews
. Based on our findings, we suggest that more guidance is needed on how to conduct, analyse, and report qualitative secondary studies.",May 2022,"Systematic review, Mapping study, Qualitative study, Experience of authors",Information and Software Technology,2025-03-18T00:00:00,6.0,"The assessment of the role of secondary studies in software engineering provides valuable insights, but the practical impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922000234,Translating quality-driven code change selection to an instance of multiple-criteria decision making,Miltiadis=Siavvas: siavvasm@iti.gr; Dionysios=Kehagias: diok@iti.gr; Alexander=Chatzigeorgiou: achat@uom.edu.gr; Christos P.=Lamprakos: cplamprakos@microlab.ntua.gr; Charalampos=Marantos: hmarantos@microlab.ntua.gr; Lazaros=Papadopoulos: lpapadop@microlab.ntua.gr; Angeliki-Agathi=Tsintzira: angeliki.agathi.tsintzira@gmail.com; Apostolos=Ampatzoglou: ampatzoglou@uom.edu.gr; Dimitrios=Soudris: dsoudris@microlab.ntua.gr,"Abstract
Context:
The definition and assessment 
of software quality
 have not converged to a single specification. Each team may formulate its own notion of quality and tools and methodologies for measuring it. Software quality can be improved via code changes, most often as part of a software maintenance loop.
Objective:
This manuscript contributes towards providing decision support for code change selection given a) a set of preferences on a software product’s qualities and b) a pool of heterogeneous code changes to select from.
Method:
We formulate the problem as an instance of Multiple-Criteria Decision Making, for which we provide both an abstract flavor and a prototype implementation. Our prototype targets energy efficiency, technical debt and dependability.
Results:
This prototype achieved inconsistent results, in the sense of not always recommending changes reflecting the decision maker’s preferences. Encouraged from some positive cases and cognizant of our prototype’s shortcomings, we propose directions for future research.
Conclusion:
This paper should thus be viewed as an imperfect first step towards quality-driven, code change-centered decision support and, simultaneously, as a curious yet pragmatic enough gaze on the road ahead.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract presents a practical approach to improving software quality through decision support for code change selection, which can have a significant impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921002378,A systematic literature review on counterexample explanation,Thomas=Vogel: thomas.vogel@informatik.hu-berlin.de; Arut Prakash=Kaleeswaran: arutprakash.kaleeswaran@de.bosch.com; Arne=Nordmann: arne.nordmann@de.bosch.com; Lars=Grunske: grunske@informatik.hu-berlin.de,"Abstract
Context:
Safety is of 
paramount importance
 for cyber–physical systems in domains such as automotive, robotics, and avionics. Formal methods such as model checking are one way to ensure the safety of cyber–physical systems. However, adoption of formal methods in industry is hindered by 
usability issues
, particularly the difficulty of understanding model checking results.
Objective:
We want to provide an overview of the state of the art for counterexample explanation by investigating the contexts, techniques, and evaluation of research approaches in this field. This overview shall provide an understanding of current and guide future research.
Method:
To provide this overview, we conducted a systematic literature review. The survey comprises 116 publications that address counterexample explanations for model checking.
Results:
Most primary studies provide counterexample explanations graphically or as traces, minimize counterexamples to reduce complexity, localize errors in the models expressed in the input formats of 
model checkers
, support 
linear temporal logic
 or computation tree logic specifications, and use 
model checkers
 of the Symbolic Model Verifier family. Several studies evaluate their approaches in safety-critical domains with industrial applications.
Conclusion:
We notably see a lack of research on counterexample explanation that targets probabilistic and real-time systems, leverages the explanations to domain-specific models, and evaluates approaches in user studies. We conclude by discussing the adequacy of different types of explanations for users with varying domain and formal methods expertise, showing the need to support laypersons in understanding model checking results to increase adoption of formal methods in industry.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract addresses usability issues in formal methods for cyber-physical systems, which can be important for European startups in automotive, robotics, and avionics industries."
https://www.sciencedirect.com/science/article/pii/S0950584922000167,Response time evaluation of mobile applications combining network protocol analysis and information fusion,Yihao=Li: yihao.li@ldu.edu.cn,"Abstract
The 
response time
 of a mobile application (app), especially a mobile stock trading app, is an important factor that affects customer satisfaction. However, it is considerably difficult to accurately evaluate the performance of mobile apps owing to numerous real-world settings such as operating systems, hardware, and test environments. This paper presents a novel method to evaluate the 
response time
 of mobile apps on different 
mobile phones
 through combining network protocol analysis and information fusion. To make the 
data collected
 from the mobile app more reliable and credible, we recruited some volunteers to collect data on their 
mobile phones
. Then we used the network protocol analysis method to obtain the response time of the mobile app on a mobile phone. Next, we adopted information fusion technology using the rank-score 
characteristic function
 to evaluate the response time of mobile apps on different mobile phones. Experiments were conducted to evaluate our approach on three types of mobile apps. The results showed that the proposed method can effectively evaluate the response time of mobile apps with low cost.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract introduces a novel method to evaluate the response time of mobile apps, which can benefit startups developing mobile applications in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584921002433,A unifying framework for the systematic analysis of Git workflows,Julio César=Cortés Ríos: juliocesar.cortesrios@manchester.ac.uk; Suzanne M.=Embury: suzanne.m.embury@manchester.ac.uk; Sukru=Eraslan: seraslan@metu.edu.tr,"Abstract
Context:
Git is a popular distributed version control system that provides flexibility and robustness for software development projects. Several workflows have been proposed to codify the way project contributors work collaboratively with Git. Some workflows are highly prescriptive while others allow more leeway but do not provide the same level of code quality assurance, thus, preventing their comparison to determine the most suitable for a specific set of requirements, or to ascertain if a workflow is being properly followed.
Objective:
In this paper, we propose a novel feature-based framework for describing Git workflows, based on a study of 26 existing instances. The framework enables workflows’ comparison, to discern how, and to what extent, they exploit Git capabilities for 
collaborative software development
.
Methods:
The framework uses feature-based modelling to map Git capabilities, regularly expressed as contribution guidelines, and a set of features that can be impartially applied to all the workflows considered. Through this framework, each workflow was characterised based on their publicly available descriptions. The characterisations were then vectorised and processed using 
hierarchical clustering
 to determine workflows’ similarities and to identify which features are most popular, and more relevant for discriminatory purposes.
Results:
Comparative analysis evidenced that some workflows claiming to be closely related, when described and then characterised, turned out to have more differences than similarities. The analysis also showed that most workflows focus on the branching and code integration strategies, whilst others emphasise subtle differences from other popular workflows or describe a specific development route and are, thus, widely reused.
Conclusion:
The characterisation and 
clustering analysis
 demonstrated that our framework can be used to compare and analyse Git workflows.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract proposes a feature-based framework for describing Git workflows, which can be valuable for startups collaborating on software development projects in Europe."
https://www.sciencedirect.com/science/article/pii/S0883902620306674,Does new venture team power hierarchy enhance or impair new venture performance? A contingency perspective,Xiao-Yun=Xie: xiexy@zju.edu.cn; Wen=Feng: fengwen@zju.edu.cn; Qiongjing=Hu: qjhu@zju.edu.cn,"Abstract
Power hierarchy has the potential to both benefit and harm the functioning of new venture teams (NVTs) and hence new venture performance. Integrating structural 
contingency theory
 with the literature on power hierarchy, we propose that the effect of NVT power hierarchy on new venture performance is contingent on NVT homogeneity (as indicated by functional background homogeneity and shared team experience) and the powerholder's prior founding experience. Specifically, we propose that the effect of NVT power hierarchy on new venture performance will be positive when NVT homogeneity is low but negative when NVT homogeneity is high. Furthermore, this positive (negative) effect under low (high) NVT homogeneity will be strengthened by the powerholder's prior founding experience. Based on a five-year panel data of 285 new Internet ventures listed on the National Equities Exchange and Quotations (NEEQ) in China combined with qualitative fieldwork, our hypotheses received general support. We discuss the theoretical and practical implications of our findings on how NVTs should design 
power structures
 to achieve optimal new venture performance.",November 2020,Not Found,Business Venturing,2025-03-21T00:00:00,6.0,The study on power hierarchy in new venture teams and its impact on performance may provide useful guidance for European startups in designing effective power structures.
https://www.sciencedirect.com/science/article/pii/S0950584921002469,"Drivers, barriers and impacts of digitalisation in rural areas from the viewpoint of experts",Alessio=Ferrari: alessio.ferrari@isti.cnr.it,"Abstract
Context:
The domain of rural areas, including rural communities, 
agriculture
, and 
forestry
, is going through a process of deep digital transformation. 
Digitalisation
 can have positive impacts on 
sustainability
 in terms of greater environmental control, and community prosperity. At the same time, it can also have disruptive effects, with the 
marginalisation
 of actors that cannot cope with the change. When developing a novel system for rural areas, requirements engineers should carefully consider the specific socio-economic characteristics of the domain, so that potential positive effects can be maximised, while mitigating 
negative impacts
.
Objective:
The goal of this paper is to support requirements engineers with a reference catalogue of 
drivers
, 
barriers
 and potential 
impacts
 associated to the introduction of novel ICT solutions in rural areas.
Method:
To this end, we interview 30 cross-disciplinary experts in digitalisation of rural areas, and we analyse the transcripts to identify common themes.
Results:
According to the experts, main 
drivers
 are economic, with the possibility of reducing costs, and regulatory, as institutions push for more precise tracing and monitoring of production; 
barriers
 are the limited connectivity, but also distrust towards technology and other socio-cultural aspects; positive 
impacts
 are socio-economic (e.g., reduction of manual labour, greater productivity), while negative ones include potential dependency from technology, with loss of hands-on expertise, and marginalisation of certain actors (e.g., 
small farms
, subjects with limited education).
Conclusion:
This paper contributes to the literature with a domain-specific catalogue that characterises digitalisation in rural areas. The catalogue can be used as a reference baseline for 
requirements elicitation
 endeavours in rural areas, to support domain analysis prior to the development of novel solutions, as well as fit-gap analysis for the adaptation of existing technologies.",May 2022,"68-02, 68U35, 68N99",Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract focuses on digital transformation in rural areas, which may have indirect relevance to European startups, but may not directly impact early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000015,Predicting vulnerability inducing function versions using node embeddings and graph neural networks,Sefa Eren=Şahin: sahinsef@itu.edu.tr; Ecem Mine=Özyedierler: ozyedierlere@itu.edu.tr; Ayse=Tosun: tosunay@itu.edu.tr,"Abstract
Context:
Predicting software vulnerabilities over code changes is a difficult task due to obtaining real vulnerability data and their associated code fixes from software projects as software organizations are often reluctant to report those.
Objective:
We aim to propose a vulnerability prediction model that runs after every code change, and identifies vulnerability inducing functions in that version. We also would like to assess the success of node and token based source code representations over 
abstract syntax trees
 (ASTs) on predicting vulnerability inducing functions.
Method:
We train 
neural networks
 to represent 
node embeddings
 and token embeddings over ASTs in order to obtain feature representations. Then, we build two 
Graph Neural Networks
 (GNNs) with 
node embeddings
, and compare them against 
Convolutional Neural Network
 (CNN) and 
Support Vector Machine
 (SVM) with token representations.
Results:
We report our empirical analysis over the change history of vulnerability inducing functions of 
Wireshark
 project. GraphSAGE model using source code representation via ASTs achieves the highest AUC rate, while 
CNN models
 using token representations achieves the highest recall, precision and F1 measure.
Conclusion:
Representing functions with their structural information extracted from ASTs, either in token form or in complete graph form, is great at predicting vulnerability inducing function versions. Transforming source code into token frequencies as a natural language text fails to build successful models for vulnerability prediction in a real software project.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed vulnerability prediction model using GraphSAGE achieves high AUC rates and provides valuable insights into predicting vulnerability inducing functions, which can benefit early-stage ventures in improving software security."
https://www.sciencedirect.com/science/article/pii/S0950584921002470,Enhancing software modularization via semantic outliers filtration and label propagation,Junfeng=Wang: wangjf@scu.edu.cn,"Abstract
Context:
Software systems’ modular structure often drifts from the intended design throughout evolution. To improve the modular structure of a software system, the 
software clustering
 technology aiming to partition a software system into meaningful modules is demanding. Many 
clustering approaches
 rely on semantic information, which cluster software entities that use similar vocabulary. However, the existence of semantic outliers obstructing the 
clustering process
 is hardly considered.
Objective:
To overcome the existence of semantic outliers, this paper proposes a two-stage 
software clustering
 approach named EVOL (Enhancing Via Outliers filtration and Label propagation).
Methods:
A feature density-based 
outliers detecting
 algorithm is used to compute the 
local outlier factor
 of each feature. Accordingly, we filter out the semantic outliers and cluster remaining high-quality features to construct a partition skeleton; After that, assign each outlier into a suitable cluster by label propagation.
Results:
To assess the effectiveness of the proposed approach, this paper conducts experiments on six folders from Mozilla Firefox and other four software systems, referring to the original design concepts and modular structure provided by the developers. The average of the 
evaluation metric
 MoJoFM shows significant improvement from 6% to 35% over the other six state-of-art 
clustering techniques
. The results demonstrate that the filtration of the outliers facilitates the 
clustering results
, and label propagation could place the outliers into a suitable cluster.
Conclusion:
In this paper, we propose EVOL, a new software clustering approach that considers semantic outliers filtration and label propagation. The experiment results show that the proposed approach EVOL can be very useful to enhance the quality of the software modularization.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The EVOL software clustering approach significantly improves the modular structure of software systems by addressing semantic outliers, offering a practical solution that can have a positive impact on European early-stage ventures in enhancing software modularization."
https://www.sciencedirect.com/science/article/pii/S0950584922000027,An automated test data generation method for void pointers and function pointers in C/C++ libraries and embedded projects,Lam Nguyen=Tung: tunglam@vnu.edu.vn; Hoang-Viet=Tran: thv@vnu.edu.vn; Khoi Nguyen=Le: khoi.n.le@vnu.edu.vn; Pham Ngoc=Hung: hungpn@vnu.edu.vn,"Abstract
Automated test data generation for unit testing C/C++ functions using concolic methods is well-known for improving software quality while reducing human testing effort. However, there have been only a few researches related to generating test data for void pointers and 
function pointers
 which are commonly used in C/C++ libraries and embedded projects. This paper proposes a concolic-based method named VFP (
V
oid and 
F
unction 
P
ointers test data generation) to generate test data for void pointers and 
function pointers
. The key idea of VFP method is to preprocess the 
source code
 of the project under test to find all possible types of void pointers and references of function pointers. These types and references are used in the initial test data generating phase of the concolic 
testing method
. VFP method is implemented in VFP verification tool to test on various C/C++ libraries and embedded projects. The experimental results show that VFP significantly improves the coverage of the generated test data in comparison with existing methods.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The VFP method for generating test data for void and function pointers in C/C++ libraries is a valuable contribution to improving software quality, especially for embedded projects, which can be beneficial for startups focusing on such technologies."
https://www.sciencedirect.com/science/article/pii/S0950584922000192,Personalizing label prediction for GitHub issues,Lin=Chen: lchen@nju.edu.cn; Xiaofang=Zhang: xfzhang@suda.edu.cn; Jun=Wang: 20194227028@stu.suda.edu.cn; Xiaoyuan=Xie: xxie@whu.edu.cn,"Abstract
Context:
Automated label prediction tools can help developers manage and categorize issues on GitHub. However, different open-source projects use various forms of labels with the same meaning. Previous label prediction methods mainly solve the problem of the synonymous labels by manual preprocessing rules, but these preprocessing rules can only identify synonyms with the same prefix or suffix.
Objective:
These factors inspire us to propose a method to identify these synonymous labels automatically and recommend personalized labels for different open-source projects.
Method:
In this paper, we propose a Personalizing Label Prediction framework for Issues named PLPI. PLPI identifies labels with similar meanings by representing labels as 
semantic vectors
 and applying 
clustering methods
. PLPI can predict personalized labels from the 
existing labels
 in the open-source project.
Result:
We conduct a comprehensive study to compare seven commonly adopted labeling models with our approach. The experimental results demonstrate the advantages of our approach. Finally, we show some representative examples and discuss the visualization results of synonyms clustering by dimension reduction.
Conclusion:
The experimental results show that our method PLPI can improve label prediction performance and provide personalized label recommendation results for different open-source projects.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The PLPI framework for personalized label prediction addresses the issue of synonymous labels in open-source projects, providing a practical solution, although it may have a limited direct impact on European early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921002391,Inferring data model from service interactions for response generation in service virtualization,Md. Arafat=Hossain: mdarafathossain@swin.edu.au; Jiaojiao=Jiang: jiaojiao.jiang@unsw.edu.au; Jun=Han: jhan@swin.edu.au; Muhammad Ashad=Kabir: akabir@csu.edu.au; Jean-Guy=Schneider: jeanguy.schneider@deakin.edu.au; Chengfei=Liu: cliu@swin.edu.au,"Abstract
Context:
 Service 
virtualization
 has become a popular tool to provide testing environments for highly connected enterprise software systems. It enables the enterprise system under test to interact with and obtain responses from model-based service emulations instead of the actual services they use in production environments, providing accessibility and realness. Existing approaches consider only the 
control dependencies
 between messages (
i.e.
, the service’s control model) and do not consider the relationships between data values of the messages (
i.e.
, the service’s data model), limiting the accuracy of service emulation.
Objective:
 In this paper, we present an approach to deriving the service’s data model from its interaction traces and using it in determining the payloads for 
response messages
, therefore achieving more accurate service emulation.
Method:
 The derivation of a service’s data model is achieved by discovering the data entities and their key attribute(s) from the service interaction messages. It is then used, together with the control model, to synthesize 
response messages
 for incoming 
request messages
 at runtime. While the control model help to identify the types of responses, the data model keeps track of the changes to the service’s data entities and provides the basis for populating accurate payloads for the responses.
Results:
 A number of experiments have been conducted on message traces collected from a range of stateful and stateless services. With the use of both the control and data models in 
response generation
, our approach consistently outperforms the existing state-of-the-art approaches. In particular, it generates 100% identical responses (compared to actual services) for most of the datasets, while the highest accuracy achieved by existing approaches was 88%.
Conclusion:
 The experimental results have shown that the inferred data model provides an effective means in determining the payloads for response messages, significantly improving the accuracy of service emulation and providing more realistic testing environments.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The approach to deriving service data models for accurate service emulation offers a significant advancement in service virtualization, which can benefit startups utilizing service emulation for testing enterprise software systems."
https://www.sciencedirect.com/science/article/pii/S0950584921002445,Feature toggles as code: Heuristics and metrics for structuring feature toggles,Rezvan=Mahdavi-Hezaveh: rmahdav@ncsu.edu,"Abstract
Context:
Using feature toggles is a technique to turn a feature either on or off in program code by checking the value of a variable in a 
conditional statement
. This technique is increasingly used by software practitioners to support continuous integration and continuous delivery (CI/CD). However, using feature toggles may increase code complexity, create dead code, and decrease the quality of a codebase.
Objective:
The goal of this research is to aid software practitioners in structuring feature toggles in the codebase by proposing and evaluating a set of heuristics and corresponding complexity, 
comprehensibility
, and 
maintainability
 metrics based upon an empirical study of open source repositories.
Method:
We identified 80 GitHub repositories that use feature toggles in their 
development cycle
. We conducted a qualitative analysis using 60 of the 80 repositories to identify heuristics and metrics. Then, we conducted a survey of practitioners of 80 repositories to obtain their feedback that the proposed heuristics can be used to guide the structure of feature toggles and to reduce technical debt. We also conducted a 
case study
 of the all 80 repositories to analyze relations between heuristics and metrics.
Results:
From the qualitative analysis, we proposed 7 heuristics to guide structuring feature toggles and identified 12 metrics to support the principles embodied in the heuristics. Our survey result shows that practitioners agree that managing feature toggles is difficult, and using identified heuristics can reduce technical debt. Based on our 
case study
, we find a relationship between the adoption of heuristics and the values of metrics.
Conclusions:
Our results support that practitioners should have self-descriptive feature toggles, use feature toggles sparingly, avoid duplicate code in using feature toggles, and ensure complete removal of a feature toggle.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The research on structuring feature toggles can provide valuable insights for software practitioners, but may have limited direct impact on early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584922000040,Ambiguity in user stories: A systematic literature review,Anis R.=Amna: AnisRahmawati.Amna@UGent.be; Geert=Poels: Geert.Poels@UGent.be,"Abstract
Context
Ambiguity in user stories is a problem that has received little research attention. Due to the absence of review studies, it is not known how and to what extent this problem, which impacts the effectiveness of user stories in supporting systems development, has been solved.
Objectives
We review the studies that investigate or develop solutions for problems related to ambiguity in user stories. We investigate how these problems manifest themselves, what their causes and consequences are, what solutions have been proposed and what evidence of their effectiveness has been presented. Based on the insights we obtain from this review, we identify research gaps and suggest opportunities for future research.
Methods
We followed Systematic Literature Review guidelines to review problems investigated, solutions proposed, and validation/evaluation methods used. We classified the reviewed studies according to the four linguistic levels of ambiguity (i.e., lexical, 
syntactic
, semantic, pragmatic) proposed by Berry and Kamsties to obtain insights from patterns that we observe in the classification of problems and solutions.
Results
A total of 36 studies published in 2001–2020 investigated ambiguity in user stories. Based on four patterns we discern, we identify three research gaps. First, we need more research on human behaviors and cognitive factors causing ambiguity. Second, ambiguity is seldom studied as a problem of a set of related user stories, like a theme or epic in Scrum. Third, there is a lack of holistic solution approaches that consider ambiguity at multiple linguistic levels.
Conclusion
Ambiguity in user stories is a known problem. However, a comprehensive solution for addressing ambiguity in a set of related user stories as it manifests itself at different linguistic levels as a cognitive problem is lacking.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"While addressing ambiguity in user stories is a relevant problem, the research focus may not directly translate to practical value for early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584922000052,Proactive hybrid learning and optimisation in self-adaptive systems: The swarm-fleet infrastructure scenario,Christian=Krupitzer: christian.krupitzer@uni-hohenheim.de,"Abstract
Context:
Smart and adaptive Systems, such as self-adaptive and self-organising (SASO) systems, typically consist of a large set of highly autonomous and heterogeneous subsystems that are able to adapt their behaviour to the requirements of ever-changing, dynamic environments. Their successful operation is based on appropriate modelling of the internal and external conditions.
Objective:
The control problem for establishing a near-to-optimal coordinated behaviour of systems with multiple, potentially conflicting objectives is either approached in a distributed (i.e., fully autonomous by the autonomous subsystems) or in a centralised way (i.e. one instance controlling the optimisation and planning process). In the distributed approach, selfish behaviour and being limited to local knowledge may lead to sub-optimal 
system behaviour
, while the 
centralised approach
 ignores the 
autonomy
 and the coordination efforts of parts of the system.
Method:
In this article, we present a concept for a hybrid (i.e., integrating a central optimisation with a distributed decision-making process) 
system management
 that combines local 
reinforcement learning
 and self-awareness mechanisms of fully autonomous subsystems with external system-wide planning and optimisation of adaptation freedom that steers the behaviour dynamically by issuing plans and guidelines augmented with incentivisation schemes.
Results:
This work addresses the inherent uncertainty of the dynamic 
system behaviour
, the local autonomous and context-aware learning of subsystems, and proactive control based on adaptiveness. We provide the ‘swarm-fleet infrastructure’ – a self-organised taxi service established by autonomous, privately-owned cars – as a 
testbed
 for structured comparison of systems.
Conclusion:
The ‘swarm-fleet infrastructure’ supports the advantages of a proactive hybrid self-adaptive and self-organising system operation. Further, we provide a system model to combine the system-wide optimisation while ensuring local decision-making through 
reinforcement learning
 for individualised configurations.",May 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The concept of a hybrid system management approach can potentially provide practical value for early-stage ventures dealing with dynamic environments and system coordination.
https://www.sciencedirect.com/science/article/pii/S0950584921001804,How resource utilization influences UI responsiveness of Android software,Jiaojiao=Fu: jjfu15@fudan.edu.cn; Yaohui=Wang: 17210240047@fudan.edu.cn; Yangfan=Zhou: zyf@fudan.edu.cn; Xin=Wang: xinw@fudan.edu.cn,"Abstract
Context:
The rapid responsiveness of smartphones is critical to 
user experience
. Excessive 
resource utilization
 is typically considered as one of the major factors leading to laggy-UI. Much work focuses on modifying the design of 
Android
 systems and software to reduce their 
resource utilization
. However, laggy-UI is still quite common on 
Android
 devices, especially the low-end ones. One reason is that developers still lack a clear understanding about how the utilization of various resources (
e.g.
, CPU and memory) affects Android responsiveness, which leads to the inadequacy of existing 
performance optimization
 measures.
Objective:
The objective of this paper is to obtain a systematical understanding of how the utilization of various resources (
e.g.
, CPU and memory) affects Android responsiveness. Then accordingly, we aim to figure out the root cause(s) of laggy-UI.
Methods:
First, we conduct a set of controlled experiments on two Android devices with a stress test tool. Second, we further test 36 real-life Android software to study whether the competition of resource(s), the root factor(s) causing laggy-UI, is severe in real-life scenarios.
Results:
The experimental results show that CPU competition is the root cause and other resources have no observable impact on Android responsiveness, except in extreme cases, 
e.g.
, utilization reaches almost 100%. We also find out CPU competition is quite common for existing Android software when it is running in the background.
Conclusion:
Through stress testing and real-life Android software testing, this work unveils that CPU competition should be the main problem to be solved. Our experimental results deepen and update previous perceptions of resources’ impact on Android responsiveness. Based on these findings, we provide a set of suggestions for designing high-performance Android systems and software, and effective 
performance optimization
 tools.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The study provides insights into how resource utilization affects Android responsiveness, identifying CPU competition as a main issue. The findings offer suggestions for designing high-performance Android systems and software, which could be crucial for startups developing mobile applications."
https://www.sciencedirect.com/science/article/pii/S0950584921002317,A systematic process for Mining Software Repositories: Results from a systematic literature review,M.=Vidoni: melina.vidoni@anu.edu.au,"Abstract
Context:
Mining Software Repositories
 (MSR) is a growing area of 
Software Engineering
 (SE) research. Since their emergence in 2004, many investigations have analysed different aspects of these studies. However, there are no guidelines on how to conduct systematic MSR studies. There is a need to evaluate how MSR research is approached to provide a framework to do so systematically.
Objective:
To identify how MSR studies are conducted in terms of repository selection and 
data extraction
. To uncover potential for improvement in directing systematic research and providing guidelines to do so.
Method:
A 
systematic literature review
 of MSR studies was conducted following the guidelines and 
template
 proposed by Mian et al. (which refines those provided by Kitchenham and Charters). These guidelines were extended and revised to provide a framework for systematic MSR studies.
Results:
MSR studies typically do not follow a systematic approach for repository selection, and many do not report selection or 
data extraction
 protocols. Furthermore, few manuscripts discuss threats to the study’s validity due to the selection or data extraction steps followed.
Conclusions:
Although MSR studies are evidence-based research, they seldom follow a systematic process. Hence, there is a need for guidelines on how to conduct systematic MSR studies. New guidelines and a 
template
 have been proposed, consolidating related studies in the MSR field and strategies for systematic literature reviews.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The evaluation of how MSR studies are conducted can offer valuable insights for researchers but may have limited immediate impact on European early-stage ventures and startups.
https://www.sciencedirect.com/science/article/pii/S095058492100224X,How far are we from reproducible research on code smell detection? A systematic literature review,Lech=Madeyski: lech.madeyski@pwr.edu.pl; Tomasz=Lewowski: tomasz.lewowski@pwr.edu.pl,"Abstract
Context:
Code smells are symptoms of wrong design decisions or coding shortcuts that may increase defect rate and decrease 
maintainability
. Research on code smells is accelerating, focusing on code smell detection and using code smells as 
defect predictors
. Recent research shows that even between software developers, agreement on what constitutes a code smell is low, but several publications claim the high performance of detection algorithms—which seems counterintuitive, considering that algorithms should be taught on data labeled by developers.
Objective:
This paper aims to investigate the possible reasons for the inconsistencies between studies in the performance of applied 
machine learning algorithms
 compared to developers. It focuses on the reproducibility of existing studies.
Methods:
A systematic literature review was performed among conference and journal articles published between 1999 and 2020 to assess the state of reproducibility of the research performed in those papers. A quasi-gold standard procedure was used to validate the search. Modeling process descriptions, reproduction scripts, data sets, and techniques used for their creation were analyzed.
Results:
We obtained data from 46 publications. 22 of them contained a detailed description of the modeling process, 17 included any reproduction data (data set, results, or scripts) and 15 used existing data sets. In most of the publications, analyzed projects were hand-picked by the researchers.
Conclusion:
Most studies do not include any form of an online reproduction package, although this has started to change recently—8% of analyzed studies published before 2018 included a full reproduction package, compared to 22% in years 2018–2019. Ones that do include a package usually use a research group website or even a personal one. Dedicated archives are still rarely used for data packages. We recommend that researchers include complete reproduction packages for their studies and use well-established research data archives instead of their own websites.",April 2022,"Software engineering, Code smells, Reproducibility, Reproducible research",Information and Software Technology,2025-03-18T00:00:00,6.0,"The investigation into the reproducibility of studies on code smells and machine learning algorithms can provide insights into improving code quality and maintainability, which can benefit startups in developing reliable software products."
https://www.sciencedirect.com/science/article/pii/S0950584921002287,Impact of software development processes on the outcomes of student computing projects: A tale of two universities,Aneta=Poniszewska-Marańda: aneta.poniszewska-maranda@p.lodz.pl,"Abstract
Context:
Project-based courses are more and more commonly used as an opportunity to teach students structured methods of developing software. Two well-known approaches in this area – traditional and Agile – have been successfully applied to drive academic projects. However too often the default is still to have no organizational process at all. While a large variety of software development life-cycle models exists, little guidance is available on which one to choose to fit the context of working with students.
Objective:
This paper assesses the impact of iterative, sequential and “hands-off” development approaches on the success of student computing projects. A structured, metric-based assessment scheme was applied to investigate team productivity, teamwork and the quality of the final product.
Method:
Empirical evidence was collected during a controlled experiment carried out at two engineering schools in Europe. More than 100 students at Bachelor’s and Master’s levels participated in the research, with varied software development and teamwork skill sets.
Results:
Similar patterns were observed among both sets of subjects, with iterative teams demonstrating the highest productivity and superior team cohesion but a decline in the quality of the final product. Sequential development led to a considerable improvement in the external 
quality characteristics
 of the software produced, owing to the method’s stress on design activities.
Conclusion:
The findings of this study will be of use to educators interested in applying software development processes to student groupwork. A set of guidelines is provided for applying a structured way of working in a project-based course.",April 2022,"Software engineering, Comparative study, Capstone project, Student projects, Education, Computer science education",Information and Software Technology,2025-03-18T00:00:00,8.0,"Assessing the impact of different software development approaches on student projects can provide valuable guidance for educators and students in early-stage ventures, helping improve project success rates and team productivity."
https://www.sciencedirect.com/science/article/pii/S0950584921002020,Erratum: Leveraging Flexible Tree Matching to repair broken locators in web automation scripts,Sacha=Brisset: sacha.brisset@hotmail.fr; Romain=Rouvoy: romain.rouvoy@univ-lille.fr; Lionel=Seinturier: lionel.seinturier@inria.fr; Renaud=Pawlak: renaud.pawlak@gmail.com,"Abstract
Web applications are constantly evolving to integrate new features and fix reported bugs. Even an imperceptible change can sometimes entail significant modifications of the 
Document Object Model
 (DOM), which is the underlying model used by browsers to render all the elements included in a web application. Scripts that interact with web applications (
e.g.
 web test scripts, crawlers, or robotic process automation) rely on this continuously evolving DOM which means they are often particularly fragile. More precisely, the major cause of breakages observed in automation scripts are 
element locators
, which are identifiers used by automation scripts to navigate across the DOM. When the DOM evolves, these identifiers tend to break, thus causing the related scripts to no longer locate the intended target elements.
For this reason, several contributions explored the idea of automatically repairing broken locators on a page. These works attempt to repair a given broken locator by scanning all elements in the new DOM to find the most similar one. Unfortunately, this approach fails to scale when the complexity of web pages grows, leading either to long 
computation times
 or incorrect element repairs. This article, therefore, adopts a different perspective on this problem by introducing a new locator repair solution that leverages 
tree
 
matching algorithms
 to relocate broken locators. This solution, named 
Erratum
, implements a holistic approach to reduce the element 
search space
, which greatly eases the locator repair task and drastically improves repair accuracy. We compare the robustness of 
Erratum
 on a large-scale benchmark composed of realistic and synthetic mutations applied to popular web applications currently deployed in production. Our empirical results demonstrate that 
Erratum
 outperforms the accuracy of WATER, a state-of-the-art solution, by 67%.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the research on automatically repairing broken locators on web pages is innovative, its direct impact on European early-stage ventures and startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921002342,A model-driven approach to reengineering processes in cloud computing,Mahdi=Fahmideh: mahdi.fahmideh@usq.edu.au,"Abstract
Context
The 
reengineering process
 of large data-intensive legacy 
software applications
 (“legacy applications” for brevity) to cloud platforms involves different interrelated activities. These activities are related to planning, architecture design, re-hosting/lift-shift, 
code refactoring
, and other related ones. In this regard, the 
cloud computing
 literature has seen the emergence of different methods with a disparate point of view of the same underlying legacy application 
reengineering process
 to cloud platforms. As such, the effective interoperability and tailoring of these methods become problematic due to the lack of integrated and consistent standard models.
Objective
We design, implement, and evaluate a novel framework called 
MLSAC (Migration of Legacy Software Applications to the Cloud)
. The core aim of MLSAC is to facilitate the sharing and tailoring of reengineering methods for migrating legacy applications to cloud platforms. MLSAC achieves this by using a collection of coherent and empirically tested cloud-specific method fragments from the literature and practice. A metamodel (or meta-method) together with corresponding 
instantiation
 guidelines is developed from this collection. The metamodel can also be used to create and maintain bespoke reengineering methods in a given scenario of reengineering to cloud platforms.
Approach
MLSAC is underpinned by a metamodeling approach that acts as a representational layer to express reengineering methods. The design and evaluation of MLSAC are informed by the guidelines from the 
design science research
 approach.
Results
Our framework is an accessible guide of what legacy-to-cloud reengineering methods can look like. The efficacy of the framework is demonstrated by modeling real-world reengineering scenarios and obtaining user feedback. Our findings show that the framework provides a fully-fledged domain-specific, yet platform-independent, foundation for the semi-automated representing, maintaining, sharing, and tailoring reengineering methods. MLSAC contributes to the state of the art of 
cloud computing
 and model-driven 
software engineering
 literature through (a) providing a collection of mainstream method fragments for incorporate into various scenarios of reengineering processes and (b) enabling a basis for consistent creation, representation, and maintenance of reengineering methods and processes within the cloud computing community.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The development of MLSAC framework for migrating legacy applications to cloud platforms has a practical value for startups looking to modernize their software systems efficiently.
https://www.sciencedirect.com/science/article/pii/S0950584921002366,"Prioritizing user concerns in app reviews – A study of requests for new features, enhancements and bug fixes",Sherlock A.=Licorish: sherlock.licorish@otago.ac.nz; Bastin Tony Roy=Savarimuthu: tony.savarimuthu@otago.ac.nz,"Abstract
Context
: App developers spend exhaustive manual efforts towards the identification and prioritization of informative end-user reviews. Informative reviews are those that express end-users’ requests for new features, bug fixes and possible enhancements. 
Problem Statement
: While prior studies have proposed approaches to convert app reviews into 
actionable knowledge
, these are limited in utility due to being domain knowledge dependent or manually-based.
Objective
: In this study, in order to facilitate app maintenance and evolution cycles, we develop two novel automated prioritization techniques to rank informative reviews, and also compare their performances.
Method
: We developed the techniques comprising of entropy, frequency, TF-IDF and sentiment scoring methods using reviews from four popular apps comprising more than 1000 informative reviews in each app. Time and accuracy metrics were then used to measure the performance of our techniques. We performed evaluations where the ranking outcomes generated by our techniques were compared to those provided by regular app users and developers using two rounds of evaluations (internal and external evaluations).
Results
: Our results show that the time required for prioritization was in the range of 17–25 s and the accuracy of prioritization was in the range of 73–90%.
Conclusion
: These are promising outcomes when compared to prior work, where our outcomes were 4% and 185% better in terms of accuracy and time respectively. Thus, it is anticipated that our proposed techniques could support app developers in identifying and prioritizing informative reviews.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The automated prioritization techniques for app reviews can benefit startups in enhancing their app maintenance and evolution cycles, though the impact may be more limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921002354,Consistent or not? An investigation of using Pull Request Template in GitHub,Huaxiao=Liu: liuhuaxiao@jlu.edu.cn,"Abstract
Context:
The arbitrary usage of pull requests in GitHub may bring many issues such as incomplete, verbose, and duplicated descriptions, which hinder the development and maintenance of the project. Thus, GitHub proposed the Pull Request 
Template
 (PRT) in 2016 so that developers could edit the pull request in a relevant consistent manner. However, whether the PRT has been widely applied to GitHub and what impact it might bring remain little known. Such uninformed cases may affect the efficiency of cooperative development.
Objective:
In this work, we conduct an empirical study on large-scale repositories to explore whether the PRT has been widely applied and what impact it can bring to the GitHub community.
Method:
This work aims to answer four research questions. The first is a statistical experiment with the aim of analyzing the current status of PRTs. The second is an explored experiment, which aims at probing which repositories are suitable to adopt the PRT. The third is the measurement evaluation experiment, focusing on discussing what impact the PRT can bring. The last is an online survey to explain why few PRTs have been adopted. Notably, both the second and third questions are conducted a mixed quantitative and qualitative analysis.
Results and conclusion:
In this work, we find that only 1.2% of repositories contain the PRT in GitHub, and such repositories are mostly in high popularity and contain a large number of PRs. Besides, contributors are willing to accept the PRT that requires pivotal information, including description, test, and check_list. Meanwhile, the PRT can assist developers to manage repositories, reflecting in less time for reviewing, fewer duplicated pull requests, and almost non-existentially invalid comments. Finally, we survey 527 well-reputed developers to explain why few repositories adopt the PRT, and further provide some actionable suggestions.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The empirical study on GitHub PRT adoption provides insights that could be valuable for startups collaborating on GitHub, but the direct impact on early-stage ventures may not be as significant."
https://www.sciencedirect.com/science/article/pii/S0950584921002408,Indexing source code and clone detection,Zdenek=Tronicek: tronicek@tarleton.edu,"Abstract
Context:
Searching 
source code
 is a common task in code recommendation systems as well as in many other areas. Clone detection is used in software maintenance and bug detection.
Objective:
The paper introduces an algorithm for building the index structure of 
abstract syntax trees
. When the index structure is built, a pattern tree can be found in time linear in the length of the pattern. Furthermore, the paper describes 
DrDup2
 and 
DrDupLex
, two open-source tools that use the index structure to find Type-2 clones.
Method:
The index structure presented in this paper is based on the trie, which is a fundamental 
data structure
 in computer science. Evaluation of the presented clone detectors is done on BigCloneBench, which is a well-established benchmark for clone detection.
Results:
Comparison with three state-of-the-art clone detectors (
NiCad
, 
CloneWorks
 and 
SourcererCC
) shows that 
DrDup2
 and 
DrDupLex
 are able to beat them in precision, recall and running time.
Conclusion:
The presented index structure can be used for example to speed up searching for code fragments in code recommendation systems. It is also shown that it can be used to detect Type-2 clones with high precision and recall.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The algorithm for building the index structure of abstract syntax trees and the presented clone detectors are highly relevant for startups using code recommendation systems, offering practical solutions with superior performance."
https://www.sciencedirect.com/science/article/pii/S235267342400057X,Not all leavers are equal: How rank and destination influence enforcement of restrictive covenants,Sepideh=Yeganegi: syeganegi@wlu.ca; André O.=Laplume: alaplume@torontomu.ca; Bradley=Bernard: bradley.bernard@torontomu.ca,"Abstract
Restrictive covenants like non-competes, non-solicitations, and non-disclosures may pose barriers to spinout ventures and mobility to competitors. However, we know little about the enforceability of these agreements despite their widespread use and associated chilling effects. Examining 332 Canadian court decisions, we find a higher rate of enforcement in cases involving high rank leavers (i.e., managers and owners) versus low rank leavers (regular employees and contractors) especially those who form spinout ventures. Our key insight is that enforcement rates differ significantly across different types of leavers. Low rank leavers and their previous employers may overestimate the potential for enforcement, creating chilling effects (i.e., where employees think they are more restricted by their employment agreements than they really are) that can deter employee mobility and entrepreneurship.",June 2025,"Spinout ventures, Employee mobility, Employee spinouts, Employee entrepreneurship, Restrictive covenants, Non-competes",Business Venturing Insights,2025-03-21T00:00:00,8.0,"The study sheds light on the enforceability of restrictive covenants and their impact on employee mobility and entrepreneurship, offering valuable insights for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921002421,VUDENC: Vulnerability Detection with Deep Learning on a Natural Codebase for Python,Laura=Wartschinski: wartschinski@informatik.hu.berlin.de; Yannic=Noller: noller@informatik.hu.berlin.de; Thomas=Vogel: thomas.vogel@informatik.hu.berlin.de; Timo=Kehrer: kehrer@informatik.hu.berlin.de; Lars=Grunske: grunske@informatik.hu.berlin.de,"Abstract
Context:
Identifying potential vulnerable code is important to improve the security of our software systems. However, the manual detection of software vulnerabilities requires expert knowledge and is time-consuming, and must be supported by automated techniques.
Objective:
Such automated 
vulnerability detection
 techniques should achieve a high accuracy, point developers directly to the vulnerable code fragments, scale to real-world software, generalize across the boundaries of a specific software project, and require no or only moderate setup or configuration effort.
Method:
In this article, we present 
Vudenc
 (Vulnerability Detection with 
Deep Learning
 on a Natural Codebase), a deep learning-based 
vulnerability detection
 tool that automatically learns features of vulnerable code from a large and real-world Python codebase. 
Vudenc
 applies a word2vec model to identify semantically similar code tokens and to provide a vector representation. A network of long-short-term memory cells (LSTM) is then used to classify vulnerable code token sequences at a fine-grained level, highlight the specific areas in the source code that are likely to contain vulnerabilities, and provide confidence levels for its predictions.
Results:
To evaluate 
Vudenc
, we used 1,009 vulnerability-fixing commits from different GitHub repositories that contain seven different types of vulnerabilities (SQL injection, XSS, Command injection, XSRF, 
Remote code execution
, Path disclosure, Open redirect) for training. In the experimental evaluation, 
Vudenc
 achieves a recall of 78%–87%, a precision of 82%–96%, and an F1 score of 80%–90%. 
Vudenc
’s code, the datasets for the vulnerabilities, and the Python corpus for the word2vec model are available for reproduction.
Conclusions:
Our experimental results suggest that 
Vudenc
 is capable of outperforming most of its competitors in terms of vulnerably detection capabilities on real-world software. Comparable accuracy was only achieved on synthetic benchmarks, within single projects, or on a much coarser level of 
granularity
 such as entire 
source code files
.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The Vudenc tool for vulnerability detection with deep learning presents a high accuracy solution that can greatly benefit startups aiming to improve the security of their software systems efficiently.
https://www.sciencedirect.com/science/article/pii/S0950584921002081,iContractML 2.0: A domain-specific language for modeling and deploying smart contracts onto multiple blockchain platforms,Mohammad=Hamdaqa: mhamdaqa@polymtl.ca,"Abstract
Context:
Smart contracts
 play a vital role in many fields. Despite being called smart, the development of smart contracts is a tedious task beyond defining a set of 
contractual rules
. In addition to business knowledge, coding a smart contract requires strong 
technical knowledge
 in a multiplex of new and rapidly changing domain-specific languages and 
blockchain
 platforms.
Objectives:
The goal of this paper is to assist developers in 
building smart
 contracts independently from the language or the target 
blockchain
 platform. In which, we present our second-generation smart contract language iContractML 2.0.
Methods:
We follow a feature-oriented approach to analyze three different 
blockchain
 platforms and propose an enhanced reference model and a modeling framework for smart contracts (iContractML 2.0). Then, we evaluate the coverage and extensibility of iContractML 2.0, first through mapping the concepts of the reference models to the constructs within each of the platforms used in devising the reference model, and second through mapping its concepts to a new smart contract language not previously considered. Finally, we demonstrate the capabilities of iContractML 2.0 using five 
case studies
 from different business domains.
Results:
iContractML 2.0 extends our first generation language to support 
DAML
, which is another standardized language for smart contracts. This makes iContractML 2.0 supports the platforms that 
DAML
 support by extension. Moreover, iContractML 2.0 supports generating the structural and deployment artifacts in addition to the smart contract behavior by implementing templates for some of the common functions. The results of evaluating the generality of the iContractML 2.0 reference model show that it is 91.7% lucid and 72.2% laconic. Moreover, the reference model is able to capture all the elements of the new language with 83.3% of the components which have a direct one-to-one mapping.
Conclusion:
iContractML 2.0 is an extensible framework that empowers developers to model and generate functional smart contract code that can be deployed onto multiple 
blockchain
 platforms.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The development of a second-generation smart contract language that can be deployed onto multiple blockchain platforms has practical value for early-stage ventures and startups in the tech industry.
https://www.sciencedirect.com/science/article/pii/S095058492100241X,HyMap: Eliciting hypotheses in early-stage software startups using cognitive mapping,Jorge=Melegati: jorge.melegati@unibz.it; Eduardo=Guerra: eduardo.guerra@unibz.it; Xiaofeng=Wang: xiaofeng.wang@unibz.it,"Abstract
Context:
 Software startups develop innovative, software-intensive products. Given the uncertainty associated with such an innovative context, experimentation, an approach based on validating assumptions about the software product through data obtained from diverse techniques, like A/B tests or interviews, is valuable for these companies. Relying on data rather than opinions reduces the chance of developing unnecessary products or features, improving the likelihood of success, especially in early development stages, when implementing unnecessary features represents a higher risk for companies’ survival. Nevertheless, researchers have argued that the lack of clearly defined practices led to limited adoption of experimentation. Since the first step of the approach is to define hypotheses, testable statements about the software product features, based on which software development teams will create experiments, eliciting hypotheses is a natural first step to develop practices. 
Objective:
 We aim to develop a systematic technique for identifying hypotheses in early-stage software startups to support experimentation in these companies and, consequently, improve their software products. 
Methods:
 We followed a Design Science approach consisting of an artifact 
construction process
, divided in three phases, and an evaluation within three startups. 
Results:
 We developed the HyMap, a hypotheses 
elicitation
 technique based on 
cognitive mapping
. It consists of a process conducted by a facilitator using pre-defined questions, supported by a visual language to depict a cognitive map representing the founder’s understanding of the product. Our evaluation showed that founders perceived the artifacts as clear, easy to use, and useful leading to hypotheses and facilitating their idea’s visualization. 
Conclusion:
 From a theoretical perspective, our study provides a better understanding of the guidance founders use to develop their startups and, from a practical point of view, a technique to identify hypotheses in early-stage software startups.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The systematic technique for identifying hypotheses in early-stage software startups to support experimentation may provide valuable insights for startups looking to improve their software products.
https://www.sciencedirect.com/science/article/pii/S095058492100238X,Introduction to the Special Issue on value and waste in software engineering,,"Abstract
In the context of software engineering, “value” and “waste” can mean different things to different stakeholders. While traditionally value and waste have been considered from a business or economic point of view, there has been a trend in recent years towards a broader perspective that also includes wider human and societal values. This Special Issue explores value and waste aspects in all areas of software engineering, including identifying, quantifying, reasoning about, and representing value and waste, driving value and avoiding waste, and managing value and waste. In this editorial we provide an introduction to the topic and provide an overview of the contributions included in this Special Issue.",April 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the exploration of value and waste aspects in software engineering is valuable, the broader perspective discussed may have limited practical impact on early-stage ventures and startups in the tech industry."
https://www.sciencedirect.com/science/article/pii/S0950584921002263,When should we (not) use the mean magnitude of relative error (MMRE) as an error measure in software development effort estimation?,Magne=Jørgensen: magnej@simula.no; Torleif=Halkjelsvik: torleif@simula.no; Knut=Liestøl: knut@ifi.uio,"Abstract
Context
The mean magnitude of relative error (MMRE) is an error measure frequently used to evaluate and compare the estimation performance of prediction models and software professionals.
Objective
This paper examines conditions for proper use of MMRE in effort estimation contexts.
Method
We apply research on scoring functions to identify the type of estimates that minimizes the expected value of the MMRE.
Results
We show that the MMRE is a proper error measure for estimates of the most likely (mode) effort, but not for estimates of the median or mean effort, provided that the effort usage is approximately log-normally distributed, which we argue is a reasonable assumption in many software development contexts. The relevance of the findings is demonstrated on real-world software development data.
Conclusion
MMRE is not a proper measure of the accuracy of estimates of the median or mean effort, but may be used for the accuracy evaluation of estimates of most likely effort.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"The research on MMRE in effort estimation for software development may have some impact on the accuracy evaluation of certain types of effort estimates, but the practical value for startups is limited as it focuses on a specific error measure."
https://www.sciencedirect.com/science/article/pii/S0950584921001865,A comparison of machine learning algorithms on design smell detection using balanced and imbalanced dataset: A study of God class,Khalid=Alkharabsheh: khalidkh@bau.edu.jo; Sadi=Alawadi: sadi.alawadi@it.uu.se; Yania=Crespo: yania@infor.uva.es; Victor R.=Kebande: victor.kebande@bth.se; Manuel=Fernández-Delgado: manuel.fernandez.delgado@usc.es; José A.=Taboada: joseangel.taboada@usc.es,"Abstract
Context:
Design smell detection has proven to be a significant activity that has an aim of not only enhancing the software quality but also increasing its life cycle.
Objective:
This work investigates whether 
machine learning approaches
 can effectively be leveraged for 
software design
 smell detection. Additionally, this paper provides a comparatively study, focused on using balanced datasets, where it checks if avoiding dataset balancing can be of any influence on the accuracy and behavior during design smell detection.
Method:
A set of experiments have been conducted-using 28 
Machine Learning
 classifiers aimed at detecting God classes. This experiment was conducted using a dataset formed from 12,587 classes of 24 software systems, in which 1,958 classes were manually validated.
Results:
Ultimately, most classifiers obtained high performances,-with Cat Boost showing a higher performance. Also, it is evident from the experiments conducted that data balancing does not have any significant influence on the accuracy of detection. This reinforces the application of machine learning in real scenarios where the data is usually imbalanced by the inherent nature of design smells.
Conclusions:
Machine learning approaches can effectively be used as a leverage for God class detection. While in this paper we have employed SMOTE technique for data balancing, it is worth noting that there exist other methods of data balancing and with other design smells. Furthermore, it is also important to note that application of those other methods may improve the results, in our experiments SMOTE did not improve God class detection.
The results are not fully generalizable because only one design smell is studied with projects developed in a single programming language, and only one balancing technique is used to compare with the imbalanced case. But these results are promising for the application in real design smells detection scenarios as mentioned above and the focus on other measures, such as Kappa, ROC, and MCC, have been used in the assessment of the 
classifier behavior
.",March 2022,"Software quality, Design smell detection, Machine learning, God class, Balanced data",Information and Software Technology,2025-03-18T00:00:00,8.0,"The study on leveraging machine learning for software design smell detection, with practical experiments and results showing the effectiveness of certain classifiers, has high practical value for startup software development teams looking to enhance software quality."
https://www.sciencedirect.com/science/article/pii/S0950584921002056,An information theoretic notion of software testability,Krishna=Patel: krishna.patel@sheffield.ac.uk; Robert M.=Hierons: r.hierons@sheffield.ac.uk; David=Clark: david.clark@ucl.ac.uk,"Abstract
Context:
In software testing, Failed 
Error Propagation
 (FEP) is the situation in which a faulty program state occurs during the execution of the system under test (SUT) but this does not lead to incorrect output. It is known that FEP can adversely affect software testing and this has resulted in associated information 
theoretic measures
.
Objective:
To devise measures that can be used to assess the 
testability
 of the SUT. By testability, we mean how likely it is that a faulty program state, that occurs during testing, will lead to incorrect output. Previous work has considered a single program point rather than an entire program.
Method:
New, more fine-grained, measures were devised. Experiments were used to evaluate these and the previously defined measures (Squeeziness and Normalised Squeeziness). The experiments assessed how well these measures correlated with an estimate of the probability of FEP occurring during testing. Mutants were used to estimate this probability.
Results:
A strong rank correlation was found between several of the measures and the probability of FEP. Importantly, this included the Normalised Squeeziness of the whole SUT, which is simpler to compute, or estimate, than most of the other measures considered. Additional experiments found that the measures were relatively insensitive to the choice of mutants and also test suite.
Conclusion:
There is scope to use information 
theoretic measures
 to estimate how prone an SUT is to FEP. As a result, there is potential to use such measures to prioritise testing or estimate how much testing an SUT might require.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The investigation into measures for assessing testability in software testing, with experiments showing correlations and potential applications in prioritizing testing efforts, provides practical value for startups aiming to improve their software testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584921002068,Refactoring embedded software: A study in healthcare domain,Apostolos=Ampatzoglou: a.ampatzoglou@uom.edu.gr; Paraskevi=Smiari: psmiari@uowm.gr; Stamatia=Bibi: sbibi@uowm.gr; Elvira-Maria=Arvanitou: e.arvanitou@uom.edu.gr,"Abstract
Context
In 
embedded software
 industry, stakeholders usually promote run-time properties (e.g., performance, energy efficiency, etc.) as quality drivers, which in many cases leads to a compromise at the levels of design-time qualities (e.g., 
maintainability
, reusability, etc.). Such a compromise does not come without a cost; since embedded systems need heavy maintenance cycles. To assure effective bug-fixing, shorten the time required for releasing updates, a refactoring of the software codebase needs to take place regularly. Objective: This study aims to investigate how refactorings are applied in ES industry; and propose a systematic approach that can guide refactoring through a 3-step process for refactoring: (a) planning; (b) design; and (c) evaluation.
Method
The aforementioned goals were achieved by conducting a single case study in a company that develops medical applications for bio-impedance devices; and follows a rather systematic 
refactoring process
 in periodic timestamps. Three 
data collection approaches
 have been used: surveys, interviews (10 practitioners), and artifact analysis (51 refactoring activities).
Results
The results of the study suggest that: (a) 
maintainability
 and reusability are the design-time quality attributes that motivate the refactoring of Embedded Software (ES), with 30% of the participants considering them as of “Very High” importance; (b) the refactorings that are most frequently performed are “Extract Method”, “Replace Magic Number with Constant” and “Remove Parameter”. We note that the “Extract Method” refactoring has an applicability of more than over 80%; and (c) to evaluate the 
refactoring process
 engineers use tools producing structural metrics, internal standards, and reviews.
Conclusions
The outcomes of this study can be useful to both researchers and practitioners, in the sense that the former can focus their efforts on aspects that are meaningful to industry, whereas the latter are provided with a systematic refactoring process.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study on refactorings in the embedded software industry, proposing a systematic approach for refactoring with insights from a case study, offers practical guidance for startups in the industry on improving design-time qualities and ensuring effective bug-fixing processes."
https://www.sciencedirect.com/science/article/pii/S0950584921002251,"Relative estimates of software development effort: Are they more accurate or less time-consuming to produce than absolute estimates, and to what extent are they person-independent?",Magne=Jørgensen: magnej@simula.no,"Abstract
Context
Estimates of software development effort may be given as judgments of relationships between the use of efforts on different tasks-that is, as relative estimates. The use of relative estimates has increased with the introduction of story points in 
agile software development
 contexts.
Objective
This study examines to what extent relative estimates are likely to be more accurate or less time-consuming to produce than absolute software development effort estimates and to what extent relative estimates can be considered developer-independent.
Method
We conducted two experiments. In the first experiment, we collected estimates from 102 professional software developers estimating the same tasks and randomly allocated to providing relative estimates in story points or absolute estimates in work-hours. In the second experiment, we collected the actual efforts of 20 professional software developers completing the same 5 programming tasks and used these to analyze the variance in relative efforts.
Results
The results from the first experiment indicates that the relative estimates were less accurate than the absolute estimates, and that the time consumed completing the estimation work was higher for those using relative estimation, even when only considering developers with extensive 
prior experience
 in story point–based estimation for both tasks. The second experiment revealed that the relative effort was far from developer-independent, especially for the least productive developers. This suggests that relative estimates to a large extent are developer-dependent.
Conclusions
Although there may be good reasons for the continued use of relative estimates, we interpret our results as not supporting that the use of relative estimates is connected with higher estimation accuracy or less time consumed on producing the estimates. Neither do our results support a high degree of developer-independence in relative estimates.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"The study highlights the limitations of relative estimates in software development, which can be important for startups to consider when planning their projects."
https://www.sciencedirect.com/science/article/pii/S095058492100210X,Developers’ viewpoints to avoid bug-introducing changes,Jairo=Souza: jrmcs@ic.ufal.br,"Abstract
Context:
During software development, developers can make assumptions that guide their development practices to avoid bug-introducing changes. For instance, developers may consider that code with low test coverage is more likely to introduce bugs; and thus, focus their attention on that code to avoid bugs, neglecting other factors during the software development process. However, there is no knowledge about the relevance of these assumptions for developers.
Objective:
This study investigates the developers’ viewpoints on the relevance of certain assumptions to avoid bug-introducing changes. In particular, we analyze which assumptions developers can make during software development; how relevant these assumptions are for developers; the common viewpoints among developers regarding these assumptions; and the main reasons for developers to put more/less relevance for some assumptions.
Method:
We applied the Q-methodology, a mixed-method from the psychometric spectrum, to investigate the relevance of assumptions and extract the developers’ viewpoints systematically. We involved 41 developers analyzing 41 assumptions extracted from literature and personal interviews.
Results:
We identified five viewpoints among developers regarding their assumptions around bug-introducing changes. Despite the differences among the viewpoints, there is also consensus, for example, regarding the importance of being aware of changes invoking high number of features. Moreover, developers rely on personal and technical reasons to put relevance on some assumptions.
Conclusion:
These findings are valuable knowledge for practitioners and researchers towards future research directions and development practices improvements.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The findings provide valuable insights for developers on assumptions to avoid bug-introducing changes, which can have practical implications for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492100207X,Summarizing source code with hierarchical code representation,Ziyi=Zhou: zhouziyi@mail.ecust.edu.cn; Huiqun=Yu: yhq@ecust.edu.cn,"Abstract
Context
Code summarization aims to automatically generate natural language descriptions for code, and has become a rapidly expanding research area. Data-driven code summarization models based on 
neural networks
 have proliferated in recent few years.
Objective
Almost all of existing 
neural models
 are built upon the 
granularity
 of token or 
AST
 node. This has several drawbacks: a) Code summarization requires high-level knowledge of code while token representations are limited to provide a global view; b) Such approaches can hardly model the hierarchy of code; c) Long input codes challenge such models to handle long-range dependencies due to the large number of tokens and 
AST
 nodes.
Method
To address these issues, we propose a novel framework to utilize hierarchical representation of code to generate better summaries. We consider two levels of code hierarchy: token-level and statement-level. Our framework contains a pair of customized encoder-decoder models for tokens and AST of code respectively. Each of them has a hierarchical encoder that aims to extract both token and statement-level code features, and an attentional decoder with the ability to attend to those different levels of representation during decoding. They are then combined to predict summaries via 
ensemble learning
.
Results
We conduct extensive experiments to evaluate our models on a large Java corpus. The experimental results show that our approach outperforms several state-of-the-art baselines by a substantial margin.
Conclusion
In conclusion, our approach could better learn global information of code and shift attention between important statements during summary generation. With the help of hierarchical attention, the models are able to locate keywords more accurately in a top-down way. Ensemble learning is also proved to be an effective way to benefit from multiple input sources.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed framework shows significant improvements in code summarization, which can greatly benefit startups in improving their code documentation and understanding."
https://www.sciencedirect.com/science/article/pii/S0950584921002275,Task assignment to counter the effect of developer turnover in software maintenance: A knowledge diffusion model,Omid=Bushehrian: bushehrian@sutech.ac.ir,"Abstract
Context:
Developer churn is the overall turnover in a software organization’s staff. Existing developers leave and new ones join the project. Retaining the knowledge of the software 
source code
 among the development team in such scenarios is an essential factor to keep the software maintenance cost as low as possible. 
Knowledge diffusion
 is an activity that could mitigate the 
negative impact
 of developer churn, while a task assignment strategy could pay an important role to attain good knowledge diffusion among the team members and effectively lower the likelihood of knowledge loss.
Objective:
In this work, a self-adaptive task assignment (SATA) approach is proposed that adaptively switches between cost-oriented and diffusion-oriented strategies over subsequent rounds of task assignments.
Method:
An entropy-based model is applied to estimate the current conditions of the development team from the knowledge concentration perspective. This model is assisted by a learning 
automata
 and 
evolutionary algorithms
 to offer smart assignments.
Results:
The experimental results show that, particularly in teams with medium churn rates, applying an entropy-aware task assignment model can reduce the total maintenance cost up to slightly over 50%, provided that the knowledge demands in the team over successive rounds of task assignment remain stationary. There are also improvements in terms of the projects’ 
bus factor
 which prevent the project to lose its key knowledge. Even for projects where there is no saving in maintenance costs, SATA results in knowledge being more distributed among the developers, resulting in a more resilient project.
Conclusion:
SATA improves the long-term 
sustainability
 of development teams with developer turnover. Projects and their managers can hence rely on it when there is the risk of knowledge loss due to developer turnover.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The self-adaptive task assignment approach can help reduce maintenance costs and improve knowledge diffusion in development teams, which is crucial for startups with limited resources."
https://www.sciencedirect.com/science/article/pii/S0950584921002135,Automated data function extraction from textual requirements by leveraging semi-supervised CRF and language model,Lin=Shi: shilin@iscas.ac.cn,"Abstract
Context:
Function Point Analysis (FPA) provides an objective, comparative measure for size estimation in the early stage of software development. When practicing FPA, analysts typically abide by the following steps: data function (DF) extraction, transactional function extraction, function type classification and adjustment factor determination. However, due to lack of approach and tool support, these steps are usually conduct by human efforts in practice. Related approaches can hardly be applied in the FPA due to the following three challenges, i.e., FPA rule-driven extraction, domain-specific 
parsing
, and expensive labeled resources.
Objective:
In this paper, we aim to automate the extraction of DFs, which is the starting and fundamental step in FPA.
Method:
We propose an automated approach named DEX to extract data functions from textual requirements. Specifically, DEX introduces the popularly-used 
conditional random field
 (CRF) model to predict the boundary of a data function. Besides, DEX employs the bootstrapping-based algorithm and DF-oriented 
language model
 to further boost the performance.
Results:
We evaluate DEX from two aspects: evaluation on a real industrial dataset and a manual review by domain experts. The evaluation on the real industrial dataset shows that DEX could achieve 80% precision, 84% recall, and 82% F1, and outperforms three state-of-the-art baselines. The expert review suggests that DEX could increase 16% precision and 13% recall, compared with those produced by engineers.
Conclusion:
DEX could achieve promising results under a small number of labeled requirements and outperform the state-of-the-art approaches. Moreover, DEX could help engineers produce more accurate and complete DFs in the industrial environment.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The automated approach for data function extraction in FPA could streamline the size estimation process in software development, providing efficiency benefits for startups."
https://www.sciencedirect.com/science/article/pii/S0950584921002044,Layout merging with relative positioning in Concern-Oriented Reuse hierarchies,Hyacinth=Ali: hyacinth.ali@mail.mcgill.ca; Gunter=Mussbacher: gunter.mussbacher@mcgill.ca,"Abstract
Context:
The advent of modeling in 
software engineering
, like other engineering fields, has revolutionized the formalism and pace of software development. However, 
software applications
 are not built from scratch, instead, other existing software artifacts are reused and combined with new artifacts. This notion of 
software reuse
 has been in existence for decades. When structural models such as 
class diagrams
 are reused, the reusing and reused models often need to be merged and the result visualized to the modeler. However, layout mechanisms such as GraphViz, JGraphX, and other related layout tools do not retain the original layout and rather arbitrarily layout the merged models. Therefore, important information that corresponds to the mental map of a modeler and is conveyed by the specific layout is currently lost.
Objective:
This paper aims to establish layout algorithms to retain the original layout information from a set of individual but interrelated models after they are merged during 
software reuse
 to preserve a modeler’s mental map of the models.
Method:
In this work, rpGraph uses the 
relative positioning
 of model elements to retain the general layout of a single reusing model and a single reused model (two-model merge). Additionally, rpGraph integrates its two-model merge approach into a multi-model merge in a reuse hierarchy to preserve the general topology of several interrelated models. Our findings are evaluated with 20 example single-model reuses from a library of reusable software model artifacts. We further carry out a 
case study
 in a reuse hierarchy framework, Concern Oriented Reuse (CORE), where rpGraph is applied to the layout of reusable artifacts, which result from a merge of several individual models.
Result:
A comparison of the merged layouts of rpGraph, GraphViz, and JGraphX shows that rpGraph performs better in terms of retaining the original layouts.
Conclusion:
Considering 
relative positioning
 during model merge increases the degree with which original layouts can be preserved.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The research addresses a practical issue in software engineering by improving model layout algorithms for software reuse, which can benefit early-stage ventures by increasing efficiency and accuracy in software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584921002093,Facilitating the co-evolution of semantic descriptions in standards and models,Philip=Makedonski: makedonski@cs.uni-goettingen.de; Jens=Grabowski: grabowski@cs.uni-goettingen.de,"Abstract
Context:
Standardised specifications for sophisticated technologies are subdivided in multiple documents maintained by different working groups, typically accompanied by models and other formalised artefacts. As the specifications and the models evolve, ensuring their consistency at scale becomes challenging.
Objective:
While previous work developed a methodology for facilitating the co-evolution of models and standards, based on the Network Function 
Virtualisation
 (NFV) Information Model (IM) and models extracted from the related standardised specifications, the methodology focused on structural aspects only. This article refines the methodology, enabling the alignment of 
semantic descriptions
 of 
information elements
 and attributes, both across specifications and across 
information elements
.
Method:
To enable the alignment of 
semantic descriptions
, we extend the methodology by using statistical and visual analyses of terms used in the specifications. The underlying meta-model for the information extracted from the specifications is extended to accommodate the capturing of additional semantic information.
Results:
We report on our experiences with the application of a prototypical implementation of the methodology during the continued alignment and maintenance of the IM and the related standardised specifications. More than 400 potential inconsistencies were identified, leading to more than 100 contributions, some of which addressed multiple findings. Feedback from the working group provided insights on how to refine the methodology further.
Conclusions:
Models shall play a more central role and be better integrated throughout the specification development and implementation processes, helping to ensure and maintain consistency among specifications. Our experiences may provide useful insights into ongoing and future initiatives where similar challenges are faced.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The refinement of the methodology for aligning semantic descriptions in model-based specifications can provide valuable insights for early-stage ventures involved in developing sophisticated technologies, enhancing consistency and efficiency in their processes."
https://www.sciencedirect.com/science/article/pii/S0950584921002305,Programming language implementations for context-oriented self-adaptive systems,Nicolás=Cardozo: n.cardozo@uniandes.edu.co; Kim=Mens: kim.mens@uclouvain.be,"Abstract
Context
The context-oriented programming paradigm is designed to enable self-adaptation, or dynamic behavior modification of software systems, in response to changes in their surrounding environment. Contextoriented programming offers an adaptation model, from a programming language perspective, that maintains a clean modularisation between the application and adaptation logic, as well as between the components providing adaptations.
Objective
We use three implementation techniques for context-oriented programming languages to assess their appropriateness to foster self-adaptive systems. These approaches take advantage of the capabilities offered by the host programming language to realize self-adaptation as proposed by context-oriented languages.
Method
We evaluate each of these approaches by assessing their modularity and complexity when defining adaptations, and by comparing their run-time performance on a simple benchmark.
Results
Our results show a higher modularity than that for common architecture based self-adaptive systems, while maintaining comparable performance.
Conclusion
We conclude that context-oriented programming is an appropriate paradigm to realize self-adaptation.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the research on context-oriented programming is relevant for enabling self-adaptive systems, the direct practical impact on European early-stage ventures may be limited compared to other abstracts focusing on software development efficiency and consistency."
https://www.sciencedirect.com/science/article/pii/S0950584921002329,An onboarding model for integrating newcomers into agile project teams,Helen=Sharp: helen.sharp@open.ac.uk; Peggy=Gregory: ajgregory@uclan.ac.uk; Diane E.=Strode: diane.strode@whitireia.ac.nz; Leonor=Barroca: leonor.barroca@open.ac.uk,"Abstract
Context
A stable team is deemed optimal for 
agile software development
 project success; however, all teams change membership over time. Newcomers joining an agile project team must rapidly assimilate into the organisational and project environment. They must do this while learning how to contribute effectively and without seriously interrupting project progress.
Objective
This paper addresses how newcomers integrate into an established agile project team and how agile practices assist with onboarding.
Method
A single, qualitative 
case study
 approach was used, investigating a co-located agile project team in a large IT department who regularly onboard inexperienced newcomers. Analysis was abductive, consisting of inductive coding and theming using categories from an existing onboarding theory.
Results
We describe the team's onboarding practices and adjustments and present an agile onboarding model that encompasses onboarding activities, individual adjustments, and workplace adjustments.
Conclusions
A mixture of general and specific agile onboarding practices contribute to successful onboarding in an agile team. We provide 
practical guidelines
 to improve onboarding practice in agile teams. Our major new contribution is an extended model of onboarding for agile teams.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on agile onboarding in software development teams provides practical guidelines for integrating newcomers, which can be beneficial for early-stage ventures looking to maintain team stability and project progress, although the direct impact on software development processes may not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921001956,SHSE: A subspace hybrid sampling ensemble method for software defect number prediction,Shihai=Wang: wangshihai@buaa.edu.cn,"Abstract
Context:
Software defect
 number prediction (SDNP) helps allocate limited testing resources by ranking software modules according to the predicted defect numbers. However, the highly skewed distribution of defects greatly degrades the performance of SDNP models by preventing SDNP models from ranking software modules accurately.
Objective:
This paper introduces a novel subspace 
hybrid sampling
 ensemble (SHSE) method based on feature subspace construction, 
hybrid sampling
, and 
ensemble learning
 for building high-performance SDNP models.
Method:
Specifically, we first construct a series of feature subspace to ensure the diversity of 
base
 learners. In each of feature subspace, we then use the proposed hybrid sampling method to balance the training subset without losing too much information and introducing lots of noisy data caused by only using undersampling or oversampling techniques. Finally, we train each 
base
 learner and combine them by using the proposed weighted ensemble strategy. Experiments are performed on 27 public defect datasets. We compare SHSE with five state-of-the-art resampling-based models and four zero-inflated/hurdle models in terms of the ranking 
performance measure
 fault-percentile-average (FPA). To demonstrate the effectiveness of SHSE, two statistical 
testing methods
 including Wilcoxon Signed-rank test and Scott–Knott 
Effect Size
 Difference test are utilized. Cliff’s 
δ
 is also computed for quantifying the difference when there is significant difference between SHSE and each baseline.
Results:
The experimental results show that SHSE significantly outperforms the baselines and improves the performance over each baseline with as least medium effect size on most datasets. On average, SHSE improves the performance over the resampling-based methods by 8.7%
∼
14.4% and the zero-inflate/hurdle models by 10.3%
∼
15.2%.
Conclusion:
It can be concluded that SHSE is a more promising alternative for software defect number prediction.",February 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The novel SHSE method for software defect number prediction presents a promising alternative with significant improvements over baselines, making it highly valuable for early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584921001889,Does it matter who pays back Technical Debt? An empirical study of self-fixed TD,Paris=Avgeriou: p.avgeriou@rug.nl; Jie=Tan: j.tan@rug.nl; Daniel=Feitosa: d.feitosa@rug.nl,"Abstract
Context:
Technical Debt (TD) can be paid back either by those that incurred it or by others. We call the former self-fixed TD, and it can be particularly effective, as developers are experts in their own code and are well-suited to fix the corresponding TD issues.
Objective:
The goal of our study is to investigate self-fixed technical debt, especially the extent in which TD is self-fixed, which types of TD are more likely to be self-fixed, whether the remediation time of self-fixed TD is shorter than non-self-fixed TD and how development behaviors are related to self-fixed TD.
Method:
We report on an empirical study that analyzes the self-fixed issues of five types of TD (i.e., Code, Defect, Design, Documentation and Test), captured via 
static analysis
, in more than 44,000 commits obtained from 20 Python and 16 Java projects of the Apache Software Foundation.
Results:
The results show that about half of the fixed issues are self-fixed and that the likelihood of contained TD issues being self-fixed is negatively correlated with project size, the number of developers and total issues. Moreover, there is no significant difference of the survival time between self-fixed and non-self-fixed issues. Furthermore, developers are more keen to pay back their own TD when it is related to lower code level issues, e.g., Defect Debt and Code Debt. Finally, developers who are more dedicated to or knowledgeable about the project contribute to a higher chance of self-fixing TD.
Conclusions:
These results can benefit both researchers and practitioners by aiding the prioritization of TD remediation activities and refining strategies within development teams, and by informing the development of TD 
management tools
.",March 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The findings on self-fixed technical debt can benefit both researchers and practitioners by aiding the prioritization of TD remediation activities, which is crucial for startups in early stages."
https://www.sciencedirect.com/science/article/pii/S095058492100183X,A mapping study on documentation in Continuous Software Development,Theo=Theunissen: theo.theunissen@gmail.com,"Abstract
Context:
With an increase in Agile, Lean, and 
DevOps
 software methodologies over the last years (collectively referred to as Continuous Software Development (CSD)), we have observed that documentation is often poor.
Objective:
This work aims at collecting studies on documentation challenges, documentation practices, and tools that can support documentation in CSD.
Method:
A 
systematic mapping study
 was conducted to identify and analyze research on documentation in CSD, covering publications between 2001 and 2019.
Results:
A total of 63 studies were selected. We found 40 studies related to documentation practices and challenges, and 23 studies related to tools used in CSD. The challenges include: informal documentation is hard to understand, documentation is considered as waste, productivity is measured by working software only, documentation is out-of-sync with the software and there is a short-term focus. The practices include: non-written and informal communication, the usage of development artifacts for documentation, and the use of architecture frameworks. We also made an inventory of numerous tools that can be used for documentation purposes in CSD. Overall, we recommend the usage of executable documentation, modern tools and technologies to retrieve information and transform it into documentation, and the practice of minimal documentation upfront combined with detailed design for knowledge transfer afterwards.
Conclusion:
It is of 
paramount importance
 to increase the quantity and quality of documentation in CSD. While this remains challenging, practitioners will benefit from applying the identified practices and tools in order to mitigate the stated challenges.",February 2022,"Systematic mapping studies, Systematic reviews, Continuous Software Development, Lean, Agile, DevOps, Documentation",Information and Software Technology,2025-03-18T00:00:00,6.0,"While documentation in CSD may not directly impact startups, the usage of modern tools and technologies recommended in this study could be beneficial for early-stage ventures looking to scale."
https://www.sciencedirect.com/science/article/pii/S0950584921001932,Patchworking: Exploring the code changes induced by vulnerability fixing activities,Matias=Martinez: matias.martinez@uphf.fr; Gerardo=Canfora: canfora@unisannio.it; Andrea=Di Sorbo: disorbo@unisannio.it; Sara=Forootani: forootani@unisannio.it; Corrado A.=Visaggio: visaggio@unisannio.it,"Abstract
Context:
Identifying and repairing vulnerable code is a critical software maintenance task. Change impact analysis plays an important role during software maintenance, as it helps software maintainers to figure out the potential effects of a change before it is applied. However, while the 
software engineering
 community has extensively studied techniques and tools for performing impact analysis of change requests, there are no approaches for estimating the impact when the change involves the resolution of a vulnerability bug.
Objective:
We hypothesize that similar vulnerabilities may present similar strategies for patching. More specifically, our work aims at understanding whether the class of the vulnerability to fix may determine the type of impact on the system to repair.
Method:
To verify our conjecture, in this paper, we examine 524 security patches applied to vulnerabilities belonging to ten different weakness categories and extracted from 98 different open-source projects written in Java.
Results:
We obtain empirical evidence that vulnerabilities of the same types are often resolved by applying similar code transformations, and, thus, produce almost the same impact on the codebase.
Conclusion:
On the one hand, our findings open the way to better management of software maintenance activities when dealing with software vulnerabilities. Indeed, vulnerability class information could be exploited to better predict how much code will be affected by the fixing, how the 
structural properties
 of the code (i.e., complexity, coupling, cohesion, size) will change, and the effort required for the fix. On the other hand, our results can be leveraged for improving automated strategies supporting developers when they have to deal with security flaws.",February 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Understanding the impact of vulnerability fixes can significantly improve software maintenance activities, which is crucial for startups looking to secure their systems and products."
https://www.sciencedirect.com/science/article/pii/S0950584921001920,The impact of the distance metric and measure on SMOTE-based techniques in software defect prediction,Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Yan=Xiao: dcsxan@nus.edu.sg; Shuo=Feng: shuo.feng@hotmail.com; Peichang=Zhang: pzhang@szu.edu.cn; Miao=Zhang: miazhang9-c@my.cityu.edu.hk,"Abstract
Context:
In software 
defect prediction
, SMOTE-based techniques are widely adopted to alleviate the 
class imbalance problem
. SMOTE-based techniques select instances close in the distance to synthesize minority class instances, ensuring few noise instances are generated.
Objective:
However, recent studies show that selecting instances far away effectively increases the diversity and alleviates the overgeneralization brought by SMOTE-based techniques. To investigate the relationship between the distance of the selected instances and the performances of SMOTE-based techniques, we carry out this study.
Method:
We first conduct experiments to empirically investigate the impact of the distance between the instances on the performances of three common SMOTE-based techniques. Based on the experimental result, we improve a recently proposed oversampling technique-SMOTUNED.
Results:
The experimental results on five common classifiers across 30 imbalanced datasets from the PROMISE repository show that (1) the selection of the distance metric has little impact on the performances of SMOTE-based techniques, (2) as long as the number of synthesized noise instances is not beyond the noise-resistant ability of classifiers, the overall performances measured by AUC and 
b
a
l
a
n
c
e
 of SMOTE-based techniques are not significantly affected by the distance between instances, and (3) the 
probability of detection
 (
p
d
) and the 
probability of false alarm
 (
p
f
) values of SMOTE-based techniques are significantly affected by the distance between the selected instances. The larger the distance between the selected instances is, the lower the 
p
d
 and 
p
f
 values SMOTE-based techniques obtain. The performance of the improved SMOTUNED is similar to that of the original SMOTUNED, but the improved SMOTUNED dramatically decreases the 
execution time
 of the original SMOTUNED.
Conclusion:
By controlling the distance, different 
p
d
 and 
p
f
 values can be obtained. The diversity of SMOTE-based techniques can be improved, and the overgeneralization can be avoided.",February 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"While the study provides insights into improving SMOTE-based techniques, the impact on European early-stage ventures may be limited as it focuses more on technical aspects rather than practical application in startups."
https://www.sciencedirect.com/science/article/pii/S0950584921002032,Early prediction for merged vs abandoned code changes in modern code reviews,Gias=Uddin: gias.uddin@ucalgary.ca,"Abstract
Context:
The modern 
code review process
 is an integral part of the current software development practice. Considerable effort is given here to inspect code changes, find defects, suggest an improvement, and address the suggestions of the reviewers. In a 
code review process
, several iterations usually take place where an author 
submits
 code changes and a reviewer gives feedback until is happy to accept the change. In around 12% cases, the changes are abandoned, eventually wasting all the efforts.
Objective:
In this research, our objective is to design a tool that can predict whether a code change would be merged or abandoned at an early stage to reduce the waste of efforts of all stakeholders (e.g., program author, reviewer, project management, etc.) involved. The real-world demand for such a tool was formally identified by a study by Fan et al. (2018).
Method:
We have mined 146,612 code changes from the code reviews of three large and popular open-source software and trained and tested a suite of supervised 
machine learning
 classifiers, both shallow and deep learning-based. We consider a total of 25 features in each code change during the training and testing of the models. The features are divided into five dimensions: reviewer, author, project, text, and code.
Results:
The best performing model named PredCR (Predicting Code Review), a LightGBM-based classifier achieves around 85% AUC score on average and relatively improves the state-of-the-art (Fan et al., 2018) by 14%–23%. In our extensive empirical study involving PredCR on the 146,612 code changes from the three software projects, we find that (1) The new features like reviewer dimensions that are introduced in PredCR are the most informative. (2) Compared to the baseline, PredCR is more effective towards reducing bias against new developers. (3) PredCR uses 
historical data
 in the code review repository and as such the performance of PredCR improves as a software system evolves with new and more data.
Conclusion:
PredCR can help save time and effort by helping developers/code reviewers to prioritize the code changes that they are asked to review. Project management can use PredCR to determine how code changes can be assigned to the code reviewers (e.g., select code changes that are more likely to be merged for review before the changes that might be abandoned).",February 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The development of PredCR for predicting code changes in code reviews can save time and effort for developers and project management, providing practical value for European early-stage ventures, especially startups."
https://www.sciencedirect.com/science/article/pii/S0950584921001907,The use of incentives to promote technical debt management,Terese=Besker: Terese.Besker@ri.se; Antonio=Martini: antonima@ifi.uio.no; Jan=Bosch: Jan.Bosch@chalmers.se,"Abstract
Context
When developing software, it is vitally important to keep the level of technical debt down since, based on several studies, it has been well established that technical debt can lower the development productivity, decrease the developers' morale and 
compromise
 the overall quality of the software, among others. However, even if researchers and practitioners working in today's software development industry are quite familiar with the concept of technical debt and its related negative consequences, there has been no empirical research focusing specifically on how software managers actively communicate and manage the need to keep the level of technical debt as low as possible.
Objective
This study aims to understand how software companies give incentives to manage technical debt. This is carried out by exploring how companies encourage and reward practitioners for actively keeping the level of technical debt down add whether the companies use any 
forcing
 or 
penalising
 initiatives when managing technical debt.
Method
As a first step, this paper reports the results of both an online survey providing quantitative data from 258 participants and interviews with 32 software practitioners. As a second step, this study sets out to specifically provide a detailed assessment of additional and in-depth analysis of technical debt management strategies based on an encouraging mindset and attitude from both managers and technical roles to understand 
how, when and by whom
 such strategies are adopted in practice.
Results
Our findings show that having a technical debt management strategy (specially based on encouragement) can significantly impact the amount of technical debt related to the software.
Conclusion
The result indicates that there is considerable unfulfilled potential to influence how software practitioners can further limit and reduce technical debt by adopting a strategy based explicitly on an encouraging mindset from managers where they also specifically dedicate time and resources for technical debt remediation activities.",February 2022,"Technical debt, Software development, Software incentive programs, Empirical study",Information and Software Technology,2025-03-18T00:00:00,6.0,"While the study on managing technical debt provides valuable insights, the focus on software companies may limit its direct impact on European early-stage ventures. However, the encouraging mindset strategy could be beneficial for startups."
https://www.sciencedirect.com/science/article/pii/S0950584921001877,Towards a taxonomy of code review smells,Emre=Doğan: emredogan7@outlook.com,"Abstract
Context:
Code review is a crucial step of the 
software development life cycle
 in order to detect possible problems in 
source code
 before merging the changeset to the codebase. Although there is no consensus on a formally defined life cycle of the 
code review process
, many companies and 
open source software
 (OSS) communities converge on common rules and best practices. In spite of minor differences in different platforms, the primary purpose of all these rules and practices leads to a faster and more effective 
code review process
. Non-conformance of developers to this process does not only reduce the advantages of the code review but can also introduce waste in later stages of the software development.
Objectives:
The aim of this study is to provide an empirical understanding of the bad practices followed in the code review process, that are 
code review (CR) smells
.
Methods:
We first conduct a multivocal literature review in order to gather code review bad practices discussed in white and gray literature. Then, we conduct a targeted survey with 32 experienced software practitioners and perform follow-up interviews in order to get their expert opinion. Based on this process, a taxonomy of code review smells is introduced. To quantitatively demonstrate the existence of these smells, we analyze 226,292 code reviews collected from eight 
OSS projects
.
Results:
We observe that a considerable number of code review smells exist in all projects with varying degrees of ratios. The empirical results illustrate that 72.2% of the code reviews among eight projects are affected by at least one code review smell.
Conclusion:
The empirical analysis shows that the 
OSS projects
 are substantially affected by the code review smells. The provided taxonomy could provide a foundation for best practices and tool support to detect and avoid code review smells in practice.",February 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study focuses on identifying bad practices in the code review process, which can help startups improve their code quality and development efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584921001816,An approach to explore sequential interactions in cognitive activities of software engineering,Luciana=Zaina: lzaina@ufscar.br; Joelma=Choma: jh.choma@hotmail.com; Eduardo M.=Guerra: guerraem@gmail.com; Tiago S.=da Silva: silvadasilva@unifesp.br,"Abstract
Context
: The study of cognitive aspects around software activities can provide valuable insights to improve 
software engineering
 practices. Objective: This paper presents an approach based on distributed cognition and sequential analysis to explore cognitive activities in the software development context by analyzing the interactions between software practitioners and the resources used to support them. Method: We conducted nine laboratory-based observation sessions to record qualitative audio/video data of interactions between the study participants and at-hand resources during the planning and managing of 
software analytics
 tasks. Results: The interaction strategies of the resources model included 21 emergent actions, and the sequential analysis revealed two different patterns of interaction over time. Conclusion: Our approach has been useful for evaluating how well an artifact works to support a team in 
software analytics
 activities. Furthermore, it can be applied to explore and discover interaction patterns in different software activities.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on cognitive aspects around software activities provides valuable insights, but may have limited immediate practical application for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921001257,Investigation on the stability of SMOTE-based oversampling techniques in software defect prediction,Xiao=Yu: xiaoyu@whut.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Yan=Xiao: dcsxan@nus.edu.sg; Shuo=Feng: shuofeng5-c@my.cityu.edu.hk; Miao=Zhang: miazhang9-c@my.cityu.edu.hk,"Abstract
Context:
In practice, software datasets tend to have more non-defective instances than defective ones, which is referred to as the 
class imbalance problem
 in 
software defect
 prediction (SDP). Synthetic Minority Oversampling TEchnique (SMOTE) and its variants alleviate the 
class imbalance problem
 by generating synthetic defective instances. SMOTE-based oversampling techniques were widely adopted as the baselines to compare with the newly proposed oversampling techniques in SDP. However, randomness is introduced during the procedure of SMOTE-based oversampling techniques. If the performance of SMOTE-based oversampling techniques is highly unstable, the conclusion drawn from the comparison between SMOTE-based oversampling techniques and the newly proposed techniques may be misleading and less convincing.
Objective:
This paper aims to investigate the stability of SMOTE-based oversampling techniques. Moreover, a series of stable SMOTE-based oversampling techniques are proposed to improve the stability of SMOTE-based oversampling techniques.
Method:
Stable SMOTE-based oversampling techniques reduce the randomness in each step of SMOTE-based oversampling techniques by selecting defective instances in turn, distance-based selection of 
K
 neighbor instances, and evenly distributed interpolation. Besides, we mathematically prove and also empirically investigate the stability of SMOTE-based and stable SMOTE-based oversampling techniques on four common classifiers across 26 datasets in terms of AUC, 
b
a
l
a
n
c
e
, and 
MCC
.
Results:
The analysis of SMOTE-based and stable SMOTE-based oversampling techniques shows that the performance of stable SMOTE-based oversampling techniques is more stable and better than that of SMOTE-based oversampling techniques. The difference between the worst and best performances of SMOTE-based oversampling techniques is up to 23.3%, 32.6%, and 204.2% in terms of AUC, 
b
a
l
a
n
c
e
, and 
MCC
, respectively.
Conclusion:
Stable SMOTE-based oversampling techniques should be considered as a drop-in replacement for SMOTE-based oversampling techniques.",November 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The investigation of stable SMOTE-based oversampling techniques in software defect prediction can have a significant impact on improving the stability of predictive models and the overall quality of software systems.
https://www.sciencedirect.com/science/article/pii/S0950584921001543,Challenges and solutions when adopting DevSecOps: A systematic review,Roshan N.=Rajapakse: roshan.rajapakse@adelaide.edu.au; Mansooreh=Zahedi: mansooreh.zahedi@adelaide.edu.au; M. Ali=Babar: ali.babar@adelaide.edu.au; Haifeng=Shen: Haifeng.Shen@acu.edu.au,"Abstract
Context:
DevOps (Development and Operations) has become one of the fastest-growing software development paradigms in the industry. However, this trend has presented the challenge of ensuring secure software delivery while maintaining the agility of DevOps. The efforts to integrate security in DevOps have resulted in the DevSecOps paradigm, which is gaining significant interest from both industry and academia. However, the adoption of DevSecOps in practice is proving to be a challenge.
Objective:
This study aims to systemize the knowledge about the challenges faced by practitioners when adopting DevSecOps and the proposed solutions reported in the literature. We also aim to identify the areas that need further research in the future.
Method:
We conducted a Systematic Literature Review of 54 peer-reviewed studies. The thematic analysis method was applied to analyze the extracted data.
Results:
We identified 21 challenges related to adopting DevSecOps, 31 specific solutions, and the mapping between these findings. We also determined key gap areas in this domain by holistically evaluating the available solutions against the challenges. The results of the study were classified into four themes: People, Practices, Tools, and Infrastructure. Our findings demonstrate that tool-related challenges and solutions were the most frequently reported, driven by the need for automation in this paradigm. Shift-left security and continuous security assessment were two key practices recommended for DevSecOps. People-related factors were considered critical for successful DevSecOps adoption but less studied.
Conclusions:
We highlight the need for developer-centered application security testing tools that target the continuous practices in DevSecOps. More research is needed on how the traditionally manual security practices can be automated to suit rapid software deployment cycles. Finally, achieving a suitable balance between the speed of delivery and security is a significant issue practitioners face in the DevSecOps paradigm.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The study on adopting DevSecOps addresses a critical issue in software development, offering practical solutions and recommendations that can benefit startups in ensuring secure software delivery."
https://www.sciencedirect.com/science/article/pii/S0950584921001580,Relationships between software architecture and source code in practice: An exploratory survey and interview,Peng=Liang: liangp@whu.edu.cn; M. Ali=Babar: ali.babar@adelaide.edu.au; Fangchao=Tian: tianfangchao@whu.edu.cn,"Abstract
Context
Software Architecture (SA) and Source Code (SC) are two intertwined artefacts that represent the interdependent design decisions made at different levels of abstractions - High-Level (HL) and Low-Level (LL). An understanding of the relationships between SA and SC is expected to bridge the gap between SA and SC for supporting maintenance and evolution of software systems.
Objective
We aimed at exploring practitioners’ understanding about the relationships between SA and SC.
Method
We used a mixed-method that combines an online survey with 87 respondents and an interview with 8 participants to collect the views of practitioners from 37 countries about the relationships between SA and SC.
Results
Our results reveal that: practitioners mainly discuss five features of relationships between SA and SC; a few practitioners have adopted dedicated approaches and tools in the literature for identifying and analyzing the relationships between SA and SC despite recognizing the importance of such information for improving a system's quality attributes, especially 
maintainability
 and reliability. It is felt that cost and effort are the major impediments that prevent practitioners from identifying, analyzing, and using the relationships between SA and SC.
Conclusions
The results have empirically identified five features of relationships between SA and SC reported in the literature from the perspective of practitioners and a systematic framework to manage the five features of relationships should be developed with dedicated approaches and tools considering the cost and benefit of maintaining the relationships.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study explores the relationships between Software Architecture and Source Code, providing insights for practitioners to improve system quality attributes. The development of a systematic framework is proposed, which could have practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921001579,Automatically inferring user behavior models in large-scale web applications,Saeedeh Sadat Sajjadi=Ghaemmaghami: sajjadig@ualberta.ca; Seyedeh Sepideh=Emam: emam@ualberta.ca; James=Miller: jimm@ualberta.ca,"Abstract
Context
Inferring a behavioral model from users’ navigation patterns in a web application helps application providers to understand their users’ interests. It is essential to automatically identify and generate such models as the volume of daily interactions with applications are enormous.
Objective
The goal of this paper is to incrementally generate such an automated user behavior model with no instrumentation for understanding users’ interests in large-scale mobile and desktop applications.
Method
We propose an approach to fully automate the behavioral model generation for large-scale web applications. Our proposed solution infers a reward augmented behavioral model using a reinforcement learning method by 1) dynamically generating a set of probabilistic Markov models from the users’ interactions, 2) augmenting the state of the model with reward values. Our analysis engine of the proposed solution evaluates the evolving properties of interaction patterns against the inferred behavioral models using probabilistic model checking.
Results
We evaluate the utility of our approach by using it on a large-scale mobile and desktop application. In order to show that it is assigning meaningful reward values, we compare these values with results from Google Analytics (as a state-of-the-art approach). Empirical results indicate that our approach is not only compatible with the results from Google Analytics, but also can provide information in situations, where Google Analytics data is not available.
Conclusion
In this paper, we present a novel stochastic approach to (1) generate user behavioral models for mobile and desktop web applications, (2) automatically calculate the states’ rewards, (3) annotate and analyze the models to verify their quantitative properties, and (4) address many limitations found in existing approaches.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The paper presents a novel stochastic approach to generating user behavioral models for web applications, addressing limitations of existing approaches. The automated calculation of states' rewards and compatibility with Google Analytics results could be valuable for startups."
https://www.sciencedirect.com/science/article/pii/S0950584921001695,Supporting refactoring of BDD specifications—An empirical study,Mohsin=Irshad: mohsin.irshad@bth.se,"Abstract
Context:
Behavior-driven development (BDD) is a variant of test-driven development where specifications are described in a structured domain-specific natural language. Although refactoring is a crucial activity of BDD, little research is available on the topic.
Objective:
To support practitioners in refactoring BDD specifications by (1) proposing semi-automated approaches to identify 
refactoring candidates
; (2) defining refactoring techniques for BDD specifications; and (3) evaluating the proposed identification approaches in an industry context.
Method:
Using Action Research, we have developed an approach for identifying refactoring candidates in BDD specifications based on two measures of similarity and applied the approach in two projects of a large software organization. The accuracy of the measures for identifying refactoring candidates was then evaluated against an approach based on 
machine learning
 and a manual approach based on practitioner perception.
Results:
We proposed two measures of similarity to support the identification of refactoring candidates in a BDD specification base; (1) normalized compression similarity (NCS) and (2) 
similarity ratio
 (SR). A semi-automated approach based on NCS and SR was developed and applied to two industrial cases to identify refactoring candidates. Our results show that our approach can identify candidates for refactoring 6o times faster than a manual approach. Our results furthermore showed that our measures accurately identified refactoring candidates compared with a manual identification by software practitioners and outperformed an ML-based text 
classification approach
. We also described four types of refactoring techniques applicable to BDD specifications; merging candidates, restructuring candidates, deleting duplicates, and renaming specification titles.
Conclusion:
Our results show that NCS and SR can help practitioners in accurately identifying BDD specifications that are suitable candidates for refactoring, which also decreases the time for identifying refactoring candidates.",January 2022,"Refactoring, Normalized Compression Distance (NCD), Normalized Compression Similarity (NCS), Reuse, Similarity ratio (SR), BDD, Behavior-driven development, Specifications, Testing",Information and Software Technology,2025-03-18T00:00:00,7.0,"The research focuses on supporting practitioners in refactoring Behavior-driven development specifications, proposing semi-automated approaches. The identification of refactoring candidates 60 times faster than manual approaches could be beneficial for startups with limited resources."
https://www.sciencedirect.com/science/article/pii/S0950584921000793,From monolithic systems to Microservices: An assessment framework,Florian=Auer: florian.auer@uibk.ac.at; Valentina=Lenarduzzi: valentina.lenarduzzi@lut.fi; Davide=Taibi: davide.taibi@tuni.fi,"Abstract
Context:
Re-architecting 
monolithic systems
 with Microservices-based architecture is a common trend. Various companies are migrating to 
Microservices
 for different reasons. However, making such an important decision like re-architecting an entire system must be based on real facts and not only on gut feelings.
Objective:
The goal of this work is to propose an evidence-based decision support framework for companies that need to migrate to Microservices, based on the analysis of a set of characteristics and metrics they should collect before re-architecting their monolithic system.
Method:
We conducted a survey done in the form of interviews with professionals to derive the assessment framework based on Grounded Theory.
Results:
We identified a set consisting of information and metrics that companies can use to decide whether to migrate to Microservices or not. The proposed assessment framework, based on the aforementioned metrics, could be useful for companies if they need to migrate to Microservices and do not want to run the risk of failing to consider some important information.",September 2021,"Microservices, Cloud migration, Software measurement",Information and Software Technology,2025-03-18T00:00:00,6.0,"The framework proposed can be useful for companies considering migration to Microservices, providing them with a structured approach based on evidence. This could be valuable for early-stage ventures undergoing architectural decision-making."
https://www.sciencedirect.com/science/article/pii/S0950584921001853,Engineering Web Augmentation software: A development method for enabling end-user maintenance,Diego=Firmenich: dfirmenich@tw.unp.edu.ar,"Abstract
Nowadays, end-users are able to adapt Web applications when some of their requirements have not been taken into account by developers. One possible way to do adaptations is by using Web Augmentation techniques. Web Augmentation allows end-users to modify the Web sites’ user interfaces once these are loaded on the client-side, i.e., in the browser. They achieve these adaptations by developing and/or installing Web browser plugins (“augmenters”) that modify the user interface with new functionalities. This particular kind of software artifacts requires 
special attention
 regarding maintenance as–in most cases–they depend on third-party resources, such as HTML pages. When these resources are upgraded, unexpected results during the augmentation process may occur. Many communities have arisen around Web Augmentation, and today there are large repositories where developers share their augmenters; end-users may give feedback about existing augmentations and even ask for new ones. Maintenance is a key phase in the augmenters’ life-cycle, and currently, this task falls (as usual) on the developers. In this paper, we present a participatory approach for allowing end-users without programming skills to participate in the augmenters’ maintenance phase. In order to allow this, we also provide support for the development phase to bootstrap a first version of the augmenter and to reduce the load on developers in both phases, development and maintenance. We present an analysis of more than eight thousand augmenters, which helped us devise the approach. Finally, we present an experiment with 48 participants to validate our approach.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The paper presents a participatory approach for end-users to participate in Web Augmentation maintenance, reducing the burden on developers. While the approach has potential value, the impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S095058492100152X,Introduction to the Special Issue on: Grey Literature and Multivocal Literature Reviews (MLRs) in software engineering,Vahid=Garousi: v.garousi@qub.ac.uk; Michael=Felderer: michael.felderer@uibk.ac.at; Mika V.=Mäntylä: mika.mantyla@oulu.fi,"Abstract
In parallel to academic (peer-reviewed) literature (e.g., journal and conference papers), an enormous extent of grey literature (GL) has accumulated since the inception of software engineering (SE). GL is often defined as “literature that is not formally published in sources such as books or journal articles”, e.g., in the form of trade magazines, online blog-posts, technical reports, and online videos such as tutorial and presentation videos. GL is typically produced by SE practitioners. We have observed that researchers are increasingly using and benefitting from the knowledge available within GL. Related to the notion of GL is the notion of Multivocal Literature Reviews (MLRs) in SE, i.e., a MLR is a form of a Systematic Literature Review (SLR) which includes knowledge and/or evidence from the GL in addition to the peer-reviewed literature. MLRs are useful for both researchers and practitioners because they provide summaries of both the state-of-the-art and -practice in a given area. MLRs are popular in other fields and have started to appear in SE community. It is timely then for a Special Issue (SI) focusing on GL and MLRs in SE. From the pool of 13 submitted papers, and after following a rigorous peer review process, seven papers were accepted for this SI. In this introduction we provide a brief overview of GL and MLRs in SE, and then a brief summary of the seven papers published in this SI.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the focus on grey literature and Multivocal Literature Reviews is relevant for researchers, the practical value for European early-stage ventures or startups is limited."
https://www.sciencedirect.com/science/article/pii/S0950584921001506,A closer look at process-based simulation with stackless coroutines,Dorian=Weber: weber@informatik.hu-berlin.de; Paula=Wiesner: wiesnerp@informatik.hu-berlin.de; Joachim=Fischer: fischer@informatik.hu-berlin.de,"Abstract
Context
Validating discrete-event 
computer simulations
 for a particular problem domain often involves the help of a domain expert. This means that a certain structural closeness between the simulator’s inner workings and the modeled system is needed in order to allow the expert to follow the implementation in analogy. Process-based simulation imposes an object-oriented view onto a modeled system which allows for a high degree of structural closeness in most cases. In comparison, event-based simulation requires a procedural definition with a relatively low degree of structural closeness for many cases, but outperforms the process-based approach both in terms of performance and portability. Recent advances in compiler technology have introduced a portable way of rewriting thread-based code into event-based code, effectively providing the means to implement portable green-threads in compiled system languages.
Objective
This work aims to cover the historical, mechanical, and implementation specific aspects as well as practical measurements of runtime performance of a library based solution to process-based discrete-event simulation in comparison to alternative solutions.
Method
We explain how to use the stackless coroutines introduced into the 
Rust
 programming language to implement a minimal simulator core and discuss aesthetic as well as performance implications through systematic benchmarking using the three simulation scenarios 
Barbershop
, 
Car Ferry
 and 
Dining Philosophers
 by comparing their implementations to equivalent ones in the simulation language 
SLX
 and the 
C


++
 library 
ODEMx
.
Results
Our results indicate that stackless coroutines enable structurally equivalent formulations to pure process-based simulations while still delivering close to equivalent or – depending on the use-case – even superior performance and portability compared to the aforementioned solutions.
Conclusion
We show that stackless coroutines can be used to bridge the gap between process- and event-based simulators, affording modelers a level of abstraction close to the former approach while delivering the performance and portability of the latter one.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The work on stackless coroutines and their impact on simulation performance and portability can be beneficial for European early-stage ventures working on software simulations.
https://www.sciencedirect.com/science/article/pii/S095058492100149X,Cronista: A multi-database automated provenance collection system for runtime-models,Owen=Reynolds: 180200041@aston.ac.uk; Antonio=García-Domínguez: a.garcia-dominguez@aston.ac.uk; Nelly=Bencomo: n.bencomo@aston.ac.uk,"Abstract
Context:
Decision making by software systems that face uncertainty needs tracing to support 
understandability
, as accountability is crucial. While logging has been essential to support explanations and 
understandability
 of behaviour, several issues still persist, such as the high cost for managing large logs, not knowing what to log, and the inability of logging techniques to relate events to each other or to specific occurrences of high-level activities in the system.
Objective:
Cronista
 is an alternative to logging for systems that act on top of runtime models. Instead of targeting the running systems, 
Cronista
 automatically collects the provenance of changes made to the runtime models, which aim at leveraging high-level representations, to produce more concise historical records. The provenance graphs capture causal links between those changes and the activities of the system, which are used to investigate issues.
Method:
Cronista
’s architecture is described with the current design and the implementation of its high-level components for single-machine, multi-threaded systems. 
Cronista
 is applied to a traffic-simulation 
case study
. The trade-offs of two different storage solutions are evaluated, i.e. the CDO 
model repositories
, and JanusGraph 
graph databases
.
Results:
Integrating 
Cronista
 into the 
case study
 requires only minor code changes. 
Cronista
 collected provenance graphs for the simulations as they ran, using both CDO and JanusGraph. Both solutions highlighted the cause of a seeded defect in the system. For the longer executions, both CDO and JanusGraph showed negligible overhead on the simulation times. Querying and visualisation tools were more user-friendly in JanusGraph than in CDO.
Conclusion:
Cronista
 demonstrates the feasibility of recording fine-grained provenance for the evolution of runtime models, while using it to investigate issues. User convenience and resource requirements need to be balanced. The paper present how the available technologies studied offer different trade-offs to satisfy the balance required.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The combination of Agile Software Development, UCD, and Lean Startup in the development approach can provide valuable insights for European early-stage ventures navigating product development and market validation."
https://www.sciencedirect.com/science/article/pii/S0950584921001701,Improving Agile Software Development using User-Centered Design and Lean Startup,Maximilian=Zorzetti: maximilian.zorzetti@acad.pucrs.br; Ingrid=Signoretti: ingrid.manfrim@acad.pucrs.br; Larissa=Salerno: larissa.salerno@acad.pucrs.br; Sabrina=Marczak: sabrina.marczak@pucrs.br; Ricardo=Bastos: bastos@pucrs.br,"Abstract
Context:
Agile methods have limitations concerning problem understanding and solution finding, which can cause organizations to push misguided products and accrue waste. Some authors suggest combining agile methods with discovery-oriented approaches to overcome this, with notable candidates being User-Centered Design (UCD) and Lean Startup, a combination of which there is yet not a demonstrated, comprehensive study on how it works.
Objective:
To characterize a development approach combination of 
Agile Software Development
, UCD, and Lean Startup; exposing how the three approaches can be intertwined in a single 
development process
 and how they affect development.
Method:
We conducted a 
case study
 with two industry software development teams that use this combined approach, investigating them through interviews, observation, focus groups, and a workshop during a nine-month period in which they were stationed in a custom-built development lab.
Results:
The teams are made up of user advocates, business advocates, and solution builders; while their development approach emphasizes experimentation by making heavy use of build-measure-learn cycles. The combined approach promotes a problem-oriented mindset, encouraging team members to work together and engage with the entire 
development process
, actively discovering stakeholders needs and how to fulfill them. Each of its approaches provide a unique contribution to the development process: UCD fosters empathy with stakeholders and enables teams to better understand the problem they are tasked with solving; Lean Startup introduces experimentation as the guiding force of development; and 
Extreme Programming
 (the teams’ agile method) provides support to experimentation and achieving technical excellence.
Conclusion:
The combined approach pushes teams to think critically throughout the development effort. Our practical example provides insight on its essence and might inspire industry practitioners to seek a similar development approach based on the same precepts.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The exploration of a combined approach of Agile, UCD, and Lean Startup in software development can offer insights for European early-stage ventures looking to improve problem understanding and solution finding."
https://www.sciencedirect.com/science/article/pii/S0950584921001841,A model-driven framework to support strategic agility: Value-added perspective,Yves=Wautelet: yves.wautelet@kuleuven.be,"Abstract
Context:
The Covid-19 pandemic has shown the entire world that the habits of work, freedom, and consumption can change quickly and significantly for an undetermined amount of time. A dynamic environment as such, prompts organizations to move fast in order to leverage changing circumstances as sources of opportunity rather than deadly threats. Drastic changes in work organization, consumption habits, compliance, etc., may require firms to quickly adopt new technology delivering all sorts of added value.
Objective:
The development and adoption of new technology – structurally impacting the way the organization conducts its activities – requires a considerable amount of effort in a short time frame, thus rendering it a governance decision where the alignment of the technology’s adoption and use to the long term strategy needs to be evaluated. The short time frame requiring fast response implies that agility should not remain a development or management/operational concept but should also be adopted onto the strategic layer.
Method:
Design Science Research (DSR) has been applied to build-up a framework supporting strategic agility in a model-driven fashion called 
Strategic Agile Model Driven IT Governance
 (
StratAMoDrIGo
). The relevance, rigor and design cycles of DSR have been applied and presented.
Results:
StratAMoDrIGo is based on the identification of sources of value for the organization’s strategy, its stakeholders and the users of the implemented/adopted technology. Relevant concepts are consolidated in an ontology of which the application uses the 
NFR
 Model at strategic-level and the i* Strategic Rationale Model at management-level. The proposal is applied on the case of an hospital facing the Covid-19 pandemic.
Conclusion:
The value brought by strategic opportunities’ adoption to the organization, stakeholders and users can be evaluated 
ex ante
 through conceptual models.",January 2022,"Strategic agility, IT governance, Strategic value, Model-driven development, Agile, Agility, i* framework, Scaled agile framework, SAFe, MoDrIGo, StratAMoDrIGo",Information and Software Technology,2025-03-18T00:00:00,8.0,The abstract addresses the impact of the Covid-19 pandemic on organizations and the need for strategic agility. The development of a framework to support this agility is relevant and practical for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584921001828,Human values in software development artefacts: A case study on issue discussions in three Android applications,Arif=Nurwidyantoro: Arif.Nurwidyantoro@monash.edu; Mojtaba=Shahin: Mojtaba.Shahin@monash.edu; Michel R.V.=Chaudron: m.r.v.chaudron@tue.nl; Waqar=Hussain: Waqar.Hussain@monash.edu; Rifat=Shams: Rifat.Shams@monash.edu; Harsha=Perera: Harsha.Perera@monash.edu; Gillian=Oliver: Gillian.Oliver@monash.edu; Jon=Whittle: Jon.Whittle@data61.csiro.au,"Abstract
Context:
Human values such as inclusion, privacy, and accessibility need to be considered during software development to attract and maintain users. However, little effort has been made to study human values consideration in software development, particularly in software development artefacts.
Objective:
Issue discussion is potentially a rich source for human values analysis because it is a common place for users and developers to share and communicate their concerns. This paper aims to investigate the extent to which human values are discussed and whether the presence of values differs across projects.
Method:
We carried out a 
case study
 to discover human values in 1,097 issues collected from three 
Android
 projects: Signal, K-9, and Focus.
Results:
We identified 20 value themes and proposed a contextualised 
software engineering
 description for each of them. The analysis shows that privacy, freedom, usability, and efficiency were the prevalent value themes in the issue discussions of these three projects. Meanwhile, Self-direction - Action and Security - Personal are the common prevalent human values found in the projects. Moreover, we found that a statement of values from the apps and their functionalities could contribute to the presence of values.
Conclusion:
The results suggest that human values are present in software development artefacts, for which automated tools can be developed to extract and classify human values from them.",January 2022,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract focuses on human values consideration in software development, which is essential for startups to attract and maintain users. The proposed analysis and results are practical for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921001348,On preserving the behavior in software refactoring: A systematic mapping study,Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Eman Abdullah=AlOmar: eman.alomar@mail.rit.edu; Christian=Newman: cdnvse@rit.edu,"Abstract
Context:
Refactoring is the art of modifying the design of a system without altering its behavior. The idea is to reorganize variables, classes and methods to facilitate their future adaptations and comprehension. As the concept of behavior preservation is fundamental for refactoring, several studies, using 
formal verification
, language transformation and dynamic analysis, have been proposed to monitor the execution of 
refactoring operations
 and their impact on the program semantics. However, there is no existing study that examines the available behavior preservation strategies for each refactoring operation.
Objective:
This paper identifies behavior preservation approaches in the research literature.
Method:
We conduct, in this paper, a 
systematic mapping study
, to capture all existing behavior preservation approaches that we classify based on several criteria including their methodology, applicability, and their degree of automation.
Results:
The results indicate that several behavior preservation approaches have been proposed in the literature. The approaches vary between using formalisms and techniques, developing automatic refactoring safety tools, and performing a manual analysis of the source code.
Conclusion:
Our taxonomy reveals that there exist some types of 
refactoring operations
 whose behavior preservation is under-researched. Our classification also indicates that several possible strategies can be combined to better detect any violation of the program semantics.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract discusses behavior preservation in refactoring operations, which is relevant for startups in the software development space. The systematic mapping study provides insights that can be beneficial for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921001312,Blurring boundaries: Toward the collective empathic understanding of product requirements,Robert C.=Fuller: rfuller@ece.ubc.ca; Philippe=Kruchten: pbk@ece.ubc.ca,"Abstract
Context
Many software product companies create cross-functional development teams that own a product or a defined set of features. These product teams often require a deep and collective understanding of the product domain, a rich context within which to understand the product requirements and to make decisions throughout the 
development process
.
Objective
Little is known about what supports or impedes these teams in collectively achieving this 
deep understanding
. This paper identifies certain organisational conditions that impact teams in this respect.
Method
Using Constructivist 
Grounded Theory method
, we studied 18 teams across seven software companies creating products for a diverse range of markets.
Results
The study found certain organisational and planning process factors play a significant role in whether product development teams have the potential to collectively develop deep domain understanding. These factors also impact individual and development team dynamics.
Conclusions
We identify two essential metaphorical dynamics, broadening the lens and blurring boundaries, that cross-functional product teams employ in order to fully embrace product ownership, visioning, and planning towards achieving this rich context for understanding product requirements. We also conclude that the highly specialised nature of many organisational models and development processes is contraindicated for cross-functional product development teams in achieving this deep collective understanding and we call for a revisiting of conventional organisational and product planning practices for software product development.",December 2021,"Requirements understanding and validation, Empathy-driven development, Product team organisation, Collective sensemaking, Constructivist Grounded Theory",Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides valuable insights into the organizational conditions impacting product development teams, which can benefit early-stage ventures in improving team dynamics and planning processes."
https://www.sciencedirect.com/science/article/pii/S095058492100135X,Topic modeling for feature location in software models: Studying both code generation and interpreted models,Francisca=Pérez: mfperez@usj.es; Carlos=Cetina: ccetina@usj.es; Raúl=Lapeña: rlapena@usj.es; Ana C.=Marcén: acmarcen@usj.es,"Abstract
Context:
In the last 20 years, the research community has increased its attention to the use of 
topic modeling
 for software maintenance and evolution tasks in code. Topic modeling is a popular and promising information retrieval technique that represents topics by word probabilities. 
Latent Dirichlet Allocation
 (LDA) is one of the most popular 
topic modeling
 methods. However, the use of topic modeling in model-driven software development has been largely neglected. Since software models have less noise (implementation details) than software code, software models might be well-suited for topic modeling.
Objective:
This paper presents our LDA-guided evolutionary approach for feature location in software models. Specifically, we consider two types of software models: models for code generation and interpreted model.
Method:
We evaluate our approach considering two real-world industrial 
case studies
: code-generation models for train control software, and interpreted models for a commercial 
video game
. To study the impact on the results, we compare our approach for feature location in models against random search and a baseline based on Latent Semantic Indexing, which is a popular information retrieval technique. In addition, we perform a statistical analysis of the results to show that this impact is significant. We also discuss the results in terms of the following aspects: data 
sparsity
, implementation complexity, calibration, and stability.
Results:
Our approach significantly outperforms the baseline in terms of recall, precision and F-measure when it comes to interpreted models. This is not the case for code-generation models.
Conclusions:
Our analysis of the results uncovers a recommendation towards results improvement. We also show that calibration approaches can be transferred from code to models. The findings of our work with regards to the compensation of instability have the potential to help not only feature location in models, but also in code.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The research presents a novel approach for feature location in software models, showcasing significant improvements in results for interpreted models. This can potentially aid startups in enhancing their software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584921001336,Evaluating the influence of scope on feature location,Carlos=Cetina: ccetina@usj.es; África=Domingo: adomingo@usj.es; Jorge=Echeverría: jecheverria@usj.es; Óscar=Pastor: opastor@dsic.upv.es,"Abstract
Context:
Feature Location (FL) is a widespread technique that is used to maintain and evolve a software product. FL is also helpful in reengineering a family of software products into a Software Product Line (SPL). Despite the popularity of FL, there is no study that evaluates the influence of scope (single product or product family) when engineers perform FL.
Objective:
The goal of this paper is to compare the performance, productivity, and perceived difficulty of manual FL when scope changes from a single product to a 
product family
.
Method:
We conducted a crossover experiment to compare the performance, productivity, and perceived difficulty of manual FL when scope changes. The 
experimental objects
 are extracted from a real-world SPL that uses a Domain-Specific Language to generate the firmware of its products.
Results:
Performance and productivity decrease significantly when engineers locate features in a 
product family
 regardless of their experience. For these variables the impact of the FL Scope is medium–large. On contrast, for perceived difficulty, the magnitude of the difference is moderate and is not significant.
Conclusions:
While performance and productivity decrease significantly when engineers locate features in a product family, the difficulty they perceive does not predict the significant worsening of the results. Our work also identifies strengths and weaknesses in FL. This can help in developing better FL approaches and test cases for evaluation.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study evaluates the impact of scope changes on feature location in software products, providing insights into performance and productivity changes. While not directly focused on startups, the findings can inform early-stage ventures on optimizing their product maintenance and evolution strategies."
https://www.sciencedirect.com/science/article/pii/S0950584921001361,Guiding the selection of research methodology in industry–academia collaboration in software engineering,Claes=Wohlin: claes.wohlin@bth.se; Per=Runeson: per.runeson@cs.lth.se,"Abstract
Background:
The literature concerning research methodologies and methods has increased in 
software engineering
 in the last decade. However, there is limited guidance on selecting an appropriate research methodology for a given research study or project.
Objective:
Based on a selection of research methodologies suitable for software engineering research in collaboration between industry and academia, we present, discuss and compare the methodologies aiming to provide guidance on which research methodology to choose in a given situation to ensure successful industry–academia collaboration in research.
Method:
Three research methodologies were chosen for two main reasons. Design Science and Action Research were selected for their usage in software engineering. We also chose a model emanating from software engineering, i.e., the Technology Transfer Model. An overview of each methodology is provided. It is followed by a discussion and an illustration concerning their use in industry–academia collaborative research. The three methodologies are then compared using a set of criteria as a basis for our guidance.
Results:
The discussion and comparison of the three research methodologies revealed general similarities and distinct differences. All three research methodologies are easily mapped to the general research process describe–solve–practice, while the main driver behind the formulation of the research methodologies is different. Thus, we guide in selecting a research methodology given the primary research objective for a given research study or project in collaboration between industry and academia.
Conclusions:
We observe that the three research methodologies have different main objectives and differ in some characteristics, although still having a lot in common. We conclude that it is vital to make an informed decision concerning which research methodology to use. The presentation and comparison aim to guide selecting an appropriate research methodology when conducting research in collaboration between industry and academia.",December 2021,"Research methodology, Selecting research methodology, Design Science, Action Research, Technology Transfer Model, Industry–academia collaboration",Information and Software Technology,2025-03-18T00:00:00,7.0,The paper offers guidance on selecting research methodologies for industry-academia collaboration in software engineering research. This can be valuable for startups seeking to conduct research in partnership with academia to drive innovation.
https://www.sciencedirect.com/science/article/pii/S0950584921001440,Prioritizing code documentation effort: Can we do it simpler but better?,Yanhui=Li: yanhuili@nju.edu.cn; Yuming=Zhou: zhouyuming@nju.edu.cn,"Abstract
Context
. Due to time or economic pressures, code developers are often unable to write documents for all modules in a project. Recently, a supervised artificial neural network (ANN) approach is proposed to prioritize documentation effort “to ensure that sections of code important to 
program comprehension
 are thoroughly explained”.
Objective
. However, as a supervised approach, there is a need to use labeled 
training data
 to train the prediction model, which may not easy to obtain in practice. Furthermore, it is unclear whether the ANN approach is generalizable, as it is only evaluated on several small data sets collected from API libraries.
Method
. In this paper, we propose an unsupervised approach based on improved PageRank to prioritize documentation effort. This approach identifies “important” modules only based on the dependence relationships between modules in a project. As a result, the PageRank approach does not need any 
training data
 to build the prediction model.
Results
. In order to evaluate the effectiveness of the PageRank approach, we use six additional large data sets collected from two larger libraries and four applications to conduct the experiment. The experimental results show that the PageRank approach is superior to the state-of-the-art ANN approach.
Conclusion
. Due to the simplicity and effectiveness, we advocate that the PageRank approach should be used as an easy-to-implement baseline in future research on documentation effort prioritization, and any newly proposed approach should be compared with it to demonstrate its effectiveness.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed unsupervised approach based on improved PageRank for prioritizing documentation effort can be beneficial for early-stage ventures by providing a more efficient and effective method of code documentation without the need for labeled training data.
https://www.sciencedirect.com/science/article/pii/S0950584921001452,UX work in software startups: A thematic analysis of the literature,Suéllen=Martinelli: suellen.martinelli@estudante.ufscar.br; Luciana=Zaina: lzaina@ufscar.br; Jullia=Saad: julliasaad01@gmail.com; Leticia S.=Machado: leticia.smachado@gmail.com; Cleidson R.B.=de Souza: cleidson.desouza@acm.org; Alexandre=Alvaro: alvaro@ufscar.br,"Abstract
Context:
Startups are new and fast-growing innovative businesses. These companies also deal with uncertain market conditions and work under constant time and business pressures. Although 
User Experience
 (UX) has been widely adopted in the software industry, this has not been a reality in the context of software startups yet. Several factors might influence whether, which, and how UX is adopted by software startups.
Objective:
The objective of this paper is to investigate in the literature how software startups work with UX and to discover the relationship between software development practices and UX in startups.
Methodology:
Our methodology is composed of three main activities: (1) mapping the literature seeking publications on UX work, 
software engineering
, and startups, which resulted in 21 relevant publications; (2) a thematic analysis based on the output of step 1 (i.e., the relevant literature); and (3) refining the themes found out in step 2 and the design of their relationships to explain the link between UX work and software startups.
Results:
The challenges, opportunities, and practices associated with UX in the context of software startups reported by the literature were organized in a set of themes. As a result, seven themes were defined so as to identify needs and opportunities related to UX work in startups. In addition, we synthesize open questions from the literature and suggest new ones to further research directions about the adoption of UX by software startups.
Conclusion:
Our findings demonstrate that software startups require an approach to UX that is more adherent to the startups’ dynamic and disruptive nature. We also suggest emerging 
open research
 questions which should be answered to promote the evolution of UX as applied to software startups.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The investigation into UX in software startups can provide valuable insights, but the findings may not have a direct immediate impact on early-stage ventures as they focus more on understanding the challenges and opportunities related to UX."
https://www.sciencedirect.com/science/article/pii/S0950584921001476,Technical debt payment and prevention through the lenses of software architects,Boris=Pérez: br.perez41@uniandes.edu.co,"Abstract
Context:
Architectural decisions
 are considered one of the most common sources of technical debt (TD). Thus, it is necessary to understand how TD is perceived by software architects, particularly, the practices supporting the elimination of debt items from projects, and the practices used to reduce the chances of TD occurrence.
Objective:
This paper investigates the most commonly used practices to pay off TD and to prevent debt occurrence in software projects from the architect’s point of view.
Method:
We used the available data from InsighTD, which is a globally distributed family of industrial surveys on the causes, effects, and management of TD. We analyze responses from a corpus of 72 software architects from Brazil, Chile, Colombia, and the United States.
Results:
Results showed that refactoring (30.2%) was the main practice related to TD payment, followed by design improvements (14.0%). Refactoring, design improvements, and test improvements are the most cited payment practices among cases of code, design and test debt. Concerning the TD preventive practices, we find that having a well-defined architecture and design is the most cited practice (13.6%), followed by having a well-defined scope and requirements. This last practice is the most cited one for expert software architects. Finally, when comparing preventive practices among the three major roles derived from the survey (software architects, engineer roles, and management roles), we found that none of the roles shared the most cited practice, meaning that each role had its worries and focus on different strategies to reduce TD’s presence in the software.
Conclusion:
The lists of TD payment and prevention practices can guide software teams by having a catalog of practices to keep debt controlled or reduced.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study on architectural decisions and technical debt payment practices can be highly valuable for startups as it provides guidance on how to manage technical debt effectively, which is crucial for the success and growth of early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921001518,An automatic methodology for the quality enhancement of requirements using genetic algorithms,Daniel=Adanza Dopazo: 100371746@alumnos.uc3m.es; Valentín=Moreno Pelayo: vmpelayo@kr.inf.uc3m.es; Gonzalo=Génova Fuster: ggenova@uc3m.es,"Abstract
Context
The set of requirements for any project offers common ground where the client and the company agree on the most important features and limitations of the project. Having a set of requirements of the highest possible quality is of enormous importance; benefits include improving project quality, understanding client needs better, reducing costs, and predicting project schedules and results with greater accuracy.
Objective
This paper's primary goal is to create a methodology that can provide effective and efficient solutions for modifying poor requirements integrated into a full-fledged system, extracting the main features of each requirement, assessing their quality at an expert level, and, finally, enhancing the quality of the requirements.
Method
In the first step, a 
machine learning algorithm
 is implemented to classify requirements based on quality and identify those that are the likeliest to be problematic. In the second step, the 
genetic algorithm
 generated solutions to enhance the quality of the requirements identified as inferior.
Results
The results of the 
genetic algorithm
 are compared with the theoretically optimal solution. The paper demonstrates the significant flexibility of genetic algorithms, which create a wide variety of solutions and can adapt to any type of classifier. From the initial dataset of requirements, the genetic algorithm finds the optimal solution in 85% of cases after 10 iterations and achieves 59.8% success after only one iteration.
Conclusions
Genetic algorithms are promising tools for 
requirements engineering
 by delivering benefits such as saving costs, automating tasks, and providing more solid and efficient planning in any project through the generation of new solutions.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The methodology proposed for enhancing the quality of project requirements can be beneficial for startups in improving project quality and understanding client needs better, but the direct impact on early-stage ventures may not be immediate or significant."
https://www.sciencedirect.com/science/article/pii/S0950584921001531,A longitudinal study of the impact of refactoring in android applications,,"Abstract
Context:
Mobile applications have to continuously evolve in order to meet new user requirements and technological changes. Addressing these constraints may lead to poor implementation and design choices, known 
code smells
. 
Code refactoring
 is a key practice that is employed to ensure that the intent of a code change is properly achieved without compromising internal software quality. While previous studies have investigated the impact of refactoring on traditional code smells in 
desktop applications
, little attention has been paid to the impact of refactoring activities in mobile application development.
Objective:
We aim to develop a broader understanding of the impact of refactoring activities on 
Android
 and traditional code smells in 
Android
 apps.
Method:
We conduct a longitudinal empirical study by analyzing the evolution history of five open-source Android apps comprising 652 releases and exhibiting a total of 9,600 
refactoring operations
. We consider 15 common Android smell types and 10 common traditional Object-Oriented (OO) code smell types to provide a broad overview of the relationship between refactoring and code smells.
Results:
We find that code smells are widespread across 
Android applications
, but smelly classes are not particularly targeted by refactoring activities and, when they are, it is rare for refactoring to actually remove a smell.
Conclusions:
These somewhat surprising results indicate that it is critical to understand better the real quality issues that Android developers face, and to develop a model of code smells and refactoring that can better address their needs in practice.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"While the study on refactoring activities in Android apps is interesting, the findings may not directly impact early-stage ventures as they focus on understanding code smells in mobile applications, which may not be a primary concern for startups."
https://www.sciencedirect.com/science/article/pii/S0950584921001567,HYDRA: Feedback-driven black-box exploitation of injection vulnerabilities,Manuel=Leithner: mleithner@sba-research.org; Bernhard=Garn: bgarn@sba-research.org; Dimitris E.=Simos: dsimos@sba-research.org,"Abstract
Context:
Injection vulnerabilities
 remain an omnipresent threat to web application security. These issues arise when user-supplied input is included in commands constructed by the application without applying adequate validation and filtering, permitting attackers to modify the resulting instructions.
Objective:
Tools used in real-world security assessments commonly employ a static list of 
malicious input
 strings to be submitted to the system under test (SUT) to gauge the presence of vulnerabilities. However, sanitizing filters may cause these simulated attacks to fail, even if they only mitigate a subset of potentially harmful values. This may result in a false sense of security. This work introduces HYDRA, a feedback-driven black-box security testing approach for the exploitation of injection vulnerabilities. It is capable of constructing inputs designed to evade such imperfect filters while allowing users to define and rank 
output contexts
, abstract locations in the output of the SUT that are associated with desirable semantics (for instance, allowing the execution of JavaScript code).
Method:
Starting with an innocuous initial input string that is submitted to the SUT and appears anywhere in the output, HYDRA identifies the initial output context. It extends the input string with the goal of reaching contexts that are deemed ”better” according to domain knowledge. This process continues until an ”ideal” output context is reached, usually corresponding to an exploit that impacts the security of the SUT. In addition to this dynamic approach, we present a static variant based on combinatorial security testing. We instantiate our approach by targeting cross-site scripting (XSS) vulnerabilities, detailing the unique challenges posed by HTML 
parsing
, and implement this application of HYDRA in a prototype tool.
Results:
The evaluation shows that our implementation is able to evade faulty filters and is effective at identifying injection vulnerabilities while remaining more flexible than existing approaches by allowing users to define desirable output contexts.
Conclusion:
Based on the results of our evaluation, we are confident that including the HYDRA approach in security assessments will increase the number of identified XSS vulnerabilities, particularly those that are difficult to exploit. We anticipate that an application to other classes of vulnerabilities such as 
SQL
 injections will significantly advance the state of the art.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The HYDRA approach introduces a feedback-driven security testing method that allows for more effective identification of vulnerabilities, particularly XSS vulnerabilities, and offers a more flexible approach compared to existing methods, which can have a significant impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492100166X,MS-QuAAF: A generic evaluation framework for monitoring software architecture quality,Salim=Kadri: salim8359@yahoo.fr; Sofiane=Aouag: Sofiane.Aouag@gmail.com; Djalal=Hedjazi: Djalal.Hedjazi@gmail.com,"Abstract
Context
In a highly competitive software market, architecture quality is one of the key 
differentiators
 between software systems. Many quantitative and qualitative evaluation frameworks were proposed to measure architecture. However, qualitative evaluation lacks statistical significance, whereas quantitative methods are designed for evaluating 
specific quality attributes
, such as modifiability and performance. Besides, the assessment covers usually a single development stage, either at the design stage or at the implementation stage.
Objective
A lack of generic frameworks that can support the assessment of a broad set of attributes and ensure continuous evaluation by covering the main development stages is addressed. Accordingly, this paper presents MS-QuAAF, a 
quantitative assessment
 framework destined for evaluating software architecture through a set of generic metrics.
Method
The 
quantitative evaluation
 consists of checking architecture facets mapped to quality attributes against the early specified meta-models. This process starts by analyzing rules infringements and calculating architecture defects after accomplishing the design stage. Second, the assigned responsibilities supposed to promote stakeholders’ quality attributes are assessed quantitatively at the end of the implementation stage. Third, the final evaluation report is generated.
Results
We made specifically three main contributions. First, the proposed metrics within the framework are generic, which means that the framework has the ability to assess any inputted quality. Second, the framework proposes a set of evaluation services capable of assessing the architecture at two main development stages, which are design and implementation. Third, we proposed a 
quantitative assessment
 tree within the framework called the Responsibilities Satisfaction Tree (RST) that uses 
NFR
 responsibilities nodes to evaluate the implemented architectures.
Conclusion
The conducted experiment showed that the framework is capable of evaluating quality attributes based on architecture specification using the proposed metrics. Furthermore, these metrics contributed to enhancing architecture quality during the development stages by notifying architects of the discovered anomalies.",December 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The MS-QuAAF framework addresses the lack of generic frameworks for evaluating software architecture, which can potentially improve architecture quality during development stages, providing a moderate impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921000938,Assessing test artifact quality—A tertiary study,Jürgen=Börstler: jurgen.borstler@bth.se; Nauman Bin=Ali: nauman.ali@bth.se; Huynh Khanh Vi=Tran: huynh.khanh.vi.tran@bth.se; Michael=Unterkalmsteiner: michael.unterkalmsteiner@bth.se,"Abstract
Context:
Modern software development increasingly relies on software testing for an ever more frequent delivery of high quality software. This puts high demands on the quality of the central artifacts in software testing, test suites and test cases.
Objective:
We aim to develop a comprehensive model for capturing the dimensions of test case/suite quality, which are relevant for a variety of perspectives.
Methods:
We have carried out a systematic literature review to identify and analyze existing secondary studies on 
quality aspects
 of software testing artifacts.
Results:
We identified 49 relevant secondary studies. Of these 49 studies, less than half did some form of quality appraisal of the included primary studies and only 3 took into account the quality of the primary study when synthesizing the results. We present an aggregation of the context dimensions and factors that can be used to characterize the environment in which the test case/suite quality is investigated. We also provide a comprehensive model of test case/suite quality with definitions for the 
quality attributes
 and measurements based on findings in the literature and ISO/IEC 25010:2011.
Conclusion:
The test artifact 
quality model
 presented in the paper can be used to support test artifact quality assessment and improvement initiatives in practice. Furthermore, the model can also be used as a framework for documenting context characteristics to make 
research results
 more accessible for research and practice.",November 2021,"Software testing, Test case quality, Test suite quality, Test artifact quality, Quality assurance",Information and Software Technology,2025-03-18T00:00:00,5.0,"The comprehensive model for test case/suite quality can support quality assessment and improvement initiatives in practice, but lacks a direct practical impact on early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921001154,A comprehensive investigation of the impact of feature selection techniques on crashing fault residence prediction models,Zhou=Xu: zhouxullx@cqu.edu.cn,"Abstract
Context:
Software crash is a serious form of the software failure, which often occurs during the software development and maintenance process. As the stack trace reported when the software crashes contains a wealth of information about crashes, recent work utilized 
classification models
 with the collected features from stack traces and 
source code
 to predict whether the fault causing the crash resides in the stack trace. This could speed-up the crash localization task.
Objective:
As the quality of features can affect the performance of the constructed 
classification models
, researchers proposed to use feature selection methods to select a representative feature subset to build models by replacing the original features. However, only limited feature selection methods and classification models were taken into consideration for this issue in previous work. In this work, we look into this topic deeply and find out the best feature selection method for crash fault residence prediction task.
Method:
We study the performance of 24 feature selection techniques with 21 classification models on a benchmark dataset containing crash instances from 7 real-world software projects. We use 4 indicators to evaluate the performance of these feature selection methods which are applied to the classification models.
Results:
The experimental results show that, overall, a probability-based feature selection, called Symmetrical Uncertainty, performs well across the studied classification models and projects. Thus, we recommend such a feature selection method to preprocess the crash instances before constructing classification models to predict the crash fault residence.
Conclusion:
This work conducts a large-scale empirical study to investigate the impact of feature selection methods on the performance of classification models for the crashing fault residence prediction task. The results clearly demonstrate that there exist significant performance differences among these feature selection techniques across different classification models and projects.",November 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on feature selection methods for crash fault residence prediction task shows significant performance differences, recommending a specific method that can enhance the prediction accuracy, which can have a positive impact on early-stage ventures relying on software stability."
https://www.sciencedirect.com/science/article/pii/S0950584921000951,"Does shortening the release cycle affect refactoring activities: A case study of the JDT Core, Platform SWT, and UI projects",Naoyasu=Ubayashi: ubayashi@ait.kyushu-u.ac.jp; Yasutaka=Kamei: kamei@ait.kyushu-u.ac.jp; Yutaro=Kashiwa: kashiwa@ait.kyushu-u.ac.jp; Olivier=Nourry: oliviern@posl.ait.kyushu-u.ac.jp,"Abstract
Context:
Several large-scale companies such as Google and Netflix chose to adopt short release cycles (e.g., rapid releases) in recent years. Although this allows these companies to provide updates and features faster for their users, it also causes developers to have less time to dedicate to development activities other than feature development.
Objective:
In this paper, we investigate how refactoring activities were impacted by the adoption of shorter releases.
Method:
We extract all refactorings applied over a period of two years during traditional yearly releases and almost two years during shorter quarterly releases in three Eclipse projects. We then analyze both time periods’ refactoring activities to understand how refactoring activities can be impacted by shortening the release cycles.
Results:
We observe reduced refactoring activities in one project and a decrease in more complex 
refactoring operations
 after shortening the release cycles. We also find that weekly efforts dedicated to refactoring activities was lower across all projects after shortening the release cycles.
Conclusion:
Shorter releases may impact software development tasks such as refactoring in unintended ways. Not applying specific types of refactoring may also affect the software’s quality in the long term. Using this 
case study
 and past work on shorter releases, potential short release adopters can now better plan their transition to shorter releases knowing which areas of development may be affected.",November 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The impact of shorter releases on refactoring activities is relevant for startups, but the practical application may vary based on the specific context of the venture."
https://www.sciencedirect.com/science/article/pii/S0950584921001051,A decision model for programming language ecosystem selection: Seven industry case studies,Slinger=Jansen: slinger.jansen@uu.nl; Siamak=Farshidi: s.farshidi@uva.nl; Mahdi=Deldar: m.deldar@datakavosh.com,"Abstract
Context:
Software development is a continuous decision-making process that mainly relies on the software engineer’s experience and intuition. One of the essential decisions in the early stages of the process is selecting the best fitting programming language ecosystem based on the project requirements. A significant number of criteria, such as developer availability and consistent documentation, in addition to the number of available options in the market, lead to a challenging decision-making process. As the selection of programming language ecosystems depends on the application to be developed and its environment, a decision model is required to analyze the selection problem using systematic identification and evaluation of potential alternatives for a development project.
Method:
Recently, we introduced a framework to build decision models for technology selection problems in software production. Furthermore, we designed and implemented a decision support system that uses such decision models to support software engineers with their decision-making problems. This study presents a decision model based on the framework for the programming language ecosystem selection problem.
Results:
The decision model has been evaluated through seven real-world 
case studies
 at seven software development companies. The case study participants declared that the approach provides significantly more insight into the programming language ecosystem selection process and decreases the decision-making process’s time and cost.
Conclusion:
With the decision model, software engineers can more rapidly evaluate and select programming language ecosystems. Having the knowledge in the decision model readily available supports software engineers in making more efficient and effective decisions that meet their requirements and priorities. Furthermore, such reusable knowledge can be employed by other researchers to develop new concepts and solutions for future challenges.",November 2021,"Programming language ecosystem selection, Decision model, Industry case study, Software production, Multi-criteria decision-making, Decision support system",Information and Software Technology,2025-03-18T00:00:00,9.0,The decision support system for programming language ecosystem selection can greatly benefit early-stage ventures by optimizing decision-making processes and reducing time and cost.
https://www.sciencedirect.com/science/article/pii/S0950584921001038,Automatic patch linkage detection in code review using textual content and file location features,Dong=Wang: wang.dong.vt8@is.naist.jp,"Abstract
Context:
Contemporary code review tools are a popular choice for 
software quality assurance
. Using these tools, reviewers are able to post a 
linkage
 between two patches during a review discussion. Large development teams that use a review-then-commit model risk being unaware of these linkages.
Objective:
Our objective is to first explore how patch linkage impacts the review process. We then propose and evaluate models that detect patch linkage based on realistic time intervals.
Method:
First, we carry out an 
exploratory study
 on three 
open source projects
 to conduct linkage impact analysis using 942 manually classified linkages. Second, we propose two techniques using textual and file location similarity to build detection models and evaluate their performance.
Results:
The study provides evidence of latency in the linkage notification. We show that a patch with the Alternative Solution linkage (i.e., patches that implement similar functionality) undergoes a quicker review and avoids additional revisions after the team has been notified, compared to other linkage types. Our detection model experiments show promising recall rates for the Alternative Solution linkage (from 32% to 95%), but precision has room for improvement.
Conclusion:
Patch linkage detection is promising, with likely improvements if the practice of posting linkages becomes more prevalent. From our implications, this paper lays the groundwork for future research on how to increase patch linkage awareness to facilitate efficient reviews.",November 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on patch linkage detection addresses a practical issue in software quality assurance, but the direct impact on European early-stage ventures may be moderate."
https://www.sciencedirect.com/science/article/pii/S0950584921001166,ALBFL: A novel neural ranking model for software fault localization via combining static and dynamic features,Xi=Xiao: xiaox@sz.tsinghua.edu.cn; Yuqing=Pan: 66panyuqing@sina.com; Bin=Zhang: bin.zhang@pcl.ac.cn; Guangwu=Hu: hugw@sziit.edu.cn; Qing=Li: liq8@sustech.edu.cn; Runiu=Lu: lurn@sz.singhua.edu.cn,"Abstract
Context
Automatic 
software fault
 localization serves as a significant purpose in helping developers solve bugs efficiently. Existing approaches for software 
fault localization
 can be categorized into static methods and dynamic ones, which have improved the fault locating ability greatly by analyzing static features from the 
source code
 or tracking dynamic behaviors during the runtime respectively. However, the accuracy of 
fault localization
 is still unsatisfactory.
Objective
To enhance the capability of detecting software faults with the statement 
granularity
, this paper puts forward ALBFL, a novel neural ranking model that combines the static and dynamic features, which obtains excellent fault 
localization accuracy
. Firstly, ALBFL learns the 
semantic features
 of the 
source code
 by a transformer encoder. Then, it exploits a self-attention layer to integrate those static features and dynamic features. Finally, those integrated features are fed into a LambdaRank model, which can list the suspicious statements in 
descending order
 by their ranked scores.
Method
The experiments are conducted on an authoritative dataset (i.e., Defect4J), which includes 5 open-source projects, 357 faulty programs in total. We evaluate the effectiveness of ALBFL, effectiveness of combining features, effectiveness of model components and aggregation on method level.
Result
The results reflect that ALBFL identifies triple more faulty statements than 11 traditional 
SBFL methods
 and outperforms 2 state-of-the-art approaches by on average 14% on ranking faults in the first position.
Conclusions
To improve the precision of automatic 
software fault
 localization, ALBFL combines 
neural network
 ranking model equipped with the self-attention layer and the transformer encoder, which can take full use of various techniques to judge whether a code statement is fault-inducing or not. Moreover, the 
joint
 architecture of ALBFL is capable of training the integration of these features under various strategies so as to improve accuracy further. In the future, we plan to exploit more features so as to improve our method's efficiency and accuracy.",November 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The ALBFL model for software fault localization presents a novel approach that can significantly improve bug solving efficiency, which is crucial for startups dealing with limited resources."
https://www.sciencedirect.com/science/article/pii/S0950584921001282,Architectural design decisions that incur technical debt — An industrial case study,Paris=Avgeriou: p.avgeriou@rug.nl; Mohamed=Soliman: m.a.m.soliman@rug.nl; Yikun=Li: yikun.li@rug.nl,"Abstract
Context:
During software development, some 
architectural design decisions
 incur technical debt, either deliberately or inadvertently. These have serious impact on the quality of a software system, and can cost significant time and effort to be changed. While current research efforts have explored general concepts of architectural design decisions and technical debt separately, debt-incurring architectural design decisions have not been specifically explored in practice.
Objective:
In this 
case study
, we explore debt-incurring architectural design decisions (DADDs) in practice. Specifically, we explore the main types of DADDs, why and how they are incurred in a software system, and how practitioners deal with these types of design decisions.
Method:
We performed interviews and a focus group with practitioners working in embedded and enterprise software companies, discussing their concrete experience with such architectural design decisions.
Results:
We provide the following contributions: 1) A categorization for the types of DADDs, which extend a current ontology on architectural design decisions. 2) A process on how deliberate DADDs are made in practice. 3) A conceptual model which shows the relationships between the causes and triggers of inadvertent DADDs. 4) The main factors that influence the way of dealing with DADDs.
Conclusion:
The results can support the development of new approaches and tools for Architecture Technical Debt management from the perspective of Design Decisions. Moreover, they support future research to capture architecture knowledge related to DADDs.",November 2021,"Technical debt, Architectural design decisions, Architectural knowledge, Architectural technical debt",Information and Software Technology,2025-03-18T00:00:00,9.0,The exploration of debt-incurring architectural design decisions in practice can greatly benefit software development by providing insights into how to manage technical debt effectively.
https://www.sciencedirect.com/science/article/pii/S0950584921001269,“Won’t We Fix this Issue?” Qualitative characterization and automated identification of wontfix issues on GitHub,Gerardo=Canfora: canfora@unisannio.it; Andrea=Di Sorbo: disorbo@unisannio.it; Sebastiano=Panichella: panc@zhaw.ch,"Abstract
Context
: Addressing user requests in the form of 
bug reports
 and Github issues represents a crucial task of any successful software project. However, user-submitted issue reports tend to widely differ in their quality, and developers spend a considerable amount of time handling them.
Objective
: By collecting a dataset of around 6,000 issues of 279 GitHub projects, we observe that developers take significant time (i.e., about five months, on average) before labeling an issue as a wontfix. For this reason, in this paper, we empirically investigate the nature of wontfix issues and methods to facilitate issue management process.
Method
: We first manually analyze a sample of 667 wontfix issues, extracted from heterogeneous projects, investigating the common reasons behind a “wontfix decision”, the main characteristics of wontfix issues and the potential factors that could be connected with the time to close them. Furthermore, we experiment with approaches enabling the prediction of wontfix issues by analyzing the titles and descriptions of reported issues when submitted.
Results and conclusion
: Our investigation sheds some light on the wontfix issues’ characteristics, as well as the potential factors that may affect the time required to make a “wontfix decision”. Our results also demonstrate that it is possible to perform prediction of wontfix issues with high average values of precision, recall, and F-measure (90%–93%).",November 2021,"Issue tracking, Issue management, Empirical study, Machine learning",Information and Software Technology,2025-03-18T00:00:00,7.0,The empirical investigation of wontfix issues in software projects can help streamline the issue management process and improve overall efficiency in handling user-submitted reports.
https://www.sciencedirect.com/science/article/pii/S0950584921001294,On the value of encouraging gender tolerance and inclusiveness in software engineering communities,Sherlock A.=Licorish: sherlock.licorish@otago.ac.nz,"Abstract
Context
The recent spike in the growth of online communities is a testament to the technological advancements of the 21st century. People with shared interests, problems, and solutions can now engage via online groups, including the 
software engineering
 community. There is evidence, however, to suggest females are often underrepresented in such online communities, and especially those that are technology related. This comes at a great loss to these communities, and for 
software engineering
 in particular. Females, like males, add much value to the field of software engineering.
Objective
Limited evidence exists to quantify the value of males and females in the software engineering process or relevant communities. This insight could inform evidence-driven inclusiveness strategies. Accordingly, we sought to better understand 
gender differences
 in the Stack Overflow community in order to delineate the value of 
gender diversity
 in the field of software engineering.
Method
This study used 
archival data
 from Stack Overflow over an 11-year period, comprising records from 9.5 million contributors. We employed quantitative and qualitative approaches to examine the role of gender in terms of contributors’ orientation, attitudes, and 
knowledge sharing
 patterns.
Results
The results indicate female contributors on Stack Overflow differed significantly from males in relation to their orientation, attitudes, and 
knowledge sharing
 patterns. We observe that female contributors tend to have a more cooperative orientation. Additionally, females expressed a more supportive and collective outlook and were more willing to share knowledge than their male counterparts.
Conclusion
The software engineering community would benefit from gender tolerance and inclusiveness to promote a knowledge sharing culture. In this regard, 
gender diversity
 should be encouraged for the value it brings to Stack Overflow and the field of software engineering.",November 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on gender differences in the software engineering community sheds light on the importance of gender diversity, although the practical impact on startups may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584921000914,On the impact of Continuous Integration on refactoring practice: An exploratory study on TravisTorrent,Fabio=Palomba: fpalomba@unisa.it; Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Islem=Saidani: islem.saidani.1@ens.etsmlt.ca,"Abstract
Context:
The ultimate goal of Continuous Integration (CI) is to support developers in integrating changes into production constantly and quickly through automated build process. While CI provides developers with prompt feedback on several quality dimensions after each change, such frequent and quick changes may in turn compromise software quality without Refactoring. Indeed, recent work emphasized the potential of CI in changing the way developers perceive and apply refactoring. However, we still lack empirical evidence to confirm or refute this assumption.
Objective:
We aim to explore and understand the evolution of refactoring practices, in terms of frequency, size and involved developers, after the switch to CI in order to emphasize the role of this process in changing the way Refactoring is applied.
Method:
We collect a corpus of 99,545 commits and 89,926 
refactoring operations
 extracted from 39 open-source GitHub projects that adopt Travis CI and analyze the changes using Multiple Regression Analysis (MRA).
Results:
Our study delivers several important findings. We found that the adoption of CI is associated with a drop in the refactoring size as recommended, while refactoring frequency as well as the number (and its related rate) of developers that perform refactoring are estimated to decrease after the shift to CI, indicating that refactoring is less likely to be applied in CI context.
Conclusion:
Our study uncovers insights about CI theory and practice and adds evidence to existing knowledge about CI practices related especially to quality assurance. Software developers need more customized refactoring tool support in the context of CI to better maintain and evolve their software systems.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The examination of refactoring practices in the context of Continuous Integration provides valuable insights, but the practical implications on early-stage ventures may be less direct."
https://www.sciencedirect.com/science/article/pii/S0950584921000963,Why many challenges with GUI test automation (will) remain,Michel=Nass: michel.nass@bth.se; Emil=Alégroth: emil.alegroth@bth.se; Robert=Feldt: robert.feldt@chalmers.se,"Abstract
Context:
Automated testing is ubiquitous in modern software development and used to verify requirement conformance on all levels of system abstraction, including the system’s graphical user interface (GUI). GUI-based test automation, like other automation, aims to reduce the cost and time for testing compared to alternative, manual approaches. Automation has been successful in reducing costs for other forms of testing (like unit- or integration testing) in industrial practice. However, we have not yet seen the same convincing results for automated GUI-based testing, which has instead been associated with multiple 
technical challenges
. Furthermore, the software industry has struggled with some of these challenges for more than a decade with what seems like only limited progress.
Objective:
This systematic literature review takes a longitudinal perspective on GUI test automation challenges by identifying them and then investigating why the field has been unable to mitigate them for so many years.
Method:
The review is based on a final set of 49 publications, all reporting empirical evidence from practice or industrial studies. Statements from the publications are synthesized, based on a thematic coding, into 24 challenges related to GUI test automation.
Results:
The most reported challenges were mapped chronologically and further analyzed to determine how they and their proposed solutions have evolved over time. This chronological mapping of reported challenges shows that four of them have existed for almost two decades.
Conclusion:
Based on the analysis, we discuss why the key challenges with GUI-based test automation are still present and why some will likely remain in the future. For others, we discuss possible ways of how the challenges can be addressed. Further research should focus on finding solutions to the identified 
technical challenges
 with GUI-based test automation that can be resolved or mitigated. However, in parallel, we also need to acknowledge and try to overcome non-technical challenges.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The research on GUI test automation challenges is relevant, but the focus on a niche technical aspect may limit its immediate practical value for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921000987,Metamorphic testing of OpenStreetMap,Manuel=Núñez: mn@sip.ucm.es; Jesús M.=Almendros-Jiménez: jalmen@ual.es; Antonio=Becerra-Terón: abecerra@ual.es; Mercedes G.=Merayo: mgmerayo@fdi.ucm.es,"Abstract
Context:
OpenStreetMap represents a collaborative effort of many different and unrelated users to create a free map of the world. Although contributors follow some general guidelines, unsupervised additions are prone to include erroneous information. Unfortunately, it is impossible to automatically detect most of these issues because there does not exist an 
oracle
 to evaluate whether the information is correct or not. Metamorphic testing has shown to be very useful in assessing the correctness of very heterogeneous artifacts when oracles are not available.
Objective:
The main goal of our work is to provide a (fully implemented) framework, based on metamorphic testing, that will support the analysis of the information provided in OpenStreetMap with the goal of detecting 
faulty
 information.
Method:
We defined a general metamorphic testing framework to deal with OpenStreetMap. We identified a set of 
good
 metamorphic relations. In order to have as much automation as possible, we paid 
special attention
 to the automatic selection of 
follow-up inputs
 because they are fundamental to diminish manual testing. In order to assess the usefulness of our framework, we applied it to analyze maps of four cities in different continents. The rationale is that we would be dealing with different problems created by different contributors.
Results:
We obtained experimental evidence that shows the potential value of our framework. The application of our framework to the analysis of the chosen cities revealed errors in all of them and in all the considered categories.
Conclusion:
The experiments showed the usefulness of our framework to identify potential issues in the information appearing in OpenStreetMap. Although our metamorphic relations are very helpful, future users of the framework might identify other relations to deal with specific situations not covered by our relations. Since we provide a general pattern to define metamorphic relations, it is relatively easy to extend the existing framework. In particular, since all our metamorphic relations are implemented and the code is freely available, users have a pattern to implement new relations.",October 2021,"Metamorphic testing, Quality of maps, OpenStreetMap",Information and Software Technology,2025-03-18T00:00:00,8.0,The framework for detecting faulty information in OpenStreetMap using metamorphic testing has practical implications for startups needing data quality assurance in their applications.
https://www.sciencedirect.com/science/article/pii/S0950584921001014,Automating user-feedback driven requirements prioritization,Fitsum Meshesha=Kifetew: kifetew@fbk.eu; Anna=Perini: perini@fbk.eu; Angelo=Susi: susi@fbk.eu; Aberto=Siena: siena@fbk.eu; Denisse=Muñante: denisse_yessica.munante_arzapalo@telecom-sudparis.eu; Itzel=Morales-Ramirez: imoralesr@iingen.unam.mx,"Abstract
Context:
Feedback from end users of 
software applications
 is a valuable resource in understanding what users request, what they value, and what they dislike. Information derived from user-feedback can support software evolution activities, such as requirements prioritization. User-feedback analysis is still mostly performed manually by practitioners, despite growing research in automated analysis.
Objective:
We address two issues in automated user-feedback analysis: (i) most of the existing automated analysis approaches that exploit 
linguistic analysis
 assume that the vocabulary adopted by users (when expressing feedback) and developers (when formulating requirements) are the same; and (ii) user-feedback analysis techniques are usually experimentally evaluated only on some user-feedback dataset, not involving assessment by potential software developers.
Method:
We propose an approach, 
ReFeed
, that computes, for each requirement, the set of related user-feedback, and from such user-feedback extracts quantifiable properties which are relevant for prioritizing the requirement. The extracted properties are propagated to the 
related requirements
, based on which ranks are computed for each requirement. 
ReFeed
 relies on domain knowledge, in the form of an ontology, helping mitigate the gap in the vocabulary of end users and developers. The effectiveness of 
ReFeed
 is evaluated on a realistic requirements prioritization scenario in two experiments involving graduate students from two different universities.
Results:
ReFeed
 is able to synthesize reasonable priorities for a given set of requirements based on properties derived from user-feedback. The implementation of 
ReFeed
 and related resources are publicly available.
Conclusion:
The results from our studies are encouraging in that using only three properties of user-feedback, 
ReFeed
 is able to prioritize requirements with reasonable accuracy. Such automatically determined prioritization could serve as a 
good starting point
 for requirements experts involved in the task of prioritizing requirements Future studies could explore additional user-feedback properties to improve the effectiveness of computed priorities.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"Automated user-feedback analysis can benefit software evolution activities, but the specific approach discussed may require further validation for wider applicability in European startups."
https://www.sciencedirect.com/science/article/pii/S0950584921000975,Convergence rate of Artificial Neural Networks for estimation in software development projects,Dragica=Rankovic: drankovic@raf.rs,"Abstract
Context:
Nowadays, companies are investing in brand new software, given that fact they always need help with 
estimating software
 development, effort, costs, and the period of time needed for completing the software itself. In this paper, four different architectures of 
Artificial Neural Networks
 (ANN), as one of the most desired tools for predicting and estimating effort in software development, were used.
Objective:
This paper aims to determine the 
convergence rate of
 each of the proposed ANNs, when obtaining the minimum 
relative error
, first depending on the cost effect function, then on the nature of the data on which the training, testing, and validation is performed.
Method:
Magnitude 
relative error
 (MRE) is calculated based on Taguchi’s orthogonal plans for each of these four proposed 
ANN architectures
. The 
fuzzification
 method, five different datasets, the 
clustering method
 for input values of each dataset, and prediction were used to achieve the best model for estimation.
Results:
Based on performed parts of the experiment, it can be concluded that the convergence rate of each proposed architecture depends on the cost effect function and the nature of projects in different datasets. By following the prediction throughout all experimental parts, it can be further confirmed that ANN-L36 gave the best results in this proposed approach.
Conclusion:
The main advantages of this model are as follows: the number of iterations is less than 10, shortened effort estimation time thanks to convergence rate, simple architecture of each proposed ANN, large coverage of different values of actual project efficiency, and minimal MMRE. This model can also serve as an idea for the construction of a tool that would be able to reliably, efficiently and accurately estimate the effort when developing various software projects.",October 2021,"Software effort estimation, Convergence rate, Taguchi Orthogonal Arrays, Artificial Neural Networks design, Fuzzification, Clustering",Information and Software Technology,2025-03-18T00:00:00,7.0,The study on estimating software development effort using Artificial Neural Networks offers valuable insights for startups seeking to enhance their project planning and estimation processes.
https://www.sciencedirect.com/science/article/pii/S0950584921001129,Code smell detection using feature selection and stacking ensemble: An empirical investigation,Amal=Alazba: aalazba@ksu.edu.sa; Hamoud=Aljamaan: hjamaan@kfupm.edu.sa,"Abstract
Context:
Code smell detection is the process of identifying code pieces that are poorly designed and implemented. Recently more research has been directed towards machine learning-based approaches for code smells detection. Many classifiers have been explored in the literature, yet, finding an effective model to detect different code smells types has not yet been achieved.
Objective:
The main objective of this paper is to empirically investigate the capabilities of stacking heterogeneous ensemble model in code smell detection.
Methods:
Gain feature selection technique was applied to select relevant features in code smell detection. Detection performance of 14 
individual classifiers
 was investigated in the context of two class-level and four method-level code smells. Then, three stacking ensembles were built using all 
individual classifiers
 as 
base classifiers
, and three different meta-classifiers (LR, SVM and DT).
Results:
GP, MLP, DT and SVM(Lin) classifiers were among the best performing classifiers in detecting most of the code smells. On the other hand, SVM(Sig), NB(B), NB(M), and SGD were among the least accurate classifiers for most smell types. The stacking ensemble with LR and SVM meta-classifiers achieved a consistent high detection performance in class-level and method-level code smells compared to all individual models.
Conclusion:
This paper concludes that the detection performance of the majority of individual classifiers varied from one code smell type to another. However, the detection performance of the stacking ensemble with LR and SVM meta-classifiers was consistently superior over all individual classifiers in detecting different code smell types.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The research on stacking ensemble model in code smell detection has practical implications for improving code quality in early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584921000926,Icon2Code: Recommending code implementations for Android GUI components,Li=Li: Li.Li@monash.edu,"Abstract
Context:
Event-driven programming plays a crucial role in implementing GUI-based software systems such as 
Android
 apps. However, such event-driven code is inherently challenging to design and implement correctly. Despite a significant amount of research to help developers efficiently implement such software, improved approaches are still needed to assist developers in better handling events and associated callback methods.
Objective:
This work aims at inventing an intelligent recommendation system for helping app developers efficiently and effectively implement 
Android
 GUI components.
Methods:
To achieve the aforementioned objective, we introduce in this work a novel approach called Icon2Code. Given an icon or UI widget provided by designers as input, Icon2Code first searches from a large-scale app database to locate similar icons used in existing popular apps. It then learns from the implementation of these similar apps and leverages a collaborative filtering model to select and recommend the most relevant APIs.
Results:
Our approach can achieve an 81% success rate when only five recommended APIs are considered, and a 94% success rate if twenty results are considered, based on ten-fold cross-validation with a large-scale dataset containing over 45,000 icons and their code implementations.
Conclusion:
It is feasible to automatically recommend code implementations for Android GUI components and Icon2Code is useful and effective in helping achieve such an objective.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The intelligent recommendation system for Android GUI components can greatly benefit startups in developing efficient apps.
https://www.sciencedirect.com/science/article/pii/S0950584921000872,TIDY: A PBE-based framework supporting smart transformations for entity consistency in PowerPoint,Shuguan=Liu: liu_shuguan@126.com; Huiyan=Wang: cocowhy1013@gmail.com; Chang=Xu: changxu@nju.edu.cn,"Abstract
Context:
Programming by Example (PBE) is increasingly assisting human users by recognizing and executing repetitive tasks, such as text editing and spreadsheet manipulation. Yet, existing work falls short on dealing with rich-formatted documents like PowerPoint (PPT) files, when examples are few and collecting them is intrusive.
Objective:
This article presents 
TIDY
, a PBE-based framework, to assist automated entity transformations for their layout and style consistency in rich-formatted documents like PowerPoint, in a way adaptive to entity contexts and flexible with user selections.
Methods:
TIDY
 achieves this by examining entities’ operation histories, and proposes a two-stage framework to first identify user intentions behind histories and then make wise next-operation recommendations for users, in order to maintain the entity consistency for rich-formatted documents.
Results:
We implemented 
TIDY
 as a prototype tool and integrated it into PowerPoint as a plug-in module. We experimentally evaluated 
TIDY
 with real-world user operation data. The evaluation reports that 
TIDY
 achieved promising effectiveness with a hit rate of 77.3% on average, which was stably holding for a variety of editing tasks. Besides, 
TIDY
 took only marginal time overhead, costing several to several tens of milliseconds, to complete each recommendation.
Conclusion:
TIDY
 assists users to complete repetitive tasks in rich-formatted documents by non-intrusive user intention recognition and smart next-operation recommendations, which is effective and practically useful.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The PBE-based framework for rich-formatted documents like PowerPoint can streamline tasks for startups and early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584921000859,Analyzing privacy policies through syntax-driven semantic analysis of information types,Mitra Bokaei=Hosseini: mbokaeihossein@stmarytx.edu; Travis D.=Breaux: breaux@cs.cmu.edu; Rocky=Slavin: Rocky.Slavin@utsa.edu; Jianwei=Niu: Jianwei.Niu@utsa.edu; Xiaoyin=Wang: xiaoyin.wang@utsa.edu,"Abstract
Context:
Several government laws and app markets, such as Google Play, require the disclosure of app data practices to users. These data practices constitute critical privacy requirements statements, since they underpin the app’s functionality while describing how various personal information types are collected, used, and with whom they are shared.
Objective:
Abstract and ambiguous terminology in requirements statements concerning information types (e.g., “we collect your device information”), can reduce shared understanding among app developers, policy writers, and users.
Method:
To address this challenge, we propose a syntax-driven method that first parses a given information type phrase (e.g. mobile device identifier) into its constituents using a context-free grammar and second infers 
semantic relationships
 between constituents using semantic rules. The inferred 
semantic relationships
 between a given phrase and its constituents generate a hierarchy that models the generality and ambiguity of phrases. Through this method, we infer relations from a lexicon consisting of a set of information type phrases to populate a partial ontology. The resulting ontology is a knowledge graph that can be used to guide requirements authors in the selection of the most appropriate information type terms.
Results:
We evaluate the method’s performance using two criteria: (1) expert assessment of relations between information types; and (2) non-expert preferences for relations between information types. The results suggest 
performance improvement
 when compared to a previously proposed method. We also evaluate the reliability of the method considering the information types extracted from different data practices (e.g., collection, usage, sharing, etc.) in privacy policies for mobile or web-based apps in various app domains.
Contributions:
The method achieves average of 89% precision and 87% recall considering information types from various app domains and data practices. Due to these results, we conclude that the method can be generalized reliably in inferring relations and reducing the ambiguity and abstraction in privacy policies.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The syntax-driven method for inferring semantic relationships in privacy policies can aid startups in complying with data privacy regulations.
https://www.sciencedirect.com/science/article/pii/S0950584921000884,Overcoming cultural barriers to being agile in distributed teams,Darja=Šmite: Darja.Smite@bth.se; Nils Brede=Moe: Nils.B.Moe@bth.se; Javier=Gonzalez-Huerta: Javier.Gonzalez.Huerta@bth.se,"Abstract
Context:
 Agile methods in offshored projects have become increasingly popular. Yet, many companies have found that the use of agile methods in coordination with companies located outside the regions of early agile adopters remains challenging. 
India
 has received particular attention as the leading destination of offshoring contracts due to significant cultural differences between sides of such contracts. Alarming differences are primarily rooted in the hierarchical business culture of Indian organizations and related command-and-control management behavior styles.
Objective:
 In this study, we attempt to understand whether cultural barriers persist in distributed projects in which Indian engineers work with a more empowering Swedish management, and if so, how to overcome them. The present work is an invited extension of a 
conference paper
.
Method:
 We performed a multiple-case study in a mature agile company located in Sweden and a more hierarchical Indian vendor. We 
collected data
 from five group interviews with a total of 34 participants and five workshops with 96 participants in five distributed 
DevOps
 teams, including 36 Indian members, whose preferred behavior in different situations we surveyed.
Results:
 We identified twelve cultural barriers, six of which were classified as impediments to 
agile software development
 practices, and report on the manifestation of these barriers in five 
DevOps
 teams. Finally, we put forward recommendations to overcome the identified barriers and emphasize the importance of 
cultural training
, especially when onboarding new team members.
Conclusions:
 Our findings confirm previously reported behaviors rooted in cultural differences that impede the adoption of agile approaches in offshore collaborations, and identify new barriers not previously reported. In contrast to the existing opinion that cultural characteristics are rigid and unchanging, we found that some barriers present at the beginning of the studied collaboration disappeared over time. Many offshore members reported behaving similarly to their onshore colleagues.",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"This study addresses cultural barriers in distributed agile projects involving Indian and Swedish teams, providing insights and recommendations which could be valuable for European startups working with offshoring contracts."
https://www.sciencedirect.com/science/article/pii/S0950584921000860,Grey Literature in Software Engineering: A critical review,Fernando=Kamei: fernando.kenji@ifal.edu.br,"Abstract
Context:
Grey Literature (GL) recently has grown in 
Software Engineering
 (SE) research since the increased use of online communication channels by software engineers. However, there is still a limited understanding of how SE research is taking advantage of GL.
Objective:
This research aimed to understand how SE researchers use GL in their secondary studies.
Methods:
We conducted a tertiary study of studies published between 2011 and 2018 in high-quality software engineering conferences and journals. We then applied qualitative and 
quantitative analysis
 to investigate 446 potential studies.
Results:
From the 446 selected studies, 126 studies cited GL but only 95 of those used GL to answer a specific research question representing almost 21% of all the 446 secondary studies. Interestingly, we identified that few studies employed specific search mechanisms and used additional criteria for assessing GL. Moreover, by the time we conducted this research, 49% of the GL URLs are not working anymore. Based on our findings, we discuss some challenges in using GL and potential 
mitigation plans
.
Conclusion:
In this paper, we summarized the last 10 years of software engineering research that uses GL, showing that GL has been essential for bringing practical new perspectives that are scarce in traditional literature. By drawing the current landscape of use, we also raise some awareness of related challenges (and strategies to deal with them).",October 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study on the use of Grey Literature in Software Engineering research is interesting, its direct impact on practical aspects for European early-stage ventures might be limited."
https://www.sciencedirect.com/science/article/pii/S0950584921000689,Joint feature representation learning and progressive distribution matching for cross-project defect prediction,Quanyi=Zou: zouquanyi2010@163.com; Lu=Lu: lul@scut.edu.cn; Zhanyu=Yang: yangzhanyu@hotmail.com; Xiaowei=Gu: amyxwgu@163.com; Shaojian=Qiu: qiushaojian@outlook.com,"Abstract
Context:
Cross-Project 
Defect Prediction
 (CPDP) aims to leverage the knowledge from label-rich source software projects to promote tasks in a label-poor target software project. Existing CPDP methods have two major flaws. One is that previous CPDP methods only consider global feature representation and ignores local relationship between instances in the same category from different projects, resulting in ambiguous predictions near the decision boundary. The other one is that CPDP methods based on pseudo-labels assume that the conditional distribution can be well matched at one stroke, when instances of target project are correctly annotated pseudo labels. However, due to the great gap between projects, the pseudo-labels seriously deviate from the real labels.
Objective:
To address above issues, this paper proposed a novel CPDP method named 
Joint
 Feature Representation with Double Marginalized 
Denoising
 
Autoencoders
 (DMDA_JFR).
Method:
Our method mainly includes two parts: joint feature 
representation learning
 and progressive distribution matching. We utilize two novel 
autoencoders
 to jointly learn the global and 
local feature
 representations simultaneously. To achieve progressive distribution matching, we introduce a repetitious pseudo-labels strategy, which makes it possible that distributions are matched after each stack layer learning rather than in one stroke.
Results:
The effectiveness of the proposed method was evaluated through experiments conducted on 10 open-source projects, including 29 software releases from PROMISE repository. Overall, experimental results show that our proposed method outperformed several state-of-the-art baseline CPDP methods.
Conclusions:
It can be concluded that (1) joint deep representations are promising for CPDP compared with only considering global feature representation methods, (2) progressive distribution matching is more effective for adapting probability distributions in CPDP compared with existing CPDP methods based on pseudo-labels.",September 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed CPDP method introduces novel techniques that could enhance defect prediction practices in software projects, offering potential benefits to European startups focusing on software development."
https://www.sciencedirect.com/science/article/pii/S0950584921000823,Leveraging developer information for efficient effort-aware bug prediction,Yu=Qu: yuq@ucr.edu; Jianlei=Chi: chijianlei@stu.xjtu.edu.cn; Heng=Yin: hengy@ucr.edu,"Abstract
Context:
Software bug prediction techniques can provide informative guidance in 
software engineering
 practices. Over the past 15 years, developer information has been intensively used in bug prediction as features or basic 
data source
 to construct other useful models.
Objective:
Further leverage developer information from a new and straightforward perspective to improve effort-aware bug prediction.
Methods:
We propose to investigate the direct relations between the number of developers and the probability for a file to be buggy. Based on an empirical study on nine open-source Java systems with 32 versions, we observe a widely-existed and interesting tendency: when there are more developers working on a source file, there will be a stronger possibility for this file to be buggy. Based on the observed tendency, we propose an unsupervised algorithm and a supervised equation both called 
top-dev
 to improve effort-aware bug prediction. The key idea is to prioritize the ranking of files, whose number of developers is large, in the suspicious file list generated by effort-aware models.
Results:
Experimental results show that the proposed 
top-dev
 algorithm and equation significantly outperform the unsupervised and supervised 
baseline models
 (ManualUp, 
R
a
d
, 
R
d
d
, 
R
e
e
, CBS+, and 
top-core
). Moreover, the unsupervised 
top-dev
 algorithm is comparable or superior to existing supervised 
baseline models
.
Conclusion:
The proposed approaches are very useful in effort-aware bug prediction practices. Practitioners can use the 
top-dev
 algorithm to generate a high-quality and informative suspicious file list without training complex 
machine learning
 classifiers. On the other hand, when building supervised bug prediction model, the best practice is to combine existing models with the 
top-dev
 equation.",September 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The investigation on leveraging developer information for bug prediction provides practical insights and proposed approaches that could benefit European early-stage ventures in improving bug prediction practices.
https://www.sciencedirect.com/science/article/pii/S0950584921000811,"How do developers discuss and support new programming languages in technical Q&A site? An empirical study of Go, Swift, and Rust in Stack Overflow",Gias=Uddin: gias.uddin@ucalgary.ca,"Abstract
Context:
New programming languages (e.g., Swift, Go, Rust, etc.) are being introduced to provide a better opportunity for the developers to make software development robust and easy. At the early stage, a programming language is likely to have 
resource constraints
 that encourage the developers to seek help frequently from experienced peers active in Question–Answering (QA) sites such as Stack Overflow (SO).
Objective:
In this study, we have formally studied the discussions on three popular new languages introduced after the inception of SO (2008) and match those with the relevant activities in GitHub whenever appropriate. For that purpose, we have mined 4,17,82,536 questions and answers from SO and 7,846 issue information along with 6,60,965 
repository information
 from Github. Initially, the development of new languages is relatively slow compared to mature languages (e.g., C, C++, Java). The expected outcome of this study is to reveal the difficulties and challenges faced by the developers working with these languages so that appropriate measures can be taken to expedite the generation of relevant resources.
Method:
We have used the 
Latent Dirichlet Allocation
 (LDA) method on SO’s questions and answers to identify different topics of new languages. We have extracted several features of the answer pattern of the new languages from SO (e.g., time to get an accepted answer, time to get an answer, etc.) to study their characteristics. These attributes were used to identify difficult topics. We explored the background of developers who are contributing to these languages. We have created a model by combining Stack Overflow data and issues, repository, user data of Github. Finally, we have used that model to identify factors that affect language evolution.
Results:
The major findings of the study are: (i) migration, data and 
data structure
 are generally the difficult topics of new languages, (ii) the time when adequate resources are expected to be available vary from language to language, (iii) the unanswered question ratio increases regardless of the age of the language, and (iv) there is a relationship between developers’ activity pattern and the growth of a language.
Conclusion:
We believe that the outcome of our study is likely to help the owner/sponsor of these languages to design better features and documentation. It will also help the software developers or students to prepare themselves to work on these languages in an informed way.",September 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides valuable insights into the challenges faced by developers working with new programming languages, which can help improve language features and documentation. This can be beneficial for early-stage ventures looking to adopt new technologies."
https://www.sciencedirect.com/science/article/pii/S095058492100080X,Source Code Transformations for Improving Security of Time-bounded K-variant Systems,Berk=Bekiroglu: bbekirog@iit.edu,"Abstract
Context
Source code transformation techniques can improve the security of systems against memory exploitation attacks. As such, the chance of exploitation of 
security vulnerabilities
 can be decreased by using different controlled source code transformation techniques. In K-variant architecture, multiple variants of a program are generated through a controlled source code transformation to improve the security of systems.
Objective
To investigate the effectiveness and practicality of source code program transformations in improving the security of time-bounded K-variant systems for memory exploitation attacks.
Method
The effectiveness of program transformations in improving the security of time-bounded K-variant systems is experimentally investigated for different memory attacks.
Results
The results suggest that generating multiple variants using the presented transformations significantly improves the survivability of time-bounded K-variant systems under memory exploitation attacks.
Conclusion
We conclude that generating multi-variants in time-bounded K-variant systems in accordance with the presented program transformations may improve the security of time-bounded K-variant systems significantly for memory exploitation attacks with a reasonable cost and overhead.",September 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The investigation on source code transformation techniques for improving security against memory exploitation attacks has practical implications for startups concerned about system security. The findings suggest significant improvements in survivability under attacks.
https://www.sciencedirect.com/science/article/pii/S0950584921000835,Phase-wise migration of multiple legacy applications–A graph-theoretic approach,Rohit=Punnoose: r14012@astra.xlri.ac.in; Supriya Kumar=De: skde@xlri.ac.in,"Abstract
Context
Many organizations undertake large-scale projects of application migration due to availability of scalable and cost-efficient technologies. Such legacy application migration projects are very complex since the process involves in-depth profiling of the applications.
Objective
During the initial profiling phase, it is imperative to understand the underlying complexities of individual applications, as well as the interdependencies among applications in the organization. This analysis phase can take considerable time and effort, depending on number and complexity of the applications. The main goal of this paper is to provide a framework that provides a cost-effective and quick approach to study the interdependencies between legacy applications with minimal prior knowledge of application usage.
Method
In this paper, we propose a framework that uses community 
detection algorithms
 and other established techniques from graph theory, to discover interdependencies of legacy applications within an organization, group these highly interdependent legacy applications in clusters, and finally sequence the clusters for migration to a modern platform. We study the proposed framework through three case studies, using network datasets from a large US organization.
Results
The experimental results from the proposed framework suggests that legacy applications can be grouped into clusters with high interdependencies between each other. Also, the framework shows how organizations can then appropriately sequence the clusters of legacy applications into a phase-wise migration project, thereby reducing migration costs.
Conclusion
The proposed framework provides a valuable design input to organizations on how to determine the interdependencies between the various legacy applications that are in scope for migration to a modern platform. Such large-scale migration projects can be simplified and broken down to use a systematic approach, thereby reducing migration costs and data integrity challenges.",September 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The framework proposed for legacy application migration can help organizations understand application interdependencies and reduce costs. While not directly focused on startups, the approach could be valuable for early-stage ventures considering application migration."
https://www.sciencedirect.com/science/article/pii/S0950584921000720,The do’s and don’ts of infrastructure code: A systematic gray literature review,Fabio=Palomba: fpalomba@unisa.it; Damian A.=Tamburri: d.a.tamburri@tue.nl; Indika=Kumara: i.p.k.weerasingha.dewage@tue.nl; Martín=Garriga: m.garriga@uvt.nl; Angel Urbano=Romeu: a.urbanoromeu@uvt.nl; Dario=Di Nucci: d.dinucci@uvt.nl; Willem-Jan=van den Heuvel: w.j.a.m.vdnheuvel@uvt.nl,"Abstract
Context:
Infrastructure-as-code (IaC) is the 
DevOps
 tactic of managing and provisioning software infrastructures through machine-readable definition files, rather than manual 
hardware configuration
 or interactive configuration tools.
Objective:
From a maintenance and evolution perspective, the topic has picked the interest of practitioners and academics alike, given the 
relative scarcity
 of supporting patterns and practices in the academic literature. At the same time, a considerable amount of gray literature exists on IaC. Thus we aim to characterize IaC and compile a catalog of best and bad practices for widely used IaC languages, all using gray literature materials.
Method:
In this paper, we systematically analyze the industrial gray literature on IaC, such as blog posts, tutorials, white papers using qualitative analysis techniques.
Results:
We proposed a definition for IaC and distilled a broad catalog summarized in a taxonomy consisting of 10 and 4 primary categories for best practices and bad practices, respectively, both language-agnostic and language-specific ones, for three IaC languages, namely Ansible, Puppet, and Chef. The practices reflect implementation issues, design issues, and the violation of/adherence to the essential principles of IaC.
Conclusion:
Our findings reveal critical insights concerning the top languages as well as the best practices adopted by practitioners to address (some of) those challenges. We evidence that the field of development and maintenance IaC is in its infancy and deserves further attention.",September 2021,"Infrastructure-as-code, DevOps, Gray literature review",Information and Software Technology,2025-03-18T00:00:00,7.0,The catalog of best and bad practices for Infrastructure-as-code languages can provide valuable guidance for practitioners and academics. Early-stage ventures looking to adopt IaC practices could benefit from the insights and recommendations presented.
https://www.sciencedirect.com/science/article/pii/S0950584921000847,"Processes, challenges and recommendations of Gray Literature Review: An experience report",Guoping=Rong: ronggp@nju.edu.cn,"Abstract
Context:
Systematic Literature Review
 (SLR), as a tool of Evidence-Based 
Software Engineering
 (EBSE), has been widely used in 
Software Engineering
 (SE). However, for certain topics in SE, especially those that are trendy or 
industry
 driven, academic literature is generally scarce and consequently Gray Literature (GL) becomes a major source of evidence. In recent years, the adoption of Gray Literature Review (GLR) or Multivocal Literature Review (MLR) is rising steadily to provide the state-of-the-practice of a specific topic where SLR is not a viable option.
Objective:
Although some SLR guidelines recommend the use of GL and several MLR guidelines have already been proposed in SE, researchers still have conflicting views on the value of GL and commonly accepted GLR or MLR studies are generally lacking in terms of publication. This experience report aims to shed some light on GLR through a 
case study
 that uses SLR and MLR guidelines to conduct a GLR on an emerging topic in SE to specifically answer the questions related to the reasons of using GL, the processes of conducting GL, and the impacts of GL on review results.
Method:
We retrospect the review process of conducting a GLR on the topic of DevSecOps with reference to Kitchenham’s SLR and Garousi’s MLR guidelines. We specifically reflect on the processes we had to adapt in order to tackle the challenges we faced. We also compare and contrast our GLR with existing MLRs or GLRs in SE to contextualize our reflections.
Results:
We distill ten challenges in nine activities of a GLR process. We provide reasons for these challenges and further suggest ways to tackle them during a GLR process. We also discuss the decision process of selecting a suitable review methodology among SLR, MLR and GLR and elaborate the impacts of GL on our review results.
Conclusion:
Although our experience on GLR is mainly derived from a specific 
case study
 on DevSecOps, we conjecture that it is relevant and would be beneficial to other GLR or MLR studies. We also expect our experience would contribute to future GLR or MLR guidelines, in a way similar to how SLR guidelines learned from the SLR experience report a dozen years ago. In addition, other researchers may find our 
decision making process
 useful before they conduct their own reviews.",September 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study on Gray Literature Review (GLR) provides insights into conducting literature reviews in SE, the practical impact on early-stage ventures may not be immediate or significant."
https://www.sciencedirect.com/science/article/pii/S0950584921000707,Automated formalization of structured natural language requirements,Dimitra=Giannakopoulou: dimitra.giannakopoulou@nasa.gov; Thomas=Pressburger: tom.pressburger@nasa.gov; Anastasia=Mavridou: anastasia.mavridou@nasa.gov; Johann=Schumann: johann.m.schumann@nasa.gov,"Abstract
The use of structured natural languages to capture requirements provides a reasonable trade-off between ambiguous natural language and unintuitive 
formal notations
. There are two major challenges in making structured natural language amenable to formal analysis: (1) formalizing requirements as formulas that can be processed by analysis tools and (2) ensuring that the formulas conform to the semantics of the structured natural language. 
fretish
 is a structured natural language that incorporates features from existing research and from NASA applications. Even though 
fretish
 is quite expressive, its underlying semantics is determined by the types of four fields: 
scope
, 
condition
, 
timing
, and 
response
. Each combination of field types defines a template with Real-Time Graphical Interval Logic (RTGIL) semantics. We have developed a framework that constructs temporal logic formulas for each template compositionally, from its fields. The compositional nature of our algorithms facilitates maintenance and extensibility. Our goal is to be inclusive not only in terms of language expressivity, but also in terms of requirements analysis tools that we can interface with. For this reason we generate metric-temporal logic formulas with (1) exclusively future-time operators, over both finite and infinite traces, and (2) exclusively past-time operators. To establish trust in the produced formalizations for each template, our framework: (1) extensively tests the generated formulas against the template semantics and (2) proves equivalence between its past-time and future-time formulas. Our approach is available through the open-source tool 
fret
 and has been used to capture and analyze requirements for a Lockheed Martin Cyber–Physical System challenge.",September 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The development of a framework to construct temporal logic formulas for structured natural language requirements can potentially benefit startups by improving their requirements analysis processes.
https://www.sciencedirect.com/science/article/pii/S095058492100046X,Measuring the cognitive load of software developers: An extended Systematic Mapping Study,Lucian José=Gonçales: lucianj@edu.unisinos.br,"Abstract
Context:
Cognitive load in 
software engineering
 refers to the mental effort users spend while reading software artifacts. The cognitive load can vary according to tasks and across developers. Researchers have measured developers’ cognitive load for different purposes, such as understanding its impact on productivity and software quality. Thus, researchers and practitioners can use cognitive load measures for solving many aspects of 
software engineering
 problems.
Problem:
However, a lack of a classification of dimensions on cognitive load measures in software engineering makes it difficult for researchers and practitioners to obtain research trends to advance 
scientific knowledge
 or apply it in software projects.
Objective:
This article aims to classify different aspects of cognitive load measures in software engineering and identify challenges for further research.
Method:
We conducted a 
Systematic Mapping Study
 (SMS), which started with 4,175 articles gathered from 11 search engines and then narrowed down to 63 primary studies.
Results:
Our main findings are: (1) 43% (27/63) of the primary studies focused on applying a combination of sensors; (2) 81% (51/63) of the selected works were validation studies; (3) 83% (52/63) of the primary studies analyzed cognitive load while developers performed programming tasks. Moreover, we created a 
classification scheme
 based on the answers to our research questions.
Conclusion:
despite the production of a significant amount of studies on cognitive load in software engineering, there are still many challenges to be solved in this particular field for effectively measuring the cognitive load in software engineering. Therefore, this work provided directions for future studies on cognitive load measurement in software engineering.",August 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The classification of cognitive load measures in software engineering is valuable for researchers and practitioners, but the direct impact on early-stage ventures may be limited in the short term."
https://www.sciencedirect.com/science/article/pii/S0950584921000550,BCI-CFI: A context-sensitive control-flow integrity method based on branch correlation integrity,Ye=Wang: daguoli415@163.com,"Abstract
Context
As part of the arms race, one emerging attack methodology has been control-hijacking attacks, e.g., return-oriented programming (ROP). Control-flow integrity (CFI) is a generic and effective defense against most control-hijacking attacks. However, existing CFI mechanisms have poor security as demonstrated by their equivalence class (EC) sizes, which are sets of targets that CFI policies cannot distinguish. Adversaries can choose an illegitimate control transfer within an EC that is included in the resulting 
CFG
 and incorrectly allowed by CFI protection policies.
Objective
The paper introduces a context-sensitive control-flow integrity method, which aims to improve the security of CFI and prevent ROP attacks.
Method
The paper presents BCI-CFI, a context-sensitive CFI technique based on branch correlation integrity (BCI), which can effectively break down EC sizes and improve the security of CFI. BCI-CFI takes the branch correlation relationship (i.e., a new type of context for CFI) as contextual information to refine the CFI policy and identify the BCI pairs in the target program via 
static analysis
. Furthermore, the paper introduces a state machine M
CFI
 for BCI-CFI to conduct target validation for the indirect control-flow transfer (ICT) instructions in the target program at runtime.
Results
Our results show that, (i) BCI-CFI prevented adversaries from manipulating the control data and launching ROP attacks, (ii) protected both forward and backward ICT in the target program, and improved the security and effectiveness of CFI, and (iii) BCI-CFI introduced a 19.67% runtime overhead on average and a maximum runtime overhead of 31.2%
Conclusion
BCI-CFI is a context-sensitive CFI technique aiming to prevent adversaries from manipulating the control data of the target program to launch ROP attacks. BCI-CFI can reduce EC sizes and improve the security of CFI while incurring a moderate runtime overhead on average.",August 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The context-sensitive CFI technique introduced has the potential to improve security and prevent ROP attacks, which can be valuable for early-stage ventures dealing with cybersecurity."
https://www.sciencedirect.com/science/article/pii/S0950584921000586,BGNN4VD: Constructing Bidirectional Graph Neural-Network for Vulnerability Detection,Bin=Li: lb@yzu.edu.cn; Xiaobing=Sun: xbsun@yzu.edu.cn,"Abstract
Context:
Previous studies have shown that existing deep learning-based approaches can significantly improve the performance of 
vulnerability detection
. They represent code in various forms and mine vulnerability features with 
deep learning models
. However, the differences of code representation forms and 
deep learning
 models make various approaches still have some limitations. In practice, their false-positive rate (FPR) and false-negative rate (FNR) are still high.
Objective:
To address the limitations of existing deep learning-based vulnerability detection approaches, we propose 
BGNN4VD
 (Bidirectional 
Graph Neural Network
 for Vulnerability Detection), a vulnerability detection approach by constructing a Bidirectional Graph Neural-Network (BGNN).
Method:
In Phase 1, we extract the syntax and semantic information of source code through 
abstract syntax tree
 (AST), 
control flow graph
 (CFG), and 
data flow graph
 (DFG). Then in Phase 2, we use vectorized source code as input to Bidirectional Graph Neural-Network (BGNN). In Phase 3, we learn the different features between vulnerable code and non-vulnerable code by introducing backward edges on the basis of traditional Graph Neural-Network (GNN). Finally in Phase 4, a Convolutional Neural-Network (CNN) is used to further extract features and detect vulnerabilities through a classifier.
Results:
We evaluate 
BGNN4VD
 on four popular C/C++ projects from NVD and GitHub, and compare it with four state-of-the-art (
Flawfinder
, 
RATS
, 
SySeVR
, and 
VUDDY
) vulnerab ility detection approaches. Experiment results show that, when compared these baselines, 
BGNN4VD
 achieves 4.9%, 11.0%, and 8.4% improvement in F1-measure, accuracy and precision, respectively.
Conclusion:
The proposed 
BGNN4VD
 achieves a higher precision and accuracy than the state-of-the-art methods. In addition, when applied on the latest vulnerabilities reported by CVE, 
BGNN4VD
 can still achieve a precision at 45.1%, which demonstrates the feasibility of 
BGNN4VD
 in practical application.",August 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The BGNN4VD vulnerability detection approach shows significant improvements in F1-measure, accuracy, and precision, which could be highly beneficial for startups aiming to enhance their security measures and reduce vulnerabilities."
https://www.sciencedirect.com/science/article/pii/S2352673425000071,Crowdfunding beyond borders: Geographic disparities in crowdfunding success,Eliran=Solodoha: liran.maymoni@gmail.com,"Abstract
This study investigates how geographic location influences the effectiveness of entrepreneurial signals in crowdfunding, integrating Regional Development Theory and Signaling Theory. Using data from 2578 reward-based crowdfunding campaigns on the Israeli platform Headstart (2012–2022), we find that structural advantages in central areas enhance the effect of entrepreneurial signals, such as prior experience and reward diversity, while systemic barriers in peripheral regions weaken these signals' effectiveness. The principal insight of this study is that geographic context not only shapes crowdfunding success but also moderates the effectiveness of signaling strategies, thereby intensifying regional disparities. These findings contribute to the literature by demonstrating how geographic context moderates the strength and interpretation of entrepreneurial signals, ultimately influencing funding success and engagement. Practical recommendations include enhancing campaign visibility for peripheral entrepreneurs and developing tailored training programs to optimize their signaling strategies.",June 2025,Not Found,Business Venturing Insights,2025-03-21T00:00:00,9.0,"The study sheds light on how geographic location influences crowdfunding success and the effectiveness of signaling strategies, offering practical recommendations for entrepreneurs, especially in European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921000562,An empirical study on clone consistency prediction based on machine learning,Fanlong=Zhang: izhangfanlong@gmail.com; Siau-cheng=Khoo: khoosc@nus.edu.sg,"Abstract
Context:
Code Clones have been accepted as a common phenomenon in software, thanks to the increasing demand for rapid production of software. The existence of code clones is recognized by developers in the form of 
clone group
, which includes several pieces of clone fragments that are similar to one another. A change in one of these clone fragments may indicate necessary 
“consistent changes”
 are required for the rest of the clones within the same group, which can increase extra maintenance costs. A failure in making such consistent change when it is necessary is commonly known as a “clone consistency-defect”, which can adversely impact software 
maintainability
.
Objective:
Predicting the need for “clone consistent changes” after successful clone-creating or clone-changing operations can help developers maintain clone changes effectively, avoid consistency-defects and reduce maintenance cost.
Method:
In this work, we use several sets of attributes in two scenarios of clone operations (
clone-creating
 and 
clone-changing
), and conduct an empirical study on five different machine-learning methods to assess each of their clone consistency predictability — whether any one of the clone operations will 
require
 or be 
free of
 clone consistency maintenance in future.
Results:
We perform our experiments on 
eight
 open-source projects. Our study shows that such predictions can be reasonably effective both for clone-creating and changing operating instances. We also investigate the use of 
five
 different machine-learning methods for predictions and show that our selected features are effective in predicting the needs of consistency-maintenance across all selected machine-learning methods.
Conclusion:
The empirical study conducted here demonstrates that the models developed by different machine-learning methods with the specified sets of attributes have the ability to perform clone-consistency prediction.",August 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,3.0,"While predicting clone consistency changes is valuable for software maintenance, the practical impact on early-stage ventures might be limited compared to cybersecurity-focused solutions."
https://www.sciencedirect.com/science/article/pii/S0950584921000537,From a Scrum Reference Ontology to the Integration of Applications for Data-Driven Software Development,Paulo Sérgio=Santos Júnior: paulo.junior@ifes.edu.br; Monalessa Perini=Barcellos: monalessa@inf.ufes.edu.br; Ricardo de Almeida=Falbo: falbo@inf.ufes.br; João Paulo A.=Almeida: jpalmeida@ieee.org,"Abstract
Context
Organizations often use different applications to support the Scrum process, including project management tools, source repository and quality assessment tools. These applications store useful data for decision-making. However, data items often remain spread in different applications, each of which adopt different data and behavioral models, posing a barrier for integrated data usage. As a consequence, data-driven decisions in agile development are uncommon, missing valuable opportunities for informed decision making.
Objective
Considering the need to address semantic issues to properly integrate applications that support the agile development process, we aim to provide a common and comprehensive conceptualization about Scrum in the software development context and apply this conceptualization to support application integration.
Method
We have developed the Scrum Reference Ontology (SRO) and used it to semantically integrate Azure DevOps and Clockify.
Results
SRO served as a reference model to build software artifacts in a semantic integration architecture that enables applications to automatically share, exchange and combine data and services. The integrated solution was used in the software development unit of a Brazilian government agency. Results demonstrate that the integrated solution contributed to improving estimates, provided data that helped allocate teams, manage team productivity and project performance, and enabled to identify and fix problems in the Scrum process execution.
Conclusions
SRO can serve as an interlingua for application integration in the context of Scrum-process support. By capturing the conceptualization underlying Scrum, the reference ontology can address semantic conflicts and thereby support the development of integrated data-driven solutions for decision making.",August 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The Scrum Reference Ontology provides a practical solution for integrating data from different applications, enabling informed decision-making, which can be highly valuable for startups seeking efficient and data-driven project management."
https://www.sciencedirect.com/science/article/pii/S0950584921000677,Insights on the relationship between decision-making style and personality in software engineering,Emilia=Mendes: emilia.mendes@bth.se; Fabiana=Mendes: fabiana.mendes@oulu.fi; Norsaremah=Salleh: norsaremah@iium.edu.my; Markku=Oivo: markku.oivo@oulu.fi,"Abstract
Context:
Software development involves many activities, and 
decision making
 is an essential one. Various factors can impact a decision-making process, and by understanding such factors, one can improve the process. Since people are the ones making decisions, some human-related aspects are amongst those influencing factors. One such aspect is the decision maker’s personality.
Objective:
This research investigates the relationship between decision-making style and personality within the context of software project development.
Method:
We conducted a survey in a population of Brazilian software engineers to gather data on their personality and decision-making style.
Results:
Data from 63 participants was gathered and resulted in the identification of seven statistically significant correlations between decision-making style and personality (personality factor and personality facets). Furthermore, we built a regression model in which decision-making style (DMS) was the response variable and personality factors the independent variables. The 
backward elimination
 procedure selected only agreeableness to explain 4.2% of DMS variation. The model accuracy was evaluated and deemed good enough. Regarding the moderation effect of demographic variables (age, educational level, experience, and role) on the relationship between DMS and Agreeableness, the analysis showed that only software engineers’ role has such effect.
Conclusion:
This paper contributes toward understanding the relationship between DMS and personality. Results show that the personality variable agreeableness can explain the variation in decision-making style. Furthermore, someone’s role in a software development project can impact the 
strength
 of the relationship between DMS and agreeableness.",August 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The research on the relationship between decision-making style and personality within software project development can provide valuable insights for startups regarding team dynamics and project management.
https://www.sciencedirect.com/science/article/pii/S0950584921000719,A methodology to automatically translate user requirements into visualizations: Experimental validation,Ana=Lavalle: alavalle@dlsi.ua.es,"Abstract
Context:
Information visualization
 is paramount for the analysis of Big Data. The volume of data requiring interpretation is continuously growing. However, users are usually not experts in information visualization. Thus, defining the visualization that best suits a determined context is a very challenging task for them. Moreover, it is often the case that users do not have a clear idea of what objectives they are building the visualizations for. Consequently, it is possible that graphics are misinterpreted, making wrong decisions that lead to missed opportunities. One of the underlying problems in this process is the lack of methodologies and tools that non-expert users in visualizations can use to define their objectives and visualizations.
Objective:
The main objectives of this paper are to (i) enable non-expert users in data visualization to communicate their analytical needs with little effort, (ii) generate the visualizations that best fit their requirements, and (iii) evaluate the impact of our proposal with reference to a 
case study
, describing an experiment with 97 non-expert users in data visualization.
Methods:
We propose a methodology that collects user requirements and semi-automatically creates suitable visualizations. Our proposal covers the whole process, from the definition of requirements to the implementation of visualizations. The methodology has been tested with several groups to measure its effectiveness and perceived usefulness.
Results:
The experiments increase our confidence about the utility of our methodology. It significantly improves over the case when users face the same problem manually. Specifically: (i) users are allowed to cover more analytical questions, (ii) the visualizations produced are more effective, and (iii) the overall satisfaction of the users is larger.
Conclusion:
By following our proposal, non-expert users will be able to more effectively express their analytical needs and obtain the set of visualizations that best suits their goals.",August 2021,"Data visualization, Big data analytics, Model-driven development, Requirements engineering, Experimental validation",Information and Software Technology,2025-03-18T00:00:00,9.0,The proposal to enable non-expert users in data visualization to express their needs effectively and obtain suitable visualizations can significantly impact startups by helping them make informed decisions based on data analysis.
https://www.sciencedirect.com/science/article/pii/S0950584921000549,"Motivations, benefits, and issues for adopting Micro-Frontends: A Multivocal Literature Review",Davide=Taibi: davide.taibi@tuni.fi; Severi=Peltonen: severi.peltonen@gmail.com; Luca=Mezzalira: luca.mezzalira@dazn.com,"Abstract
Context:
Micro-Frontends are increasing in popularity, being adopted by several large companies, such as DAZN, Ikea, Starbucks and may others. Micro-Frontends enable splitting of monolithic frontends into independent and smaller micro applications. However, many companies are still hesitant to adopt Micro-Frontends, due to the lack of knowledge concerning their benefits. Additionally, provided online documentation is often times perplexed and contradictory.
Objective:
The goal of this work is to map the existing knowledge on Micro-Frontends, by understanding the motivations of companies when adopting such applications as well as possible benefits and issues.
Method:
For this purpose, we surveyed the academic and grey literature by means of the Multivocal Literature Review process, analysing 173 sources, of which 43 reported motivations, benefits and issues.
Results:
The results show that existing architectural options to build web applications are cumbersome if the application and development team grows, and if multiple teams need to develop the same frontend application. In such cases, companies adopted Micro-Frontends to increase team independence and to reduce the overall complexity of the frontend. The application of the Micro-Frontend, confirmed the expected benefits, and Micro-Frontends resulted to provide the same benefits as 
microservices
 on the back end side, combining the development team into a fully cross-functional development team that can scale processes when needed. However, Micro-Frontends also showed some issues, such as the increased payload size of the application, increased code duplication and coupling between teams, and monitoring complexity.
Conclusions:
Micro-Frontends allow companies to scale development according to business needs in the same way microservices do with the back end side. In addition, Micro-Frontends have a lot of overhead and require careful planning if an advantage is achieved by using Micro-Frontends. Further research is needed to carefully investigate this new hype, by helping practitioners to understand how to use Micro-Frontends as well as understand in which contexts they are the most beneficial.",August 2021,"Micro-Frontends, Microservices, Web front-end development, Software architectures, Multivocal Literature Review",Information and Software Technology,2025-03-18T00:00:00,7.0,The exploration of Micro-Frontends and their benefits for development teams can be valuable for startups looking to scale their applications and understand the implications of adopting such architectural patterns.
https://www.sciencedirect.com/science/article/pii/S0950584921000574,RLTCP: A reinforcement learning approach to prioritizing automated user interface tests,Vu=Nguyen: nvu@fit.hcmus.edu.vn; Bach=Le: ldbach@apcs.vn,"Abstract
Context:
User interface testing validates the correctness of an application through visual cues and interactive events emitted in real-world usages. Performing user interface tests is a time-consuming process, and thus, many studies have focused on prioritizing test cases to help maintain the effectiveness of testing while reducing the need for full execution.
Objective:
This paper describes a novel test prioritization method called RLTCP whose goal is to maximize the number of test faults detected while reducing the amount of test.
Methods:
We define a weighted coverage graph to model the underlying association among test cases for the user interface testing. Our method combines 
Reinforcement Learning
 (RL) and the coverage graph to prioritize test cases. While RL is found to be suitable for rapidly changing projects with abundant 
historical data
, the coverage graph considers in-depth the event-based aspects of user interface testing and provides a fine-grained level at which the 
RL system
 can gain more insights into individual test cases.
Results:
We experiment and assess the proposed method using nine data sets obtained from two mature web applications, finding that the method outperforms the six, including the state-of-the-art, methods.
Conclusions:
The use of both reinforcement learning and the underlying structure of user interface tests modeled via the coverage has the potential to improve the performance of test prioritization methods. Our study also shows the benefit of using the coverage graph to gain insights into test cases, their relationship and execution history.",August 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The novel test prioritization method for user interface testing using Reinforcement Learning and coverage graphs can benefit startups by optimizing testing processes, improving fault detection, and reducing time spent on testing."
https://www.sciencedirect.com/science/article/pii/S0950584921000458,Continuous Systems and Software Engineering for Industry 4.0: A disruptive view,Elisa Yumi=Nakagawa: elisa@icmc.usp.br; Pablo Oliveira=Antonino: pablo.antonino@iese.fraunhofer.de; Frank=Schnicke: Frank.Schnicke@iese.fraunhofer.de; Peter=Liggesmeyer: peter.liggesmeyer@iese.fraunhofer.de,"Abstract
Context:
Industry 4.0
 has substantially changed the manufacturing processes, leading to smart factories with full 
digitalization
, intelligence, and dynamic production. The need for rigorous and continuous development of highly networked software-intensive 
Industry 4.0
 systems entails great challenges. Hence, Industry 4.0 requires new ways to develop, operate, and evolve these systems accordingly.
Objective:
We introduce the view of 
Continuous Systems
 and 
Software Engineering
 for Industry 4.0 (CSSE I4.0).
Method:
Based on our research and industrial projects, we propose this novel view and its core elements, including continuous twinning, which is also introduced first in this paper. We also discuss the existing industrial engagement and research that could leverage this view for practical application.
Results:
There are still several open issues, so we highlight the most urgent perspectives for future work.
Conclusions:
A disruptive view on how to engineer Industry 4.0 systems must be established to pave the way for the realization of the fourth industrial revolution.",July 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,Addresses a significant issue in Industry 4.0 systems development with practical applications and future perspectives.
https://www.sciencedirect.com/science/article/pii/S0950584921000501,Test case generation for agent-based models: A systematic literature review,Robert M.=Hierons: r.hierons@sheffield.ac.uk; Andrew G.=Clark: agclark2@sheffield.ac.uk; Neil=Walkinshaw: n.walkinshaw@sheffield.ac.uk,"Abstract
Context:
Agent-based models play an important role in simulating complex emergent phenomena and supporting critical decisions. In this context, a 
software fault
 may result in poorly informed decisions that lead to disastrous consequences. The ability to rigorously test these models is therefore essential.
Objective:
Our objective is to summarise the state-of-the-art techniques for test case generation in agent-based models and identify future research directions.
Method:
We have conducted a systematic literature review in which we pose five research questions related to the key aspects of test case generation in agent-based models: What are the information artifacts used to generate tests? How are these tests generated? How is a verdict assigned to a generated test? How is the adequacy of a generated test suite measured? What level of abstraction of an agent-based model is targeted by a generated test?
Results:
Out of the 464 
initial search results
, we identified 24 primary publications. Based on these primary publications, we formed a taxonomy to summarise the state-of-the-art techniques for test case generation in agent-based models. Our results show that whilst the majority of techniques are effective for testing functional requirements at the agent and integration levels of abstraction, there are comparatively few techniques capable of testing society-level behaviour. Furthermore, the majority of techniques cannot test non-functional requirements or “soft goals”.
Conclusions:
This paper reports insights into the key developments and open challenges concerning test case generation in agent-based models that may be of interest to both researchers and practitioners. In particular, we identify the need for test case generation techniques that focus on societal and non-functional behaviour, and a more thorough evaluation using realistic 
case studies
 that feature challenging properties associated with a typical agent-based model.",July 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"Although important for agent-based models, the impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584921000379,On the generalizability of Neural Program Models with respect to semantic-preserving program transformations,Md Rafiqul Islam=Rabin: mrabin@uh.edu,"Abstract
Context:
With the prevalence of publicly available 
source code
 repositories to train 
deep neural network
 models, neural program models can do well in 
source code analysis
 tasks such as predicting method names in given programs that cannot be easily done by traditional program analysis techniques. Although such neural program models have been tested on various existing datasets, the extent to which they generalize to unforeseen 
source code
 is largely unknown.
Objective:
Since it is very challenging to test neural program models on all unforeseen programs, in this paper, we propose to evaluate the 
generalizability
 of neural program models with respect to semantic-preserving transformations: a generalizable neural program model should perform equally well on programs that are of the same semantics but of different lexical appearances and syntactical structures.
Method:
We compare the results of various neural program models for the method name prediction task on programs before and after automated semantic-preserving transformations. We use three Java datasets of different sizes and three state-of-the-art 
neural network
 models for code, namely 
code2vec
, 
code2seq
, and 
GGNN
, to build nine such neural program models for evaluation.
Results:
Our results show that even with small semantically preserving changes to the programs, these neural program models often fail to generalize their performance. Our results also suggest that neural program models based on data and 
control dependencies
 in programs generalize better than neural program models based only on 
abstract syntax trees
 (ASTs). On the positive side, we observe that as the size of the training dataset grows and diversifies the 
generalizability
 of correct predictions produced by the neural program models can be improved too.
Conclusion:
Our results on the generalizability of neural program models provide insights to measure their limitations and provide a stepping stone for their improvement.",July 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"Relevant for neural program models, but the impact on startups may be moderate compared to the Industry 4.0 focus."
https://www.sciencedirect.com/science/article/pii/S0950584921000422,iMER: Iterative process of entity relationship and business process model extraction from the requirements,Muhammad=Javed: m.javed@uon.edu.au; Yuqing=Lin: yuqing.lin@newcastle.edu.au,"Abstract
Context
Extracting conceptual models, e.g., 
entity relationship model
 or Business Process model, from software requirement document is an essential task in the 
software development life cycle
. Business process model presents a clear picture of required system's functionality. Operations in business process model together with the data entity consumed, help the software developers to understand the database design and operations to be implemented. Researchers have been aiming at automatic extraction of these artefacts from the requirement document.
Objective
In this paper, we present an automated approach to extract the entity relationship and business process models from requirements, which are possibly in different formats such as general requirements, use case specification and user stories. Our approach is based on the efficient 
natural language processing
 techniques.
Method
It is an iterative approach of Models Extraction from the Requirements (iMER). iMER has multiple iterations where each iteration is to address a sub-problem. In the first iteration, iMER extracts the data entities and attributes. Second iteration is to find the relationships between data entities, while extracting 
cardinalities
 is in the third step. Business process model is generated in the fourth iteration, containing the external (actors’) and internal (system's) operations.
Evaluation
To evaluate the performance and accuracy of iMER, experiments are conducted on various formats of the requirement documents. Additionally, we have also evaluated our approaches using the requirement documents which been modified by shuffling the sentences and by merging with other requirements. Comparative study is also performed. The preliminary results show a noticeable improvement.
Conclusion
The iMER is an efficient automated iterative approach that is able to extract the conceptual models from the various formats of requirements.",July 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The automated extraction of entity relationship and business process models from requirements can greatly benefit software developers, leading to improved database design and system understanding for startups."
https://www.sciencedirect.com/science/article/pii/S0950584921000495,Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model,Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Lobna=Ghadhab: lobnaghadhab@gmail.com; Ilyes=Jenhani: ijenhani@pmu.edu.sa; Montassar=Ben Messaoud: montassar.benmassaoud@isgs.u-sousse.tn,"Abstract
Context:
Analyzing software maintenance activities is very helpful in ensuring cost-effective evolution and development activities. The categorization of commits into maintenance tasks supports practitioners in making decisions about 
resource allocation
 and managing technical debt.
Objective:
In this paper, we propose to use a pre-trained language neural model, namely BERT (Bidirectional Encoder Representations from Transformers) for the classification of commits into three categories of maintenance tasks — corrective, perfective and adaptive. The proposed commit 
classification approach
 will help the classifier better understand the context of each word in the commit message.
Methods:
We built a balanced dataset of 1793 labeled commits that we collected from publicly available datasets. We used several popular code change distillers to extract fine-grained code changes that we have incorporated into our dataset as additional features to BERT’s word representation features. In our study, a 
deep neural network
 (DNN) classifier has been used as an additional layer to fine-tune the BERT model on the task of commit classification. Several models have been evaluated to come up with a deep analysis of the impact of code changes on the classification performance of each commit category.
Results and conclusions:
Experimental results have shown that the 
DNN model
 trained on BERT’s word representations and Fixminer code changes (DNN@BERT+Fix_cc) provided the best performance and achieved 79.66% accuracy and a macro-average f1 score of 0.8. Comparison with the state-of-the-art model that combines keywords and code changes (RF@KW+CD_cc) has shown that our model achieved approximately 8% improvement in accuracy. Results have also shown that a 
DNN model
 using only BERT’s word representation features achieved an improvement of 5% in accuracy compared to the RF@KW+CD_cc model.",July 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The use of a pre-trained language neural model for classifying commits into maintenance tasks shows a high level of accuracy and improvement over state-of-the-art models, which can greatly assist startups in efficient resource allocation and technical debt management."
https://www.sciencedirect.com/science/article/pii/S0950584921000525,MEGDroid: A model-driven event generation framework for dynamic android malware analysis,Behrouz=Tork Ladani: Ladani@eng.ui.ac.ir,"Abstract
Context
The tremendous growth of 
Android malware
 in recent years is a strong motivation for the vast endeavor in detection and analysis of 
malware
 apps. A prominent approach for this purpose is dynamic analysis in which providing complex interactions with the samples under analysis is a need. Event generation tools are almost used to provide such interactions, but they have deficiencies for effective 
malware analysis
. For example, anti-static and anti-dynamic analysis techniques employed by the 
malware
 prevent event generators to extract sufficient information for generating appropriate events. As a result, they fail to trigger 
malicious payloads
 or obtain high code coverage in most cases.
Objective
In this paper, we aim to present a new framework to improve the event generation process for dynamic analysis of 
Android malware
.
Method
We propose MEGDroid, a 
Model Driven Engineering
 (MDE) framework in which malware-related information is automatically extracted and represented as a domain-specific model. This model, then is used to generate appropriate events for 
malware analysis
 using model-to-model and model-to-code transformations. The proposed model-driven artifacts also provide required facilities to put the 
human in the loop
 for properly taking his/her knowledge into account.
Results
The proposed framework has been realized as an Eclipse plugin and we performed extensive practical analysis on a set of 
malware samples
 selected from the AMD dataset. The experimental results showed that MEGDroid considerably increases the number of triggered 
malicious payloads
 as well as the execution code coverage compared with Monkey and DroidBot, as two state of the art general-purpose and malware specific event generators respectively.
Conclusion
The proposed MDE approach, enhances the event generation process through both automatic event generation and analyzer user involvement who can efficiently direct the process to increase the effectiveness of the generated events considering small amount of information that is extractable from the malware code.",July 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed framework for improving event generation for dynamic analysis of Android malware shows significant improvement in triggering malicious payloads and code coverage, which can be crucial for startups in enhancing cybersecurity measures."
https://www.sciencedirect.com/science/article/pii/S0950584921000483,Multi-objective software performance optimisation at the architecture level using randomised search rules,Youcong=Ni: youcongni@foxmail.com; Xin=Du: xindu79@126.com; Peng=Ye: whuyp@126.com,"Abstract
Architecture-based software 
performance optimisation
 can help to find potential performance problems and mitigate their negative effects at an early stage. To automate this optimisation process, rule-based and metaheuristic-based 
performance optimisation
 methods have been proposed. However, existing rule-based methods explore a limited 
search space
, potentially excluding optimal or near-optimal solutions. Most of current metaheuristic-based methods ignore existing practical knowledge of 
performance improvement
, and lead to solutions that are not easily explicable to humans. To address these problems, we propose a novel approach for performance optimisation at the software architecture level named Multiobjective performance Optimisation based on 
Randomised search
 rulEs (MORE). First, we 
design randomised
 search rules (MORE-R) to provide explanation without parameters while benefiting from existing practical knowledge of 
performance improvement
. Second, based on all possible 
composite applications
 of MORE-R, an explicable multi-objective 
optimisation problem
 (MORE-P) is defined to enlarge 
search space
 and enable solutions explicable to architectural stakeholder. Third, a multi-objective evolutionary algorithm (MORE-EA) with an introduced do-nothing rule, innovative encoding and repair mechanism is designed to effectively solve MORE-P. The experiments show that MORE is able to achieve more explicable and higher quality solutions than two state-of-the-art techniques. They also demonstrate the benefits of integrating search-based 
software engineering
 approaches with practical knowledge.",July 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,"The MORE approach for performance optimization at the software architecture level offers explicable and high-quality solutions, integrating practical knowledge with evolutionary algorithms, which can greatly benefit early-stage ventures in mitigating performance problems and improving software architecture."
https://www.sciencedirect.com/science/article/pii/S0950584921000513,Analyzing the sensitivity of multi-objective software architecture refactoring to configuration characteristics,Vittorio=Cortellessa: vittorio.cortellessa@univaq.it; Daniele=Di Pompeo: daniele.dipompeo@univaq.it,"Abstract
Context:
Software architecture refactoring can be induced by multiple reasons, such as satisfying new functional requirements or improving non-functional properties. Multi-objective optimization approaches have been widely used in the last few years to introduce automation in the 
refactoring process
, and they have revealed their potential especially when quantifiable attributes are targeted. However, the effectiveness of such approaches can be heavily affected by configuration characteristics of the 
optimization algorithm
, such as the composition of solutions.
Objective:
In this paper, we analyze the behavior of 
, which is an Evolutionary Approach for Software archItecturE Refactoring, while varying its configuration characteristics, with the objective of studying its potential to find near-optimal solutions under different configurations.
Method:
In particular, we use two different 
solution space
 inspection algorithms (i.e., 
 and 
) while varying the genome length and the solution composition.
Results:
We have conducted our experiments on a specific 
case study
 modeled in 
Æ
 ADL, on which we have shown the ability of 
 to identify performance-critical elements in the software architecture where refactoring is worth to be applied. Beside this, from the comparison of multi-objective algorithms, 
 has revealed to outperform 
 in most of cases, although the latter one is able to induce more diversity in the proposed solutions.
Conclusion:
Our results show that the 
 thoroughly automated process for software architecture refactoring allows to identify configuration contexts of the 
evolutionary algorithm
 in which multi-objective optimization more effectively finds near-optimal Pareto solutions.",July 2021,"Search-based software engineering, Automated refactoring, Software quality, Multi-objective optimization, Genetic algorithms, Software performance engineering, Software performance antipatterns",Information and Software Technology,2025-03-18T00:00:00,6.0,"The analysis of the Evolutionary Approach for Software archItecturE Refactoring shows potential in identifying performance-critical elements, but the impact on startups may vary depending on the configuration characteristics."
https://www.sciencedirect.com/science/article/pii/S0950584921000434,A field experiment on trialsourcing and the effect of contract types on outsourced software development,Magne=Jørgensen: magnej@simula.no; Jon=Grov: jon.grov@langs.no,"ABSTRACT
Context
To ensure the success of software projects, it is essential to select skilled developers and to use suitable work contracts.
Objective
This study tests two hypotheses: (i) the use of work-sample testing (trialsourcing) improves the selection of skilled software developers; and (ii) the use of contracts based on hourly payment leads to better software project outcomes than fixed-price contracts.
Method
Fifty-seven software freelancers with relevant experience and good evaluation scores from previous clients were invited to complete a two-hour long trialsourcing task to qualify for a software development project. Thirty-six developers completed the trialsourcing task with acceptable performance, and, based on a 
stratified random
 allocation process, were asked to give a proposal based on an hourly payment or a fixed-price contract. Eight hourly payment-based and eight fixed-priced proposals were accepted. The process and product characteristics of the completion of these 16 projects were collected and analysed.
Results and Conclusion
While the use of trialsourcing may have prevented the selection of developers with insufficient skills, the performance on the trialsourcing task of the selected developers did, to a large extent, not predict their performance on the projects. The use of hourly payments seems to have led to lower costs than fixed-price contracts, but not to improved processes or products. We plan to follow up these results with research on how to design more skill-predictive trialsourcing tasks, and when and why different project contexts give different contract consequences.",June 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study addresses the selection of skilled developers and work contracts in software projects, the impact on European early-stage ventures is limited as it focuses more on individual freelancers. The results suggest areas for further research but do not provide immediate practical value for startups."
https://www.sciencedirect.com/science/article/pii/S0950584921000276,A decentralized blockchain oriented framework for automated bug assignment,Chetna=Gupta: chetna.gupta@ubi.pt; Mário M=Freire: mario@di.ubi.pt,"ABSTRACT
Context
In large software projects bug fixing is a time-bound, time-consuming, mind-numbing, and challenging task that requires a collaborative effort with multiple developers, separated geographically.
Objective
The objective of this paper is to propose a decentralized automated bug assignment approach to improve the quality of bug assignments to minimize backlogs and overall bug fixing time.
Method
To the best of our knowledge, the literature lacks in studies focusing on how to increase software developer's motivation for efficient bug resolution. It is a novel decentralized 
blockchain
 oriented, transparent auction-based bug assignment framework which uses incentive mechanism as reward and penalty backed by 
blockchain
 technology using 
smart contracts
 for developers motivation. The process allows individual developers to select 
bug reports
, matching their preferences and schedule for which they shall we able to provide 
robust solutions
 with reduced overhead in cost and time of bug fixing.
Results
Results of experimentation and surveys conclude that the proposed method is transparent and effective in bug assignment minimizing overall bug fixing time. The low cost of contract execution demonstrates that it can be used quantitatively and without ambiguity.
Conclusion
The work presented is novel to improve (i) bug assignment (ii) allow individual developers to choose what they like to provide 
robust solutions
 (iii) handles two major issues of differentiating between active and inactive developers and confusion over the assignment of bugs (iv) will further reduce bug-fixing delays and will prevent reassignment problem.",June 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed decentralized automated bug assignment approach using blockchain technology could have a significant impact on improving bug resolution efficiency for European early-stage ventures. The transparent and effective method with low cost implications could be valuable for startups with limited resources.
https://www.sciencedirect.com/science/article/pii/S0950584921000252,Game industry problems: An extensive analysis of the gray literature,Cristiano=Politowski: c_polito@encs.concordia.ca; Fabio=Petrillo: fabio@petrillo.com; Gabriel C.=Ullmann: gabriel.cavalheiro@sou.unijui.edu.br; Yann-Gaël=Guéhéneuc: yann-gael.gueheneuc@concordia.ca,"Abstract
Context:
Given its competitiveness, the video-game 
industry
 has a closed-source culture. Hence, little is known about the problems faced by game developers. However, game developers do 
share information
 about their game projects through postmortems, which describe informally what happened during the projects.
Objective:
The software-engineering research community and game developers would benefit from a state of the problems of the 
video game
 
industry
, in particular the problems faced by game developers, their evolution in time, and their root causes. This state of the practice would allow researchers and practitioners to work towards solving these problems.
Method:
We analyzed 200 postmortems from 1997 to 2019, resulting in 927 problems divided into 20 types. Through our analysis, we described the overall landscape of game industry problems in the past 23 years and how these problems evolved over the years. We also give details on the most common problems, their root causes, and possible solutions. We finally discuss suggestions for future projects.
Results:
We observe that (1) the game industry suffers from management and production problems in the same proportion; (2) management problems decreased over the years, giving space to 
business problems
, while production problems remained constant; (3a) technical and game design problems are decreasing over the years, the latter only after the last decade; (3b) problems related to the team increase over the last decade; (3c) marketing problems are the ones that had the biggest increase over the 23 years compared to other problem types; (4) finally, the majority of the main root causes are related to people, not technologies. Conclusions: In this paper, we provide a state of the practice for researchers to understand and study video-game development problems. We also offer suggestions to help practitioners to avoid the most common problems in future projects.",June 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The analysis of postmortems in the video game industry provides valuable insights into the problems faced by game developers over the years. Understanding the evolving landscape of industry challenges can guide European startups in the gaming sector to anticipate and address common issues, enhancing project outcomes."
https://www.sciencedirect.com/science/article/pii/S095058492100029X,Efilter: An effective fault localization based on information entropy with unlabelled test cases,Shihai=Wang: wangshihai@buaa.edu.cn; Yan=Xiaobo: yxbbuaa@buaa.edu.cn; Liu=Bin: liubin@buaa.edu.cn; An=Dong: ad14011099@buaa.edu.cn; Zhu=Feng: fenix_zh@126.com; Yang=Yelin: ylyang05@163.com,"Abstract
Context:
Automatic 
fault localization
 is essential to intelligent software system. Most 
fault localization
 techniques assume the test oracle is perfect before debugging, which is hard to exist in practice. In fact, the test suite would contain a number of unlabelled test cases which have been proved to be useful in fault localization. However, due to the execution diversity, not all unlabelled test cases are suitable for fault localization. Selecting inappropriate unlabelled test cases can even weaken the fault localization efficiency.
Objective:
To solve the problem of filtering unlabelled test cases, this work aims to construct a feasible framework to select suitable unlabelled test cases for better fault localization.
Method:
To address this issue, an entropy-based framework Efilter is constructed to filter unlabelled test cases. In Efilter, a Statement-based entropy and Testsuite-based entropy are constructed to measure the localization uncertainty of given test suite. The unlabelled test case with less Statement-based entropy or Testsuite-based entropy compared with its threshold would be selected. Further, the feature integration strategies for both Statement-based entropy and Testsuite-based entropy are given to calculate the 
suspiciousness
 of statements.
Results:
The Efilter efficiency is evaluated across 6 open-source programs and 3 spectrum-based fault localizations. The results reveal that Efilter can improve fault localization efficiency by 18.8% and 16.5% with the Statement-based entropy and the Testsuite-based entropy respectively compared with the strategy without Efilter from the perspective of 
EXAM
 score on average.
Conclusion:
Our results indicate that the Efilter with both the Statement-based entropy and the Testsuite-based entropy can improve the fault localization in the scenario lack of test oracles, serving as an enhancement for fault localization in practice.",June 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The framework for selecting suitable unlabelled test cases for fault localization presents a promising approach to improve software system intelligence. While the results show efficiency improvements, the direct impact on European early-stage ventures may not be immediate but could be valuable for startups focusing on software quality."
https://www.sciencedirect.com/science/article/pii/S2352673424000179,Entrepreneurship after prison: It’s complicated,Stephanie A.=Fernhaber: sfernhab@butler.edu; Fiona=Robinson: firobinson@mtroyal.ca,"Abstract
Entrepreneurship is increasingly seen as a creative solution for individuals after they have been released from prison given the difficulties they face in finding viable employment. However, considering that entrepreneurship inherently involves maneuvering around and overcoming obstacles, it is likely an even more complicated endeavor for these individuals. A 
thick problem description
 of entrepreneurship after prison is needed to better understand the unique challenges associated with this unconventional entrepreneurial journey. Drawing on the existing literature coupled with semistructured interviews with five individuals who started businesses after being incarcerated, we utilize an empathy mapping tool to explicate our findings. We then outline key insights and offer recommendations on how to move forward.",June 2024,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"The exploration of entrepreneurship after prison and the unique challenges faced by individuals post-incarceration is insightful. However, the practical implications for European early-stage ventures or startups may be limited, as the focus is more on understanding obstacles faced by a specific group of entrepreneurs."
https://www.sciencedirect.com/science/article/pii/S0950584921000446,A process for analysing the energy efficiency of software,Javier=Mancebo: Javier.Mancebo@uclm.es; Félix=García: Felix.Garcia@uclm.es; Coral=Calero: Coral.Calero@uclm.es,"Abstract
Context
It is essential to be aware of the energy efficiency of software when it is running, so that it can be improved; to that end, energy consumption measurements need to be carried out. To ensure that these measurements are as reliable as possible, it is recommended that a well-defined process be followed.
Objective
To identify how the process for analysing the energy efficiency of software should be carried out (including the definition of the software to be evaluated, the selection of measuring instruments, the analysis and the presentation of results, etc.), in an endeavour to improve the reliability and consistency of the information obtained regarding energy efficiency.
Method
An analysis of related work was carried out, to extract some good practices in measuring energy consumption; based on our experience, a process to analyse the energy efficiency of the software has been defined.
Results
We have defined a process to analyse the energy efficiency of the software. We describe this process through a set of phases that covers all the steps needed to carry out a correct analysis of the energy consumption of the software executed. Moreover, this process was validated with two different studies using different measurement instruments (one with a hardware-based approach and one with a software-based approach) to ensure its applicability to all types of studies with software energy consumption measurement.
Conclusion
The steps to be followed to analyse the energy efficiency of the software need to be established. A new process has hence been defined to improve the reliability and consistency of the measurements. Furthermore, this process facilitates the replicability and comparison of the studies carried out.",June 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The defined process for analyzing the energy efficiency of software provides practical guidance for conducting reliable energy consumption measurements. European early-stage ventures, including startups, can benefit from improved energy efficiency analysis to optimize software performance and resource usage."
https://www.sciencedirect.com/science/article/pii/S0950584921000367,Controlled experimentation in continuous experimentation: Knowledge and challenges,Per=Runeson: per.runeson@cs.lth.se; Florian=Auer: florian.auer@uibk.ac.at; Rasmus=Ros: rasmus.ros@cs.lth.se; Lukas=Kaltenbrunner: lukas.kaltenbrunner@uibk.ac.at,"Abstract
Context:
Continuous experimentation and A/B testing is an established industry practice that has been researched for more than 10 years. Our aim is to synthesize the conducted research.
Objective:
We wanted to find the core constituents of a framework for continuous experimentation and the solutions that are applied within the field. Finally, we were interested in the challenges and benefits reported of continuous experimentation.
Methods:
We applied forward snowballing on a known set of papers and identified a total of 128 relevant papers. Based on this set of papers we performed two qualitative narrative syntheses and a thematic synthesis to answer the research questions.
Results:
The framework constituents for continuous experimentation include experimentation processes as well as supportive technical and organizational infrastructure. The solutions found in the literature were synthesized to nine themes, e.g. experiment design, automated experiments, or metric specification. Concerning the challenges of continuous experimentation, the analysis identified cultural, organizational, business, technical, statistical, ethical, and domain-specific challenges. Further, the study concludes that the benefits of experimentation are mostly implicit in the studies.
Conclusion:
The research on continuous experimentation has yielded a large body of knowledge on experimentation. The synthesis of published research presented within include recommended infrastructure and experimentation process models, guidelines to mitigate the identified challenges, and what problems the various published solutions solve.",June 2021,"Continuous experimentation, Online controlled experiments, A/B testing, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,7.0,The synthesis of research on continuous experimentation provides valuable insights and recommendations for infrastructure and experimental processes.
https://www.sciencedirect.com/science/article/pii/S0950584921000264,On the practitioners’ understanding of coupling smells — A grey literature based Grounded-Theory study,Apitchaka=Singjai: apitchaka.singjai@univie.ac.at; Georg=Simhandl: georg.simhandl@univie.ac.at; Uwe=Zdun: uwe.zdun@univie.ac.at,"Abstract
Context:
Code and design smells, such as the coupling smells examined in this article, are widely studied. Existing empirical studies reveal gaps between the scientific theory and practice, not yet explained by the scientific literature. Only basic coupling smell detection approaches and metrics seem to have been transferred to practice so far.
Objective:
This article aims to study the current practitioner’s understanding of coupling smells.
Method:
Based on grey literature sources containing practitioner views on coupling smells, we performed a Grounded Theory (GT) study. We used UML-based modeling to precisely encode our findings and performed a 
rigorous analysis
 of our codes and models.
Results:
Our results are defining factors of coupling smells, as well as smell impacts, trade-offs, relationships to other smells, relationships to practices and patterns, and fix options as perceived by practitioners. We further identified gaps in the understanding of coupling smells between science and practice, and derived opportunities and challenges for future scientific work.
Conclusions:
Five lessons are presented as opportunities and challenges for future research. Our results can help scientists to get a better understanding of practitioner concerns, and practitioners to get an overview of the current perception of other practitioners on coupling smells.",June 2021,"Grey literature, Grounded theory, Design smells, Code smells, Coupling smells, Software design quality, Code quality",Information and Software Technology,2025-03-18T00:00:00,8.0,Studying the understanding of coupling smells by practitioners is important for bridging the gap between theory and practice in software engineering.
https://www.sciencedirect.com/science/article/pii/S0950584921000033,"Case Study Research in Software Engineering—It is a Case, and it is a Study, but is it a Case Study?",Claes=Wohlin: claes.wohlin@bth.se,"Abstract
Background:
Case studies
 are regularly published in the 
software engineering
 literature, and guidelines for conducting case studies are available. Based on a perception that the label “case study” is assigned to studies that are not case studies, an investigation has been conducted.
Objective:
The aim was to investigate whether or not the label “case study” is correctly used in software engineering research.
Method:
To address the objective, 100 recent articles found through Scopus when searching for case studies in software engineering have been investigated and classified.
Results:
Unfortunately, the perception of misuse of the label “case study” is correct. Close to 50% of the articles investigated were judged as not being case studies according to the definition of a case study.
Conclusions:
We either need to ensure correct use of the label “case study”, or we need another label for its definition. Given that “case study” is a well-established label, it is probably impossible to change the label. Thus, we introduce an alternative definition of case study emphasising its real-life context, and urge researchers to carefully follow the definition of different research methods when presenting their research.",May 2021,"Case study, Empirical, Misuse, Software engineering",Information and Software Technology,2025-03-18T00:00:00,5.0,Investigating the correct use of the label 'case study' in software engineering research is informative but may have limited practical impact on early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673423000355,Bridging worlds: The intersection of religion and entrepreneurship as meaningful heterodoxy,Brett R.=Smith: smithbr2@miamioh.edu,"Abstract
There is a resurgence in both the advancement and critique of research at the intersection of religion and entrepreneurship. It is precisely because there are important conflicts, tensions, and paradoxes in religion and entrepreneurship that this stream of research is important to the field of entrepreneurship as a source of meaningful heterodoxy. Without grappling with these values and concerns, entrepreneurship scholars are left with an incomplete and possibly emaciated understanding of entrepreneurship. When properly harnessed to build bridges across social divides, the intersection of religion and entrepreneurship is an important source of fresh, new, and heterodox insights into the processes through which entrepreneurs strive to transform organizations and society through entrepreneurial action and an emerging subfield of entrepreneurship research.",November 2023,"Religion, Entrepreneurship, Heterodoxy, Subfield",Business Venturing Insights,2025-03-21T00:00:00,5.0,"While the intersection of religion and entrepreneurship is an interesting topic, it may not have direct practical value for early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584920302123,Mobile app privacy in software engineering research: A systematic mapping study,Anas=Mahmoud: mahmoud@csc.lsu.edu,"Abstract
Context:
 Mobile applications (apps) have become deeply personal, constantly demanding access to privacy-sensitive information in exchange for more personalized 
user experiences
. Such privacy-invading practices have generated major multidimensional privacy concerns among app users.
Objective:
 The research on mobile app privacy has experienced rapid growth over the past decade. This line of research is aimed at systematically exposing the privacy practices of apps and proposing solutions to protect the privacy of mobile app users. In this paper, we conduct a 
systematic mapping study
 of this body of research. Our objectives are to 
a)
 explore trends in 
SE
 app privacy research, 
b)
 categorize existing evidence, and 
c)
 identify potential directions for future research.
Method:
 A 
systematic mapping study
 of 59 Software Engineering (SE) primary studies on mobile app privacy. Our scope is studies published in software engineering venues between 2008 and 2018.
Results:
 Our results show that existing literature can be divided into four main categories: privacy policy, requirements, user perspective, and leak detection. Furthermore, our survey reveals an imbalance between these categories—the majority of existing research focuses on proposing tools for detecting privacy leaks, with fewer studies targeting privacy requirements and policy and even fewer on user perspective.
Conclusions:
 Our survey exposes several gaps in existing research and suggests areas for improvement.",May 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The systematic mapping study on mobile app privacy research provides insights into current trends, categories of research, and gaps for improvement in protecting app users' privacy."
https://www.sciencedirect.com/science/article/pii/S095058492100001X,Bridging the state-of-the-art and the state-of-the-practice of SaaS pricing: A multivocal literature review,Andrey=Saltan: andrey.saltan@lut.fi,"Abstract
Context
Pricing
 is an essential element of software 
business strategy
 and tactics. Informed pricing decision-making requires the involvement of different stakeholders and comprehensive data analysis. Achieving both appears to be challenging, and pricing remains one of the most under-managed processes in the software business. Simultaneously, a coherent 
SaaS
 pricing body of knowledge and verified solutions to assist SaaS providers while designing and implementing pricing are missing.
Objective
There is a lack of integration among different research areas focused on SaaS pricing and, more importantly, between academia and 
industry
. The primary aim of this paper is to clarify this misconception by classifying, thematically analyzing, and putting in correspondent academic state-of-the-art and industrial state-of-the-practice of SaaS pricing.
Method
A multivocal literature review (MLR) approach was used for the study, exploring both “white” literature as well as “grey” literature. The body of literature of 387 
bibliography
 items was collected using a formal protocol. Of these, 57 were white literature items, and 330 were grey. A multistage content analysis process was implemented to classify the rich literature body across multiple dimensions with further mapping, synthesis, and reporting.
Results
A taxonomy of pricing-related concepts was created. It classifies SaaS pricing aspects, affecting factors, and challenges facing SaaS providers. The findings and interpretations are summarized to emphasize the major research themes and practical challenges of SaaS pricing practices’ transformation and provide further research guidelines in this area.
Conclusion
SaaS pricing is a maturing and prominent area of research that requires further investigation. The conducted MLR formed a clear picture of SaaS pricing research and practice and identified different SaaS pricing aspects and affecting factors. The study will enable both scholars and practitioners to assess the current state-of-the-art in research and practice.",May 2021,"Software-as-a-Service, SaaS, Pricing, Software Economics, Software Product Management, Multi-vocal Literature Review",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study addresses the important issue of SaaS pricing, providing a taxonomy of pricing-related concepts and practical challenges, which can be beneficial for startups in the software business."
https://www.sciencedirect.com/science/article/pii/S0950584920302457,Rigorous code review by reverse engineering,Shaoying=Liu: sliu@hiroshima-u.ac.jp,"Abstract
Context:
Agile 
software development methods
 advocate the importance of producing working software without comprehensive documentation. While this approach seems to suit the evolutionary nature of realistic software development for many applications, even including safety-critical systems, it faces two major challenges. One is the lack of a comprehensible specification for code evolution and future maintenance, and the other is the potentially huge cost in code verification.
Objective:
To address this problem, we believe that supporting the efficient production of system specification by reversing the program constructed as the result of an 
agile development
 will be a useful solution. The reverse engineering of specifications from programs will not only help us produce the necessary specification for future program evolution, but more importantly can help us rigorously review the program to detect bugs for the enhancement of program quality.
Method:
In this paper, we put forward a novel method for rigorously reviewing code by reversing it into a comprehensible, formal specification. We elaborate on the principle of translating code into a specification and discuss how the translation process helps detect bugs in programs. We demonstrate how the proposed method works in practice with examples. We also present an experiment to evaluate the performance of the method by comparing it with existing checklist-based inspection.
Conclusions:
How to utilize reverse engineering of formal specifications from programs as a means to review the program for bug detection is an almost unexplored topic in 
software engineering
. In this paper, we have described a specific method called RCRRE to reverse engineering of SOFL formal specifications from code and discussed how the reverse 
engineering process
 can be taken as an effective means to review the program for bug detection. The principle of converting code to a SOFL specification is reflected by a set of translation patterns and a two-step approach to construct a SOFL specification is established. To evaluate the performance, we have carried out an experiment on the effectiveness of our RCRRE method by comparing it with the CBI approach. The result of the experiment indicates that using our RCRRE method can effectively help the reviewer scrutinize the code and therefore find more bugs than the CBI when the reviewer is rather familiar with the SOFL specification language and skills. In the meanwhile, it also shows that the effectiveness of our RCRRE method may be affected in the situation where the reviewer lacks sufficient understanding and experience of SOFL, and using our RCRRE method may in general take a little longer time than the CBI.",May 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The paper introduces a novel method (RCRRE) for reviewing code to detect bugs, which could be valuable for startups in agile software development, improving program quality and maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584920302147,A graph-based clustering algorithm for software systems modularization,Habib=Izadkhah: izadkhah@tabrizu.ac.ir,"Abstract
Context:
Clustering algorithms
, as a modularization technique, are used to modularize a program aiming to understand large software systems as well as software refactoring. These algorithms partition the 
source code
 of the software system into smaller and easy-to-manage modules (clusters). The resulting decomposition is called the software system structure (or software architecture). Due to the NP-hardness of the modularization problem, evolutionary 
clustering approaches
 such as the 
genetic algorithm
 have been used to solve this problem. These methods do not make much use of the information and knowledge available in the artifact 
dependency graph
 which is extracted from the 
source code
.
Objective:
To overcome the limitations of the existing modularization techniques, this paper presents a new modularization technique named GMA (Graph-based Modularization Algorithm).
Methods:
In this paper, a new graph-based clustering algorithm is presented for software modularization. To this end, the depth of relationships is used to compute the similarity between artifacts, as well as seven new criteria are proposed to evaluate the quality of a modularization. The similarity presented in this paper enables the algorithm to use graph-theoretic information.
Results:
To demonstrate the applicability of the proposed algorithm, ten folders of Mozilla Firefox with different domains and functions, along with four other applications, are selected. The experimental results demonstrate that the proposed algorithm produces modularization closer to the human expert’s decomposition (i.e., directory structure) than the other existing algorithms.
Conclusion:
The proposed algorithm is expected to help a software designer in the software reverse 
engineering process
 to extract easy-to-manage and understandable modules from 
source code
.",May 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed GMA algorithm for modularization aims to help software designers in reverse engineering, producing modularization closer to human expert's decomposition, which can be highly impactful for startups dealing with large software systems."
https://www.sciencedirect.com/science/article/pii/S0950584920302111,Understanding Hypotheses Engineering in Software Startups through a Gray Literature Review,Eduardo=Guerra: eduardo.guerra@unibz.it; Xiaofeng=Wang: xiaofeng.wang@unibz.it; Jorge=Melegati: jmelegatigoncalves@unibz.it,"Abstract
Context
The 
higher availability
 of software usage data and the influence of the Lean Startup led to the rise of experimentation in 
software engineering
, a new approach for development based on experiments to understand the user needs. In the models proposed to guide this approach, the first step is generally to identify, prioritize, and specify the hypotheses that will be tested through experimentation. However, although practitioners have proposed several techniques to handle hypotheses, the scientific literature is still scarce.
Objective
The goal of this study is to understand what activities, as proposed in industry, are entailed to handle hypotheses, facilitating the comparison, creation, and evaluation of relevant techniques.
Methods
We performed a gray literature review (GLR) on the practices proposed by practitioners to handle hypotheses in the context of software startups. We analyzed the identified documents using thematic synthesis.
Results
The analysis revealed that techniques proposed for software startups in practice compress five different activities: elicitation, prioritization, specification, analysis, and management. It also showed that practitioners often classify hypotheses in types and which qualities they aim for these statements.
Conclusion
Our results represent the first description for hypotheses engineering grounded in practice data. This mapping of the state-of-practice indicates how research could go forward in investigating hypotheses for experimentation in the context of software startups. For practitioners, they represent a catalog of available practices to be used in this context.",May 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study examines techniques for handling hypotheses in software startups, providing a catalog of available practices, which could benefit startups in experimentation and understanding user needs."
https://www.sciencedirect.com/science/article/pii/S095058492030094X,Context-Oriented Behavioral Programming,Achiya=Elyasaf: achiya@bgu.ac.il,"Abstract
Context:
Modern systems require programmers to develop code that dynamically adapts to different contexts, leading to the evolution of new 
context-oriented
 programming languages. These languages introduce new software-engineering challenges, such as: how to maintain the separation of concerns of the codebase? how to model the changing behaviors? how to verify the 
system behavior
? and more.
Objective:
This paper introduces 
Context-Oriented Behavioral Programming
 (COBP) — a novel paradigm for developing context-aware systems, centered on natural and incremental specification of context-dependent behaviors. As the name suggests, we combine 
behavioral-programming
 (BP) — a scenario-based modeling paradigm — with context idioms that explicitly specify when scenarios are relevant and what information they need. The core idea is to connect the behavioral model with a data model that represents the context, allowing an intuitive connection between the models via update and select queries. Combining behavioral-programming with context-oriented programming brings the best of the two worlds, solving issues that arise when using each of the approaches in separation.
Methods:
We begin with providing abstract semantics for COBP and two implementations for the semantics, laying the foundations for applying 
reasoning algorithms
 to context-aware behavioral programs. Next, we exemplify the semantics with formal specifications of systems, including a variant of Conway’s 
Game of Life
. Then, we provide two 
case studies
 of real-life context-aware systems (one in robotics and another in IoT) that were developed using this tool. Throughout the examples and 
case studies
, we provide 
design patterns
 and a methodology for coping with the above challenges.
Results:
The case studies show that the proposed approach is applicable for developing real-life systems, and presents measurable advantages over the alternatives — behavioral programming alone and context-oriented programming alone.
Conclusion:
We present a paradigm allowing programmers and system engineers to capture complex context-dependent requirements and align their code with such requirements.",May 2021,"Behavioral programming, Scenario-based programming, Programming paradigm, Context awareness, Context-oriented programming, Context-Oriented Behavioral Programming",Information and Software Technology,2025-03-18T00:00:00,9.0,"The COBP paradigm introduced in the paper offers a novel approach for developing context-aware systems, combining behavioral programming with context-oriented programming, which could greatly benefit startups in developing modern systems."
https://www.sciencedirect.com/science/article/pii/S0950584921000185,Improving high-impact bug report prediction with combination of interactive machine learning and active learning,Wei=Zheng: wzheng@nwpu.edu.cn,"Abstract
Context:
Bug reports
 record issues found during software development and maintenance. A high-impact bug report (HBR) describes an issue that can cause severe damage once occurred after deployment. Identifying HBRs from the bug repository as early as possible is crucial for guaranteeing software quality.
Objective:
In recent years, many machine learning-based approaches have been proposed for HBR prediction, and most of them are based on supervised 
machine learning
. However, the assumption of supervised 
machine learning
 is that it needs a large number of labeled data, which is often difficult to gather in practice.
Method:
In this paper, we propose hbrPredictor, which combines interactive machine learning and active learning to HBR prediction. On the one hand, it can dramatically reduce the number of bug reports required for prediction model training; on the other hand, it improves the diversity and 
generalization ability
 of 
training samples
 via 
uncertainty sampling
.
Result:
We take security bug report (SBR) prediction as an example of HBR prediction and perform a large-scale experimental evaluation on datasets from different open-source projects. The results show: (1) hbrPredictor substantially outperforms the two baselines and obtains the maximum values of F1-score (0.7939) and AUC (0.8789); (2) with the dynamic 
stop criteria
, hbrPredictor could reach its best performance with only 45% and 13% of the total bug reports for small-sized datasets and large-sized datasets, respectively.
Conclusion:
By reducing the number of required 
training samples
, hbrPredictor could substantially save the data labeling effort without decreasing the effectiveness of the model.",May 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"hbrPredictor introduces a novel approach to predicting high-impact bug reports, demonstrating substantial performance improvements and data labeling savings, which can greatly benefit startups in ensuring software quality."
https://www.sciencedirect.com/science/article/pii/S0950584921000239,Alignment and granularity of requirements and architecture in agile development: A functional perspective,Tjerk=Spijkman: tjerk@fizor.io,"Abstract
Context:
Requirements engineering
 and software architecture are tightly linked disciplines. The Twin Peaks model suggests that requirements and architectural components should stay aligned while the system is designed and as the level of detail increases. Unfortunately, this is hardly the case in practical settings.
Objective:
We surmise that a reason for the absence of conjoint evolution is that existing models, such as the Twin Peaks, do not provide concrete guidance for practitioners. We propose the Requirements Engineering for Software Architecture (RE4SA) model to assist in analyzing the alignment and the 
granularity
 of functional requirements and architectural components.
Methods:
After detailing the RE4SA model in notation-independent terms, we propose a concrete instance, called RE4SA-Agile, that connects common artifacts in 
agile development
, such as user stories and features. We introduce metrics that measure the alignment between the requirements and architecture, and we define 
granularity
 smells to pinpoint situation in which the granularity of one high-level requirement or high-level component is not uniform with the norm. We show two applications of RE4SA-Agile, including the use of the metrics, to real-world 
case studies
.
Results:
Our applications of RE4SA-Agile, which were discussed with representatives from the development teams, prove to be able to pinpoint problematic situations regarding the relationship between functional requirements and architecture.
Conclusion:
RE4SA and its metrics can be seen as a first attempt to provide a concrete approach for supporting the application of the Twin Peaks model. We expect future research to apply our metrics to additional cases and to provide variants for RE4SA that support different concrete notations, and extend the perspective beyond the functional perspective of this research, similar to what we did with RE4SA-Agile in this paper.",May 2021,"Requirements engineering, Software architecture, Twin Peaks, Alignment, Granularity, Case study, Agile development",Information and Software Technology,2025-03-18T00:00:00,7.0,"RE4SA model offers concrete guidance for aligning requirements and architecture, helping practitioners analyze relationship granularity, although the immediate impact on startups may be less pronounced compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302172,Leveraging Small Sample Learning for Business Process Management,Martin=Käppel: martin.kaeppel@uni-bayreuth.de; Stefan=Schönig: stefan.schoenig@ur.de; Stefan=Jablonski: stefan.jablonski@uni-bayreuth.de,"Abstract
Context:
 Tool support for business process management (BPM) is improving more and more. Often, 
machine learning techniques
 are used to recognize certain execution patterns, to optimize workflows and to observe or predict processes. Frequently, many organisations cannot meet the fundamental prerequisites of 
machine learning
 methods since less data is recorded and therefore available for analysis. Most 
machine learning techniques
 rely on big and sufficient data source sets that can be analyzed. Small Sample Learning (SSL) tackles the issue of implementing 
machine learning
 methods in environments where only quantitatively insufficient datasets are available. These methods are strongly tailored to computer vision or 
natural language processing
 problems, which is why they are still neglected in the BPM area.
Objective:
 This paper motivates the use of SSL methods in the BPM area and fosters a research stream that is concerned with the transferability to and the application of these methods in the BPM area.
Method:
 We propose a concept for leveraging SSL methods in BPM and illustrate the idea exemplarly in the field of process mining.
Results:
 Reasons for the need of SSL methods in the BPM area and a conceptual approach for transferring existing SSL methods to the BPM area. The feasibility of our apprach is shown by a brief overview of a primary study leveraging SSL methods for process prediction.
Conclusions:
 Many areas of process mining or BPM in general depend on a sufficient amount of (training) data. Often 
small and medium sized companies
 lack ”big data”, which is why advantages of machine learning and data analysis in the context of BPM cannot be applied. Existing methods that deal with insufficient data are very domain-specific and must be transferred to the process mining area respectively the BPM area.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"SSL methods in BPM area show potential for leveraging machine learning in environments with limited data, but the direct impact on European early-stage ventures is more indirect and may require further research and application."
https://www.sciencedirect.com/science/article/pii/S0950584920302214,A systematic review of scheduling approaches on multi-tenancy cloud platforms,John=Grundy: john.grundy@monash.edu; Jacky Wai=Keung: Jacky.Keung@cityu.edu.hk; Ru=Jia: jiaruweiwei@gmail.com; Yun=Yang: yyang@swin.edu.au; Li=Hao: liucoolhao@gmail.com,"Abstract
Context:
Scheduling in cloud is complicated as a result of multi-tenancy. Diverse tenants have different requirements, including service functions, response time, QoS and throughput. Diverse tenants require different scheduling capabilities, resource consumption and competition. Multi-tenancy scheduling approaches have been developed for different service models, such as 
Software as a Service
 (SaaS), Platform as a service (PaaS), Infrastructure as a Service (IaaS), and Database as a Service (DBaaS).
Objective:
In this paper, we survey the current landscape of multi-tenancy scheduling, laying out the challenges and complexity of 
software engineering
 where multi-tenancy issues are involved. This study emphasises scheduling policies, cloud provisioning and deployment with regards to multi-tenancy issues. We conduct a systematic literature review of research studies related to multi-tenancy scheduling approaches on cloud platforms determine the primary scheduling approaches currently used and the challenges for addressing key multi-tenancy scheduling issues.
Method:
We adopted a systematic literature review method to search and review many major journal and 
conference papers
 on four major online electronic databases, which address our four predefined research questions. Defining inclusion and exclusion criteria was the initial step before extracting data from the selected papers and deriving answers addressing our enquiries.
Results:
Finally, 53 papers were selected, of which 62 approaches were identified. Most of these methods are developed without cloud layers’ limitation (43.40%) and on SaaS, most of scheduling approaches are oriented to framework design (43.75%).
Conclusion:
The results have demonstrated most of multi-tenancy scheduling solutions can work at any delivery layer. With the difference of tenants’ requirements and functionalities, the choice of cloud service delivery models is changed. Based on our study, designing a multi-tenancy scheduling framework should consider the following 3 factors: computing, QoS and storage resource. One of the potential research foci of multi-tenancy scheduling approaches is on GPU scheduling.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Multi-tenancy scheduling approaches for cloud platforms are crucial for different service models, offering valuable insights for startups working on cloud-based solutions."
https://www.sciencedirect.com/science/article/pii/S0950584920301981,Big Data analytics in Agile software development: A systematic mapping study,Katarzyna=Biesialska: katarzyna.biesialska@upc.edu,"Abstract
Context:
Over the last decade, Agile methods have changed the software development process in an unparalleled way and with the increasing popularity of Big Data, optimizing 
development cycles
 through 
data analytics
 is becoming a commodity.
Objective:
Although a myriad of research exists on 
software analytics
 as well as on 
Agile software development
 (ASD) practice on itself, there exists no 
systematic overview
 of the research done on ASD from a 
data analytics
 perspective. Therefore, the objective of this work is to make progress by linking ASD with 
Big Data analytics
 (BDA).
Method:
As the primary method to find relevant literature on the topic, we performed manual search and snowballing on papers published between 2011 and 2019.
Results:
In total, 88 primary studies were selected and analyzed. Our results show that BDA is employed throughout the whole 
ASD lifecycle
. The results reveal that data-driven software development is focused on the following areas: code repository analytics, defects/bug fixing, testing, project management analytics, and application usage analytics.
Conclusions:
As BDA and ASD are fast-developing areas, improving the productivity of software development teams is one of the most important objectives BDA is facing in the industry. This study provides scholars with information about the state of 
software analytics
 research and the current trends as well as applications in the business environment. Whereas, thanks to this literature review, practitioners should be able to understand better how to obtain actionable insights from their software artifacts and on which aspects of data analytics to focus when investing in such initiatives.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"Linking Agile Software Development with Big Data analytics can significantly impact software development teams' productivity, presenting valuable information for startups in software industry."
https://www.sciencedirect.com/science/article/pii/S095058492030238X,Identifying method-level mutation subsumption relations using Z3,Rohit=Gheyi: rohit@dsc.ufcg.edu.br; Leopoldo=Teixeira: lmt@cin.ufpe.br; Márcio=Ribeiro: marcio@ic.ufal.br; Baldoino=Fonseca: baldoino@ic.ufal.br; Beatriz=Souza: beatriz.souza@ccc.ufcg.edu.br; Marcio=Guimarães: masg@ic.ufal.br; Leo=Fernandes: leonardo.oliveira@ifal.edu.br; Marcelo=d’Amorim: damorim@cin.ufpe.br; Vander=Alves: valves@unb.br,"Abstract
Context:
Mutation analysis is a popular but costly approach to assess the quality of test suites. One recent promising direction in reducing costs of mutation analysis is to identify redundant mutations, i.e., mutations that are subsumed by some other mutations. A previous approach found redundant mutants manually through truth tables but it cannot be applied to all mutations. Another work derives them using automatic test suite generators but it is a time consuming task to generate mutants and tests, and to execute tests.
Objective:
This article proposes an approach to discover redundant mutants by proving 
subsumption relations
 among method-level 
mutation operators
 using weak mutation testing.
Method:
We conceive and encode a theory of 
subsumption relations
 in the Z3 
theorem prover
 for 37 mutation targets (mutations of an expression or statement).
Results:
We automatically identify and prove a number of subsumption relations using Z3, and reduce the number of mutations in a number of mutation targets. To evaluate our approach, we modified 
MuJava
 to include the results of 24 mutation targets and evaluate our approach in 125 classes of 5 large open source popular projects used in prior work. Our approach correctly discards mutations in 75.93% of the cases, and reduces the number of mutations by 71.38%.
Conclusions:
Our approach offers a good balance between the effort required to derive subsumption relations and the effectiveness for the targets considered in our evaluation in the context of strong mutation testing.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The approach to discover redundant mutants using weak mutation testing can provide cost-effective solutions for assessing test suite quality, which can benefit startups with limited resources."
https://www.sciencedirect.com/science/article/pii/S0950584920302445,Spectral clustering based mutant reduction for mutation testing,Xiangjuan=Yao: yaoxj@cumt.edu.cn,"Abstract
Context:
Mutation testing techniques, which attempt to construct a set of so-called mutants by seeding various faults into the software under test, have been widely used to generate test cases as well as to evaluate the effectiveness of a test suite. Its popularity in practice is significantly hindered by its high cost, majorly caused by the large number of mutants generated by the technique.
Objective:
It is always a challenging task to reduce the number of mutants while preserving the effectiveness of mutation testing. In this paper, we make use of an intelligent technique, namely 
spectral clustering
, to improve the efficacy of mutant reduction.
Method:
First of all, we give a family of definitions and the method to calculate the distance between mutants according to the weak mutation testing criteria. Then we propose a mutant reduction method based on 
spectral clustering
 (SCMT), including the determination method of the number of clusters, spectral clustering of mutants, and selection of representative mutants.
Results:
The experimental studies based on 12 object programs show that the new approach can significantly reduce the number of mutants without jeopardizing the performance of mutation testing. As compared with other benchmark techniques, the new approach based on weak mutation testing criteria cannot only consistently deliver high effectiveness of mutation testing, but also help significantly reduce the time-cost of mutation testing.
Conclusion:
It is clearly demonstrated that the use of spectral clustering can help enhance the cost-effectiveness of mutation testing. The research reveals some potential research directions for not only mutation testing but also the broad area of software testing.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The use of spectral clustering to improve mutation testing efficacy can lead to cost-effectiveness in software testing, offering potential benefits for startups looking to optimize their testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584920302408,Using mutual information to test from Finite State Machines: Test suite selection,Alfredo=Ibias: aibias@ucm.es; Manuel=Núñez: mn@sip.ucm.es; Robert M.=Hierons: r.hierons@sheffield.ac.uk,"Abstract
Context:
Mutual Information
 is an information 
theoretic measure
 designed to quantify the amount of similarity between two 
random variables
 ranging over two sets. In this paper, we adapt this concept and show how it can be used to select a 
good
 test suite to test from a 
Finite State Machine
 (
FSM
) based on a 
maximise diversity
 approach.
Objective:
The main goal of this paper is to use 
Mutual Information
 in order to select test suites to test from 
FSM
s and evaluate whether we obtain better results, concerning the quality of the selected test suite, than current state-of-the-art measures.
Method:
First, we defined our scenario. We considered the case where we receive two (or more) test suites and we have to choose between them. We were interested in this scenario because it is a 
recurrent
 case in regression testing. Second, we defined our notion based on 
Mutual Information
: Biased 
Mutual Information
. Finally, we carried out experiments in order to evaluate the measure.
Results:
We obtained experimental evidence that demonstrates the potential value of the measure. We also showed that the time needed to compute the measure is negligible when compare to the time needed to apply extra testing. We compared our measure with a state-of-the-art test selection measure and showed that our proposal outperforms it. Finally, we have compared our measure with a notion of transition coverage. Our experiments showed that our measure is slightly worse than transition coverage, as expected, but its computation is 10 times faster.
Conclusion:
Our experiments showed that Biased Mutual Information is a good measure for selecting test suites, outperforming the current state-of-the-art measure, and having a (negative) correlation to fault coverage. Therefore, we can conclude that our new measure can be used to select the test suite that is likely to find more faults. As a result, it has the potential to be used to automate test generation.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The paper presents a new measure for selecting test suites, which outperforms current state-of-the-art measures and has potential to automate test generation, benefiting early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302470,Validating class integration test order generation systems with Metamorphic Testing,Tsong Yueh=Chen: tychen@swin.edu.au; Yan=Xiao: dcsxan@nus.edu.sg; Miao=Zhang: miazhang9-c@my.cityu.edu.hk; Jacky Wai=Keung: jacky.Keung@cityu.edu.hk,"Abstract
Context:
Previous studies proposed different kinds of approaches for class integration test order generation, and corresponding systems can be implemented based on these approaches. Such class integration test order generation systems can facilitate the process of software integration testing if they are implemented correctly.
Objective:
However, a test oracle problem exists in the class integration test order generation systems. Since these approaches for class integration test order generation normally deliver a local optimum rather than a global optimum, there are no practically feasible ways to validate their generated class integration test orders, that is, these implementation systems are untestable.
Method:
To address the test oracle problem, we apply Metamorphic Testing (MT) to validate class integration test order generation systems. Metamorphic Relations (MRs), which are the key components of MT, reason about relations between test outputs of a system. Five effective MRs are developed to ensure the quality of the class integration test order generation systems. In these proposed MRs, follow-up test inputs are generated by modifying classes or class dependencies in the source test inputs while some characteristics of the source test outputs are preserved, for example, the same class integration test order or the equal stubbing cost. Faults can be detected in systems if an individual MR is violated for certain tests.
Results:
Failure detection of MT has been successfully demonstrated in empirical experiments on three systems implementing different typical class integration test order generation approaches. More than 84% of faulty programs can be detected by all MRs, for three class integration test order generation systems under investigation.
Conclusion:
The experimental results show that the proposed MRs are able to systematically and effectively detect faults in class integration test order generation systems. This study explores a new application domain in MT and further extends its applications in 
Software Engineering
.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study introduces a new application of Metamorphic Testing to detect faults in class integration test order generation systems, showing effectiveness in fault detection, which can be valuable for startups in improving software testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584920302044,Fast and curious: A model for building efficient monitoring- and decision-making frameworks based on quantitative data,Iris=Figalist: iris.figalist@siemens.com,"Abstract
Context:
Nowadays, the hype around 
artificial intelligence
 is at its absolute peak. Large amounts of data are collected every second of the day and a variety of tools exists to enable easy 
analysis of data
. In practice, however, making meaningful use of it is way more challenging. For instance, affected stakeholders often struggle to specify their information needs and to interpret the results of such analyses.
Objective:
In this study we investigate how to enable continuous monitoring of information needs, and the generation of knowledge and insights for various stakeholders involved in the lifecycle of software-intensive products. The overarching goal is to support their decision making by providing relevant insights related to their area of responsibility.
Methods:
We implement multiple monitoring- and decision-making frameworks for six individual, real-world cases selected from three different platforms and covering four types of stakeholders. We compare the individual procedures to derive a 
generic process
 for instantiating such frameworks as well as a model to scale it up for multiple stakeholders.
Results:
For one, we discovered that information needs of stakeholders are often related to a limited subset of 
data sources
 and should be specified in stages. For another, stakeholders often benefit from sharing and reusing existing components among themselves in later phases. Specifically, we identify three types of reuse: (1) Data and knowledge, (2) tools and methods, and (3) concepts. As a result, key aspects of our model are iterative feedback and specification cycles as well as the reuse of appropriate components to speed up the 
instantiation
 process and maximize the efficiency of the model.
Conclusion:
Our results indicate that knowledge and insights can be generated much faster and stakeholders feel the benefits of the analysis very early on by iteratively specifying information needs and by systematically sharing and reusing knowledge, tools and concepts.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The research provides insights on enabling continuous monitoring of information needs for stakeholders in software-intensive products, offering a generic process that could potentially enhance decision-making processes for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302160,Do users care about ad’s performance costs? Exploring the effects of the performance costs of in-app ads on user experience,Cuiyun=Gao: cygao@cse.cuhk.edu.hk; Jichuan=Zeng: jczeng@cse.cuhk.edu.hk; Federica=Sarro: f.sarro@ucl.ac.uk; David=Lo: davidlo@smu.edu.sg; Irwin=King: king@cse.cuhk.edu.hk; Michael R.=Lyu: lyu@cse.cuhk.edu.hk,"Abstract
Context:
 In-app advertising is the primary source of revenue for many mobile apps. The cost of advertising (ad cost) is non-negligible for app developers to ensure a good 
user experience
 and continuous profits. Previous studies mainly focus on addressing the hidden performance costs generated by ads, including consumption of memory, CPU, data traffic, and 
battery
. However, there is no research on analyzing users’ perceptions of ads’ performance costs to our knowledge.
Objective:
 To fill this gap and better understand the effects of performance costs of in-app ads on 
user experience
, we conduct a study on analyzing user concerns about ads’ performance costs.
Method:
 First, we propose RankMiner, an approach to quantify user concerns about specific app issues, including performance costs. Then, based on the usage traces of 20 subject apps, we measure the performance costs of ads. Finally, we conduct correlation analysis on the performance costs and quantified user concerns to explore whether users complain more for higher performance costs.
Results:
 Our findings include the following: (1) RankMiner can quantify users’ concerns better than baselines by an improvement of 214% and 2.5% in terms of 
Pearson
 
correlation coefficient
 (a metric for computing correlations between two variables) and NDCG score (a metric for computing accuracy in prioritizing issues), respectively. (2) The performance costs of the with-ads versions are statistically significantly larger than those of no-ads versions with 
negligible effect
 size; (3) Users are more concerned about the battery costs of ads, and tend to be insensitive to ads’ data traffic costs.
Conclusion:
 Our study is complementary to previous work on in-app ads, and can encourage developers to pay more attention to alleviating the most user-concerned performance costs, such as battery cost.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study analyzes users' perceptions of in-app ads' performance costs, introducing a new approach to quantify user concerns and providing valuable insights for app developers to improve user experience, which can be beneficial for startups focused on optimizing revenue."
https://www.sciencedirect.com/science/article/pii/S0950584920302299,"A methodical framework for service oriented architecture adoption: Guidelines, building blocks, and method fragments",Supriya=Pulparambil: s.pulparambil@squ.edu.com; Youcef=Baghdadi: ybaghdadi@squ.edu.om; Camille=Salinesi: camille.salinesi@univ-paris1.fr,"Abstract
Context
Rapidly-changing business requirements expect high business process flexibility that can be achieved using 
service oriented architecture
 (SOA). This requires enterprises to adopt SOA and assess their SOA adoption maturity to achieve continuous improvement. SOA realization demands service development with varying levels of 
granularity
.
Objectives
The research aims to develop a methodical framework for SOA realization based on Welke's SOA maturity model, a model that assumes a methodology dimension. The framework is concerned with formalizing knowledge on how to identify and shape the main 
building blocks
 of a method at each maturity level.
Methods
The research applies the principles of 
design science research
 and method engineering to develop a methodical framework for SOA realization.
Results
The research identifies the gaps in SOA realization methods and illustrates how a methodical framework based on a maturity model facilitates the SOA adoption process. The evaluation results revealed that the framework would help enterprises to select method fragments required at each maturity level to accomplish business excellence.
Conclusion
The implications of this research are twofold: from a theoretical perspective, the researchers or practitioners can use the results for further study. From a practical standpoint, enterprises can use the methodical guidelines to assess their current maturity level and select and implement the required method fragments from the method base provided in the proposed framework.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The framework developed for SOA realization based on a maturity model may provide some guidance for enterprises, but the practical value for early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302482,On the prediction of long-lived bugs: An analysis and comparative study using FLOSS projects,Luiz Alberto Ferreira=Gomes: luizgomes@pucpcaldas.br; Ricardo=da Silva Torres: ricardo.torres@ntnu.no; Mario Lúcio=Côrtes: cortes@ic.unicamp.br,"Abstract
Context:
Software evolution and maintenance activities in today’s Free/Libre 
Open Source Software
 (FLOSS) rely primarily on information extracted from 
bug reports
 registered in 
bug tracking systems
. Many studies point out that most bugs that adversely affect the user’s experience across versions of 
FLOSS projects
 are long-lived bugs. However, proposed approaches that support bug fixing procedures do not consider the real-world lifecycle of a bug, in which bugs are often fixed very fast. This may lead to useless efforts to automate the bug management process.
Objective:
This study aims to confirm whether the number of long-lived bugs is significantly high in popular open-source projects and to characterize the population of long-lived bugs by considering the attributes of 
bug reports
. We also aim to conduct a comparative study evaluating the prediction accuracy of five well-known 
machine learning algorithms
 and text mining techniques in the task of predicting long-lived bugs.
Methods:
We collected bug reports from six popular open-source projects repositories (Eclipse, Freedesktop, Gnome, GCC, Mozilla, and WineHQ) and used the following 
machine learning algorithms
 to predict long-lived bugs: K-Nearest Neighbor, Naïve Bayes, 
Neural Networks
, 
Random Forest
, and 
Support Vector Machines
.
Results:
Our results show that long-lived bugs are relatively frequent (varying from 7.2% to 40.7%) and have unique characteristics, confirming the need to study solutions to support bug fixing management. We found that the Neural Network classifier yielded the best results in comparison to the other algorithms evaluated.
Conclusion:
Research efforts regarding long-lived bugs are needed and our results demonstrate that it is possible to predict long-lived bugs with a high accuracy (around 70.7%) despite the use of simple prediction algorithms and text mining methods.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The study addresses a significant issue in FLOSS projects regarding bug management and provides practical insights for improving bug fixing procedures using machine learning algorithms.
https://www.sciencedirect.com/science/article/pii/S0950584920302469,Multifaceted infrastructure for self-adaptive IoT systems,Rossana M.C.=Andrade: rossana@great.ufc.br; Belmondo R.=Aragão: belmondorodrigues@great.ufc.br; Pedro Almir M.=Oliveira: pedromartins@great.ufc.br; Marcio E.F.=Maia: marcio@great.ufc.br; Windson=Viana: windson@great.ufc.br; Tales P.=Nogueira: tales@great.ufc.br,"Abstract
Background:
Internet of Things
 (IoT) enables the interaction among objects to provide services to their users. Areas such as eHealth, smart energy, and smart buildings have been benefiting from the IoT potential. However, the development of IoT systems is still complex because it deals with a highly dynamic, volatile, and heterogeneous environment. These characteristics require discovering devices, managing these devices’ context, and self-adapt their behavior.
Goal
: In this work, we propose a self-adaptive IoT infrastructure to support multiple facets, 
i.e.
, the contextual discovery of smart objects, the context management, and the self-adaptation process of the development of these systems.
Methods
: We evaluated the proposed infrastructure by developing a smart building application with and without it. The evaluation focused on four issues: the feasibility of integrating the context management through middleware platforms with adaptation based on workflows in a request/response communication model, the impact of our infrastructure on the development of self-adaptive IoT systems considering 
cyclomatic complexity
 and coupling 
code metrics
; the impact of using contextual filters on the orchestrator of self-adaptation; and the impact on the quality of the self-adaptation.
Results
: The results suggest that: (i) it is feasible to use the proposed infrastructure in the development of self-adaptive IoT systems; (ii) there is a reduction in the 
cyclomatic complexity
 and the coupling with our approach, (iii) there is a considerable decrease in the number of rules evaluated at runtime, (iv) our infrastructure reduces the execution time of the adaptations when using contextual filters, and (v) the self-adaptation process was effective when using the orchestrator of self-adaptations.
Conclusion
: With these results, we observed that the proposed multifaceted infrastructure could reduce the complexity related to the development of IoT systems, in addition to optimizing their self-adaptation process.",April 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The proposed self-adaptive IoT infrastructure shows potential for simplifying the development of IoT systems, but the impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000367,The weaker sex? A tale of means and tails,David B.=Audretsch: daudrets@indiana.edu; Indu=Khurana: ikhurana@hsc.edu; Jagannadha Pawan=Tamvada: jp.tamvada@soton.ac.uk,"Abstract
One of the most commonly held beliefs prevalent in entrepreneurship research is that women-led ventures tend to generate lower earnings than men-led ventures. We contend that this thinking emanates from empirical analyses that obscure the variation in entrepreneurial performance across the earnings distribution. Relying solely on the mean as a measure of central tendency conceals the heterogeneity among so-called underperformers. Using density plots from a nationally representative database, we demonstrate that women-led ventures perform better at some quantiles of the earnings distribution, contrary to the common myth that men-led ventures consistently outperform them. Our study debunks this myth and contributes to entrepreneurship research that adopts a gendered perspective by showing that the reality experienced by women entrepreneurs is not as dismal as it appears when compared to focusing exclusively on the mean. Our study has implications for policymakers, who need to adjust their policy approach by designing targeted policies explicitly incorporating the heterogeneity inherent in entrepreneurship.",November 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"This abstract challenges a commonly held belief in entrepreneurship research and highlights the heterogeneity in entrepreneurial performance, particularly focusing on women-led ventures. The findings could be impactful for European startups in terms of addressing gender disparities and reevaluating performance metrics."
https://www.sciencedirect.com/science/article/pii/S0950584920301993,Understanding and addressing quality attributes of microservices architecture: A Systematic literature review,He=Zhang: dr.hezhang@gmail.com,"Abstract
Context
: As a rapidly adopted 
architectural style
 in 
software engineering
, 
Microservices Architecture
 (MSA) advocates implementing small-scale and independently distributed services, rather than binding all functions into one monolith. Although many initiatives have contributed to the quality improvement of microservices-based systems, there is still a lack of a systematic understanding of the Quality Attributes (QAs) associated with MSA.
Objective
: This study aims to investigate the evidence-based state-of-the-art of QAs of microservices-based systems.
Method
: We carried out a Systematic Literature Review (SLR) to identify and synthesize the relevant studies that report evidence related to QAs of MSA.
Results
: Based on the data extracted from the 72 selected primary studies, we portray an overview of the six identified QAs most concerned in MSA, 
scalability, performance, availability, monitorability, security
, and 
testability
. We identify 19 tactics that architecturally address the critical QAs in MSA, including two tactics for 
scalability
, four for 
performance
, four for 
availability
, four for 
monitorability
, three for 
security
, and two for 
testability
.
Conclusion
: This SLR concludes that for MSA-based systems: 1) Although 
scalability
 is the commonly acknowledged benefit of MSA, it is still an indispensable concern among the identified QAs, especially when trading-off with other QAs, e.g., 
performance
. Apart from the six identified QAs in this study, other QAs for MSA like 
maintainability
 need more attention for effective improvement and evaluation in the future. 3) Practitioners need to carefully make the decision of migrating to MSA based on the 
return on investment
, since this 
architectural style
 additionally cause some pains in practice.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The investigation of Quality Attributes in Microservices Architecture contributes to the understanding of MSA quality concerns, but the practical impact on European startups may vary."
https://www.sciencedirect.com/science/article/pii/S0950584920302019,Feature selection and embedding based cross project framework for identifying crashing fault residence,Meng=Yan: mengy@cqu.edu.cn; Xiapu=Luo: csxluo@comp.polyu.edu.hk,"Abstract
Context: The automatically produced crash reports are able to analyze the root of fault causing the crash (crashing fault for short) which is a critical activity for 
software quality assurance
.
Objective: Correctly predicting the existence of crashing fault residence in stack traces of crash report can speed up 
program debugging
 process and optimize debugging efforts. Existing work focused on the collected label information from bug-fixing logs, and the extracted features of crash instances from stack traces and 
source code
 for 
I
dentification of 
C
rashing 
F
ault 
R
esidence (
ICFR
) of newly-submitted crashes. This work develops a novel cross project ICFR framework to address the data scarcity problem by using labeled crash data of other project for the ICFR task of the project at hand. This framework removes irrelevant features, reduces distribution differences, and eases the 
class imbalance
 issue of cross project data since these factors may negatively impact the ICFR performance.
Method: The proposed framework, called 
FSE
, combines 
F
eature 
S
election and feature 
E
mbedding techniques. The FSE framework first uses an 
information gain
 ratio based feature ranking method to select a relevant feature subset for cross project data, and then employs a state-of-the-art 
W
eighted 
B
alanced 
D
istribution 
A
daptation (
WBDA
) method to map features of cross project data into a common space. WBDA considers both marginal and conditional distributions as well as their weights to reduce 
data distribution
 discrepancies. Besides, WBDA balances the class proportion of each project data to alleviate the 
class imbalance
 issue.
Results: We conduct experiments on 7 projects to evaluate the performance of our FSE framework. The results show that FSE outperforms 25 methods under comparison.
Conclusion: This work proposes a cross project learning framework for ICFR, which uses feature selection and embedding to remove irrelevant features and reduce distribution differences, respectively. The results illustrate the performance superiority of our FSE framework.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed cross project learning framework for ICFR demonstrates superior performance and addresses a critical issue in software quality assurance, making it highly relevant for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302202,A decentralized approach for discovering runtime software architectural models of distributed software systems,Jason=Porter: jason.porter@ung.edu; Daniel A.=Menascé: menasce@gmu.edu,"Abstract
Context:
Runtime software 
architectural models
 of self-adaptive systems are needed for making adaptation decisions in architecture-based self-adaptive systems. However, when these systems are distributed and highly dynamic, there is an added need to discover the system’s software architecture model at runtime. Current methods of runtime architecture discovery use a 
centralized approach
, in which the process is carried out from a single location. These methods are inadequate for large distributed software systems because they do not scale up well and have a 
single point of failure
.
Objective and Method:
This paper describes DeSARM (Decentralized Software Architecture discoveRy Mechanism), a completely decentralized and automated approach, based on gossiping and message tracing, for runtime discovery of software architecture models of distributed software systems. DeSARM is able to identify at runtime important architectural characteristics such as components and connectors, in addition to 
synchronous and asynchronous communication
 patterns. Furthermore, through its use of gossiping, DeSARM exhibits the properties of scalability, global consistency among participating nodes, and resiliency to failures. This paper demonstrates DeSARM’s properties and answers key research questions through experimentation with software architectures of varying sizes and complexities executing within a computer cluster.
Results:
DeSARM enables the decentralized discovery of runtime software 
architectural models
 of distributed software systems while exhibiting the properties of scalability, global consistency among participating nodes and resiliency to failures. Scalability is achieved through DeSARM’s ability to successfully discover software architectures of increasing sizes and complexities executing across node counts of increasing sizes. Global consistency among participating nodes is achieved by each node within the system discovering the complete software architecture independently but in coordination with each other. Finally, resiliency to failures is achieved by DeSARM successfully discovering the software architecture of the system in the presence of component failures.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Decentralized runtime discovery of software architecture models for distributed systems with properties of scalability, global consistency, and resiliency to failures has significant practical value for early-stage ventures developing complex software systems."
https://www.sciencedirect.com/science/article/pii/S0950584920302275,Mining the Technical Roles of GitHub Users,Marco Túlio=Valente: mtov@dcc.ufmg.br; João Eduardo=Montandon: joao.montandon@dcc.ufmg.br; Luciana L.=Silva: luciana.lourdes.silva@ifmg.edu.br,"Abstract
Context:
Modern software development demands high levels of technical specialization. These conditions make IT companies focus on creating cross-functional teams, such as frontend, backend, and mobile developers. In this context, the success of software projects is highly influenced by the expertise of these teams in each field.
Objective:
In this paper, we investigate machine-learning based approaches to automatically identify the technical roles of open source developers.
Method:
For this, we first build a ground truth with 2284 developers labeled in six different roles: backend, frontend, full-stack, mobile, devops, and data science. Then, we build three different machine-learning models used to identify these roles.
Results:
These models presented competitive results for precision (0.88) and AUC (0.89) when identifying all six roles. Moreover, our results show that programming-languages are the most relevant features to predict the investigated roles.
Conclusion:
The approach proposed in this paper can assist companies during their hiring process, such as by recommending developers with the expertise required by job positions.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Machine learning-based approaches to automatically identify technical roles of developers can assist startups in building cross-functional teams, but the direct impact on European early-stage ventures may be slightly limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302305,Security in agile software development: A practitioner survey,Kalle=Rindell: kakrind@utu.fi,"Abstract
Context:
 Software 
security engineering
 provides the means to define, implement and verify security in software products. Software security engineering is performed by following a software security 
development life cycle
 model or a security 
capability maturity model
. However, agile 
software development methods
 and processes, dominant in the software industry, are viewed to be in conflict with these security practices and the security requirements.
Objective:
 Empirically verify the use and impact of software security engineering activities in the context of 
agile software development
, as practiced by software developer professionals.
Method:
 A survey (
N
=
61
) was performed among software practitioners in Finland regarding their use of 40 common security engineering practices and their perceived security impact, in conjunction with the use of 16 agile software development items and activities.
Results:
 The use of agile items and activities had a measurable effect on the selection of security engineering practices. Perceived impact of the security practices was lower than the rate of use would imply: This was taken to indicate a selection bias, caused by e.g. developers’ awareness of only certain security engineering practices, or by difficulties in applying the security engineering practices into an iterative software development workflow. Security practices deemed to have most impact were proactive and took place in the early phases of software development.
Conclusion:
 Systematic use of agile practices conformed, and was observed to take place in conjunction with the use of security practices. Security activities were most common in the requirement and implementation phases. In general, the activities taking place early in the life cycle were also considered most impactful. A discrepancy between the level of use and the perceived security impact of many security activities was observed. This prompts research and methodological development for better integration of security engineering activities into software development processes, methods, and tools.",March 2021,"Survey, Security engineering, Agile software development, Software security, Security standards, Security assurance",Information and Software Technology,2025-03-18T00:00:00,6.0,"Empirical verification of software security engineering activities in agile software development can be relevant to European startups, but the impact on practical application may be moderate compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302433,SRPTackle: A semi-automated requirements prioritisation technique for scalable requirements of software system projects,Fadhl=Hujainah: fadelhogina@gmail.com,"Abstract
Context
Requirement prioritisation (RP) is often used to select the most important 
system requirements
 as perceived by system stakeholders. RP plays a vital role in ensuring the development of a quality system with defined constraints. However, a closer look at existing RP techniques reveals that these techniques suffer from some key challenges, such as scalability, lack of quantification, insufficient prioritisation of participating stakeholders, overreliance on the participation of professional expertise, lack of automation and excessive time consumption. These key challenges serve as the motivation for the present research.
Objective
This study aims to propose a new semiautomated scalable prioritisation technique called ‘SRPTackle’ to address the key challenges.
Method
SRPTackle provides a semiautomated process based on a combination of a constructed requirement priority value formulation function using a multi-criteria decision-making method (i.e. weighted sum model), 
clustering algorithms
 (K-means and K-means++) and a 
binary search tree
 to minimise the need for expert involvement and increase efficiency. The effectiveness of SRPTackle is assessed by conducting seven experiments using a benchmark dataset from a large actual software project.
Results
Experiment results reveal that SRPTackle can obtain 93.0% and 94.65% as minimum and maximum accuracy percentages, respectively. These values are better than those of alternative techniques. The findings also demonstrate the capability of SRPTackle to prioritise large-scale requirements with reduced time consumption and its effectiveness in addressing the key challenges in comparison with other techniques.
Conclusion
With the time effectiveness, ability to scale well with numerous requirements, automation and clear implementation guidelines of SRPTackle, project managers can perform RP for large-scale requirements in a proper manner, without necessitating an extensive amount of effort (e.g. tedious manual processes, need for the involvement of experts and time workload).",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"Proposing a new semiautomated scalable prioritization technique for system requirements with high accuracy percentages, reduced time consumption, and clear implementation guidelines can have a significant positive impact on European early-stage ventures in managing large-scale requirements efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584920302159,Dynamic random testing with test case clustering and distance-based parameter adjustment,Beibei=Yin: yinbeibei@buaa.edu.cn; Hanyu=Pei: peihanyu@buaa.edu.cn; Kai-Yuan=Cai: kycai@buaa.edu.cn,"Abstract
Context
Software testing is essential in 
software engineering
 to improve 
software reliability
. One goal of software testing strategies is to detect faults faster. Dynamic Random Testing (DRT) strategy uses the testing results to guide the selection of test cases, which has shown to be effective in the 
fault detection
 process.
Objective
Previous studies have demonstrated that DRT is greatly affected by the test case classification and the process of adjusting the testing profile. In this paper, we propose Distance-based DRT (D-DRT) strategies, aiming at enhancing the 
fault detection
 effectiveness of DRT.
Method
D-DRT strategies utilize distance information of inputs into the test case classification and the testing profile adjustment process. The test cases are vectorized based on the input parameters and classified into disjoint 
subdomains
 through certain 
clustering methods
. And the distance information of 
subdomains
, along with testing results, are used to adjust the testing profile, such that test cases that are closer to failure-causing subdomains are more likely to be selected.
Results
We conduct empirical studies to evaluate the performance of the proposed algorithms using 12 versions of 4 open-source programs. The experimental results show that, compared with Random Testing (RT), Random Partition Testing (RPT), DRT and Adaptive Testing (AT), our strategies achieve greater fault detection effectiveness with a low computational cost. Moreover, the distance-based testing profile adjustment method is the dominant factor in the improvement of the D-DRT strategy.
Conclusion
D-DRT strategies are effective testing strategies, and the distance-based testing profile adjustment method plays a crucial role.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Introducing Distance-based Dynamic Random Testing strategies for enhancing fault detection effectiveness in software testing can be beneficial for startups, but the practical impact compared to other abstracts may be slightly lower."
https://www.sciencedirect.com/science/article/pii/S0950584920302196,Method-level bug localization using hybrid multi-objective search,Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Marouane=Kessentini: marouane@umich.edu; Rafi=Almhana: ralmhana@umich.edu,"Abstract
Context:
 One of the time-consuming maintenance tasks is the localization of bugs especially in large software systems. Developers have to follow a tedious process to reproduce the abnormal behavior then inspect a large number of files. While several studies have been proposed for bugs localization, the majority of them are recommending classes/files as outputs which may still require high inspection effort. Furthermore, there is a significant difference between the natural language used in 
bug reports
 and the programming language which limits the efficiency of existing approaches since most of them are mainly based on lexical similarity.
Objective:
 In this paper, we propose an automated approach to find and rank the potential methods in order to localize the source of a bug based on a bug report description.
Method:
 Our approach finds a good balance between minimizing the number of recommended classes and maximizing the relevance of the proposed solution using a hybrid multi-objective 
optimization algorithm
 combining local and global search. The relevance of the recommended code fragments is estimated based on the use of the history of changes and bug-fixing, and the lexical similarity between the bug report description and the API documentation. Our approach operates on two main steps. The first step is to find the best set of classes satisfying the two conflicting criteria of relevance and the number of classes to recommend using a global search based on NSGA-II. The second step is to locate the most appropriate methods to inspect, using a local multi-objective search based on Simulated Annealing (MOSA) from the list of classes recommended by the first step.
Results:
 We evaluated our system on 6 open source Java projects, using the version of the project before fixing the bug of many 
bug reports
. Our hybrid multi-objective approach is able to successfully locate the true buggy methods within the top 10 recommendations for over 78% of the bug reports leading to a significant reduction of developers’ effort comparing to class-level bug localization techniques.
Conclusion:
 The experimental results show that the search-based approach significantly outperforms four state-of-the-art methods in recommending relevant files for bug reports.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The automated approach proposed for bug localization can significantly reduce developers' effort leading to a practical impact on early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584920302391,A risk prediction model for software project management based on similarity analysis of context histories,Alexsandro Souza=Filippetto: alexsandrofilippetto@gmail.com; Robson=Lima: robsonklima@gmail.com; Jorge Luis Victória=Barbosa: jbarbosa@unisinos.br,"Abstract
Context
Risk event management has become strategic in Project Management, where uncertainties are inevitable. In this sense, the use of concepts of ubiquitous computing, such as contexts, context histories, and mobile computing can assist in proactive project management.
Objective
This paper proposes a computational model for the reduction of the probability of project failure through the prediction of risks. The purpose of the study is to show a model to assist teams to identify and monitor risks at different points in the life cycle of projects. The work presents as scientific contribution to the use of context histories to infer the recommendation of risks to new projects.
Method
The research conducted a case study in a software development company. The study was applied in two scenarios. The first involved two teams that assessed the use of the prototype during the implementation of 5 projects. The second scenario considered 17 completed projects to assess the recommendations made by the Átropos model comparing the recommendations with the risks in the original projects. In this scenario, Átropos used 70% of each project's execution as learning for the recommendations of risks generated to the same projects. Thus, the scenario aimed to assess whether the recommended risks are contained in the remaining 30% of the executed projects. We used as context histories, a database with 153 software projects from a financial company.
Results
A project team with 18 professionals assessed the recommendations, obtaining a result of 73% acceptance and 83% accuracy when compared to projects already being executed. The results demonstrated a high percentage of acceptance of the recommendation of risks compared to the other models that do not use the characteristics and similarities of projects.
Conclusion
The results show the applicability of the risk recommendation to new projects, based on the similarity analysis of context histories. This study applies inferences on context histories in the development and planning of projects, focusing on risk recommendation. Thus, with recommendations considering the characteristics of each new project, the manager starts with a larger set of information to make more assertive project planning.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The computational model for risk prediction in project management can assist in proactive management, but its impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920302263,On deriving conceptual models from user requirements: An empirical study,Fabiano=Dalpiaz: f.dalpiaz@uu.nl,"Abstract
Context:
 There are numerous textual notations and techniques that can be used in requirements engineering. Currently, practitioners make a choice without having scientific evidence regarding their suitability for given tasks. This uninformed choice may affect task performance. 
Objective:
 In this research, we investigate the adequacy of two well-known notations: use cases and user stories, as a starting point for the manual derivation of a structural conceptual model that represents the domain of the system. We also examine other factors that may affect the performance of this task. 
Methods:
 This work relies on two experiments. The first is a controlled classroom experiment. The second one is a quasi-experiment, conducted over multiple weeks, that aims at evaluating the quality of the derived conceptual model in light of the notation used, the adopted derivation process, and the complexity of the system to be. We 
measure quality
 in terms of validity and completeness of the conceptual model. 
Results:
 The results of the controlled experiment indicate that, for deriving conceptual models, user stories fit better than use cases. Yet, the second experiment indicates that the quality of the derived conceptual models is affected mainly by the derivation process and by the complexity of the case rather than the notation used. 
Contribution:
 We present evidence that the task of deriving a conceptual model is affected significantly by additional factors other than requirements notations. Furthermore, we propose implications and hypotheses that pave the way for further studies that compare alternative notations for the same task as well as for other tasks. Practitioners may use our findings to analyze the factors that affect the quality of the conceptual model when choosing a requirements notation and an 
elicitation
 technique that best fit their needs.",March 2021,"Requirements engineering, Conceptual modeling, Use cases, User stories, Derivation process",Information and Software Technology,2025-03-18T00:00:00,7.0,"The investigation into the adequacy of requirements engineering notations provides valuable insights for practitioners, albeit with moderate immediate practical value."
https://www.sciencedirect.com/science/article/pii/S0950584920301002,Runtime testing of context-aware variability in adaptive systems,Rossana M.C.=Andrade: rossana@great.ufc.br; Erick Barros dos=Santos: erickbarros@great.ufc.br; Ismayle de Sousa=Santos: ismaylesantos@great.ufc.br,"Abstract
Context:
 A Dynamically Adaptive System (DAS) supports runtime adaptations to handle changes in the 
operational environment
. These adaptations can change the system’s structure or behavior and even the logic of its adaptation mechanism. However, these adaptations may insert defects, leading the system to fail at runtime.
Objective:
 Aiming to identify these failures, testing can be executed to verify the system at runtime. Studies in the literature mostly focus on testing to verify the adaptations at design-time or functionalities at runtime, rather than exercising the adaptation mechanism at runtime. So, we propose RETAkE (RuntimE Testing of dynamically Adaptive systEms).
Method:
 RETAkE is an approach to perform the runtime testing based on the system’s context variability and feature modeling. RETAkE tests the adaptation mechanism, enabling the verification of its adaptation rules with the system’s variability model. The runtime testing is supported by the verification of behavioral properties. For the evaluation, we used the mutation testing technique with two DAS. We also conducted an evaluation to measure the overhead introduced when RETAkE is integrated to the DAS.
Results:
 RETAkE identified the mutants in the two mobile DAS, but the results vary due to the probabilistic nature of the approach to generate test sequences. Regarding the overhead, test sequences of size 30 had a low impact. However, bigger test sequences increase the overhead.
Conclusion:
 The integration of RETAkE to the DAS adaptation mechanism can support the discovery of adaptation failures that occur at runtime. Furthermore, the results of the evaluation suggest its feasibility to perform runtime testing.",March 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The RETAkE approach for runtime testing of Dynamically Adaptive Systems can support the discovery of adaptation failures, which can be beneficial for early-stage ventures relying on such systems."
https://www.sciencedirect.com/science/article/pii/S0950584920301610,Quality Assessment in Systematic Literature Reviews: A Software Engineering Perspective,Haifeng=Shen: Haifeng.Shen@acu.edu.au; Guoping=Rong: ronggp@nju.edu.cn; Lanxin=Yang: yang931001@outlook.com; He=Zhang: hezhang@nju.edu.cn; Xin=Huang: njuhuangx@outlook.com; Xin=Zhou: job@wetist.com; Dong=Shao: dongshao@nju.edu.cn,"Abstract
Context
: Quality Assessment (QA) of reviewed literature is paramount to a 
Systematic Literature Review
 (SLR) as the quality of conclusions completely depends on the quality of selected literature. A number of researchers in 
Software Engineering
 (SE) have developed a variety of QA instruments and also reported their challenges. We previously conducted a tertiary study on SLRs with QA from 2004 to 2013, and reported the findings in 2015.
Objective
: With the widespread use of SLRs in SE and the increasing adoption of QA in these SLRs in recent years, it is necessary to empirically investigate whether the previous conclusions are still valid and whether there are new insights to the subject in question using a larger and a more up-to-date SLR set. More importantly, we aim to depict a clear picture of QA used in SLRs in SE by aggregating and distilling good practices, including the commonly used QA instruments as well as the major roles and aspects of QA in research.
Method
: An extended tertiary study was conducted with the newly collected SLRs from 2014 to 2018 and the original SLRs from 2004 to 2013 to systematically review the QA used by SLRs in SE during the 15-year period from 2004 to 2018. In addition, this extended study also compared and contrasted the findings of the previous study conducted in 2015.
Results
: A total of 241 SLRs between 2004 and 2018 were included, from which we identified a number of QA instruments. These instruments are generally designed to focus on the rationality of study design, the rigor of study execution and analysis, and the credibility and contribution of study findings and conclusions, with the emphasis largely placed on its rigor. The quality data is mainly used for literature selection or as evidence to support conclusions.
Conclusions
: QA has received much attention in SE in more recent years and the improvement is evident since the last study in 2015. New findings show that the aims are more concise, the instruments are more diverse and rigorous, and the criteria are more thoughtful.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on Quality Assessment in Systematic Literature Reviews provides valuable insights, but the practical impact on early-stage ventures or startups may not be as direct as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920301737,Boundary sampling to boost mutation testing for deep learning models,Yanhui=Li: yanhuili@nju.edu.cn,"Abstract
Context: The prevalent application of 
Deep Learning
 (DL) models has raised concerns about their reliability. Due to the data-driven programming paradigm, the quality of 
test datasets
 is extremely important to gain accurate assessment of 
DL
 models. Recently, researchers have introduced mutation testing into 
DL
 testing, which applies 
mutation operators
 to generate mutants from DL models, and observes whether the 
test data
 can identify mutants to check the quality of test dataset. However, there still exist many factors (e.g., huge labeling efforts and high running cost) hindering the implementation of mutation testing for DL models.
Objective: We desire for an approach to selecting a smaller, sensitive, representative and efficient subset of the whole test dataset to promote the current mutation testing (e.g., reduce labeling and running cost) for DL Models.
Method: We propose boundary sample selection (BSS), which employs the distance of samples to decision boundary of DL models as the indicator to construct the appropriate subset. To evaluate the performance of BSS, we conduct an extensive empirical study with two widely-used datasets, three popular DL models, and 14 up-to-date DL 
mutation operators
. Results
: We observe that (1) The sizes of our subsets generated by BSS are much smaller (about 3%-20% of the whole test set). (2) Under most 
mutation operators
, our subsets are superior (about 9.94-21.63) than the whole test sets in observing mutation effects. (3) Our subsets could replace the whole test sets to a very high degree (higher than 97%) when considering mutation score. (4) The MRR values of our proposed subsets are clearly better (about 2.28-13.19 times higher) than that of the whole test sets.
Conclusions: The result shows that BSS can help testers save labelling cost, run mutation testing quickly and identify killed mutants early.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The BSS approach for selecting a smaller, efficient subset of test datasets for Deep Learning models can greatly benefit startups by reducing costs and improving efficiency in testing."
https://www.sciencedirect.com/science/article/pii/S2352673423000215,The inefficiencies of venture capital funding,Chris=Welter: chriswelter@miamioh.edu; Tim R.=Holcomb: holcomtr@miamioh.edu; John=McIlwraith: john@allosventures.com,"Abstract
Despite plentiful research into venture capital (VC), the process of obtaining funding still frustrates both VC firms and startups. While uncertainty is necessary for the returns that VC investors desire, there are inefficiencies in the process that stem from 
information asymmetry
. We articulate those inefficiencies from both the founder and the VC perspective and offer some pathways toward reducing those inefficiencies to drive better outcomes for startups, VCs, and society as a whole.",June 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"While important, the abstract focuses on inefficiencies in the VC funding process, which may have limited direct practical value for early-stage ventures in Europe compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920301713,Laprob: A Label propagation-Based software bug localization method,Xiang=Chen: xchencs@ntu.edu.cn; Zhengliang=Li: lzl@smail.nju.edu.cn; Zhiwei=Jiang: jiangzhiwei@outlook.com; Kaibo=Cao: imkbcao@gmail.com; Qing=Gu: guq@nju.edu.cn,"Abstract
Context
Bug localization, which locates suspicious snippets related to the bugs mentioned in the 
bug reports
, is time-consuming and laborious. Many automatic bug 
localization methods
 have been proposed to speed up the process of bug fixing and reduce the burden on developers. However, these methods have not fully utilized the intra-relations and inter-relations among the 
bug reports
 and the source files (i.e., call relationships between the source files).
Objective
In this paper, we propose a novel method LaProb (a label propagation-based software bug localization method) that makes full use of the intra-relations and inter-relations among the bug reports and the source files.
Method
LaProb transforms the problem of bug localization into a multi-label distribution learning problem. LaProb first constructs a BHG (Biparty Hybrid Graph) by analyzing the structures and contents of bug reports and source files, and calculates the intra-relations between pairs of bug reports and source files, as well as the inter-relations between bug reports and source files. Based on BHG, LaProb then predicts the label distribution on source files by using the label 
propagation algorithm
 for the target bug report. Finally, LaProb finishes the bug localization task by sorting the results of label propagation.
Results
The experimental results on nine open-source software projects (i.e., SWT, AspectJ, Eclipse, ZXing, SEC, HIVE, HBASE, WFLY and ROO) show that compared with several state-of-the-art methods (including BugLocator, BRTracer, BLUiR, AmaLgam, Locus and BLIZZARD), LaProb performs the best in terms of all five metrics on average. For 
MAP
 
performance measure
, LaProb achieves an improvement of 30.9%, 36.6%, 28.0%, 22.2%, 20.1% and 53.5%, respectively.
Conclusion
LaProb is capable of making full use of the intra-relations and inter-relations among the bug reports and the source files and achieves better performance than seven state-of-the-art methods.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The LaProb bug localization method stands out as it improves bug fixing processes significantly, which is crucial for startups aiming to develop reliable software products efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584920302007,Community detection in software ecosystem by comprehensively evaluating developer cooperation intensity,Xiangjuan=Yao: yaoxj@cumt.edu.cn,"Abstract
Context
: As soon as the concept of software ecosystem was proposed, it has aroused great interest in both academia and industry. Software ecosystem can be described as a special complex network. Community structures are critical towards understanding not only the 
network topology
 but also how the network functions. Traditional community 
detection algorithms
 in complex networks mainly utilize the 
network topology
 to measure the similarities between nodes. Because of the complexity of information interaction in software ecosystem, only considering the topology structure will lead to unreasonable division of communities.
Objective
: For solving community detection in software ecosystem more reasonably, we present a method of community detection by comprehensively evaluating developer cooperation intensity in software ecosystems.
Method
: First, we combine network topology information and developer interaction information to calculate the developer cooperation intensity, so as to deeply explore the relationship between developers from both topological and semantic properties. Then a community detection algorithm ABDCI is proposed based on the cooperation intensity of developers by referring to the 
hierarchical clustering
 idea of Louvain algorithm. Finally, this method is applied to many different types of developer networks in the software ecosystem through GitHub hosting platform.
Results
: Comparing with three classical community 
detection algorithms
, we find that the proposed method can identify a clearer community structure for the developer collaboration network in the software ecosystem.
Conclusion
: Our approach provides an effective and extensible technique for solving the community detection problem of real developer collaboration network in software ecosystem. According to our findings, we conclude that community detection algorithms based on comprehensive topological properties and semantic properties are more suitable for real communities in software ecosystems than traditional single-property algorithms.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the community detection method in software ecosystems is interesting, its practical value for startups may be limited compared to other abstracts that directly impact software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584920301956,Social network analysis of open source software: A review and categorisation,Des=Greer: des.greer@qub.ac.uk,"Abstract
Context:
 As companies have become large users of 
Open Source Software
, it is important that they feel comfortable in their Open Source strategies. One of the critical differences between Open Source and Proprietary Software is the communication networks.
Objective:
 This paper tries to set a base for understanding how open source teams are structured and how they change. This is vital to understanding 
Open Source Software
 Communities.
Method:
 The paper looks into previous research on 
Social Network Analysis
 of Open Source Software, using a systematic literature review. Papers were gathered from Scopus, IEEEXplore and ACM Digital Library, and used or discarded based on predetermined inclusion and exclusion criteria. Research which focuses on the 
success factors
 of Open Source Software through Network Analysis is also examined.
Results:
 A subjective categorisation is established for the papers: Structure, Lifecycle and Communication. It was found that the structure of a project has a large bearing on project success, with developers having previously worked together being indicative of project success. Other structure indicators of success are having a small but structured hierarchy, a diverse user and developer base, and project prominence. However, it was found that information on how these structures appear and evolve over time is lacking, and future research into temporal data models to determine project success information is suggested.
Conclusions:
 A categorisation of existing research on 
Social Network Analysis
 is provided as a basis for further research. Further work into the lifecycle of 
OSS projects
 through Social Network Analysis of temporal project information is suggested.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The study provides insights into Open Source Software communities but lacks direct practical impact on European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584920302020,Towards a unified criteria model for usability evaluation in the context of open source software based on a fuzzy Delphi method,A.A.=Zaidan: aws.alaa@fskik.upsi.edu.my,"Abstract
Context
A plethora of models are available for open-source software (OSS) 
usability evaluation
. However, these models lack consensus between scholars as well as standard bodies on a specific set of 
usability evaluation
 criteria. Retaining irrelevant criteria and omitting essential ones will mislead the direction of the usability evaluation.
Objective
This study introduces a three-step method to develop a usability evaluation model in the context of OSS.
Method
The fuzzy Delphi method has been employed to unify the usability evaluation criteria in the context of OSS. The first step in the method is the usability criteria analysis, which involves redefining and restructuring all collected usability criteria reported in the literature. The second step is fuzzy Delphi analysis, which includes the design and validates the fuzzy Delphi instrument and the utilisation of the fuzzy Delphi method to analyse the fuzziness consensus of experts' opinions on the usability evaluation criteria. The third step is the proposal of the OSS usability evaluation model.
Results
A total of 124 usability criteria were identified, redefined, and restructured by creating groups of related meaning criteria. The result of the groupings generated 11 main criteria; the findings of the fuzzy Delphi narrowed down the criteria to only seven. The final set of criteria was sent back to the panellists for 
reconsideration
 of their responses. The panellists verified that these criteria are suitable in the evaluation of the usability of OSS.
Discussion
The empirical analysis confirmed that the proposed evaluation model is acceptable in assessing the usability of OSS. Therefore, this model can be used as a reference metric for OSS usability evaluation which will have a practical benefit for the community in public and private organisations in helping the decision-maker to select the best OSS software package amongst the alternatives.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The usability evaluation model proposed has practical benefits for the community in selecting OSS software, which can have a significant impact on European startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000592,A translational framework for entrepreneurship research,Pablo=Muñoz: pablo.munoz-roman@durham.ac.uk; Dimo=Dimov: dpd24@bath.ac.uk,"Abstract
In this paper, we put forward a new 
translational research
 framework for entrepreneurship, which leverages translational research from biomedical science and design science to lay the ground for a new research ecosystem of entrepreneurship. Instead of describing, explaining and predicting, our framework places emphasis on framing, experimenting and interacting. It comprises three modes of translational research, which allow for moving discoveries made in basic entrepreneurship research to entrepreneurial practice (T1), entrepreneurial communities (T2) and entrepreneurship policy (T3). These are alternative modes of research, marking different scientific domains, that can ensure the outcomes of our 
basic science
 are understood, adapted to and adopted by stakeholders in the best way possible. This new ecosystem can expand our 
scope of action
 as entrepreneurship researchers, open new pathways to materialize the elusive “scholarly impact” and advance the conversation and practice of engaged scholarship.",June 2023,"Translational research, Entrepreneurship research, Scholarly impact, Design science, Engaged scholarship",Business Venturing Insights,2025-03-21T00:00:00,9.0,"This abstract proposes a new translational research framework for entrepreneurship, which could significantly impact how research is translated into practice, policy, and communities. The framework has the potential to shape the future direction of entrepreneurship research and practice in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584920302032,Two-level clustering of UML class diagrams based on semantics and structure,Zhongchen=Yuan: yuanzhongchen@163.com,"Abstract
Context
The reuse of 
software design
 has been an important issue of 
software reuse
. 
UML
 
class diagrams
 are widely applied in 
software design
 and has become DE factor standard. As a result, the reuse of 
UML
 
class diagrams
 has received more attention. With the increasing number of class diagrams stored in reuse repository, their retrieval becomes a time-consuming job. The clustering can narrow down retrieval range and improve the retrieval efficiency. But few efforts have been done in clustering 
UML
 class diagrams. This paper tries to propose a 
clustering approach
 for 
UML
 class diagrams.
Objective
This paper proposes a two-level clustering of UML class diagrams, namely, semantic clustering and structural clustering. The UML class diagrams stored in reuse repository are clustered into a few domains based on semantics in the first level and a few categories based on structure in the second level.
Method
We propose a 
clustering algorithm
 named 
CUFS
, in which the idea of partitioning and 
hierarchical clustering
 is combined and feature similarity is proposed for the similarity measure between two clusters in order to merge clusters. A better feature representation of a cluster, namely, feature class diagram, is proposed in this paper. In order to form each sub-cluster, the semantic and 
structural similarities
 between UML class diagrams are defined, respectively.
Results
A series of experimental results show that, the proposed feature similarity measure not only speeds up the 
clustering process
, but also expresses the closeness degree between clusters for merging clusters. The proposed algorithm shows a good 
clustering quality
 and efficiency under the condition of different size and distribution of UML class diagrams.
Conclusion
It is concluded that the proposed two-level 
clustering method
 considers both semantics and structure contained in a class diagram, which can flexibly adapt to different clustering requirements. Also, the proposed 
clustering algorithm
 performs better than other related algorithms, regardless of in semantic, structural and hybrid clustering.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The two-level clustering approach for UML class diagrams can improve retrieval efficiency, which can benefit European early-stage ventures working with software design and reuse."
https://www.sciencedirect.com/science/article/pii/S0950584920300033,Large-scale intent analysis for identifying large-review-effort code changes,Song=Wang: wangsong@eecs.yorku.ca; Chetan=Bansal: chetanb@microsoft.com; Nachiappan=Nagappan: nachin@microsoft.com,"Abstract
Context
: Code changes to software occur due to various reasons such as bug fixing, new feature addition, and 
code refactoring
. Change intents have been studied for years to help developers understand the rationale behind code commits. However, in most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis.
Objective
: In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (
LRE
) changes—changes with large review effort.
Method
: Specifically, we first propose a feedback-driven and heuristics-based approach to identify change intents of code changes. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying 
LRE
 changes. We conduct our study on four large-scale projects, one from 
Microsoft
 and three are 
open source projects
, i.e., Qt, 
Android
, and OpenStack.
Results
: Our results show that, (i) code changes with some intents (i.e., Feature and Refactor) are more likely to be LRE changes, (ii) 
machine learning
 based prediction models are applicable for identifying 
LRE
 changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average.
Conclusion
: The change intent analysis and its application on LRE identification proposed in this study has already been used in 
Microsoft
 to provide the review effort and intent information of changes for reviewers to accelerate the review process. To show how to deploy our approaches in real-world practice, we report a 
case study
 of developing and deploying the intent analysis system in 
Microsoft
. Moreover, we also evaluate the usefulness of our approaches by using a questionnaire survey. The feedback from developers demonstrate its practical value.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The study leverages change intent analysis to identify Large-Review-Effort changes, providing practical value for developers and accelerating the review process, benefiting European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300021,RSTrace+: Reviewer suggestion using software artifact traceability graphs,Emre=Sülün: emre.sulun@bilkent.edu.tr; Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr; Uğur=Doğrusöz: ugur@cs.bilkent.edu.tr,"Abstract
Context:
Various types of artifacts (requirements, 
source code
, test cases, documents, etc.) are produced throughout the lifecycle of a software. These artifacts are connected with each other via 
traceability links
 that are stored in modern 
application lifecycle management
 repositories. Throughout the lifecycle of a software, various types of changes can arise in any one of these artifacts. It is important to review such changes to minimize their potential 
negative impacts
. To make sure the review is conducted properly, the reviewer(s) should be chosen appropriately.
Objective:
We previously introduced a novel approach, named RSTrace, to automatically recommend reviewers that are best suited based on their familiarity with a given artifact. In this study, we introduce an advanced version of RSTrace, named RSTrace+ that accounts for recency information of 
traceability links
 including practical tool support for GitHub.
Methods:
In this study, we conducted a series of experiments on finding the appropriate code reviewer(s) using RSTrace+ and provided a comparison with the other code reviewer recommendation approaches.
Results:
We had initially tested RSTrace+ on an 
open source project
 (Qt 3D Studio) and achieved a top-3 accuracy of 0.89 with an MRR (mean reciprocal ranking) of 0.81. In a further empirical evaluation of 40 open source projects, we compared RSTrace+ with Naive-Bayes, RevFinder and Profile based approach, and observed higher accuracies on the average.
Conclusion:
We confirmed that the proposed reviewer recommendation approach yields promising top-k and MRR scores on the average compared to the existing reviewer recommendation approaches. Unlike other code reviewer recommendation approaches, RSTrace+ is not limited to recommending reviewers for 
source code
 artifacts and can potentially be used for recommending reviewers for other types of artifacts. Our approach can also visualize the affected artifacts and help the developer to make assessments of the potential impacts of change to the reviewed artifact.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The advanced version of RSTrace for recommending reviewers in software development has practical implications for improving review processes, which can benefit European startups working with software artifacts."
https://www.sciencedirect.com/science/article/pii/S0950584919302204,Performance analysis of out-of-distribution detection on trained neural networks,Jens=Henriksson: jens.henriksson@semcon.com; Christian=Berger: christian.berger@gu.se,"Abstract
Context
Deep Neural Networks
 (DNN) have shown great promise in various domains, for example to support pattern recognition in medical imagery. However, DNNs need to be tested for robustness before being deployed in safety critical applications. One common challenge occurs when the model is exposed to data samples outside of the 
training data
 domain, which can yield to outputs with high confidence despite no prior knowledge of the given input.
Objective
The aim of this paper is to investigate how the performance of detecting out-of-distribution (OOD) samples changes for 
outlier detection
 methods (e.g., supervisors) when DNNs become better on 
training samples
.
Method
Supervisors are components aiming at detecting out-of-distribution samples for a DNN. The experimental setup in this work compares the performance of supervisors using metrics and datasets that reflect the most common setups in related works. Four different DNNs with three different supervisors are compared during different stages of training, to detect at what point during training the performance of the supervisors begins to deteriorate.
Results
Found that the 
outlier detection
 performance of the supervisors increased as the accuracy of the underlying DNN improved. However, all supervisors showed a large variation in performance, even for variations of network parameters that marginally changed the model accuracy. The results showed that understanding the relationship between training results and supervisor performance is crucial to improve a model’s robustness.
Conclusion
Analyzing DNNs for robustness is a challenging task. Results showed that variations in model parameters that have small variations on model predictions can have a large impact on the out-of-distribution detection performance. This kind of behavior needs to be addressed when DNNs are part of a safety critical application and hence, the necessary safety argumentation for such systems need be structured accordingly.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"This abstract addresses the crucial issue of detecting out-of-distribution samples in deep neural networks, highlighting the importance of model robustness for safety critical applications."
https://www.sciencedirect.com/science/article/pii/S0950584920301920,Software engineering and advanced applications conference 2019 – selected papers,Miroslaw=Staron: special_issue@staron.nu,"Abstract
Software Engineering and Advanced Applications (SEAA) is a long-standing international forum for researchers, practitioners, and students to present and discuss the latest innovations, trends, experiences, and concerns in the field of Software Engineering and Advanced Applications in information technology for software-intensive systems. In this special issue, we present a selection of papers which show the current trends in software engineering – improved systematic reviews, deep learning and cloud computing.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"This abstract discusses general trends in software engineering and advanced applications, but lacks specific impact on early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S0950584920300070,A comprehensive empirical evaluation of generating test suites for mobile applications with diversity,Thomas=Vogel: thomas.vogel@informatik.hu-berlin.de; Lars=Grunske: grunske@informatik.hu-berlin.de; Chinh=Tran: mail@chinhtran.de,"Abstract
Context:
 In search-based 
software engineering
 we often use popular heuristics with 
default configurations
, which typically lead to suboptimal results, or we perform experiments to identify configurations on a trial-and-error basis, which may lead to better results for a specific problem. We consider the problem of generating test suites for mobile applications (apps) and rely on 
Sapienz
, a state-of-the-art approach to this problem that uses a popular heuristic (NSGA-II) with a default configuration. 
Objective:
 We want to achieve better results in generating test suites with 
Sapienz
 while avoiding trial-and-error experiments to identify a more suitable configuration of 
Sapienz
. 
Method:
 We conducted a fitness landscape analysis of 
Sapienz
 to analytically understand the search problem, which allowed us to make informed decisions about the heuristic and configuration of 
Sapienz
 when developing 
Sapienz
div
. We comprehensively evaluated 
Sapienz
div
 in a head-to-head comparison with 
Sapienz
 on 34 apps. 
Results:
 Analyzing the fitness landscape of 
Sapienz
, we observed a lack of diversity of the evolved test suites and a stagnation of the search after 25 generations. 
Sapienz
div
 realizes mechanisms that preserve the diversity of the test suites being evolved. The evaluation showed that 
Sapienz
div
 achieves better or at least similar test results than 
Sapienz
 concerning coverage and the number of revealed faults. However, 
Sapienz
div
 typically produces longer test sequences and requires more 
execution time
 than 
Sapienz
. 
Conclusions:
 The understanding of the search problem obtained by the fitness landscape analysis helped us to find a more suitable configuration of 
Sapienz
 without trial-and-error experiments. By promoting diversity of test suites during the search, improved or at least similar test results in terms of faults and coverage can be achieved.",February 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract presents a practical approach to improving test suites for mobile applications, focusing on avoiding trial-and-error experiments and achieving better results."
https://www.sciencedirect.com/science/article/pii/S0950584920300069,A Systematic Comparison of search-Based approaches for LDA hyperparameter tuning,Annibale=Panichella: a.panichella@tudelft.nl,"Abstract
Context:
Latent Dirichlet Allocation
 (LDA) has been successfully used in the literature to extract topics from software documents and support developers in various 
software engineering
 tasks. While LDA has been mostly used with default settings, previous studies showed that default hyperparameter values generate sub-optimal topics from software documents.
Objective:
 Recent studies applied meta-heuristic search (mostly evolutionary algorithms) to configure LDA in an unsupervised and automated fashion. However, previous work advocated for different meta-heuristics and surrogate metrics to optimize. The objective of this paper is to shed light on the influence of these two factors when tuning LDA for SE tasks.
Method:
We empirically evaluated and compared seven state-of-the-art meta-heuristics and three alternative surrogate metrics (i.e., fitness functions) to solve the problem of identifying duplicate 
bug reports
 with LDA. The benchmark consists of ten real-world and open-source projects from the 
Bench4BL
 dataset.
Results:
Our results indicate that (1) meta-heuristics are mostly comparable to one another (except for random search and CMA-ES), and (2) the choice of the surrogate metric impacts the quality of the generated topics and the tuning overhead. Furthermore, calibrating LDA helps identify twice as many duplicates than untuned LDA when inspecting the top five past similar reports.
Conclusion:
No meta-heuristic and/or fitness function outperforms all the others, as advocated in prior studies. However, we can make recommendations for some combinations of meta-heuristics and fitness functions over others for practical use. Future work should focus on improving the surrogate metrics used to calibrate/tune LDA in an unsupervised fashion.",February 2021,"Topic modeling, Latent dirichlet allocation, Search-based software engineering, Metaheuristic search, Duplicate bug report, Hyperparameter optimization",Information and Software Technology,2025-03-18T00:00:00,6.0,"This abstract delves into the optimization of Latent Dirichlet Allocation for software engineering tasks, providing insights but lacking a direct impact on startups or early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920301580,Recommending tags for pull requests in GitHub,Jing=Jiang: jiangjing@buaa.edu.cn; Qiudi=Wu: 1040814720@qq.com; Jin=Cao: 13277061183@163.com; Xin=Xia: xin.xia@monash.edu; Li=Zhang: lily@buaa.edu.cn,"Abstract
Context
In GitHub, contributors make code changes, then create and 
submit
 pull requests to projects. Tags are a simple and effective way to attach additional information to pull requests and facilitate their organization. However, little effort has been devoted to study pull requests’ tags in GitHub.
Objective
Our objective in this paper is to propose an approach which automatically recommends tags for pull requests in GitHub.
Method
We make a survey on the usage of tags in pull requests. Survey results show that tags are useful for developers to track, search or classify pull requests. But some respondents think that it is difficult to choose right tags and keep consistency of tags. 60.61% of respondents think that a 
tag recommendation
 tool is useful. In order to help developers choose tags, we propose a method FNNRec which uses feed-forward neural network to analyze titles, description, file paths and contributors.
Results
We evaluate the effectiveness of FNNRec on 10 projects containing 68,497 tagged pull requests. The experimental results show that on average, FNNRec outperforms approach TagDeepRec and TagMulRec by 62.985% and 24.953% in terms of 
F
1
−
s
c
o
r
e
@
3
,
 respectively.
Conclusion
FNNRec is useful to find appropriate tags and improve tag setting process in GitHub.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"This abstract introduces a method to recommend tags for pull requests in GitHub, demonstrating clear practical value and potential impact on software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584920301701,Integrated framework for incorporating sustainability design in software engineering life-cycle: An empirical study,Theresia Ratih Dewi=Saputri: trdsaputri@ajou.ac.kr; Seok-Won=Lee: leesw@ajou.ac.kr,"Abstract
Context:
Owing to the critical role of software-intensive systems in society, software engineers have the accountability to consider sustainability as a goal while structuring a software system. However, there are no 
practical guidelines
 providing a tangible decomposition of the sustainability aspect. Moreover, there are limited quantifiable methods to support 
sustainable design
 and analysis.
Objectives:
The purpose of this study is to help software practitioners to take sustainability into account by providing systematic guidelines for the software 
engineering process
. We propose a framework that presents a meta model to decompose sustainability requirements and an assessment approach to evaluate sustainability achievements.
Method:
This work presents an integrated framework that combines a goal-based approach, scenario-based approach, and feature modeling to gather sustainability 
related requirements
 and corresponding features. For sustainability assessment, software analysis and 
machine learning techniques
 are utilized to analyze software products based on sustainability metrics and criteria.
Results and Conclusions:
The empirical study conducted with participants from academia and industry revealed that the proposed framework improves participant’s ability to consider sustainability aspect in their 
software engineering
 tasks through focusing on requirements, design, and evaluation. With the provided sustainability meta-model, the participants could extract more stakeholders, requirements, and features in shorter time. Moreover, the empirical study result also demonstrated that this study is capable to indicate specific scenarios that should be redesigned to improve the sustainability achievements level.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study provides systematic guidelines for software practitioners to consider sustainability in software engineering processes, which could benefit early-stage ventures by promoting sustainable practices."
https://www.sciencedirect.com/science/article/pii/S0950584920301749,Governance and Management of Green IT: A Multi-Case Study,Per=Runeson: per.runeson@cs.lth.se; Mario=Piattini: Mario.Piattini@uclm.es; J. David=Patón-Romero: JoseDavid.Paton@gmail.com; Maria Teresa=Baldassarre: mariateresa.baldassarre@uniba.it; Moisés=Rodríguez: mrodriguez@aqclab.es; Martin=Höst: martin.host@cs.lth.se,"Abstract
Context
The changes that are taking place with respect to environmental sensitivity are forcing organizations to adopt a new approach to this problem. Implementing 
sustainability
 initiatives has become a priority for the social and environmental awareness of organizations that want to stay ahead of the curve. One of the business areas that has, more than others, proven to be a vital asset and a potential ally of the environment, is the area of Information Technology (IT). Through this area, Green IT practices advocate 
sustainability
 in and by IT. However, organizations have a significant handicap in this regard, due to the lack of specific Green IT standards and frameworks that help them carry out this type of sustainability practices.
Objective
We have developed the 
“Governance and Management Framework for Green IT”
 (GMGIT), which establishes the necessary characteristics to implement Green IT in organizations, from the point of view of the governance and management of this area. After developing and validating a first version of this framework, we have performed a set of improvements, obtaining the GMGIT 2.0, which we want to validate.
Method
We have conducted a series of empirical validations at international level based on 
case studies
, whose characteristics and results are presented in this study.
Results
The results of this multi-case study show an example of the current situation of organizations in Green IT, as well as the resolution of problems encountered during the validations conducted with the GMGIT 1.0.
Conclusion
The findings obtained demonstrate the usefulness, applicability, and validity of the framework when implementing, auditing, and improving Green IT in organizations in a systematic and progressive manner.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"The framework for Green IT governance and management could have some impact on European early-stage ventures, but the lack of specific Green IT standards may limit its immediate practical value."
https://www.sciencedirect.com/science/article/pii/S0950584920301841,Statement frequency coverage: A code coverage criterion for assessing test suite effectiveness,Alireza=Aghamohammadi: aaghamohammadi@ce.sharif.edu; Seyed-Hassan=Mirian-Hosseinabadi: hmirian@sharif.edu; Sajad=Jalali: sajalali@ce.sharif.edu,"Abstract
Context:
Software testing is a pivotal activity in the development of high-quality software. As software is evolving through its life cycle, the need for a fault-revealing criterion assessing the effectiveness of the test suite grows. Over the years, researchers have proposed coverage-based criteria, including statement and branch coverage, to solve this issue. In literature, the effectiveness of such criteria is attested in terms of their correlations with the mutation score.
Objective:
In this paper, we aim at proposing a coverage-based criterion named statement frequency coverage, which outperforms statement and branch coverage in terms of correlation with mutation score.
Method:
To this end, we incorporated the frequency of executed statements into 
statement coverage
 and created a coverage-based criterion for assessing test suite effectiveness. Statement frequency coverage assigns a continuous value to a statement whose value is proportional to the number of times executed during test execution. We evaluated our approach on 22 real-world Python projects with more than 118 000 source lines of code (without blank lines, comments, and test cases) and 21 000 test cases through measuring the correlation between statement frequency coverage and corresponding mutation score.
Results:
The results show that statement frequency coverage outperforms statement and branch coverage criteria. The correlation between it and the corresponding mutation score is higher than the correlation of statement and branch coverage with their mutation score. The results also show that unlike statement and branch coverage, there is no statistical difference between statement frequency coverage and mutation score.
Conclusion:
Statement frequency coverage is a better choice compared to statement and branch coverage in assessing test suite effectiveness in the real-world setting. Furthermore, we demonstrate that although statement frequency coverage subsumes 
statement coverage
, it is incomparable to branch coverage under the adequate test suite condition.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The proposed coverage-based criterion for assessing test suite effectiveness could greatly benefit European early-stage ventures by improving software quality and efficiency.
https://www.sciencedirect.com/science/article/pii/S0950584920301853,A unified framework for declarative debugging and testing,Rafael=Caballero: rafacr@ucm.es; Enrique=Martin-Martin: emartinm@ucm.es; Salvador=Tamarit: stamarit@dsic.upv.es,"Abstract
Context:
Debugging is the most challenging and time consuming task in software development. However, it is not properly integrated in the software 
development cycle
, because the result of so much effort is not available in further iterations of the cycle, and the debugging process itself does not benefit from the outcome of other phases such as testing.
Objective:
We propose to integrate debugging and testing within a single unified framework where each phase generates useful information for the other and the outcomes of each phase are reused.
Method:
We consider a declarative debugging setting that employs tests to automatically entail the validity of some subcomputations, thus decreasing the time and effort needed to find a bug. Additionally, the 
debugger
 stores as new tests the information collected from the user during the debugging phase. This information becomes part of the program test suite, and can be used in future 
debugging sessions
, and also as 
regression tests
.
Results:
We define a general framework where declarative debugging establishes a bidirectional collaboration with testing. The new setting preserves the properties of the underlying declarative debugging framework (weak completeness and soundness) while generating test cases that can be used later in other 
debugging sessions
 or even in other cycles of the software development. The proposed framework is general enough to be instantiated to very different programming languages: Erlang (functional), Java (imperative, object-oriented), and 
SQL
 (data query); and the experimental results obtained for Erlang programs validate the effectiveness of the framework.
Conclusion:
We propose a general unified framework for debugging and testing that simplifies each phase and maximizes the 
reusability
 of the outcomes in the different phases of the software 
development cycle
, therefore reducing the overall effort.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Integrating debugging and testing within a unified framework could streamline software development processes for early-stage ventures, potentially saving time and effort in debugging cycles."
https://www.sciencedirect.com/science/article/pii/S0950584920301877,What skills do IT companies look for in new developers? A study with Stack Overflow jobs,João Eduardo=Montandon: joao.montandon@dcc.ufmg.br,"Abstract
Context:
 There is a growing demand for information on how IT companies look for candidates to their open positions. 
Objective:
 This paper investigates which hard and soft skills are more required in IT companies by analyzing the description of 20,000 job opportunities. 
Method:
 We applied open card sorting to perform a high-level analysis on which types of hard skills are more requested. Further, we manually analyzed the most mentioned soft skills. 
Results:
 Programming languages are the most demanded hard skills. Communication, collaboration, and problem-solving are the most demanded soft skills. 
Conclusion:
 We recommend developers to organize their resumé according to the positions they are applying. We also highlight the importance of soft skills, as they appear in many job opportunities.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"Analyzing the skills required in IT job opportunities may provide some insights for European early-stage ventures, but the practical impact on startups may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920301865,On the influence of model fragment properties on a machine learning-based approach for feature location,Carlos=Cetina: ccetina@usj.es; Ana C.=Marcén: acmarcen@usj.es; Manuel=Ballarín: mballarin@usj.es; Vicente=Pelechano: pele@dsic.upv.es,"Abstract
Context:
Leveraging 
machine learning techniques
 to address feature location on models has been gaining attention. Machine learning techniques empower software product companies to take advantage of the knowledge and the experience to improve the performance of the feature location process. Most of the machine learning-based works for feature location on models report the 
machine learning techniques
 and the tuning parameters in detail. However, these works focus on the size and the distribution of the data sets, neglecting the properties of their contents.
Objective:
In this paper, we analyze the influence of three model fragment properties (density, multiplicity, and dispersion) on a machine learning-based approach for feature location.
Method:
The analysis of these properties is based on an industrial case provided by CAF, a worldwide provider of railway solutions. The test cases were evaluated through a 
machine learning
 technique that uses different subsets of a 
knowledge base
 to learn how to locate unknown features.
Results:
Results show that the density and dispersion properties have a direct impact on the results. In our 
case study
, the model fragments with extra-small density values achieve results with up to 43% more precision, 41% more recall, 42% more F-measure, and 0.53 more Matthews 
Correlation Coefficient
 (MCC) than the model fragments with other density values. On the other hand, the model fragments with extra-small and small dispersion values achieve results with up to 53% more precision, 52% more recall, 52% more F-measure, and 0.57 more MCC than the model fragments with other dispersion values.
Conclusions:
The analysis of the results shows that both density and dispersion properties significantly influence the results. These results can serve not only to improve the reports by means of the model fragment properties, but also to be able to compare machine learning-based feature location approaches fairly improving the feature location results.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The analysis of model fragment properties in feature location can significantly improve machine learning-based approaches, providing practical value for improving feature location results in software product companies."
https://www.sciencedirect.com/science/article/pii/S0950584920301889,COSTE: Complexity-based OverSampling TEchnique to alleviate the class imbalance problem in software defect prediction,Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Kwabena Ebo=Bennin: kwabena.bennin@wur.nl; Shuo=Feng: shuofeng5-c@my.cityu.edu.hk; Miao=Zhang: miazhang9-c@my.cityu.edu.hk; Xiao=Yu: xyu224-c@my.cityu.edu.hk; Yan=Xiao: xiaoyan.hhu@gmail.com; Md Alamgir=Kabir: makabir4-c@my.cityu.edu.hk,"Abstract
Context:
Generally, there are more non-defective instances than defective instances in the datasets used for 
software defect
 prediction (SDP), which is referred to as the 
class imbalance problem
. Oversampling techniques are frequently adopted to alleviate the problem by generating new synthetic defective instances. Existing techniques generate either near-duplicated instances which result in overgeneralization (high probability of false alarm, 
p
f
) or overly diverse instances which hurt the prediction model’s ability to find defects (resulting in low probability of detection, 
p
d
). Furthermore, when existing oversampling techniques are applied in SDP, the effort needed to inspect the instances with different complexity is not taken into consideration.
Objective:
In this study, we introduce Complexity-based OverSampling TEchnique (COSTE), a novel oversampling technique that can achieve low 
p
f
 and high 
p
d
 simultaneously. Meanwhile, COSTE also performs better in terms of 
N
o
r
m
(
p
o
p
t
)
 and 
A
C
C
, two effort-aware measures that consider the testing effort.
Method:
COSTE combines pairs of defective instances with similar complexity to generate synthetic instances, which improves the diversity within the data, maintains the ability of prediction models to find defects, and takes the different testing effort needed for different instances into consideration. We conduct experiments to compare COSTE with Synthetic Minority Oversampling TEchnique, Borderline-SMOTE, Majority Weighted Minority Oversampling TEchnique and MAHAKIL.
Results:
The experimental results on 23 releases of 10 projects show that COSTE greatly improves the diversity of the synthetic instances without compromising the ability of prediction models to find defects. In addition, COSTE outperforms the other oversampling techniques under the same testing effort. The statistical analysis indicates that COSTE’s ability to outperform the other oversampling techniques is significant under the statistical Wilcoxon rank sum test and Cliff’s effect size.
Conclusion:
COSTE is recommended as an efficient alternative to address the class imbalance problem in SDP.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The COSTE oversampling technique addresses the class imbalance problem in software defect prediction, achieving low false alarm rates and high detection rates while considering testing effort, providing a practical and efficient solution."
https://www.sciencedirect.com/science/article/pii/S0950584920301919,Evaluating the effects of similar-class combination on class integration test order generation,Yan=Xiao: dcsxan@nus.edu.sg; Miao=Zhang: miazhang9-c@my.cityu.edu.hk; Jacky Wai=Keung: jacky.Keung@cityu.edu.hk; Md Alamgir=Kabir: makabir4-c@my.cityu.edu.hk,"Abstract
Context:
In integration testing, the order in which classes are integrated and tested is significant for the construction of test stubs. With the existing approaches, it is usually difficult to generate the sub-optimal test orders for real applications, which have large numbers of classes.
Objective:
There exist moderately large numbers of classes in software systems, which is one of the main factors that complicate the generation of class integration test order (CITO). The main objectives of this study are reducing the problem space for CITO generation, and minimizing the stubbing cost of the generated test orders.
Method:
The approach proposed in this study is based on the hypothesis that similar-class combination can remove class dependencies and yield a smaller problem space. Identical class dependence and symmetric classes are the two main properties that are used to identify similar classes. In addition, a new cycle-breaking algorithm is introduced to minimize the stubbing cost of the generated test orders, which fully considers the two factors (number of test stubs and the corresponding stubbing complexity) that affect the overall stubbing cost. Empirical experiments are conducted on nine open-source Java programs to evaluate the performance of the proposed approach.
Results:
With similar-class combination, the proposed approach reduced the numbers of classes and class dependencies by over 10% and 6%, respectively, for six programs. Moreover, for four programs, the proposed approach reduced the number of cycles among class dependencies by more than 20%. The cycle-breaking algorithm achieved reduction of more than 13% in the stubbing cost, thus outperforming other competing techniques.
Conclusions:
The proposed method relies on the two aforementioned important properties to identify similar classes, and these properties are known to significantly improve the performance of CITO generation. The results obtained in this study confirmed the capability of the proposed approach in terms of minimizing the number of classes and class dependencies in programs. It outperformed other competing methods in minimizing the stubbing costs of the generated test orders.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The proposed method for class integration test order generation shows improvements in reducing class dependencies and stubbing costs, which can benefit integration testing in software systems with moderately large numbers of classes."
https://www.sciencedirect.com/science/article/pii/S0950584920301890,A Method to Estimate Software Strategic Indicators in Software Development: An Industrial Application,Martí=Manzano: mmanzano@essi.upc.edu,"Abstract
Context
Exploiting software development related data from software-development intensive organizations to support tactical and strategic decision making is a challenge. Combining data-driven approaches with expert knowledge has been highlighted as a sensible approach for leading software-development intensive organizations to rightful decision-making improvements. However, most of the existing proposals lack of important aspects that hinders their industrial uptake such as: 
customization
 guidelines to fit the proposals to other contexts and/or automatic or semi-automatic data collection support for putting them forward in a real organization. As a result, existing proposals are rarely used in the industrial context.
Objective
Support software-development intensive organizations with guidance and tools for exploiting software development related data and expert knowledge to improve their decision making.
Method
We have developed a novel method called SESSI (Specification and Estimation of Software Strategic Indicators) that was articulated from industrial experiences with Nokia, Bittium, Softeam and iTTi in the context of Q-Rapids European project following a design science approach. As part of the industrial 
summative evaluation
, we performed the first 
case study
 focused on the application of the method.
Results
We detail the phases and steps of the SESSI method and illustrate its application in the development of ModelioNG, a software product of Modeliosoft development firm.
Conclusion
The application of the SESSI method in the context of ModelioNG 
case study
 has provided us with useful feedback to improve the method and has evidenced that applying the method was feasible in this context.",January 2021,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The SESSI method aims to support software development intensive organizations with decision-making using software development data, although the industrial application and impact may require further validation and evidence of practical value."
https://www.sciencedirect.com/science/article/pii/S0950584920301476,Exploring software bug-proneness based on evolutionary clique modeling and analysis,Ran=Mo: moran@mail.ccnu.edu.cn; Zhen=Yin: yinzhen0906@126.com,"Abstract
Context:
Even if evolutionary coupling between files has been widely used for various studies, such as change impact analysis, 
defect prediction
, and 
software design
 analysis etc., there has little work focusing on studying the linkage among evolutionary coupled files.
Objective:
In this paper, we propose a novel model, 
evolutionary clique (EClique)
, to characterize evolutionary coupled files as maintainable groups for bug fixes, analyze their bug-proneness and examine the possible causes of the bug-proneness.
Methods:
To identify ECliques from a project, we propose two history measures to reason about the evolutionary coupling between files, and create a novel 
clustering algorithm
. Given the evolutionary coupling information, our 
clustering algorithm
 will automatically identify ECliques in a project.
Results:
We conduct analyses on 33,099 commits of ten 
open source projects
 to evaluate the usefulness of our 
EClique
 modeling and analysis approach: (1) The results show that files involved in an 
EClique
 are more likely to share similar design characteristics and change together for resolving bugs; (2) The results also show that the identified ECliques significantly contribute to a project’s bug-proneness. Meanwhile, the majority of a project’s bug-proneness can be captured by just a few ECliques which only contain a small portion of files; (3) Finally, we qualitatively demonstrate that bug-prone ECliques often exhibit design problems that propagate changes among files and can potentially be the causes of bug-proneness.
Conclusion:
To reduce the bug-proneness of a software project, practitioners should pay attention to the identified ECliques, and resolve design problems embedded in these ECliques.",December 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The EClique model provides a novel approach to characterizing evolutionary coupled files for bug fixes, with significant findings on bug-proneness and design characteristics, offering valuable insights for bug reduction in software projects."
https://www.sciencedirect.com/science/article/pii/S0950584919302113,On the diffuseness of technical debt items and accuracy of remediation time when using SonarQube,Valentina=Lenarduzzi: valentina.lenarduzzi@lut.fi; Maria Teresa=Baldassarre: mariateresa.baldassarre@uniba.it; Simone=Romano: simone.romano@uniba.it; Nyyti=Saarimäki: nyyti.saarimaki@tuni.fi,"Abstract
Context
. Among the 
static analysis
 tools available, SonarQube is one of the most used. SonarQube detects Technical Debt (TD) items—i.e., violations of coding rules—and then estimates TD as the time needed to remedy TD items. However, practitioners are still skeptical about the accuracy of remediation time estimated by the tool. 
Objective
. In this paper, we analyze both diffuseness of TD items and accuracy of remediation time, estimated by SonarQube, to fix TD items on a set of 21 open-source Java projects. 
Method
. We designed and conducted a 
case study
 where we asked 81 junior developers to fix TD items and reduce the TD of 21 projects. 
Results
. We observed that TD items are diffused in the analyzed projects and most items are code smells. Moreover, the results point out that the remediation time estimated by SonarQube is inaccurate and, as compared to the actual time spent to fix TD items, is in most cases overestimated. 
Conclusions
. The results of our study are promising for practitioners and researchers. The former can make more aware decisions during project execution and resource management, the latter can use this study as a starting point for improving TD estimation models.",December 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study addresses the practical concerns of accuracy in technical debt estimation, which can have a significant impact on resource management for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302356,Assessing safety-critical systems from operational testing: A study on autonomous vehicles,Xingyu=Zhao: xingyu.zhao@hw.ac.uk; Kizito=Salako: k.o.salako@city.ac.uk; Lorenzo=Strigini: l.strigini@city.ac.uk; Valentin=Robu: v.robu@hw.ac.uk; David=Flynn: d.flynn@hw.ac.uk,"Abstract
Context
Demonstrating high reliability and safety for safety-critical systems (SCSs) remains a hard problem. Diverse evidence needs to be combined in a rigorous way: in particular, results of operational testing with other evidence from design and verification. Growing use of 
machine learning
 in SCSs, by precluding most established methods for gaining assurance, makes evidence from operational testing even more important for supporting safety and reliability claims.
Objective
We revisit the problem of using operational testing to demonstrate high reliability. We use Autonomous Vehicles (AVs) as a current example. AVs are making their debut on public roads: methods for assessing whether an AV is safe enough are urgently needed. We demonstrate how to answer 5 questions that would arise in assessing an AV type, starting with those proposed by a highly-cited study.
Method
We apply new theorems extending our Conservative 
Bayesian
 Inference (CBI) approach, which exploit the rigour of 
Bayesian methods
 while reducing the risk of involuntary misuse associated (we argue) with now-common applications of Bayesian inference; we define additional conditions needed for applying these methods to AVs.
Results
Prior knowledge
 can bring substantial advantages if the AV design allows strong expectations of safety before road testing. We also show how naive attempts at conservative assessment may lead to over-optimism instead; why extrapolating the trend of disengagements (take-overs by human drivers) is not suitable for safety claims; use of knowledge that an AV has moved to a “less stressful” environment.
Conclusion
While some reliability targets will remain too high to be practically verifiable, our CBI approach removes a major source of doubt: it allows use of prior knowledge without inducing dangerously optimistic biases. For certain ranges of required reliability and prior beliefs, CBI thus supports feasible, sound arguments. Useful conservative claims can be derived from limited prior knowledge.",December 2020,"Autonomous systems, Safety assurance, Statistical testing, Safety-critical systems, Ultra-high reliability, Conservative Bayesian inference, AI safety, Proven in use, Globally at least equivalent, Software reliability growth models",Information and Software Technology,2025-03-18T00:00:00,9.0,The research on using operational testing for safety-critical systems like Autonomous Vehicles provides valuable insights for startups working in this domain to ensure safety and reliability.
https://www.sciencedirect.com/science/article/pii/S0950584919302101,A dynamic evolutionary multi-objective virtual machine placement heuristic for cloud data centers,Radu=Prodan: radu@itec.aau.at,"Abstract
Minimizing the resource wastage reduces the energy cost of operating a 
data center
, but may also lead to a considerably high resource overcommitment affecting the 
Quality of Service
 (QoS) of the running applications. The effective tradeoff between resource wastage and overcommitment is a challenging task in virtualized Clouds and depends on the allocation of virtual machines (VMs) to physical resources. We propose in this paper a multi-objective method for dynamic 
VM placement
, which exploits live migration mechanisms to simultaneously optimize the resource wastage, overcommitment ratio and migration energy. Our 
optimization algorithm
 uses a novel evolutionary meta-heuristic based on an island population model to approximate the 
Pareto optimal set
 of VM placements with good accuracy and diversity. Simulation results using traces collected from a real Google cluster demonstrate that our method outperforms related approaches by reducing the migration energy by up to 57% with a QoS increase below 6%.",December 2020,"VM placement, Multi-objective optimisation, Resource overcommitment, Resource wastage, Live migration, Energy consumption, Pareto optimal set, Genetic algorithm, Data center simulation",Information and Software Technology,2025-03-18T00:00:00,7.0,"The multi-objective method for dynamic VM placement in data centers can help startups optimize resource wastage and improve QoS, which is crucial for efficient operations."
https://www.sciencedirect.com/science/article/pii/S0950584920301312,Crowdsourced software testing: A systematic literature review,Sultan=Alyahya: sualyahya@ksu.edu.sa,"Abstract
Context
Crowdsourced software testing (CST) refers to the use of 
crowdsourcing techniques
 in the domain of software testing. CST is an emerging area with its applications rapidly increasing in the last decade.
Objective
A comprehensive review on CST has been conducted to determine the current studies aiming to improve and assess the value of using CST as well as the challenges identified by these evaluation studies.
Method
We conducted a systematic literature review on CST by searching six popular databases. We identified 50 primary studies that passed our quality assessment criteria and defined two research questions covering the aim of the study.
Results
There are three main process activities that the current literature aims to improve, namely selection of suitable testers, reporting of defects, and validation of submitted defects. In addition, there are 23 CST evaluation studies and most of them involve a large group and real crowd. These studies have identified 27 different challenges encountered during the application of crowdsourcing in software testing.
Conclusions
The improvements achieved for the specific process activities in CST help explore other unexplored process activities. Similarly, knowing the characteristics of the evaluation studies can direct us on what other studies are worth investigating. Additionally, many of the challenges identified by the evaluation studies represent research problems that need better understanding and alternative solutions. This research also offers opportunities for practitioners to understand and apply new solutions proposed in the literature and the variations between them. Moreover, it provides awareness to the related parties regarding the challenges reported in the literature, which they may encounter during CST tasks.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The review on crowdsourced software testing offers insights into improving testing processes, but the direct impact on early-stage ventures may not be as immediate as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920301129,BITA*: Business-IT alignment framework of multiple collaborating organisations,Ayalew=Kassahun: ayalew.kassahun@wur.nl,"Abstract
Context
Businesses today must collaborate in a coordinated fashion. To collaborate, they must align their business processes and IT by complying to a common reference architecture. The common reference architecture that addresses their specific collaboration requirements is generally an adaptation of an existing generic reference architecture. However, a design framework for adapting reference architectures is lacking.
Objective
In this paper we propose a design framework for aligning business processes and IT across diverse collaborating organisations in order to derive a more specific reference architecture from a generic one.
Method
We developed the design framework using the guidelines of ISO/IEC/IEEE standard for modelling design viewpoints and validated it in a real-life business 
case study
.
Results
We developed an architectural design framework which we call BITA* that is composed of three coherent architectural design viewpoints. The BP2BP alignment viewpoint provides alignment modelling abstractions for business analysts to be used to align business collaboration processes. The IT2IT alignment viewpoint provides alignment modelling abstractions for software architects to be used to align distributed IT systems. The BP2IT alignment viewpoint provides alignment modelling abstractions for interdisciplinary teams of business and IT specialists for aligning the mapping of business collaboration processes and the underlying distributed IT. The modelling abstractions are applied in a case study to derive a reference architecture for meat supply chain transparency systems.
Conclusion
A key challenge in developing the design framework is the difficulty of comparing models of business processes and IT that come from diverse organisations. Our main contribution is the set of modelling abstractions, which enabled us to represent business processes and IT in a uniform and comparable manner, and the systematic approach for applying the modelling abstractions. The framework is applied in the agri-food sector and needs to be evaluated further in multiple case studies from various application domains.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The design framework for aligning business processes and IT in diverse organizations provides a valuable tool for startups looking to collaborate effectively and integrate their systems.
https://www.sciencedirect.com/science/article/pii/S0950584920301397,A microservice composition approach based on the choreography of BPMN fragments,Pedro=Valderas: pvalderas@pros.upv.es; Victoria=Torres: vtorres@pros.upv.es; Vicente=Pelechano: pele@pros.upv.es,"Abstract
Context
Microservices
 must be composed to provide users with complex and elaborated functionalities. It seems that the decentralized nature of microservices makes a choreography style more appropriate to achieve such cooperation, where lighter solutions based on asynchronous events are generally used. However, a microservice composition based on choreography distributes the flow logic of the composition among microservices making further analysis and updating difficult, i.e. there is not a big picture of the composition that facilitates these tasks. 
Business Process Model and Notation
 (BPMN) is the OMG standard developed to represent Business Processes (BPs), being widely used to define the big picture of such compositions. However, BPMN is usually considered in orchestration-based solutions, and orchestration can be a drawback to achieve the decoupling pursued by a 
microservice architecture
.
Objective
Defining a microservice composition approach that allows us to create a composition in a BPMN model, which facilitates further analysis for taking engineering decisions, and execute them through an event-based choreography to have a high degree of decoupling and independence among microservices.
Method
We followed a research methodology for 
information systems
 that consists of a 5-step process: awareness of the problem, suggestion, development, evaluation, and conclusion.
Results
We presented a microservice composition approach based on the choreography of BPMN fragments. On the one hand, we propose to describe the big picture of the composition with a BPMN model, providing a valuable mechanism to analyse it when engineering decisions need to be taken. On the other hand, this model is split into fragments in order to be executed through an event-based choreography form, providing the high degree of decoupling among microservices demanded in this type of architecture. This composition approach is supported by a 
microservice architecture
 defined to achieve that both descriptions of a composition (big picture and split one) coexist. A realization of this architecture in Java/Spring technology is also presented.
Conclusions
The evaluation that is done to our work allows us to conclude that the proposed approach for composing microservices is more efficient than solutions based on ad-hoc development.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The approach of composing microservices using BPMN and choreography provides a practical and efficient way for startups to design their systems with a high degree of decoupling. The evaluation of the approach and the realization in Java/Spring technology demonstrate its feasibility and effectiveness.
https://www.sciencedirect.com/science/article/pii/S0950584920301385,Type slicing: An accurate object oriented slicing based on sub-statement level dependence graph,Li=Bixin: bx.li@seu.edu.cn,"Abstract
Context
Program slicing is very useful in program analysis and software engineering. It computes the slice, which is a part of program and contains all the statements related to the given slicing criterion. The more accurate a slicing technique could be, the smaller the slice is.
Objective
This paper aims to improve the current slicing accuracy for object-oriented programs. The slicing accuracy is mainly related to three factors, the dependency graph (which extracts the inner relationships of source code), the slicing criterion (which determines the slicing requirement), and the slicing algorithm (which computes the slice for the criterion from the dependency graph).
Method
Our method consists of three parts. First, we present a 
Sub-Statement Level Dependence Graph
 (SSLDG), which computes finer-grained dependences for object-oriented programs than mostly-used statement level graph. Second, we present a new type slicing criterion called 
(Sub-statement) Type Slicing Criterion
 (STSC), which supports the user to specify not only the statement and object variable, but also the type of object among its polymorphic types. At last, a corresponding slicing algorithm called 
(Sub-statement) Type Slicing
 (STS) is designed to perform the slicing process.
Results
We implement STS on Java programs as MyJavaSlicer, and run it with ten open source projects and random slicing criteria. The results show that STS slicing algorithm as well as SSLDG would make slices 35.90% smaller than traditional two-phase slicing; additionally using STSC would make the slices 48.4% further smaller; STSC also helps traditional two-phase slices reduced by 56.90%.
Conclusions
STS could provide more accurate slices than traditional two-phase slicing, and it also runs faster on most cases; STSC helps specify the slicing requirement, and roughly halves the size of slices for both slicing algorithms.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The improvement in slicing accuracy for object-oriented programs through SSLDG, STSC, and STS could benefit startups working on software development. The results show significant reductions in slice size, indicating a practical application of the proposed method."
https://www.sciencedirect.com/science/article/pii/S0950584920301403,Automated model-based performance analysis of software product lines under uncertainty,Paolo=Arcaini: arcaini@nii.ac.jp,"Abstract
Context:
 A Software Product Line (SPL) can express the variability of a system through the specification of configuration options. Evaluating performance characteristics, such as the 
system response time
 and 
resource utilization
, of a software product is challenging, even more so in the presence of uncertain values of the attributes.
Objective:
 The goal of this paper is to automate the generation of performance models for software products derived from the feature model by selection heuristics. We aim at obtaining model-based predictive results to quantify the correlation between the features, along with their uncertainties, and the 
system performance
. This way, software engineers can be informed on the performance characteristics before implementing the system.
Method:
 We propose a tool-supported framework that, starting from a feature model annotated with performance-related characteristics, derives 
Queueing Network
 (QN) performance models for all the products of the SPL. Model-based performance analysis is carried out on the models obtained by selecting the products that show the maximum and minimum performance-based costs.
Results:
 We applied our approach to almost seven thousand feature models including more than one hundred and seventy features. The generation of QN models is automatically performed in much less than one second, whereas their model-based performance analysis embeds simulation delays and requires about six minutes on average.
Conclusion:
 The experimental results confirm that our approach can be effective on a variety of systems for which software engineers may be provided with early insights on the 
system performance
 in reasonably short times. Software engineers are supported in the task of understanding the performance bounds that may encounter when (de)selecting different configuration options, along with their uncertainties.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,Automating the generation of performance models for software products can greatly benefit startups in understanding the correlation between features and system performance. The tool-supported framework and the application to thousands of feature models demonstrate the potential impact and efficiency of the approach.
https://www.sciencedirect.com/science/article/pii/S0950584920301452,Cloud applications monitoring: An industrial study,Damian A.=Tamburri: d.a.tamburri@tue.nl; Marco=Miglierina: marco.miglierina@contentwise.com; Elisabetta Di=Nitto: elisabetta.dinitto@polimi.it,"Abstract
Context
Modern software systems employ large IT infrastructures hosted in on-premise clouds or using “rented” cloud resources from specific vendors. The unifying force across any cloud strategy is incremental product and application improvement against conservation of those resources. This is where monitoring of cloud applications becomes a key asset
Objective
To shed light over the status of monitoring practices in industry, we study: (a) monitoring practices and tools adoption in industry; (b) size and complexity of industrial monitoring problems; (c) the role of software architecture and software process with respect to monitoring strategies.
Method
We conduct mixed-methods empirical research featuring interviews and a web survey featuring 140+ practitioners from over 70 different organizations.
Results
Even if the market makes available a significant set of monitoring tools, our results show a rather unappealing picture of industrial monitoring: (a) industrial decision-makers do not perceive monitoring as a key asset even though the downtime of their applications correlates heavily with the level of automation and responsiveness enabled by monitoring; (b) monitoring is done with crude technology, mostly MySQL querying or similar (e.g., Nagios); finally, (c) incidents are discovered by clients rather than application owners.
Conclusion
We conclude that the road toward the industrial adoption of cutting-edge monitoring technology is still one of the less travelled, presumably in connection to the considerable investment required. Furthermore, the lack of industrial cloud monitoring standards does not help in addressing the proliferation of multiple tool combinations, with varying effectiveness. Further research should be invested in looking into and addressing these major concerns.",November 2020,"Cloud monitoring, Applications monitoring, Incident handling, Rapid response organizational structures, Online survey, Industrial study",Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on monitoring practices in industry provides insights that could be relevant to startups managing cloud applications. However, the lack of adoption of cutting-edge monitoring technology and the challenges in standardization may limit the immediate practical value for startups."
https://www.sciencedirect.com/science/article/pii/S0950584920300641,Multiple fault localization of software programs: A systematic literature review,Abubakar=Zakari: abubakar.zakari@yahoo.com,"Abstract
Context
Multiple 
fault localization
 (MFL) is the act of identifying the locations of multiple faults (more than one fault) in a faulty software program. This is known to be more complicated, tedious, and costly in comparison to the traditional practice of presuming that a software contains a single fault. Due to the increasing interest in MFL by the research community, a broad spectrum of MFL debugging approaches and solutions have been proposed and developed.
Objective
The aim of this study is to systematically review existing research on MFL in the 
software fault
 localization (SFL) domain. This study also aims to identify, categorize, and synthesize relevant studies in the research domain.
Method
Consequently, using an evidence-based 
systematic methodology
, we identified 55 studies relevant to four research questions. The methodology provides a systematic selection and evaluation process with rigorous and repeatable evidence-based studies selection process.
Result
The result of the systematic review shows that research on MFL is gaining momentum with stable growth in the last 5 years. Three prominent MFL debugging approaches were identified, i.e. One-bug-at-a-time debugging approach (OBA), parallel debugging approach, and multiple-bug-at-a-time debugging approach (MBA), with OBA debugging approach being utilized the most.
Conclusion
The study concludes with some identified research challenges and suggestions for future research. Although MFL is becoming of grave concern, existing solutions in the field are less mature. Studies utilizing real faults in their experiments are scarce. Concrete solutions to reduce MFL debugging time and cost by adopting an approach such as MBA debugging approach are also less, which require more attention from the research community.",August 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The systematic review of MFL debugging approaches provides valuable insights for startups working on software development, although the practical implications may be more relevant to established companies."
https://www.sciencedirect.com/science/article/pii/S0950584920301427,Towards automatically generating block comments for code snippets,Xiapu=Luo: csxluo@comp.polyu.edu.hk; Yuan=Huang: huangyjn@gmail.com; Shaohao=Huang: huangshh29@mail2.sysu.edu.cn; Huanchao=Chen: fchenhch@mail2.sysu.edu.cn; Xiangping=Chen: chenxp8@mail.sysu.edu.cn; Nan=Jia: jianan_0101@163.com; Xinyu=Hu: husense@foxmail.com; Xiaocong=Zhou: isszxc@mail.sysu.edu.cn,"Abstract
Code commenting is a common programming practice of practical importance to help developers review and comprehend 
source code
. There are two main types of code comments for a method: header comments that summarize the method functionality located before a method, and block comments that describe the functionality of the code snippets within a method. Inspired by the effectiveness of 
deep learning
 techniques in the NLP field, many studies focus on using the machine 
translation model
 to automatically generate comment for the 
source code
. Because the data set of block comments is difficult to collect, current studies focus more on the automatic generation of header comments than that of block comments. However, block comments are important for 
program comprehension
 due to their explanation role for the code snippets in a method. To fill the gap, we have proposed an approach that combines heuristic rules and learning-based method to collect a large number of comment-code pairs from 1,032 
open source projects
 in our previous study. In this paper, we propose a reinforcement learning-based method, 
RL-BlockCom
, to automatically generate block comments for code snippets based on the collected comment-code pairs. Specifically, we utilize the 
abstract syntax tree
 (i.e., AST) of a code snippet to generate a token sequence with a statement-based traversal way. Then we propose a composite learning model, which combines the actor-critic algorithm of 
reinforcement learning
 with the encoder-decoder algorithm, to generate block comments. On the data set of the comment-code pairs, the BLEU-4 score of our method is 24.28, which outperforms the baselines and state-of-the-art in comment generation.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed approach of automatically generating block comments for code snippets using reinforcement learning has the potential to enhance program comprehension and improve development efficiency.
https://www.sciencedirect.com/science/article/pii/S0950584920301440,The impact of using a domain language for an agile requirements management,Matias=Urbieta: murbieta@lifia.info.unlp.edu.ar; Leandro=Antonelli: lanto@lifia.info.unlp.edu.ar; Gustavo=Rossi: gustavo@lifia.info.unlp.edu.ar; Julio Cesar Sampaio=do Prado Leite: http://www.inf.puc-rio.br/julio,"Abstract
Context
: The development of software systems is a complex activity because of its nature and the management of its construction. It is challenging to create and follow a plan. Moreover, budget overrun is a common consequence of this situation. Agile methods, like Scrum, help to mitigate this problem using incremental and 
iterative development
. Agile methods jump start new developments, but it is difficult to be agile after several months when the software has to deal with many requirements that are scattered and tangled across several User Stories written in different Sprints. 
Objective
: In this paper, we propose a traceability approach anchored on an index structure to access specific User Stories from a large set. Our proposed strategy has the goal to consolidate the information dispersed in different User Stories into a particular lexicon: The Language Extended Lexicon (LEL). 
Method
: The proposed approach consists of a set of rules which extract the information dispersed in the User Stories and organize it in symbols of the Lexicon. Thus, the Lexicon supplies a consolidated and organized structure to mitigate the problem of tangled information that generates lack of traceability among different sprints. 
Results
: We assessed how the Lexicon built by our approach improves everyday activities related to requirement management. The assessment is based on a 
quantitative evaluation
 with 36 subjects. 
Conclusion
: The approach presents benefits for requirement tracing in 
agile methodologies
 supported by the preliminary results of the evaluation. We have developed an application (a prototype) that automates the LEL derivation rules from a set of User Stories.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"While the proposed traceability approach anchored on an index structure is beneficial for consolidating information in agile methodologies, the practical impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920301439,Effectiveness of Kotlin vs. Java in android app development tasks,Riccardo=Coppola: riccardo.coppola@polito.it; Luca=Ardito: luca.ardito@polito.it; Giovanni=Malnati: giovanni.malnati@polito.it; Marco=Torchiano: marco.torchiano@polito.it,"Abstract
Context:
Kotlin is a new programming language representing an alternative to Java; they both target the same 
JVM
 and can safely coexist in the same application. Kotlin is advertised as capable to solve several known limitations of Java. Recent surveys show that Kotlin achieved a relevant diffusion among Java developers. 
Goal:
We planned to empirically assess a few typical promises of Kotlin w.r.t. known Java’s limitations, in terms of development effectiveness, 
maintainability
, and ease of development. 
Method:
Our experiment involved 27 teams of 4 people each that completed a set of maintenance tasks (both defect correction and feature addition) on 
Android
 apps written in either Java or Kotlin. In addition to the number of fixed defects, effort, and code size, we collected, though a questionnaire, the participants’ perceptions about the avoidance of known pitfalls. 
Results:
We did not observe any significant difference in terms of 
maintainability
 between the two languages.We found a significant difference regarding the amount of code written, which constitutes evidence of better 
conciseness
 of Kotlin. Concerning ease of development, the frequency of NullPointerExceptions reported by the subjects was significantly lower when developing in Kotlin. On the other hand, no significant difference was found in the occurrence of other common Java pitfalls. Finally, the IDE support was deemed better for Java than Kotlin. 
Conclusions:
Some of the promises of Kotlin to be a ”better Java” have been confirmed by our empirical assessment. Evidence suggests that the effort in transitioning to Kotlin can provide some advantages to Java developers, especially regarding code 
conciseness
.Our results may serve as the basis for further investigations on the properties of the language.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The empirical assessment of Kotlin as an alternative to Java in terms of development effectiveness, maintainability, and ease of development provides valuable insights for startups looking to adopt a new programming language."
https://www.sciencedirect.com/science/article/pii/S095058491930223X,Guidelines for the search strategy to update systematic literature reviews in software engineering,Katia Romero=Felizardo: katiascannavino@utfpr.edu.br; Claes=Wohlin: claes.wohlin@bth.se; Marcos=Kalinowski: kalinowski@inf.puc-rio.br; Emilia=Mendes: emilia.mendes@bth.se,"Abstract
Context
Systematic Literature Reviews (SLRs) have been adopted within Software Engineering (SE) for more than a decade to provide meaningful summaries of evidence on several topics. Many of these SLRs are now potentially not fully up-to-date, and there are no standard proposals on how to update SLRs in SE.
Objective
The objective of this paper is to propose guidelines on how to best search for evidence when updating SLRs in SE, and to evaluate these guidelines using an SLR that was not employed during the formulation of the guidelines.
Method
To propose our guidelines, we compare and discuss outcomes from applying different search strategies to identify primary studies in a published SLR, an SLR update, and two replications in the area of effort estimation. These guidelines are then evaluated using an SLR in the area of software ecosystems, its update and a replication.
Results
The use of a single iteration forward snowballing with Google Scholar, and employing as a seed set the original SLR and its primary studies is the most cost-effective way to search for new evidence when updating SLRs. Furthermore, the importance of having more than one researcher involved in the selection of papers when applying the inclusion and exclusion criteria is highlighted through the results.
Conclusions
Our proposed guidelines formulated based upon an effort estimation SLR, its update and two replications, were supported when using an SLR in the area of software ecosystems, its update and a replication. Therefore, we put forward that our guidelines ought to be adopted for updating SLRs in SE.",November 2020,"Systematic literature review update, Systematic literature reviews, Software engineering, Snowballing, Searching for evidence",Information and Software Technology,2025-03-18T00:00:00,5.0,"The proposed guidelines for updating Systematic Literature Reviews in Software Engineering offer a standard approach, but the immediate practical value for startups may not be significant."
https://www.sciencedirect.com/science/article/pii/S0950584919301740,"The Symposium on Search-Based Software Engineering: Past, Present and Future",Silvia R.=Vergilio: silvia@inf.ufpr.br; Thelma E.=Colanzi: thelma@din.uem.br; Wesley K.G.=Assunção: wesleyk@utfpr.edu.br; Paulo Roberto=Farah: paulo.farah@udesc.br; Giovani=Guizzo: g.guizzo@ucl.ac.uk,"Abstract
Context
Search-Based 
Software Engineering
 (SBSE) is the research field where 
Software Engineering
 (SE) problems are modelled as search problems to be solved by search-based techniques. The Symposium on Search Based Software Engineering (SSBSE) is the premier event on SBSE, which had its 11
th
 edition in 2019.
Objective
In order to better understand the characteristics and evolution of papers published at SSBSE, this work reports results from a mapping study targeting the proceedings of all SSBSE editions. Despite the existing mapping studies on SBSE, our contribution in this work is to provide information to researchers and practitioners willing to enter the SBSE field, being a source of information to strengthen the symposium, guide new studies, and motivate new collaboration among research groups.
Method
A 
systematic mapping study
 was conducted with a set of four research questions, in which 134 studies published in all editions of SSBSE, dated from 2009 to 2019, were evaluated. In a fifth question, 32 papers published in the challenge track were summarised.
Results
Throughout the years, 290 authors from 25 countries have contributed to the main track of the symposium, with the collaboration of at least two institutions in 46.3% of the papers. SSBSE papers have got substantial external visibility, as most citations are from different venues. The SE tasks addressed by SSBSE are mostly related to software testing, 
software debugging
, 
software design
, and maintenance. 
Evolutionary algorithms
 are present in 75% of the papers, being the most common search technique. The evaluation of the SBSE approaches usually includes industrial systems.
Conclusions
SSBSE has helped increase the popularity of SBSE in the SE research community and has played an important role on making SBSE mature. There are still problems and challenges to be addressed in the SBSE field, which can be tackled by SSBSE authors in further studies.",November 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The research on Search-Based Software Engineering (SBSE) presented in this abstract can provide valuable insights and information to researchers and practitioners entering this field, thus contributing to the overall growth and collaboration in the SBSE community."
https://www.sciencedirect.com/science/article/pii/S0950584920300744,NLP-assisted software testing: A systematic mapping of the literature,Vahid=Garousi: v.garousi@qub.ac.uk; Sara=Bauer: sara.bauer@uibk.ac.at,"Abstract
Context
To reduce manual effort of extracting test cases from natural-language requirements, many approaches based on 
Natural Language Processing
 (NLP) have been proposed in the literature. Given the large amount of approaches in this area, and since many practitioners are eager to utilize such techniques, it is important to synthesize and provide an overview of the state-of-the-art in this area.
Objective
Our objective is to summarize the state-of-the-art in NLP-assisted software testing which could benefit practitioners to potentially utilize those NLP-based techniques. Moreover, this can benefit researchers in providing an overview of the research landscape.
Method
To address the above need, we conducted a survey in the form of a systematic literature mapping (classification). After compiling an initial pool of 95 papers, we conducted a systematic voting, and our final pool included 67 technical papers.
Results
This review paper provides an overview of the contribution types presented in the papers, types of NLP approaches used to assist software testing, types of required input requirements, and a review of tool support in this area. Some key results we have detected are: (1) only four of the 38 tools (11%) presented in the papers are available for download; (2) a larger ratio of the papers (30 of 67) provided a shallow exposure to the NLP aspects (almost no details).
Conclusion
This paper would benefit both practitioners and researchers by serving as an “index” to the body of knowledge in this area. The results could help practitioners utilizing the existing NLP-based techniques; this in turn reduces the cost of test-case design and decreases the amount of human resources spent on test activities. After sharing this review with some of our industrial collaborators, initial insights show that this review can indeed be useful and beneficial to practitioners.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The overview of NLP-assisted software testing and the tool support analysis presented in this abstract can greatly benefit practitioners and researchers, reducing the cost of test-case design and optimizing test activities, making it a valuable contribution to the software testing community."
https://www.sciencedirect.com/science/article/pii/S0950584920301166,Engineering human-in-the-loop interactions in cyber-physical systems,Vicente=Pelechano: pele@pros.upv.es; Miriam=Gil: mgil@pros.upv.es; Manoli=Albert: malbert@pros.upv.es; Joan=Fons: jjfons@pros.upv.es,"Abstract
Context:
 Cyber-Physical Systems (CPSs) are gradually and widely introducing autonomous capabilities into everything. However, human participation is required to accomplish tasks that are better performed with humans (often called human-in-the-loop). In this way, human-in-the-loop solutions have the potential to handle complex tasks in unstructured environments, by combining the cognitive skills of humans with 
autonomous systems
 behaviors.
Objective:
 The objective of this paper is to provide appropriate techniques and methods to help designers analyze and design human-in-the-loop solutions. These solutions require interactions that engage the human, provide natural and understandable collaboration, and avoid disturbing the human in order to improve human experience.
Method:
 We have analyzed several works that identified different requirements and critical factors that are relevant to the design of human-in-the-loop solutions. Based on these works, we have defined a set of design principles that are used to build our proposal. Fast-prototyping techniques have been applied to simulate the designed human-in-the-loop solutions and validate them.
Results:
 We have identified the technological challenges of designing human-in-the-loop CPSs and have provided a method that helps designers to identify and specify how the human and the system should work together, focusing on the 
control strategies
 and interactions required.
Conclusions:
 The use of our approach facilitates the design of human-in-the-loop solutions. Our method is practical at earlier stages of the 
software life cycle
 since it allows domain experts to focus on the problem and not on the solution.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"While the research on human-in-the-loop solutions for Cyber-Physical Systems (CPSs) is important in advancing autonomous capabilities, the practical application of the proposed techniques and methods may be limited to a niche audience, thus potentially impacting a smaller subset of early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584920301142,Refactoring effect on internal quality attributes: What haven’t they told you yet?,Alessandro=Garcia: afgarcia@inf.puc-rio.br; Eduardo=Fernandes: emfernandes@inf.puc-rio.br; Alexander=Chávez: achavez@tecgraf.puc-rio.br; Isabella=Ferreira: isabella.ferreira@polymtl.ca; Diego=Cedrim: dccedrim@amazon.com; Leonardo=Sousa: leo.sousa@sv.cmu.edu; Willian=Oizumi: woizumi@inf.puc-rio.br,"Abstract
Context
Code refactoring
 was conceived for enhancing code structures, often in terms of internal quality attributes such as cohesion and coupling. Developers may have to apply multiple 
refactoring operations
 to achieve the expected enhancement. Re-refactoring occurs whenever one or more refactoring operations are performed on a previously refactored code element. The literature often assumes each single refactoring improves rather than worsens internal quality attributes, while re-refactoring implies further improvements. Unfortunately, quantitative evidence on this matter is scarce if not nonexistent.
Objective
This paper extends a large quantitative study about the refactoring effect on internal quality attributes with new insights, plus an unprecedented re-refactoring effect analysis. We particularly investigate if re-refactoring operations are more effective in improving attributes when compared to single operations.
Method
We analyzed 23 
open software
 projects with 29,303 refactoring operations, from which nearly 50% constitute re-refactorings. We assessed five attributes: cohesion, complexity, coupling, inheritance, and size. We combined descriptive analysis and statistical tests to deeply understand the effect of both refactoring and re-refactoring on each attribute.
Results
Contrary to current knowledge, our study revealed that 90% of refactoring operations, and 100% of re-refactoring operations, were applied to code elements with at least one critical attribute. Critical attribute is an attribute whose metrics used for computing it have anomalous values, e.g. high coupling. Most operations (65%) improve attributes presumably associated with the refactoring type applied; the other operations (35%) keep those attributes unaffected. Whenever refactoring and re-refactoring operations are applied without additional changes, i.e., root-canal refactoring, attributes tend to improve or at least not worsen. Surprisingly, if these operations occur with additional changes such as feature additions, i.e., floss refactoring, they mostly improve rather than worsen attributes.
Conclusions
Besides revealing the effect of refactoring and re-refactoring on each attribute, we derived insights on leveraging the current refactoring practices.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides valuable insights into the effects of refactoring and re-refactoring on code attributes, which can be crucial for startups looking to improve their code quality and practices."
https://www.sciencedirect.com/science/article/pii/S2352673422000671,Whistleblowing in entrepreneurial ventures,Daniel R.=Clark: dclark@ivey.ca; Bradley R.=Skousen: bradleyskousen@gmail.com,"Abstract
Despite the occurrence of high-profile whistleblowing events in entrepreneurial firms (e.g., We Work, Uber, and Theranos), there is a dearth of understanding of when and why whistleblowing occurs 
outside
 the domain of traditional large firms. Indeed, we argue that new ventures represent a unique and meaningful heterodoxy as entrepreneurs, rebels with a cause, inspire others to join their cause who will ultimately betray the entrepreneur to protect that cause. We test and find support for our hypotheses regarding firm size and new venture status on whistleblowing on a unique dataset of 3113 reported frauds. From these findings we inductively theorize a new model of 
whistleblower
 motivation driven by the unique context of entrepreneurs drawing people to join a cause, and the price when fidelity is not maintained.",June 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"The abstract introduces a new model of whistleblower motivation in entrepreneurial firms, shedding light on a less explored area. This could be valuable for European startups to understand the dynamics of whistleblowing and loyalty within their organizations."
https://www.sciencedirect.com/science/article/pii/S0950584920301130,Using simulated annealing for locating array construction,Tatsuhiro=Tsuchiya: t-tutiya@ist.osaka-u.ac.jp,"Abstract
Context
Combinatorial interaction testing is known to be an efficient testing strategy for computing and 
information systems
. Locating arrays are mathematical objects that are useful for this testing strategy, as they can be used as a test suite that permits 
fault localization
 as well as fault detection. In this application, each row of an array is used as an individual test.
Objective
This paper proposes an algorithm for constructing locating arrays with a small number of rows. Testing cost increases as the number of tests increases; thus the problem of finding locating arrays of small sizes is of practical importance.
Method
The proposed algorithm uses simulated annealing, a meta-heuristic algorithm, to find locating array of a given size. The whole algorithm repeatedly executes the 
simulated annealing algorithm
 with the input array size being dynamically varied.
Results
Experimental results show (1) that the proposed algorithm is able to construct locating arrays for problem instances of large sizes and (2) that, for problem instances for which nontrivial locating arrays are known, the algorithm is often able to generate locating arrays that are smaller than or at least equal to the known arrays.
Conclusion
Based on the results, we conclude that the proposed algorithm can produce small locating arrays and scale to practical problems.",October 2020,"Locating arrays, Combinatorial interaction testing, Software testing, Simulated annealing",Information and Software Technology,2025-03-18T00:00:00,6.0,"The algorithm proposed for constructing locating arrays can be beneficial for startups involved in testing strategies, but may have a limited impact compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920300653,"Early prediction of quality of service using interface-level metrics, code-level metrics, and antipatterns",Marouane=Kessentini: marouane@umich.edu; Chaima=Abid: cabid@umich.edu; Hanzhang=Wang: hanzwang@ebay.com,"Abstract
Context:
 With the current high trends of deploying and using web services in practice, effective techniques for maintaining high quality of Service are becoming critical for both service providers and subscribers/users. Service providers want to predict the quality of service during early stages of development before releasing them to customers. Service clients consider the quality of service when selecting the best one satisfying their preferences in terms of price/budget and quality between the services offering the same features. The majority of existing studies for the prediction of quality of service are based on 
clustering algorithms
 to classify a set of services based on their collected quality attributes. Then, the user can select the best service based on his expectations both in terms of quality and features. However, this assumption requires the deployment of the services before being able to make the prediction and it can be time-consuming to collect the required data of running web services during a period of time. Furthermore, the clustering is only based on well-known quality attributes related to the services performance after deployment. 
Objective:
 In this paper, we start from the hypothesis that the quality of the source code and 
interface design
 can be used as indicators to predict the quality of service attributes without the need to deploy or run the services by the subscribers. 
Method:
 We collected 
training data
 of 707 web services and we used 
machine learning
 to generate 
association rules
 that predict the quality of service based on the interface and code quality metrics, and antipatterns. 
Results:
 The empirical validation of our prediction techniques shows that the generated 
association rules
 have strong support and high confidence which confirms our hypothesis that source code and interface quality metrics/antipatterns are correlated with web service quality attributes which are response time, availability, throughput, successability, reliability, compliance, best practices, latency, and documentation. 
Conclusion:
 To the best of our knowledge, this paper represents the first study to validate the correlation between interface metrics, source 
code metrics
, antipatterns and quality of service. Another contribution of our work consists of generating association rules between the code/interface metrics and quality of service that can be used for prediction purposes before deploying new releases.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The paper introduces a novel approach to predicting service quality attributes based on source code and interface design, which can be highly valuable for startups aiming to optimize their services before deployment."
https://www.sciencedirect.com/science/article/pii/S0950584920300902,Understanding the relationship of conflict and success in software development projects,,"Abstract
Context
Software development incorporates numerous people with diverse expertise and expectations. This makes conflict a common phenomenon in software development. Besides human causes, many conflicts in software development root in the tools and processes. Moreover, the growing role of software in any type of system is increasing the heterogeneity in software projects. The number and variety of tools and processes are increasing. Nevertheless, the relationship between conflicts, particularly rooted in non-human elements, and software project success is still unclear.
Objective
We aim to understand the impact of conflict on the success of software development projects for different types of conflict and different environments. Particularly, we distinguish between human-rooted conflict (HRC) and non-human-rooted conflict (NHRC). Moreover, we investigate whether organization size and team size moderate the impact of conflict on software project success.
Methods
First, we conduct a survey and analyze it using 
structural equation modeling
 (SEM) to investigate any correlation between conflict and software project success. Second, we explore the reasons behind the relationship between conflict and software project success by conducting 13 semi-structured expert interviews.
Results
HRC is always a threat to software project success for any organization or team size. Based on the interviews, resolving an HRC is regularly problematic. On the other hand, NHRC is negatively correlated with software project success only in corporate organizations and small teams. High coordination overhead and dependency on tools and processes make NHRC more influential in corporate organizations. In contrast, overlooking non-human elements and lack of experienced individuals in smaller teams make them more vulnerable to NHRC.
Conclusion
While the detrimental impact of HRC is constant for software project success, NHRC can be controlled efficiently. Corporate organizations need to frequently improve the non-human elements in the development. Smaller teams should expect tools and processes to be significantly influential in their success.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides valuable insights into the impact of conflict on software project success, distinguishing between human-rooted and non-human-rooted conflict. The findings can help organizations improve software development processes and manage conflicts more effectively."
https://www.sciencedirect.com/science/article/pii/S0950584920301026,Investigating the relationship between personalities and agile team climate of software professionals in a telecom company,Sai Datta=Vishnubhotla: sai-datta.vishnubhotla@bth.se,"Abstract
Context
Previous research found that the performance of a team not only depends on the team personality composition, but also on the interactive effects of team climate. Although investigation on personalities associated with software development has been an active research area over the past decades, there has been very limited research in relation to team climate.
Objective
Our study investigates the association between the 
five factor model
 
personality traits
 (openness to experience, 
conscientiousness
, extraversion, agreeableness and neuroticism) and the factors related to team climate (team vision, participative safety, support for innovation and task orientation) within the context of agile teams working in a 
telecom company
.
Method
A survey was used to gather data on personality characteristics and team climate perceptions of 43 members from eight agile teams. The data was initially used for correlation analysis; then, regression models were developed for predicting the 
personality traits
 related to team climate perception.
Results
We observed a statistically significant 
positive correlation
 between openness to experience and support for innovation (r = 0.31). Additionally, agreeableness was observed to be positively correlated with overall team climate (r = 0.35). Further, from regression models, we observed that 
personality traits
 accounted to less than 15% of the variance in team climate.
Conclusion
A person's ability to easily get along with team members (agreeableness) has a significant positive influence on the perceived level of team climate. Results from our 
regression analysis
 suggest that further data may be needed, and/or there are other human factors, in addition to 
personality traits
, that should also be investigated with regard to their relationship with team climate. Overall, the relationships identified in our study are likely to be applicable to organizations within the telecommunications domain that use scrum methodology for software development.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study explores the association between personality traits and team climate within agile teams, providing some insights into the importance of agreeableness and openness to experience. While the findings are interesting, the practical implications for startups may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673423000070,You take after your father: Paternal grit and young adult self-employment,Pankaj C.=Patel: pankaj.patel@villanova.edu; Marcus T.=Wolfe: Marcus.Wolfe@unt.edu,"Abstract
Considerable scholarly attention has been given to the influence parents have on the self-employment of their children. We further investigate this relationship by examining whether paternal grit, via a young adult's grit, could influence young adult self-employment. Using a sample of 1504 participants from the Cultural Pathways to Economic Self-Sufficiency and Entrepreneurship (CUPESSE) survey, our findings indicate that paternal grit is positively associated with young adult grit, and that paternal grit has a positive indirect relationship with young adult self-employment, as mediated by young adult grit. Our study has important implications to ongoing conversations regarding the generational transmission aspects of self-employment, as well as the influence that grit can have on the entrepreneurial process.",June 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"The study provides important insights into the influence of parental grit on young adult self-employment, contributing to the understanding of generational transmission aspects of self-employment and the role of grit in the entrepreneurial process."
https://www.sciencedirect.com/science/article/pii/S0950584920300914,Recommending refactorings via commit message analysis,Marouane=Kessentini: marouane@umich.edu; Soumaya=Rebai: srebal@umich.edu; Vahid=Alizadeh: alizadeh@umich.edu; Oussama Ben=Sghaier: oussama@umich.edu; Rick=Kazman: kazman@hawaii.edu,"Abstract
Context
The purpose of software restructuring, or refactoring, is to improve software quality and developer productivity.
Objective
Prior studies have relied mainly on static and dynamic analysis of code to detect and recommend refactoring opportunities, such as code smells. Once identified, these smells are fixed by applying refactorings which then improve a set of quality metrics. While this approach has value and has shown promising results, many detected refactoring opportunities may not be related to a developer’s current context and intention. Recent studies have shown that while developers document their refactoring intentions, they may miss relevant refactorings aligned with their rationale.
Method
In this paper, we first identify refactoring opportunities by analyzing developer commit messages and check the quality improvements in the changed files, then we distill this knowledge into usable context-driven refactoring recommendations to complement static and dynamic analysis of code.
Results
The evaluation of our approach, based on six 
open source projects
, shows that we outperform prior studies that apply refactorings based on static and dynamic analysis of code alone.
Conclusion
This study provides compelling evidence of the value of using the information contained in existing commit messages to recommend future refactorings.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The study introduces a novel approach to recommending refactoring opportunities based on developer commit messages, outperforming prior studies. This has significant practical value for early-stage ventures looking to improve software quality and productivity."
https://www.sciencedirect.com/science/article/pii/S0950584920301178,Neural networks learn to detect and emulate sorting algorithms from images of their execution traces,Cătălin F.=Perticas: perticascatalin@gmail.com; Bipin=Indurkhya: bipin.indurkhya@uj.edu.pl,"Abstract
Context
Recent advancements in the applicability of 
neural networks
 across a variety of fields, such as 
computer vision
, 
natural language processing
 and others, have re-sparked an interest in program induction methods. (Kitzelman 
[1]
, Gulwani et al. 
[2]
 or Kant [3].)
Problem
When performing a program induction task, it is not feasible to search across all possible programs that map an input to an output because the number of possible combinations or sequences of instructions is too high: at least an 
exponential growth
 based on the generated program length. Moreover, there does not exist a general framework to formulate such program induction tasks and current computational limitations do not allow a very wide range of 
machine learning
 applications in the field of computer programs generation.
Objective
In this study, we analyze the effectiveness of execution traces as 
learning representations
 for 
neural network models
 in a program induction set-up. Our goal is to generate visualizations of program execution dynamics, specifically of sorting algorithms, and to apply 
machine learning techniques
 on them to capture their semantics and emulate their behavior using 
neural networks
.
Method
We begin by classifying images of execution traces for algorithms working on a finite array of numbers, such as various sorting and 
data structures
 algorithms. Next we experiment with detecting sub-program patterns inside the trace sequence of a larger program. The last step is to predict future steps in the execution of various sorting algorithms. More specifically, we try to emulate their behavior by observing their execution traces. We also discuss generalizations to other classes of programs, such as 1-D 
cellular automata
.
Results
Our experiments show that 
neural networks
 are capable of modeling the mechanisms underlying simple algorithms if enough execution traces are provided as data. We compare the performance of our program induction model with other similar experimental results from Graves et al. [4] and Vinyals et al. [5]. We were also able to demonstrate that sorting algorithms can be treated both as images displaying spatial patterns, as well as sequential instructions in a 
domain specific language
, such as swapping two elements. We tested our approach on three types of increasingly harder tasks: detection, recognition and emulation.
Conclusions
We demonstrate that simple algorithms can be modelled using 
neural networks
 and provide a method for representing specific classes of programs as either images or sequences of instructions in a domain-specific language, such that a neural network can learn their behavior. We consider the complexity of various set-ups to arrive at some improvements based on the 
data representation
 type. The insights from our experiments can be applied for designing better models of program induction.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study explores the effectiveness of using execution traces as learning representations for neural network models in program induction tasks. While the findings are interesting and relevant to computer science research, the direct impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920301282,Requirements elicitation methods based on interviews in comparison: A family of experiments,José Ignacio=Panach: joigpana@uv.es; Silvia=Rueda: silvia.rueda@uv.es; Damiano=Distante: damiano.distante@unitelmasapienza.it,"Abstract
Context
There are several methods to elicit requirements through interviews between an end-user and a team of software developers. The choice of the best method in this context is usually on subjective developers’ preferences instead of objective reasons. There is a lack of empirical evaluations of methods to elicit requirements that help developers to choose the most suitable one.
Objective
This paper designs and conducts a family of experiments to compare three methods to elicit requirements: Unstructured Interviews, where there is no specific protocol or artifacts; 
Joint
 Application Design (JAD), where each member of the development team has a specific role; Paper Prototyping, where developers contrast the requirements with the end-user through prototypes.
Method
The experiment is a between-subjects design with next response variables: number of requirements, time, diversity, completeness, quality and performance. The experiment consists of a maximum of 4 rounds of interviews between students that play the role of developers and an instructor that plays the role of client. Subjects had to elaborate a requirements specification document as results of the interviews. We recruited 167 subjects in 4 replications in 3 years. Subjects were gathered in development teams of 6 developers at most, and each team was an experimental unit.
Results
We found some significant differences. Paper Prototyping yields the best results to elicit as many requirements as possible, JAD requires the highest time to report the requirements and the least overlapping, and Unstructured Interviews yields the highest overlapping and the lowest time to report the requirements.
Conclusions
Paper Prototyping is the most suitable for eliciting functional requirements, JAD is the most suitable for non-functional requirements and to avoid overlapping, Unstructured Interviews is the fastest but with poor quality in the results.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study compares different methods to elicit requirements, providing insights into the strengths and weaknesses of each approach. While the findings can be valuable for software development teams, the direct impact on European early-stage ventures may vary."
https://www.sciencedirect.com/science/article/pii/S0950584920301154,A statistical pattern based feature extraction method on system call traces for anomaly detection,Ruoyu=Wang: rywang@scut.edu.cn,"Abstract
Context
In host-based 
anomaly detection
, feature extraction on the system call traces is important to build an effective 
anomaly detection
 model. Different kinds of feature extraction methods are recently proposed and most of them aim at preserving the positional information of the system calls within a trace. These extracted features are generally named from system calls, therefore, cannot be used directly in the case of cross platform applications. In addition, some of these feature extraction methods are very costly to implement.
Objective
This paper presents a new feature extraction method. It aims at extracting features that are irrelevant to the names of system calls. The samples represented by the extracted features can be directly used in the case of cross platform applications. In addition, this method is lightweight in that the feature values are not expensive to compute.
Method
The proposed method firstly transforms the system calls in a trace into frequency sequences of n-grams and then explores a fixed number of statistical features on the frequency sequences. The extracted features are irrelevant to the names/indexes of system calls on a platform. The calculation of feature values works on the frequency sequences rather than on system call sequences. These feature vectors built on the training set with only normal data are then used to train a one class 
classification model
 for 
anomaly detection
.
Results
We compared our method with four previously proposed feature extraction methods on system call traces. When used on the same platform, even though our method does not always obtain the highest AUC, overall, it performs better than all the compared methods. When testing on cross platform, it performs the best among all compared methods.
Conclusion
The features extracted by our method are platform-independent and are suitable for 
anomaly detection
 across platforms.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed feature extraction method for anomaly detection is platform-independent, lightweight, and outperforms existing methods on both same platform and cross-platform applications."
https://www.sciencedirect.com/science/article/pii/S0950584920301324,Effort-Aware semi-Supervised just-in-Time defect prediction,Weiwei=Li: liweiwei@nuaa.edu.cn; Wenzhou=Zhang: wenzhou2671@163.com; Xiuyi=Jia: jiaxy@njust.edu.cn; Zhiqiu=Huang: zqhuang@nuaa.edu.cn,"Abstract
Context
Software defect
 prediction is an important technique that can help practitioners allocate their quality assurance efforts. In recent years, just-in-time (JIT) 
defect prediction
 has attracted considerable interest, as it enables developers to identify risky changes at check-in time.
Objective
Many studies have conducted research from supervised and unsupervised perspectives. A model that does not rely on label information would be preferred. However, the performance of unsupervised models proposed by previous studies in the classification scenario was unsatisfactory due to the lack of 
supervised information
. Furthermore, most supervised models fail to outperform simple unsupervised models in the ranking scenario. To overcome this weakness, we conduct research from the semi-supervised perspective that only requires a small quantity of labeled data for training.
Method
In this paper, we propose a semi-supervised model for JIT defect prediction named Effort-Aware Tri-Training (EATT), which is an effort-aware method using a 
greedy strategy
 to rank changes. We compare EATT with the state-of-the-art supervised and unsupervised models with respect to different labeled rate.
Results
The experimental results on six open-source projects demonstrate that EATT outperforms existing supervised and unsupervised models for effort-aware JIT defect prediction, and has similar or superior performance in classifying defect-inducing changes.
Conclusion
The results show that EATT can not only achieve high 
classification accuracy
 as supervised models, but also offer more practical value than other compared models from the perspective of the effort needed to review changes.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The semi-supervised model EATT for defect prediction offers practical value by outperforming existing supervised and unsupervised models, requiring only a small amount of labeled data for training."
https://www.sciencedirect.com/science/article/pii/S2352673421000366,What entrepreneurship is really “productive”? An alternative view on Baumol's typology,Dmitrii=Trubnikov: dtrubnikov@hse.ru,"Abstract
The paper aims to contribute to the discussion on “productive, unproductive, and destructive” entrepreneurship started by William Baumol. It supports the position that all three categories in Baumol's typology are important to understand how institutions affect entrepreneurship but advocates for an alternative approach to distinguish among them. While the traditional demarcation is often based on the net effect on productivity, the proposed approach focuses on the public choice reasoning that not only distinguishes between “rent-seeking” and “profit-seeking,” but also emphasizes that rent-seeking should not be considered a pure transfer. Rent-seeking not only affects regulatory decisions, it also generates activities in the sphere that is traditionally perceived in the productive side. It is important to take this sphere into account when welfare implications of regulatory initiatives are discussed and when policymakers aim to stimulate “productive” entrepreneurship.",November 2021,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"This paper contributes to the discussion on different types of entrepreneurship and provides insights on how institutions affect entrepreneurship, which can be beneficial for European startups."
https://www.sciencedirect.com/science/article/pii/S0950584920301336,Simplifying the Search of npm Packages,Ahmad=Abdellatif: a_bdella@encs.concordia.ca; Yi=Zeng: ze_yi@encs.concordia.ca; Mohamed=Elshafei: m_lshafe@encs.concordia.ca; Emad=Shihab: eshihab@encs.concordia.ca; Weiyi=Shang: shang@encs.concordia.ca,"Abstract
Context
Code reuse, generally done through software packages, allows developers to reduce time-to-market and improve code quality. The npm ecosystem is a Node.js package 
management system
 which contains more than 700 K Node.js packages and to help developers find high-quality packages that meet their needs, npms developed a search engine to rank Node.js packages in terms of quality, popularity, and maintenance. However, the current ranking mechanism for npms tends to be arbitrary and contains many different equations, which increases complexity and computation.
Objective
The goal of this paper is to empirically improve the efficiency of npms by simplifying the used components without impacting the current npms package ranks.
Method
We use feature selection methods with the aim of simplifying npms’ equations. We remove the features that do not have a significant effect on the package’s rank. Then, we study the impact of the simplified npms on the packages’ rank, the amount of resources saved compared to the original npms, and the performance of the simplified npms as npm evolves.
Results
Our findings indicate that (1) 31% of the unique variables of npms’ equation can be removed without breaking the original packages’ ranks; (2) The simplified npms, on average, preserves the overlapping of the packages by 98% and the ranking of those packages by 97%; (3) Using the simplified npms saves 10% of packages scoring time and more than 1.47 million network requests on each scoring run; (4) As the npm evolve through a period of 12 months, the simplified-npms was able to achieve results similar to the original npms.
Conclusion
Our results show that the simplified npms preserves the original ranks of packages and is more efficient than the original npms. We believe that using our approach, helps the npms community speed up the scoring process by saving 
computational resources
 and time.",October 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The study on simplifying the npm ranking mechanism shows significant improvements in efficiency, preserving original package ranks while saving resources and time, making it highly valuable for developers."
https://www.sciencedirect.com/science/article/pii/S0950584920300689,Model composition in Model Driven Engineering: A systematic literature review,Anas=Abouzahra: anas.abouzahra@edu.uiz.ac.ma,"Abstract
Context
Model Driven Engineering
 (MDE) aims to alleviate complexity and improve 
reusability
 in software development. The development of complex software implies to divide it into independent parts before then assembled. This is how the problem of model composition has become an interesting and stills an emerging topic in MDE.
Objective
Our goal is to analyze the current state of the art in model composition in the context of 
Model Driven Engineering
.
Method
We use the 
systematic literature review
 based on the guidelines proposed by Biolchini et al., Brereton et al., and Kitchenham and Charters. We propose five research questions and six quality assessments.
Results
Of the 9270 search results, 56 have been considered relevant studies. These studies have resulted in 36 primary studies.
Conclusion
The evaluation shows that most of approaches allow more than two models as inputs of the composition, allow composing heterogeneous models and enable the tuning of the composition schema, while the important limitations are about the maturity of implementations and the lack on the management of future evolutions or 
backwards compatibility
.",September 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The analysis of model composition in Model Driven Engineering provides insights into the current state of the art, but the limitations in implementation maturity and handling future evolutions impact its practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300719,Automated isolation for white-box test generation,Dávid=Honfi: honfi@mit.bme.hu; Zoltán=Micskei: micskeiz@mit.bme.hu,"Abstract
Context:
 White-box test generation is a technique used for automatically selecting test inputs using only the code under test. However, such techniques encounter challenges when applying them to complex programs. One of the challenges is handling invocations to external modules or dependencies in the code under test.
Objective:
 Without using proper isolation, like mocks, generated tests cannot cover all parts of the source code. Moreover, invoking 
external dependencies
 may cause unexpected side effects (e.g., accessing the file system or network). Our goal was to tackle this issue while maintaining the advantages of white-box test generation.
Method:
 In this paper, we present an automated approach addressing the external dependency challenge for white-box test generation. This technique isolates the test generation and execution by transforming the code under test and creating a parameterized sandbox with generated mocks. We implemented the approach in a ready-to-use tool using Microsoft Pex as a test generator, and evaluated it on 10 open-source projects from GitHub having more than 38.000 lines of code in total.
Results:
 The results from the evaluation indicate that if the lack of isolation hinders white-box test generation, then our approach is able to help: it increases the code coverage reached by the automatically generated tests, while it prevents invoking any external module or dependency. Also, our results act as a unique baseline for the test generation performance of Microsoft Pex on open-source projects.
Conclusion:
 Based on the results, our technique might serve well for handling external dependencies in white-box test generation as it increases the coverage reached in such situations, while maintaining the practical applicability of the tests generated on the isolated code.",September 2020,"Testing, Test generation, White-box, Isolation, Mocking, Code transformation, Empirical evaluation",Information and Software Technology,2025-03-18T00:00:00,8.0,The proposed approach addresses a significant challenge in white-box test generation and has practical applicability for improving code coverage and handling external dependencies.
https://www.sciencedirect.com/science/article/pii/S0950584920300616,CodeGRU: Context-aware deep learning with gated recurrent unit for source code modeling,Yu=Zhou: zhouyu@nuaa.edu.cn; Zhiqiu=Huang: zqhuang@nuaa.edu.cn; Yasir=Hussain: yaxirhuxxain@nuaa.edu.cn; Senzhang=Wang: szwang@nuaa.edu.cn,"Abstract
Context: Recently 
deep learning
 based 
Natural Language Processing
 (NLP) models have shown great potential in the modeling of 
source code
. However, a major limitation of these approaches is that they take 
source code
 as simple tokens of text and ignore its contextual, syntactical and structural dependencies.
Objective: In this work, we present CodeGRU, a 
gated recurrent unit
 based 
source code
 
language model
 that is capable of capturing source code’s contextual, syntactical and structural dependencies.
Method: We introduce a novel approach which can capture the 
source code
 context by leveraging the source code token types. Further, we adopt a novel approach which can learn variable size context by taking into account source code’s syntax, and structural information.
Results: We evaluate CodeGRU with real-world data set and it shows that CodeGRU outperforms the state-of-the-art language models and help reduce the vocabulary size up to 24.93%. Unlike previous works, we tested CodeGRU with an independent test set which suggests that our methodology does not requisite the source code comes from the same domain as 
training data
 while providing suggestions. We further evaluate CodeGRU with two 
software engineering
 applications: source code suggestion, and source code completion.
Conclusion: Our experiment confirms that the source code’s contextual information can be vital and can help improve the software language models. The extensive evaluation of CodeGRU shows that it outperforms the state-of-the-art models. The results further suggest that the proposed approach can help reduce the vocabulary size and is of practical use for software developers.",September 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The CodeGRU model presents advancements in capturing contextual information in source code, outperforming state-of-the-art models, and reducing vocabulary size, which can benefit software developers."
https://www.sciencedirect.com/science/article/pii/S0950584920300665,LTRWES: A new framework for security bug report detection,Yuan=Jiang: jiangyuan@hit.edu.cn; Pengcheng=Lu: pclu57@gmail.com; Xiaohong=Su: sxh@hit.edu.cn; Tiantian=Wang: sweetwtt@126.com,"Abstract
Context
: Security 
bug reports
 (SBRs) usually contain security-related vulnerabilities in software products, which could be exploited by malicious attackers. Hence, it is important to identify SBRs quickly and accurately among 
bug reports
 (BRs) that have been disclosed in 
bug tracking systems
. Although a few methods have been already proposed for the detection of SBRs, challenging issues still remain due to noisy samples, 
class imbalance
 and data scarcity.
Object
: This motivates us to reveal the potential challenges faced by the state-of-the-art SBRs prediction methods from the viewpoint of data filtering and representation. Furthermore, the purpose of this paper is also to provide a general framework and new solutions to solve these problems.
Method
: In this study, we propose a novel approach LTRWES that incorporates learning to rank and 
word embedding
 into the identification of SBRs. Unlike previous keyword-based approaches, LTRWES is a content-based data filtering and representation framework that has several 
desirable properties
 not shared in other methods. Firstly, it exploits ranking model to efficiently filter non-security bug reports (NSBRs) that have higher content similarity with respect to SBRs. Secondly, it applies 
word embedding
 technology to transform the rest of NSBRs, together with SBRs, into low-dimensional real-value vectors.
Result
: Experiment results on benchmark and large real-world datasets show that our proposed method outperforms the state-of-the-art method.
Conclusion
: Overall, the LTRWES is valid with high performance. It will help security engineers to identify SBRs from thousands of NSBRs more accurately than existing algorithms. Therefore, this will positively encourage the research and development of the content-based methods for security bug report detection.",August 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The proposed LTRWES method for identifying security bug reports could have a significant impact on early-stage ventures by helping them quickly and accurately detect vulnerabilities in their software products.
https://www.sciencedirect.com/science/article/pii/S0950584920300926,A large scale study on how developers discuss code smells and anti-pattern in Stack Exchange sites,Amjed=Tahir: a.tahir@massey.ac.nz,"Abstract
Context:
 In this paper, we investigate how developers discuss 
code smells
 and 
anti-patterns
 across three technical Stack Exchange sites. Understanding developers perceptions of these issues is important to inform and align future research efforts and direct tools vendors to design tailored tools that best suit developers. 
Method:
 we mined three Stack Exchange sites and used quantitative and qualitative methods to analyse more than 4000 posts that discuss code smells and anti-patterns.
Results:
 results showed that developers often asked their peers to smell their code, thus utilising those sites as an 
informal, crowd-based
 code smell/anti-pattern detector. The majority of questions (556) asked were focused on smells like Duplicated Code, 
Spaghetti Code
, God and Data Classes. In terms of languages, most of discussions centred around popular languages such as C
#
 (772 posts), JavaScript (720) and Java (699), however greater support is available for Java compared to other languages (especially 
modern languages
 such as Swift and Kotlin). We also found that developers often discuss the downsides of implementing specific 
design patterns
 and ‘flag’ them as potential anti-patterns to be avoided. Some well-defined smells and anti-patterns are discussed as potentially being acceptable practice in certain scenarios. In general, developers actively seek to consider 
trade-offs
 to decide whether to use a design pattern, an anti-pattern or not.
Conclusion:
 our results suggest that there is a need for: 1) more 
context and 
domain sensitive
 evaluations of code smells and anti-patterns, 2) better guidelines for making 
trade-offs
 when applying 
design patterns
 or eliminating smells/anti-patterns in industry, and 3) a unified, constantly updated, catalog of smells and anti-patterns. We conjecture that the 
crowd-based
 detection approach considers contextual factors and thus tend to be more trusted by developers than automated detection tools.",September 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study provides insights into how developers discuss code smells and anti-patterns and suggests the need for more context-sensitive evaluations and guidelines, which can inform future research and tool development."
https://www.sciencedirect.com/science/article/pii/S095058492030104X,Comparing manual and automated feature location in conceptual models: A Controlled experiment,Francisca=Pérez: mfperez@usj.es; Carlos=Cetina: ccetina@usj.es; Raúl=Lapeña: rlapena@usj.es; Jorge=Echeverría: jecheverria@usj.es,"Abstract
Context
Maintenance activities cannot be completed without locating the set of software artifacts that realize a particular feature of a software system. Manual Feature Location (FL) is widely used in industry, but it becomes challenging (time-consuming and error prone) in large software repositories. To reduce manual efforts, automated FL techniques have been proposed. Research efforts in FL tend to make comparisons between automated FL techniques, ignoring manual FL techniques. Moreover, existing research puts the focus on code, neglecting other artifacts such as models.
Objective
This paper aims to compare manual FL against automated FL in models to answer important questions about performance, productivity, and satisfaction of both treatments.
Method
We run an experiment for comparing manual and automated FL on a set of 18 subjects (5 experts and 13 non-experts) in the domain of our industrial partner, BSH, manufacturer of induction hobs for more than 15 years. We measure performance (recall, precision, and F-measure), productivity (ratio between F-measure and spent time), and satisfaction (perceived ease of use, perceived usefulness, and intention to use) of both treatments, and perform statistical tests to assess whether the obtained differences are significant.
Results
Regarding performance, manual FL significantly outperforms automated FL in precision and F-measure (up to 27.79% and 19.05%, respectively), whereas automated FL significantly outperforms manual FL in recall (up to 32.18%). Regarding productivity, manual FL obtains 3.43%/min, which improves automated FL significantly. Finally, there are no significant differences in satisfaction for both treatments.
Conclusions
The findings of our work can be leveraged to advance research to improve the results of manual and automated FL techniques. For instance, automated FL in industry faces issues such as low discrimination capacity. In addition, the obtained satisfaction results have implications for the usage and possible combination of manual, automated, and guided FL techniques.",September 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The comparison between manual and automated Feature Location techniques offers valuable insights into their performance, productivity, and satisfaction aspects, contributing to advancing research in this domain."
https://www.sciencedirect.com/science/article/pii/S0950584920300872,On an optimal analogy-based software effort estimation,Passakorn=Phannachitta: passakorn.p@cmu.ac.th,"Abstract
Context:
 An analogy-based software effort estimation technique estimates the required effort for a new software project based on the total effort used in completing past similar projects. In practice, offering high accuracy can be difficult for the technique when the new software project is not similar to any completed projects. In this case, the accuracy will rely heavily on a process called effort adaptation, where the level of difference between the new project and its most similar past projects is quantified and transformed to the difference in the effort. In the past, attempts to adapt to the effort used 
machine learning algorithms
; however, no algorithm was able to offer a significantly higher performance. On the contrary, only a simple heuristic such as scaling the effort by consulting the difference in software size was adopted.
Objective:
More recently, million-dollar prize data-science competitions have fostered the rapid development of more powerful 
machine learning
 algorithms, such as the 
Gradient boosting
 machine and 
Deep learning algorithm
. Therefore, this study revisits the comparison of software effort adaptors that are based on heuristics and 
machine learning algorithms
.
Method:
A systematic comparison of software effort estimators, which they all were fully optimized by Bayesian optimization technique, was carried out on 13 standard benchmark datasets. The comparison was supported by robust performance metrics and robust statistical test methods.
Conclusion:
The results suggest a novel strategy to construct a more accurate analogy-based estimator by adopting a combined effort adaptor. In particular, the analogy-based model that adapts to the effort by integrating the 
Gradient boosting
 machine algorithm and a traditional adaptation technique based on productivity adjustment has performed the best in the study. Particularly, this model significantly outperformed various state-of-the-art effort estimation techniques, including a current standard benchmark algorithmic-based technique, analogy-based techniques, and machine learning-based techniques.",September 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study revisits software effort estimation techniques using machine learning algorithms and heuristics, suggesting a novel strategy that significantly outperformed existing techniques, which can have practical implications for software projects."
https://www.sciencedirect.com/science/article/pii/S0950584920300938,ManQ: Many-objective optimization-based automatic query reduction for IR-based bug localization,Misoo=Kim: misoo12@skku.edu; Eunseok=Lee: leees@skku.edu,"Abstract
Context
An information retrieval-based bug localization (IRBL) method is proposed to localize buggy files using a 
bug report
 as a query. The performance of this method strongly depends on the quality of the query. However, these queries contain noise terms that hinder their use for IRBL. To improve the quality of a query, an automatic query reduction (AQR) technique that removes noise words from the query is needed.
Objective
Our objective is to develop an AQR method for IRBL. Most existing AQR techniques are based on single 
objective optimization
, which presents issues in terms of biased and limited performance. To solve these issues, it is necessary to find a subquery that comprehensively satisfies all of their objectives.
Method
We propose an AQR technique called ManQ, which is a many-objective optimization-based AQR method for IRBL. We design 15 objective functions to (1) maintain the query quality properties, (2) maintain the important terms, (3) maintain the initial information, and (4) minimize the query length. ManQ finds a final subquery that maximize the return values of these objective functions.
Results
The experimental results show that ManQ improves the quality of poor queries. We also show that if we select the best query among the candidates generated by ManQ, we can increase the number of improved queries by more than 53.4% of all queries.
Conclusion
ManQ improves the performance of IRBL by improving the quality of queries through a many-objective optimization approach.",September 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed AQR method for IRBL using many-objective optimization has the potential to significantly improve the quality of bug queries, which could be beneficial for early-stage ventures developing software products."
https://www.sciencedirect.com/science/article/pii/S2352673421000433,The governance of entrepreneurial community ventures: How do conflicting community interests influence opportunity exploitation?,Helen M.=Haugh: h.haugh@jbs.cam.ac.uk,"Abstract
Participatory governance is upheld as a fundamental organizing principle in community entrepreneurship. This paper brings new insights from a 
case study
 that investigated how governance structures, processes, and practices, and divergent community interests influence community venture opportunity exploitation. We find that while community stakeholder governance enables 
community participation
 and accountability, the interests of the majority triumph over the minority in determining opportunity exploitation. Adopting supplementary governance mechanisms of multistakeholder advisory committees and community engagement process reporting would enable minority interests to be acknowledged and communicated, and increase accountability by acknowledging conflicting views about opportunity exploitation.",November 2021,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"The insights on participatory governance in community entrepreneurship are valuable, but the practical implications for European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920300690,An experimental and practical study on the equivalent mutant connection: An evolutionary approach,Pedro=Delgado-Pérez: pedro.delgado@uca.es,"Abstract
Context
Mutation testing is considered to be a powerful approach to assess and improve the quality of test suites. However, this technique is expensive mainly because some mutants are semantically equivalent to the original program; in general, equivalent mutants require manual revision to differentiate them from useful ones, which is known as the Equivalent Mutant Problem (EMP).
Objective
In the past, several authors have proposed different techniques to individually identify certain equivalent mutants, with notable advances in the last years. In our work, by contrast, we address the EMP from a global perspective. Namely, we wonder the extent to which equivalent mutants are connected (i.e., whether they share 
mutation operators
 and code areas) as well as the extent to which the knowledge of that connection can benefit the mutant selection process. Such a study could allow going beyond the implicit limit in the traditional individual detection of equivalent mutants.
Method
We use an 
evolutionary algorithm
 to select the mutants, an approach called Evolutionary Mutation Testing (EMT). We propose a new derived version, 
Equivalence-Aware EMT
 (EA-EMT), which penalizes the fitness of known equivalent mutants so that they do not transfer their features to the next generations of mutants.
Results
In our experiments applying EMT to well-known C++ programs, we found that (i) equivalent mutants often originate from other equivalent mutants (over 60% on average); (ii) EA-EMT’s approach of penalizing known equivalent mutants provides better results than the original EMT in most of the cases (notably, the more equivalent mutants are detected, the better); and (iii) we can combine EA-EMT with Trivial Compiler Equivalence as a way to automatically identify equivalent mutants in a real situation, reaching a more stable version of EMT.
Conclusions
This novel approach opens the way for improvement in other related areas that deal with equivalent versions.",August 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The Evolutionary Mutation Testing approach addresses the Equivalent Mutant Problem from a global perspective, showing promising results that could benefit startups in improving test suites."
https://www.sciencedirect.com/science/article/pii/S0950584920300501,Automatic block dimensioning on GPU-accelerated programs through particle swarm optimization,Claudio M.N.A.=Pereira: cmnap@ien.gov.br,"Abstract
Context
Nowadays, the use of GPU to improve performance of computationally expensive systems are widely explored. On GPU-accelerated programs, performance is related to the partition of the problem into blocks of threads in such a way that the parallel tasks to be executed better fit the GPU architecture. Although there exists some general guidelines to help defining 
block dimensions
, finding the optimum partition is still a complex and problem dependent task. In this work, it has been investigated the use of 
particle swarm optimization
 (PSO) to optimize blocks dimensions aiming to minimize 
programs execution time
. The approach was evaluated on a GPU-accelerated wind field calculation program, in which block dimensioning was based on literature guidelines and empirical adjusts. Before PSO optimization, the program was about 25 times faster than the sequential program. After applying PSO, speedup increased to about 60 times. Unexpected optimized configurations were observed, ratifying that finding optimum dimensioning is a complex task. So the use of a 
robust optimization
 tool, such as PSO, demonstrated to be very profitable, allowing automatic optimization of blocks dimensions without necessity of a 
priori knowledge
 about problem, programs peculiarities and GPU architecture.
Objective
Improve speedup of GPU-accelerated programs by automatic defining optimized 
block dimensions
 using PSO.
Method
A GPU-accelerated wind field calculation problem has been focused. A PSO was interfaced to the program in order to find the block dimensions that leads to a minimum 
execution time
. Results were compared to literature results.
Results
The speedup obtained with the proposed approach is more than 2 times the original speedup.
Conclusion
PSO, demonstrated to be very profitable, allowing automatic optimization of blocks dimensions without necessity of a 
priori knowledge
 about problem/programs peculiarities and/or GPU architecture.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The use of PSO to optimize blocks dimensions for GPU-accelerated programs demonstrates significant speedup improvements, offering valuable practical implications for startups working on computationally expensive systems."
https://www.sciencedirect.com/science/article/pii/S0950584920300458,Search-based fault localisation: A systematic mapping study,Silvia R.=Vergilio: silvia@inf.ufpr.br; Plinio S.=Leitao-Junior: plinio@inf.ufg.br; Diogo M.=Freitas: diogom42@gmail.com; Celso G.=Camilo-Junior: celso@inf.ufg.br; Rachel=Harrison: rachel.harrison@brookes.ac.uk,"Abstract
Context
Software 
Fault Localisation
 (FL) refers to finding faulty software elements related to failures produced as a result of test case execution. This is a laborious and time consuming task. To allow FL automation search-based algorithms have been successfully applied in the field of Search-Based Fault Localisation (SBFL). However, there is no study mapping the SBFL field to the best of our knowledge and we believe that such a map is important to promote new advances in this field.
Objective
To present the results of a mapping study on SBFL, by characterising the proposed methods, identifying sources of used information, adopted evaluation functions, applied algorithms and elements regarding reported experiments.
Method
Our mapping followed a defined process and a search protocol. The conducted analysis considers different dimensions and categories related to the main characteristics of 
SBFL methods
.
Results
All methods are grounded on the coverage spectra category. Overall the methods search for solutions related to suspiciousness formulae to identify possible faulty code elements. Most studies use 
evolutionary algorithms
, mainly 
Genetic Programming
, by using a single-objective function. There is little investigation of real-and-multiple-fault scenarios, and the subjects are mostly written in C and Java. No consensus was observed on how to apply the 
evaluation metrics
.
Conclusions
Search-based fault localisation has seen a rise in interest in the past few years and the number of studies has been growing. We identified some research opportunities such as exploring new sources of fault data, exploring multi-objective algorithms, analysing benchmarks according to some classes of faults, as well as, the use of a unique definition for evaluation measures.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The mapping study on Search-Based Fault Localisation provides insights into research opportunities, but the direct practical value for European early-stage ventures may be limited at this point."
https://www.sciencedirect.com/science/article/pii/S0950584920300471,Testing and verification of neural-network-based safety-critical control software: A systematic literature review,Jingyue=Li: jingyue.li@ntnu.no; Jin=Zhang: jin.zhang@ntnu.no,"Abstract
Context:
 
Neural Network
 (NN) algorithms have been successfully adopted in a number of Safety-Critical Cyber-Physical Systems (SCCPSs). Testing and Verification (T&V) of NN-based control software in safety-critical domains are gaining interest and attention from both 
software engineering
 and safety engineering researchers and practitioners.
Objective:
 With the increase in studies on the T&V of NN-based control software in safety-critical domains, it is important to systematically review the state-of-the-art T&V methodologies, to classify approaches and tools that are invented, and to identify challenges and gaps for future studies.
Method:
 By searching the six most relevant digital libraries, we retrieved 950 papers on the T&V of NN-based Safety-Critical Control Software (SCCS). Then we filtered the papers based on the predefined inclusion and exclusion criteria and applied snowballing to identify new relevant papers.
Results:
 To reach our result, we selected 83 primary papers published between 2011 and 2018, applied the thematic analysis approach for analyzing the data extracted from the selected papers, presented the classification of approaches, and identified challenges.
Conclusion:
 The approaches were categorized into five high-order themes, namely, assuring robustness of NNs, improving the failure resilience of NNs, measuring and ensuring test completeness, assuring safety properties of NN-based control software, and improving the 
interpretability
 of NNs. From the industry perspective, improving the interpretability of NNs is a crucial need in safety-critical applications. We also investigated nine safety integrity properties within four major safety lifecycle phases to investigate the achievement level of T&V goals in IEC 61508-3. Results show that correctness, completeness, freedom from intrinsic faults, and 
fault tolerance
 have drawn most attention from the research community. However, little effort has been invested in achieving repeatability, and no reviewed study focused on precisely defined testing configuration or defense against 
common cause failure
.",July 2020,"Software testing and verification, Neural network, Safety-critical control software, Systematic literature review",Information and Software Technology,2025-03-18T00:00:00,7.0,"The study on testing and verification of NN-based control software in safety-critical domains addresses important challenges and gaps in the industry, impacting startups working in those domains."
https://www.sciencedirect.com/science/article/pii/S2352673421000469,Does gender matter? Evidence from crowdfunding,Ramy=Elitzur: ramy.elitzur@rotman.utoronto.ca; Eliran=Solodoha: solodoha@post.bgu.ac.il,"Abstract
The lack of resources and support for female entrepreneurs and their ventures lowers their chances of success and ultimately leads to the underrepresentation of female led ventures in the economy. Thus, to remedy this problem, it is crucial for female entrepreneurs to attract potential investors. The latter may use in their decision-making process cues such as the number of supporters, which provides social validation of the ventures. To test this, we analyze 2275 reward-based crowdfunding projects to investigate the effects of female entrepreneurs’ presence, and the consequences of social validation (i.e., number of supporters), on their crowdfunding success.",November 2021,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"While the focus on female entrepreneurs and crowdfunding is important, the direct impact on European early-stage ventures may not be significant."
https://www.sciencedirect.com/science/article/pii/S095058491930240X,Management of quality requirements in agile and rapid software development: A systematic mapping study,Woubshet=Behutiye: woubshet.behutiye@oulu.fi,"Abstract
Context
Quality requirements (QRs) describe the desired 
quality of software
, and they play an important role in the success of software projects. In 
agile software development
 (ASD), QRs are often ill-defined and not well addressed due to the focus on quickly delivering functionality. Rapid software development (RSD) approaches (e.g., continuous delivery and continuous deployment), which shorten delivery times, are more prone to neglect QRs. Despite the significance of QRs in both ASD and RSD, there is limited synthesized knowledge on their management in those approaches.
Objective
This study aims to synthesize state-of-the-art knowledge about QR management in ASD and RSD, focusing on three aspects: bibliometric, strategies, and challenges.
Research method
Using a 
systematic mapping study
 with a snowballing search strategy, we identified and structured the literature on QR management in ASD and RSD.
Results
We found 156 primary studies: 106 are empirical studies, 16 are experience reports, and 34 are theoretical studies. Security and performance were the most commonly reported QR types. We identified various QR management strategies: 74 practices, 43 methods, 13 models, 12 frameworks, 11 advices, 10 tools, and 7 guidelines. Additionally, we identified 18 categories and 4 non-recurring challenges of managing QRs. The limited ability of ASD to handle QRs, time constraints due to short iteration cycles, limitations regarding the testing of QRs and neglect of QRs were the top categories of challenges.
Conclusion
Management of QRs is significant in ASD and is becoming important in RSD. This study identified research gaps, such as the need for more tools and guidelines, lightweight QR management strategies that fit short iteration cycles, investigations of the link between QRs challenges and technical debt, and extension of empirical validation of existing strategies to a wider context. It also synthesizes QR management strategies and challenges, which may be useful for practitioners.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The synthesis of knowledge on quality requirement management in agile and rapid software development provides valuable insights for startups focusing on software projects, although it may not directly impact early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300422,Orientation-based Ant colony algorithm for synthesizing the test scenarios in UML activity diagram,Vinay=Arora: vinay.arora@thapar.edu,"Abstract
Context
The model-based analysis is preferred over the code-based analysis as it speeds up the development process and directs the guiding effort. In the software industry, the Unified Modeling Language (UML) is a set standard followed by the developers as well as system analysts to extract all attainable paths of controls, usually known as scenarios under an activity diagram.
Objective
In this manuscript, a bio-inspired methodology has been applied on concurrent sub-part of a UML activity diagram to fetch various feasible test scenarios.
Method
The food search pattern of an ant has been taken as a base heuristic. An orientation factor has been introduced in the existing ant colony optimization algorithm. Experiments have been performed using three student projects, five synthetic models and an openly available model repository named LINDHOLMEN data-set at Github.
Results
The statistical analysis has validated the results obtained through various existing approaches and the proposed approach. Experimentation shows that the orientation-based ant colony algorithm has produced better results as compared to the existing Genetic Algorithm (GA) and Ant Colony Optimization (ACO) on the basis of feasible test scenarios generated.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The bio-inspired methodology for extracting test scenarios from UML activity diagrams offers an interesting approach that could potentially benefit startups in the software industry.
https://www.sciencedirect.com/science/article/pii/S0950584920300392,BVDetector: A program slice-based binary code vulnerability intelligent detection system,Zhen=Li: lizhen@hbu.edu.cn,"Abstract
Context
Software 
vulnerability detection
 is essential to ensure cybersecurity. Currently, most software is published in binary form, thus researchers can only detect vulnerabilities in these software by analysing binary programs. Although existing research approaches have made a substantial contribution to binary 
vulnerability detection
, there are still many deficiencies, such as high false positive rate, detection with 
coarse granularity
, and dependence on expert experience.
Objective
The goal of this study is to perform fine-grained intelligent detection on the vulnerabilities in binary programs. This leads us to propose a fine-grained representation of binary programs and introduce 
deep learning techniques
 to intelligently detect the vulnerabilities.
Method
We use program slices of library/API function calls to represent binary programs. Additionally, we design and construct a Binary 
Gated Recurrent Unit
 (BGRU) network model to intelligently learn 
vulnerability patterns
 and automatically detect vulnerabilities in binary programs.
Results
This approach yields the design and implementation of a program slice-based binary code vulnerability intelligent detection system called BVDetector. We show that BVDetector can effectively detect vulnerabilities related to library/API function calls in binary programs, which reduces the false positive rate and 
false negative
 rate of vulnerability detection.
Conclusion
This paper proposes a program slice-based binary code vulnerability intelligent detection system called BVDetector. The experimental results show that BVDetector can effectively reduce the 
false negative
 rate and false positive rate of binary vulnerability detection.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The fine-grained intelligent detection system for binary vulnerabilities using deep learning techniques addresses crucial cybersecurity concerns, providing practical value to startups working on software security."
https://www.sciencedirect.com/science/article/pii/S0950584920300628,Deep learning model for end-to-end approximation of COSMIC functional size based on use-case names,Mirosław=Ochodek: mochodek@cs.put.poznan.pl; Sylwia=Kopczyńska: sylwia.kopczynska@cs.put.poznan.pl; Miroslaw=Staron: miroslaw.staron@cse.gu.se,"Abstract
Context
COSMIC is a widely used functional size measurement (FSM) method that supports software development effort estimation. The FSM methods measure functional product size based on functional requirements. Unfortunately, when the description of the product’s functionality is often abstract or incomplete, the size of the product can only be approximated since the object to be measured is not yet fully described. Also, the measurement performed by human-experts can be time-consuming, therefore, it is worth considering automating it.
Objective
Our objective is to design a new prediction model capable of approximating COSMIC-size of use cases based only on their names that is easier to train and more accurate than existing techniques.
Method
Several neural-network architectures are investigated to build a COSMIC size 
approximation
 model. The accuracy of models is evaluated in a simulation study on the dataset of 437 use cases from 27 software development projects in the 
Management Information Systems
 (MIS) domain. The accuracy of the models is compared with the Average Use-Case 
approximation
 (AUC), and two recently proposed two-step models—Average Use-Case Goal-aware Approximation (AUCG) and 
Bayesian Network
 Use-Case Goal AproxImatioN (BN-UCGAIN).
Results
The best prediction accuracy was obtained for a 
convolutional neural network
 using a word-embedding model trained on Wikipedia+Gigaworld. The accuracy of the model outperformed the baseline AUC model by ca. 20%, and the two-step models by ca. 5–7%. In the worst case, the improvement in the prediction accuracy is visible after estimating 10 use cases.
Conclusions
The proposed 
deep learning
 model can be used to automatically approximate COSMIC size of 
software applications
 for which the requirements are documented in the form of use cases (or at least in the form of use-case names). The advantage of the model is that it does not require collecting 
historical data
 other than COSMIC size and names of use cases.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The development of a deep learning model to approximate COSMIC size of software applications based on use-case names has the potential to streamline software development processes for startups, although the impact may vary based on the domain."
https://www.sciencedirect.com/science/article/pii/S2352673421000585,Self-employment through the COVID-19 pandemic: An analysis of linked monthly CPS data,Samuel C.H.=Mindes: smindes@iastate.edu,"Abstract
The COVID-19 pandemic that began in the United States in March of 2020 had a profound adverse effect on the economy. In particular, the pandemic had a harsh impact on women, minorities, and self-employed individuals. However, research on why the pandemic hit some groups harder is in its nascent stages. We contribute to the growing body of knowledge by comparatively analyzing the inability to work due to the pandemic in the wage and self-employment sectors. We utilize data from the Current Population Survey from May 2020 to May 2021 to investigate the effect of individual, business, and geographic characteristics on the probability of work interruption in each sector. We find that self-employers were much harder hit but fared better than wage workers in several of the harder-hit sectors and when they had incorporated businesses. We also find that women, non-Whites, and Hispanics were more adversely affected in both sectors.",November 2021,"Self-employment, Entrepreneurship, COVID-19 pandemic, Minorities, Women",Business Venturing Insights,2025-03-21T00:00:00,5.0,"While the research on the impact of the COVID-19 pandemic on certain groups is important, the focus on wage and self-employment sectors may not have direct practical value for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300604,Assessing the effectiveness of approximate functional sizing approaches for effort estimation,Filomena=Ferrucci: fferrucci@unisa.it; Carmine=Gravino: gravino@unisa.it; Federica=Sarro: f.sarro@ucl.ac.uk; Sergio=Di Martino: sergio.dimartino@unina.it,"Abstract
Context
: Functional Size Measurement (FSM) methods, like Function Points Analysis (FPA) or 
COSMIC
, are well-established approaches to estimate software size. Several 
approximations
 of these methods have been recently proposed as they require less time/information to be applied, however their effectiveness for effort prediction is not known.
Objective
: The effectiveness of approximated functional size measures for estimating the development effort is a key open question, since an approximate sizing approach may miss to capture factors affecting the effort. Therefore, we empirically investigated the use of approximate FPA and 
COSMIC
 sizing approaches, also compared with their standard versions, for effort estimation.
Method
: We measured 25 industrial software projects realised by a single company by using FPA, COSMIC, two approximate sizing approaches proposed by 
IFPUG
 for FPA (i.e. High Level and Indicative FPA), and three approximate sizing approaches proposed by the 
COSMIC organisation
 for COSMIC (i.e. Average Functional Process, Fixed Size Classification, and Equal Size Band). Then we investigated the quality of the regression models built using the obtained measures to estimate the development effort.
Results
: Models based on High Level FPA are effective, providing a prediction accuracy comparable to the one of the original FPA, while those based on the Indicative FPA method show poor estimation accuracy. Models based on COSMIC approximate 
sizing methods
 are also quite effective, in particular those based on the Equal Size Band approximation provided an accuracy similar to the one of standard COSMIC.
Conclusion
: Project managers should be aware that predictions based on High Level FPA and standard FPA can be similar, making this approximation very interesting and effective, while Indicative FPA should be avoided. COSMIC 
approximations
 can also provide accurate effort estimates, nevertheless, the Fixed Size Classification and Equal Size Band approaches introduce subjectivity in the measurement.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides practical insights into the effectiveness of approximated functional size measures for effort estimation in software projects, which can be valuable for startups in optimizing resource allocation."
https://www.sciencedirect.com/science/article/pii/S0950584920300495,Analyzing and documenting the systematic review results of software testing ontologies,Guido=Tebes: guido.tebes92@gmail.com; Denis=Peppino: denispeppino92@gmail.com; Pablo=Becker: beckerp@ing.unlpam.edu.ar; Gerardo=Matturro: matturro@ort.edu.uy; Martin=Solari: martin.solari@ort.edu.uy; Luis=Olsina: olsinal@ing.unlpam.edu.ar,"Abstract
Context
Software testing is a complex area since it has a large number of specific methods, processes and strategies, involving a lot of domain concepts. Therefore, it would be valuable to have a conceptualized software testing ontology that explicitly and unambiguously defines the concepts. Consequently, it is important to find out the available evidence in the literature on primary studies for software testing ontologies. In particular, we are looking for research that has a rich ontological coverage that includes Non-Functional Requirements (NFRs) and Functional Requirements (FRs) concepts in conjunction with static and dynamic testing concepts, which can be used in method and process specifications for a family of testing strategies.
Objective
The main goal for this secondary study is to identify, evaluate and synthesize the available primary studies on conceptualized software testing ontologies.
Method
To conduct this study, we use the Systematic Literature Review (SLR) approach, which follows our enhanced SLR process. We set three research questions. Additionally, to quantitatively evaluate the quality of the selected conceptualized ontologies, we designed a NFRs tree and its associated metrics and indicators.
Results
We obtained 12 primary studies documenting conceptualized testing ontologies by using three different 
retrieval methods
. In general, we noted that most of them have a lack of NFRs and static testing terminological coverage. Finally, we observe that none of them is directly linked with FRs and NFRs conceptual components.
Conclusion
A general benefit of having the suitable software testing ontology is to minimize the current heterogeneity, ambiguity and incompleteness problems in terms, properties and relationships. We have confirmed that exists heterogeneity, ambiguity, and incompleteness for concepts dealing with testing artifacts, roles, activities, and methods. Moreover, we did not find the suitable ontology for our aim since none of the conceptualized ontologies are directly linked with NFRs and FRs components.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the study on software testing ontologies is important for conceptual clarity, it may have limited immediate impact on early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S095058492030063X,Demystifying the adoption of behavior-driven development in open source projects,Massimiliano=Di Penta: dipenta@unisannio.it,"Abstract
Context:
Behavior-Driven Development (BDD) features the capability, through appropriate domain-specific languages, of specifying acceptance test cases and making them executable. The availability of frameworks such as Cucumber or RSpec makes the application of BDD possible in practice. However, it is unclear to what extent developers use such frameworks, and whether they use them for actually performing BDD, or, instead, for other purposes such as unit testing. 
Objective:
In this paper, we conduct an empirical investigation about the use of BDD tools in open source, and how, when a BDD tool is in place, BDD specifications co-evolve with source code. 
Method:
Our investigation includes three different phases: (i) a large-scale analysis to understand the extent to which BDD frameworks are used in 50,000 popular open-source projects written in five programming languages; (ii) a study on the co-evolution of scenarios, fixtures and production code in a sample of 20 Ruby projects, through the Granger’s causality test, and (iii) a survey with 31 developers to understand how they use BDD frameworks. 
Results:
Results of the study indicate that  ≃  27% of the sampled projects use BDD frameworks, with a prevalence in Ruby projects (68%). In about 37% of the cases, we found a co-evolution between scenarios/fixtures and production code. Specifically, changes to scenarios and fixtures often happen together or after changes to source code. Moreover, survey respondents indicate that, while they understand the intended purpose of BDD frameworks, most of them write tests while/after coding rather than strictly applying BDD. 
Conclusions:
Even if the BDD frameworks usage is widespread among 
open source projects
, in many cases they are used for different purposes such as unit testing activities. This mainly happens because developers felt BDD remains quite effort-prone, and its application goes beyond the simple adoption of a BDD framework.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The investigation on the use of BDD tools in open source projects provides insights into real-world practices, which can be beneficial for startups in understanding industry trends."
https://www.sciencedirect.com/science/article/pii/S0950584920300598,An empirical comparison of predictive models for web page performance,Raghu=Ramakrishnan: raghuramakrishnan71@gmail.com,"Abstract
Context
The quality of 
user experience
 is the cornerstone of any organization’s successful digital transformation journey. Web pages are the main touchpoint for users to access services in a digital mode. Web page performance is a key determinant of the quality of 
user experience
. The 
negative impact
 of poor web page performance on the productivity, profits, and brand value of an organization is well-recognized. The use of realistic prediction models for predicting page load time at the early stages of development can help minimize the effort and cost arising out of fixing performance defects late in the lifecycle.
Objective
We present a comprehensive evaluation of models based on 18 widely used 
machine learning techniques
 on their capability to predict page load times. The models use only those metrics which relate to the form and structure of a page because such metrics are easy to ascertain during the early stages with minimal effort.
Method
The 
machine learning techniques
 are trained on more than 8,700 pages from HTTP Archive data, a database of web performance information widely used to conduct web performance research. The trained models are then validated using the 10-fold cross-validation method and accuracy measures like the 
Pearson
 correlation coefficient (r), 
Root Mean Square Error
 (RMSE), and Normalized 
Root Mean Square Error
 (NRMSE) are reported.
Results
Radial Basis Function
 regression and 
Random Forest
 outperform all other techniques. The value of r ranges from 0.69-0.92, indicating a high correlation between the observed and 
predicted values
. The NRMSE varies between 0.11-0.16, implying that RMSE is less than 16% of the range of actual value. The RMSE improves by 41%-54% compared to the best baseline prediction model.
Conclusion
It is possible to build realistic prediction models using 
machine learning techniques
 that can be used by practitioners during the early stages of development with minimal effort.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The evaluation of machine learning techniques for predicting web page load times is highly relevant for startups aiming to optimize user experience and performance, providing practical tools for early-stage development."
https://www.sciencedirect.com/science/article/pii/S0950584920300483,State identification sequences from the splitting tree,Michal=Soucha: michal.soucha@gmail.com; Kirill=Bogdanov: k.bogdanov@sheffield.ac.uk,"Abstract
Context:
 Software testing based on finite-state machines.
Objective:
Improving the performance of existing 
testing methods
 by construction of more efficient separating sequences, so that states entered by a system under test can be identified in a much shorter span of time.
Method:
 This paper proposes an efficient way to construct separating sequences for subsets of states for any deterministic finite-state machine. It extends an existing algorithm that builds an adaptive distinguishing sequence (ADS) from a splitting tree to machines that do not possess an ADS. Our extension to this 
construction algorithm
 allows one not only to construct a separating sequence for any subset of states but also form sets of separating sequences, such as harmonized state identifiers (HSI) and incomplete adaptive distinguishing sequences, that are used by efficient testing and learning algorithms.
Results:
 The experiments confirm that the length and number of test sequences produced by 
testing methods
 that use HSIs constructed by our extension is significantly improved.
Conclusion:
By constructing more efficient separating sequences the performance of existing test methods significantly improves.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposal of more efficient separating sequences for finite-state machines can greatly benefit startups by improving testing methods and reducing the time needed to identify system states, enhancing product development efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584919302137,Automatic prediction of the severity of bugs using stack traces and categorical features,Korosh Koochekian=Sabor: k_kooche@ece.concordia.ca; Mohammad=Hamdaqa: mhamdaqa@ru.is; Abdelwahab=Hamou-Lhadj: abdelw@ece.concordia.ca,"Abstract
Context
The severity of a bug is often used as an indicator of how a bug negatively affects system functionality. It is used by developers to prioritize bugs which need to be fixed. The problem is that, for various reasons, bug submitters often enter the incorrect 
severity level
, delaying the bug resolution process. Techniques that can automatically predict the severity of a bug can significantly reduce the bug triaging overhead. In our previous work, we showed that the accuracy of description-based severity prediction techniques could be significantly improved by using stack traces as a source of information.
Objective
In this study, we expand our previous work by exploring the effect of using categorical features, in addition to stack traces, to predict the severity of bugs. These categorical features include faulty product, faulty component, and operating system. We experimented with other features and observed that they do not improve the severity prediction accuracy. A Software system is composed of many products; each has a set of components. Components interact with each to provide the functionality of the product. The operating 
system field
 refers to the operating system on which the software was running on during the crash.
Method
The proposed approach uses a 
linear combination
 of stack trace and categorical features similarity to predict the severity. We adopted a cost sensitive K Nearest Neighbor approach to overcome the unbalance label distribution problem and improve the classifier accuracy.
Results
Our experiments on 
bug reports
 of Eclipse submitted between 2001 and 2015 and Gnome submitted between 1999 and 2015 show that the accuracy of our severity prediction approach can be improved from 5% to 20% by considering categorical features, in addition to stack traces.
Conclusion
The accuracy of predicting the severity of bugs is higher when combining stack traces and three categorical features, product, component, and operating system.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study addresses a practical issue in bug triaging for software development, showing significant improvement in prediction accuracy, which can benefit early-stage ventures and startups by reducing bug resolution time and improving system functionality."
https://www.sciencedirect.com/science/article/pii/S0950584919302332,MAESTRO: Automated test generation framework for high test coverage and reduced human effort in automotive industry,Dongju=Lee: dongju.lee@mobis.co.kr; Junki=Baek: jk.baek@mobis.co.kr; Moonzoo=Kim: moonzoo@cs.kaist.ac.kr,"Abstract
Context
The importance of automotive software has been rapidly increasing because software controls many components of motor vehicles such as smart-key system, tire pressure 
monitoring system
, and 
advanced driver assistance system
. Consequently, the automotive industry spends a large amount of human effort to test automotive software and is interested in automated testing techniques to ensure high-quality automotive software with reduced human effort.
Objective
Applying automated test generation techniques to automotive software is technically challenging because of 
false alarms
 caused by imprecise test drivers/stubs and lack of tool supports for symbolic analysis of bit-fields and 
function pointers
 in C. To address such challenges, we have developed an automated testing framework MAESTRO.
Method
MAESTRO automatically builds a test driver and stubs for a target task (i.e., a software unit consisting of target functions). Then, it generates test inputs to a target task with the test driver and stubs by applying concolic testing and fuzzing together in an adaptive way. In addition, MAESTRO transforms a target program that uses bit-fields into a semantically equivalent one that does not use bit-fields. Also, MAESTRO supports symbolic 
function pointers
 by identifying the candidate functions of a symbolic function pointer through 
static analysis
.
Results
MAESTRO achieved 94.2% branch coverage and 82.3% MC/DC coverage on the four target modules (238 KLOC) developed by Hyundai Mobis. Furthermore, it significantly reduced the cost of coverage testing by reducing the manual effort for coverage testing by 58.8%.
Conclusion
By applying automated testing techniques, MAESTRO can achieve high test coverage for automotive software with significantly reduced manual testing effort.",July 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The development of an automated testing framework for automotive software can greatly benefit startups by reducing manual testing efforts and achieving high test coverage, leading to higher quality software products."
https://www.sciencedirect.com/science/article/pii/S0950584920300227,Test coverage criteria for software product line testing: Systematic literature review,Jihyun=Lee: jihyun30@jbnu.ac.kr; Sungwon=Kang: sungwon.kang@kaist.ac.kr; Pilsu=Jung: psjung@kaist.ac.kr,"Abstract
Context
In software product line testing (SPLT), test coverage criterion is an important concept, as it provides a means of measuring the extent to which domain testing has been performed and redundant application testing can be avoided based on the test coverage level achieved in domain testing. However, no previous literature reviews on SPLT have addressed test coverage criterion in SPLT.
Objective
The objectives of this paper are as follows: (1) to clarify the notions of test basis and test coverage criterion for SPLT; (2) to identify the test coverage criteria currently used for SPLT; (3) to investigate how various SPLT aspects, such as the 
SPLT method
, variability implementation mechanism, and variability management approach, affect the choice of test coverage criterion for SPLT; and (4) to analyze the limitations of test coverage criteria currently used for SPLT.
Method
This paper conducts a systematic review of test coverage criteria in SPLT with 78 selected studies.
Results
We have several findings that can guide the future research on SPLT. One important finding is that choice of test coverage criterion in SPLT is independent from variability implementation mechanism, variability management, SPL approach, and binding time but is dependent on the variability representation used in development artifacts. Another that is easily overlooked is that SPL test coverage criteria with the same test coverage criterion names of single system testing neither adequately convey what should be covered by the test methods applying them, nor can they be more generally regarded as extensions or generalizations for SPLT of their corresponding test coverage criteria of single system testing.
Conclusion
This study showed that SPL test coverage criteria should be defined or redefined so that they can clearly deliver the target properties to be satisfied by SPLT.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the systematic review on software product line testing is important, it may have limited immediate practical impact on early-stage ventures or startups in comparison to the other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920300379,A systematic review of unsupervised learning techniques for software defect prediction,Martin=Shepperd: martin.shepperd@brunel.ac.uk,"Abstract
Background
Unsupervised 
machine learners
 have been increasingly applied to software 
defect prediction
. It is an approach that may be valuable for software practitioners because it reduces the need for labeled 
training data
.
Objective
Investigate the use and performance of 
unsupervised learning
 techniques in 
software defect
 prediction.
Method
We conducted a systematic literature review that identified 49 studies containing 2456 individual experimental results, which satisfied our 
inclusion criteria
 published between January 2000 and March 2018. In order to compare prediction performance across these studies in a consistent way, we (re-)computed the 
confusion matrices
 and employed the Matthews 
Correlation Coefficient
 (MCC) as our main performance measure.
Results
Our meta-analysis shows that unsupervised models are comparable with supervised models for both within-project and cross-project prediction. Among the 14 families of unsupervised model, Fuzzy CMeans (FCM) and Fuzzy SOMs (FSOMs) perform best. In addition, where we were able to check, we found that almost 11% (262/2456) of published results (contained in 16 papers) were internally inconsistent and a further 33% (823/2456) provided insufficient details for us to check.
Conclusion
Although many factors impact the performance of a classifier, e.g., dataset characteristics, broadly speaking, unsupervised classifiers do not seem to perform worse than the supervised classifiers in our review. However, we note a worrying prevalence of (i) demonstrably erroneous experimental results, (ii) undemanding benchmarks and (iii) incomplete reporting. We therefore encourage researchers to be comprehensive in their reporting.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The investigation on unsupervised learning techniques in software defect prediction is relevant and could be beneficial for startups in improving software quality, although the impact may be more indirect compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919302484,Software trustworthiness evaluation model based on a behaviour trajectory matrix,Yuhui=Guo: tjf@hbu.edu.cn,"Abstract
Context
Software trustworthiness is a highly important 
research topic
. 
Trustworthiness evaluation
 based on factors that affect software behaviour is conducted mainly according to the influence degrees of these factors on the software behaviour to evaluate trustworthiness. As a result, minimization of the interference of human factors is considered.
Objective
In this study, to ensure the objectivity of evaluating the trustworthiness of software behaviour, a software trustworthiness evaluation model based on a behaviour trajectory matrix, namely, BTBM-TM was proposed.
Method
Checkpoints were set up in the trajectory of the software behaviour, and binary code was introduced to express the software behaviour trajectory tree. The scenario information of the checkpoints was acquired, and used to construct behaviour trajectory matrices, which were used to represent the behaviour trajectory. The behaviour trajectory matrices were transformed into grayscale images, which were used to train the 
deep residual network
 (ResNet) to classify the software behaviour. The trained 
deep residual network
 was used to categorize the current software behaviour, and the 
cosine similarity
 algorithm was used to calculate the deviation degree of the software behaviour trajectory; to perform a dual evaluation of the trustworthiness of software behaviour.
Results
The behaviour trajectory information of the Model class of 300 cycles was used to evaluate the trustworthiness of the mine-sweeping game. The trustworthiness evaluation results of the software behaviour of the scheme proposed in this paper (BTBM-TM) were compared with those of the schemes from references [6] and [10]. The accuracies of the schemes from [6] and [10] are lower than that of the BTBM-TM scheme.
Conclusions
The trajectory of software behaviour is represented by a matrix and converted into a grayscale image, whose 
processing method
 is used to evaluate the trustworthiness of software behaviour more objectively and accurately.",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed software trustworthiness evaluation model based on behaviour trajectory matrix can contribute to enhancing the reliability of software products, which could be beneficial for startups seeking to build trust with their users."
https://www.sciencedirect.com/science/article/pii/S0950584920300215,Software architectures of the convergence of cloud computing and the Internet of Things: A systematic literature review,Ahmad=Banijamali: ahmad.banijamali@oulu.fi,"Abstract
Context
Over the last few years, there has been an increasing interest in the convergence of 
cloud computing
 and the 
Internet of Things
 (IoT). Although software systems in this domain have attracted researchers to develop a large body of knowledge on 
software architecture designs
, there is no 
systematic analysis
 of this knowledge.
Objective
This study aims to identify and synthesise state-of-the-art 
architectural elements
 including the 
design patterns
, styles, views, 
quality attributes
, and evaluation methodologies in the convergence of 
cloud computing
 and IoT.
Method
We used systematic literature review (SLR) methodology for a detailed analysis of 82 primary studies of a total of 1618 studies.
Results
We extracted six 
architectural design
 patterns in this domain; among them, edge connectivity patterns stand out as the most popular choice. The service-oriented architecture is the most frequently applied style in this context. Among all applicable 
quality attributes
, scalability, timeliness, and security were the most investigated quality attributes. In addition, we included nine cross analyses to address the relationship between 
architectural patterns
, styles, views, and evaluation methodologies with respect to different quality attributes and 
application areas
.
Conclusions
Our findings indicate that research on software architectures in this domain is increasing. Although few studies were found in which industrial evaluations were presented, industry requires more scientific and empirically validated design frameworks to guide 
software engineering
 in this domain. This work provides an overview of the field while identifying areas for future research.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides valuable insights into architectural elements in the convergence of cloud computing and IoT, identifying popular patterns and styles. This can be beneficial for startups exploring this domain."
https://www.sciencedirect.com/science/article/pii/S0950584920300276,Mining API usage scenarios from stack overflow,Gias=Uddin: gias.uddin@mail.mcgill.ca,"Abstract
Context
APIs
 play a central role in software development. The seminal research of Carroll et al. [15] on minimal manual and subsequent studies by Shull et al. [79] showed that developers prefer task-based API documentation instead of traditional hierarchical official documentation (e.g., Javadoc). The Q&A format in Stack Overflow offers developers an interface to ask and answer questions related to their development tasks.
Objective
With a view to produce API documentation, we study automated techniques to mine API 
usage scenarios
 from Stack Overflow.
Method
We propose a framework to mine API 
usage scenarios
 from Stack Overflow. Each task consists of a code example, the task description, and the reactions of developers towards the code example. First, we present an algorithm to automatically link a code example in a forum post to an API mentioned in the textual contents of the forum post. Second, we generate a natural language description of the task by summarizing the discussions around the code example. Third, we automatically associate developers reactions (i.e., positive and negative opinions) towards the code example to offer information about code quality.
Results
We evaluate the algorithms using three benchmarks. We compared the algorithms against seven baselines. Our algorithms outperformed each baseline. We developed an online tool by automatically mining API usage scenarios from Stack Overflow. A user study of 31 software developers shows that the participants preferred the mined usage scenarios in Opiner over API official documentation. The tool is available online at: 
http://opiner.polymtl.ca/
.
Conclusion
With a view to produce API documentation, we propose a framework to automatically mine API usage scenarios from Stack Overflow, supported by three novel algorithms. We evaluated the algorithms against a total of eight state of the art baselines. We implement and deploy the framework in our proof-of-concept online tool, Opiner.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The framework proposed for mining API usage scenarios from Stack Overflow is innovative and outperforms existing baselines. The user study results indicate practical value for developers, especially in startups."
https://www.sciencedirect.com/science/article/pii/S0950584920300240,Is this GitHub project maintained? Measuring the level of maintenance activity of open-source projects,Jailton=Coelho: jailtoncoelho@dcc.ufmg.br,"Abstract
Context
GitHub hosts an impressive number of high-quality OSS projects. However, selecting “the right tool for the job” is a challenging task, because we do not have precise information about those high-quality projects.
Objective
In this paper, we propose a data-driven approach to measure the level of maintenance activity of GitHub projects. Our goal is to alert users about the risks of using unmaintained projects and possibly motivate other developers to assume the maintenance of such projects.
Method
We train 
machine learning
 models to define a metric to express the level of maintenance activity of GitHub projects. Next, we analyze the historical evolution of 2927 active projects in the time frame of one year.
Results
From 2927 active projects, 16% become unmaintained in the interval of one year. We also found that Objective-C projects tend to have lower maintenance activity than projects implemented in other languages. Finally, software tools—such as compilers and editors—have the highest maintenance activity over time.
Conclusions
A metric about the level of maintenance activity of GitHub projects can help developers to select 
open source projects
.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The data-driven approach to measure maintenance activity of GitHub projects can help startups make informed decisions about using open source projects. The machine learning models and analysis provide practical insights.
https://www.sciencedirect.com/science/article/pii/S0950584920300288,A large scale empirical study of the impact of Spaghetti Code and Blob anti-patterns on program comprehension,Foutse=Khomh: foutse.khomh@polymtl.ca; Cristiano=Politowski: c_polito@encs.concordia.ca; Fabio=Petrillo: fabio@petrillo.com; Yann-Gaël=Guéhéneuc: yann-gael.gueheneuc@concordia.ca; Simone=Romano: simone.romano@uniba.it; Giuseppe=Scanniello: giuseppe.scanniello@unibas.it; Abdou=Maiga: ma_karim@yahoo.fr,"Abstract
Context
Several studies investigated the impact of anti-patterns (
i.e.,
 “poor” solutions to recurring design problems) during maintenance activities and reported that anti-patterns significantly affect the developers’ effort required to edit files. However, before developers edit files, they must understand the 
source code
 of the systems. This 
source code
 must be easy to understand by developers.
Objective
In this work, we provide a complete assessment of the impact of two instances of two anti-patterns, Blob or 
Spaghetti Code
, on 
program comprehension
.
Method
We analyze the impact of these two anti-patterns through three empirical studies conducted at Polytechnique Montré al (Canada) with 24 participants; at Carlton University (Canada) with 30 participants; and at University Basilicata (Italy) with 79 participants.
Results
We collect data from 372 tasks obtained thanks to 133 different participants from the three universities. We use three metrics to assess the developers’ comprehension of the source code: (1) the duration to complete each task; (2) their percentage of correct answers; and, (3) the NASA task load index for their effort.
Conclusions
We report that, although single occurrences of Blob or Spaghetti code anti-patterns have little effect on code comprehension, two occurrences of either Blob or 
Spaghetti Code
 significantly increases the developers’ time spent in their tasks, reduce their percentage of correct answers, and increase their effort. Hence, we recommend that developers act on both anti-patterns, which should be refactored out of the source code whenever possible. We also recommend further studies on combinations of anti-patterns rather than on single anti-patterns one at a time.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The assessment of anti-patterns impact on program comprehension is useful for developers, but the focus on two specific anti-patterns may limit the applicability to a broader range of scenarios for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300380,WCA: A weighting local search for constrained combinatorial test optimization,Yingjie=Fu: fuyj@ios.ac.cn; Zhendong=Lei: leizd@ios.ac.cn; Shaowei=Cai: caisw@ios.ac.cn; Jinkun=Lin: jkunlin@gmail.com; Haoran=Wang: wanghr@ios.ac.cn,"Abstract
Context
Covering array generation (CAG) is the core task of Combinatorial interaction testing (CIT), which is widely used to discover interaction faults in real-world systems. Considering the universality, constrained covering array generation (CCAG) is more in line with the characteristics of applications, and has attracted a lot of researches in the past few years.
Objective
In CIT, a covering array (CA) with smaller size means lower cost of testing, particularly for the systems where the execution of a test suite is time consuming. As constraints between parameters are ubiquitous in real systems, this work is dedicated to more efficient algorithms for CCAG. Specifically, we aim to develop a 
heuristic search algorithm
 for CCAG, which allows generating CAs with smaller size in a limited time when compared with existing algorithms.
Method
We propose a weighting 
local search algorithm
 named 
WCA
, which makes use of weights associated with the tuples and dynamically adjusts them during the search, helping the algorithm to avoid search stagnation. As far as we know, this is the first weighting local search for solving CCAG.
Results
We apply 
WCA
 to a wide range of benchmarks, including real-world ones and synthetic ones. The results show that 
WCA
 achieves a significant improvement over three state-of-the-art competitors in 2-way and 3-way CCAG, in terms of both effectiveness and efficiency. The importance of weighting is also reflected by the experimental comparison between 
WCA
 and its alternative algorithm without the weighting mechanism.
Conclusion
WCA
 is an effective 
heuristic algorithm
 for CCAG to obtain smaller CAs efficiently, and the weighting mechanism plays a crucial role.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The development of WCA heuristic search algorithm for CCAG shows significant improvement over existing algorithms, offering startups a more efficient way to generate covering arrays. The practical results demonstrate the algorithm's effectiveness."
https://www.sciencedirect.com/science/article/pii/S0950584920300409,Identifying security issues for mobile applications based on user review summarization,Chuanqi=Tao: taochuanqi@nuaa.edu.cn,"Abstract
Context
With the development of mobile apps, public concerns about security issues are continually rising. From the user’s perspective, it is crucial to be aware of the security issues of apps. Reviews serve as an important channel for users to discover the diverse issues of apps. However, previous works rarely rely on existing reviews to provide a detailed summarization of the app’s security issues.
Objective
To provide a detailed overview of apps’ security issues for users, this paper introduces SRR-Miner, a novel review summarization approach that automatically summarizes security issues and users’ sentiments.
Method
SRR-Miner follows a keyword-based approach to extracting security-related review sentences. It summarizes security issues and users’ sentiments with  <misbehavior-aspect-opinion>  triples, which makes full use of the deep analysis of sentence structures. SRR-Miner also provides visualized review summarization through a radar chart.
Results
The evaluation on 17 mobile apps shows that SRR-Miner achieves higher F1-score and 
MCC
 than Machine Learning-based 
classification approaches
 in extracting security-related review sentences. It also accurately identifies misbehaviors, aspects and opinions from review sentences. A qualitative study shows that SRR-Miner outperforms two state-of-the-art approaches (AR-Miner and SUR-Miner) in terms of summarizing security issues and users’ sentiments. A further user survey indicates the usefulness of the summarization of SRR-Miner.
Conclusion
SRR-Miner is capable of automatically extracting security-related review sentences based on keywords, and summarizing misbehaviors, aspects and opinions of review sentences with a deep analysis of the sentence structures.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The paper introduces a novel approach, SRR-Miner, for summarizing security issues in mobile apps, outperforming state-of-the-art approaches. This can have practical value for early-stage ventures in ensuring app security."
https://www.sciencedirect.com/science/article/pii/S0950584920300410,A study of run-time behavioral evolution of benign versus malicious apps in android,Haipeng=Cai: haipeng.cai@wsu.edu; Xiaoqin=Fu: xiaoqin.fu@wsu.edu; Abdelwahab=Hamou-Lhadj: wahab.hamou-lhadj@concordia.ca,"Abstract
Context
The constant evolution of the Android platform and its applications have imposed significant challenges both to understanding and securing the Android ecosystem. Yet, despite the growing body of relevant research, it remains unclear how Android apps evolve in terms of their run-time behaviors in ways that impede our gaining consistent empirical knowledge about the workings of the ecosystem and developing effective 
technical solutions
 to defending it against security threats. Intuitively, an essential step towards addressing these challenges is to first understand the evolution itself. Among others, one avenue to examining a program’s run-time behavior is to dissect the program’s execution in terms of its 
syntactic
 and semantic structure.
Objective
In this paper, we study how benign Android apps execute differently from 
malware
 over time, in terms of their execution structures measured by the distribution and interaction among functionality scopes, app components, and callbacks. In doing so, we attempt to reveal how relevant app execution structure is to app security orientation (i.e., benign or malicious).
Method
By tracing the method calls and inter-component communications (ICCs) of 15,451 benign apps and 15,183 
malware
 developed during eight years (2010–2017), we systematically characterized the execution structure of malware versus benign apps and revealed similarities and disparities between them that are not previously known.
Results
Our results show, among other findings, that (1) despite their similarity in execution distribution over functionality scopes, malware accessed framework functionalities mainly through third-party libraries, while benign apps were dominated by calls within the framework; (2) use of 
Activity
 component had been rising in malware while benign apps saw continuous drop in such uses; (3) malware invoked significantly more 
Services
 but less 
Content Providers
 than benign apps during the evolution of both groups; (4) malware carried ICC data significantly less often via standard data fields than benign apps, albeit both groups did not carry any data in most ICCs; and (5) newer malware tended to have more even distribution of callbacks among event-handler categories, while the distribution remained constant in benign apps over time.
Conclusion
We discussed how these findings inform understanding app behaviors, optimizing static and dynamic code analysis of Android apps, and developing sustainable app security defense solutions.",June 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The research on the evolution of Android apps in terms of run-time behaviors and security implications provides valuable insights that can impact the development and security strategies of European startups in the mobile app space.
https://www.sciencedirect.com/science/article/pii/S0950584920300185,Test Case Prioritization in Continuous Integration environments: A systematic mapping study,Jackson A. do=Prado Lima: japlima@inf.ufpr.br; Silvia R.=Vergilio: silvia@inf.ufpr.br,"Abstract
Context:
 Continuous Integration (CI) environments allow frequent integration of software changes, making software evolution more rapid and cost-effective. In such environments, the 
regression test
 plays an important role, as well as the use of Test Case Prioritization (TCP) techniques. Such techniques attempt to identify the test case order that maximizes certain goals, such as early fault detection. This research subject has been raising interest because some new challenges are faced in the CI context, as TCP techniques need to consider time constraints of the CI environments.
Objective:
 This work presents the results of a 
systematic mapping study
 on Test Case Prioritization in Continuous Integration environments (TCPCI) that reports the main characteristics of TCPCI approaches and their evaluation aspects.
Method:
 The mapping was conducted following a plan that includes the definition of research questions, selection criteria and search string, and the selection of search engines. The search returned 35 primary studies classified based on the goal and kind of used TCP technique, addressed CI particularities and 
testing problems
, and adopted evaluation measures.
Results:
 The results show a growing interest in this research subject. Most studies have been published in the last four years. 80% of the approaches are history-based, that is, are based on the failure and test execution history. The great majority of studies report evaluation results by comparing prioritization techniques. The preferred measures are Time and number/percentage of Faults Detected. Few studies address CI 
testing problems
 and characteristics, such as parallel execution and test case volatility.
Conclusions:
 We observed a growing number of studies in the field. Future work should explore other 
information sources
 such as models and requirements, as well as CI particularities and testing problems, such as test case volatility, time constraint, and flaky tests, to solve existing challenges and offer cost-effective approaches to the software industry.",May 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The systematic mapping study on Test Case Prioritization in Continuous Integration environments contributes to improving software development practices, which can benefit early-stage ventures by offering cost-effective testing solutions."
https://www.sciencedirect.com/science/article/pii/S0950584919302733,Web service design defects detection: A bi-level multi-objective approach,Marouane=Kessentini: marouane@umich.edu; Hanzhang=Wang: hanzwang@ebay.com; Soumaya=Rebai: srebal@umich.edu; Bruce=Maxim: bmaxim@umich.edu,"Abstract
Context:
 Web services frequently evolve to integrate new features, update existing operations and fix errors to meet the new requirements of subscribers. While this evolution is critical, it may have a 
negative impact
 on the quality of services (QoS) such as reduced cohesion, increased coupling, poor response time and availability, etc. Thus, the design of services could become hard to maintain and extend in future releases. Recent studies addressed the problem of web service design antipatterns detection, also called design defects, by either manually defining detection rules, as combination of quality metrics, or generating them automatically from a set of defect examples. The manual definition of these rules is time-consuming and difficult due to the subjective nature of design issues, especially to find the right thresholds value. The efficiency of the generated rules, using automated approaches, will depend on the quality of the training set since examples of web services antipatterns are limited. Furthermore, the majority of existing studies for design defects detection for web services are limited to structural information (interface/code static metrics) and they ignore the use of quality of services (QoS) or performance metrics, such as response time and availability, for this detection process or understanding the impact of antipatterns on these QoS attributes.
Objective:
 To address these challenges, we designed a bi-level multi-objective optimization approach to enable the generation of antipattern examples that can improve the efficiency of detection rules.
Method:
 The upper-level generates a set of detection rules as a combination of quality metrics with their threshold values maximizing the coverage of defect examples extracted from several existing web services and artificial ones generated by a lower level. The lower level maximizes the number of generated artificial defects that cannot be detected by the rules of the upper level and minimizes the similarity to well-designed web service examples. The generated detection rules, by our approach, are based on a combination of dynamic QoS attributes and structural information of web service (static interface/code metrics).
Results:
 The statistical analysis of our results, based on a data-set of 662 web services, confirms the efficiency of our approach in detecting web service antipatterns comparing to the current state of the art in terms of precision and recall.
Conclusion:
 The multi-objective search formulation at both levels helped to diversify the generated artificial web service defects which produced better quality of detection rules. Furthermore, the combination of dynamic QoS attributes and structural information of web services improved the efficiency of the generated detection rules.",May 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The approach designed for detecting web service design antipatterns using a bi-level multi-objective optimization can significantly improve the quality of services, which is crucial for startups aiming to maintain service quality and extendibility."
https://www.sciencedirect.com/science/article/pii/S095058492030001X,Understanding predictive factors for merge conflicts,Klissiomara=Dias: kld2@cin.ufpe.br; Paulo=Borba: phmb@cin.ufpe.br; Marcos=Barreto: msb5@cin.ufpe.br,"Abstract
Context:
 Merge conflicts often occur when developers change the same code artifacts. Such conflicts might be frequent in practice, and resolving them might be costly and is an error-prone activity.
Objective:
 To minimize these problems by reducing merge conflicts, it is important to better understand how conflict occurrence is affected by technical and organizational factors.
Method:
 With that aim, we investigate seven factors related to modularity, size, and timing of developers contributions. To do so, we reproduce and analyze 73504 merge scenarios in GitHub repositories of Ruby and Python MVC projects.
Results:
 We find evidence that the likelihood of merge conflict occurrence significantly increases when contributions to be merged are not modular in the sense that they involve files from the same MVC slice (related model, view, and controller files). We also find bigger contributions involving more developers, commits, and changed files are more likely associated with merge conflicts. Regarding the timing factors, we observe contributions developed over longer periods of time are more likely associated with conflicts. No evaluated factor shows 
predictive power
 concerning both the number of merge conflicts and the number of files with conflicts.
Conclusion:
 Our results could be used to derive recommendations for development teams and merge conflict prediction models. Project management and assistive tools could benefit from these models.",May 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on merge conflicts provides useful insights for development teams and merge conflict prediction models, which can help startups reduce costly and error-prone activities. However, the impact on early-stage ventures may not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920300203,Identifying self-admitted technical debt through code comment analysis with a contextualized vocabulary,Marcos=Kalinowski: kalinowski@inf.puc-rio.br; Mário André de Freitas=Farias: mario.andre@ifs.edu.br; Manoel Gomes de Mendonça=Neto: manoel.mendonca@ufba.br; Rodrigo Oliveira=Spínola: rodrigo.spinola@unifacs.br,"Abstract
Context
Previous work has shown that one can explore code comments to detect Self-Admitted Technical Debt (SATD) using a contextualized vocabulary. However, current detection strategies still return a large number of 
false positives
 items. Moreover, those strategies do not allow the automatic identification of the type of debt of the identified items.
Objective
This work applies, evaluates, and improves a set of contextualized patterns we built to detect self-admitted technical debt using code comment analysis. We refer to this set of patterns as the self-admitted technical debt identification vocabulary.
Method
We carry out three empirical studies. Firstly, 23 participants analyze the patterns of a previously defined contextualized vocabulary and register their level of importance in identifying SATD items. Secondly, we perform a qualitative analysis to investigate the relation between each pattern and types of debt. Finally, we perform a feasibility study using a new vocabulary, improved based on the results of the previous empirical studies, to automatically identify self-admitted technical debt items, and types of debt, that exist in three 
open source projects
.
Results
More than half of the new patterns were considered decisive or very decisive to detect technical debt items. The new vocabulary was able to find items associated to code, design, defect, documentation, and requirement debt. Thus, the result of the work is an improved vocabulary that considers the level of importance of each pattern and the relationship between patterns and debt types to support the identification and classification of SATD items.
Conclusion
The studies allowed us to improve a vocabulary to identify self-admitted technical debt items through code comments analysis. The results show that the use of pattern-based code comment analysis can contribute to improve existing methods, or create new ones, for automatically identifying and classifying technical debt items.",May 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The work on identifying self-admitted technical debt through code comments analysis can benefit startups in improving existing methods for identifying and classifying technical debt items, leading to better software quality. The improved vocabulary provides practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300197,Incorporating fault-proneness estimations into coverage-based test case prioritization methods,Seyed-Hassan=Mirian-Hosseinabadi: hmirian@sharif.edu,"Abstract
Context:
 During the 
development process
 of a software program, regression testing is used to ensure that the correct behavior of the software is retained after updates to the 
source code
. This regression testing becomes costly over time as the number of test cases increases and it makes sense to prioritize test cases in order to execute fault-detecting test cases as soon as possible. There are many coverage-based test case prioritization (TCP) methods that only use the code coverage data to prioritize test cases. By incorporating the fault-proneness estimations of code units into the coverage-based TCP methods, we can improve such techniques.
Objective:
 In this paper, we aim to propose an approach which improves coverage-based TCP methods by considering the fault-proneness distribution over code units. Further, we present the results of an empirical study that shows using our proposed approach significantly improves the additional strategy, which is a widely used coverage-based TCP method.
Method:
 The approach presented in this study uses the bug history of the software in order to introduce a 
defect prediction
 method to learn a 
neural network model
. This model is then used to estimate fault-proneness of each area of the 
source code
 and then the estimations are incorporated into coverage-based TCP methods. Our proposed approach is a general idea that can be applied to many coverage-based methods, such as the additional and total TCP methods.
Results:
 The proposed methods are evaluated on datasets collected from the development history of five real-world projects including 357 versions in total. The experiments show that using an appropriate bug history can improve coverage-based TCP methods.
Conclusion:
 The proposed approach can be applied to various coverage-based TCP methods and the experiments show that it can improve these methods by incorporating estimations of code units fault-proneness.",May 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The proposed approach for coverage-based TCP methods improvement is valuable for prioritizing test cases, but the direct impact on early-stage ventures may not be as significant compared to other abstracts. The approach may provide incremental benefits for startups in improving regression testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584920300239,Detection of malicious software by analyzing the behavioral artifacts using machine learning algorithms,Jagsir=Singh: erjagsirsingh18@gmail.com; Jaswinder=Singh: dr.jaswinder@pbi.ac.in,"Abstract
Malicious software
 deliberately affects the 
computer systems
. Malware are analyzed using static or dynamic analysis techniques. Using these techniques, unique patterns are extracted to 
detect malware
 correctly. In this paper, a behavior-based 
malware detection
 technique is proposed. Various runtime features are extracted by setting up a dynamic analysis environment using the Cuckoo sandbox. Three primary features are processed for developing malware classifier. Firstly, printable strings are processed word by word using text mining techniques which produced a very high dimension matrix of the string features. Then we apply the 
singular value
 decomposition technique for reducing dimensions of string features. Secondly, 
Shannon entropy
 is computed over the printable strings and API calls to consider the randomness of API and PSI features. In addition to these features, behavioral features regarding file operations, registry key modification and network activities are used in 
malware detection
. Finally, all features are integrated in the training feature set to develop the malware classifiers using the 
machine learning algorithms
. The proposed technique is validated with 16489 malware and 8422 benign files. Our experimental results show the accuracy of 99.54% in malware detection using ensemble 
machine learning algorithms
. Moreover, it aims to develop a behavior-based malware detection technique of high accuracy by processing the runtime features in a new way.",May 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The behavior-based malware detection technique proposed in this research has high accuracy in detecting malware, which is crucial for protecting computer systems of startups. The use of machine learning algorithms and innovative feature extraction methods provide practical value and impact for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300252,A survey on the practical use of UML for different software architecture viewpoints,Mert=Ozkaya: mozkaya@cse.yeditepe.edu.tr,"Abstract
Context
Software 
architecture viewpoints
 modularize the software architectures in terms of different viewpoints that each address a different concern. 
Unified Modeling Language
 (UML) is so popular among practitioners for modeling software architectures from different viewpoints.
Objective
In this paper, we aimed at understanding the practitioners’ UML usage for the modeling of software architectures from different viewpoints.
Method
To this end, 109 practitioners with diverse profiles have been surveyed to understand practitioners’ UML usage for six different viewpoints: functional, information, concurrency, development, deployment, and operational. Each viewpoint has been considered in terms of a set of software models that can be created in that viewpoint.
Results
The survey includes 35 questions for different viewpoint models, and the results lead to interesting findings. While the top popular viewpoints for the UML-based software architecture modeling are the functional (96%) and information (99%) viewpoints, the least popular one is the operational viewpoint that is considered by 26% of the practitioners. The top popular 
UML modeling
 tool is Enterprise Architect regardless of the viewpoints considered. Concerning the software models that can be created in each viewpoint, UML’s 
class diagram
 is practitioners’ top choice for the functional structure (71%), 
data structure
 (85%), concurrency structure (75%), software code structure (34%), and system installation (39%), and system support (16%) models; UML’s 
sequence diagram
 is the top choice for the 
data lifecycle
 models (47%); UML’s deployment diagram for the physical structure (71%), mapping between the functional and physical components (53%), and system migration (21%) models; UML’s activity diagram for the data flow (65%), software build and release processes (20–22%), and system administration (36%) models; UML’s component diagram for the mapping between the functional and concurrent components (35%), software module structure (47%), and system configuration (21%) models; and UML’s 
package diagram
 for the software module structure (47%) models.",May 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract provides insights into practitioners' UML usage for different software architecture viewpoints, but the practical value for early-stage ventures is limited as it focuses more on modeling techniques."
https://www.sciencedirect.com/science/article/pii/S0950584919302563,Generative software module development for domain-driven design with annotation-based domain specific language,Duc-Hanh=Dang: hanhdd@vnu.edu.vn; Duc Minh=Le: duclm@hanu.edu.vn; Viet-Ha=Nguyen: hanv@vnu.edu.vn,"Abstract
Context
Object-oriented domain-driven design (DDD) aims to iteratively develop software around a realistic model of the application domain, which both thoroughly captures the domain requirements and is technically feasible for implementation. The main focus of recent work in DDD has been on using a form of annotation-based 
domain specific language
 (aDSL), internal to an object-oriented programming language, to build the domain model. However, these work do not consider software modules as first-class objects and thus lack a method for their development.
Objective
In this paper, we tackle software module development with the DDD method by adopting a 
generative approach
 that uses aDSL. To achieve this, we first extend a previous work on module-based software architecture with three enhancements that make it amenable to generative development. We then treat module configurations as first-class objects and define an aDSL, named 
MCCL
, to express module configuration classes. To improve productivity, we define function 
MCCGen
 to automatically generate each configuration class from the module’s domain class.
Method
We define our method as a refinement of an aDSL-based 
software development method
 from a previous work. We apply meta-modelling with UML/OCL to define 
MCCL
 and implement 
MCCL
 in a Java software framework. We evaluate the applicability of our method using a 
case study
 and formally define an evaluation framework for module generativity. We also analyse the correctness and performance of function 
MCCGen
.
Results
MCCL
 is an aDSL for module configurations. Our evaluation shows 
MCCL
 is applicable to complex problem domains. Further, the MCCs and software modules can be generated with a high and quantifiable degree of automation.
Conclusion
Our method bridges an important gap in DDD with a software module development method that uses a novel aDSL with a module-based software architecture and a 
generative technique
 for module configuration.",April 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"This abstract introduces a generative approach to software module development within the DDD method, addressing a gap in software architecture. The practical implications for early-stage ventures are significant."
https://www.sciencedirect.com/science/article/pii/S0950584919302629,Patterns of user involvement in experiment-driven software development,Tomi=Männistö: tomi.mannisto@helsinki.fi; Sezin=Yaman: sezin.yaman@helsinki.fi; Fabian=Fagerholm: fabian.fagerholm@helsinki.fi; Myriam=Munezero: myriam.munezero@helsinki.fi; Tommi=Mikkonen: tommi.mikkonen@helsinki.fi,"Abstract
Background
Experiments are often used as a means to continuously validate user needs and to aid in making software development decisions. Involving users in the development of software products benefits both the users and companies. How software companies efficiently involve users in both general development and in experiments remains unclear; however, it is especially important to determine the perceptions and attitudes held by practitioners in different roles in these companies.
Objective
We seek to: 1) explore how software companies involve users in software development and experimentation; 2) understand how developer, manager and UX designer roles perceive and involve users in experimentation; and 3) uncover systematic patterns in practitioners’ views on user involvement in experimentation. The study aims to reveal behaviors and perceptions that could support or undermine experiment-driven development, point out what skills could enhance experiment-driven development, and raise awareness of such issues for companies that wish to adopt experiment-driven development.
Methods
We conducted a survey within four Nordic software companies, inviting practitioners in three major roles: developers, managers, and UX designers. We asked the respondents to indicate how they involve users in their job function, as well as their perspectives regarding software experiments and ethics.
Results and Conclusion
We identified six patterns describing experimentation and user involvement. For instance, managers were associated with a cautious user notification policy, that is, to always let users know of an experiment they are subject to, and they also believe that users have to be convinced before taking part in experiments. We discovered that, due to lack of clear processes for involving users and the lack of a common understanding of ethics in experimentation, practitioners tend to rationalize their perceptions based on their own experiences. Our patterns were based on empirical evidence and they can be evaluated in different populations and contexts.",April 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract explores how software companies involve users in development and experimentation, which can be relevant for early-stage ventures looking to understand user involvement and perceptions."
https://www.sciencedirect.com/science/article/pii/S0950584919302605,Collaborative or individual identification of code smells? On the effectiveness of novice and professional developers,Alessandro=Garcia: afgarcia@inf.puc-rio.br; Eduardo=Fernandes: emfernandes@inf.puc-rio.br; Roberto=Oliveira: roberto.oliveira@ueg.br; Rafael=de Mello: rmaiani@inf.puc-rio.br; Carlos=Lucena: lucena@inf.puc-rio.br,"Abstract
Context
The code smell identification aims to reveal code structures that harm the software 
maintainability
. Such identification usually requires a 
deep understanding
 of multiple parts of a system. Unfortunately, developers in charge of identifying code smells individually can struggle to identify, confirm, and refute code smell suspects. Developers may reduce their struggle by identifying code smells in pairs through the collaborative smell identification.
Objective
The current knowledge on the effectiveness of collaborative smell identification remains limited. Some scenarios were not explored by previous work on effectiveness of collaborative versus individual smell identification. In this paper, we address a particular scenario that reflects various organizations worldwide. We also compare our study results with recent studies.
Method
We have carefully designed and conducted a controlled experiment with 34 developers. We exploited a particular scenario that reflects various organizations: novices and professionals inspecting systems they are unfamiliar with. We expect to minimize some critical threats to validity of previous work. Additionally, we interviewed 5 project leaders aimed to understand the potential adoption of the collaborative smell identification in practice.
Results
Statistical testing suggests 27% more precision and 36% more recall through the collaborative smell identification for both novices and professionals. These results partially confirm previous work in a not previously exploited scenario. Additionally, the interviews showed that leaders would strongly adopt the collaborative smell identification. However, some organization and tool constraints may limit such adoption. We derived recommendations to organizations concerned about adopting the collaborative smell identification in practice.
Conclusion
We recommend that organizations allocate novice developers for identifying code smells in collaboration. Thus, these organizations can promote the 
knowledge sharing
 and the correct smell identification. We also recommend the allocation of developers that are unfamiliar with the system for identifying smells. Thus, organizations can allocate more experience developers in more critical tasks.",April 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"This abstract presents findings on collaborative code smell identification, offering insights that can improve software maintainability. The practical implications for startups are significant."
https://www.sciencedirect.com/science/article/pii/S0950584919302617,On the value of quality attributes for refactoring ATL model transformations: A multi-objective approach,Manuel=Wimmer: manuel.wimmer@jku.at; Marouane=Kessentini: marouane@umich.edu; Chaima=Abid: cabid@umich.edu; Bader=Alkhazi: balkhazi@umich.edu,"Abstract
Context
Model transformations play a fundamental role in Model-Driven Engineering (MDE) as they are used to manipulate models and to transform them between source and target metamodels. However, model transformation programs lack significant support to maintain good quality which is in contrast to established programming paradigms such as object-oriented programming. In order to improve the quality of model transformations, the majority of existing studies suggest manual support for the developers to execute a number of refactoring types on model transformation programs. Other recent studies aimed to automate the refactoring of model transformation programs, mostly focusing on the ATLAS Transformation Language (ATL), by improving mainly few quality metrics using a number of refactoring types.
Objective
In this paper, we propose a novel set of quality attributes to evaluate refactored 
ATL programs
 based on the hierarchical 
quality model
 QMOOD.
Method
We used the proposed quality attributes to guide the selection of the best refactorings to improve 
ATL programs
 using multi-objective search.
Results
We validate our approach on a comprehensive dataset of model transformations. The statistical analysis of our experiments on 30 runs shows that our automated approach recommended useful refactorings based on a benchmark of ATL transformations and compared to random search, mono-objective search formulation, a previous work based on a different formulation of multi-objective search with few quality metrics, and a semi-automated refactoring approach not based on 
heuristic search
.
Conclusion
All these existing studies did not use our QMOOD adaptation for ATL which confirms the relevance of our quality attributes to guide the search for good refactoring suggestions.",April 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The study proposes a novel set of quality attributes to evaluate and improve ATL programs, which can benefit early-stage ventures by enhancing the quality of model transformations."
https://www.sciencedirect.com/science/article/pii/S0950584919302721,Regression testing for large-scale embedded software development – Exploring the state of practice,Jürgen=Börstler: jurgen.borstler@bth.se; Nasir Mehmood=Minhas: nasir.mehmood.minhas@bth.se; Kai=Petersen: kai.petersen@bth.se; Krzysztof=Wnuk: krzysztof.wnuk@bth.se,"Abstract
Context
A majority of the regression testing techniques proposed by academics have not been adopted in 
industry
. To increase adoption rates, we need to improve our understanding of the practitioners’ perspectives on regression testing.
Objective
This study aims at exploring the regression testing state of practice in the large-scale 
embedded software
 development. The study has two objectives: 1) to highlight the potential challenges in practice, and 2) to identify the industry-relevant research areas regarding regression testing.
Method
We conducted a qualitative study in two large-scale 
embedded software
 development companies, where we carried out semi-structured interviews with representatives from five software testing teams.
Results
The practitioners run regression testing mostly with limited scope based on the size, complexity, and location of the change. Test cases are prioritized on the basis of risk and critical functionality. The practitioners rely on their knowledge and experience for the decision making regarding selection and prioritization of test cases. The companies are using both automated and manual regression testing, and mainly rely on in-house developed tools for test automation. The challenges identified in the companies are: time to test, information management, test suite maintenance, lack of communication, test selection/prioritization, lack of assessment, etc. Regression testing goals identified in this study are customer satisfaction, critical defect detection, confidence, effectiveness, efficiency, and controlled slip through of faults.
Conclusions
Considering the current state of practice and the identified challenges we conclude that there is a need to reconsider the 
regression test
 strategy in the companies. Researchers need to analyze the 
industry
 perspective when proposing new regression testing techniques.",April 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study explores regression testing practices in large-scale embedded software development, providing insights that can be valuable for startups in improving their testing strategies."
https://www.sciencedirect.com/science/article/pii/S0950584919302551,Comparison of development methodologies in web applications,Jimmy=Molina-Ríos: jmolina@utmachala.edu.ec; Nieves=Pedreira-Souto: nieves.pedreira@udc.es,"Abstract
Context
Web applications development is at its peak due to the advance of technological trends and the constant dependence of the Internet. As a result of the needs of developers, new development methodologies have emerged. However, that does not mean that companies always implement an optimal 
development process
; instead, there are several disadvantages presented by an inadequate and not versatile methodologies.
Objective
The aim is to compare web development methodologies based on dynamic features presented during the life cycle to identify their use, relevance, and characteristics. The process employing is an SLR and field research to Ecuadorian development companies.
Method
The method used 
is
 a systematic literature review (SLR) for the identification of characteristics and processes of development methodologies. Additionally, a survey of Ecuadorian web application developers was implemented to assess the importance of using a method during the project.
Results
The literature review exhibited as a result that UWE and OOHDM have greater flexibility than other methodologies before dynamic environments during the web 
development process
. On the other hand, within field research was obtained that companies use different 
software development methods
 than those assessed in the study (hybrid methodologies). However, within the range of companies using the compared methodologies, UWE is the most selected.
Conclusions
Each methodology holds particular features and employment environment, which makes them useful in specific conditions. Through the field research, it is possible to conclude that most of the companies use different methodologies than the evaluated ones; thus, the process is guided by hybrids methods or models based on experience. On the other hand, through the SLR, we identified UWE as the most suitable methodology for web development under dynamic environments, such as the size of the company, the need to modify the requirements, or the knowledge that the development team has about the process.",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The comparison of web development methodologies based on dynamic features offers useful insights for companies looking to optimize their development processes, potentially benefiting early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302125,Better together: Comparing vulnerability prediction models,Christopher=Theisen: http://www.theisencr.github.io/; Laurie=Williams: lawilli3@ncsu.edu,"Abstract
Context
Vulnerability Prediction Models (VPMs) are an approach for prioritizing security inspection and testing to find and fix vulnerabilities. VPMs have been created based on a variety of metrics and approaches, yet widespread adoption of VPM usage in practice has not occurred. Knowing which VPMs have strong prediction and which VPMs have low data requirements and resources usage would be useful for practitioners to match VPMs to their project’s needs. The low density of vulnerabilities compared to defects is also an obstacle for practical VPMs.
Objective
The goal of the paper is to help security practitioners and researchers choose appropriate features for vulnerability prediction through a comparison of Vulnerability Prediction Models.
Method
We performed replications of VPMs on Mozilla Firefox with 28,750 
source code files
 featuring 271 vulnerabilities using software metrics, text mining, and crash data. We then combined features from each VPM and reran our classifiers.
Results
We improved the F-score of the best VPM (.20 to 0.28) by combining features from three types of VPMs and using Naive Bayes as the classifier. The strongest features in the combined model were the number of times a file was involved in a crash, the number of outgoing calls from a file, and the string “nullptr”.
Conclusion
Our results indicate that further work is needed to develop new features for input into classifiers. In addition, new analytic approaches for VPMs are needed for VPMs to be useful in practical situations, due to the low density of vulnerabilities in software (less than 1% for our dataset).",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study provides insights into improving Vulnerability Prediction Models, which can be crucial for security practitioners and researchers in early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302496,How are distributed bugs diagnosed and fixed through system logs?,Wei=Yuan: cindyyuanwei@buaa.edu.cn; Shan=Lu: shanlu@uchicago.edu; Hailong=Sun: sunhl@buaa.edu.cn; Xudong=Liu: liuxd@act.buaa.edu.cn,"Abstract
Context
Distributed systems are the backbone of today’s computing ecosystems. Debugging distributed bugs is crucial and challenging. There are still many unknowns about debugging real-world distributed bugs, especially through system logs.
Objective
This paper aims to provide a comprehensive study of how system logs can help diagnose and fix distributed bugs in practice.
Method
The study was carried out with three core research questions (RQs): How to identify failures in distributed bugs through logs? How to find and utilize bug-related log entries to figure out the root causes? How are distributed bugs fixed and how are logs and patches related? To answer these questions, we studied 106 real-world distributed bugs randomly sampled from five widely used distributed systems, and manually checked the 
bug report
, the log, the patch, the source code and other related information for each of these bugs.
Results
Seven findings are observed and the main findings include: (1) For only about half of the distributed bugs, the failures are indicated by FATAL or ERROR log entries. FATAL are not always fatal, and INFO could be fatal. (2) For more than half of the studied bugs, root-cause diagnosis relies on log entries that are not part of the failure symptoms. (3) One third of the studied bugs are fixed by eliminating end symptoms instead of root causes. Finally, a distributed bug dataset with the in-depth analysis has been released to the research community.
Conclusion
The findings in our study reveal the characteristics of distributed bugs, the differences from debugging single-machine system bugs, and the usages and limitations of existing logs. Our study also provides guidance and opportunities for future research on distributed bug diagnosis, fixing, and log analysis and enhancement.",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Understanding and diagnosing distributed bugs through system logs can greatly benefit startups dealing with distributed systems, making this study highly valuable."
https://www.sciencedirect.com/science/article/pii/S0950584919302393,Adequate vs. inadequate test suite reduction approaches,Simone=Romano: simone.romano@uniba.it; Giuseppe=Scanniello: giuseppe.scanniello@unibas.it; Carmen=Coviello: carmen.coviello@unibas.it; Alessandro=Marchetto: alex.marchetto@gmail.com; Anna=Corazza: anna.corazza@unina.it; Giuliano=Antoniol: antoniol@ieee.org,"Abstract
Context:
 Regression testing is an important activity that allows ensuring the correct behavior of a system after changes. As the system grows, the time and resources to perform regression testing increase. Test Suite Reduction (TSR) approaches aim to speed up regression testing by removing obsolete or redundant test cases. These approaches can be classified as adequate or inadequate. Adequate TSR approaches reduce test suites and completely preserve test requirements (
e.g.,
 covered statements) of the original test suites. Inadequate TSR approaches do not preserve test requirements. The percentage of satisfied test requirements indicates the inadequacy level.
Objective:
 We compare some state-of-the-art adequate and inadequate TSR approaches with respect to the size of reduced test suites and their fault-detection capability. We aim to increase our body of knowledge on TSR approaches by comparing: 
(i)
 well-known traditional adequate TSR approaches; 
(ii)
 their inadequate variants; and 
(iii)
 several variants of a novel Clustering-Based (CB) approach for (adequate and inadequate) TSR.
Method:
 We conducted an experiment to compare adequate and inadequate TSR approaches. This comparison is founded on a public dataset containing information on real faults.
Results:
 The most important findings from our experiment can be summarized as follows: 
(i)
 there is not an inadequate TSR approach that outperforms the others;
(ii)
 some inadequate variants of the CB approach, and few traditional inadequate approaches, outperform the adequate ones in terms of reduction in test suite size with a 
negligible effect
 on fault-detection capability; and 
(iii)
 the CB approach is less sensitive than the other inadequate approaches, that is, variations in the inadequacy level have small effect on reduction in test suite size and on loss in fault-detection capability.
Conclusions:
 These findings imply that inadequate TSR approaches and especially the CB approach might be appealing because they lead to a greater reduction in test suite size (with respect to the adequate ones) at the expense of a small loss in fault-detection capability.",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"While the study on Test Suite Reduction approaches is important, the practical implications for early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919302228,A systematic literature review of machine learning techniques for software maintainability prediction,Hadeel=Alsolai: hadeel.alsolai@strath.ac.uk; Marc=Roper: marc.roper@strath.ac.uk,"Abstract
Context
Software 
maintainability
 is one of the fundamental 
quality attributes
 of 
software engineering
. The accurate prediction of software 
maintainability
 is a significant challenge for the effective management of the software maintenance process.
Objective
The major aim of this paper is to present a systematic review of studies related to the prediction of 
maintainability
 of object-oriented software systems using 
machine learning techniques
. This review identifies and investigates a number of research questions to comprehensively summarize, analyse and discuss various viewpoints concerning software 
maintainability
 measurements, metrics, datasets, evaluation measures, individual models and ensemble models.
Method
The review uses the standard systematic literature review method applied to the most common computer science digital database libraries from January 1991 to July 2018.
Results
We survey 56 relevant studies in 35 journals and 21 conference proceedings. The results indicate that there is relatively little activity in the area of software maintainability prediction compared with other 
software quality attributes
. CHANGE maintenance effort and the maintainability index were the most commonly used software measurements (dependent variables) employed in the selected primary studies, and most made use of class-level 
product metrics
 as the independent variables. Several private datasets were used in the selected studies, and there is a growing demand to publish datasets publicly. Most studies focused on 
regression problems
 and performed k-fold cross-validation. Individual prediction models were employed in the majority of studies, while ensemble models relatively rarely.
Conclusion
Based on the findings obtained in this systematic literature review, ensemble models demonstrated increased accuracy prediction over individual models, and have been shown to be useful models in predicting software maintainability. However, their application is relatively rare and there is a need to apply these, and other models to an extensive variety of datasets with the aim of improving the accuracy and consistency of results.",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"Predicting maintainability of software systems using machine learning techniques is highly relevant for startups, making this systematic review valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673421000639,Occupy Wall Street ten years on: How its disruptive institutional entrepreneurship spread and why it fizzled,Thomas H.=Allison: t.allison@tcu.edu; Matthew=Grimes: m.grimes@jbs.cam.ac.uk; Aaron F.=McKenny: AMcKenny@iu.edu; Jeremy C.=Short: Jeremy.Short@unt.edu,"Abstract
How does media impact institutional entrepreneurs and their ability to create change? We draw from research on social movements and media frames to examine the paradox that media-informed discursive opportunities pose for institutional entrepreneurs engaged in efforts to transform or create social institutions. Through content analysis of 8473 newspaper articles covering the 2011 Occupy Wall Street movement, we highlight the paradox of discursive opportunities: the same types of media frames that initially encourage more disruptive tactics also subsequently increase the perceived threat of such disruption, thereby encouraging swifter counteraction. Our findings hold implications for the importance of media as a potential catalyst for 
entrepreneurial activity
 in the realm of social movements hoping to engage in reform.",November 2021,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"The study on media impact on institutional entrepreneurs has practical implications for understanding the role of media in catalyzing entrepreneurial activity, which can be beneficial for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302587,Intelligent software engineering in the context of agile software development: A systematic literature review,Angelo=Perkusich: perkusic@virtus.ufcg.edu.br; Mirko=Perkusich: mirko@embedded.ufcg.edu.br; Lenardo=Chaves e Silva: lenardo.silva@embedded.ufcg.edu.br; Alexandre=Costa: alexandre.costa@embedded.ufcg.edu.br; Felipe=Ramos: felipe.ramos@embedded.ufcg.edu.br; Renata=Saraiva: renata.saraiva@embedded.ufcg.edu.br; Arthur=Freire: arthur.freire@embedded.ufcg.edu.br; Ednaldo=Dilorenzo: ednaldo.dilorenzo@virtus.ufcg.edu.br; Emanuel=Dantas: emanuel.dantas@embedded.ufcg.edu.br; Danilo=Santos: danilo.santos@embedded.ufcg.edu.br; Kyller=Gorgônio: kyller@embedded.ufcg.edu.br; Hyggo=Almeida: hyggo@embedded.ufcg.edu.br,"Abstract
CONTEXT
: Intelligent 
Software Engineering
 (ISE) refers to the application of intelligent techniques to software engineering. We define an “intelligent technique” as a technique that explores data (from digital artifacts or domain experts) for knowledge discovery, reasoning, learning, planning, 
natural language processing
, perception or supporting decision-making.
OBJECTIVE
: The purpose of this study is to synthesize and analyze the state of the art of the field of applying intelligent techniques to 
Agile Software Development
 (ASD). Furthermore, we assess its maturity and identify adoption risks.
METHOD
: Using a systematic literature review, we identified 104 primary studies, resulting in 93 unique studies. 
RESULTS
: We identified that there is a positive trend in the number of studies applying intelligent techniques to ASD. Also, we determined that reasoning under uncertainty (mainly, Bayesian network), search-based solutions, and 
machine learning
 are the most popular intelligent techniques in the context of ASD. In terms of purposes, the most popular ones are effort estimation, requirements prioritization, 
resource allocation
, requirements selection, and requirements management. Furthermore, we discovered that the primary goal of applying intelligent techniques is to support decision making. As a consequence, the adoption risks in terms of the safety of the current solutions are low. Finally, we highlight the trend of using explainable intelligent techniques.
CONCLUSION
: Overall, although the topic area is up-and-coming, for many areas of application, it is still in its infancy. So, this means that there is a need for more empirical studies, and there are a plethora of new opportunities for researchers.",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"Analyzing the state of applying intelligent techniques to Agile Software Development can provide valuable insights for startups looking to adopt these techniques, making this study highly practical and impactful."
https://www.sciencedirect.com/science/article/pii/S0950584918301642,Towards assisting developers in API usage by automated recovery of complex temporal patterns,Mohamed Aymen=Saied: m_saied@encs.concordia.ca; Erick=Raelijohn: erick.raelijohn@umontreal.ca; Edouard=Batot: batotedo@iro.umontreal.ca; Michalis=Famelis: famelis@iro.umontreal.ca; Houari=Sahraoui: sahraouh@iro.umontreal.ca,"Abstract
Context
Despite the many advantages, the use of external libraries through their APIs remains difficult because of the usage patterns and constraints that are hidden or not properly documented. Existing work provides different techniques to recover API usage patterns from client programs in order to help developers use those libraries. However, most of these techniques produce patterns that generally do not involve 
temporal properties
.
Objective
In this paper, we discuss the problem of temporal usage patterns recovery and propose an algorithm to solve it. We also discuss how the obtained patterns can be used at different stages of client development.
Method
We address the recovery of temporal API usage patterns as an 
optimization problem
 and solve it using a genetic-programming algorithm.
Results
Our evaluation on different APIs shows that the proposed algorithm allows to derive non-trivial temporal usage that are useful and generalizable to new API clients.
Conclusion
Recovering API usage temporal patterns helps client developers to use APIs in an appropriate way. In addition to potentially improve productivity, such patterns also helps preventing errors that result from an incorrect use of the APIs.",March 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed algorithm for recovering temporal API usage patterns can potentially improve productivity and prevent errors in client development, which could be valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302083,Architecting systems of systems: A tertiary study,Paris=Avgeriou: p.avgeriou@rug.nl; Héctor=Cadavid: h.f.cadavid.rengifo@rug.nl; Vasilios=Andrikopoulos: v.andrikopoulos@rug.nl,"Abstract
Context:
 The term System of Systems (SoS) has increasingly been used in a wide variety of domains to describe those systems composed of independent 
constituent systems
 that collaborate towards a mission that they could not accomplish on their own. There is a significant volume of research by the software architecture community that aims to overcome the challenges involved in architecting SoS, as evidenced by the number of secondary studies in the field published so far. However, the boundaries of such research do not seem to be well defined, at least partially, due to the emergence of SoS-adjacent areas of interest like the 
Internet of Things
.
Objective:
 This paper aims to investigate the current state of research on SoS architecting by synthesizing the demographic data, assessing the quality and the coverage of architecting activities and 
software quality attributes
 by the research, and distilling a concept map that reflects a community-wide understanding of the concept of SoS. 
Method:
 We conduct what is, to the best of our understanding, the first tertiary study on SoS architecting. Such tertiary study was based on five research questions, and was performed by following the guidelines of Kitchenham et al. In all, 19 secondary studies were evaluated, which is comparable to other tertiary studies. 
Results:
 The study illustrates a state of disconnection in the research community, with research gaps in the coverage of particular phases and 
quality attributes
. Furthermore, a more effective approach in classifying systems as SoS is required, as the means of resolving conceptual and terminological overlaps with the related domains. 
Conclusions:
 Despite the amount of research in the area of SoS architecting, more coordinated and systematic targeted efforts are required in order to address the identified issues with the current state of research.",February 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on the Overall Path Complexity (OPC) metric for software complexity evaluation provides a new perspective, but the practical implications for startups might be limited compared to the other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919302289,A generic methodology for early identification of non-maintainable source code components through analysis of software releases,Michail D.=Papamichail: mpapamic@issel.ee.auth.gr,"Abstract
Context
Contemporary development approaches consider that time-to-market is of 
utmost importance
 and assume that software projects are constantly evolving, driven by the continuously changing requirements of end-users. This practically requires an iterative process where software is changing by introducing new or updating existing software/user features, while at the same time continuing to support the stable ones. In order to ensure efficient software evolution, the need to produce maintainable software is evident.
Objective
In this work, we argue that non-maintainable software is not the outcome of a single change, but the consequence of a series of changes throughout the 
development lifecycle
. To that end, we define a 
maintainability
 evaluation methodology across releases and employ various information residing in software repositories, so as to decide on the maintainability of software.
Method
Upon using the dropping of packages as a non-maintainability indicator (accompanied by a series of quality-related criteria), the proposed methodology involves using one-class-classification techniques for evaluating maintainability at a package level, on four different axes each targeting a primary 
source code
 property: complexity, cohesion, coupling, and inheritance.
Results
Given the qualitative and 
quantitative evaluation
 of our methodology, we argue that apart from providing accurate and interpretable maintainability evaluation at package level, we can also identify non-maintainable components at an early stage. This early stage is in many cases around 50% of the software package lifecycle.
Conclusion
Based on our findings, we conclude that modeling the trending behavior of certain 
static analysis
 metrics enables the effective identification of non-maintainable software components and thus can be a valuable tool for the software engineers.",February 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The evaluation methodology for maintainability of software can be useful for early-stage startups to ensure efficient software evolution.
https://www.sciencedirect.com/science/article/pii/S2352673420300731,A xenophilic perspective of social entrepreneurship,Reginald=Tucker: regtucker@lsu.edu,"Abstract
Social entrepreneurship has grown as an established field of inquiry, accompanied by growth in both academic and practice. In this paper, we offer a novel perspective on why some social entrepreneurs venture for foreigners. We employ xenophilia, a love of foreigners, to explain why some people care for foreigners by venturing for them. We conceptualize that religious and social class logics influence a xenophilic perspective of foreigners. We also analyze how xenophilia can have a darker side, particularly in social entrepreneurship. Our arguments and analysis allow us to provoke future research questions and offer practical implications.",June 2021,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"The exploration of xenophilia and its influence on social entrepreneurship offers a unique perspective, but may have limited immediate impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302307,Energy efficient adaptation engines for android applications,Angel=Cañete: angelcv@lcc.uma.es,"Abstract
Context
 The energy consumption of mobile devices is increasing due to the improvement in their components (e.g., better processors, larger screens). Although the hardware consumes the energy, the software is responsible for managing hardware resources such as the camera software and its functionality, and therefore, affects the energy consumption. Energy consumption not only depends on the installed code, but also on the execution context (environment, devices status) and how the user interacts with the application.
Objective
 In order to reduce the energy consumption based on 
user behavior
, it is necessary to dynamically adapt the application. However, the adaptation mechanism also consumes a certain amount of energy in itself, which may lead to an important increase in the energy expenditure of the application in comparison with the benefits of the adaptation. Therefore, this footprint must be measured and compared with the benefit obtained.
Method
 In this paper, we (1) determine the benefits, in terms of energy consumption, of dynamically adapting mobile applications, based on 
user behavior
; and (2) advocate the most energy-efficient adaptation mechanism. We provide four different implementations of a proposed adaptation model and measure their energy consumption.
Results
 The proposed adaptation engines do not increase the energy consumption when compared to the benefits of the adaptation, which can reduce the energy consumption by up to 20%.
Conclusion
 The adaptation engines proposed in this paper can decrease the energy consumption of the mobile devices based on user behavior. The overhead introduced by the adaptation engines is negligible in comparison with the benefits obtained by the adaptation.",February 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The energy-efficient adaptation mechanism for mobile applications based on user behavior can help startups reduce energy consumption and improve overall performance.
https://www.sciencedirect.com/science/article/pii/S0950584918302258,Energy aware simulation and testing of smart-spaces,Khaled=El-Fakih: kelfakih@aus.edu; Teruhiro=Mizumoto: mizumoto@ist.osaka-u.ac.jp; Keiichi=Yasumoto: yasumoto@is.naist.jp; Teruo=Higashino: higashino@ist.osaka-u.ac.jp,"Abstract
Context
A smart-space SS typically consists of many rooms, with temperature and humidity environment attributes, devices, and software components that communicate with each other to satisfy certain test purposes that need to be checked over various realistic exterior environment weather conditions.
Objective
We present a novel energy-aware approach for the validation of smart-spaces while minimizing the energy consumption encountered during testing.
Method
A framework for deriving minimal (energy) cost tests is provided. It includes SS, a controlled environment 
Env
 that depicts the exterior conditions, and a 
Tester
 that can control SS and 
Env
, derive and runs tests, and observe relevant SS attributes in order to release a success verdict whenever a test purpose is met. A simulator is proposed for deriving tests by appropriately exploring part of the SS behavior employing several 
cost functions
 for computing the estimated cost and duration of test events.
Results
The framework is deployed in a real SS environment which is used to assess the actual energy consumption of derived tests in practice. Experiments show that the actual 
power consumption
 of the derived tests is close to the ones estimated by the simulator. A 
case study
 that assesses the gains in using energy aware tests in comparison to non energy-aware alternatives is also provided.
Conclusions
The obtained results highlight the importance of considering 
power consumption
 in the development and testing of smart-spaces.",February 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,The energy-aware approach for validating smart-spaces and minimizing energy consumption during testing is highly valuable for startups working with smart-space technologies.
https://www.sciencedirect.com/science/article/pii/S0950584919302022,"Impact of usability mechanisms: An experiment on efficiency, effectiveness and user satisfaction",Juan M.=Ferreira: jmferreira1978@fpuna.edu.py; Silvia T.=Acuña: silvia.acunna@uam.es; Oscar=Dieste: odieste@fi.upm.es; Sira=Vegas: svegas@fi.upm.es; Adrián=Santos: adrian.santos.parrilla@oulu.fi; Francy=Rodríguez: francy.rodriguez@uam.es; Natalia=Juristo: natalia@fi.upm.es,"Abstract
Context
As a software quality characteristic, usability includes the attributes of efficiency, effectiveness and user satisfaction. There are several recommendations in the literature on how to build usable software systems, but there are not very many empirical studies that provide evidence about their impact.
Objective
We report an experiment carried out with users to understand the effect of three usability mechanisms —Abort Operation, Progress Feedback and Preferences— on efficiency, effectiveness and user satisfaction. Usability mechanisms are functionalities that should, according to the HCI community, be implemented within a software system to increase its usability.
Method
The experiment was conducted with 168 users divided into 24 experimental groups. Each group performs three online shopping tasks. We measure efficiency variables (number of clicks and time taken), effectiveness (percentage of task completion) and user satisfaction gathered from a questionnaire.
Results
The adoption of Abort Operation has a significantly positive effect on efficiency (time taken), effectiveness and user satisfaction. The adoption of Progress Feedback does not appear to have any impact on any of the variables. The adoption of Preferences has a significantly positive effect on effectiveness and user satisfaction but no influence on efficiency.
Conclusions
We provide relevant evidence of the impact of the three usability mechanisms on efficiency, effectiveness and user satisfaction. In no case do the usability mechanisms degrade user performance. The effort to adopt Abort Operation and Preferences appears to be justified by the benefits in terms of effectiveness and user satisfaction. Also Abort Operation enables the user to be more productive. We believe that the effects on efficiency, effectiveness and satisfaction depend not only on mechanism functionality but also on the problem domain. The impact of a mechanism in other contexts could differ. Therefore, we need to conduct further experiments to gather more evidence and confirm these results.",January 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides relevant evidence of the impact of usability mechanisms on efficiency, effectiveness, and user satisfaction, which can be valuable for European early-stage ventures in improving user experience and product performance."
https://www.sciencedirect.com/science/article/pii/S0950584919302046,The missing link – A semantic web based approach for integrating screencasts with security advisories,Ellis E.=Eghan: e_eghan@encs.concordia.ca; Parisa=Moslehi: p_mosleh@encs.concordia.ca; Juergen=Rilling: juergen.rilling@concordia.ca; Bram=Adams: bram.adams@polymtl.ca,"Abstract
Context
Collaborative tools and repositories have been introduced to facilitate 
open source software development
, allowing projects, developers, and users to share their knowledge and expertise through formal and informal channels such as repositories, Q&A websites, blogs and screencasts. While significant progress has been made in mining and cross-linking traditional software repositories, limited work exists in making 
multimedia content
 in the form of screencasts or 
audio recordings
 an integrated part of 
software engineering
 processes.
Objective
The objective of this research is to provide a standardized ontological representation that allows for a seamless knowledge integration of screencasts with other software artifacts across knowledge resource boundaries.
Method
In this paper, we propose a modeling approach that takes advantage of the Semantic Web and its inference services to capture and establish 
traceability links
 between knowledge extracted from different resources such as 
vulnerability information
 in 
NVD
, project dependency information from Maven Central, and YouTube screencasts.
Results
We performed a 
case study
 on 48 videos that illustrate attacks on vulnerable systems and show that our approach can successfully link relevant vulnerabilities and screencasts with an average precision of 98% and an average recall of 54% when vulnerability identifiers (CVE ID) are explicitly mentioned in the metadata (title and description) of videos. When no CVE ID is present, our initial results show that for a reduced search space (for one vulnerability), using only the textual content of the image frames, our approach is still able to link video-vulnerability pairs and rank the correct result within the top two positions of the result set.
Conclusion
Our approach not only establishes bi-directional, direct, and indirect 
traceability links
 from screencasts to these other software artifacts; these links can also be used to guide practitioners in comprehending the potential security impact of vulnerable components in their projects.",January 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,3.0,"While the study explores linking screencasts with other software artifacts, the direct practical value for early-stage ventures or startups in Europe may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919302058,Automatic extraction of product line architecture and feature models from UML class diagram variants,Silvia R.=Vergilio: silvia@inf.ufpr.br; Wesley K.G.=Assunção: wesleyk@inf.ufpr.br; Roberto E.=Lopez-Herrejon: roberto.lopez@etsmtl.ca,"Abstract
Context
Software Product Lines (SPLs) are families of 
related products
 developed for specific domains. SPLs commonly emerge from existing variants when their individual maintenance and/or evolution become complex. Even though there exists a vast research literature on SPL extraction, the majority of the approaches have only focused on 
source code
, are partially automated, or do not reflect domain constraints. Such limitations can make more difficult the extraction, management, documentation and generation of some important SPL artifacts such as the 
product line architecture
, a fact that can impact negatively the evolution and maintenance of SPLs.
Objective
To tackle these limitations, this work presents ModelVars2SPL (
Model Variants to SPL Core Assets
), an automated approach to aid the development of SPLs from existing system variants.
Method
The input for ModelVars2SPL is a set of 
Unified Modeling Language
 (UML) 
class diagrams
 and the list of features they implement. The approach extracts two main assets: (i) Feature Model (FM), which represents the combinations of features, and (ii) a Product Line Architecture (PLA), which represents a global structure of the variants. ModelVars2SPL is composed of four automated steps. We conducted a thorough evaluation of ModelVars2SPL to analyze the artefacts it generates and its performance.
Results
The results show that the FMs well-represent the features organization, providing useful information to define and manage commonalities and variabilities. The PLAs show a global structure of current variants, facilitating the understanding of existing implementations of all variants.
Conclusions
An advantage of ModelVars2SPL is to exploit the use of UML design models, that is, it is independent of the programming language, and supports the re-engineering process in the design level, allowing practitioners to have a broader view of the SPL.",January 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"The approach presented aids in developing software product lines from existing variants, which may have limited immediate practical impact on early-stage ventures, thus receiving a moderate score."
https://www.sciencedirect.com/science/article/pii/S095058491930206X,Utilising CI environment for efficient and effective testing of NFRs,Emil=Alégroth: emil.alegroth@bth.se; Liang=Yu: liang.yu@bth.se; Panagiota=Chatzipetrou: panagiota.chatzipetrou@oru.se; Tony=Gorschek: tony.gorschek@bth.se,"Abstract
Context
Continuous integration (CI) is a practice that aims to continuously verify 
quality aspects
 of a software intensive system both for functional and non-functional requirements (NFRs). Functional requirements are the inputs of development and can be tested in isolation, utilising either manual or automated tests. In contrast, some NFRs are difficult to test without functionality, for NFRs are often aspects of functionality and express 
quality aspects
. Lacking this 
testability
 attribute makes NFR testing complicated and, therefore, underrepresented in industrial practice. However, the emergence of CI has radically affected software development and created new avenues for software quality evaluation and quality 
information acquisition
. Research has, consequently, been devoted to the utilisation of this additional information for more efficient and effective NFR verification.
Objective
We aim to identify the state-of-the-art of utilising the CI environment for NFR testing, hereinafter referred to as CI-NFR testing.
Method
Through rigorous selection, from an initial set of 747 papers, we identified 47 papers that describe how NFRs are tested in a CI environment. Evidence-based analysis, through coding, is performed on the identified papers in this SLR.
Results
Firstly, ten CI approaches are described by the papers selected, each describing different tools and nine different NFRs where reported to be tested. Secondly, although possible, CI-NFR testing is associated with eight challenges that adversely affect its adoption. Thirdly, the identified CI-NFR testing processes are tool-driven, but there is a lack of NFR testing tools that can be used in the CI environment. Finally, we proposed a CI framework for NFRs testing.
Conclusion
A synthesised CI framework is proposed for testing various NFRs, and associated CI tools are also mapped. This contribution is valuable as results of the study also show that CI-NFR testing can help improve the quality of NFR testing in practices.",January 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The study focuses on utilising the CI environment for NFR testing, which may provide some insights for startups in improving software quality evaluation, but the direct impact on European early-stage ventures is moderate."
https://www.sciencedirect.com/science/article/pii/S0950584918302271,Ontology-based test generation for automated and autonomous driving functions,Franz=Wotawa: wotawa@ist.tugraz.at; Yihao=Li: yihao.li@ist.tugraz.at,"Abstract
Context:
 Ontologies are known as a formal and explicit conceptualization of entities, their interfaces, behaviors, and relationships. They have been applied in various application domains such as 
autonomous driving
 where ontologies are used for decision making, traffic description, auto-pilot etc. It has always been a challenge to test the corresponding safety-critical software systems in 
autonomous driving
 that have been playing an increasingly important role in our daily routines.
Objective:
 Failures in these systems potentially not only cause great financial loss but also the loss of lives. Therefore, it is vital to obtain and cover as many as critical driving scenarios during auto drive testing to ensure that the system can always reach a fail-safe state under different circumstances.
Method:
 We outline a general framework for testing, verification, and validation for automated and autonomous driving functions. The introduced method makes use of ontologies for describing the environment of autonomous vehicles and convert them to input models for combinatorial testing. The combinatorial test suite comprises abstract test cases that are mapped to concrete test cases that can be executed using simulation environments.
Results:
 We discuss in detail on how to automatically convert ontologies to the corresponding combinatorial testing input models. Specifically, we present two conversion algorithms and compare their applicability using ontologies with different sizes. We also carried out a 
case study
 to further demonstrate the practical value of applying ontology-based test generation in industrial settings.
Conclusion:
 The proposed approach for testing autonomous driving takes ontologies describing the environment of autonomous vehicles, and automatically converts it to test cases that are used in a simulation environment to verify automated driving functions. The conversion relies on combinatorial testing. The first experimental results relying on an example from the automotive industry indicates that the approach can be used in practice.",January 2020,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract presents a practical approach for testing autonomous driving functions using ontologies, which can have a significant impact on the safety and reliability of autonomous vehicles. The method outlined is robust and can contribute positively to the European early-stage ventures in the automotive industry."
https://www.sciencedirect.com/science/article/pii/S0950584919301843,Improving feature location accuracy via paragraph vector tuning,Allysson Costa e=Silva: allcostaes@ufu.br; Marcelo de Almeida=Maia: marcelo.maia@ufu.br,"Abstract
Context
Feature location techniques are still not highly accurate despite advances in the field.
Objective
This paper aims at investigating the impact of applying different tunings to paragraph vector to the feature location problem. It evaluates the influence of different 
artificial neural network
 (ANN) configurations for 
learning rate
 and negative sampling loss function in paragraph 
vectors training
.
Method
The suggested weight configuration relies on the search for an adequate ANN 
learning rate
 and an adequate calibration of negative sampling skip-gram mode of the Doc2vec (DV) algorithm. A dataset with 633 feature descriptions, extracted from six open-source Java projects, organized within method 
granularity
, is used for the empirical assessment.
Results
Our results suggest that feature location techniques benefit from the use of paragraph vector with systematic tuning. We show that an adequate update policy for 
ANN weights
 can increase feature location accuracy. An adequate calibration for negative sampling also improved accuracy. We got it with no default values of negative sampling pointed by literature. Moreover, an ensemble of learning rate policies and the use of a tuned DV negative sampling option had overcome state-of-the-art approaches.
Conclusions
We show evidence of a relationship between hyper-parameter settings and accuracy gain. Modern paragraph vector approaches require adequate calibration to produce better results, and we have improved the accuracy of feature location process with proper tuning.",December 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the abstract discusses the impact of tuning paragraph vectors for feature location techniques, the practical implications for European early-stage ventures, especially startups, are not as direct or significant as the autonomous driving testing methods in the previous abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919301715,Software process line as an approach to support software process reuse: A systematic literature review,Eldânae=Nogueira Teixeira: danny@cos.ufrj.br,"Abstract
Context
Software 
Process Line
 (SPrL) aims at providing a systematic reuse technique to support reuse experiences and knowledge in the definition of software processes for new projects thus contributing to reduce effort and costs and to achieve improvements in quality. Although the research body in SPrL is expanding, it is still an immature area with results offering an overall view scattered with no consensus.
Objective
The goal of this work is to identify existing approaches for developing, using, managing and visualizing the evolution of SPrLs and to characterize their support, especially during the development of reusable process family artefacts, including an overview of existing SPrL supporting tools in their multiple stages; to 
analyse variability
 management and component-based aspects in SPrL; and, finally, to list practical examples and conducted evaluations. This research aims at reaching a broader and more consistent view of the research area and to provide perspectives and gaps for future research.
Method
We performed a systematic literature review according to well-established guidelines set. We used tools to partially support the process, which relies on a six-member research team.
Results
We report on 49 primary studies that deal mostly with conceptual or theoretical proposals and the domain engineering stage. Years 2014, 2015, and 2018 yielded the largest number of articles. This can indicate SPrL as a recent research theme and one that attracts ever-increasing interest.
Conclusion
Although this research area is growing, there is still a lack of practical experiences and approaches for actual applications or project-specific process derivations and decision-making support. The concept of an integrated reuse infrastructure is less discussed and explored; and the development of integrated tools to support all reuse stages is not fully addressed. Other topics for future research are discussed throughout the paper with gaps pointed as opportunities for improvements in the area.",December 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"The abstract discusses the development and management of software process lines, but the direct impact on European early-stage ventures, especially startups, is not as clear or immediate as the autonomous driving testing methods presented in other abstracts."
https://www.sciencedirect.com/science/article/pii/S095058491930165X,Impact of the conceptual model's representation format on identifying and understanding user stories,Marina=Trkman: marina.trkman@gmail.com,"Abstract
Context
Eliciting user stories is a major challenge for 
agile development
 approaches. Conceptual models are used to support the identification of user stories and increase their understanding. In many companies, existing model documentation stored as either use cases or 
BPMN
 models is available. However, these two types of business process models might not be equally effective for 
elicitation
 tasks due to their formats.
Objective
We address the effectiveness of different 
elicitation
 tasks when supported either with visual or textual conceptual model. Since the agile literature shows little attention to reusing existing 
BPMN
 documentation, we propose several hypotheses to compare it to the use of textual use case models.
Method
We conducted an experiment to compare the effectiveness of the two business process formats: textual use cases and visual BPMN models. We studied their effects on three elicitation tasks: identifying user stories and understanding their execution-order and integration dependencies.
Results
The subjects better understood execution-order dependencies when visual input in the form of BPMN models was provided. The performance of the other two tasks showed no statistical differences.
Conclusion
We addressed an important problem of user story elicitation: which informationally equivalent model (visual BPMN or textual use case) is more effective when identifying and understanding user stories.",December 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study addresses an important problem in agile development, but the impact on early-stage ventures may be limited to companies using agile methodologies."
https://www.sciencedirect.com/science/article/pii/S0950584919301673,Assessing the effectiveness of goal-oriented modeling languages: A family of experiments,Silvia=Abrahão: sabrahao@dsic.upv.es; Emilio=Insfran: einsfran@dsic.upv.es; Fernando=González-Ladrón-de-Guevara: fgonzal@omp.upv.es; Marta=Fernández-Diego: marferdi@omp.upv.es; Carlos=Cano-Genoves: carcage1@dsic.upv.es; Raphael=Pereira de Oliveira: raphael.oliveira@ifs.edu.br,"Abstract
Context
Several goal-oriented languages focus on modeling stakeholders’ objectives, interests or wishes. However, these languages can be used for various purposes (e.g., exploring system solutions or evaluating alternatives), and there are few guidelines on how to use these models downstream to the software requirements and design artifacts. Moreover, little attention has been paid to the empirical evaluation of this kind of languages. In a previous work, we proposed value@GRL as a specialization of the Goal Requirements Language (GRL) to specify stakeholders’ goals when dealing with early requirements in the context of incremental software development.
Objective
This paper compares the value@GRL language with the i* language, with respect to the quality of goal models, the participants’ modeling time and productivity when creating the models, and their perceptions regarding ease of use and usefulness.
Method
A family of experiments was carried out with 184 students and practitioners in which the participants were asked to specify a goal model using each of the languages. The participants also filled in a questionnaire that allowed us to assess their perceptions.
Results
The results of the individual experiments and the meta-analysis indicate that the quality of goal models obtained with value@GRL is higher than that of i*, but that the participants required less time to create the goal models when using i*. The results also show that the participants perceived value@GRL to be easier to use and more useful than i* in at least two experiments of the family.
Conclusions
value@GRL makes it possible to obtain goal models with good quality when compared to i*, which is one of the most frequently used goal-oriented 
modeling languages
. It can, therefore, be considered as a promising emerging approach in this area. Several insights emerged from the study and opportunities for improving both languages are outlined.",December 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The comparison of goal-oriented modeling languages can provide valuable insights for early-stage ventures in software development, leading to potential improvements in their processes."
https://www.sciencedirect.com/science/article/pii/S0950584919301727,Finding key classes in object-oriented software systems by techniques based on static analysis,Ioana=Şora: ioana.sora@cs.upt.ro,"Abstract
Context
Software maintenance is burdened by 
program comprehension
 activities which consume a big part of project resources. Program comprehension is difficult because the code to be analyzed is very large and the documentation may not be well structured to help navigating through the code.
Objective
Tools should support the early stages of program comprehension. Our goal is to build tools that analyze the code and filter this large amount of information such that only the most important information is presented to the software 
maintenance team
. In the case of object-oriented systems, finding the important information means finding the most important classes, also called the key classes of the system.
Method
In this work, we formulate and explore several hypotheses regarding which are the class attributes that characterize important classes. By class attributes, we understand here different metrics that quantify properties of the class such as its connections and relationships with other classes. All the necessary input data for computing class attributes are extracted from code by 
static analysis
. We experimentally investigate which attributes are best suited to rank classes according to their importance, doing an extensive empirical study on fifteen software systems.
Result
Attributes from the categories of 
direct connections
 and network centrality are the best for finding key classes. We identified three class attributes which are best as class ranking criteria: PR-U2-W and CONN-TOTAL-W when the target set of key classes is small and CONN-TOTAL when the target set has a large and variable size. We show that the method of ranking classes based on these attributes outperforms known related work approaches of finding key classes.
Conclusions
Our method allows us to build easy-to-use fully automatic tools which find almost instantly the key classes of a software system starting from its code.",December 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The development of tools for program comprehension and identifying key classes in software systems can have a significant impact on the efficiency and effectiveness of early-stage ventures in software development.
https://www.sciencedirect.com/science/article/pii/S2352673420300755,ADHD and entrepreneurship: Beyond person-entrepreneurship fit,Reginald=Tucker: regtucker@lsu.edu,"Abstract
Research examining 
mental health
 and entrepreneurship has found important links between 
mental health
 and entrepreneurship. These findings have led scholars to suggest a fit between some aspects of mental health, and in particular, mental dysfunction, and entrepreneurship. This paper complements extant studies in this area by examining the mental health and entrepreneurship relationship from a sociocognitive perspective. We examine to what extent does 
ADHD
 influence entrepreneurial self-efficacy and opportunity recognition tendency. Our findings are consistent with our hypotheses, suggesting that people with 
ADHD
 may not be efficacious in the entrepreneurial context, and specifically in recognizing opportunities. However, confidence in one’s ability regarding the entrepreneurship vocation can grow with education and experience. Our findings allow us to advance theory and offer practical implications.",June 2021,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"Examining the link between mental health, ADHD, and entrepreneurship from a sociocognitive perspective provides valuable insights that can inform support strategies for entrepreneurs in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584919301661,Taking the emotional pulse of software engineering — A systematic literature review of empirical studies,Mary=Sánchez-Gordón: mary.sanchez-gordon@hiof.no; Ricardo=Colomo-Palacios: ricardo.colomo-palacios@hiof.no,"Abstract
Context
Over the past 50 years of 
Software Engineering
, numerous studies have acknowledged the importance of human factors. However, software developers’ emotions are still an area under investigation and debate that is gaining relevance in the software 
industry
.
Objective
In this study, a 
systematic literature review
 (SLR) was carried out to identify, evaluate, and synthesize research published concerning software developers’ emotions as well as the measures used to assess its existence.
Method
By searching five major 
bibliographic databases
, authors identified 7172 articles related to emotions in 
Software Engineering
. We selected 66 of these papers as primary studies. Then, they were analyzed in order to find empirical evidence of the intersection of emotions and software engineering.
Results
Studies report a total of 40 discrete emotions but the most frequent were: 
anger, fear, disgust, sadness, joy, love, and happiness
. There are also 2 different dimensional approaches and 10 datasets related to this topic which are publicly available on the Web. The findings also showed that self-reported 
mood
 instruments (e.g., 
SAM
, PANAS), 
physiological measures
 (e.g., heart rate, perspiration) or behavioral measures (e.g., keyboard use) are the least reported tools, although, there is a recognized intrinsic problem with the accuracy of current state of the art 
sentiment analysis
 tools. Moreover, most of the studies used software practitioners and/or datasets from industrial context as subjects.
Conclusions
The study of emotions has received a growing attention from the research community in the recent years, but the management of emotions has always been challenging in practice. Although it can be said that this field is not mature enough yet, our results provide a holistic view that will benefit researchers by providing the latest trends in this area and identifying the corresponding research gaps.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The study of emotions in Software Engineering, although not mature yet, provides valuable insights and trends that can benefit researchers and identify research gaps in the field."
https://www.sciencedirect.com/science/article/pii/S0950584919301648,Bug report severity level prediction in open source software: A survey and research opportunities,Luiz Alberto Ferreira=Gomes: luizgomes@pucpcaldas.br; Mario Lúcio=Côrtes: cortes@ic.unicamp.br; Ricardo da Silva=Torres: rtorres@ic.unicamp.br,"Abstract
Context:
 The 
severity level
 attribute of a 
bug report
 is considered one of the most critical variables for planning evolution and maintenance in Free/Libre 
Open Source Software
. This variable measures the impact the bug has on the successful execution of the software system and how soon a bug needs to be addressed by the development team. Both business and academic community have made an extensive investigation towards the proposal methods to automate the 
bug report
 severity prediction.
Objective:
 This paper aims to provide a comprehensive mapping study review of recent research efforts on automatically bug report severity prediction. To the best of our knowledge, this is the first review to categorize quantitatively more than ten aspects of the experiments reported in several papers on bug report severity prediction.
Method:
 The mapping study review was performed by searching four electronic databases. Studies published until December 2017 were considered. The initial resulting comprised of 54 papers. From this set, a total of 18 papers were selected. After performing snowballing, more nine papers were selected.
Results:
 From the mapping study, we identified 27 studies addressing bug report severity prediction on Free/Libre 
Open Source Software
. The gathered data confirm the relevance of this topic, reflects the scientific maturity of the research area, as well as, identify gaps, which can motivate new research initiatives.
Conclusion:
 The message drawn from this review is that unstructured text features along with traditional 
machine learning algorithms
 and text mining methods have been playing a central role in the most proposed methods in literature to predict bug 
severity level
. This scenario suggests that there is room for improving prediction results using state-of-the-art 
machine learning
 and text mining algorithms and techniques.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The mapping study review on bug report severity prediction in Free/Libre Open Source Software offers valuable quantitative insights that can motivate new research initiatives and improve prediction results.
https://www.sciencedirect.com/science/article/pii/S0950584919301478,Multi-reviewing pull-requests: An exploratory study on GitHub OSS projects,Dongyang=Hu: hudongyang17@163.com; Yang=Zhang: yangzhang15@nudt.edu.cn,"Abstract
Context:
GitHub has enabled developers to easily contribute their review comments on multiple pull-requests and switch their review focus 
between
 different pull-requests, 
i.e.
, multi-reviewing. Reviewing multiple pull-requests simultaneously may enhance work efficiency. However, multi-reviewing also relies on developers’ rationally allocating their focus, which may bring a different influence to the resolution of pull-requests.
Objective:
 In this paper, we present an ongoing study of the impact of multi-reviewing on pull-request resolution in GitHub 
open source projects
.
Method:
 We collected and analyzed 1,836,280 pull-requests from 760 GitHub projects to explore how multi-reviewing affects the resolution of a pull-request.
Results:
 We find that multi-reviewing is a common behavior in GitHub. However, more multi-reviewing behaviors tend to bring longer pull-request resolution latency.
Conclusion:
 Multi-reviewing is a complex behavior of developers, and has an important impact on the efficiency of pull-request resolution. Our study motivates the need for more research on multi-reviewing.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The ongoing study on the impact of multi-reviewing on pull-request resolution in GitHub open source projects is interesting but may need further exploration to determine practical implications for developers.
https://www.sciencedirect.com/science/article/pii/S0950584919301624,Using cognitive dimensions to evaluate the usability of security APIs: An empirical investigation,Chamila=Wijayarathna: z5122098@student.unsw.edu.au; Nalin Asanka Gamagedara=Arachchilage: n.arachchilage@latrobe.edu.au,"Abstract
Context
Usability issues
 of security 
Application Programming Interfaces
 (APIs) are a main factor for mistakes programmers make that could result in introducing 
security vulnerabilities
 into applications they develop. This has become a common problem as there is no methodology to evaluate the usability of security APIs. A 
usability evaluation
 methodology for security APIs would allow API developers to 
identify usability issues
 of security APIs and fix them. A Cognitive Dimensions Framework (CDF) based 
usability evaluation
 methodology has been proposed in previous research to empirically evaluate the usability of security APIs.
Objective
In this research, we evaluated the proposed CDF based methodology through four security APIs (Google 
Authentication
 API, Bouncy Castle light weight Crypto API, Java Secure Socket Extension API, OWASP Enterprise Security API).
Method
We conducted four experiments where in each experiment we recruited programmers and they completed a programming task using one of the four security APIs. Participants’ feedback on each cognitive dimension of the particular API was collected using the cognitive dimensions questionnaire. 
Usability issues
 of each API was identified based on this feedback.
Results
Results of the four experiments revealed that over 83% of the usability issues in a security API could be identified by this methodology with a considerably good validity and reliability.
Conclusion
The proposed CDF based usability evaluation methodology provides a good platform to conduct usability evaluation for security APIs.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed methodology for evaluating usability of security APIs has practical value in improving the security of applications developed by early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S2352673421000044,Relief and exploration after firm failure: Taking into account pre-failure experiences to understand post-failure responses,Anna S=Jenkins: a.jenkins@business.uq.edu.au,"Abstract
Conceptualizing firm failure as the loss of something important to the entrepreneur, the literature on emotional responses to firm failure has focused on the negative emotions experienced in response to this loss. We shift emphasis to introduce the positively valanced emotions relief and exploration as emotional responses to firm failure. These emotions reflect the inherently stressful nature of firm failure enabling an exploration into the timing of when stress is experienced during the failure process. Empirically we test our hypotheses, using a combination of a telephone and mail survey, on a sample of 114 entrepreneurs who had recently experienced the 
bankruptcy
 of their firm. We extend the literature on responses to firm failure by establishing relief and exploration as common emotional responses to firm failure and provide initial empirical support for the importance of considering pre-failure experiences in the process of entrepreneurial failure. Our findings also lend empirical support to the anticipatory grief argument put forward by Shepherd and colleagues (2009).",June 2021,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"Shifting focus to positive emotions like relief and exploration in response to firm failure adds value to the understanding of entrepreneurial experiences, which can be relevant for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919301612,Automatic recall of software lessons learned for software project managers,Tamer Mohamed=Abdellatif: tmohame7@uwo.ca; Luiz Fernando=Capretz: lcapretz@uwo.ca; Danny=Ho: danny@nfa-estimation.com,"Abstract
Context
Lessons learned (LL) records constitute the software organization memory of successes and failures. LL are recorded within the organization repository for future reference to optimize planning, gain experience, and elevate market competitiveness. However, manually searching this repository is a daunting task, so it is often disregarded. This can lead to the repetition of previous mistakes or even missing potential opportunities. This, in turn, can negatively affect the organization's profitability and competitiveness.
Objective
We aim to present a novel solution that provides an automatic process to recall relevant LL and to push those LL to project managers. This will dramatically save the time and effort of manually searching the unstructured LL repositories and thus encourage the LL exploitation.
Method
We exploit existing project artifacts to build the LL search queries on-the-fly in order to bypass the tedious manual searching. An empirical 
case study
 is conducted to build the automatic LL recall solution and evaluate its effectiveness. The study employs three of the most popular information 
retrieval models
 to construct the solution. Furthermore, a real-world dataset of 212 LL records from 30 different software projects is used for validation. Top-k and MAP well-known accuracy metrics are used as well.
Results
Our case study results confirm the effectiveness of the automatic LL recall solution. Also, the results prove the success of using existing project artifacts to dynamically build the search query string. This is supported by a discerning accuracy of about 70% achieved in the case of top-k.
Conclusion
The automatic LL recall solution is valid with high accuracy. It will eliminate the effort needed to manually search the LL repository. Therefore, this will positively encourage project managers to reuse the available LL knowledge – which will avoid old pitfalls and unleash hidden business opportunities.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The automatic LL recall solution presented has the potential to save time and effort for startups, improving planning and competitiveness."
https://www.sciencedirect.com/science/article/pii/S0950584919301697,The usefulness of software metric thresholds for detection of bad smells and fault prediction,Mariza A.S.=Bigonha: mariza@dcc.ufmg.br; Kecia=Ferreira: kecia@decom.cefetmg.br; Priscila=Souza: priscilinhapsouza@gmail.com; Bruno=Sousa: bruno.luan.sousa@dcc.ufmg.br; Marcela=Januário: marcelajanuario92@hotmail.com; Daniele=Lima: danieleddelima@gmail.com,"Abstract
Context
Software metrics may be an effective tool to assess the 
quality of software
, but to guide their use it is important to define their thresholds. Bad smells and fault also impact the 
quality of software
. Extracting metrics from software systems is relatively low cost since there are tools widely used for this purpose, which makes feasible applying software metrics to identify bad smells and to predict faults.
Objective
To inspect whether thresholds of object-oriented metrics may be used to aid bad smells detection and fault predictions.
Method
To direct this research, we have defined three research questions (RQ), two related to identification of bad smells, and one for identifying fault in software systems. To answer these RQs, we have proposed detection strategies for the bad smells: Large Class, Long Method, Data Class, Feature Envy, and Refused Bequest, based on metrics and their thresholds. To assess the quality of the derived thresholds, we have made two studies. The first one was conducted to evaluate their efficacy on detecting these bad smells on 12 systems. A second study was conducted to investigate for each of the class level software metrics: 
DIT
, LCOM, NOF, NOM, NORM, NSC, NSF, NSM, SIX, and WMC, if the ranges of values determined by thresholds are useful to identify fault in software systems.
Results
Both studies confirm that metric thresholds may support the prediction of faults in software and are significantly and effective in the detection of bad smells.
Conclusion
The results of this work suggest practical applications of metric thresholds to identify bad smells and predict faults and hence, support 
software quality assurance
 activities.Their use may help developers to focus their efforts on classes that tend to fail, thereby minimizing the occurrence of future problems.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The approach to using object-oriented metrics to identify bad smells and predict faults could provide useful insights for software quality assurance in startups.
https://www.sciencedirect.com/science/article/pii/S0950584919301259,Scaling-up domain-specific modelling languages through modularity services,Antonio=Garmendia: antonio.garmendia@uam.es,"Abstract
Context
Model-driven engineering (MDE) promotes the active use of models in all phases of software development. Even though models are at a high level of abstraction, large or complex systems still require building monolithic models that prove to be too big for their processing by existing tools, and too difficult to comprehend by users. While modularization techniques are well-known in programming languages, they are not the norm in MDE.
Objective
Our goal is to ease the modularization of models to allow their efficient processing by tools and facilitate their management by users.
Method
We propose five patterns that can be used to extend a 
modelling language
 with services related to modularization and scalability. Specifically, the patterns allow defining model fragmentation strategies, scoping and visibility rules, model indexing services, and scoped constraints. Once the patterns have been applied to the meta-model of a 
modelling language
, we synthesize a customized modelling environment enriched with the defined services, which become applicable to both existing monolithic legacy models and new models.
Results
Our proposal is supported by a tool called EMF-Splitter, combined with the Hawk model indexer. Our experiments show that this tool improves the validation performance of large models. Moreover, the analysis of 224 meta-models from 
OMG
 standards, and a public repository with more than 300 meta-models, demonstrates the applicability of our patterns in practice.
Conclusions
Modularity mechanisms typically employed in programming IDEs can be successfully transferred to MDE, leading to more scalable and structured domain-specific modelling languages and environments.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The proposal for modularization of models in MDE could benefit startups by improving the efficiency and scalability of software development.
https://www.sciencedirect.com/science/article/pii/S095058491930134X,Test case selection-prioritization approach based on memoization dynamic programming algorithm,Ovidiu=Banias: ovidiu.banias@aut.upt.ro,"Abstract
Context
In the software industry, selection and prioritization techniques become a necessity in the regression and validation testing phases because a lot of test cases are available for reuse, yet time and project specific constraints must be respected.
Objective
In this paper we propose a 
dynamic programming
 approach in solving test case selection-prioritization problems. We focus on low memory consumption in pseudo-polynomial time complexity applicable in both selection and selection-prioritization problems over sets of test cases or test suites. In 
dynamic programming
 optimization solutions, huge amounts of memory are required and unfortunately the memory is limited. Therefore, lower memory consumption leads to a higher number of test cases to be involved in the selection process.
Method
Our approach is suited for medium to large projects where the required memory space is not higher than the order of tens of GBytes. We employed both objective methods as the 
dynamic programming algorithm
 and subjective and empiric human decision as defining the prioritization criteria. Furthermore, we propose a method of employing multiple project specific criteria in evaluating the importance of a test case in the project context.
Results
To evaluate the proposed solution relative to the classical dynamic programming 
knapsack
 solution, we developed a suite of 
comparative case studies
 based on 1000 generated scenarios as close as possible to real project scenarios. The results of the comparative study reported the proposed algorithm requires up to 400 times less memory in the best-case scenarios and about 40 times less memory in average.
Conclusion
The solution delivers optimal results in pseudo-polynomial time complexity, is effective for amounts of test cases up to the order of millions and compared with the classical 
dynamic programming methods
 leads to higher number of test cases to be involved in the selection process due to reduced memory consumption.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The dynamic programming approach for test case selection and prioritization could be helpful for startups in optimizing testing processes with lower memory consumption.
https://www.sciencedirect.com/science/article/pii/S2352673421000135,A whole new world: Counterintuitive crowdfunding insights for female founders,Joakim=Wincent: joakim.wincent@hanken.fi; Henrik=Wesemann: henrik.wesemann@unisg.ch,"Abstract
Female entrepreneurs are subjected to stereotypes that make it difficult to secure funding. Crowdfunding challenges many of the causes of this discrimination but we know little about if and how it changes optimal funding strategies for female entrepreneurs. Using a sample of 3191 crowdfunding campaigns by female entrepreneurs, we draw from signaling theory to develop and test a series of counterintuitive conjectures for female crowdfunding success. Our results contradict advice that may be derived from traditional entrepreneurial 
finance
: women in crowdfunding should use their gender as advertising, use more female-centric language, avoid self-promotion, start businesses in male-dominated sectors, and ask for more money. These findings highlight new theoretical mechanisms in crowdfunding and develop recommendations for female entrepreneurs who want to raise funds.",June 2021,"Crowdfunding, Female entrepreneurship, Gender, Signaling theory",Business Venturing Insights,2025-03-21T00:00:00,8.0,"This abstract provides valuable insights into how female entrepreneurs can optimize their funding strategies through crowdfunding, challenging traditional advice. This has practical value for early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584919301363,Simsax: A measure of project similarity based on symbolic approximation method and software defect inflow,Mirosław=Ochodek: mochodek@cs.put.poznan.pl; Miroslaw=Staron: miroslaw.staron@cse.gu.se; Wilhelm=Meding: wilhelm.meding@ericsson.com,"Abstract
Background
Profiling software development projects, in order to compare them, find similar sub-projects or sets of activities, helps to monitor changes in software processes. Since we lack 
objective measures
 for profiling or hashing, researchers often fall back on manual assessments.
Objective
The goal of our study is to define an objective and intuitive measure of similarity between software development projects based on software defect-inflow profiles.
Method
We defined a measure of project similarity called 
SimSAX
 which is based on segmentation of defect-inflow profiles, coding them into strings (sequences of symbols) and comparing these strings to find so-called motifs. We use simulations to find and calibrate the parameters of the measure. The objects in the simulations are two different large industry projects for which we know the similarity a priori, based on the input from industry experts. Finally, we apply the measure to find similarities between five industrial and six 
open source projects
.
Results
Our results show that the measure provides the most accurate simulated results when the compared motifs are long (32 or more weeks) and we use an alphabet of 5 or more symbols. The measure provides the possibility to calibrate for each industrial case, thus allowing to optimize the method for finding specific patterns in project similarity.
Conclusions
We conclude that our proposed measure provides a 
good approximation
 for project similarity. The industrial evaluation showed that it can provide a 
good starting point
 for finding similar periods in software development projects.",November 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The SimSAX measure provides a method for comparing software development projects based on defect-inflow profiles, offering a way to find similarities and patterns. While useful, it may not have as direct of an impact on European early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919301387,An empirical study of sentiments in code reviews,Ikram El=Asri: ikram.asri@um5s.net.ma,"Abstract
Context
Modern code reviews are supported by tools to enhance developers’ interactions allowing contributors to submit their opinions for each committed change in form of comments. Although the comments are aimed at discussing potential technical issues, the text might enclose harmful sentiments that could erode the benefits of suggested changes.
Objective
In this paper, we study empirically the impact of sentiment embodied within developers’ comments on the time and outcome of the 
code review process
.
Method
Based on historical data of four long-lived Open Source Software (OSS) projects from a code review system we investigate whether perceived sentiments have any impact on the interval time of code changes acceptance.
Results
We found that (1) contributors frequently express positive and negative sentiments during code review activities; (2) the expressed sentiments differ among the contributors depending on their position within the social network of the reviewers (
e.g.,
 core vs peripheral contributors); (3) the sentiments expressed by contributors tend to be neutral as they progress from the status of newcomer in an OSS project to the status of core team contributors; (4) the reviews with negative comments on average took more time to complete than the reviews with positive/neutral comments, and (5) the reviews with controversial comments took significantly longer time in one project.
Conclusion
Through this work, we provide evidences that text-based sentiments have an impact on the duration of the 
code review process
 as well as the acceptance or rejection of the suggested changes.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,Studying the impact of sentiments in developers' comments on the code review process can provide valuable insights for software development teams. Understanding how sentiments affect review time and outcomes can lead to improved collaboration and decision-making in early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584919301430,A systematic mapping addressing Hyper-Heuristics within Search-based Software Testing,Juliana Marino=Balera: juliana.balera@inpe.br; Valdivino Alexandre de=Santiago Júnior: valdivino.santiago@inpe.br,"Abstract
Context
Search-based Software Testing
 (SBST) is a research field where testing a software product is formulated as an 
optimization problem
. It is an active sub-area of 
Search-based 
Software Engineering
 (SBSE) where many studies have been published and some reviews have been carried out. The majority of studies in SBST has been adopted meta-heuristics while hyper-heuristics have a long way to go. Moreover, there is still a lack of studies to perceive the state-of-the-art of the use of hyper-heuristics within SBST.
Objective
The objective of this work is to investigate the adoption of hyper-heuristics for Software Testing highlighting the current efforts and identifying new research directions.
Method
A 
Systematic mapping
 study was carried out with 5 research questions considering papers published up to may/2019, and 4 different bases. The research questions aims to find out, among other things, what are the hyper-heuristics used in the context of Software Testing, for what problems hyper-heuristics have been applied, and what are the objective functions in the scope of Software Testing.
Results
A total of 734 studies were found via the search strings and 164 articles were related to Software Testing. However, from these, only 26 papers were actually in accordance with the scope of this research and 3 more papers were considered due to snowballing or expert’s suggestion, totalizing 29 selected papers. Few different problems and application domains where hyper-heuristics have been considered were identified.
Conclusion
Differently from other communities (Operational Research, Artificial Intelligence), SBST has little explored the benefits of hyper-heuristics which include generalization and less difficulty in parameterization. Hence, it is important to further investigate this area in order to alleviate the effort of practitioners to use such an approach in their testing activities.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The abstract focuses on an important research area related to software testing and highlights the need for further investigation into hyper-heuristics, which could benefit European early-stage ventures by improving testing efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584919301399,Employment of multiple algorithms for optimal path-based test selection strategy,Miroslav=Bures: miroslav.bures@fel.cvut.cz; Bestoun S.=Ahmed: bestoun@kau.se,"Abstract
Context
Executing various sequences of 
system functions
 in a system under test represents one of the primary techniques in software testing. The natural method for creating effective, consistent and efficient test sequences is to model the system under test and employ an algorithm to generate tests that satisfy a defined test coverage criterion. Several criteria for preferred test set properties can be defined. In addition, to optimize the test set from an economic viewpoint, the priorities of the various parts of the system model under test must be defined.
Objective
Using this prioritization, the test cases exercise the high-priority parts of the system under test by more path combinations than those with low priority (this prioritization can be combined with the test coverage criterion that determines how many path combinations of the individual parts of the system are tested). Evidence from the literature and our observations confirm that finding a universal algorithm that produces a test set with preferred properties for all test coverage criteria is a challenging task. Moreover, for different individual problem instances, different algorithms provide results with the best value of a preferred property. In this paper, we present a portfolio-based strategy to perform the best test selection.
Method
The proposed strategy first employs a set of current algorithms to generate test sets; then, a preferred property of each test set is assessed in terms of the selected criterion, and finally, the test set with the best value of a preferred property is chosen.
Results
The experimental results confirm the validity and usefulness of this strategy. For individual instances of 50 system under test models, different algorithms provided results having the best preferred property value; these results varied by the required test coverage level, the size of the priority parts of the model, and the selected test set preferred property criteria.
Conclusion
In addition to the used algorithms, the proposed strategy can be used to assess the 
optimality
 of different path-based testing algorithms and choose a 
suitable algorithm
 for the testing.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The abstract presents a strategy for test selection which can be useful for startups in optimizing their testing processes, but the applicability may be limited to certain contexts."
https://www.sciencedirect.com/science/article/pii/S0950584919301417,Startup ecosystem effect on minimum viable product development in software startups,Nirnaya=Tripathi: nirnaya.tripathi@oulu.fi,"Abstract
Context
Software startups develop innovative products through which they scale their business rapidly, and thus, provide value to the economy, including job generation. However, most startups fail within two years of their launch because of a poor problem-solution fit and negligence of the learning process during 
minimum viable product
 (MVP) development. An ideal startup ecosystem can assist in MVP development by providing the necessary entrepreneurial education and technical skills to founding team members for identifying problem-solution fit for their product idea, allowing them to find the right product-market fit. However, existing knowledge on the effect of the startup ecosystem elements on the MVP development is limited.
Objective
The empirical study presented in this article aims to identify the effect of the six ecosystem elements (entrepreneurs, technology, market, support factors, finance, and human capital) on MVP development.
Method
We conducted a study with 13 software startups and five supporting organizations (accelerators, 
incubator
, co-working space, and investment firm) in the startup ecosystem of the city of Oulu in Finland. Data were collected through semi-structured interviews, observation, and materials.
Results
The study results showed that 
internal sources
 are most common for identifying requirements for the product idea for MVP development. The findings indicate that supporting factors, such as incubators and accelerators, can influence MVP development by providing young founders with the necessary entrepreneurship skills and education needed to create the right product-market fit.
Conclusions
We conclude from this study of a regional startup ecosystem that the 
MVP development process
 is most affected by founding team members’ experiences and skill sets and by advanced technologies. Furthermore, a constructive startup ecosystem around software startups can boost up the creation of an effective MVP to test product ideas and find a product-market fit.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"This abstract addresses a critical issue faced by software startups regarding MVP development and the role of ecosystem elements, providing practical insights that can directly benefit European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919301405,On the use of virtual reality in software visualization: The case of the city metaphor,Simone=Romano: simone.romano@uniba.it; Giuseppe=Scanniello: giuseppe.scanniello@unibas.it; Nicola=Capece: nicola.capece@unibas.it; Ugo=Erra: ugo.erra@unibas.it; Michele=Lanza: michele.lanza@usi.ch,"Abstract
Background:
 Researchers have been exploring 3D representations for visualizing software. Among these representations, one of the most popular is the 
city metaphor
, which represents a target object-oriented system as a virtual city. Recently, this metaphor has been also implemented in interactive software visualization tools that use virtual reality in an immersive 3D environment medium.
Aims:
 We assessed the city metaphor displayed on a standard 
computer screen
 and in an 
immersive virtual reality
 with respect to the support provided in the comprehension of Java software systems.
Method:
 We conducted a controlled experiment where we asked the participants to fulfill 
program comprehension
 tasks with the support of 
(i)
 an 
integrated development environment
 (Eclipse) with a plugin for gathering 
code metrics
 and identifying bad smells; and 
(ii)
 a visualization tool of the city metaphor displayed on a standard 
computer screen
 and in an 
immersive virtual reality
.
Results:
 The use of the city metaphor displayed on a standard computer screen and in an immersive virtual reality significantly improved the correctness of the solutions to 
program comprehension
 tasks with respect to Eclipse. Moreover, when carrying out these tasks, the participants using the city metaphor displayed in an immersive virtual reality were significantly faster than those visualizing with the city metaphor on a standard computer screen.
Conclusions:
 Virtual reality is a viable means for software visualization.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract discusses the use of virtual reality for software visualization, which could have potential applications for startups in enhancing their development processes, but the direct impact may be more limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919301351,A novel approach for automatic remodularization of software systems using extended ant colony optimization algorithm,Bright Gee=Varghese R: brightachus@karunya.edu; Kumudha=Raimond: kraimond@karunya.edu; Jeno=Lovesum: jenolovesum@karunya.edu,"Abstract
Context
Software modularization is extremely important to streamline the inner structure of the program modules without influencing its 
core functionality
. As the framework advances during the upkeep stage, the pristine design of the software package gets disintegrated and hence it is arduous to understand and maintain. There are many existing approaches being carried out to automatically remodularize using optimization techniques to ease the maintenance and improve the quality of the system. The outcomes are rather insufficiently optimal and depend on problem-specific operators, which in turn expands the time multifaceted nature to land at an answer. Apart from these limitations, the issues, such as time complexity, scalability and performance need to be addressed.
Objective
In this paper, an efficient automatic software remodularization using extended 
Ant Colony Optimization
 (ACO) has been proposed to remodularize the software systems.
Method
The proposed approach mainly includes two phases: optimised traversal of software system using ACO for finding the order of software files to be processed and remodularization of software system using the proposed approach of extended ACO.
Results
We experimented our proposed approach on seven software systems. The performance is evaluated by using Turbo modularization quality (MQ) which supports 
Module dependency
 graph (MDG) that have edge weights. The time complexity of remodularized software system is evaluated based on number of Turbo MQ.
Conclusion
It can be concluded that when the performance has been compared with the subsisting methodologies, for example, 
Genetic algorithm
 (GA), Hill climbing (HC) and Interactive genetic algorithms (I-GAs), the proposed approach has higher Turbo MQ value with lesser time complexity in the evaluated software systems.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The proposed approach of automatic software remodularization using extended Ant Colony Optimization can have a significant impact on improving the quality of software systems. The experimentation on seven software systems and comparison with existing methodologies show promising results.
https://www.sciencedirect.com/science/article/pii/S0950584919301454,Scheduling sequence selection for generating test data to cover paths of MPI programs,Dunwei=Gong: dwgong@vip.163.com,"Abstract
Context: As one of key tasks in software testing, test data generation has been receiving widespread attention in recent years. Message-passing Interface (MPI) programs, which are one representative type of parallel programs, have the characteristic of non-determinism, which is reflected by the non-deterministic execution under different scheduling sequences against the same program input. Previous studies have shown that different difficulties are raised in generating test data under different scheduling sequences, suggesting that selecting appropriate scheduling sequences is beneficial to a high efficiency.
Objective: We propose a method of selecting a superior and feasible scheduling sequence for generating test data in the criterion of path coverage against each target path of an MPI program.
Method: In the proposed method, a number of program inputs are first sampled by Latin 
hypercube
 sampling. Then, the program is executed against each sample under each scheduling sequence, and all the scheduling sequences are sorted according to the similarities between the paths traversed by these samples and the target one. Finally, the feasibility of a scheduling sequence with the best quality is investigated based on the symbolic execution.
Results: We apply the proposed method to seven typical MPI programs and compare it with the random one. The experimental results show that test data covering the target path can be generated under the selected scheduling sequence with high success rate and low time consumption.
Conclusion: The proposed method takes the influence of scheduling sequences on generating test data into consideration, thus providing a competent way to test parallel programs.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The method of selecting a scheduling sequence for test data generation in MPI programs addresses an important issue, but the impact may not be as significant for a wider range of European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584917302793,DevOps in practice: A multiple case study of five companies,Lucy Ellen=Lwakatare: lucylwakatare@yahoo.com,"Abstract
Context:
 
DevOps
 is considered important in the ability to frequently and reliably update a system in operational state. 
DevOps
 presumes cross-functional collaboration and automation between software development and operations. DevOps adoption and implementation in companies is non-trivial due to required changes in technical, organisational and cultural aspects.
Objectives:
 This 
exploratory study
 presents detailed descriptions of how DevOps is implemented in practice. The context of our empirical investigation is web application and service development in 
small and medium sized companies
.
Method:
 A multiple-case study was conducted in five different development contexts with successful DevOps implementations since its benefits, such as quick releases and minimum deployment errors, were achieved. Data was mainly collected through interviews with 26 practitioners and observations made at the companies. Data was analysed by first coding each case individually using a set of predefined themes and thereafter perform a cross-case synthesis.
Results:
 Our analysis yielded some of the following results: (i) software development team attaining ownership and responsibility to deploy software changes in production is crucial in DevOps. (ii) toolchain usage and support in deployment pipeline activities accelerates the delivery of software changes, bug fixes and handling of production incidents. (ii) the delivery speed to production is affected by context factors, such as manual approvals by the product owner (iii) steep 
learning curve
 for new skills is experienced by both software developers and operations staff, who also have to cope with working under pressure.
Conclusion:
 Our findings contributes to the overall understanding of DevOps concept, practices and its perceived impacts, particularly in 
small and medium sized companies
. We discuss two practical implications of the results.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The detailed exploration of DevOps implementation in small and medium sized companies provides valuable insights into the practical challenges and benefits. The study contributes to the understanding of DevOps impact on software development processes.
https://www.sciencedirect.com/science/article/pii/S0950584918301216,"A large-scale, in-depth analysis of developers’ personalities in the Apache ecosystem",Fabio=Calefato: fabio.calefato@uniba.it; Filippo=Lanubile: filippo.lanubile@uniba.it; Bogdan=Vasilescu: vasilescu@cmu.edu,"Abstract
Context
Large-scale distributed projects are typically the results of collective efforts performed by multiple developers with heterogeneous personalities.
Objective
We aim to find evidence that personalities can explain developers’ behavior in large scale-distributed projects. For example, the propensity to trust others — a critical factor for the success of global 
software engineering
 — has been found to influence positively the result of code reviews in distributed projects.
Method
In this paper, we perform a quantitative analysis of ecosystem-level data from the code commits and email messages contributed by the developers working on the Apache Software Foundation (ASF) projects, as representative of large scale-distributed projects.
Results
We find that there are three common types of personality profiles among Apache developers, characterized in particular by their level of Agreeableness and Neuroticism. We also confirm that developers’ personality is stable over time. Moreover, personality traits do not vary with their role, membership, and extent of contribution to the projects. We also find evidence that more open developers are more likely to make contributors to Apache projects.
Conclusion
Overall, our findings reinforce the need for future studies on human factors in 
software engineering
 to use psychometric tools to control for differences in developers’ personalities.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The analysis of developers' personalities in large scale-distributed projects is interesting, but the practical implications for European early-stage ventures and startups may not be as direct or immediately impactful."
https://www.sciencedirect.com/science/article/pii/S0950584918301228,Resilience of distributed student teams to stress factors: A longitudinal case-study,Igor=Čavrak: igor.cavrak@fer.hr,"Abstract
Context:
 Teaching global 
software engineering
 is continuously evolving and improving to prepare future software engineers adequately. Geographically distributed work in project-oriented software development courses is both demanding and rewarding for student teams, who are susceptible to various risks stemming from different internal and external factors, being the sources of stress and impacting team performance.
Objective:
 In this paper, we analyze the resilience of teams of students working in a geographically fully distributed setting. Resilience is analyzed in relation to two representative stress factors: non-contributing team members and changes to customer project requirements. We also reason on team collaboration patterns and analyze potential dependencies among these collaboration patterns, team resilience and stress factors.
Method:
 We conduct a longitudinal case-study over five years on our Distributed Software Development (DSD) course. Based on empirical data, we study team resilience to two stress factors by observing their impact on process and product 
quality aspects
 of team performance. The same performance aspects are studied for identified collaboration patterns, and bidirectional influence between patterns and resilience is investigated.
Results:
 Teams with up to two non-contributing members experience 
graceful degradation
 of performance indicators. A large number of non-contributing students almost guarantees the occurrence of educationally undesirable collaboration patterns. Exposed to requirements change stress, less resilient teams tend to focus on delivering the functional product rather than retaining a proper 
development process
.
Conclusions:
 Practical recommendations to be applied in contexts similar to our case have been provided at the end of the study. They include suggestions to mitigate the sources of stress, for example, by careful planning the team organization and balancing the number of regular and exchange students, or by discussing the issue of changing requirements with the external customers before the start of the project.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The analysis of team resilience in geographically distributed settings can offer practical recommendations for startups facing similar challenges, thereby enhancing their team performance and project outcomes."
https://www.sciencedirect.com/science/article/pii/S0950584918301721,Pareto efficient multi-objective black-box test case selection for simulation-based testing,Aitor=Arrieta: aarrieta@mondragon.edu; Shuai=Wang: shuai.wang@testify.no; Urtzi=Markiegi: umarkiegi@mondragon.edu; Ainhoa=Arruabarrena: eibek03@mondragon.edu; Leire=Etxeberria: letxeberria@mondragon.edu; Goiuria=Sagardui: gsagardui@mondragon.edu,"Abstract
Context:
 In many domains, engineers build simulation models (e.g., Simulink) before developing code to simulate the behavior of complex systems (e.g., Cyber-Physical Systems). Those models are commonly heavy to simulate which makes it difficult to execute the entire test suite. Furthermore, it is often difficult to measure white-box coverage of test cases when employing such models. In addition, the 
historical data
 related to failures might not be available.
Objective:
 The objective of the approach presented in this paper is to cost-effectively select test cases without making use of white-box coverage information or 
historical data
 related to fault detection.
Method:
 We propose a cost-effective approach for test case selection that relies on black-box data related to inputs and outputs of the system. The approach defines in total six effectiveness measures and one cost measure followed by deriving in total 21 objective combinations and integrating them within Non-Dominated Sorting Genetic Algorithm-II (NSGA-II). The proposed six effectiveness metrics are specific to simulation models and are based on anti-patterns and similarity measures.
Results:
 We empirically evaluated our approach with these 21 combinations using six 
case studies
 by employing mutation testing to assess the fault revealing capability. We compared our approach with Random Search (RS), two many-objective algorithm, as well as three white-box metrics. The results demonstrated that our approach managed to improve Random Search by up to around 28% in terms of the Hypervolume quality indicator. Similarly, black-box metrics-based test case selection also significantly outperformed those of white-box metrics.
Conclusion:
 We demonstrate that test case selection is a non-trivial problem in the context of simulation models. We also show that the proposed effectiveness metrics performed significantly better than traditional white-box metrics. Thus, we show that black-box test selection approaches are appropriate to solve the test case selection problem within simulation models.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The cost-effective approach for test case selection in simulation models can significantly benefit startups by improving testing efficiency and fault detection, thus optimizing software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584918301630,Standing on the shoulders of giants: Seeding search-based multi-objective optimization with prior knowledge for software service composition,Tao=Chen: txc919@gmail.com; Miqing=Li: m.li.8@cs.bham.ac.uk,"Abstract
Context
Search-Based 
Software Engineering
, in particular multi-objective 
evolutionary algorithm
, is a promising approach to engineering software service composition while simultaneously optimizing multiple conflicting Quality-of-Service (QoS) objectives. Yet, existing applications of 
evolutionary algorithms
 have failed to consider domain knowledge about the problem into the optimization, which is a perhaps obvious but challenging task.
Objective
This paper aims to investigate different strategies of exploring and injecting knowledge about the problem into the Multi-Objective Evolutionary Algorithm (MOEA) by 
seeding
. Further, we investigate various factors that contribute to the effectiveness of seeding, including the number of seeds, the importance of crossover operation and the similarity of historical problems.
Method
We conduced empirical evaluations with NSGA-II, MOEA/D and IBEA based on a wide spectrum of problem instances, including 10 different workflow structures, from 5 to 100 abstract services and 510 to 5.529  × 10
203
 candidate concrete services with diverse QoS on latency, throughput and cost, which was chosen from the real-world WS-DREAM dataset that contains 4500 QoS values.
Results
We found that, (i) all seeding strategies generally outperform their non-seeded counterparts under the same search budget with large statistical significance. Yet, they may involve relatively smaller compromise on one or two of the 
quality aspects
 among convergence, uniformity and spread. (ii) The implication of the number of seeds on the service 
composition problems
 is minimal in general (except for IBEA). (iii) In contrast to the non-seeded counterparts, the seeding strategies suffer much less implications by the crossover operation. (iv) The differences of historical problems, which are important for two proposed seeding strategies, can indeed affect the results in a non-linear manner; however, the results are still greatly better than the non-seeded counterparts even with up to 90% difference of the problem settings.
Conclusion
The paper concludes that (i) When applying the seeding strategies, the number of seeds to be placed in is less important in general, except for the pre-optimization based strategies under IBEA. (ii) Eliminating or having less crossover is harmful for multi-objective service composition optimization, but the seeding strategies are much less sensitive to this operator than their non-seeded counterparts. (iii) For the history based seeding strategies, the seeds do not have to come from the most similar historical composition problem to achieve the best HV value, but a largely different historical problem should usually be avoided, unless they are the only available seeds.",October 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,Investigating strategies for injecting domain knowledge into evolutionary algorithms for software composition optimization can be highly beneficial for startups aiming to enhance the quality of their software services while optimizing multiple QoS objectives.
https://www.sciencedirect.com/science/article/pii/S0950584919300990,A systematic literature review of test breakage prevention and repair techniques,Javaria=Imtiaz: javaria.imtiaz@questlab.pk; Salman=Sherin: salman.sherin@questlab.pk; Muhammad Uzair=Khan: uzair.khan@questlab.pk; Muhammad Zohaib=Iqbal: zohaib.iqbal@questlab.pk,"Abstract
Context
When an application evolves, some of the developed test cases break. Discarding broken test cases causes a significant waste of effort and leads to test suites that are less effective and have lower coverage. Test repair approaches evolve test suites along with applications by repairing the broken test cases.
Objective
Numerous studies are published on test repair approaches every year. It is important to summarise and consolidate the existing knowledge in the area to provide directions to researchers and practitioners. This research work provides a systematic literature review in the area of test case repair and breakage prevention, aiming to guide researchers and practitioners in the field of software testing.
Method
We followed the standard protocol for conducting a systematic literature review. First, research goals were defined using the Goal Question Metric (GQM). Then we formulate research questions corresponding to each goal. Finally, metrics are extracted from the included papers. Based on the defined selection criteria a final set of 41 primary studies are included for analysis.
Results
The selection process resulted in 5 journal papers, and 36 
conference papers
. We present a taxonomy that lists the causes of test case breakages extracted from the literature. We found that only four proposed test repair tools are publicly available. Most studies evaluated their approaches on open-source 
case studies
.
Conclusion
There is significant room for future research on test repair techniques. Despite the positive trend of evaluating approaches on large scale open source studies, there is a clear lack of results from studies done in a real industrial context. Few tools are publicly available which lowers the potential of adaption by industry practitioners.",September 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The systematic literature review on test case repair and breakage prevention provides valuable insights for researchers and practitioners in the field of software testing. However, the lack of real industrial context studies and limited availability of test repair tools slightly limit the immediate practical impact."
https://www.sciencedirect.com/science/article/pii/S095058491930103X,Adopting configuration management principles for managing experiment materials in families of experiments,Silvia T.=Acuña: silvia.acunna@uam.es; Sira=Vegas: svegas@fi.upm.es; Natalia=Juristo: natalia@fi.upm.es; Edison=Espinosa: egespinosa1@espe.edu.ec,"Abstract
Context
Replication is a key component of experimentation for verifying previous results and findings. Experiment replication requires products like documentation describing the baseline experiment and a version of the experimental material. When replicating an experiment, changes may have to be made to some of the products, leading to new or modified versions of materials. After the replication has been conducted, part of or all the materials should be added to the family history or to the baseline experiment documentation. As the number of replications increases, more versions of the materials are generated. This can lead to product management chaos in replications sharing the same protocol.
Objective
The aim of this paper is to adopt 
configuration management
 principles to manage experimental materials. We apply and validate these principles in a code inspection technique comparison experiment and a personality quasi-experiment.
Method
The study was conducted within a research group with lengthy experience in experiment replication. This research group has had trouble with the management of the materials used to run some of the experiments replicated by other colleagues. This is a suitable context for applying action research. We used action research to adopt the 
configuration management
 principles and build a materials management framework.
Result
We generated the instances of an experiment and a quasi-experiment, identifying the status and traceability of the materials. Additionally, we documented the workload required for 
instantiation
 in person-hours. We also checked the ease of use and understanding of the framework for instantiating the personality quasi-experiment configuration plan executed by researchers who did not develop the framework, as well as its usefulness for managing the experimental materials.
Conclusion
The experimental materials management framework is useful for establishing the status and traceability of the experimental materials. Additionally, it improves the storage, search, location and retrieval of the experimental material versions.",September 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"The experimental materials management framework is useful for establishing the status and traceability of experimental materials, improving storage and retrieval. However, the focus on a specific research group's experience may limit generalizability and widespread practical applicability."
https://www.sciencedirect.com/science/article/pii/S0950584919301053,Multi-armed bandits in the wild: Pitfalls and strategies in online experiments,Jan=Bosch: jan.bosch@chalmers.se; David=Issa Mattos: davidis@chalmers.se; Helena Holmström=Olsson: helena.holmstrom.olsson@mah.se,"Abstract
Context
Delivering faster value to customers with online experimentation is an emerging practice in industry. Multi-Armed Bandit (MAB) based experiments have the potential to deliver even faster results with a better allocation of resources over traditional A/B experiments. However, the incorrect use of MAB-based experiments can lead to incorrect conclusions that can potentially hurt the company's business.
Objective
The objective of this study is to understand the pitfalls and restrictions of using MABs in online experiments, as well as the strategies that are used to overcome them.
Method
This research uses a multiple 
case study method
 with eleven experts across five software companies and simulations to triangulate the data of some of the identified limitations.
Results
This study analyzes some limitations faced by companies using MAB and discusses strategies used to overcome them. The results are summarized into practitioners’ guidelines with criteria to select an appropriated 
experimental design
.
Conclusion
MAB algorithms have the potential to deliver even faster results with a better allocation of resources over traditional A/B experiments. However, potential mistakes can occur and hinder the 
potential benefits
 of such approach. Together with the provided guidelines, we aim for this paper to be used as reference material for practitioners during the design of an online experiment.",September 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,Understanding the pitfalls and restrictions of using Multi-Armed Bandit (MAB) experiments and providing guidelines for selecting experimental designs can significantly impact companies engaging in online experiments. The practical implications of avoiding potential mistakes and improving resource allocation make this study highly valuable.
https://www.sciencedirect.com/science/article/pii/S0950584919301156,Specifying quantities in software models,Loli=Burgueño: lburguenoc@uoc.edu,"Abstract
Context
An essential requirement for the design and development of any 
engineering application
 that deals with real-world 
physical systems
 is the formal representation and processing of 
physical quantities
, comprising both measurement uncertainty and units. Although solutions exist for several programming languages and simulation frameworks, this problem has not yet been fully solved for software models.
Objective
This paper shows how both measurement uncertainty and units can be effectively incorporated into software models, becoming part of their basic type systems.
Method
We introduce the main concepts and mechanisms needed for representing and handling 
physical quantities
 in software models. More precisely, we describe an extension of basic type Real, called Quantity, and a set of operations defined for the values of that type, together with a ready-to-use library of 
dimensions and units
, which can be added to any modeling project.
Results
We show how our approach permits modelers to safely represent and operate with physical quantities, statically ensuring type- and unit-safe assignments and operations, prior to any simulation of the system or implementation in any programming language.
Conclusion
Our approach improves the 
expressiveness
 and type-safety of software models with respect to measurement uncertainty and units of physical quantities, and its effective use in modeling projects of 
physical systems
.",September 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"Incorporating measurement uncertainty and units into software models can enhance type-safety and expressiveness in representing physical quantities, benefiting engineering applications. The proposed Quantity type and operations provide a practical solution, although the application in real-world projects needs further validation."
https://www.sciencedirect.com/science/article/pii/S0950584919300904,Dynamic selection of fitness function for software change prediction using Particle Swarm Optimization,Ruchika=Malhotra: ruchikamalhotra@dtu.ac.in,"Abstract
Context
Over the past few years, researchers have been actively searching for an effective classifier which correctly predicts change prone classes. Though, few researchers have ascertained the predictive capability of search-based algorithms in this domain, their effectiveness is highly dependent on the selection of an optimum fitness function. The criteria for selecting one fitness function over the other is the improved predictive capability of the developed model on the entire dataset. However, it may be the case that various subsets of instances of a dataset may give best results with a different fitness function.
Objective
The aim of this study is to choose the best fitness function for each instance rather than the entire dataset so as to create models which correctly ascertain the change prone nature of majority of instances. Therefore, we propose a novel framework for the adaptive selection of a dynamic optimum fitness function for each instance of the dataset, which would correctly determine its change prone nature.
Method
The 
predictive models
 in this study are developed using seven different fitness variants of Particle Swarm Optimization (PSO) algorithm. The proposed framework predicts the best suited fitness variant amongst the seven investigated fitness variants on the basis of structural characteristics of a corresponding instance.
Results
The results of the study are empirically validated on fifteen datasets collected from popular open-source software. The proposed adaptive framework was found efficient in determination of change prone classes as it yielded improved results when compared with models developed using individual fitness variants and fitness-based voting 
ensemble classifiers
.
Conclusion
The performance of the models developed using the proposed adaptive framework were statistically better than the models developed using individual fitness variants of PSO algorithm and competent to models developed using 
machine learning
 
ensemble classifiers
.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study proposes a novel framework for adaptive selection of fitness functions in predictive models, which could greatly impact the effectiveness of change prone class determination in software development."
https://www.sciencedirect.com/science/article/pii/S095058491930117X,An HMM-based approach for automatic detection and classification of duplicate bug reports,Abdelwahab=Hamou-Lhadj: abdelw@ece.concordia.ca; Neda=Ebrahimi: n_ebr@ece.concordia.ca; Abdelaziz=Trabelsi: trabelsi@ece.concordia.ca; Md. Shariful=Islam: mdsha_i@ece.concordia.ca; Kobra=Khanmohammadi: k_khanm@ece.concordia.ca,"Abstract
Context
Software projects rely on their issue tracking systems to guide maintenance activities of software developers. 
Bug reports
 submitted to the issue tracking systems carry crucial information about the nature of the crash (such as texts from users or developers and execution information about the running functions before the occurrence of a crash). Typically, big software projects receive thousands of reports every day.
Objective
The aim is to reduce the time and effort required to fix bugs while improving software quality overall. Previous studies have shown that a large amount of bug reports are duplicates of previously reported ones. For example, as many as 30% of all reports in for Firefox are duplicates.
Method
While there exist a wide variety of approaches to automatically detect duplicate bug reports by 
natural language processing
, only a few approaches have considered execution information (the so-called stack traces) inside bug reports. In this paper, we propose a novel approach that automatically detects duplicate bug reports using stack traces and Hidden Markov Models.
Results
When applying our approach to Firefox and GNOME datasets, we show that, for Firefox, the average recall for Rank 
k
 = 1 is 59%, for Rank 
k
 = 2 is 75.55%. We start reaching the 90% recall from 
k
 = 10. The 
Mean Average Precision
 (MAP) value is up to 76.5%. For GNOME, The recall at 
k
 = 1 is around 63%, while this value increases by about 10% for 
k
 = 2. The recall increases to 97% for 
k
 = 11. A MAP value of up to 73% is achieved.
Conclusion
We show that HMM and stack traces are a powerful combination for detecting and classifying duplicate bug reports in large bug repositories.",September 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The novel approach of automatically detecting duplicate bug reports using stack traces and Hidden Markov Models shows promising results with high recall rates and Mean Average Precision values for large bug repositories like Firefox and GNOME. The potential to significantly reduce time and effort required to fix bugs and improve software quality makes this study highly impactful.
https://www.sciencedirect.com/science/article/pii/S0950584919301223,On the use of usage patterns from telemetry data for test case prioritization,Jeff=Anderson: jeffand@microsoft.com; Maral=Azizi: maraazizi@my.unt.edu; Saeed=Salem: saeed.salem@ndsu.edu; Hyunsook=Do: hyunsook.do@unt.edu,"Abstract
Context
Modern applications contain pervasive telemetry to ensure reliability and enable monitoring and diagnosis. This presents a new opportunity in the area of regression testing techniques, as we now have the ability to consider usage profiles of the software when making decisions on test execution.
Objective
The results of our prior work on test prioritization using telemetry data showed improvement rate on test suite reduction, and test 
execution time
. The objective of this paper is to further investigate this approach and apply prioritization based on multiple prioritization algorithms in an enterprise level cloud application as well as 
open source projects
. We aim to provide an effective prioritization scheme that practitioners can implement with minimum effort. The other objective is to compare the results and the benefits of this technique factors with code coverage-based prioritization approaches, which is the most commonly used test prioritization technique.
Method
We introduce a method for identifying usage patterns based on telemetry, which we refer to as “telemetry fingerprinting.” Through the use of various algorithms to compute fingerprints, we conduct empirical studies on multiple software products to show that telemetry fingerprinting can be used to more effectively prioritize 
regression tests
.
Results
Our experimental results show that the proposed techniques were able to reduce over 30% in regression test suite run times compared to the coverage-based prioritization technique in detecting discoverable faults. Further, the results indicate that fingerprints are effective in identifying usage patterns, and that the fingerprints can be applied to improve regression testing techniques.
Conclusion
In this research, we introduce the concept of fingerprinting software usage patterns through telemetry. We provide various algorithms to compute fingerprints and conduct empirical studies that show that fingerprints are effective in identifying distinct usage patterns. By applying these techniques, we believe that regression testing techniques can be improved beyond the current state-of-the-art, yielding additional cost and quality benefits.",September 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The paper introduces a novel approach in regression testing techniques using telemetry data, showing significant improvements in test suite reduction and execution time, which can benefit early-stage ventures by improving testing efficiency and quality."
https://www.sciencedirect.com/science/article/pii/S0950584919300709,Ranking of software developers based on expertise score for bug triaging,Asmita=Yadav: asmita.yadav85@gmail.com; Sandeep Kumar=Singh: sandeepk.singh@jiit.ac.in,"Abstract
Context
Existing bug triage approaches for developer recommendation systems are mainly based on 
machine learning
 (ML) techniques. These approaches have shown low prediction accuracy and high bug tossing length (BTL).
Objective
The objective of this paper is to develop a robust algorithm for reducing BTL based on the concept of developer expertise score (DES).
Method
None of the existing approaches to the best of our knowledge have utilized metrics to build developer expertise score. The novel strategy of DES is consisted of two stages: Stage-I consisted of an offline process for detecting the developers based on DES which computes the score using priority, versatility and average fix-time for his individual contributions. The online system process consisted of finding the capable developers using three kinds of similarity measures (feature-based, cosine-similarity and Jaccard). Stage-II of the online process consisted of simply ranking the developers. Hit-ratio and reassignment accuracy were used for performance evaluation. We compared our system against the ML-based bug triaging approaches using three types of classifiers: Navies Bayes, Support Vector Machine and C4.5 paradigms.
Results
By adapting the five open source databases, namely: Mozilla, Eclipse, Netbeans, Firefox, and Freedesktop, covering 41,622 
bug reports
, our novel DES system yielded a mean accuracy, precision, recall rate and F-score of 
89.49%, 89.53%, 89.42%
 and 
89.49%
, respectively, reduced BTLs of up to 
88.55%
. This demonstrates an improvement of up to 
20%
 over existing strategies.
Conclusion
This work presented a novel developer recommendation algorithm to rank the developers based on a metric-based integrated score for bug triaging. This integrated score was based on the developer's expertise with an objective to improve (i) bug assignment and (ii) reduce the bug tossing length. Such architecture has an application in software bug triaging frameworks.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The paper presents a robust algorithm for bug triage based on developer expertise score, showing a high level of accuracy and significantly reduced bug tossing length, which could have a substantial impact on startups by improving bug resolution efficiency."
https://www.sciencedirect.com/science/article/pii/S095058491930076X,“Bad smells” in software analytics papers,Tim=Menzies: timm@ieee.org,"Abstract
Context
There has been a rapid growth in the use of 
data analytics
 to underpin evidence-based 
software engineering
. However the combination of complex techniques, diverse reporting standards and poorly understood underlying phenomena are causing some concern as to the reliability of studies.
Objective
Our goal is to provide guidance for producers and consumers of 
software analytics
 studies (computational experiments and correlation studies).
Method
We propose using “bad smells”, i.e., surface indications of deeper problems and popular in the agile software community and consider how they may be manifest in 
software analytics
 studies.
Results
We list 12 “bad smells” in software analytics papers (and show their impact by examples).
Conclusions
We believe the metaphor of bad smell is a useful device. Therefore we encourage more debate on what contributes to the validity of software analytics studies (so we expect our list will mature over time).",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The paper addresses concerns about the reliability of software analytics studies but does not provide a concrete solution or improvement for early-stage ventures, hence the score is lower."
https://www.sciencedirect.com/science/article/pii/S0950584919300771,A critical appraisal tool for systematic literature reviews in software engineering,Nauman Bin=Ali: nauman.ali@bth.se; Muhammad=Usman: muu@bth.se,"Abstract
Context:
 Methodological research on 
systematic literature reviews
 (SLRs) in 
Software Engineering
 (SE) has so far focused on developing and evaluating guidelines for conducting 
systematic reviews
. However, the support for quality assessment of completed SLRs has not received the same level of attention.
Objective:
 To raise awareness of the need for a critical appraisal tool (CAT) for assessing the quality of SLRs in SE. To initiate a community-based effort towards the development of such a tool.
Method:
 We reviewed the literature on the quality assessment of SLRs to identify the frequently used CATs in SE and other fields. 
Results:
 We identified that the CATs currently used is SE were borrowed from medicine, but have not kept pace with substantial advancements in the field of medicine.
Conclusion:
 In this paper, we have argued the need for a CAT for quality appraisal of SLRs in SE. We have also identified a tool that has the potential for application in SE. Furthermore, we have presented our approach for adapting this state-of-the-art CAT for assessing SLRs in SE.",August 2019,"Systematic literature reviews, Quality assessment, Software engineering, Critical appraisal tools, AMSTAR",Information and Software Technology,2025-03-18T00:00:00,6.0,"The paper highlights the need for a critical appraisal tool for assessing the quality of systematic literature reviews in Software Engineering, which can be beneficial for startups in understanding and evaluating existing research but does not directly impact their operations."
https://www.sciencedirect.com/science/article/pii/S0950584919300898,Towards a reduction in architectural knowledge vaporization during agile global software development,Gilberto=Borrego: gilberto.borrego@uabc.edu.mx,"Abstract
Context
The adoption of agile methods is a trend in 
global software development
 (GSD), but may result in many challenges. One important challenge is architectural knowledge (AK) management, since agile developers prefer 
sharing knowledge
 through face-to-face interactions, while in GSD the preferred manner is documents. Agile knowledge-sharing practices tend to predominate in GSD companies that practice 
agile development
 (AGSD), leading to a lack of documents, such as 
architectural designs
, data models, deployment specifications, etc., resulting in the loss of AK over time, i.e., it vaporizes.
Objective
In a previous study, we found that there is important AK in the log files of unstructured textual electronic media (UTEM), such as instant messengers, emails, forums, etc., which are the preferred means employed in AGSD to contact remote teammates. The objective of this paper is to present and evaluate a proposal with which to recover AK from UTEM logs. We developed and evaluated a prototype that implements our proposal in order to determine its feasibility.
Method
The evaluation was performed by conducting a study with agile/global developers and students, who used the prototype and different UTEM to execute tasks that emulate common situations concerning AGSD teams’ lack of documentation during development phases.
Results
Our prototype was considered a useful, usable and unobtrusive tool when retrieving AK from UTEM logs. The participants also preferred our prototype when searching for AK and found AK faster with the prototype than with UTEM when the origin of the AK required was unknown.
Conclusion
The participants’ performance and perceptions when using our prototype provided evidence that our proposal could reduce AK vaporization in AGSD environments. These results encourage us to evaluate our proposal in a long-term test as future work.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The prototype developed to recover architectural knowledge from unstructured textual electronic media was considered useful and could potentially reduce knowledge loss in agile/global software development environments.
https://www.sciencedirect.com/science/article/pii/S0950584919300928,A Community Strategy Framework – How to obtain influence on requirements in meritocratic open source software communities?,J.=Linåker: johan.linaker@cs.lth.se; B.=Regnell: bjorn.regnell@cs.lth.se; D.=Damian: damian.daniela@gmail.com,"Abstract
Context:
 In the 
Requirements Engineering
 (RE) process of an 
Open Source Software
 (OSS) community, an involved firm is a stakeholder among many. Conflicting agendas may create miss-alignment with the firm’s internal requirements strategy. In communities with meritocratic governance or with aspects thereof, a firm has the opportunity to affect the RE process in line with their own agenda by gaining influence through active and symbiotic engagements.
Objective:
 The focus of this study has been to identify what aspects that firms should consider when they assess their need of influencing the RE process in an OSS community, as well as what engagement practices that should be considered in order to gain this influence.
Method:
 Using a design science approach, 21 interviews with 18 industry professionals from 12 different software-intensive firms were conducted to explore, design and validate an artifact for the problem context.
Results:
 A Community Strategy Framework (CSF) is presented to help firms create community strategies that describe if and why they need influence on the RE process in a specific (meritocratic) OSS community, and how the firm could gain it. The framework consists of aspects and engagement practices. The aspects help determine how important an 
OSS project
 and its community is from business and technical perspectives. A community perspective is used when considering the feasibility and potential in gaining influence. The engagement practices are intended as a tool-box for how a firm can engage with a community in order to build influence needed.
Conclusion:
 It is concluded from interview-based validation that the proposed CSF may provide support for firms in creating and tailoring community strategies and help them to focus resources on communities that matter and gain the influence needed on their respective RE processes.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The Community Strategy Framework presented in the study could assist firms in gaining influence on the Requirements Engineering process in Open Source Software communities, but its practical application and impact may vary."
https://www.sciencedirect.com/science/article/pii/S0950584919300941,Enhancing context specifications for dependable adaptive systems: A data mining approach,Arthur=Rodrigues: arthy.rf@gmail.com; Genaína Nunes=Rodrigues: genaina@cic.unb.br; Alessia=Knauss: alessia.knauss@chalmers.se; Raian=Ali: rali@bournemouth.ac.uk; Hugo=Andrade: sica@chalmers.se,"Abstract
Context:
 Adaptive systems are expected to cater for various 
operational contexts
 by having multiple strategies in achieving their objectives and the logic for matching strategies to an actual context. The prediction of relevant contexts at design time is paramount for dependability. With the current trend on using data mining to support the 
requirements engineering
 process, this task of understanding context for adaptive system at design time can benefit from such techniques as well.
Objective:
 The objective is to provide a method to refine the specification of contextual variables and their relation to strategies for dependability. This refinement shall detect dependencies between such variables, priorities in monitoring them, and decide on their relevance in choosing the right strategy in a 
decision tree
.
Method:
 Our requirements-driven approach adopts the contextual goal modelling structure in addition to the operationalization values of sensed information to map contexts to the system’s behaviour. We propose a design time analysis process using a subset of 
data mining algorithms
 to extract a list of relevant contexts and their related variables, tasks, and/or goals.
Results:
 We experimentally evaluated our proposal on a Body Sensor Network system (BSN), simulating 12 resources that could lead to a variability space of 4096 possible context conditions. Our approach was able to elicit subtle contexts that would significantly affect the service provided to assisted patients and relations between contexts, assisting the decision on their need, and priority in monitoring.
Conclusion:
 The use of some 
data mining techniques
 can mitigate the lack of precise definition of contexts and their relation to system strategies for dependability. Our method is practical and supportive to traditional requirements specification methods, which typically require intense human intervention.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The method proposed for refining contextual variables in adaptive systems using data mining techniques shows promise in improving system dependability, but the practical implications and real-world impact need further validation."
https://www.sciencedirect.com/science/article/pii/S0950584919300953,Using Squeeziness to test component-based systems defined as Finite State Machines,Alfredo=Ibias: aibias@ucm.es; Manuel=Núñez: manuelnu@ucm.es; Robert M.=Hierons: r.hierons@sheffield.ac.uk,"Abstract
Context:
Testing is the main validation technique used to increase the reliability of software systems. The effectiveness of testing can be strongly reduced by 
Failed 
Error Propagation
. This situation happens when the System Under Test executes a faulty statement, the state of the system is affected by this fault, but the expected output is observed. Squeeziness is an information 
theoretic measure
 designed to quantify the likelihood of Failed Error Propagation and previous work has shown that Squeeziness correlates strongly with Failed Error Propagation in white-box scenarios. Despite its usefulness, this measure, in its current formulation, cannot be used in a black-box scenario where we do not have access to the 
source code
 of the components.
Objective:
The main goal of this paper is to adapt Squeeziness to a black-box scenario and evaluate whether it can be used to estimate the likelihood that a component of a software system introduces Failed Error Propagation.
Method:
 First, we defined our black-box scenario. Specifically, we considered the Failed Error Propagation that a component introduces when it receives its input from another component. We were interested in this since such fault masking makes it more difficult to find faults in the 
previous
 component when testing. Second, we defined our notion of Squeeziness in this framework. Finally, we carried out experiments in order to evaluate our measure.
Results:
 Our experiments showed a strong correlation between the likelihood of Failed Error Propagation and Squeeziness.
Conclusion:
 We can conclude that our new notion of Squeeziness can be used as a measure that estimates the probability of Failed Error Propagation being introduced by a component. As a result, it has the potential to be used as a measure of 
testability
, allowing testers to assess how easy it is to test either the whole system or a single component. We considered a simple model (Finite State Machines) but the notions and results can be extended/adapted to deal with more complex state-based models, in particular, those containing data.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"Adapting Squeeziness to estimate the likelihood of Failed Error Propagation in software components has potential for improving testability, but the applicability and effectiveness in real-world scenarios require more extensive testing and validation."
https://www.sciencedirect.com/science/article/pii/S0950584919300965,Source code properties of defective infrastructure as code scripts,Akond=Rahman: aarahman@ncsu.edu,"Abstract
Context
In continuous deployment, software and services are rapidly deployed to end-users using an automated deployment pipeline. Defects in infrastructure as code (IaC) scripts can hinder the reliability of the automated deployment pipeline. We hypothesize that certain properties of IaC 
source code
 such as lines of code and hard-coded strings used as configuration values, show correlation with defective IaC scripts.
Objective
The objective of this paper is to help practitioners in increasing the quality of infrastructure as code (IaC) scripts through an empirical study that identifies 
source code
 properties of defective IaC scripts.
Methodology
We apply qualitative analysis on defect-related commits mined from 
open source software
 repositories to identify source code properties that correlate with defective IaC scripts. Next, we survey practitioners to assess the practitioner’s agreement level with the identified properties. We also construct 
defect prediction
 models using the identified properties for 2439 scripts collected from four datasets.
Results
We identify 10 source code properties that correlate with defective IaC scripts. Of the identified 10 properties we observe lines of code and hard-coded string i.e. putting strings as configuration values, to show the strongest correlation with defective IaC scripts. According to our survey analysis, majority of the practitioners show agreement for two properties: include, the property of executing external modules or scripts, and hard-coded string. Using the identified properties, our constructed 
defect prediction
 models show a precision of 0.70
∼
0.78, and a recall of 0.54
∼
0.67.
Conclusion
Based on our findings, we recommend practitioners to allocate sufficient inspection and testing efforts on IaC scripts that include any of the identified 10 source code properties of IaC scripts.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study provides valuable insights on improving the quality of infrastructure as code, which is crucial for early-stage ventures relying on automated deployment pipelines."
https://www.sciencedirect.com/science/article/pii/S0950584918301290,Internal and external quality in the evolution of mobile software: An exploratory study in open-source market,Bahar=Gezici: bahargezici@hacettepe.edu.tr; Ayça=Tarhan: atarhan@hacettepe.edu.tr; Oumout=Chouseinoglou: uhus@hacettepe.edu.tr,"Abstract
Context
Mobile applications evolve rapidly and grow constantly to meet user requirements. Satisfying these requirements may lead to poor design choices that can degrade internal quality and performance, and consequently external quality and quality in use. Therefore, monitoring the characteristics of mobile applications through their evolution is important to facilitate maintenance and development.
Objective
This study aims to explore internal quality, external quality and the relation between these two by carrying out an embedded, multiple 
case study
 that includes two cases in different functional domains. In each 
case study
, the evolution of three open-source mobile applications having similar features in the same domain and platform is investigated with the analysis of a number of code-based and community-based metrics, to understand whether they are significantly related to 
quality characteristics
.
Method
A total of 105 releases of the six mobile applications are analyzed to understand internal quality, where code-based characteristics are employed in the light of Lehman’s Increasing Complexity, Continuous Growth, and Decreasing Quality laws. External quality is explored by adapting DeLone and McLean model of 
information system
 success and using community-based metrics, when data is available for the included releases, to derive a corresponding success index. Finally, internal and external quality relationship is investigated by applying Spearman’s correlation analysis on metrics data from 91 corresponding releases.
Results
The analysis of Lehman’s laws shows that only the law of Continuous Growth is validated for the selected mobile applications in both case studies. Spearman’s analysis results indicate that the internal 
quality attribute
 of ‘Understandability’ is negatively related to ‘Success Index’ for Case Study A and ‘LCOM’ is negatively related to ‘Success Index’ for Case Study B. No other significant relationship between the internal quality attributes and the Success Index is observed; but specific to community-based metrics, some significant relationships with code-based attributes were determined.
Conclusion
Our 
exploratory study
 is unique for the method it employs for exploring the relationship between internal and external quality in the evolution of mobile applications. Yet, our findings should be used with caution as they are derived from a limited number of applications. Therefore, this study should be considered to provide initial evidence for applicability of the method and a degree of confidence for repeating similar studies in wider contexts.",August 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study's findings on internal and external quality in the evolution of mobile applications can offer some insights for startups, but the limited application of the findings may reduce its impact."
https://www.sciencedirect.com/science/article/pii/S0950584919300539,Enactment of adaptation in data stream processing with latency implications—A systematic literature review,Cui=Qin: qin@sse.uni-hildesheim.de; Holger=Eichelberger: eichelberger@sse.uni-hildesheim.de; Klaus=Schmid: schmid@sse.uni-hildesheim.de,"Abstract
Context
Stream processing is a popular paradigm to continuously process huge amounts of data. Runtime adaptation plays a significant role in supporting the optimization of data 
processing tasks
. In recent years runtime adaptation has received significant interest in scientific literature. However, so far no categorization of the enactment approaches for runtime adaptation in stream processing has been established.
Objective
This paper identifies and characterizes different approaches towards the enactment of runtime adaptation in stream processing with a main focus on latency as quality dimension.
Method
We performed a systematic literature review (SLR) targeting five main research questions. An automated search, resulting in 244 papers, was conducted. 75 papers published between 2006 and 2018 were finally included. From the selected papers, we extracted data like processing problems, adaptation goals, enactment approaches of adaptation, enactment techniques, 
evaluation metrics
 as well as evaluation parameters used to trigger the enactment of adaptation in their evaluation.
Results
We identified 17 different enactment approaches and categorized them into a taxonomy. For each, we extracted the underlying technique used to implement this enactment approach. Further, we identified 9 categories of processing problems, 6 adaptation goals, 9 
evaluation metrics
 and 12 evaluation parameters according to the extracted data properties.
Conclusion
We observed that the research interest on enactment approaches to the adaptation of stream processing has significantly increased in recent years. The most commonly applied enactment approaches are parameter adaptation to tune parameters or settings of the processing, load balancing used to re-distribute workloads, and processing scaling to dynamically scale up and down the processing. In addition to latency, most adaptations also address resource fluctuation / bottleneck problems. For presenting a dynamic environment to evaluate enactment approaches, researchers often change input rates or processing workloads.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The categorization of runtime adaptation approaches in stream processing can have significant practical implications for startups dealing with huge amounts of data and real-time processing.
https://www.sciencedirect.com/science/article/pii/S0950584919300564,Bootstrapping cookbooks for APIs from crowd knowledge on Stack Overflow,Marcelo de Almeida=Maia: marcelo.maia@ufu.br; Eduardo C.=Campos: eccampos@ufu.br; Fernanda=Madeiral: fernanda.madeiral@ufu.br; Klérisson=Paixão: klerisson@ufu.br,"Abstract
Context
Well established libraries typically have 
API
 documentation. However, they frequently lack examples and explanations, possibly making difficult their effective reuse. Stack Overflow is a question-and-answer website oriented to issues related to software development. Despite the increasing adoption of Stack Overflow, the information related to a particular topic (e.g., an API) is spread across the website. Thus, Stack Overflow still lacks organization of the 
crowd knowledge
 available on it.
Objective
Our target goal is to address the problem of the poor quality documentation for APIs by providing an alternative artifact to document them based on the crowd knowledge available on Stack Overflow, called 
crowd cookbook
. A 
cookbook
 is a recipe-oriented book, and we refer to our cookbook as 
crowd cookbook
 since it contains 
content generated
 by a crowd. The cookbooks are meant to be used through an exploration process, i.e. browsing.
Method
In this paper, we present a semi-automatic approach that organizes the crowd knowledge available on Stack Overflow to build cookbooks for APIs. We have generated cookbooks for three APIs widely used by the software development community: SWT, LINQ and QT. We have also defined 
desired properties
 that crowd cookbooks must meet, and we conducted an evaluation of the cookbooks against these properties with 
human subjects
.
Results
The results showed that the cookbooks built using our approach, in general, meet those properties. As a highlight, most of the recipes were considered appropriate to be in the cookbooks and have self-contained information.
Conclusion
We concluded that our approach is capable to produce adequate cookbooks automatically, which can be as useful as manually produced cookbooks. This opens an opportunity for 
API designers
 to enrich existent cookbooks with the different points of view from the crowd, or even to generate initial versions of new cookbooks.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The creation of crowd cookbooks based on crowd knowledge from Stack Overflow can help in addressing the issue of poor quality documentation for APIs, which can benefit startups in utilizing APIs effectively."
https://www.sciencedirect.com/science/article/pii/S0950584919300576,The relationship between personality and decision-making: A Systematic literature review,Emilia=Mendes: emilia.mendes@bth.se; Norsaremah=Salleh: norsaremah@iium.edu.my; Fabiana Freitas=Mendes: fabianamendes@unb.br,"Abstract
Context
From a point of view, software development is a set of decisions that need to be made while the software is developed. Many alternatives should be considered, such as the technology to employ, or the most important features to implement. However, many factors can influence one’s decision-making, such as the decision maker’s personality.
Objective
This paper reports the state of the art with regard to the relationship between decision-makers’ personality and decision-making aspects.
Method
We conducted a 
Systematic Literature Review
 to search and analyze published primary studies that discuss the abovementioned relationship in the context of companies that develop any kind of product or service.
Results
Despite the recognized influence of personality in decision-making activities, we were not able to find any study in 
Software Engineering
 field that discusses this relationship. We included 15 studies and most of them are from Management field, excluding one from 
Information System
 field. From these studies, we identified 75 reported relationships between 28 different personality aspects and 30 different decision-making aspects.
Conclusion
The interest in this topic born on 80’s and it has grown after 2002. However, despite the number of reported relationships, and the number of personalities and decision-making aspects investigated, more research on this topic is necessary. In particular, it is important to verify how someone’s personality influences the decision-making considering the software development context. This can help in improving how a decision is made in software engineering context.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The paper addresses the relationship between decision-makers' personality and decision-making aspects in the context of software engineering, which can potentially impact decision-making processes in early-stage ventures. However, the practical application and impact of this research on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S095058491930059X,A reference model-based user requirements elicitation process: Toward operational business-IT alignment in a co-creation value network,Samaneh=Bagheri: s.bagheri@tue.nl; R.J.=Kusters: r.j.kusters@tue.nl; J.J.M.=Trienekens: j.j.m.trienekens@tue.nl; P.W.P.J.=Grefen: p.w.p.j.grefen@tue.nl,"Abstract
Context
To improve operational business-IT alignment (BITA), the development of IT-based systems should be derived from business requirements. However, the 
requirements elicitation
 process is challenging and encounters several problems which might lead to acquiring low-quality user requirements and failure of systems development projects. Many of 
elicitation
 problems are also identified as being relevant in the BITA literature. We focus on one category of well-known 
elicitation
 problems, such as communication flaws.
Until now, the majority of 
requirements elicitation
 studies with the aim of addressing operational BITA are based on an asking strategy. This elicitation strategy is suitable for relatively stable situations. To compensate for the limitation of this strategy in a more complex situation, e.g., a co-creation value network (VN) setting, using it in conjunction with other elicitation strategies is more likely to yield satisfactory results.
Objective
To contribute to operational BITA improvement in a VN setting by addressing one category of elicitation problems. For this purpose, we design and evaluate a reference model-based approach to facilitate the user requirements 
elicitation process
.
Method
Two-phase research according to the design science approach is followed. In the design phase, a reference model-based user requirements 
elicitation process
 is designed. Also, as a proof of concept, two instances of this artifact are designed. Two reference models, respectively, describing customer 
knowledge management
 processes and customer 
knowledge management
 challenges in a VN setting are used separately in designing these two instances. In the evaluation phase, the applicability and usefulness of these instances are evaluated in two separate studies.
Results
A reference model supports asking-based user requirements elicitation process via a Delphi method in a complex context of a VN. It improves the user requirements elicitation process by addressing a set of recognized elicitation problems.
Conclusions
The reference model-based approach, by addressing the elicitation problems, contributes to user requirements elicitation process improvement in general and to a better operational BITA in the complex situation of a VN in particular.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The paper focuses on improving operational business-IT alignment by addressing requirements elicitation problems. This can have a direct impact on the development of IT-based systems in early-stage ventures, enhancing their operational efficiency and overall success. The reference model-based approach presented in the paper offers practical insights for startups."
https://www.sciencedirect.com/science/article/pii/S0950584919300734,Leveraging keyword-guided exploration to build test models for web applications,Ziyuan=Wang: wangziyuan@njupt.edu.cn; Xiao-Fang=Qi: xfqi@seu.edu.cn; Peng=Wang: pwang@seu.edu.cn,"Abstract
Context
Dynamic exploration techniques, which automatically exercise possible 
user interface elements
, have been used to explore user interface state flow graphs as test models for web applications. An exhaustive exploration may incur the well-known state explosion problem. In a limited amount of time, most existing dynamic exploration techniques tend to become mired in local or irrelevant regions of the web application due to not considering functionality semantics information. Hence, generated test models have often inadequate functionality coverage for deriving effective test cases.
Objective
This paper proposes a keyword-guided exploration strategy for automatic construction of web application test models. The goal is to generate incomplete test models with adequate functionality coverage in a given time budget for deriving test cases w.r.t. specified functionalities.
Method
Given very few keywords that describe specified functionalities, our strategy guides the exploration to discover user interface states and transitions among them that are relevant to the specified functionalities by computing similarity scores between text contents in web pages and given keywords. We use nine representative web applications to perform dynamic explorations in a given time budget and empirically evaluate functionality coverage, and other metrics, e.g., code coverage, the size of test model, the number of the test suite, path diversity, and 
DOM
 diversity.
Results
Our keyword-guided exploration strategy achieves a higher functionality coverage as compared with the generic and feedback-directed exploration strategies. Yet the significant improvement of functionality coverage achieved by our strategy is not exchanged at the cost of other metrics.
Conclusion
Our keyword-guided exploration strategy is more effective than the generic and feedback-directed exploration strategies in terms of functionality coverage. In a limited amount of time, test models generated with our strategy can be used to derive effective web application test cases.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The keyword-guided exploration strategy proposed in the paper for automatic construction of web application test models can significantly benefit early-stage ventures by improving functionality coverage in a limited time frame. This practical approach can enhance the testing process for startups, ultimately leading to better product quality and user experience."
https://www.sciencedirect.com/science/article/pii/S095058491830106X,State of the art in hybrid strategies for context reasoning: A systematic literature review,Roger S.=Machado: rdsmachado@inf.ufpel.edu.br; Ricardo B.=Almeida: rbalmeida@inf.ufpel.edu.br; Ana Marilza=Pernas: marilza@inf.ufpel.edu.br; Adenauer C.=Yamin: adenauer@inf.ufpel.edu.br,"Abstract
Context
Several strategies have been used to implement context reasoning, and a strategy that can be applied satisfactorily in different smart systems applications has not yet been found. Because of this, hybrid proposals for context reasoning are gaining prominence. These proposals allow the combination of two or more strategies.
Objective
This work aims to identify the state of the art in the 
context awareness
 field, considering papers that use 
hybrid strategies
 for context reasoning.
Method
A Systematic Literature Review was explored, contributing to the identification of relevant works in the field, as well as the specification of criteria for its selection. In this review, we analyzed papers published between 2004 and 2018.
Results
During the process, we identified 3241 papers. After applying filtering and conditioning processes, ten papers about 
hybrid strategies
 for context reasoning were selected. We described, discussed, and compared the selected papers.
Conclusion
The Systematic Literature Review showed that some researchers explore hybrid proposals, but these proposals do not offer flexibility regarding the reasoning strategies used. Thus, we noted that research efforts related to the topic are still necessary, mainly focusing on the development of dynamic approaches that allow the applications to choose how they want to use the different resources available.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The paper explores hybrid strategies for context reasoning, which can be relevant for smart systems applications, including those used in early-stage ventures. While the research contributes to the state of the art in context awareness, the direct practical implications for European startups may require further exploration."
https://www.sciencedirect.com/science/article/pii/S0950584918301113,An overview of a novel analysis approach for enhancing context awareness in smart environments,Nesrine=Khabou: nesrine.khabou@redcad.org; Ismael=Bouassida Rodriguez: bouassida@redcad.org; Mohamed=Jmaiel: mohamed.jmaiel@enis.rnu.tn,"Abstract
Context
This work is part of 
context aware applications
 design and development, and smart environments in which context changes frequently.
Objective
The objective of the work is to facilitate the design and the development of 
context aware applications
 able to detect context changes and to predict context.
Method
In the paper, two analysis tasks are proposed. An analysis task for detection aiming at supporting application designers to conceive easily context aware applications able to detect context changes and an analysis task for prediction aiming at helping the application designers to conceive context aware applications able to predict context. The paper details also an analysis module that implements the functionalities of the analysis tasks. The analysis module helps the application developers to develop context aware applications. Finally, the paper introduces a 
case study
 related to smart buildings in order to show the usefulness of the analysis tasks.
Results
The paper shows an application scenario related to smart buildings and particularly water consumption prediction. Also the paper presents experiments related to memory consumption introduced by the use of our analysis module.
Conclusions
The application scenario illustrates the usefulness of the analysis approach. The overhead introduced by the analysis module is negligeable.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The paper provides analysis tasks for detection and prediction of context changes in context-aware applications, with a focus on smart environments like smart buildings. The practical application of these analysis tasks can benefit European early-stage ventures by improving the design and development of context-aware applications for enhanced user experiences."
https://www.sciencedirect.com/science/article/pii/S0950584918302052,Automatically identifying code features for software defect prediction: Using AST N-grams,Thomas=Shippey: t.shippey@herts.ac.uk; David=Bowes: dbowes@uclan.ac.uk; Tracy=Hall: t.hall3@lancaster.ac.uk,"Abstract
Context:
 Identifying defects in code early is important. A wide range of static 
code metrics
 have been evaluated as potential defect indicators. Most of these metrics offer only high level insights and focus on particular pre-selected features of the code. None of the currently used metrics clearly performs best in 
defect prediction
.
Objective:
 We use 
Abstract Syntax Tree
 (AST) n-grams to identify features of defective Java code that improve 
defect prediction
 performance.
Method:
 Our approach is bottom-up and does not rely on pre-selecting any specific features of code. We use non-parametric testing to determine relationships between AST n-grams and faults in both open source and commercial systems. We build defect prediction models using three 
machine learning techniques
.
Results:
 We show that AST n-grams are very significantly related to faults in some systems, with very large 
effect sizes
. The occurrence of some frequently occurring AST n-grams in a method can mean that the method is up to three times more likely to contain a fault. AST n-grams can have a large effect on the performance of defect prediction models.
Conclusions:
 We suggest that AST n-grams offer developers a promising approach to identifying potentially defective code.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The use of AST n-grams to identify features of defective code and improve defect prediction models can be valuable for startups to identify and address code defects early in the development process.
https://www.sciencedirect.com/science/article/pii/S0950584918301137,A distributed event-driven architectural model based on situational awareness applied on internet of things,Roger S.=Machado: rdsmachado@inf.ufpel.edu.br; Ricardo B.=Almeida: rbalmeida@inf.ufpel.edu.br; Ana Marilza=Pernas: marilza@inf.ufpel.edu.br; Adenauer C.=Yamin: adenauer@inf.ufpel.edu.br; Victor Renan Covalski=Junes: vrcjunes@inf.ufpel.edu.br; Diórgenes Yuri Leal da=Rosa: diorgenes@inf.ufpel.edu.br; Lucas Medeiros=Donato: lucas.donato@my365.dmu.ac.uk,"Abstract
Context
The 
IoT
 network is comprised of numerous and heterogeneous devices that are capable of generating large amounts of events. To enable the 
IoT
 paradigm, it is necessary to integrate, process, and react to events on the fly.
Objective
The goal of this paper is to support the increased demands of scalability, flexibility, autonomy, and heterogeneity for IoT event processing. A distributed 
architectural model
 based on 
Situational Awareness
, named EXEHDA-SA, was designed to provide event collection, hybrid processing, and customizable and dynamic reaction features.
Method
The conception of the model was based on a middleware for 
ubiquitous computing
 called EXEHDA, thus benefiting from its already defined strategies. The proposal follows a multi-level strategy and consists of three hierarchically interconnected modular components.
Results
Our main contribution is the conception and validation of a model for event collection, processing and reaction for modern distributed environments. The contribution is evidenced through experiments performed on a prototype implemented on consolidated free and 
open source technologies
. The experiments are made up of five 
case studies
 where each one evaluates a scenario for IoT demands.
Conclusion
Through these 
case studies
 which were proposed in information security area, we demonstrated the feasibility of this proposal for deployment in IoT production environments. Furthermore, EXEHDA-SA is able to operate on different scenarios due to each component modularity and its consequent extensibility.",July 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The abstract presents a model for event processing in IoT environments, which is relevant for early-stage ventures working with IoT technologies. The use of open source technologies and case studies add practical value."
https://www.sciencedirect.com/science/article/pii/S0950584918300715,Detecting terminological ambiguity in user stories: Tool and experimentation,Fabiano=Dalpiaz: f.dalpiaz@uu.nl,"Abstract
Context.
 Defects such as ambiguity and incompleteness are pervasive in software requirements, often due to the limited time that practitioners devote to writing good requirements. 
Objective.
We study whether a synergy between humans’ analytic capabilities and 
natural language processing
 is an effective approach for quickly identifying near-synonyms, a possible source of terminological ambiguity. 
Method.
We propose a tool-supported approach that blends 
information visualization
 with two 
natural language processing
 techniques: conceptual model extraction and semantic similarity. We evaluate the precision and recall of our approach compared to a pen-and-paper manual inspection session through a controlled quasi-experiment that involves 57 participants organized into 28 groups, each group working on one real-world requirements data set. 
Results.
The experimental results indicate that manual inspection delivers higher recall (statistically significant with 
p
 ≤ 0.01) and non-significantly higher precision. Based on qualitative observations, we analyze the quantitative results and suggest interpretations that explain the advantages and disadvantages of each approach. 
Conclusions.
Our experiment confirms conventional wisdom in 
requirements engineering
: identifying terminological ambiguities is time consuming, even when with tool support; and it is hard to determine whether a near-synonym may challenge the correct development of a software system. The results suggest that the most effective approach may be a combination of manual inspection with an improved version of our tool.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The abstract addresses a common issue in software requirements, but the focus on terminological ambiguity may have limited impact on early-stage ventures. The experimental results provide some insights but may not have significant practical implications for startups."
https://www.sciencedirect.com/science/article/pii/S0950584918301599,GuideGen: An approach for keeping requirements and acceptance tests aligned via automatically generated guidance,Sofija=Hotomski: hotomski@ifi.uzh.ch; Martin=Glinz: glinz@ifi.uzh.ch,"Abstract
Context
When software-based systems evolve, their requirements change. The changes in requirements affect the associated 
acceptance tests
, which should be adapted accordingly. In practice, however, requirements and their 
acceptance tests
 are not always kept up-to-date nor aligned. Such inconsistencies may introduce software quality problems, unintended costs and project delays.
Objective
In order to keep evolving requirements and their acceptance tests aligned, we are developing an approach called GuideGen. GuideGen automatically generates guidance in natural language about how to adapt the impacted acceptance tests when their requirements change.
Method
We have implemented GuideGen as a prototype tool and evaluated it in two studies: first, by assessing the correctness, completeness, 
understandability
 and relevance of the generated guidance using three data sets from industry and second, by assessing the applicability and usefulness of the approach and the tool with 23 practitioners from ten companies.
When a requirement having more than one associated acceptance test is changed, GuideGen currently generates guidance for all of them together. As a first step towards overcoming this limitation, we assessed how well existing methods for change impact analysis can identify the tests actually impacted by the changes in a requirement.
Results
In the first study, we found that GuideGen produced correct guidance in about 67 to 89 percent of all changes. Our approach performed better for agile requirements than for traditional ones. The results of the second study show that GuideGen is perceived to be useful, but that the practitioners would prefer a GuideGen plug-in for commercial tools instead of a standalone tool. Further, in our experiment we could correctly identify the affected acceptance tests for 63% to 91% of the changes in the requirements.
Conclusion
Our approach facilitates the alignment of acceptance tests with the actual requirements and can improve the communication between requirements engineers and testers.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The development of GuideGen to keep requirements and acceptance tests aligned is a valuable contribution for startups aiming to improve software quality. The positive results from the studies and the preference for a plug-in tool enhance the practical relevance of the approach.
https://www.sciencedirect.com/science/article/pii/S0950584918300739,Quality requirements challenges in the context of large-scale distributed agile: An empirical study,Maya=Daneva: m.daneva@utwente.nl; Wasim=Alsaqaf: w.h.a.alsaqaf@utwente.nl; Roel=Wieringa: r.j.wieringa@utwente.nl,"Abstract
Context
Engineering quality requirements in agile projects does not fit organically with agile methods. Despite the agile community acknowledges this, little empirical evidence has been published on this topic.
Objective
This exploratory qualitative interview-based study explicates the challenging situations experienced by practitioners in engineering the quality requirements in the context of large-scale distributed agile projects. Moreover, this study describes the practices that agile distributed teams currently use which could contribute by dealing with the identified challenges.
Method
The challenging situations and possible mitigation practices were studied from the perspective of 17 practitioners from large distributed agile project teams in six organizations in The Netherlands. Qualitative data were collected using semi-structured, open-ended interviews. Qualitative coding techniques were used for data analysis, to identify the challenges of engineering quality requirements, the mechanisms behind the challenges and the practices used that could mitigate the impact of those challenges. Further, by using dialog mapping technique for qualitative data structuring, we have mapped the identified mechanisms and practices to the challenges.
Results
From the perspective of the participating practitioners, our 
exploratory study
 revealed 15 challenges classified in five categories: (1) team coordination and communication, (2) quality assurance, (3) quality 
requirements elicitation
, (4) conceptual challenges, and (5) software architecture. The study has also disclosed 13 mechanisms behind the challenges and 9 practices that could mitigate the impact of those challenges.
Conclusions
The main contributions of the paper are: (1) the explication of the challenges from practitioners’ perspective and the comparison of our findings with previously published results, (2) the description of the mechanisms behind the challenges, and (3) the identification of the practices currently used by agile teams that could mitigate the impact of the challenges. The findings of this study provide useful input into the process of designing possible solution approaches to overcome the challenges.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on engineering quality requirements in agile projects offers insights into challenges faced by practitioners, but the practical implications for early-stage ventures may be limited. The identification of practices used by agile teams can be helpful, but more concrete recommendations could improve the score."
https://www.sciencedirect.com/science/article/pii/S095058491930031X,Investigation on test effort estimation of mobile applications: Systematic literature review and survey,Anureet=Kaur: anumahal@gmail.com; Kulwant=Kaur: kulwantkaur@apjimtc.org,"Abstract
Context
In the last few years, the exigency of mobile devices has proliferated to prodigious heights. The process of developing the mobile software/application proceeds amidst testing phase to verify the correctness of the mobile app. The estimation of testing plays a vital role in the effective completion of testing.
Objective
To identify how estimation of test effort for mobile applications is distinct from other software via published literature and from mobile software organizations. Second is to recognize different issues in adapting traditional test estimation methods to the mobile domain and if suggestions from survey results could be helpful in providing an improved test estimation model for mobile applications.
Method
A systematic literature review is conducted followed by a survey through an online questionnaire filled from experienced mobile application developers and testers.
Results
The results from SLR cover identification of mobile app specific characteristics and reports test effort estimation techniques in the mobile domain. Findings from survey corroborate that a) Function Point/Test Point Analysis is highly adapted traditional test estimation technique to mobile domain; b) Challenges like uncertain requirements, no tool support for test estimation, complexity in testing, client miscommunication etc. are reported; c)Suggestions to improve test estimation process include proper test planning, adoption of 
agile methodology
, healthier communication among client, developer, and tester etc.; d) On the basis of responses, Analytical Hierarchical Process (AHP) identifies “Diverse Devices and OS” along with “Type of App” as highly influential mobile app characteristic on the test estimation process.
Conclusion
Results conclude that the importance of identified mobile app characteristics from SLR cannot be ignored in the estimation process of mobile software testing. There might be a possibility to improve existing test estimation techniques for mobile apps by giving weight to mobile app specific characteristics and by considering suggestions from experienced developers and testers.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The focus on test estimation for mobile applications is relevant given the importance of mobile technology for startups. The use of systematic literature review and survey results to improve test estimation techniques provides practical value for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584919300321,Towards functional change decision support based on COSMIC FSM method,Mariem=Haoues: mariem.haoues@isims.usf.tn; Asma=Sellami: asma.sellami@isims.usf.tn; Hanêne=Ben-Abdallah: hbenabdallah@hct.ac.ae,"Abstract
Context:
 Managing requirements change is a central issue in the software development industry. In fact, inappropriate decisions about a change request may jeopardize the project development progress by going over budget/time or delivering a software with functional requirements that do not fully meet the user’s needs. Hence, a change decision support is required for the success of the software development.
Objective:
 This paper has a three-fold objective: (i) explore the applicability of the ISO standard COSMIC FSM method to evaluate a change request; (ii) investigate the use of estimation models to predict the effort required to handle a functional change and its impact on the initially estimated software development effort; and (iii) propose a decision support method that offers the appropriate information for the 
change advisory board
 members to decide whether to accept, deny or defer a functional change request.
Method:
 To guide the decision on a change request, the method proposed in this paper accounts for the most important factors when evaluating a change request, namely the functional change status, the preference of the change requester, and the effort required to handle the change. The functional change status is identified based on the sensitivity of the changed functionality and the functional size of the functional change. The functional change effort can be estimated using several ways including the COCOMO II model, the 
Simple Linear Regression
 Model and 
expert judgment
. Furthermore, this paper proposes a prototype to determine automatically the functional change status and offers pertinent information that the 
change advisory board
 can use to determine how to handle a change request. The use of the decision support method and tool is illustrated through three 
case studies
.
Results:
 A decision support method to help decision-makers respond to a functional change request is provided. This method takes into account the functional change status, the preference of the change requester and the functional change effort. The empirical evaluation of the proposed method is illustrated through three 
case studies
. The role of experiments here is primarily to provide a proof-of-concept rather than an exhaustive evaluation.
Conclusion:
 Using COSMIC FSM method, it is possible to identify functional changes leading to a potential impact on the software development progress. Based on the evaluation of the functional change, the change advisory board members can make judicious decisions about whether to accept, defer or deny a functional change request.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The paper provides a decision support method for managing requirements change in software development, which can significantly impact the success of projects. The proposed method and tool offer practical guidance for decision-makers to handle functional change requests."
https://www.sciencedirect.com/science/article/pii/S0950584919300400,CaMeLOT: An educational framework for conceptual data modelling,Daria=Bogdanova: daria.bogdanova@kuleuven.be; Monique=Snoeck: monique.snoeck@kuleuven.be,"Abstract
Context
Teaching 
conceptual data modelling
 (CDM) remains a challenging task for educators. Despite the fact that CDM is an integral part of 
software engineering
 curricula, there is no generally accepted educational framework for the subject. Moreover, the existing educational literature shows significant gaps when it comes to pursued 
learning outcomes
 and their assessment.
Objective
In this paper, we propose an educational framework for 
conceptual data modelling
, based on the revised Bloom's taxonomy of educational objectives, and provide necessary examples of systemized 
learning outcomes
.
Method
We utilized the revised Bloom's taxonomy to develop an adapted framework specifically for learning outcomes related to CDM. We validated the framework by mapping learning outcomes distilled from the existing course material to the framework, by presenting the framework for feedback to the experts in the field and further elaborating and refining it based on the feedback and experiences from these validation activities.
Results
CaMeLOT is an adaptation of the Bloom's taxonomy specifically for learning outcomes related to CDM. We identified different content areas and indicated the necessary scaffolding. Based on the framework, we worked out 17 example tables of learning outcomes related to content areas at different levels of scaffolding, exemplifying the different knowledge and cognitive levels. We clarify the differences in learning outcomes related to different knowledge and cognitive levels and thereby provide a domain specific clarification of the classification guidelines.
Conclusion
CaMeLOT gives educators an opportunity to enhance the CDM part of 
software engineering
 curricula with a systemized set of learning outcomes to be pursued, and open the path for creating more complete, useful and effective assessment packages. The adoption of our educational framework may reduce the time spent on designing educational material and, at the same time, improve its quality.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The educational framework proposed for conceptual data modeling can enhance software engineering curricula, providing educators with a systematic set of learning outcomes. This framework may improve the quality of educational material and assessment packages."
https://www.sciencedirect.com/science/article/pii/S0950584919300424,Why is my code change abandoned?,David=Lo: davidlo@smu.edu.sg; Xin=Xia: xin.xia@monash.edu; Qingye=Wang: wqyy@zju.edu.cn; Shanping=Li: shan@zju.edu.cn,"Abstract
Context
: Software developers contribute numerous changes every day to the code review systems. However, not all submitted changes are merged into a codebase because they might not pass the 
code review process
. Some changes would be abandoned or be asked for resubmission after improvement, which results in more workload for developers and reviewers, and more delays to deliverables.
Objective
: To understand the underlying reasons why changes are abandoned, we conduct an empirical study on the code review of four 
open source projects
 (Eclipse, LibreOffice, OpenStack, and Qt).
Method
: First, we manually analyzed 1459 abandoned changes. Second, we leveraged the open card sorting method to label these changes with reasons why they were abandoned, and we identified 12 categories of reasons. Next, we further investigated the frequency distribution of the categories across projects. Finally, we studied the relationship between the categories and time-to-abandonment.
Results
: Our findings include the following: (1) 
Duplicate
 changes are the majority of the abandoned changes; (2) the frequency distribution of abandoned changes across the 12 categories is similar for the four 
open source projects
; (3) 98.39% of the changes are abandoned within a year.
Conclusion
: Our study concluded the root causes of abandoned changes, which will help developers submit high-quality code changes.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The empirical study on abandoned code changes in open source projects addresses a common issue in software development. Understanding the root causes of abandoned changes can help developers submit higher quality code, reducing workload and delays."
https://www.sciencedirect.com/science/article/pii/S0950584919300461,Revisiting the refactoring mechanics,Jonhnanthan=Oliveira: jonhnanthan@copin.ufcg.edu.br; Rohit=Gheyi: rohit@dsc.ufcg.edu.br; Márcio=Ribeiro: marcio@ic.ufal.br; Alessandro=Garcia: afgarcia@inf.puc-rio.br; Melina=Mongiovi: melina@computacao.ufcg.edu.br; Gustavo=Soares: gustavo.soares@microsoft.com,"Abstract
Context
Refactoring is a key practice in 
agile methodologies
 used by a number of developers, and available in popular IDEs. However, it is unclear whether the refactoring mechanics have the same meaning for developers.
Objective
In this article, we revisit the refactoring mechanics.
Method
We conduct a survey with 107 developers of popular Java projects on GitHub. We asked them about the output of seven refactoring types applied to small programs.
Results
Developers do not expect the same outputs in all questions. The refactoring mechanics is based on developers’ experience for a number of them (71.02%). Some developers (75.70%) use IDEs to apply refactorings. However, the output yielded by the preferred IDE is different from what they want.
Conclusion
Developers and IDE developers use different mechanics for most refactoring types considered in our survey, and this may impact developers’ communication.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The survey on refactoring mechanics provides insights into developers' expectations and the discrepancies with IDE outputs. While the findings can impact developers' communication, the practical implications on early-stage European ventures might be limited."
https://www.sciencedirect.com/science/article/pii/S0950584919300503,Images don’t lie: Duplicate crowdtesting reports detection with screenshot information,Junjie=Wang: wangjunjie@itechs.iscas.ac.cn; Mingyang=Li: limingyang@itechs.iscas.ac.cn; Song=Wang: song.wang@uwaterloo.ca; Tim=Menzies: tim@menzies.us; Qing=Wang: wq@itechs.iscas.ac.cn,"Abstract
Context
: Crowdtesting is effective especially when it comes to the feedback on GUI systems, or subjective opinions about features. Despite of this, we find crowdtesting reports are highly duplicated, i.e., 82% of them are duplicates of others. Most of the existing approaches mainly adopted textual information for 
duplicate detection
, and suffered from low accuracy because of the lexical gap. Our observation on real industrial crowdtesting data found that when dealing with crowdtesting reports of GUI systems, the reports would be accompanied with images, i.e., the screenshots of the tested app. We assume the screenshot to be valuable for duplicate crowdtesting report detection because it reflects the real context of the bug and is not affected by the variety of natural languages.
Objective
: We aim at automatically detecting duplicate crowdtesting reports that could help reduce triaging effort.
Method
: In this work, we propose SETU which combines information from the ScrEenshots and the TextUal descriptions to detect duplicate crowdtesting reports. We extract four types of features to characterize the screenshots (i.e., image structure feature and image color feature) and the textual descriptions (i.e., TF-IDF feature and 
word embedding
 feature), and design a hierarchical algorithm to detect duplicates based on the four similarity scores derived from the four features respectively.
Results
: We investigate the effectiveness of SETU on 12 projects with 3,689 reports from one of the Chinese largest crowdtesting platforms. Results show that recall@1 achieved by SETU is 0.44 to 0.79, recall@5 is 0.66 to 0.92, and 
MAP
 is 0.21 to 0.58 across all experimental projects. Furthermore, SETU can outperform existing state-of-the-art approaches significantly and substantially.
Conclusion
: Through combining the screenshots and textual descriptions, our proposed SETU can improve the duplicate crowdtesting reports detection performance.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The proposed SETU method for detecting duplicate crowdtesting reports offers a practical solution to reduce triaging effort. The combination of screenshots and textual descriptions shows significant improvement in detection performance, which can benefit software testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584919300515,Reusability in goal modeling: A systematic literature review,Gunter=Mussbacher: gunter.mussbacher@mcgill.ca; Mustafa Berk=Duran: berk.duran@mail.mcgill.ca,"Abstract
Context:
 Goal modeling is an important instrument for the 
elicitation
, specification, analysis, and validation of early requirements. Goal models capture hierarchical representations of stakeholder objectives, requirements, possible solutions, and their relationships to help requirements engineers understand 
stakeholder goals
 and explore solutions based on their impact on these goals. To reuse a goal model and benefit from the strengths of goal modeling, we argue that it is necessary (i) to make sure that analysis and validation of goal models is possible through reuse hierarchies, (ii) to provide the means to delay decision making to a later point in the reuse hierarchy, (iii) to take constraints imposed by other 
modeling notations
 into account during analysis, (iv) to allow context dependent information to be modeled so that the goal model can be used in various reuse contexts, and (v) to provide an interface for reuse.
Objective:
 In this two-part systematic literature review, we (i) evaluate how well existing goal modeling approaches support reusability with our five desired characteristics of contextual and reusable goal models, (ii) categorize these approaches based on language constructs for context modeling and connection to other modeling formalisms, and then (iii) draw our conclusions on future research themes.
Method:
 Following guidelines by Kitchenham, the review is conducted on seven major academic search engines. Research questions, 
inclusion criteria
, and categorization criteria are specified, and threats to validity are discussed. A final list of 146 publications and 34 comparisons/assessments of goal modeling approaches is discussed in more detail.
Results:
 Five major research themes are derived to realize reusable goal models with context dependent information.
Conclusion:
 The results indicate that existing goal modeling approaches do not fully address the required capabilities for reusability in different contexts and that further research is needed to fill this gap in the landscape of goal modeling approaches.",June 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The research on goal modeling approaches is relevant for early-stage ventures in understanding stakeholder goals and exploring solutions, but the conclusion that existing approaches do not fully address reusability needs more research does not provide immediate practical value."
https://www.sciencedirect.com/science/article/pii/S0950584919300047,Is deep learning better than traditional approaches in tag recommendation for software information sites?,John=Grundy: john.grundy@monash.edu; Jin=Liu: jinliu@whu.edu.cn; Pingyi=Zhou: zhou_pinyi@whu.edu.cn; Xiao=Liu: xiao.liu@deakin.edu.au; Zijiang=Yang: zijiang.yang@wmich.edu,"Abstract
Context
Inspired by the success of 
deep learning
 in other domains, this new technique been gaining widespread recent interest in being applied to diverse data analysis problems in 
software engineering
. Many 
deep learning
 models, such as 
CNN
, 
DBN
, 
RNN
, 
LSTM
 and 
GAN
, have been proposed and recently applied to 
software engineering
 tasks including effort estimation, 
vulnerability analysis
, code clone detection, test case selection, requirements analysis and many others. However, there is a perception that applying 
deep learning
 is a ”silver bullet” if it can be applied to a software engineering data analysis problem.
Object
This motivated us to ask the question as to whether 
deep learning
 is better than traditional approaches in 
tag recommendation
 task for software information sites.
Method
In this paper we test this question by applying both the latest deep 
learning approaches
 and some traditional approaches on 
tag recommendation
 task for software information sites. This is a typical Software 
Engineering automation
 problem where intensive data processing is required to link disparate information to assist developers. Four different deep 
learning approaches
 – TagCNN, TagRNN, TagHAN and TagRCNN – are implemented and compared with three advanced traditional approaches – EnTagRec, TagMulRec, and FastTagRec.
Results
Our comprehensive experimental results show that the performance of these different deep learning approaches varies significantly. The performance of TagRNN and TagHAN approaches are worse than traditional approaches in tag recommendation tasks. The performance of TagCNN and TagRCNN approaches are better than traditional approaches in tag recommendation tasks.
Conclusion
Therefore, using appropriate deep learning approaches can indeed achieve better performance than traditional approaches in tag recommendation tasks for software information sites.",May 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The comparison between deep learning and traditional approaches in tag recommendation tasks for software information sites provides practical insights for early-stage ventures in software engineering, highlighting the potential of deep learning solutions."
https://www.sciencedirect.com/science/article/pii/S0950584919300059,"Formal Quality of Service assurances, ranking and verification of cloud deployment options with a probabilistic model checking method",Vlado=Stankovski: vlado.stankovski@fgg.uni-lj.si,"Abstract
Context
: Existing software workbenches allow for the deployment of cloud applications across a variety of Infrastructure-as-a-Service (IaaS) providers. The expected workload, 
Quality of Service
 (QoS) and Non-Functional Requirements (NFRs) must be considered before an appropriate infrastructure is selected. However, this decision-making process is complex and time-consuming. Moreover, the software engineer needs assurances that the selected infrastructure will lead to an adequate QoS of the application.
Objective
: The goal is to develop a new method for selection of an optimal cloud 
deployment option
, that is, an infrastructure and configuration for deployment and to verify that all hard and as many soft QoS requirements as possible will be met at runtime.
Method
: A new Formal QoS Assurances Method (FoQoSAM), which relies on stochastic Markov models is introduced to facilitate an automated decision-making process. For a given workload, it uses QoS 
monitoring data
 and a user-related metric in order to automatically generate a probabilistic model. The probabilistic model takes the form of a 
finite automaton
. It is further used to produce a rank list of cloud deployment options. As a result, any of the cloud deployment options can be verified by applying a probabilistic model checking approach.
Results
: Testing was performed by ranking deployment options for two cloud applications, File Upload and Video-conferencing. The FoQoSAM method was compared to a baseline 
Analytic Hierarchy Process
 (AHP). The results show that the first ranked cloud deployment options satisfy all hard and at least one of the soft requirements for both methods, however, the FoQoSAM method always satisfies at least an additional QoS requirement compared to the baseline AHP method.
Conclusions
: The proposed new FoQoSAM method is appropriate and can be used in decision-making when ranking and verifying cloud deployment options. Due to its practical utility it was integrated into the SWITCH workbench.",May 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,The development of a new method for optimal cloud deployment options with a focus on Quality of Service requirements and automation of decision-making processes is highly relevant and impactful for European early-stage ventures dealing with cloud applications.
https://www.sciencedirect.com/science/article/pii/S0950584919300072,On the need to update systematic literature reviews,Sergio=Soares: scbs@cin.ufpe.br; Vilmar=Nepomuceno: vsn@cin.ufpe.br,"Abstract
Context
Many 
Systematic Literature Reviews
 (SLRs) were performed in the recent past, but just a few are being updated. Keeping SLRs updated is essential to prolong their lifespan.
Objective
To give a picture about how SLRs are being updated and what researchers think about SLRs updates.
Method
In this work, we present a Systematic Mapping (SM) study about SLRs updates and a survey with 
EBSE
 researchers that published their SLRs between 2011 and 2015.
Results
We included 22 studies in the 
SM
, where 15 changed some artifact from the original study, including changes in research questions. We obtained 28 answers in our survey with SLRs authors that, in general, consolidate interpretations retrieved from the 
SM
, but some answers did not.
Conclusion
SLRs may lose their impact over the years. Identifying actions to keep them updated is of great importance to SLR research field.",May 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"While the importance of updating Systematic Literature Reviews (SLRs) is acknowledged, the practical value and impact on early-stage ventures are not as direct as other abstracts that provide actionable insights."
https://www.sciencedirect.com/science/article/pii/S0950584919300096,"Euphoria: A Scalable, event-driven architecture for designing interactions across heterogeneous devices in smart environments",Ovidiu-Andrei=Schipor: schipor@eed.usv.ro; Radu-Daniel=Vatavu: http://www.eed.usv.ro/~vatavu; Jean=Vanderdonckt: jean.vanderdonckt@uclouvain.be,"Abstract
Context:
 From personal mobile and wearable devices to public ambient displays, our 
digital ecosystem
 has been growing with a large variety of smart sensors and devices that can capture and deliver insightful data to 
connected applications
, creating thus the need for new software architectures to enable fluent and flexible interactions in such smart environments.
Objective:
 We introduce 
Euphoria
, a new 
software architecture design
 and implementation that enables easy prototyping, deployment, and evaluation of adaptable and flexible interactions across heterogeneous devices in smart environments.
Method:
 We designed 
Euphoria
 by following the requirements of the ISO/IEC 25010:2011 standard on Software Quality Requirements and Evaluation applied to the specific context of smart environments.
Results:
 To demonstrate the adaptability and flexibility of 
Euphoria
, we describe three application scenarios for contexts of use involving multiple users, multiple input/output devices, and various types of smart environments, as follows: (1) wearable user interfaces and whole-body gesture input for interacting with public ambient displays, (2) multi-device interactions in physical-digital spaces, and (3) interactions on smartwatches for a connected car application scenario. We also perform a technical evaluation of 
Euphoria
 regarding the main factors responsible for the magnitudes of the request-response times for producing, broadcasting, and consuming messages inside the architecture. We deliver the source code of 
Euphoria
 free to download and use for research purposes.
Conclusion:
 By introducing 
Euphoria
 and discussing its applicability, we hope to foster advances and developments in new software architecture initiatives for our increasingly complex smart environments, but also to readily support implementations of novel interactive 
systems and applications
 for smart environments of all kinds.",May 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The introduction of Euphoria as a new software architecture design for smart environments and its practical implementation in various application scenarios demonstrate its potential to enable flexible interactions, which can be valuable for startups exploring smart environment technologies."
https://www.sciencedirect.com/science/article/pii/S0950584919300102,A new benchmark for evaluating pattern mining methods based on the automatic generation of testbeds,A.=Rasoolzadegan: rasoolzadegan@um.ac.ir,"Abstract
Context
Mining patterns is one of the most attractive topics in the field of software design. Knowledge about the number, type, and location of pattern instances is crucial to understand the original design decisions. Several techniques and tools have been presented in the literature for mining patterns in a software system. However, evaluating the quality of the detection results is usually done manually or subjectively. This can significantly affect the evaluation results. Therefore, a fair comparison of the quality of the various mining methods is not possible.
Objective
This paper describes a new benchmark to evaluate pattern mining methods in source code or design. Our work aims at overcoming the challenges faced in benchmarking in pattern detection. The proposed benchmark is comprehensive, fair, and objective, with a repeatable evaluation process.
Method
Our proposed benchmark is based on automatic generation of testbeds using graph theory. The generated testbeds are Java source codes and their corresponding class diagrams in which various types of patterns and their variants are inserted in different locations. The generated testbeds differ in their levels of complexity and full information is available on the utilized patterns.
Results
The results show that our proposed benchmark is able to evaluate the pattern mining methods quantitatively and objectively. Also, it can be used to compare pattern mining methods in a fair and repeatable manner.
Conclusions
Based on our findings, it can be argued that benchmarking in the pattern mining field is significantly less mature than topics such as presenting a new detection method. Therefore, special attention is needed in the pattern evaluation topic. Our proposed benchmark is a step towards achieving a comparative understanding of the effectiveness of detection methods and demonstrating their strengths and weaknesses.",May 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The benchmark proposed in this abstract can significantly impact early-stage ventures by providing a quantitative and objective way to compare pattern mining methods, a crucial aspect in software design."
https://www.sciencedirect.com/science/article/pii/S095058491930028X,A model of requirements engineering in software startups,Jorge=Melegati: jmelegatigoncalves@unibz.it,"Abstract
Context
Over the past 20 years, software startups have created many products that have changed human life. Since these companies are creating brand-new products or services, requirements are difficult to gather and highly volatile. Although scientific interest in software development in this context has increased, the studies on 
requirements engineering
 in software startups are still scarce and mostly focused on elicitation activities.
Objective
This study overcomes this gap by answering how 
requirements engineering
 practices are performed in this context.
Method
We conducted a grounded theory study based on 17 interviews with software startups practitioners.
Results
We constructed a model to show that software startups do not follow a single set of practices but, instead, build a custom process, changed throughout the development of the company, combining different practices according to a set of influences (Founders, Software Development Manager, Developers, Market, Business Model and Startup Ecosystem).
Conclusion
Our findings show that requirements engineering activities in software startups are similar to those in agile teams, but some steps vary as a consequence of the lack of an accessible customer.",May 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"This study on requirements engineering practices in software startups can be beneficial for early-stage ventures looking to understand and improve their development processes, but the findings are more specific to agile teams."
https://www.sciencedirect.com/science/article/pii/S0950584919300291,Empirical evaluation and proposals for bands-based COSMIC early estimation methods,,"Abstract
Background
. In the early phases of software development projects, thorough application of the 
COSMIC
 functional size measurement method may require more time and effort than available. Thus, early approximate methods have been proposed for estimating the 
COSMIC
 functional size of an application, instead of measuring it.
Objective
. The goal of this paper is to empirically evaluate the accuracy of the COSMIC early size estimation methods that are based on evaluations at the functional process level, for which 
historical data
 are available. The goal is to provide practitioners with empirical evidence on the accuracy of these methods.
Method
. We evaluated the Average Functional Process and the Equal Size Bands methods. We also proposed and evaluated two new approaches for defining bands in the Fixed Size Classification method. The estimation was performed by applying these methods to a set of 
software applications
 for which the data necessary to perform estimations were available, having been previously measured according to the standard COSMIC method.
Results
. Our analyses show that the Average Functional Process method generally provides estimates that are reasonable for early and quick sizing, but in some cases its 
estimation errors
 are too large to be acceptable. On the contrary, the methods using bands can provide quite accurate estimates. We determine the level of accuracy that can be obtained based on the type of method used, the number of bands used, and the quantitative characterization of the ability to classify each functional process in the correct band.
Conclusions
. The Average Functional Process method may be unreliable, as it occasionally yields quite large errors. Organizations using bands-based methods cannot just follow the prescribed estimation process: they need to properly train people in charge of classifying functional processes in the correct size band.",May 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The evaluation of early size estimation methods can directly benefit European early-stage ventures by providing empirical evidence on the accuracy of these methods, which can help in resource allocation and project planning."
https://www.sciencedirect.com/science/article/pii/S0950584918302477,Model-based test suite generation for graph transformation system using model simulation and search-based techniques,Akram=Kalaee: a-kalaee@arshad.araku.ac.ir; Vahid=Rafe: v-rafe@araku.ac.ir,"Abstract
Context
Test generation by model checking is a useful technique in model-based testing that allows automatic generation of test cases from models by utilizing the counter-examples/witnesses produced through a 
model checker
. However, generating redundant test cases and state space explosion problem are two major obstacles to transfer this technique into industrial practice.
Objective
An idea to cope with these challenges consists in an intelligent model checking for exploring only a portion of the state space according to the test objectives. Motivated by this idea, we propose an approach that exploits meta-heuristic algorithms to adapt a 
model checker
 when used for integration testing of systems formally specified by graph transformations.
Method
This method is not based on 
model checking algorithms
, but rather uses the 
modeling and simulation
 features of the underlying model checker. In the proposed approach, a population of test suites that each of which is a set of paths on the state space, is evolved towards satisfying the all def-use test objectives. Consequently, a test suite with high coverage is generated.
Results
To assess the efficiency of our approach, it is implemented in GROOVE, an open source toolset for designing and model checking graph transformation systems. Empirical results based on some 
case studies
, confirm a significant improvement in terms of coverage, speed and memory usage, in comparison with the 
state of the art techniques
.
Conclusion
Our analysis reveals that intelligent model checking can appropriately address the challenges of traditional model-checking-assisted testing. We further conclude that graph transformation specification is an efficient modeling solution to behavioral testing and graph transformation tools have a great potential for developing a model-based testing tool.",April 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The approach proposed in this abstract for intelligent model checking can greatly impact the efficiency of testing processes in software development, providing a practical solution to challenges faced in industrial practice."
https://www.sciencedirect.com/science/article/pii/S0950584918302490,A survey on software testability,Vahid=Garousi: vahid.garousi@wur.nl; Feyza Nur=Kılıçaslan: feyzanur@cs.hacettepe.edu.tr,"Abstract
Context
Software testability is the degree to which a software system or a unit under test supports its own testing. To predict and improve software testability, a large number of techniques and metrics have been proposed by both practitioners and researchers in the last several decades. Reviewing and getting an overview of the entire state-of-the-art and state-of-the-practice in this area is often challenging for a practitioner or a new researcher.
Objective
Our objective is to summarize the body of knowledge in this area and to benefit the readers (both practitioners and researchers) in preparing, measuring and improving software testability.
Method
To address the above need, the authors conducted a survey in the form of a systematic literature mapping (classification) to find out what we as a community know about this topic. After compiling an initial pool of 303 papers, and applying a set of inclusion/exclusion criteria, our final pool included 208 papers (published between 1982 and 2017).
Results
The area of software testability has been comprehensively studied by researchers and practitioners. Approaches for measurement of testability and improvement of testability are the most-frequently addressed in the papers. The two most often mentioned factors affecting testability are observability and controllability. Common ways to improve testability are testability transformation, improving observability, adding assertions, and improving controllability.
Conclusion
This paper serves for both researchers and practitioners as an “index” to the vast body of knowledge in the area of testability. The results could help practitioners measure and improve software testability in their projects. To assess 
potential benefits
 of this review paper, we shared its draft version with two of our industrial collaborators. They stated that they found the review useful and beneficial in their testing activities. Our results can also benefit researchers in observing the trends in this area and identify the topics that require further investigation.",April 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"While the survey on software testability provides an overview of the state-of-the-art, the practical value for European early-stage ventures may be limited as it is more focused on summarizing existing knowledge."
https://www.sciencedirect.com/science/article/pii/S0950584918302507,A systematic mapping study of infrastructure as code research,Akond=Rahman: aarahman@ncsu.edu,"Abstract
Context:
 Infrastructure as code (IaC) is the practice to automatically configure system dependencies and to provision local and remote instances. Practitioners consider IaC as a fundamental pillar to implement 
DevOps
 practices, which helps them to rapidly deliver software and services to end-users. Information technology (IT) organizations, such as GitHub, Mozilla, Facebook, Google and Netflix have adopted IaC. A 
systematic mapping study
 on existing IaC research can help researchers to identify potential research areas related to IaC, for example defects and security flaws that may occur in IaC scripts.
Objective:
 The objective of this paper is to help researchers identify research areas related to infrastructure as code (IaC) by conducting a 
systematic mapping study
 of IaC-related research.
Method:
 We conduct our research study by searching five scholar databases. We collect a set of 31,498 publications by using seven search strings. By systematically applying inclusion and exclusion criteria, which includes removing duplicates and removing non-English and non peer-reviewed publications, we identify 32 publications related to IaC. We identify topics addressed in these publications by applying qualitative analysis.
Results:
 We identify four topics studied in IaC-related publications: (i) framework/tool for infrastructure as code; (ii) adoption of infrastructure as code; (iii) empirical study related to infrastructure as code; and (iv) testing in infrastructure as code. According to our analysis, 50.0% of the studied 32 publications propose a framework or tool to implement the practice of IaC or extend the functionality of an existing IaC tool.
Conclusion:
 Our findings suggest that framework or tools is a well-studied topic in IaC research. As defects and security flaws can have serious consequences for the deployment and development environments in 
DevOps
, we observe the need for research studies that will study defects and security flaws for IaC.",April 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The research on IaC can have a practical impact on improving software delivery processes in IT organizations, making it relevant for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584918302519,Impact of model notations on the productivity of domain modelling: An empirical study,Santiago=Meliá: santi@dlsi.ua.es; Cristina=Cachero: ccachero@dlsi.ua.es; Jesús M.=Hermida: jhermida@dlsi.ua.es,"Abstract
Context
The intensive use of models is a cornerstone of the Model-Driven Engineering (MDE) paradigm and its claimed gains in productivity. However, in order to maximize these productivity gains, it is important to adequately select the modeling formalism to be used. Unfortunately, the MDE community still lacks empirical data to support such choice.
Objective
This paper aims at contributing to filling this gap by reporting an empirical study in which two types of domain model notations, graphical vs. textual, are compared regarding their efficiency and effectiveness during the creation of domain models.
Method
A quasi-experiment was designed in which 127 participants were randomly classified in four groups. Then, each group was randomly assigned to a different combination of notation and application. All the participants were students enrolled in the 6th semester of the Computer Engineering degree at the University of Alicante. The statistical procedure applied was a two-factor multivariate analysis of variance (two-way MANOVA).
Results
The data shows a statistically significant effect of notation type on the efficiency and effectiveness of domain modelling activities, independently from the application being modelled.
Conclusion
The joint examination of our results and those of previous studies suggests that, in MDE, different tasks call for different types of notations. Therefore, MDE environments should offer both textual and graphical notations, and assist developers in selecting the most suitable one depending on the task being carried out. In particular, our data suggest that domain model creation tasks are better supported by graphical notations. To augment the validity of the conclusions of this paper, the experiment should be replicated with different subject profiles, notations, domain model sizes, tasks and application types.",April 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study on selecting modeling formalism in MDE can provide valuable insights for startups looking to maximize productivity gains, hence scoring higher in practical value."
https://www.sciencedirect.com/science/article/pii/S0950584918302593,Live programming in practice: A controlled experiment on state machines for robotic behaviors,Miguel=Campusano: mcampusa@dcc.uchile.cl; Johan=Fabry: jfabry@gmail.com; Alexandre=Bergel: abergel@dcc.uchile.cl,"Abstract
Context
Live programming environments are gaining momentum across multiple programming languages. A tenet of live programming is a development feedback cycle, resulting in faster development practices. Although practitioners of live programming consider it a positive inclusion in their workflow, no in-depth investigations have yet been conducted on its benefits in a realistic scenario, nor using complex API.
Objective
This paper carefully studies the advantage of using live programming in defining nested state machines for robot behaviors. We analyzed two important aspects of developing robotic behaviors using these machines: 
program comprehension
 and program writing. We analyzed both development practices in terms of speed and accuracy.
Method
We conducted two controlled experiments, one for 
program comprehension
 and another for program writing. We measured the speed and accuracy of randomized assigned participants on completing programming tasks, against a baseline.
Results
In a robotic behavior context, we found that a live programming system for nested state machine programs does not significantly outperform a non-live language in program comprehension nor in program writing in terms of speed and accuracy. However, the feedback of test subjects indicates their preference for the live programming system.
Conclusions
The results of this work seem to contradict the studies of live programming in other areas, even while participants still favor using live programming techniques. We learned that the complex API chosen in this work has a strong negative influence on the results. To the best of our knowledge, this is the first in-depth live programming experiment in a complex domain.",April 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"While the study on live programming in robot behaviors is interesting, the lack of significant performance improvement limits its practical applicability for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584918302623,Machine learning techniques for code smell detection: A systematic literature review and meta-analysis,Qing=Wang: wq@itechs.iscas.ac.cn; Muhammad Ilyas=Azeem: azeem@itechs.iscas.ac.cn; Fabio=Palomba: palomba@ifi.uzh.ch; Lin=Shi: shilin@itechs.iscas.ac.cn,"Abstract
Background
: Code smells indicate suboptimal design or implementation choices in the source code that often lead it to be more change- and fault-prone. Researchers defined dozens of code smell detectors, which exploit different sources of information to support developers when diagnosing design flaws. Despite their good accuracy, previous work pointed out three important limitations that might preclude the use of code smell detectors in practice: (i) subjectiveness of developers with respect to code smells detected by such tools, (ii) scarce agreement between different detectors, and (iii) difficulties in finding good thresholds to be used for detection. To overcome these limitations, the use of 
machine learning techniques
 represents an ever increasing research area.
Objective
: While the research community carefully studied the methodologies applied by researchers when defining heuristic-based code smell detectors, there is still a noticeable lack of knowledge on how 
machine learning approaches
 have been adopted for code smell detection and whether there are points of improvement to allow a better detection of code smells. Our goal is to provide an overview and discuss the usage of 
machine learning approaches
 in the field of code smells.
Method
: This paper presents a Systematic Literature Review (SLR) on Machine Learning Techniques for Code Smell Detection. Our work considers papers published between 2000 and 2017. Starting from an initial set of 2456 papers, we found that 15 of them actually adopted machine learning approaches. We studied them under four different perspectives: (i) code smells considered, (ii) setup of machine learning approaches, (iii) design of the evaluation strategies, and (iv) a meta-analysis on the performance achieved by the models proposed so far.
Results
: The analyses performed show that 
God Class, Long Method, 
Functional Decomposition
, and 
Spaghetti Code
 have been heavily considered in the literature. 
Decision Trees
 and 
Support Vector Machines
 are the most commonly used 
machine learning algorithms
 for code smell detection. Models based on a large set of independent variables have performed well. 
JRip
 and 
Random Forest
 are the most effective classifiers in terms of performance. The analyses also reveal the existence of several open issues and challenges that the research community should focus on in the future.
Conclusion
: Based on our findings, we argue that there is still room for the improvement of 
machine learning techniques
 in the context of code smell detection. The open issues emerged in this study can represent the input for researchers interested in developing more powerful techniques.",April 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The use of machine learning techniques for code smell detection can have a significant impact on software development practices, making it relevant and valuable for startups."
https://www.sciencedirect.com/science/article/pii/S0950584919300011,The current state of software license renewals in the I.T. industry,James=Miller: jimm@ualberta.ca; Aindrila=Ghosh: aindrila@ualberta.ca; Mona=Nashaat: nashaata@ualberta.ca,"Abstract
Context
The software industry has changed significantly in the 21st century; no longer is it dominated by organizations seeking to sell products directly to customers, instead most 
multinational organizations
 nowadays provide services via licensing agreements. These licenses are for a fixed-duration; and hence, the question of their renewal becomes of 
paramount importance
 for the selling organization’s revenue.
Objective
Despite its financial impact, the topic of license renewal strategies, processes, tools, and support receives very limited attention in the research literature. Hence, it is believed that an interesting research question is: What is the state of current industrial practice in this essential field?
Method
To initially explore the topic of license renewals, this paper implements the 
Grounded theory method
. To implement the method, semi-structured, cross-sectional, anonymous, selfreported interviews are carried out with 20 professionals from multiple organizations, later the Constant Comparative Method is used to analyse the 
collected data
.
Results
This paper presents a synthesized picture of the current industrial practice of the end-to-end software license 
renewal process
. Alongside, it also identifies a set of challenges and risk factors that impact on renewal decisions of customers, hence on the overall revenue of seller organizations. Finally, using structured brainstorming techniques, this paper identifies 11 future research directions, that can help organizations with the mitigation of the risks in the license 
renewal process
.
Conclusion
It is concluded that lack of effective communication among stakeholders, the absence of customer trust, and scarcity of value generated from purchased licenses are among the primary drivers that influence renewal decisions. Also, there is a need to invest in intelligent automation along with 
artificial intelligence
 enabled analytics in order to enhance customer satisfaction.",April 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The research on software license renewal processes is important but might have limited immediate practical value for startups unless they are in the software licensing industry.
https://www.sciencedirect.com/science/article/pii/S095058491830209X,An extensible collaborative framework for monitoring software quality in critical systems,Marisol=García-Valls: mvalls@it.uc3m.es; Julio=Escribano-Barreno: jebarreno@indra.es; Javier=García-Muñoz: 100291551@alumnos.uc3m.es,"Abstract
Context
Current practices on software quality monitoring for critical software systems development rely on the manual integration of the information provided by a number of independent commercial tools for code analysis; some external tools for code analysis are mandatory in some critical software projects that must comply with specific norms. However, there are no approaches to providing an integrated view over the analysis results of independent external tools into a unified software quality framework.
Objective
This paper presents the design and development of ESQUF (Enhanced Software Quality Monitoring Framework) suitable for critical software systems. It provides the above enriched quality results presentation derived not only from multiple external tools but from the local analysis functions of the framework.
Method
An analysis of the norms and standards that apply to critical software systems is provided. The detailed and modular design of ESQUF adjusts to the integration requirements for external tools. UML is used for designing the framework, and Java is used to provide the detailed design. The framework is validated with a prototype implementation that integrates two different external tools and their respective quality results over a real software project 
source code
.
Results
The integration of results files and data from external tools as well as from internal analysis functions is enabled. The analysis of critical software projects is made posible yielding a 
collaborative space
 where 
verification engineers
 
share information
 about code analysis activities of specific projects; and single 
presentation space
 with rich static and dynamic analysis information of software projects that comply with the required development norms.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The development of ESQUF framework for critical software systems could have a significant impact on improving software quality monitoring, which is crucial for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584918302210,Slimming javascript applications: An approach for removing unused functions from javascript libraries,Alexandre=Bergel: abergel@dcc.uchile.cl; H.C.=Vázquez: hvazquez@exa.unicen.edu.ar; S.=Vidal: svidal@exa.unicen.edu.ar; J.A.=Díaz Pace: adiaz@exa.unicen.edu.ar; C.=Marcos: cmarcos@exa.unicen.edu.ar,"Abstract
Context
A 
common practice
 in JavaScript development is to ship and deploy an application as a large file, called 
bundle
, which is the result of combining the application code along with the code of all the libraries the application depends on. Despite the benefits of having a single bundle per application, this approach leads to applications being shipped with significant portions of code that are actually not used, which unnecessarily inflates the JavaScript bundles and could slow down website loading because of the extra unused code. Although some 
static analysis
 techniques exist for removing unused code, our investigations suggest that there is still room for improvements.
Objective
The goal of this paper is to address the problem of reducing the size of bundle files in JavaScript applications.
Method
In this context, we define the notion of Unused Foreign Function (UFF) to denote a JavaScript function contained in dependent libraries that is not needed at runtime. Furthermore, we propose an approach based on dynamic analysis that assists developers to identify and remove UFFs from JavaScript bundles.
Results
We report on a case-study performed over 22 JavaScript applications, showing evidence that our approach can produce size reductions of 26% on average (with reductions going up to 66% in some applications).
Conclusion
It is concluded that removing unused foreign functions from JavaScript bundles helps reduce their size, and thus, it can boost the results of existing 
static analysis
 techniques.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"Addressing the problem of reducing the size of bundle files in JavaScript applications is valuable, although the direct impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584918302234,Adapting usability techniques for application in open source Software: A multiple case study,Silvia T.=Acuña: silvia.acunna@uam.es; Lucrecia=Llerena: lucrecia.llerena@estudiante.uam.es; Nancy=Rodriguez: nancy.rodriguez@estudiante.uam.es; John W.=Castro: john.castro@uda.cl,"Abstract
Context
As a result of the growth of non-developer users of 
OSS applications
, usability has over the last ten years begun to attract the interest of the open source software (OSS) community. The 
OSS
 community has some special characteristics (such as worldwide geographical distribution of both users and developers and missing resources) which are an obstacle to the direct adoption of many usability techniques as specified in the human-computer interaction (HCI) field.
Objective
The aim of this research is to adapt and evaluate the feasibility of applying four usability techniques: user profiles, personas, direct observation and post-test information to four 
OSS projects
 from the viewpoint of the development team.
Method
The applied research method was a multiple 
case study
 of the following 
OSS projects
: Quite Universal Circuit Simulator, PSeInt, FreeMind and OpenOffice Writer.
Results
We formalized the application procedure of each of the adapted usability techniques. We found that either there were no procedures for adopting usability techniques in 
OSS
 or they were not fully systematized. Additionally, we identified the adverse conditions that are an obstacle to their adoption in OSS and propose the special adaptations required to overcome the obstacles. To avoid some of the adverse conditions, we created web artefacts (online survey, 
wiki
 and forum) that are very popular in the OSS field.
Conclusion
It is necessary to adapt usability techniques for application in OSS projects considering their idiosyncrasy. Additionally, we found that there are obstacles (for example, number of participant users, biased information provided by developers) to the application of the techniques. Despite these obstacles, it is feasible to apply the adapted techniques in OSS projects.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"Adapting usability techniques for OSS projects is important, but the practical impact on European early-stage ventures may require further validation."
https://www.sciencedirect.com/science/article/pii/S095058491830226X,On semantic detection of cloud API (anti)patterns,Fabio=Petrillo: fabio@petrillo.com; Hayet=Brabra: hayet.brabra@telecom-sudparis.eu; Achraf=Mtibaa: achraf.mtibaa@enetcom.usf.tn; Philippe=Merle: philippe.merle@inria.fr; Layth=Sliman: layth.sliman@efrei.fr; Naouel=Moha: moha.naouel@uqam.ca; Walid=Gaaloul: walid.gaaloul@telecom-sudparis.eu; Yann-Gaël=Guéhéneuc: yann-gael.gueheneuc@polymtl.ca; Boualem=Benatallah: boualem@cse.unsw.edu.au; Faïez=Gargouri: faiez.gargouri@isims.usf.tn,"Abstract
Context
Open standards are urgently needed for enabling software interoperability in 
Cloud Computing
. Open 
Cloud Computing
 Interface (OCCI) provides a set of best design principles to create interoperable REST management APIs. Although OCCI is the only standard addressing the management of any kind of cloud resources, it does not support a range of best principles related to REST design. This often worsens REST API quality by decreasing their 
understandability
 and 
reusability
.
Objective
We aim at assisting cloud developers to enhance their REST management APIs by providing a compliance evaluation of OCCI and REST best principles and a recommendation support to comply with these principles.
Method
First, we leverage patterns and anti-patterns to drive respectively the good and poor practices of OCCI and REST best principles. Then, we propose a semantic-based approach for defining and detecting REST and OCCI (anti)patterns and providing a set of correction recommendations to comply with both REST and OCCI best principles. We validated this approach by applying it on cloud REST APIs and evaluating its accuracy, usefulness and extensibility.
Results
We found that our approach accurately detects OCCI and REST(anti)patterns and provides useful recommendations. According to the compliance results, we reveal that there is no widespread adoption of OCCI principles in existing APIs. In contrast, these APIs have reached an 
acceptable level
 of maturity regarding REST principles.
Conclusion
Our approach provides an effective and extensible technique for defining and detecting OCCI and REST (anti)patterns in Cloud REST APIs. Cloud software developers can benefit from our approach and defined principles to accurately evaluate their APIs from OCCI and REST perspectives. This contributes in designing interoperable, understandable, and reusable Cloud management APIs. Thank to the compliance analysis and the recommendation support, we also contribute to improving these APIs, which make them more straightforward.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,Enhancing REST management APIs in Cloud Computing through compliance evaluation and recommendations could have a moderate impact on European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584918302313,Information quality requirements engineering with STS-IQ,Mohamad=Gharib: mohamad.gharib@unifi.it; Paolo=Giorgini: paolo.giorgini@unitn.it,"Abstract
Context
Information Quality (IQ) is particularly important for organizations: they depend on information for managing their daily tasks and relying on low-quality information may negatively influence their overall performance. Despite this, the literature shows that most software development approaches do not consider IQ requirements during the system design, which leaves the system open to different kinds of vulnerabilities.
Objective
The main objective of this research is proposing a framework for modeling and analyzing IQ requirements for Socio-Technical Systems (STS).
Method
We propose STS-IQ, a goal-oriented framework for modeling and analyzing IQ requirements in their social and organizational context since the early phases of the system design. The framework extends and refines our previous work, and it consists of: (i) a 
modeling language
 that provides concepts and constructs for modeling IQ requirements; (ii) a set of analysis techniques that support the verification of the correctness and consistency of the IQ requirements model; (iii) a mechanism for deriving the final IQ specifications in terms of IQ policies; (iv) a methodology to assist software engineers during the system design; and (v) a CASE tool, namely STS-IQ Tool.
Result
We demonstrated the applicability, usefulness, and scalability of the modeling and reasoning techniques within a stock market 
case study
, and we also evaluated the usability and utility of the framework with end-users.
Conclusion
We conclude that the STS-IQ framework supports the modeling and analysis of IQ requirements, and also the derivation of precise IQ specifications in terms of IQ policies. Therefore, we believe it has potential in practice.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The proposed STS-IQ framework addresses an important issue in software development and has demonstrated applicability and utility in a case study, showing potential practical value."
https://www.sciencedirect.com/science/article/pii/S0950584918302325,Exploratory testing: Do contextual factors influence software fault identification?,Fredrik=Asplund: fasplund@kth.se,"Abstract
Context:
 Exploratory Testing (ET) is a manual approach to software testing in which learning, test design and test execution occurs simultaneously. Still a developing topic of interest to academia, although as yet insufficiently investigated, most studies focus on the skills and experience of the individual tester. However, contextual factors such as project processes, test scope and organisational boundaries are also likely to affect the approach.
Objective:
 This study explores contextual differences between teams of testers at a MedTec firm developing safety-critical products to ascertain whether contextual factors can influence the outcomes of ET, and what associated implications can be drawn for test management.
Method:
 A development project was studied in two iterations, each consisting of a quantitative phase testing hypotheses concerning when ET would identify faults in comparison to other testing approaches and a qualitative phase involving interviews.
Results:
 Influence on ET is traced to how the scope of tests focus learning on different types of knowledge and imply an asymmetry in the strength and number of information flows to test teams.
Conclusions:
 While test specialisation can be attractive to software development organisations, results suggest changes to processes and organisational structures might be required to maintain test efficiency throughout projects: the responsibility for test cases might need to be rotated late in projects, and asymmetries in information flows might require management to actively strengthen the presence and connections of test teams throughout the firm. However, further research is needed to investigate whether these results also hold for non safety-critical faults.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"The study on contextual differences in exploratory testing provides insights for test management, but the implications for practical application in startups are not clearly defined."
https://www.sciencedirect.com/science/article/pii/S0950584918302416,A two-phase transfer learning model for cross-project defect prediction,Chao=Liu: liu.chao@cqu.edu.cn; Xin=Xia: xin.xia@monash.edu; Dan=Yang: dyang@cqu.edu.cn; Meng=Yan: mengy@zju.edu.cn; Xiaohong=Zhang: xhongz@cqu.edu.cn,"Abstract
Context:
 Previous studies have shown that a 
transfer learning
 model, TCA+ proposed by Nam et al., can significantly improve the performance of cross-project 
defect prediction
 (CPDP). TCA+ achieves the improvement by reducing 
data distribution
 difference between source (training data) and target (testing data) projects. However, TCA+ is unstable, i.e., its performance varies largely when using different source projects to build prediction models. In practice, it is hard to choose a suitable source project to build the prediction model.
Objective:
 To address the limitation of TCA+, we propose a two-phase 
transfer learning
 model (TPTL) for CPDP.
Method:
 In the first phase, we propose a source project estimator (SPE) to automatically choose two source projects with the highest distribution similarity to a target project from candidates. Next, two source projects that are estimated to achieve the highest values of F1-score and cost-effectiveness are selected. In the second phase, we leverage TCA+ to build two prediction models based on the two selected projects and combine their prediction results to further improve the prediction performance.
Results:
 We evaluate TPTL on 42 defect datasets from PROMISE repository, and compare it with two versions of TCA+ (TCA+_Rnd, randomly selecting one source project; TCA+_All, using all alternative source projects), a related source project selection model TDS proposed by Herbold, a state-of-the-art CPDP model leveraging a log transformation (LT) method, and a 
transfer learning
 model Dycom with better form of TCA. Experiment results show that, on average across 42 datasets, TPTL respectively improves these 
baseline models
 by 19%, 5%, 36%, 27%, and 11% in terms of F1-score; by 64%, 92%, 71%, 11%, and 66% in terms of cost-effectiveness.
Conclusion:
 The proposed TPTL model can solve the instability problem of TCA+, showing substantial improvements over the state-of-the-art and related CPDP models.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The TPTL model addresses the instability issue of an existing model with significant improvements in performance across various datasets, making it highly valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584918302428,FSCT: A new fuzzy search strategy in concolic testing,Arash=Sabbaghi: a.sabbaghi@qiau.ac.ir; Hamidreza=Rashidy Kanan: h.rashidykanan@sru.ac.ir; Mohammad Reza=Keyvanpour: keyvanpour@alzahra.ac.ir,"Abstract
Context
Concolic testing is a promising approach to automate structural test data generation. However, combinatorial explosion of the path space, known as path explosion, and also constrained testing budget, makes achieving high code coverage in concolic testing a challenging task.
Objective
All branches of the previously explored paths make up the 
search space
 of concolic testing and search strategy define the mechanism of choosing branches to be flipped to drive the execution toward testing goals. With regard to the large number of candidate branches, choosing the right branch to continue the search is so crucial and has a direct impact on coverage rate and effort. This paper aims to improve the effectiveness of branch testing by considering the characteristics of paths reaching uncovered branches and presenting a novel search strategy for effectively and efficiently exploring the 
search space
.
Method
We model the branch selection process in concolic testing as a decision making system and introduce a new Fuzzy Search Strategy in Concolic Testing (FSCT). FSCT chooses a branch to be filliped in which the most suitable path with respect to the proposed 
coverage factors
 reaches an uncovered branch with the highest priority and this priority is assigned by the designed fuzzy 
expert system
. The proposed 
coverage factors
 effectively help to determine the characteristics of paths.
Results
We implemented FSCT on top of CREST and evaluated it using several popular benchmarks. The experimental results show that FSCT outperforms the state-of-the-art techniques in terms of coverage rate and coverage effort.
Conclusion
FSCT helps concolic testing to better cope with path explosion problem and shows its capabilities to achieve higher code coverage while at the same time decreases testing efforts in terms of both runtime and number of iterations.",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The FSCT approach in concolic testing shows better coverage rates and effort reductions, highlighting its potential impact on efficiency and effectiveness for startups in software testing."
https://www.sciencedirect.com/science/article/pii/S0950584918302441,A survey on software coupling relations and tools,Fabio=Palomba: palomba@ifi.uzh.ch; Enrico=Fregnan: fregnan@ifi.uzh.ch; Tobias=Baum: tobias.baum@inf.uni-hannover.de; Alberto=Bacchelli: bacchelli@ifi.uzh.ch,"Abstract
Context
Coupling relations reflect the dependencies between software entities and can be used to assess the quality of a program. For this reason, a vast amount of them has been developed, together with tools to compute their related metrics. However, this makes the coupling measures suitable for a given application challenging to find.
Goals
The first objective of this work is to provide a classification of the different kinds of coupling relations, together with the metrics to measure them. The second consists in presenting an overview of the tools proposed until now by the 
software engineering
 academic community to extract these metrics.
Method
This work constitutes a systematic literature review in 
software engineering
. To retrieve the referenced publications, publicly available scientific research databases were used. These sources were queried using keywords inherent to software coupling. We included publications from the period 2002 to 2017 and highly cited earlier publications. A snowballing technique was used to retrieve further related material.
Results
Four groups of coupling relations were found: structural, dynamic, semantic and logical. A fifth set of coupling relations includes approaches too recent to be considered an 
independent group
 and measures developed for specific environments. The investigation also retrieved tools that extract the metrics belonging to each coupling group.
Conclusion
This study shows the directions followed by the research on software coupling: e.g., developing metrics for specific environments. Concerning the metric tools, three trends have emerged in recent years: use of visualization techniques, extensibility and scalability. Finally, some coupling metrics applications were presented (e.g., code smell detection), indicating possible future research directions. 
Public preprint
 [
https://doi.org/10.5281/zenodo.2002001
].",March 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The systematic literature review on software coupling metrics provides a comprehensive overview, but the direct practical implications for early-stage ventures are not explicitly stated."
https://www.sciencedirect.com/science/article/pii/S0950584918301873,Metrics for analyzing variability and its implementation in software product lines: A systematic literature review,Klaus=Schmid: schmid@sse.uni-hildesheim.de; Sascha=El-Sharkawy: elscha@sse.uni-hildesheim.de,"Abstract
Context:
 Software Product Line (SPL) development requires at least concepts for variability implementation and 
variability modeling
 for deriving products from a product line. These variability implementation concepts are not required for the development of single systems and, thus, are not considered in traditional 
software engineering
. Metrics are well established in traditional 
software engineering
, but existing metrics are typically not applicable to SPLs as they do not address variability management. Over time, various specialized product line metrics have been described in literature, but no systematic description of these metrics and their characteristics is currently available.
Objective:
 This paper describes and analyzes variability-aware metrics, designed for the needs of software product lines. More precisely we restrict the scope of our study explicitly to metrics designed for variability models, code artifacts, and metrics taking both kinds of artifacts into account. Further, we categorize the purpose for which these metrics were developed. We also analyze to what extent these metrics were evaluated to provide a basis for researchers for selecting adequate metrics.
Method:
 We conducted a systematic literature review to identify variability-aware implementation metrics. We discovered 42 relevant papers reporting metrics intended to measure aspects of variability models or code artifacts.
Results:
 We identified 57 variability model metrics, 34 annotation-based 
code metrics
, 46 
code metrics
 specific to composition-based implementation techniques, and 10 metrics integrating information from variability model and code artifacts. For only 31 metrics, an evaluation was performed assessing their suitability to draw any qualitative conclusions.
Conclusions:
 We observed several problematic issues regarding the definition and the use of the metrics. Researchers and practitioners benefit from the catalog of variability-aware metrics, which is the first of its kind. Also, the research community benefits from the identified observations in order to avoid those problems when defining new metrics.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,2.0,"While the paper provides insights into variability-aware metrics for software product lines, the practical value for early-stage ventures is limited as it is more focused on academia and research."
https://www.sciencedirect.com/science/article/pii/S0950584918301903,Cognitive complexity as a quantifier of version to version Java-based source code change: An empirical probe,Loveleen=Kaur: loveleen.kaur@thapar.edu; Ashutosh=Mishra: ashutosh.mishra@thapar.edu,"Abstract
Context
It has been often argued that it is challenging to modify code fragments from existing software that contains files that are difficult to comprehend. Since systematic software maintenance includes an extensive human activity, cognitive complexity is one of the intrinsic factors that could potentially contribute to or impede an efficient software maintenance practice, the empirical validation of which remains vastly unaddressed.
Objective
This study conducts an experimental analysis in which the software developer's level of difficulty in comprehending the software: the cognitive complexity, is theoretically computed and empirically evaluated for estimating its relevance to actual software change.
Method
For multiple successive releases of two Java-based software projects, where the 
source code
 of a previous release has been substantively used in a novel release, we calculate the change results and the values of the cognitive complexity for each of the version's 
source code
 Java files. We construct eight datasets and build 
predictive models
 using statistical analysis and 
machine learning techniques
.
Results
The pragmatic comparative examination of the estimated cognitive complexity against prevailing metrics of software change and software complexity clearly validates the cognitive complexity metric as a noteworthy measure of version to version source code change.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,The study on cognitive complexity in software maintenance has some relevance for startups as it addresses a common challenge that may impact software change practices.
https://ieeexplore.ieee.org/document/10098596/,"Object Detection Using Deep Learning, CNNs and Vision Transformers: A Review",,"Detecting objects remains one of computer vision and image understanding applications’ most fundamental and challenging aspects. Significant advances in object detection have been achieved through improved object representation and the use of deep neural network models. This paper examines more closely how object detection has evolved in the era of deep learning over the past years. We present a literature review on various state-of-the-art object detection algorithms and the underlying concepts behind these methods. We classify these methods into three main groups: anchor-based, anchor-free, and transformer-based detectors. Those approaches are distinct in the way they identify objects in the image. We discuss the insights behind these algorithms and experimental analyses to compare quality metrics, speed/accuracy tradeoffs, and training methodologies. The survey compares the major convolutional neural networks for object detection. It also covers the strengths and limitations of each object detector model and draws significant conclusions. We provide simple graphical illustrations summarising the development of object detection methods under deep learning. Finally, we identify where future research will be conducted.",10 April 2023,"Object detection, Deep learning, Transformers, Feature extraction, Detectors, Convolutional neural networks, Visualization, Neural networks, Deep Learning, Convolutional Neural Network, Object Detection, Deep Convolutional Neural Network, Vision Transformer, Convolutional Network, Image Object, Detection Model, Object Detection Model, Object Detection Network, Loss Function, Convolutional Layers, Feature Maps, Negative Samples, Intersection Over Union, Bounding Box, Entire Image, Fully-connected Layer, Convolutional Neural Network Architecture, Region Proposal, You Only Look Once, Single Shot Multibox Detector, Anchor Boxes, MS COCO Dataset, Feature Pyramid Network, Object Detection Task, Region Proposal Network, Predicted Bounding Box, 3D Object Detection, Multiple Convolutional Layers, Object detection, deep learning, review, convolutional neural networks, transformers, survey, neural networks",IEEE Access,2025-03-17T00:00:00,8.0,Object detection using deep learning has significant practical value for startups working on computer vision applications. The comparison of state-of-the-art algorithms and insights can directly impact European early-stage ventures in this field.
https://www.sciencedirect.com/science/article/pii/S0950584917300770,Evaluating different i*-based approaches for selecting functional requirements while balancing and optimizing non-functional requirements: A controlled experiment,Jose=Zubcoff: jose.zubcoff@ua.es,"Abstract
Context
A relevant question in requirements engineering is which set of functional requirements (FR) to prioritize and implement, while keeping non-functional requirements (NFR) balanced and optimized.
Objective
We aim to provide empirical evidence that requirement engineers may perform better at the task of selecting FRs while optimizing and balancing NFRs using an alternative (automated) i* post-processed model, compared to the original i* model.
Method
We performed a controlled experiment, designed to compare the original i* graphical notation, with our post-processed i* visualizations based on Pareto efficiency (a tabular and a radar chart visualization). Our experiment consisted of solving different exercises of various complexity for selecting FRs while balancing NFR. We considered the efficiency (time spent to correctly answer exercises), and the effectiveness (regarding time: time spent to solve exercises, independent of correctness; and regarding correctness of the answer, independent of time).
Results
The efficiency analysis shows it is 3.51 times more likely to solve exercises correctly with our tabular and radar chart visualizations than with i*. Actually, i* was the most time-consuming (effectiveness regarding time), had a lower number of correct answers (effectiveness regarding correctness), and was affected by complexity. Visual or textual preference of the subjects had no effect on the score. Beginners took more time to solve exercises than experts if i* is used (no distinction if our Pareto-based visualizations are used).
Conclusion
For complex model instances, the Pareto front based tabular visualization results in more correct answers, compared to radar chart visualization. When we consider effectiveness regarding time, the i* graphical notation is the most time consuming visualization, independent of the complexity of the exercise. Finally, regarding efficiency, subjects consume less time when using radar chart visualization than tabular visualization, and even more so compared to the original i* graphical notation.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,The experiment comparing i* visualizations for requirements selection provides valuable insights that can benefit early-stage ventures in optimizing functional and non-functional requirements prioritization.
https://www.sciencedirect.com/science/article/pii/S0950584918301927,Creative goal modeling for innovative requirements,J.=Horkoff: jenho@chalmers.se; N.A.=Maiden: neil.maiden.1@city.ac.uk; D.=Asboth: david.asboth.2@city.ac.uk,"Abstract
Context
 When determining the functions and qualities (a.k.a. requirements) for a system, creativity is key to drive innovation and foster business success. However, creative requirements must be practically operationalized, grounded in concrete functions and system interactions. 
Requirements Engineering
 (RE) has produced a wealth of methods centered around goal modeling, in order to graphically explore the space of alternative requirements, linking functions to goals and dependencies. In parallel work, 
creativity theories
 from the social sciences have been applied to the design of creative requirements workshops, pushing stakeholders to develop innovative systems. Goal models tend to focus on what is known, while creativity workshops are expensive, require a specific skill set to facilitate, and produce mainly paper-based, unstructured outputs. 
Objective
 Our aim in this work is to explore beneficial combinations of the two areas of work in order to overcome these and other limitations, facilitating creative 
requirements elicitation
, supported by a simple extension of a well-known and structured requirements modeling technique. 
Method
 We take a Design Science approach, iterating over 
exploratory studies
, design, and summative validation studies. 
Results
 The result is the Creative Leaf tool and method supporting creative goal modeling for RE. 
Conclusion
 We support creative RE by making creativity techniques more accessible, producing structured digital outputs which better match to existing RE methods with associated analysis procedures and transformations.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,The Creative Leaf tool and method for creative requirements elicitation offers a practical approach that can be beneficial for startups in fostering innovation and structured digital outputs.
https://www.sciencedirect.com/science/article/pii/S0950584918301939,Guidelines for including grey literature and conducting multivocal literature reviews in software engineering,Mika V.=Mäntylä: mika.mantyla@oulu.fi; Vahid=Garousi: vahid.garousi@wur.nl,"Abstract
Context
A Multivocal Literature Review (MLR) is a form of a 
Systematic Literature Review
 (SLR) which includes the grey literature (e.g., blog posts, videos and white papers) in addition to the published (formal) literature (e.g., journal and conference papers). MLRs are useful for both researchers and practitioners since they provide summaries both the state-of-the art and –practice in a given area. MLRs are popular in other fields and have recently started to appear in 
software engineering
 (SE). As more MLR studies are conducted and reported, it is important to have a set of guidelines to ensure high quality of MLR processes and their results.
Objective
There are several guidelines to conduct SLR studies in SE. However, several phases of MLRs differ from those of traditional SLRs, for instance with respect to the search process and source quality assessment. Therefore, SLR guidelines are only partially useful for conducting MLR studies. Our goal in this paper is to present guidelines on how to conduct MLR studies in SE.
Method
To develop the MLR guidelines, we benefit from several inputs: (1) existing SLR guidelines in SE, (2), a literature survey of MLR guidelines and experience papers in other fields, and (3) our own experiences in conducting several MLRs in SE. We took the popular SLR guidelines of Kitchenham and Charters as the baseline and extended/adopted them to conduct MLR studies in SE. All derived guidelines are discussed in the context of an already-published MLR in SE as the running example.
Results
The resulting guidelines cover all phases of conducting and reporting MLRs in SE from the planning phase, over conducting the review to the final reporting of the review. In particular, we believe that incorporating and adopting a vast set of experience-based recommendations from MLR guidelines and experience papers in other fields have enabled us to propose a set of guidelines with solid foundations.
Conclusion
Having been developed on the basis of several types of experience and evidence, the provided MLR guidelines will support researchers to effectively and efficiently conduct new MLRs in any area of SE. The authors recommend the researchers to utilize these guidelines in their MLR studies and then share their lessons learned and experiences.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,4.0,"The guidelines for conducting Multivocal Literature Reviews provide some value for researchers and practitioners in software engineering, but the direct impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584918302040,Exploiting Parts-of-Speech for effective automated requirements traceability,Abdelwahab=Hamou-Lhadj: abdelw@ece.concordia.ca; Nasir=Ali: cnali@memphis.edu; Haipeng=Cai: hcai@eecs.wsu.edu; Jameleddine=Hassine: jhassine@kfupm.edu.sa,"Abstract
Context
Requirement traceability (RT) is defined as the ability to describe and follow the life of a requirement. RT helps developers ensure that relevant requirements are implemented and that the source code is consistent with its requirement with respect to a set of 
traceability links
 called 
trace links
. Previous work leverages Parts Of Speech (POS) tagging of software artifacts to recover trace links among them. These studies work on the premise that discarding one or more POS tags results in an improved accuracy of Information Retrieval (IR) techniques.
Objective
First, we show empirically that excluding one or more POS tags could negatively impact the accuracy of existing IR-based traceability approaches, namely the 
Vector Space Model
 (VSM) and the Jensen Shannon Model (JSM). Second, we propose a method that improves the accuracy of IR-based traceability approaches.
Method
We developed an approach, called 
ConPOS
, to recover 
trace links
 using constraint-based pruning. 
ConPOS
 uses major POS categories and applies constraints to the recovered trace links for pruning as a filtering process to significantly improve the effectiveness of IR-based techniques. We conducted an experiment to provide evidence that removing POSs does not improve the accuracy of IR techniques. Furthermore, we conducted two empirical studies to evaluate the effectiveness of 
ConPOS
 in recovering trace links compared to existing peer RT approaches.
Results
The results of the first empirical study show that removing one or more POS negatively impacts the accuracy of VSM and JSM. Furthermore, the results from the other empirical studies show that 
ConPOS
 provides 11%-107%, 8%-64%, and 15%-170% higher precision, recall, and 
mean average precision
 (MAP) than VSM and JSM.
Conclusion
We showed that 
ConPos
 outperforms existing IR-based RT approaches that discard some POS tags from the input documents.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The proposed ConPos method shows significant improvement in trace links recovery compared to existing approaches, which can have a positive impact on early-stage ventures by enhancing requirement traceability."
https://ieeexplore.ieee.org/document/9446143/,U-Net and Its Variants for Medical Image Segmentation: A Review of Theory and Applications,,"U-net is an image segmentation technique developed primarily for image segmentation tasks. These traits provide U-net with a high utility within the medical imaging community and have resulted in extensive adoption of U-net as the primary tool for segmentation tasks in medical imaging. The success of U-net is evident in its widespread use in nearly all major image modalities, from CT scans and MRI to X-rays and microscopy. Furthermore, while U-net is largely a segmentation tool, there have been instances of the use of U-net in other applications. Given that U-net's potential is still increasing, this narrative literature review examines the numerous developments and breakthroughs in the U-net architecture and provides observations on recent trends. We also discuss the many innovations that have advanced in deep learning and discuss how these tools facilitate U-net. In addition, we review the different image modalities and application areas that have been enhanced by U-net.",03 June 2021,"Image segmentation, Convolution, Biomedical imaging, Three-dimensional displays, Logic gates, Deep learning, Computer architecture, Medical Imaging, Image Segmentation, Medical Image Segmentation, Magnetic Resonance Imaging, Computed Tomography, Deep Learning, Imaging Modalities, Application Areas, Segmentation Task, U-Net Architecture, Convolutional Layers, Feature Maps, Deep Learning Models, Recurrent Neural Network, Image Object, Age-related Macular Degeneration, Generative Adversarial Networks, Deep Learning Techniques, Skip Connections, Retinal Vessels, U-Net Model, Expansive Path, Attention Gate, Fully Convolutional Network, 3D U-Net, Medical Image Analysis, U-Net For Segmentation, Feature Pyramid Network, Identity Mapping, Dice Similarity Coefficient, Biomedical imaging, deep learning, neural network architecture, segmentation, U-net",IEEE Access,2025-03-17T00:00:00,8.0,"The abstract explores the practical applications of U-net in medical imaging, highlighting its widespread use across different modalities. The discussion on recent developments and breakthroughs in U-net architecture provides valuable insights for startups looking to innovate in the medical imaging field."
https://www.sciencedirect.com/science/article/pii/S0950584918302076,Software defect number prediction: Unsupervised vs supervised methods,Xiang=Chen: xchencs@ntu.edu.cn; Dun=Zhang: dunnzhang0@gmail.com; Yingquan=Zhao: enockchao@gmail.com; Zhanqi=Cui: czq@bistu.edu.cn; Chao=Ni: jacknichao920209@gmail.com,"Abstract
Context: 
Software defect
 number prediction (SDNP) can rank the program modules according to the prediction results and is helpful for the optimization of testing 
resource allocation
.
Objective: In previous studies, supervised methods vs 
unsupervised methods
 is an active issue for just-in-time 
defect prediction
 and file-level 
defect prediction
 based on effort-aware 
performance measures
. However, this issue has not been investigated for SDNP. To the best of our knowledge, we are the first to make a thorough comparison for these two different types of methods.
Method: In our empirical studies, we consider 7 real open-source projects with 24 versions in total, use 
FPA
 and 
Kendall
 as our effort-aware 
performance measures
, and consider three different performance evaluation scenarios (i.e., within-version scenario, cross-version scenario, and cross-project scenario).
Result: We first identify two 
unsupervised methods
 with best performance. These two methods simply rank modules according to the value of metric LOC and metric RFC from large to small respectively. Then we compare 9 state-of-the-art supervised methods incorporating SMOTEND, which is used for handling 
class imbalance problem
, with the unsupervised method based on LOC metric (i.e., LOC_D method). Final results show that LOC_D method can perform significantly better than or the same as these supervised methods. Later motivated by a recent study conducted by Agrawla and Menzies, we apply differential evolutionary (DE) to optimize parameter value of SMOTEND used by these supervised methods and find that using DE can effectively improve the performance of these supervised methods for SDNP too. Finally, we continue to compare LOC_D with these optimized supervised methods using DE, and LOC_D method still has advantages in the performance, especially in the cross-version and cross-project scenarios.
Conclusion: Based on these results, we suggest that researchers need to use the unsupervised method LOC_D as the 
baseline method
, which is used for comparing their proposed novel methods for SDNP problem in the future.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,The comparison of supervised and unsupervised methods for software defect number prediction provides insights that can be beneficial for startups in optimizing testing resource allocation and improving performance evaluation in software development.
https://www.sciencedirect.com/science/article/pii/S0950584918302106,"Identifying, categorizing and mitigating threats to validity in software engineering secondary studies",Apostolos=Ampatzoglou: apostolos.ampatzoglou@gmail.com,"Abstract
Context
Secondary studies are vulnerable to threats to validity. Although, mitigating these threats is crucial for the credibility of these studies, we currently lack a systematic approach to identify, categorize and mitigate threats to validity for secondary studies.
Objective
In this paper, we review the corpus of secondary studies, with the aim to identify: (a) the trend of reporting threats to validity, (b) the most common threats to validity and corresponding 
mitigation actions
, and (c) possible categories in which threats to validity can be classified.
Method
To achieve this goal we employ the tertiary study research method that is used for synthesizing knowledge from existing secondary studies. In particular, we 
collected data
 from more than 100 studies, published until December 2016 in top quality 
software engineering
 venues (both journals and conference).
Results
Our results suggest that in recent years, secondary studies are more likely to report their threats to validity. However, the presentation of such threats is rather ad hoc, e.g., the same threat may be presented with a different name, or under a different category. To alleviate this problem, we propose a classification schema for reporting threats to validity and possible 
mitigation actions
. Both the classification of threats and the associated mitigation actions have been validated by an empirical study, i.e., Delphi rounds with experts.
Conclusion
Based on the proposed schema, we provide a checklist, which authors of secondary studies can use for identifying and categorizing threats to validity and corresponding mitigation actions, while readers of secondary studies can use the checklist for assessing the validity of the reported results.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,10.0,The systematic approach proposed to identify and mitigate threats to validity in secondary studies can greatly benefit startups by providing a structured way to ensure credibility and accuracy in research findings.
https://www.sciencedirect.com/science/article/pii/S0950584918302192,Heuristics for improving the rigour and relevance of grey literature searches for software engineering research,Austen=Rainer: austen.rainer@canterbury.ac.nz; Ashley=Williams: ashley.williams@pg.canterbury.ac.nz,"Abstract
Background:
 
Software engineering
 research has a growing interest in grey literature (GL). Aim: To improve the identification of relevant and rigorous GL. Method: We develop and demonstrate heuristics to find more relevant and rigorous GL. The heuristics generate stratified samples of search and post–search datasets using a formally structured set of 
search keywords
. Conclusion: The heuristics require further evaluation. We are developing a tool to implement the heuristics.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The development of heuristics to identify relevant and rigorous grey literature can potentially assist startups in accessing valuable information, but further evaluation of the heuristics is needed to determine their effectiveness."
https://www.sciencedirect.com/science/article/pii/S0950584918302209,Challenges and recommended practices for software architecting in global software development,Outi=Sievi-Korte: outi.sievi-korte@tut.fi; Sarah=Beecham: sarah.beecham@lero.ie; Ita=Richardson: ita.richardson@lero.ie,"Abstract
Context
Global software development
 (GSD), although now a norm in the software industry, carries with it enormous challenges mostly regarding communication and coordination. Aforementioned challenges are highlighted when there is a need to transfer knowledge between sites, particularly when software artifacts assigned to different sites depend on each other. The design of the software architecture and associated 
task dependencies
 play a major role in reducing some of these challenges.
Objective
The current literature does not provide a cohesive picture of how the distributed nature of software development is taken into account during the design phase: what to avoid, and what works in practice. The objective of this paper is to gain an understanding of software architecting in the context of GSD, in order to develop a framework of challenges and solutions that can be applied in both research and practice.
Method
We conducted a systematic literature review (SLR) that synthesises (i) challenges which GSD imposes on 
software architecture design
, and (ii) recommended practices to alleviate these challenges.
Results
We produced a comprehensive set of guidelines for performing 
software architecture design
 in GSD based on 55 selected studies. Our framework comprises nine key challenges with 28 related concerns, and nine recommended practices, with 22 related concerns for software architecture design in GSD. These challenges and practices were mapped to a thematic conceptual model with the following concepts: Organization (Structure and Resources), Ways of Working (Architecture 
Knowledge Management
, Change Management and Quality Management), Design Practices, Modularity and Task Allocation.
Conclusion
The synthesis of findings resulted in a thematic conceptual model of the problem area, a mapping of the key challenges to practices, and a concern framework providing concrete questions to aid the design process in a distributed setting. This is a first step in creating more 
concrete architecture
 design practices and guidelines.",February 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The research on software architecture design in a distributed setting is highly relevant for early-stage ventures with global development teams, providing practical guidelines for addressing challenges in GSD."
https://www.sciencedirect.com/science/article/pii/S0950584918301617,What can violations of good practices tell about the relationship between GoF patterns and run-time quality attributes?,Daniel=Feitosa: d.feitosa@rug.nl,"Abstract
Context
GoF patterns have been extensively studied with respect to the benefit they provide as problem-solving, communication and quality improvement mechanisms. The latter has been mostly investigated through empirical studies, but some aspects of quality (esp. run-time ones) are still under-investigated.
Objective
In this paper, we study if the presence of patterns enforces the conformance to good coding practices. To achieve this goal, we explore the relationship between the presence of GoF 
design patterns
 and violations of good practices related to 
source code
 correctness, performance and security, via 
static analysis
.
Method
Specifically, we exploit 
static analysis
 so as to investigate whether the number of violations of good coding practices identified on classes is related to: (a) their participation in pattern occurrences, (b) the pattern category, (c) the pattern in which they participate, and (d) their role within the pattern occurrence. To answer these questions, we performed a 
case study
 on approximately 13,000 classes retrieved from five open-source projects.
Results
The obtained results suggest that classes not participating in patterns are more probable to violate good coding practices for correctness, performance and security. In a more fine-grained level of analysis, by focusing on specific patterns, we observed that patterns with more complex structure (e.g., Decorator) and pattern roles that are more change-prone (e.g., Subclasses) are more likely to be associated with a higher number of violations (up to 50 times more violations).
Conclusion
This finding implies that investing in a well-thought architecture based on best practices, such as patterns, is often accompanied with cleaner code with fewer violations.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The study on the impact of design patterns on coding practices provides valuable insights for startups aiming to build clean and efficient code, which can be crucial for scalability and maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584918301666,An extensible framework for software configuration optimization on heterogeneous computing systems: Time and energy case study,Ivan=Švogor: isvogor@foi.hr,"Abstract
Context:
 Application of 
component based software engineering
 methods to 
heterogeneous computing
 (HC) enables different 
software configurations
 to realize the same function with different non–functional properties (NFP). Finding the best software configuration with respect to multiple NFPs is a non–trivial task.
Objective:
 We propose a Software Component Allocation Framework (SCAF) with the goal to acquire a (sub–) optimal software configuration with respect to multiple NFPs, thus providing performance prediction of a software configuration in its early design phase. We focus on the software configuration optimization for the average energy consumption and 
average execution time
.
Method:
 We validated SCAF through its 
instantiation
 on a real–world demonstrator and a simulation. Firstly, we verified the correctness of our model through comparing the performance prediction of six 
software configurations
 to the actual performance, obtained through extensive measurements with a confidence interval of 95%. Secondly, to demonstrate how SCAF scales up, we performed software configuration optimization on 55 generated use–cases (with 
solution spaces
 ranging from 10
30
 to 30
70
) and benchmark the results against best performing random configurations.
Results:
 The performance of a configuration as predicted by our framework matched the configuration implemented and measured on a real–world platform. Furthermore, by applying the 
genetic algorithm
 and simulated annealing to the weight function given in SCAF, we obtain sub–optimal software configurations differing in performance at most 7% and 13% from the optimal configuration (respectfully).
Conclusion:
 SCAF is capable of correctly describing a HC platform and reliably predict the performance of software configuration in the early design phase. Automated in the form of an Eclipse plugin, SCAF allows software architects to model 
architectural constraints
 and preferences, acting as a multi–criterion software architecture decision 
support system
. In addition to said, we also point out several interesting research directions, to further investigate and improve our approach.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,9.0,"The Software Component Allocation Framework (SCAF) offers a practical solution for optimizing software configurations in heterogeneous computing systems, which can be beneficial for startups looking to enhance performance and efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584918301678,On the impact of code smells on the energy consumption of mobile applications,Fabio=Palomba: fpalomba@unisa.it,"Abstract
Context.
 The demand for green 
software design
 is steadily growing higher especially in the context of mobile devices, where the computation is often limited by battery life. Previous studies found how wrong programming solutions have a strong impact on the energy consumption. 
Objective.
 Despite the efforts spent so far, only a little knowledge on the influence of code smells, 
i.e.,
symptoms of poor design or implementation choices, on the energy consumption of mobile applications is available. 
Method.
 To provide a wider overview on the relationship between smells and energy efficiency, in this paper we conducted a large-scale empirical study on the influence of 9 Android-specific code smells on the energy consumption of 60 
Android
 apps. In particular, we focus our attention on the design flaws that are theoretically supposed to be related to non-functional attributes of 
source code
, such as performance and energy consumption. 
Results.
 The results of the study highlight that methods affected by four code smell types, 
i.e.,Internal Setter, Leaking Thread, Member Ignoring Method
, and 
Slow Loop
, consume up to 87 times more than methods affected by other code smells. Moreover, we found that refactoring these code smells reduces energy consumption in all of the situations. 
Conclusions.
 Based on our findings, we argue that more research aimed at designing automatic refactoring approaches and tools for mobile apps is needed.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The investigation on code smells and energy consumption in mobile applications is highly relevant for startups focusing on developing energy-efficient software, offering insights for improving app performance."
https://www.sciencedirect.com/science/article/pii/S095058491830168X,Insights into startup ecosystems through exploration of multi-vocal literature,Nirnaya=Tripathi: nirnaya.tripathi@oulu.fi,"Abstract
Context: Successful startup firms have the ability to create jobs and contribute to 
economic welfare
. A suitable ecosystem developed around startups is important to form and support these firms. In this regard, it is crucial to understand the startup ecosystem, particularly from researchers’ and practitioners’ perspectives. However, a systematic literature research on the startup ecosystem is limited. Objective: In this study, our objective was to conduct a multi-vocal literature review and rigorously find existing studies on the startup ecosystem in order to organize and analyze them, know the definitions and major elements of this ecosystem, and determine the roles of such elements in startups’ product development. Method: We conducted a multi-vocal literature review to analyze relevant articles, which are published technical articles, white papers, and Internet articles that focused on the startup ecosystem. Our search generated 18,310 articles, of which 63 were considered primary candidates focusing on the startup ecosystem. Results: From our analysis of primary articles, we found four definitions of a startup ecosystem. These definitions used common terms, such as stakeholders, supporting organization, infrastructure, network, and region. Out of 63 articles, 34 belonged to the opinion type, with contributions in the form of reports, whereas over 50% had full relevance to the startup ecosystem. We identified eight major elements (finance, demography, market, education, 
human capital
, technology, entrepreneur, and support factors) of a startup ecosystem, which directly or indirectly affected startups. Conclusions: This study aims to provide the state of the art on the startup ecosystem through a multi-vocal literature review. The results indicate that current knowledge on the startup ecosystem is mainly shared by non-peer-reviewed literature, thus signifying the need for more systematic and empirical literature on the topic. Our study also provides some recommendations for future work.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"While the study on the startup ecosystem provides valuable insights, it focuses more on the understanding of the ecosystem rather than direct practical implications for early-stage ventures, hence the slightly lower score."
https://www.sciencedirect.com/science/article/pii/S0950584918301708,Combining Automated GUI Exploration of Android apps with Capture and Replay through Machine Learning,Anna Rita=Fasolino: annarita.fasolino@unina.it,"Abstract
Context
Automated GUI Exploration Techniques have been widely adopted in the context of mobile apps for supporting critical engineering tasks such as reverse engineering, testing, and network traffic signature generation. Although several techniques have been proposed in the literature, most of them fail to guarantee the exploration of relevant parts of the applications when GUIs require to be exercised with particular and complex input event sequences. We refer to these GUIs as Gate GUIs and to the sequences required to effectively exercise them as Unlocking GUI Input Event Sequences.
Objective
In this paper, we aim at proposing a GUI exploration approach that exploits the human involvement in the automated process to solve the limitations introduced by Gate GUIs, without requiring the preliminary configuration of the technique or the user involvement for the entire duration of the exploration process.
Method
We propose juGULAR, a Hybrid GUI Exploration Technique combining Automated GUI Exploration with Capture and Replay. Our approach is able to automatically detect Gate GUIs during the app exploration by exploiting a 
Machine Learning approach
 and to unlock them by leveraging input event sequences provided by the user. We implement juGULAR in a modular software architecture that targets the 
Android
 mobile platform. We evaluate the performance of juGULAR by an experiment involving 14 real 
Android
 apps.
Results
The experiment shows that the hybridization introduced by juGULAR allows to improve the exploration capabilities in terms of Covered Activities, Covered Lines of Code, and generated Network Traffic Bytes at a reasonable manual intervention cost. The experimental results also prove that juGULAR is able to outperform the state-of-the-practice tool Monkey.
Conclusion
We conclude that the combination of Automated GUI Exploration approaches with Capture and Replay techniques is promising to achieve a thorough app exploration. Machine Learning approaches aid to pragmatically integrate these two techniques.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The juGULAR approach proposed in this abstract addresses the limitations of current GUI exploration techniques in mobile apps, showcasing improved exploration capabilities with reasonable manual intervention cost. This has practical value for early-stage ventures focusing on app development."
https://www.sciencedirect.com/science/article/pii/S2352673421000184,"The effects of subclinical ADHD symptomatology on the subjective financial, physical, and mental well-being of entrepreneurs and employees",Zsófia=Vörös: voros.zsofia@ktk.pte.hu,"Abstract
Results on the relationship between 
ADHD
 and entrepreneurial success are conflicting and several aspects of entrepreneurial success, especially on the personal level, have not been studied. By using a randomly selected Hungarian sample, the study examines the effects of subclinical 
ADHD
 symptomatology on the subjective quality-of-life outcomes in employment and entrepreneurship. The results indicate that subclinical ADHD impairs only entrepreneurs’ subjective income and harms entrepreneurs’ health perception to a larger extent than that of employees. Yet, the negative effects of ADHD symptomatology on 
life satisfaction
 are rather felt among employees. We argue that these results reflect a relatively good fit between entrepreneurship and subclinical ADHD symptomatology on the needs-supplies dimension but not on the demands-abilities dimension.",June 2021,"Subjective well-being, ADHD, Income perception, Heath perception, Demands-abilities fit, Needs-supplies fit",Business Venturing Insights,2025-03-21T00:00:00,5.0,"While the study on ADHD and entrepreneurial success is interesting, it may have limited impact on early-stage ventures in Europe as it focuses on a specific sample from Hungary."
https://www.sciencedirect.com/science/article/pii/S0950584917301118,CERSE - Catalog for empirical research in software engineering: A Systematic mapping study,Jefferson Seide=Molléri: jefferson.molleri@bth.se,"Abstract
Context
 Empirical research in 
software engineering
 contributes towards developing 
scientific knowledge
 in this field, which in turn is relevant to inform decision-making in industry. A number of empirical studies have been carried out to date in 
software engineering
, and the need for guidelines for conducting and evaluating such research has been stressed.
Objective:
 The main goal of this mapping study is to identify and summarize the body of knowledge on research guidelines, assessment instruments and knowledge organization systems on how to conduct and evaluate empirical research in software engineering.
Method:
 A 
systematic mapping study
 employing manual search and snowballing techniques was carried out to identify the suitable papers. To build up the catalog, we extracted and categorized information provided by the identified papers.
Results:
 The mapping study comprises a list of 341 methodological papers, classified according to research methods, research phases covered, and type of instrument provided. Later, we derived a brief explanatory review of the instruments provided for each of the research methods.
Conclusion:
 We provide: an aggregated body of knowledge on the state of the art relating to guidelines, assessment instruments and knowledge organization systems for carrying out empirical software engineering research; an exemplary 
usage scenario
 that can be used to guide those carrying out such studies is also provided. Finally, we discuss the catalog’s implications for research practice and the needs for further research.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"This mapping study provides a comprehensive overview of research guidelines in software engineering, which can be valuable for startups looking to inform decision-making based on scientific knowledge. The implications and usage scenario provided can guide early-stage ventures in conducting empirical research."
https://www.sciencedirect.com/science/article/pii/S095058491830185X,A first look at unfollowing behavior on GitHub,David=Lo: davidlo@smu.edu.sg; Jing=Jiang: jiangjing@buaa.edu.cn; Li=Zhang: lily@buaa.edu.cn; Yun=Yang: ayonel@qq.com; Jianfeng=Li: powerfaster@163.com,"Abstract
Context
Many 
open source software projects
 rely on contributors to fix bugs and contribute new features. On GitHub, developers often broadcast their activities to followers, which may entice followers to be project contributors. It is important to understand unfollowing behavior, maintain current followers, and attract some followers to become contributors in OSS projects.
Objective
Our objective in this paper is to provide a comprehensive analysis of unfollowing behavior on GitHub.
Method
To the best of our knowledge, we present a first look at unfollowing behavior on GitHub. We collect a dataset containing 701,364 developers and their 4,602,440 following relationships in March 2016. We also crawl their following relationships in May 2013, August 2015 and November 2015. We conduct surveys, define potential impact factors, and analyze the correlation of factors with the likelihood of unfollowing behavior.
Results
Our main observations are: (1) Between May 2013 and August 2015, 19.8% of active developers ever unfollowed some users. (2) Developers are more likely to unfollow those who have fewer activities, lower programming language similarity, and asymmetric relationships.
Conclusion
Our results give suggestions for developers to reduce the likelihood of being unfollowed by their followers, and attract researchers’ attention on relationship dissolution.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,5.0,"Analyzing unfollowing behavior on GitHub may not directly impact European early-stage ventures in the startup domain. While the study provides insights, the practical value for startups in Europe is relatively lower compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584918301848,Software product line evolution: A systematic literature review,Maíra=Marques: mmarques@dcc.uchile.cl; Jocelyn=Simmonds: jsimmond@dcc.uchile.cl; Pedro O.=Rossel: prossel@ucsc.cl; María Cecilia=Bastarrica: cecilia@dcc.uchile.cl,"Abstract
Context:
 Software Product Lines (SPL) evolve when there are changes in the requirements, product structure or the technology being used. Different approaches have been proposed for managing SPL assets and some also address how evolution affects these assets. Existing mapping studies have focused on specific aspects of SPL evolution, but there is no cohesive body of work that gives an overview of the area as a whole.
Objective:
 The goals of this work are to review the characteristics of the approaches reported as supporting SPL evolution, and to synthesize the evidence provided by primary studies about the nature of their processes, as well as how they are reported and validated.
Method:
 We conducted a systematic literature review, considering six research questions formulated to evaluate evolution approaches for SPL. We considered journal, conference and workshop papers published up until March 2017 in leading digital libraries for computer science.
Results:
 After a thorough analysis of the papers retrieved from the digital libraries, we ended up with a set of 60 primary studies. Feature models are widely used to represent SPLs, so feature evolution is frequently addressed. Other assets are less frequently addressed. The area has matured over time: papers presenting more rigorous work are becoming more common. The processes used to support SPL evolution are systematic, but with a low level of automation.
Conclusions:
 Our research shows that there is no consensus about SPL formalization, what assets can evolve, nor how and when these evolve. 
Case studies
 are quite popular, but few industrial-sized case studies are publicly available. Also, few of the proposed techniques offer tool support. We believe that the SPL community needs to work together to improve the state of the art, creating methods and tools that support SPL evolution in a more comparable manner.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,This systematic literature review on managing Software Product Lines (SPL) evolution offers insights but does not directly provide immediate practical value for European early-stage ventures. The need for more tool support and collaboration within the SPL community may have long-term benefits for startups.
https://www.sciencedirect.com/science/article/pii/S0950584916302178,Integration of feature models: A systematic mapping study,Lucian José=Gonçales: lucianj@edu.unisinos.br; Jorge Luis Victória=Barbosa: jbarbosa@unisinos.br; Vinicius=Bischoff: viniciusbischof@edu.unisinos.br; Kleinner=Farias: kleinnerfarias@unisinos.br,"Abstract
Context
The integration of feature models has been widely investigated in the last decades, given its 
pivotal role
 for supporting the evolution of software product lines. Unfortunately, academia and industry have overlooked the production of a thematic analysis of the current literature. Hence, a thorough understanding of the state-of-the-art works remains still limited.
Objective
This study seeks to create a panoramic view of the current literature to pinpoint gaps and supply insights of this research field.
Method
A 
systematic mapping study
 was performed based on well-established empirical guidelines for answering six research questions. In total, 47 primary studies were selected by applying a filtering process from a sample of 2874 studies.
Results
The main results obtained are: (1) most studies use a generic notation (68.09%, 32/47) for representing feature models; (2) only one study (2%, 1/47) compares feature models based on their 
syntactic
 and semantics; (3) there is no preponderant use of a particular integration technique in the selected studies; (4) most studies (70%, 33/47) provide a product-based strategy to evaluate the integrated feature models; (5) majority (70%, 33/47) automates the integration process; and (6) most studies (90%, 42/47) propose techniques, rather than focusing on producing practical knowledge derived from empirical studies.
Conclusion
The results were encouraging and suggest that integration of feature models is still an evolving research area. This study provides insightful information for the definition of a more ambitious 
research agenda
. Lastly, empirical studies exploring the required effort to apply the current integration techniques in real-world settings are highly recommended in future work.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,7.0,"The systematic mapping study on the integration of feature models provides valuable insights for understanding the current literature in this research field. The study can help startups pinpoint gaps and define a research agenda, contributing to their understanding of feature model integration techniques."
https://www.sciencedirect.com/science/article/pii/S0950584918301885,Empirical research on concurrent software testing: A systematic mapping study,Silvana M.=Melo: morita@icmc.usp.br,"Abstract
Background:
 
Concurrent software
 testing is a costly and difficult task, especially due to the exponential increase in the test sequences caused by non-determinism. Such an issue has motivated researchers to develop testing techniques that select a subset of the input domain that has a high probability of revealing faults. Academics and industrial practitioners rarely use most concurrent software testing techniques because of the lack of data about their applicability. Empirical evidence can provide an important scientific basis for the strengths and weaknesses of each technique to help researchers and practitioners choose concurrent testing techniques appropriate for their environments.
Aim:
 This paper gathers and synthesizes empirical research on concurrent software testing to characterize the field and the types of empirical studies performed.
Method:
 We performed a 
systematic mapping study
 to identify and analyze empirical research on concurrent software testing techniques. We provide a detailed analysis of the studies and their design choices.
Results:
 The primary findings are: (1) there is a general lack of empirical validation of concurrent software testing techniques, (2) the type of evaluation method varies with the type of technique, (3) there are some key challenges to empirical study design in concurrent software testing, and (4) there is a dearth of controlled experiments in concurrent software testing.
Conclusions:
 There is little empirical evidence available about some specific concurrent testing techniques like model-based testing and formal testing. Overall, researchers need to perform more empirical work, especially real-world 
case studies
 and controlled experiments, to validate properties of concurrent software testing techniques. In addition, researchers need to perform more analyses and synthesis of the existing evidence. This paper is a first step in that direction.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,6.0,"The study on concurrent software testing techniques and the need for more empirical evidence can provide valuable insights for European early-stage ventures developing software products, but the practical applicability may vary depending on the specific startup's needs."
https://www.sciencedirect.com/science/article/pii/S0950584918301897,A new algorithm for software clustering considering the knowledge of dependency between artifacts in the source code,Habib=Izadkhah: izadkhah@tabrizu.ac.ir,"Abstract
Context:
 Software systems evolve over time to meet the new requirements of users. These new requirements, usually, are not reflected in the original documents of these software systems. Therefore, the new version of a software system deviates from the original and documented architecture. This way, it will be more difficult to understand it after a while and it will be difficult to make new changes conveniently. 
Clustering techniques
 are used to extract the architecture of a software system in order to understand it. An artifact 
dependency graph
 (ADG) is often used for clustering, which is extracted from a source code. In the literature, some hierarchical and search-based 
clustering methods
 have been presented to extract the software architecture. Hierarchical algorithms have reasonable search time; however, they are not able to find a good architecture. In contrast, search-based algorithms are often better in this regard; however, their time and space limitations make them useless in practice for large-scale software systems. Both hierarchical and search-based 
clustering methods
 overlook the existing knowledge in an ADG for clustering.
Objective:
 To overcome the limitations of the existing clustering methods, this paper presents a new deterministic 
clustering algorithm
 named Neighborhood tree algorithm.
Method:
 The new algorithm creates a neighborhood tree using available knowledge in an ADG and uses this tree for clustering.
Results:
 Our initial results indicate that the algorithm is better able to extract an acceptable architecture in a reasonable time, compared with hierarchical and search-based algorithms.
Conclusions:
 The proposed 
clustering algorithm
 is expected to greatly assist software engineers in extracting meaningful and understandable subsystems from a source code.",January 2019,Not Found,Information and Software Technology,2025-03-18T00:00:00,8.0,"The development of a new deterministic clustering algorithm that overcomes limitations of existing methods can have a significant impact on software engineering practices for European early-stage ventures, providing them with a more efficient way to extract software architecture. This innovation can greatly benefit startups seeking to improve their software systems."
https://ieeexplore.ieee.org/document/9046805/,A Survey of Autonomous Driving: Common Practices and Emerging Technologies,,"Automated driving systems (ADSs) promise a safe, comfortable and efficient driving experience. However, fatalities involving vehicles equipped with ADSs are on the rise. The full potential of ADSs cannot be realized unless the robustness of state-of-the-art is improved further. This paper discusses unsolved problems and surveys the technical aspect of automated driving. Studies regarding present challenges, high-level system architectures, emerging methodologies and core functions including localization, mapping, perception, planning, and human machine interfaces, were thoroughly reviewed. Furthermore, many state-of-the-art algorithms were implemented and compared on our own platform in a real-world driving setting. The paper concludes with an overview of available datasets and tools for ADS development.",25 March 2020,"Automation, Task analysis, Systems architecture, Accidents, Planning, Vehicle dynamics, Robot sensing systems, System Architecture, Automated Vehicles, Deep Learning, Convolutional Neural Network, Deep Neural Network, Urban Planning, Object Detection, Pedestrian, Point Cloud, Deep Reinforcement Learning, Object Tracking, Single Camera, Dynamic Objects, Simultaneous Localization And Mapping, Radar Sensor, Deep Q-network, Vehicular Ad Hoc Networks, 3D Object Detection, Dead Reckoning, You Only Look Once, Dynamic Vision Sensor, Rapidly-exploring Random Tree, Deep Convolutional Neural Network, 3D Detection, Semantic Segmentation, Inertial Measurement Unit, Image-based Detection, Multiple Object Tracking, Hidden Markov Model, Region Proposal Network, Autonomous vehicles, control, robotics, automation, intelligent vehicles, intelligent transportation systems",IEEE Access,2025-03-17T00:00:00,5.0,"While the topic of automated driving systems is important for the future of transportation, the practical value for European early-stage ventures might be limited as the focus is more on technical aspects than on startup applications."
https://ieeexplore.ieee.org/document/8352646/,Multi-Agent Systems: A Survey,,"Multi-agent systems (MASs) have received tremendous attention from scholars in different disciplines, including computer science and civil engineering, as a means to solve complex problems by subdividing them into smaller tasks. The individual tasks are allocated to autonomous entities, known as agents. Each agent decides on a proper action to solve the task using multiple inputs, e.g., history of actions, interactions with its neighboring agents, and its goal. The MAS has found multiple applications, including modeling complex systems, smart grids, and computer networks. Despite their wide applicability, there are still a number of challenges faced by MAS, including coordination between agents, security, and task allocation. This survey provides a comprehensive discussion of all aspects of MAS, starting from definitions, features, applications, challenges, and communications to evaluation. A classification on MAS applications and challenges is provided along with references for further studies. We expect this paper to serve as an insightful and comprehensive resource on the MAS for researchers and practitioners in the area.",30 April 2018,"Task analysis, Multi-agent systems, Computer science, Security, Australia, Computational modeling, Decision making, Multi-agent Systems, Digital Networks, History Of Activity, Smart Grid, Task Allocation, Reference For Further Studies, Neighboring Agents, Energy Production, Cloud Computing, Number Of Agents, Group Of Agents, Virtual Machines, Wireless Sensor Networks, Expert System, Communication Overhead, Low-cost Solution, Position Of Agent, Intrusion Detection System, Vehicular Ad Hoc Networks, Cloud Providers, Mobile Agents, Decisions Of Agents, Multi-agent Reinforcement Learning, Processing Overhead, Agent Communication, Reliable Route, Software Agents, Probabilistic Neural Network, Social Networks, Fundamental Method, Multi-agent systems, survey, MAS applications, challenges",IEEE Access,2025-03-17T00:00:00,6.0,"The discussion on multi-agent systems provides a good overview of a relevant topic with potential applications for startups. However, the challenges faced by MAS might not directly impact European early-stage ventures at the moment."
https://ieeexplore.ieee.org/document/9523565/,"Deep Learning for Anomaly Detection in Time-Series Data: Review, Analysis, and Guidelines",,"As industries become automated and connectivity technologies advance, a wide range of systems continues to generate massive amounts of data. Many approaches have been proposed to extract principal indicators from the vast sea of data to represent the entire system state. Detecting anomalies using these indicators on time prevent potential accidents and economic losses. Anomaly detection in multivariate time series data poses a particular challenge because it requires simultaneous consideration of temporal dependencies and relationships between variables. Recent deep learning-based works have made impressive progress in this field. They are highly capable of learning representations of the large-scaled sequences in an unsupervised manner and identifying anomalies from the data. However, most of them are highly specific to the individual use case and thus require domain knowledge for appropriate deployment. This review provides a background on anomaly detection in time-series data and reviews the latest applications in the real world. Also, we comparatively analyze state-of-the-art deep-anomaly-detection models for time series with several benchmark datasets. Finally, we offer guidelines for appropriate model selection and training strategy for deep learning-based time series anomaly detection.",26 August 2021,"Anomaly detection, Time series analysis, Guidelines, Deep learning, Data models, Biological system modeling, Time factors, Deep Learning, Time Series Data, Anomaly Detection, Detection In Time Series Data, Training Strategy, Multivariate Data, Benchmark Datasets, Time Series Models, Temporal Dependencies, Unsupervised Manner, Multivariate Time Series, Guidelines For Selection, Multivariate Time Series Data, Convolutional Neural Network, Prediction Error, Long Short-term Memory, Recurrent Neural Network, Temporality, Detection Model, Generative Adversarial Networks, Gated Recurrent Unit, Automated Guided Vehicles, Anomaly Data, Temporal Convolutional Network, Incremental Update, Autoregressive Integrated Moving Average, Anomaly Detection Methods, Water Distribution, Structural Health Monitoring, Deep Learning-based Methods, Anomaly detection, deep learning, fault diagnosis, industry applications, Internet-of-Things (IoT), time series analysis",IEEE Access,2025-03-17T00:00:00,7.0,The review on anomaly detection in time-series data using deep learning has practical implications for startups dealing with vast amounts of data. The guidelines provided can be valuable for European early-stage ventures in implementing anomaly detection.
https://ieeexplore.ieee.org/document/9142202/,Data Security and Privacy Protection for Cloud Storage: A Survey,,"The new development trends including Internet of Things (IoT), smart city, enterprises digital transformation and world’s digital economy are at the top of the tide. The continuous growth of data storage pressure drives the rapid development of the entire storage market on account of massive data generated. By providing data storage and management, cloud storage system becomes an indispensable part of the new era. Currently, the governments, enterprises and individual users are actively migrating their data to the cloud. Such a huge amount of data can create magnanimous wealth. However, this increases the possible risk, for instance, unauthorized access, data leakage, sensitive information disclosure and privacy disclosure. Although there are some studies on data security and privacy protection, there is still a lack of systematic surveys on the subject in cloud storage system. In this paper, we make a comprehensive review of the literatures on data security and privacy issues, data encryption technology, and applicable countermeasures in cloud storage system. Specifically, we first make an overview of cloud storage, including definition, classification, architecture and applications. Secondly, we give a detailed analysis on challenges and requirements of data security and privacy protection in cloud storage system. Thirdly, data encryption technologies and protection methods are summarized. Finally, we discuss several open research topics of data security for cloud storage.",16 July 2020,"Cloud computing, Encryption, Data privacy, Secure storage, Memory, Cloud Computing, Data Privacy, Data Security, Privacy Protection, Security Protection, Data Privacy Protection, Data Storage, Internet Of Things, Massive Data, Privacy Issues, Security Issues, Individual Users, Information Leakage, Smart City, Encrypted Data, Protection Methods, Digital Economy, Cloud Applications, Data Security Issues, Data Privacy Issues, Attribute-based Encryption, Secret Key, Encrypted File, Cloud Data, Public Key, Data Owner, Public Cloud, Encryption Scheme, Decryption Key, Access Control, Cloud storage, data security, cryptography, access control, privacy protection",IEEE Access,2025-03-17T00:00:00,4.0,"While data security and privacy in cloud storage is crucial, the focus of this paper might not have a direct impact on European early-stage ventures, as the survey covers a broad topic that might not be immediately applicable to startups."
https://ieeexplore.ieee.org/document/10319418/,Artificial Intelligence in Accounting and Finance: Challenges and Opportunities,,"The rapid expansion of artificial intelligence (AI) technologies presents novel technical solutions to traditional accounting and finance problems. Despite this, scholars in accounting and finance frequently encounter difficulties navigating the extensive and intricate domain knowledge of AI and its continuously evolving literature. To address this gap, this paper conducts a qualitative survey of the implementation of AI methods in accounting and finance. The paper is structured into four sections. Firstly, we examine the conventional accounting and finance issues and their requirement for AI techniques. Secondly, to inform accounting and finance researchers about the potential of AI, we present broad categories of AI applications. Thirdly, we explore recent research on AI solutions to conventional problems. Finally, we highlight emerging trends and possible research directions.",16 November 2023,"Artificial intelligence, Finance, Investment, Forecasting, Business, Decision making, Pricing, Machine learning, Computational modeling, Artificial Intelligence, Financial Problems, Artificial Intelligence Applications, Artificial Intelligence Technology, Artificial Intelligence Techniques, Accounting Research, Artificial Intelligence Methods, Traditional Finance, Traditional Accounting, Neural Network, Deep Learning, Support Vector Machine, Artificial Neural Network, Financial Statements, Multi-objective Optimization, Cash Flow, Textual Information, Stock Price, Deep Reinforcement Learning, Optimal Portfolio, Financial Fraud, Fraud Detection, Analysis Of Statements, GARCH Model, Capital Structure, Money Laundering, Financial Crime, Corporate Finance, Option Pricing, Financial Measures, Artificial intelligence, computational finance, accounting, machine learning, computational model",IEEE Access,2025-03-17T00:00:00,7.0,"The paper addresses a gap in knowledge by conducting a survey on the implementation of AI in accounting and finance, providing insights and research directions for scholars in the field."
https://ieeexplore.ieee.org/document/9721302/,Deepfake Detection: A Systematic Literature Review,,"Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.",24 February 2022,"Videos, Information integrity, Measurement, Faces, Deep learning, Computational modeling, Web pages, Systematic Review, Deepfake Detection, Machine Learning, Deep Learning, Learning-based Methods, Deep Learning-based Methods, Machine Learning-based Methods, Learning Models, Convolutional Neural Network, Support Vector Machine, Deep Models, Deep Learning Models, Detection Techniques, Recurrent Neural Network, Generative Adversarial Networks, Convolutional Neural Network Model, Spatiotemporal Characteristics, Deep Neural Network Model, Learning-based Models, Latent Features, Deep Learning-based Models, Multiple Instance Learning, Head Pose, Maximum Mean Discrepancy, Convolutional Recurrent Neural Network, Blockchain Technology, Public Blockchain, Recurrent Neural Network Model, Video Content, Video Frames, Deepfake detection, video or image manipulation, digital media forensics, systematic literature review",IEEE Access,2025-03-17T00:00:00,9.0,"The paper focuses on a critical issue of Deepfake detection, summarizing relevant articles and evaluating different techniques, which can have a significant impact on media and society."
https://ieeexplore.ieee.org/document/9069875/,Artificial Intelligence in Education: A Review,,"The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors' duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students' assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students' needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning.",17 April 2020,"Education, Technological innovation, Learning (artificial intelligence), Microcomputers, Robots, Artificial Intelligence, Artificial Intelligence In Education, Intelligence In Education, Cognitive Function, Machine Learning, Scope Of This Study, Education System, Education Institutions, Learning Experiences, Intelligent Systems, Cognitive Learning, Grade Students, Learning Capability, Quality Of Learning, Artificial Intelligence Applications, Web-based System, Use Of Robots, Adaptive Capabilities, Humanoid Robot, Artificial Intelligence Systems, Development Of Artificial Intelligence, Web-based Platform, Use Of Artificial Intelligence, Intelligent Tutoring Systems, Administrative Tasks, Integration Of Artificial Intelligence, Education Sector, Online Learning, Personal Content, Education, artificial intelligence, leaner",IEEE Access,2025-03-17T00:00:00,6.0,"The study assesses the impact of AI in education, highlighting the various applications of AI in administration, instruction, and learning, contributing to the enhancement of educational processes."
https://ieeexplore.ieee.org/document/9773102/,Zero Trust Architecture (ZTA): A Comprehensive Survey,,"We present a detailed survey of the Zero Trust (ZT) security paradigm which has a growing number of advocates in the critical infrastructure risk management space. The article employs a descriptive approach to present the fundamental tenets of ZT and provides a review of numerous potential options available for successful realization of this paradigm. We describe the role of authentication and access control in Zero Trust Architectures (ZTA) and present an in-depth discussion of state-of-the-art techniques for authentication and access control in different scenarios. Furthermore, we comprehensively discuss the conventional approaches to encryption, micro-segmentation, and security automation available for instantiating a ZTA. The article also details various challenges associated with contemporary authentication mechanisms, access control schemes, trust and risk computation techniques, micro-segmentation approaches, and Software-Defined Perimeter, that can impact the implementation of ZT in its true sense. Based upon our analysis, we finally pinpoint the potential future research directions for successful realization of ZT in critical infrastructures.",12 May 2022,"Access control, Authentication, Computer architecture, NIST, Encryption, Critical infrastructure, Automation, Zero Trust Architecture, Access Control, Critical Infrastructure, Authentication Mechanism, Authentication Techniques, Contextual Information, Internet Of Things, Quantum Computing, Internet Of Things Devices, Public Key, Policy Enforcement, Internet Of Things Systems, Access Request, Internet Of Things Networks, Smart Contracts, Security Control, User Authentication, Dynamic Policy, Authentication Scheme, Virtual Network Functions, Physical Unclonable Functions, Blockchain, Mutual Authentication, Access Control Mechanism, Public Key Infrastructure, Identity Management, Static Random Access Memory, Smart Home, Cyber Attacks, Zero trust architecture (ZTA), access control, authentication, micro-segmentation, software-defined parameter (SDP)",IEEE Access,2025-03-17T00:00:00,8.0,"The article presents a detailed survey of the Zero Trust security paradigm, discussing authentication, access control, encryption, micro-segmentation, and security automation, which can greatly benefit critical infrastructure risk management."
https://ieeexplore.ieee.org/document/10521640/,"Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers",,"The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.",06 May 2024,"Decoding, Mathematical models, Task analysis, Vectors, Codes, Transformers, Neural networks, Generative AI, Generative adversarial networks, Artificial intelligence, Chatbots, Encoding, Generative Adversarial Networks, Diffusion Model, Generative Pretrained Transformer, Artificial Intelligence, Misinformation, Transformer Model, Variational Autoencoder, Code Generation, Privacy Breaches, Text Generation, Music Composition, Neural Network, Deep Learning, Convolutional Neural Network, Denoising, Computer Vision, Long Short-term Memory, Attention Mechanism, Reversible Process, Real Samples, Stochastic Differential Equations, Input Text, Wasserstein Generative Adversarial Networks, Feed-forward Network, Chatbot, StyleGAN, Industrial Revolution, Latent Vector, Cyber Operations, Vanishing Gradient, Generative AI, GPT, bard, ChatGPT, diffusion model, transformer, GAN, autoencoder, artificial intelligence",IEEE Access,2025-03-17T00:00:00,5.0,"The launch of ChatGPT and other GAI tools is a significant development in the AI field, but the abstract mainly highlights the capabilities and challenges without offering specific practical implications for startups."
https://ieeexplore.ieee.org/document/10102467/,"Review of Electric Vehicle Charging Technologies, Standards, Architectures, and Converter Configurations",,"Electric Vehicles (EVs) are projected to be one of the major contributors to energy transition in global transportation due to their rapid expansion. High-level EVs integration into the electricity grid will introduce many challenges for the power grid planning, operation, stability, standards, and safety. Therefore, the wide-scale adoption of EVs imposes research and development of charging systems and EV supply equipment (EVSE) to achieve expected charging solutions for EV batteries as well as to improve ancillary services. Analysis of the status of EV charging technologies is important to accelerate EV adoption with advanced control strategies to discover a remedial solution for negative impacts and to enhance desired charging efficiency and grid support. This paper presents a comprehensive review of EV charging technologies, international standards, the architecture of EV charging stations, and the power converter configurations of EV charging systems. The charging systems require a dedicated converter topology, a control strategy, compatibility with standards, and grid codes for charging and discharging to ensure optimum operation and enhance grid support. An overview of different charging systems in terms of onboard and off-board chargers, AC-DC and DC-DC converter configuration, and AC and DC-based charging station architectures are evaluated. In addition, recent charging systems which are integrated with renewable energy sources are presented to identify the power train of modern charging stations. Finally, future trends and challenges in EV charging and grid integration issues are summarized as the future direction of the research.",14 April 2023,"Electric vehicle charging, Batteries, Power grids, Charging stations, Costs, Reliability, Vehicle-to-grid, Electric Vehicles, Electric Vehicles Charging, Charging Technology, Converter Configuration, Control Strategy, International Standards, State Of Charge, Power Grid, Renewable Energy Sources, Power Conversion, Future Trends, Charging System, Dcdc Converter, Utility Grid, Ancillary Services, Converter Topology, Electric Vehicles Battery, Grid Code, Acdc Converter, High Power, Battery Electric Vehicles, Fast Charging, Multilevel Converter, Plug-in Hybrid Electric Vehicles, Buck Converter, Ultrafast Charge, AC Power, Internal Combustion Engine Vehicles, Hybrid Electric Vehicles, Plug-in Electric Vehicles, Electric vehicle, charging configuration, grid integration, international standards, onboard and offboard charger, power converters",IEEE Access,2025-03-17T00:00:00,7.0,"The abstract discusses the challenges and advancements in EV charging technologies, which are crucial for the energy transition. It addresses a key aspect of sustainable transportation and grid integration."
https://ieeexplore.ieee.org/document/10354308/,Deepfake Generation and Detection: Case Study and Challenges,,"In smart communities, social media allowed users easy access to multimedia content. With recent advancements in computer vision and natural language processing, machine learning (ML), and deep learning (DL) models have evolved. With advancements in generative adversarial networks (GAN), it has become possible to create fake images/audio/and video streams of a person or use some person’s audio and visual details to fit other environments. Thus, deepfakes are specifically used to disseminate fake information and propaganda on social circles that tarnish the reputation of an individual or an organization. Recently, many surveys have focused on generating and detecting deepfake images, audio, and video streams. Existing surveys are mostly aligned toward detecting deepfake contents, but the generation process is not suitably discussed. To address the survey gap, the paper proposes a comprehensive review of deepfake generation and detection and the different ML/DL approaches to synthesize deepfake contents. We discuss a comparative analysis of deepfake models and public datasets present for deepfake detection purposes. We discuss the implementation challenges and future research directions regarding optimized approaches and models. A unique case study, IBMM is discussed, which presents a multi-modal overview of deepfake detection. The proposed survey would benefit researchers, industry, and academia to study deepfake generation and subsequent detection schemes.",12 December 2023,"Deepfakes, Generative adversarial networks, Feature extraction, Artificial intelligence, Convolutional neural networks, Surveys, Fake news, Deepfake Generation, Social Media, Deep Learning Models, Generative Adversarial Networks, Convolutional Neural Network, Deep Neural Network, Convolutional Layers, Long Short-term Memory, Recurrent Neural Network, Detection Model, Ensemble Model, Fake News, Video Content, Dropout Layer, Original Content, Artificial Intelligence Models, Contrastive Loss, Scale-invariant Feature Transform, Type Of Manipulation, Generative Adversarial Networks Model, Audio Content, Real Content, Speeded Up Robust Features, Capsule Network, Residual Block, Open Challenges, Fake Images, Loss Function, Gaussian Mixture Model, Pooling Layer, Artificial intelligence, Deepfake generation, Deepfake detection, fake content, generative adversarial networks",IEEE Access,2025-03-17T00:00:00,6.0,"The abstract highlights the issue of deepfakes and their impact on social circles. While the technology is concerning, its direct impact on European early-stage ventures may not be as significant as other topics."
https://ieeexplore.ieee.org/document/10433480/,"A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",,"Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolut...",13 February 2024,"Cognition, Artificial intelligence, Transformers, Training, Taxonomy, Task analysis, Surveys, Natural language processing, Question answering (information retrieval), Information analysis, Linguistics, Language Model, Open Issues, Large Language Models, Business, Natural Language, Language Processing, Review Paper, Question Answering, Natural Language Processing Tasks, Text Generation, Neural Network, Deep Neural Network, Specific Tasks, Recurrent Neural Network, Text Data, Input Sequence, Range Of Tasks, Transformer Model, Deep Neural Network Model, Sentiment Analysis, Tokenized, Transformer Architecture, Few-shot Learning, Video Summarization, Neural Language Models, Zero-shot, Chatbot, Positional Encoding, Output Embedding, Large language models (LLM), natural language processing (NLP), artificial intelligence, transformer, pre-trained models, taxonomy, application",IEEE Access,2025-03-17T00:00:00,9.0,Large Language Models (LLMs) are important in various NLP tasks with wide-ranging applications. Understanding their impacts and challenges can benefit startups in developing AI-driven solutions.
https://ieeexplore.ieee.org/document/8721134/,"Towards Sustainable Energy: A Systematic Review of Renewable Energy Sources, Technologies, and Public Opinions",,"The use of renewable energy resources, such as solar, wind, and biomass will not diminish their availability. Sunlight being a constant source of energy is used to meet the ever-increasing energy need. This review discusses the world's energy needs, renewable energy technologies for domestic use, and highlights public opinions on renewable energy. A systematic review of the literature was conducted from 2009 to 2018. During this process, more than 300 articles were classified and 42 papers were filtered for critical review. The literature analysis showed that despite serious efforts at all levels to reduce reliance on fossil fuels by promoting renewable energy as its alternative, fossil fuels continue to contribute 73.5% to the worldwide electricity production in 2017. Conversely, renewable sources contributed only 26.5%. Furthermore, this study highlights that the lack of public awareness is a major barrier to the acceptance of renewable energy technologies. The results of this study show that worldwide energy crises can be managed by integrating renewable energy sources in the power generation. Moreover, in order to facilitate the development of renewable energy technologies, this systematic review has highlighted the importance of public opinion and performed a real-time analysis of public tweets. This example of tweet analysis is a relatively novel initiative in a review study that will seek to direct the attention of future researchers and policymakers toward public opinion and recommend the implications to both academia and industries.",23 May 2019,"Fossil fuels, Systematics, Information technology, Computer science, Wind, Biomass, Systematic Review, Energy Source, Renewable Energy, Public Opinion, Energy Development, Renewable Energy Sources, Renewable Energy Technologies, Fossil Fuels, Renewable Sources, Power Generation, Energy Deficit, Technology Acceptance, Renewable Energy Resources, Lack Of Public Awareness, Greenhouse Gas, Thermal Energy, Energy Use, Solar Energy, Wind Power, Solar System, Solar Heating, Wind Farm, Use Of Renewable Energy, Analysis Rules, Ocean Energy, Renewable Energy Projects, Energy Security, Solar Thermal, Offshore Wind, Solar Panels, Energy policies, public opinion, renewable energy sources (RES), renewable energy technology (RET), solar energy, wind energy",IEEE Access,2025-03-17T00:00:00,5.0,"The abstract addresses renewable energy technologies and public opinions but lacks a direct focus on early-stage ventures. While renewable energy is important, the practical impact on startups is not explicitly discussed."
https://ieeexplore.ieee.org/document/10638538/,Does ChatGPT Help Novice Programmers Write Better Code? Results From Static Code Analysis,,"In the realm of AI-enhanced programming education, there is growing interest in using such tools to help students understand good coding principles. This study investigates the impact of ChatGPT on code quality among part-time undergraduate students in introductory Java programming courses, who lack prior Java experience. The source code of 16 students from the control group (without ChatGPT) and 22 students from the treatment group (with ChatGPT) who completed identical programming exercises focused on coding conventions was analyzed. Static code analysis tools assessed adherence to a common coding convention ruleset and calculated cyclomatic and cognitive complexity metrics. The comparative analysis shows that the ChatGPT-assisted group significantly improved code quality, with fewer rule violations and reduced cyclomatic and cognitive complexities. The treatment group adhered more closely to coding standards and produced less complex code. Violations primarily occurred in line length, final parameters, and the extensibility of object-oriented programming (OOP). These findings suggest that ChatGPT can be beneficial in programming education by helping students write cleaner, less complex code and adhere to coding conventions. However, the study’s limitations, such as the small sample size and novice status of participants, call for further research with larger, more diverse populations and different educational contexts.",19 August 2024,"Codes, Chatbots, Programming, Programming profession, Education, Complexity theory, Java, Novice Programmers, Treatment Groups, Prior Experience, Source Code, Educational Contexts, Static Analysis, Object-oriented, Students In Courses, Student Understanding, Cognitive Complexity, Introductory Course, Rule Violations, Software Quality, Introduction Of Programs, Java Programming, Part-time Students, Complexity Metrics, Non-parametric, Critical Thinking, Group Of Students, Significant Differences In Adherence, Low Complexity, Differences In Adherence, Code Generation, Complexity Of Students, Coding Efficiency, Stream Of Research, Chatbot, Programming Tasks, Alternative Hypothesis H1, Programming education, ChatGPT large language models, static code analysis",IEEE Access,2025-03-17T00:00:00,6.0,"The study evaluates the impact of ChatGPT on code quality in programming education. While relevant for AI-enhanced education, the direct impact on early-stage ventures may be limited."
https://ieeexplore.ieee.org/document/10604830/,Explainable Artificial Intelligence for Autonomous Driving: A Comprehensive Overview and Field Guide for Future Research Directions,,"Autonomous driving has achieved significant milestones in research and development over the last two decades. There is increasing interest in the field as the deployment of autonomous vehicles (AVs) promises safer and more ecologically friendly transportation systems. With the rapid progress in computationally powerful artificial intelligence (AI) techniques, AVs can sense their environment with high precision, make safe real-time decisions, and operate reliably without human intervention. However, intelligent decision-making in such vehicles is not generally understandable by humans in the current state of the art, and such deficiency hinders this technology from being socially acceptable. Hence, aside from making safe real-time decisions, AVs must also explain their AI-guided decision-making process in order to be regulatory-compliant across many jurisdictions. Our study sheds comprehensive light on the development of explainable artificial intelligence (XAI) approaches for AVs. In particular, we make the following contributions. First, we provide a thorough overview of the state-of-the-art and emerging approaches for XAI-based autonomous driving. We then propose a conceptual framework considering the essential elements for explainable end-to-end autonomous driving. Finally, we present XAI-based prospective directions and emerging paradigms for future directions that hold promise for enhancing transparency, trustworthiness, and societal acceptance of AVs.",19 July 2024,"Visualization, Autonomous vehicles, Safety, Artificial intelligence, Accidents, Regulation, Standards, Autonomous driving, Explainable AI, Intelligence, Autonomous Vehicles, Explainable Artificial Intelligence, Research And Development, Conceptual Framework, Artificial Intelligence Techniques, Artificial Intelligence Approaches, Real-time Decision, Safe Decisions, User Study, Work Context, Semantic Segmentation, General Data Protection Regulation, Lead Time, Self-driving, Traffic Safety, Learning Software, Automated Vehicles, Regulatory Compliance, Road Vehicles, Imitation Learning, Human Drivers, Need For Explanation, Vehicular Ad Hoc Networks, Trolley Problem, Visual Question Answering, Visual Explanation, Emergent Need, Traffic Rules, Road Users, Autonomous driving, explainable artificial intelligence, intelligent transportation systems, regulatory compliance, safety",IEEE Access,2025-03-17T00:00:00,9.0,"The development of explainable AI approaches for autonomous vehicles is crucial for societal acceptance and regulatory compliance, impacting the future of transportation systems."
https://ieeexplore.ieee.org/document/8694781/citations?tabFilter=patents#anchor-patent-citations,Review of Deep Learning Algorithms and Architectures,,"Deep learning (DL) is playing an increasingly important role in our lives. It has already made a huge impact in areas, such as cancer diagnosis, precision medicine, self-driving cars, predictive forecasting, and speech recognition. The painstakingly handcrafted feature extractors used in traditional learning, classification, and pattern recognition systems are not scalable for large-sized data sets. In many cases, depending on the problem complexity, DL can also overcome the limitations of earlier shallow networks that prevented efficient training and abstractions of hierarchical representations of multi-dimensional training data. Deep neural network (DNN) uses multiple (deep) layers of units with highly optimized algorithms and architectures. This paper reviews several optimization methods to improve the accuracy of the training and to reduce training time. We delve into the math behind training algorithms used in recent deep networks. We describe current shortcomings, enhancements, and implementations. The review also covers different types of deep architectures, such as deep convolution networks, deep residual networks, recurrent neural networks, reinforcement learning, variational autoencoders, and others.",22 April 2019,"Deep learning, Training, Computer architecture, Feature extraction, Recurrent neural networks, Feedforward neural networks, Deep Learning, Learning Algorithms, Neural Network, Training Data, Deep Network, Deep Neural Network, Training Time, Recurrent Neural Network, Autoencoder, Speech Recognition, Training Algorithm, Variational Autoencoder, Units In Layer, Deep Residual Network, Gradient Descent, Convolutional Layers, Sigmoid Function, Hidden Layer, Unsupervised Learning, Long Short-term Memory, Restricted Boltzmann Machine, Feed-forward Network, Deep Reinforcement Learning, Implementation Of Neural Networks, Extreme Learning Machine, Unlabeled Data, Image Recognition, Deep Belief Network, MNIST Dataset, Proper Orthogonal Decomposition, Machine learning algorithm, optimization, artificial intelligence, deep neural network architectures, convolution neural network, backpropagation, supervised and unsupervised learning",IEEE Access,2025-03-17T00:00:00,7.0,The review of optimization methods for deep learning networks is valuable for improving accuracy and reducing training time across various applications.
https://ieeexplore.ieee.org/document/9072123/,Unsupervised K-Means Clustering Algorithm,,"The k-means algorithm is generally the most known and used clustering method. There are various extensions of k-means to be proposed in the literature. Although it is an unsupervised learning to clustering in pattern recognition and machine learning, the k-means algorithm and its extensions are always influenced by initializations with a necessary number of clusters a priori. That is, the k-means algorithm is not exactly an unsupervised clustering method. In this paper, we construct an unsupervised learning schema for the k-means algorithm so that it is free of initializations without parameter selection and can also simultaneously find an optimal number of clusters. That is, we propose a novel unsupervised k-means (U-k-means) clustering algorithm with automatically finding an optimal number of clusters without giving any initialization and parameter selection. The computational complexity of the proposed U-k-means clustering algorithm is also analyzed. Comparisons between the proposed U-k-means and other existing methods are made. Experimental results and comparisons actually demonstrate these good aspects of the proposed U-k-means clustering algorithm.",20 April 2020,"Clustering algorithms, Indexes, Linear programming, Entropy, Clustering methods, Unsupervised learning, Machine learning algorithms, Clustering Algorithm, Unsupervised Clustering, K-means Algorithm, Unsupervised K-means, Unsupervised K-means Clustering, Clustering Method, Unsupervised Learning, Parameter Selection, Objective Function, Bayesian Information Criterion, Clustering Results, Number Of Data Points, Number Range, Validity Index, Cluster Centers, Cluster Membership, Gaussian Mixture Model, True Number, Cluster C, Partitioning Method, Silhouette Width, Average Accuracy Rate, Lung Datasets, UCI Machine Learning Repository, Gap Statistic, Davies-Bouldin Index, Clusters In Dataset, Internal Index, Correct Number, Cluster Validity, Clustering, K-means, number of clusters, initializations, unsupervised learning schema, Unsupervised k-means (U-k-means)",IEEE Access,2025-03-17T00:00:00,5.0,"While the development of an unsupervised k-means clustering algorithm is relevant in machine learning, its impact on European early-stage ventures may not be as immediate or significant compared to other abstracts."
https://ieeexplore.ieee.org/document/10695056/,A Comprehensive Review on Generative AI for Education,,"Artificial Intelligence (AI) has immense potential for personalized learning experiences, content generation, and vivid educational support. This paper delves into generative AI (GAI) and its potential applications within GAI, specifically mentioning generative adversarial networks (GANs). The article delves into the transformative impact of GAI in education, underscoring its expertise in creating diverse instructional materials, from texts and images to videos. Adaptive learning, one of the chief abilities of GAI, has been highlighted, emphasizing its capability to select content customized to individual student profiles, learning habits, and preferences. The paper further explores the fusion of GAI with innovative education systems, highlighting how these models can mimic conversational interfaces, promoting an engaging, customized learning journey. The exploration doesn’t stop at the benefits; it delves into challenges like ensuring data privacy, mitigating biases, and ensuring accountability in AI-driven educational systems. The conclusion contemplates the potential limitations and assurances of embedding GAI within educational setups. An appeal has been made for more profound research and enhancement of AI’s educational function. The intersection of pedagogical insights and effective human-AI collaboration is pivotal in this journey. This paper serves as a compass, guiding educators, researchers, and policymakers toward harnessing GAI’s potential to sculpt enriched, immersive educational landscapes.",26 September 2024,"Artificial intelligence, Education, Computational modeling, Solid modeling, Videos, Three-dimensional displays, Metaverse, Learning systems, Generative AI, Learning Experiences, Generative Adversarial Networks, Individual Students, Adaptive Learning, Teaching Methods, Field Of Education, Language Teaching, Learning Styles, Early Education, Language Model, Artificial Intelligence Technology, Artificial Intelligence Algorithms, Content Creation, Artificial Intelligence Models, Latent Dirichlet Allocation, Student Confidence, Privacy Breaches, Text Generation, Entrepreneurship Education, Video Simulation, Deepfake, Educational Endeavors, Learning Pace, Immersive Learning, Training Data, Model Bias, Skills Of Students, Language Learning, Interactive, Educational Contexts, GAI, education, applications, case studies, challenges, metaverse",IEEE Access,2025-03-17T00:00:00,8.0,The exploration of generative AI in education and the challenges it poses offers insights into the potential of personalized learning experiences and the importance of human-AI collaboration.
https://ieeexplore.ieee.org/document/9439459/,Machine Learning for Anomaly Detection: A Systematic Review,,"Anomaly detection has been used for decades to identify and extract anomalous components from data. Many techniques have been used to detect anomalies. One of the increasingly significant techniques is Machine Learning (ML), which plays an important role in this area. In this research paper, we conduct a Systematic Literature Review (SLR) which analyzes ML models that detect anomalies in their application. Our review analyzes the models from four perspectives; the applications of anomaly detection, ML techniques, performance metrics for ML models, and the classification of anomaly detection. In our review, we have identified 290 research articles, written from 2000-2020, that discuss ML techniques for anomaly detection. After analyzing the selected research articles, we present 43 different applications of anomaly detection found in the selected research articles. Moreover, we identify 29 distinct ML models used in the identification of anomalies. Finally, we present 22 different datasets that are applied in experiments on anomaly detection, as well as many other general datasets. In addition, we observe that unsupervised anomaly detection has been adopted by researchers more than other classification anomaly detection systems. Detection of anomalies using ML models is a promising area of research, and there are a lot of ML models that have been implemented by researchers. Therefore, we provide researchers with recommendations and guidelines based on this review.",24 May 2021,"Anomaly detection, Machine learning, Intrusion detection, Systematics, Training, Bibliographies, Analytical models, Systematic Review, Machine Learning, Anomaly Detection, Machine Learning Models, Research Articles, Performance Metrics, Machine Learning Techniques, Research Papers, Model Metrics, Learning Algorithms, Training Dataset, Search Terms, Machine Learning Methods, Data Mining, Unsupervised Learning, Detection Techniques, Filtering Process, Hybrid Model, False Alarm Rate, Intrusion Detection, Percentage Of Papers, Anomaly Detection Methods, Intrusion Detection System, Fraud Detection, Real-life Datasets, Contextual Dimensions, Semi-supervised Learning, Performance Of Machine Learning Models, Deep Learning Techniques, Anomaly detection, machine learning, security and privacy protection",IEEE Access,2025-03-17T00:00:00,6.0,"The systematic literature review on anomaly detection using ML models provides valuable insights, but the practical implications for European early-stage ventures may vary."
https://ieeexplore.ieee.org/document/10500411/,"GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions",,"The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.",15 April 2024,"Natural language processing, Solid modeling, Artificial intelligence, Surveys, Task analysis, Reviews, Transformers, Enabling Technologies, Generative Pretrained Transformer, Natural Language, Transformer Architecture, Social Media, Marketing, Training Data, Large Amount Of Data, Cloud Computing, Customer Service, Language Model, Sentiment Analysis, Text Classification, Content Creation, Customer Experience, Customer Orientation, Text Generation, Virtual Assistant, AI Models, Chatbot, NLP Tasks, AI Techniques, Data Analysis Capabilities, Business, Intelligent Tutoring Systems, Real-time Data, Data Privacy, Edge Devices, Generative pre-trained transformer, natural language processing, artificial intelligence",IEEE Access,2025-03-17T00:00:00,7.0,The detailed overview of Generative Pre-trained Transformer (GPT) and its impact on natural language processing tasks has significance for startups working in language-related applications.
https://ieeexplore.ieee.org/document/10409290/,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot distinguish the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.",19 January 2024,"Artificial intelligence, Visualization, Data models, Image recognition, Computational modeling, Synthetic data, Image classification, Image Classification, Synthetic Images, Neural Network, Convolutional Network, Convolutional Neural Network, Computer Vision, Binary Classification, Authentication, Hyperparameter Tuning, Image Generation, Binary Classification Problem, Message Authentication, Explainable Artificial Intelligence, Artificial Neural Network, Photography, F1 Score, Feature Maps, Precision And Recall, Human Eye, Diffusion Model, Synthetic Generation, Valuable Resource For Research, Trustworthiness Of The Data, Image Collection, Fake News, Matter Of Seconds, Depth Of Field, Photo-realistic Images, Human Faces, Validation Metrics, AI-generated images, generative AI, image classification, latent diffusion",IEEE Access,2025-03-17T00:00:00,8.0,"This abstract presents a significant advancement in AI-generated image recognition, which can have practical applications in various industries, including startups working with image processing technologies."
https://ieeexplore.ieee.org/document/9774372/,"A Review of BLDC Motor: State of Art, Advanced Control Techniques, and Applications",,"Brushless direct current (BLDC) motors are mostly preferred for dynamic applications such as automotive industries, pumping industries, and rolling industries. It is predicted that by 2030, BLDC motors will become mainstream of power transmission in industries replacing traditional induction motors. Though the BLDC motors are gaining interest in industrial and commercial applications, the future of BLDC motors faces indispensable concerns and open research challenges. Considering the case of reliability and durability, the BLDC motor fails to yield improved fault tolerance capability, reduced electromagnetic interference, reduced acoustic noise, reduced flux ripple, and reduced torque ripple. To address these issues, closed-loop vector control is a promising methodology for BLDC motors. In the literature survey of the past five years, limited surveys were conducted on BLDC motor controllers and designing. Moreover, vital problems such as comparison between existing vector control schemes, fault tolerance control improvement, reduction in electromagnetic interference in BLDC motor controller, and other issues are not addressed. This encourages the author in conducting this survey of addressing the critical challenges of BLDC motors. Furthermore, comprehensive study on various advanced controls of BLDC motors such as fault tolerance control, Electromagnetic interference reduction, field orientation control (FOC), direct torque control (DTC), current shaping, input voltage control, intelligent control, drive-inverter topology, and its principle of operation in reducing torque ripples are discussed in detail. This paper also discusses BLDC motor history, types of BLDC motor, BLDC motor structure, Mathematical modeling of BLDC and BLDC motor standards for various applications.",13 May 2022,"Induction motors, Brushless DC motors, Hysteresis motors, Electromagnetic interference, Industries, Rotors, Torque measurement, Control Techniques, Brushless DC, Brushless Direct Current Motor, Control Strategy, Vector Control, Motor Control, Direct Control, Fault-tolerant, Input Voltage, Electromagnetic Interference, Closed-loop Control, Intelligent Control, Torque Control, Induction Motor, Fault-tolerant Control, Acoustic Noise, Torque Ripple, Motor Type, Field-oriented Control, Fault-tolerant Capability, Back Electromotive Force, Pulsewidth Modulation Scheme, Magnetic Rotor, Pulse Width, Electric Vehicles, Flux Linkage, Rotor Position, Voltage Vector, Permanent Magnet, Three-phase Motor, BLDC motor, torque ripple, current shaping techniques, controlling input voltage, direct torque control, drive-inverter topology, field orientation control, motor design, fault tolerance control, electromagnetic interference reduction",IEEE Access,2025-03-17T00:00:00,5.0,"While the abstract discusses important challenges in BLDC motors, the practical value for startups and early-stage ventures in Europe may be limited as it focuses more on industrial applications."
https://ieeexplore.ieee.org/document/9840390/,"AI-Based Personalized E-Learning Systems: Issues, Challenges, and Solutions",,"A personalized e-learning system is effective in imparting enhanced learning to its users. As compared to a conventional e-learning system, which provides similar contents to each learner, a personalized learning system provides specific learning contents and assessments to the learners. Personalization is based on Artificial Intelligence (AI) based techniques in which appropriate contents for each learner are determined using the level of comprehension of the learner and the preferred modes of learning. This paper presents requirements and challenges for a personalized e-learning system. The paper is focused in elaborating four research questions, which are related to identifying key factors of personalized education, elaborating on state of the art research in the domain, utilizing benefits of AI in personalized education, and determining future research directions. The paper utilizes an in-depth survey of current research papers in answering these questions. It provides a comprehensive review of existing solutions in offering personalized e-learning solutions. It also elaborates on different learning models and learning theories, which are significant in providing personalized education. It proposes an efficient framework, which can offer personalized e-learning to each learner. The proposed framework includes five modules i.e Data Module, Adaptive Learning Module, Adaptable Learning Module, Recommender Module, Content and Assessment Delivery Module. Our work also identifies significant directions for future research. The paper is beneficial for academicians and researchers in understanding the requirements of such a system, comprehending its methodologies, and identifying challenges which are needed to be addressed.",26 July 2022,"Electronic learning, Education, Videos, Adaptation models, Object recognition, Artificial intelligence, Learning (artificial intelligence), Recommender systems, Data mining, E-learning System, Learning Models, Research Papers, Level Of Understanding, Individual Learning, Learning Module, Learning Content, Adaptive Learning, Content Delivery, Personal Education, Adaptive Modulation, Adaptive System, Unsupervised Learning, Long Short-term Memory, Recurrent Neural Network, Learning Performance, Learning Styles, Cognitive Components, Recommender Systems, Levels Of Learning, Personal Content, Personalized Recommendations, Learning Path, Behaviorism, Level Of Mastery, Item Response Theory, Graph Neural Networks, Recurrent Model, Continuous Data Collection, Collaborative Filtering, Adaptability, artificial intelligence, educational data mining, knowledge tracing, personalized e-learning, recommender systems",IEEE Access,2025-03-17T00:00:00,7.0,"The personalized e-learning system proposed in this abstract could have a positive impact on educational technology startups in Europe, offering a tailored learning experience for users."
https://ieeexplore.ieee.org/document/8972389/,"Internet of Things (IoT) for Next-Generation Smart Systems: A Review of Current Challenges, Future Trends and Prospects for Emerging 5G-IoT Scenarios",,"The Internet of Things (IoT)-centric concepts like augmented reality, high-resolution video streaming, self-driven cars, smart environment, e-health care, etc. have a ubiquitous presence now. These applications require higher data-rates, large bandwidth, increased capacity, low latency and high throughput. In light of these emerging concepts, IoT has revolutionized the world by providing seamless connectivity between heterogeneous networks (HetNets). The eventual aim of IoT is to introduce the plug and play technology providing the end-user, ease of operation, remotely access control and configurability. This paper presents the IoT technology from a bird's eye view covering its statistical/architectural trends, use cases, challenges and future prospects. The paper also presents a detailed and extensive overview of the emerging 5G-IoT scenario. Fifth Generation (5G) cellular networks provide key enabling technologies for ubiquitous deployment of the IoT technology. These include carrier aggregation, multiple-input multiple-output (MIMO), massive-MIMO (M-MIMO), coordinated multipoint processing (CoMP), device-to-device (D2D) communications, centralized radio access network (CRAN), software-defined wireless sensor networking (SD-WSN), network function virtualization (NFV) and cognitive radios (CRs). This paper presents an exhaustive review for these key enabling technologies and also discusses the new emerging use cases of 5G-IoT driven by the advances in artificial intelligence, machine and deep learning, ongoing 5G initiatives, quality of service (QoS) requirements in 5G and its standardization issues. Finally, the paper discusses challenges in the implementation of 5G-IoT due to high data-rates requiring both cloud-based platforms and IoT devices based edge computing.",28 January 2020,"5G mobile communication, Market research, Protocols, Internet of Things, Quality of service, Security, Next generation networking, Internet Of Things, Standardised, Machine Learning, Deep Learning, Artificial Intelligence, Service Quality, Wireless Networks, Detailed Overview, Multiple-input Multiple-output, Low Latency, Heterogeneous Network, Internet Of Things Devices, High Data Rate, Large Bandwidth, Wireless Sensor Networks, Service Requirements, Internet Of Things Technology, Quality Of Service Requirements, Cognitive Radio, Internet Of Things Nodes, Internet Of Things Architecture, Wireless Technologies, Internet Of Things Applications, 5G Technology, Internet Of Things Networks, Big Data, Control Plane, D2D Communication, High-quality Services, Internet of Things (IoT), 5G, carrier aggregation, CoMP, CRAN, CRs, HetNets, MIMO, M-MIMO, NFV, SD-WSN, QoS",IEEE Access,2025-03-17T00:00:00,6.0,"The overview of IoT and 5G technologies presents valuable insights for startups engaged in IoT solutions, showcasing the potential for innovation in connectivity and network technologies."
https://ieeexplore.ieee.org/document/9852458/,Explainable AI for Healthcare 5.0: Opportunities and Challenges,,"In the healthcare domain, a transformative shift is envisioned towards Healthcare 5.0. It expands the operational boundaries of Healthcare 4.0 and leverages patient-centric digital wellness. Healthcare 5.0 focuses on real-time patient monitoring, ambient control and wellness, and privacy compliance through assisted technologies like artificial intelligence (AI), Internet-of-Things (IoT), big data, and assisted networking channels. However, healthcare operational procedures, verifiability of prediction models, resilience, and lack of ethical and regulatory frameworks are potential hindrances to the realization of Healthcare 5.0. Recently, explainable AI (EXAI) has been a disruptive trend in AI that focuses on the explainability of traditional AI models by leveraging the decision-making of the models and prediction outputs. The explainability factor opens new opportunities to the black-box models and brings confidence in healthcare stakeholders to interpret the machine learning (ML) and deep learning (DL) models. EXAI is focused on improving clinical health practices and brings transparency to the predictive analysis, which is crucial in the healthcare domain. Recent surveys on EXAI in healthcare have not significantly focused on the data analysis and interpretation of models, which lowers its practical deployment opportunities. Owing to the gap, the proposed survey explicitly details the requirements of EXAI in Healthcare 5.0, the operational and data collection process. Based on the review method and presented research questions, systematically, the article unfolds a proposed architecture that presents an EXAI ensemble on the computerized tomography (CT) image classification and segmentation process. A solution taxonomy of EXAI in Healthcare 5.0 is proposed, and operational challenges are presented. A supported case study on electrocardiogram (ECG) monitoring is presented that preserves the privacy of local models via federated learning (FL) and EXAI for metric vali...",08 August 2022,"Medical services, Artificial intelligence, Predictive models, Analytical models, Prediction algorithms, Medical diagnostic imaging, Deep learning, Explainable Artificial Intelligence, Artificial Intelligence In Healthcare, Privacy, Prediction Model, Deep Learning, Big Data, Machine Learning Models, Image Classification, Image Segmentation, Deep Learning Models, Model Interpretation, Artificial Intelligence Models, Federated Learning, Healthcare Domain, Electrocardiogram Monitoring, Model Explainability, Learning Algorithms, Convolutional Neural Network, Convolutional Layers, Local Data, Artificial Intelligence Systems, Electrocardiogram Signals, Virtual Network Functions, Class Activation Maps, Future Scope, Local Explanations, Human-machine Interaction, SHapley Additive exPlanations, Open Challenges, Healthcare Applications, Explainable AI, healthcare 50, metrics, deep learning",IEEE Access,2025-03-17T00:00:00,9.0,"The Healthcare 5.0 concept and the focus on explainable AI in healthcare present a high practical value for startups in the health tech sector in Europe, addressing key issues and paving the way for ethical AI implementation in healthcare."
https://ieeexplore.ieee.org/document/8949524/,A Comprehensive Review on Malware Detection Approaches,,"According to the recent studies, malicious software (malware) is increasing at an alarming rate, and some malware can hide in the system by using different obfuscation techniques. In order to protect computer systems and the Internet from the malware, the malware needs to be detected before it affects a large number of systems. Recently, there have been made several studies on malware detection approaches. However, the detection of malware still remains problematic. Signature-based and heuristic-based detection approaches are fast and efficient to detect known malware, but especially signature-based detection approach has failed to detect unknown malware. On the other hand, behavior-based, model checking-based, and cloud-based approaches perform well for unknown and complicated malware; and deep learning-based, mobile devices-based, and IoT-based approaches also emerge to detect some portion of known and unknown malware. However, no approach can detect all malware in the wild. This shows that to build an effective method to detect malware is a very challenging task, and there is a huge gap for new studies and methods. This paper presents a detailed review on malware detection approaches and recent detection methods which use these approaches. Paper goal is to help researchers to have a general idea of the malware detection approaches, pros and cons of each detection approach, and methods that are used in these approaches.",03 January 2020,"Computer viruses, Feature extraction, Encryption, Internet, Detection Approach, Detection Methods, Challenging Task, Deep Learning-based Approaches, Neural Network, Deep Learning, Learning Algorithms, Support Vector Machine, Mobile Devices, Encryption, Internet Of Things, Application Programming Interface, Internet Of Things Devices, Automatic Generation, Model Checking, Benign Samples, Malicious Behavior, System Calls, Control Flow Graph, Signature Generation, Data Mining Algorithms, Graph Kernel, Use Of New Techniques, Ransomware, Detection Accuracy, Virus Detection, Hybrid Feature, Cyber security, malware classification, malware detection approaches, malware features",IEEE Access,2025-03-17T00:00:00,5.0,"The abstract addresses the pressing issue of malware detection, discussing various approaches and the challenges faced. While relevant for cybersecurity startups, the lack of specific new breakthroughs or innovations may limit its immediate impact on early-stage ventures."
https://ieeexplore.ieee.org/document/9893798/,"A Survey of Ensemble Learning: Concepts, Algorithms, Applications, and Prospects",,"Ensemble learning techniques have achieved state-of-the-art performance in diverse machine learning applications by combining the predictions from two or more base models. This paper presents a concise overview of ensemble learning, covering the three main ensemble methods: bagging, boosting, and stacking, their early development to the recent state-of-the-art algorithms. The study focuses on the widely used ensemble algorithms, including random forest, adaptive boosting (AdaBoost), gradient boosting, extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), and categorical boosting (CatBoost). An attempt is made to concisely cover their mathematical and algorithmic representations, which is lacking in the existing literature and would be beneficial to machine learning researchers and practitioners.",16 September 2022,"Boosting, Classification algorithms, Prediction algorithms, Machine learning algorithms, Computational modeling, Bagging, Machine learning, Learning systems, Machine Learning, Random Forest, Machine Learning Applications, Ensemble Method, Gradient Boosting, AdaBoost, Ensemble Learning Techniques, Learning Algorithms, Decision Tree, Machine Learning Models, Recurrent Neural Network, Final Prediction, Ensemble Model, Majority Voting, Random Forest Algorithm, Sentiment Analysis, Base Learners, Gradient Boosting Decision Tree, Subset Of Models, Ensemble Technique, Ensemble Learning Method, Conventional Machine Learning Algorithms, Fraud Detection, Dynamic Selection, Ensemble Learning Algorithm, Ensemble Diversity, Weak Learners, Long Short-term Memory, Individual Models, Misclassified Samples, Algorithms, classification, ensemble learning, fraud detection, machine learning, medical diagnosis",IEEE Access,2025-03-17T00:00:00,9.0,"The abstract presents a comprehensive overview of ensemble learning techniques, focusing on state-of-the-art algorithms. This valuable resource can benefit startups in machine learning applications by providing insights into the mathematical and algorithmic representations of ensemble methods."
https://ieeexplore.ieee.org/document/9103025/,"Digital Twin: Enabling Technologies, Challenges and Open Research",,"Digital Twin technology is an emerging concept that has become the centre of attention for industry and, in more recent years, academia. The advancements in industry 4.0 concepts have facilitated its growth, particularly in the manufacturing industry. The Digital Twin is defined extensively but is best described as the effortless integration of data between a physical and virtual machine in either direction. The challenges, applications, and enabling technologies for Artificial Intelligence, Internet of Things (IoT) and Digital Twins are presented. A review of publications relating to Digital Twins is performed, producing a categorical review of recent papers. The review has categorised them by research areas: manufacturing, healthcare and smart cities, discussing a range of papers that reflect these areas and the current state of research. The paper provides an assessment of the enabling technologies, challenges and open research for Digital Twins.",28 May 2020,"Smart cities, Data analysis, Manufacturing, Data models, Internet of Things, Computational modeling, Open Research, Digital Twin, Enabling Technologies, Area Of Research, Artificial Intelligence, Digital Technologies, Internet Of Things, Manufacturing Industry, Smart City, Machine Learning, Learning Algorithms, Manufacturing Process, Digital Model, Physical System, Broad Areas, Data Fusion, Internet Of Things Devices, Artificial Intelligence Algorithms, Cyber-physical Systems, Smart Manufacturing, Smart City Development, Internet Of Things Sensors, Internet Of Things Systems, Remaining Useful Life, Internet Of Things Technology, Blockchain, Predictive Maintenance, Manufacturing Environment, Industrial Internet Of Things, Digital twins, applications, enabling technologies, industrial Internet of Things (IIoT), Internet of Things (IoT), machine learning, deep learning, literature review",IEEE Access,2025-03-17T00:00:00,7.0,The abstract highlights the emerging concept of Digital Twin technology and its applications in various industries. The discussion on enabling technologies and research areas provides a solid foundation for startups interested in leveraging Digital Twins for innovation.
https://ieeexplore.ieee.org/document/10478883/,Privacy and Security Concerns in Generative AI: A Comprehensive Survey,,"Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.",25 March 2024,"Security, Generative AI, Privacy, Surveys, Data privacy, Data models, Computational modeling, Artificial intelligence, Generative adversarial networks, Deep learning, Ethics, Computer security, Threat assessment, Fake news, Homomorphic encryption, Privacy Issues, Comprehensive Survey, Security Concern, Privacy Challenges, Personal Data, Data Generation, Internet Of Things, Data Privacy, Recurrent Neural Network, Generative Adversarial Networks, Data Security, Anomaly Detection, Fake News, Artificial Intelligence Applications, Variational Autoencoder, Ethical Perspective, Adversarial Training, Federated Learning, Adversarial Attacks, Differential Privacy, Adversarial Examples, Generative Adversarial Network Framework, Multi-party Computation, AI Systems, Neural Network, Data Distribution, Data Storage, General Data Protection Regulation, Data Protection, User Perspective, Generative artificial intelligence, privacy concerns, security concerns, deep learning, adversarial attacks, synthetic data, Deepfake, ethical implications, cybersecurity, machine learning, privacy protection, ethical responsibility, misinformation, social engineering, regulatory compliance, artificial intelligence, privacy preservation, data security, threat analysis",IEEE Access,2025-03-17T00:00:00,6.0,"The abstract delves into the transformative impact of Generative Artificial Intelligence (GAI) across different domains. While the discussion on privacy and security challenges is relevant, the lack of specific practical applications or new advancements may limit its immediate relevance to early-stage ventures."
https://ieeexplore.ieee.org/document/8740989/,Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques,,"Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM).",19 June 2019,"Diseases, Heart, Data mining, Support vector machines, Feature extraction, Machine learning, Predictive models, Cardiovascular Disease, Machine Learning, Machine Learning Techniques, Disease Prediction, Heart Disease Prediction, Hybrid Machine Learning Techniques, Prediction Accuracy, Random Forest, Health Sector, Internet Of Things, Predictor Of Cardiovascular Disease, Different Combinations Of Features, Disease Severity, Neural Network, Diagnosis Of Disease, Convolutional Neural Network, Decision Tree, Data Mining, Results Of Method, Internet Of Things Devices, Presence Of Heart Disease, Absence Of Heart Disease, Heart Disease Patients, Multivariate Adaptive Regression Splines, Carotid Artery Stenting, Random Forest Method, UCI Machine Learning Repository, Radial Basis Function Network, Right Bundle Branch Block, Premature Ventricular Complexes, Machine learning, heart disease prediction, feature selection, prediction model, classification algorithms, cardiovascular disease (CVD)",IEEE Access,2025-03-17T00:00:00,7.0,The research on improving accuracy in the prediction of cardiovascular disease using machine learning techniques can have a significant impact on the healthcare industry and early-stage ventures focusing on healthcare technology.
https://ieeexplore.ieee.org/document/10198233/,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,,"Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.",01 August 2023,"Chatbots, Artificial intelligence, Computer security, Hidden Markov models, Privacy, Ethics, Switches, Generative adversarial networks, Open Challenges, Ethical Implications, Artificial Intelligence Models, Development Of Artificial Intelligence, Legal Implications, Code Generation, Incident Response, Injection Attacks, Encryption, Hallucinations, Sensitive Data, Language Model, General Data Protection Regulation, Large Volumes Of Data, Security Vulnerabilities, Artificial Intelligence Systems, Use Of Artificial Intelligence, Distributed Denial Of Service, Code Snippets, Piece Of Code, Code Review, Chatbot, Encrypted File, Use Of Personal Information, Malicious Activities, Intrusion Detection System, Text Generation, Generative AI, GenAI and cybersecurity, ChatGPT, Google bard, cyber offense, cyber defense, ethical GenAI, privacy, artificial intelligence, cybersecurity, jailbreaking",IEEE Access,2025-03-17T00:00:00,9.0,"The exploration of GenAI models in cybersecurity and privacy, along with the discussion on potential attacks and defense techniques, addresses a critical issue with high practical value in the context of European startups dealing with cybersecurity threats."
https://ieeexplore.ieee.org/document/7169508/citations?tabFilter=patents#anchor-patent-citations,A Survey of 5G Network: Architecture and Emerging Technologies,,"In the near future, i.e., beyond 4G, some of the prime objectives or demands that need to be addressed are increased capacity, improved data rate, decreased latency, and better quality of service. To meet these demands, drastic improvements need to be made in cellular network architecture. This paper presents the results of a detailed survey on the fifth generation (5G) cellular network architecture and some of the key emerging technologies that are helpful in improving the architecture and meeting the demands of users. In this detailed survey, the prime focus is on the 5G cellular network architecture, massive multiple input multiple output technology, and device-to-device communication (D2D). Along with this, some of the emerging technologies that are addressed in this paper include interference management, spectrum sharing with cognitive radio, ultra-dense networks, multi-radio access technology association, full duplex radios, millimeter wave solutions for 5G cellular networks, and cloud technologies for 5G radio access networks and software defined networks. In this paper, a general probable 5G cellular network architecture is proposed, which shows that D2D, small cell access points, network cloud, and the Internet of Things can be a part of 5G cellular network architecture. A detailed survey is included regarding current research projects being conducted in different countries by research groups and institutions that are working on 5G technologies.",28 July 2015,"5G mobile communication, Cloud computing, MIMO, Radio access networks, Cellular networks, 5G Networks, Data Rate, Service Quality, Small Cell, Cloud Computing, Cellular Networks, Internet Of Things, General Architecture, Cellular Architecture, Device-to-device, User Demand, Radio Access Network, Cognitive Radio, 5G Technology, Interference Management, Ultra-dense Networks, Wireless Networks, Cellular Systems, Base Station, Massive MIMO, User Equipment, Type Of Communication, Virtual Network Functions, Large Antenna Arrays, Millimeter Wave Communication, Attainment Rates, Code Division Multiple Access, Wireless Systems, Resource Block, 5G, Cloud, D2D, Massive MIMO, mm-wave, Relay, Small-cel, 5G, cloud, D2D, massive MIMO, mm-wave, relay, small-cell",IEEE Access,2025-03-17T00:00:00,8.0,"The detailed survey on 5G cellular network architecture and emerging technologies can provide valuable insights for startups working on improving network capabilities, making it highly relevant and impactful for the European market."
https://ieeexplore.ieee.org/document/9110603/,The Impact of Artificial Intelligence and Blockchain on the Accounting Profession,,"Recent developments in technology have introduced dramatic changes to the practice of the accounting profession. This paper provides a comprehensive review of current developments in big data, machine learning, artificial intelligence, and blockchain utilized in general business practice and by specialized practitioners in the accounting profession worldwide. This paper explores the evolution of the accounting profession following these recent technological developments and assesses the impact of future developments. Inherent challenges and opportunities posed by these new technologies pertaining to accounting professionals and accounting educators are also examined, including an increased demand for IT professionals with accounting experience as opposed to accounting major graduates. Considering the dramatic changes and developments of AI applications in accounting, this paper reflects how all these technologies and the associated requirements of job candidates will affect the desired capabilities of accounting graduates and provides further discussion regarding what higher institutions and their accounting graduates can do to adopt such changes.",08 June 2020,"Big Data, Blockchain, Machine learning, Finance, Artificial Intelligence, Professional Accountability, Impact Of Artificial Intelligence, Machine Learning, Development Of Technology, Big Data, Artificial Intelligence Applications, Recent Technological Developments, Development Of Artificial Intelligence, Big Machine, Development Of Big Data, IT Professionals, Artificial Neural Network, Professional Knowledge, Data Security, Machine Learning Applications, Real-time Information, General Data Protection Regulation, Radio Frequency Identification, Artificial Intelligence Technology, Machine Learning Technology, Blockchain Technology, Smart Contracts, Liberal Education, Text Generation, Fraud Detection, Message Authentication, Natural Language Processing Technologies, Programming Skills, Tax Returns, Accounting profession, artificial intelligence, big data, blockchain, machine learning",IEEE Access,2025-03-17T00:00:00,6.0,"The review of technological developments in accounting may have an impact on accounting professionals, but its immediate practical value for European early-stage ventures may be limited compared to other abstracts."
https://ieeexplore.ieee.org/document/9831441/,Artificial Intelligence Crime: An Overview of Malicious Use and Abuse of AI,,"The capabilities of Artificial Intelligence (AI) evolve rapidly and affect almost all sectors of society. AI has been increasingly integrated into criminal and harmful activities, expanding existing vulnerabilities, and introducing new threats. This article reviews the relevant literature, reports, and representative incidents which allows to construct a typology of the malicious use and abuse of systems with AI capabilities. The main objective is to clarify the types of activities and corresponding risks. Our starting point is to identify the vulnerabilities of AI models and outline how malicious actors can abuse them. Subsequently, we explore AI-enabled and AI-enhanced attacks. While we present a comprehensive overview, we do not aim for a conclusive and exhaustive classification. Rather, we provide an overview of the risks of enhanced AI application, that contributes to the growing body of knowledge on the issue. Specifically, we suggest four types of malicious abuse of AI (integrity attacks, unintended AI outcomes, algorithmic trading, membership inference attacks) and four types of malicious use of AI (social engineering, misinformation/fake news, hacking, autonomous weapon systems). Mapping these threats enables advanced reflection of governance strategies, policies, and activities that can be developed or improved to minimize risks and avoid harmful consequences. Enhanced collaboration among governments, industries, and civil society actors is vital to increase preparedness and resilience against malicious use and abuse of AI.",18 July 2022,"Artificial intelligence, Data models, Computer crime, Training data, Taxonomy, Machine learning, Legislation, Use Of Artificial Intelligence, Malicious Use, Use Of Systems, Civil Society, Body Of Knowledge, Sectors Of Society, Trading System, Harmful Actions, Types Of Abuse, Social Engineering, Unintended Outcomes, Malicious Activities, Artificial Intelligence Capabilities, Machine Learning, Election, European Union, Social Media Platforms, Generative Adversarial Networks, Dividend, Fake News, Artificial Intelligence Systems, Adversarial Examples, Malware, Artificial Intelligence Techniques, Brute-force Attacks, Cybercrime, Phishing, Information Literacy, Stop Sign, Malicious Intent, Artificial intelligence, artificial intelligence typology, computer crime, malicious artificial intelligence, security, social implications of technology",IEEE Access,2025-03-17T00:00:00,2.0,"While the abstract touches on important issues related to the malicious use and abuse of AI, the practical value for European early-stage ventures and startups is limited."
https://ieeexplore.ieee.org/document/9755930/,Credit Card Fraud Detection Using State-of-the-Art Machine Learning and Deep Learning Algorithms,,"People can use credit cards for online transactions as it provides an efficient and easy-to-use facility. With the increase in usage of credit cards, the capacity of credit card misuse has also enhanced. Credit card frauds cause significant financial losses for both credit card holders and financial companies. In this research study, the main aim is to detect such frauds, including the accessibility of public data, high-class imbalance data, the changes in fraud nature, and high rates of false alarm. The relevant literature presents many machines learning based approaches for credit card detection, such as Extreme Learning Method, Decision Tree, Random Forest, Support Vector Machine, Logistic Regression and XG Boost. However, due to low accuracy, there is still a need to apply state of the art deep learning algorithms to reduce fraud losses. The main focus has been to apply the recent development of deep learning algorithms for this purpose. Comparative analysis of both machine learning and deep learning algorithms was performed to find efficient outcomes. The detailed empirical analysis is carried out using the European card benchmark dataset for fraud detection. A machine learning algorithm was first applied to the dataset, which improved the accuracy of detection of the frauds to some extent. Later, three architectures based on a convolutional neural network are applied to improve fraud detection performance. Further addition of layers further increased the accuracy of detection. A comprehensive empirical analysis has been carried out by applying variations in the number of hidden layers, epochs and applying the latest models. The evaluation of research work shows the improved results achieved, such as accuracy, f1-score, precision and AUC Curves having optimized values of 99.9%,85.71%,93%, and 98%, respectively. The proposed model outperforms the state-of-the-art machine learning and deep learning algorithms for credit card detection problems. In addition, we ha...",12 April 2022,"Credit cards, Deep learning, Support vector machines, Prediction algorithms, Machine learning algorithms, Machine learning, Classification algorithms, Machine Learning, Deep Learning, Learning Algorithms, Credit Card, Fraud Detection, Credit Card Fraud Detection, Logistic Regression, Neural Network, Convolutional Neural Network, Support Vector Machine, Random Forest, Decision Tree, Hidden Layer, XGBoost, Machine Learning Analysis, Artificial Neural Network, Convolutional Layers, Machine Learning Models, Machine Learning Techniques, Long Short-term Memory, ReLU Activation Function, Batch Normalization Layer, Dropout Layer, Convolutional Neural Network Model, Generative Adversarial Networks, Dense Layer, Recurrent Neural Network, Restricted Boltzmann Machine, Node Parameters, Deep Belief Network, Fraud detection, deep learning, machine learning, online fraud, credit card frauds, transaction data analysis",IEEE Access,2025-03-17T00:00:00,8.0,"The research on credit card fraud detection using deep learning algorithms has a high practical value for European startups, especially in the financial sector, to reduce fraud losses and improve detection accuracy."
https://ieeexplore.ieee.org/document/10081336/,"Machine Learning Operations (MLOps): Overview, Definition, and Architecture",,"The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.",27 March 2023,"Interviews, Machine learning, Training, Collaboration, Bibliographies, Automation, Codes, Machine Learning, Machine Learning Operations, Best Practices, Set Of Concepts, Feedback Loop, Machine Learning Models, Performance Metrics, Software Development, Software Engineering, Continuous Training, Open-source Tool, Feature Engineering, System Challenges, Directed Acyclic Graph, Step Test, Train Machine Learning, Organizational Challenges, Machine Learning Systems, Train Machine Learning Models, Continuous Delivery, Monitoring Component, Concept Drift, Continuous Integration, Apache Spark, Best-performing Algorithm, Inference Rules, Data Streams, Credit Risk, Business, Proof Of Concept, CI/CD, DevOps, machine learning, MLOps, operations, workflow orchestration",IEEE Access,2025-03-17T00:00:00,5.0,"MLOps can help automate ML processes and bring products into production efficiently, which can be beneficial for startups working on ML projects."
https://ieeexplore.ieee.org/document/10549884/,EXplainable Artificial Intelligence (XAI)—From Theory to Methods and Applications,,"Intelligent applications supported by Machine Learning have achieved remarkable performance rates for a wide range of tasks in many domains. However, understanding why a trained algorithm makes a particular decision remains problematic. Given the growing interest in the application of learning-based models, some concerns arise in the dealing with sensible environments, which may impact users’ lives. The complex nature of those models’ decision mechanisms makes them the so-called “black boxes,” in which the understanding of the logic behind automated decision-making processes by humans is not trivial. Furthermore, the reasoning that leads a model to provide a specific prediction can be more important than performance metrics, which introduces a trade-off between interpretability and model accuracy. Explaining intelligent computer decisions can be regarded as a way to justify their reliability and establish trust. In this sense, explanations are critical tools that verify predictions to discover errors and biases previously hidden within the models’ complex structures, opening up vast possibilities for more responsible applications. In this review, we provide theoretical foundations of Explainable Artificial Intelligence (XAI), clarifying diffuse definitions and identifying research objectives, challenges, and future research lines related to turning opaque machine learning outputs into more transparent decisions. We also present a careful overview of the state-of-the-art explainability approaches, with a particular analysis of methods based on feature importance, such as the well-known LIME and SHAP. As a result, we highlight practical applications of the successful use of XAI.",05 June 2024,"Machine learning, Explainable AI, Predictive models, Computational modeling, Machine learning algorithms, Data models, Closed box, Artificial Intelligence, Explainable Artificial Intelligence, Machine Learning, Decision-making Process, Important Characteristics, Black Box, Performance Metrics, Learning-based Models, Application Of Intelligence, SHapley Additive exPlanations, Linear Model, Neural Network, Learning Models, Complex Models, Learning Algorithms, Convolutional Neural Network, Deep Neural Network, Deep Models, Input Features, Visualization Tool, Shapley Value, Local Explanations, Transparent Model, Model Interpretation, Monte Carlo Tree Search, Exploratory Methods, General Data Protection Regulation, Graph Neural Networks, Partial Dependence Plots, Decision Boundary, Black-box models, explainability, explainable machine learning, interpretability, interpretable machine learning",IEEE Access,2025-03-17T00:00:00,5.0,"The focus on Explainable AI (XAI) and transparency in decision-making has relevance for European startups using ML applications, but the abstract could provide more specific examples or applications for early-stage ventures."
https://ieeexplore.ieee.org/document/8325446/,Artificial Intelligence in the 21st Century,,"The field of artificial intelligence (AI) has shown an upward trend of growth in the 21st century (from 2000 to 2015). The evolution in AI has advanced the development of human society in our own time, with dramatic revolutions shaped by both theories and techniques. However, the multidisciplinary and fast-growing features make AI a field in which it is difficult to be well understood. In this paper, we study the evolution of AI at the beginning of the 21st century using publication metadata extracted from 9 top-tier journals and 12 top-tier conferences of this discipline. We find that the area is in the sustainable development and its impact continues to grow. From the perspective of reference behavior, the decrease in self-references indicates that the AI is becoming more and more open-minded. The influential papers/researchers/institutions we identified outline landmarks in the development of this field. Last but not least, we explore the inner structure in terms of topics’ evolution over time. We have quantified the temporal trends at the topic level and discovered the inner connection among these topics. These findings provide deep insights into the current scientific innovations, as well as shedding light on funding policies.",26 March 2018,"Artificial intelligence, Conferences, Computer vision, Statistical analysis, Cognition, Collaboration, Market research, Artificial Intelligence, Development Of Artificial Intelligence, Behavioral Perspective, Field Of Artificial Intelligence, Machine Learning, Deep Learning, Field Of Science, Internal Validity, Data Mining, Computer Vision, Number Of Papers, Conference Papers, Number Of Authors, Relevant Topics, Number Of Citations, Journal Papers, Popular Topics, Influence Of Institutions, Beginning Of This Century, Total Number Of Publications, Average Number Of Citations, Total Number Of Papers, Total Number Of Citations, Publications In This Area, Reference Number, Construct Validity, Programming Language, North America, Citations Of Papers, Development Of The Discipline, Artificial intelligence, data analytics, scientific impact, science of science, data science",IEEE Access,2025-03-17T00:00:00,3.0,The study on the evolution of AI in the 21st century provides interesting insights but lacks direct practical implications for European early-stage ventures or startups.
https://ieeexplore.ieee.org/document/9404177/,A Systematic Literature Review on Cloud Computing Security: Threats and Mitigation Strategies,,"Cloud computing has become a widely exploited research area in academia and industry. Cloud computing benefits both cloud services providers (CSPs) and consumers. The security challenges associated with cloud computing have been widely studied in the literature. This systematic literature review (SLR) is aimed to review the existing research studies on cloud computing security, threats, and challenges. This SLR examined the research studies published between 2010 and 2020 within the popular digital libraries. We selected 80 papers after a meticulous screening of published works to answer the proposed research questions. The outcomes of this SLR reported seven major security threats to cloud computing services. The results showed that data tampering and leakage were among the highly discussed topics in the chosen literature. Other identified security risks were associated with the data intrusion and data storage in the cloud computing environment. This SLR’s results also indicated that consumers’ data outsourcing remains a challenge for both CSPs and cloud users. Our survey paper identified the blockchain as a partnering technology to alleviate security concerns. The SLR findings reveal some suggestions to be carried out in future works to bring data confidentiality, data integrity, and availability.",14 April 2021,"Cloud computing, Security, Computational modeling, Information technology, Law, Cloud computing security, Authentication, Systematic Review, Cloud Computing, Mitigation Strategies, Multi-party Computation, Cloud Computing Security, Service Providers, Data Integration, Data Storage, Confidential Information, Digital Library, Information Leakage, Security Threats, Consumption Of Services, Security Risks, Paper Surveys, Security Challenges, Cloud Users, Internet Of Things, Data Privacy, Intrusion Detection System, Blockchain Technology, Security Issues, Cloud Providers, Security Approach, Smart Contracts, Virtual Machines, Identity Management, Intrusion Detection, Data Security, Auditing, cloud computing, cloud models, decryption, encryption, malicious behavior, intrusion, secured communication",IEEE Access,2025-03-17T00:00:00,5.0,"The systematic literature review on cloud computing security identifies major threats and suggests blockchain as a partnering technology, which may be beneficial for startups focusing on cloud services and security."
https://ieeexplore.ieee.org/document/10258162/,"Advances in Batteries, Battery Modeling, Battery Management System, Battery Thermal Management, SOC, SOH, and Charge/Discharge Characteristics in EV Applications",,"The second-generation hybrid and Electric Vehicles are currently leading the paradigm shift in the automobile industry, replacing conventional diesel and gasoline-powered vehicles. The Battery Management System is crucial in these electric vehicles and also essential for renewable energy storage systems. This review paper focuses on batteries and addresses concerns, difficulties, and solutions associated with them. It explores key technologies of Battery Management System, including battery modeling, state estimation, and battery charging. A thorough analysis of numerous battery models, including electric, thermal, and electro-thermal models, is provided in the article. Additionally, it surveys battery state estimations for a charge and health. Furthermore, the different battery charging approaches and optimization methods are discussed. The Battery Management System performs a wide range of tasks, including as monitoring voltage and current, estimating charge and discharge, equalizing and protecting the battery, managing temperature conditions, and managing battery data. It also looks at various cell balancing circuit types, current and voltage stressors, control reliability, power loss, efficiency, as well as their advantages and disadvantages. The paper also discusses research gaps in battery management systems.",22 September 2023,"Batteries, Battery management systems, State of charge, Renewable energy sources, Discharges (electric), Voltage control, Kalman filters, Electric vehicles, Thermal management, Health Status, State Of Charge, Thermal Management, Battery Model, Battery Management, Battery Management System, EV Applications, Battery Thermal, Renewable Energy, Electric Vehicles, Energy Storage Systems, Thermal Model, Cell Voltage, Battery Charging, Battery State, Energy Density, Kalman Filter, Data-driven Models, Internal Resistance, Equivalent Circuit Model, Battery State Of Charge, Battery Temperature, Thermal Runaway, Battery Current, Extended Kalman Filter, Electrochemical Model, Unscented Kalman Filter, Battery Capacity, Charging Rate, Battery Performance, Electric vehicle, battery management, battery modelling, state of charge, state of health, cell balancing, battery thermal management system",IEEE Access,2025-03-17T00:00:00,7.0,"The review paper on Battery Management System for electric vehicles addresses key technologies, concerns, and solutions, offering practical information for startups in the electric vehicle industry."
https://ieeexplore.ieee.org/document/10438431/,The Impact of Artificial Intelligence on Language Translation: A Review,,"In the context of a more linked and globalized society, the significance of proficient cross-cultural communication has been increasing to a position of utmost importance. Language functions as a crucial medium that establishes connections among people, corporations, and countries, demanding the implementation of precise and effective translation systems. This comprehensive review paper aims to contribute to the evolving landscape of AI-driven language translation by critically examining the existing literature, identifying key debates, and uncovering areas of innovation and limitations. The primary objective is to provide a nuanced understanding of the current state of AI-driven language translation, emphasizing the advancements, challenges, and ethical considerations. In this review, ongoing debates surrounding AI-driven language translations were actively involved. By evaluating different viewpoints and methodologies, insights into unresolved questions that contribute to a broader discourse in the field were provided. The future trajectory of this study involves the incorporation of cross-lingual dialect adaptability and the advancement of Artificial Intelligence translation systems, with a focus on prioritizing inclusion and cultural understanding.",16 February 2024,"Artificial intelligence, Machine translation, Natural language processing, Fuzzy logic, Feature extraction, Deep learning, Training, Language Translation, Translation System, Neural Network, Deep Learning, Deep Neural Network, Attention Mechanism, Areas For Improvement, Fuzzy Logic, Language Model, English Translation, Parallel Data, Fuzzy Theory, Translation Accuracy, Machine Translation, Use Of Neural Networks, Named Entity Recognition, Language Pairs, Parallel Corpus, Field Of Translation, Neural Machine Translation, Translation Technique, Google Translate, Natural Language Processing Techniques, Recurrent Neural Network, Deep Learning Techniques, Use Of Machines, English Text, Conditional Random Field, Artificial intelligence, language translation, machine translation",IEEE Access,2025-03-17T00:00:00,3.0,"While AI-driven language translation is important for global communication, the direct impact on European early-stage ventures may be limited unless they are specifically focused on language technology."
https://ieeexplore.ieee.org/document/9279211/,Medical Diagnostic Systems Using Artificial Intelligence (AI) Algorithms: Principles and Perspectives,,"Disease diagnosis is the identification of an health issue, disease, disorder, or other condition that a person may have. Disease diagnoses could be sometimes very easy tasks, while others may be a bit trickier. There are large data sets available; however, there is a limitation of tools that can accurately determine the patterns and make predictions. The traditional methods which are used to diagnose a disease are manual and error-prone. Usage of Artificial Intelligence (AI) predictive techniques enables auto diagnosis and reduces detection errors compared to exclusive human expertise. In this paper, we have reviewed the current literature for the last 10 years, from January 2009 to December 2019. The study considered eight most frequently used databases, in which a total of 105 articles were found. A detailed analysis of those articles was conducted in order to classify most used AI techniques for medical diagnostic systems. We further discuss various diseases along with corresponding techniques of AI, including Fuzzy Logic, Machine Learning, and Deep Learning. This research paper aims to reveal some important insights into current and previous different AI techniques in the medical field used in today’s medical research, particularly in heart disease prediction, brain disease, prostate, liver disease, and kidney disease. Finally, the paper also provides some avenues for future research on AI-based diagnostics systems based on a set of open problems and challenges.",03 December 2020,"Diseases, Artificial intelligence, Medical diagnostic imaging, Medical services, Fuzzy logic, Deep learning, Medical diagnosis, Diagnostic Systems, Artificial Intelligence Algorithms, Medical Diagnostic Systems, Cardiovascular Disease, Machine Learning, Kidney Disease, Deep Learning, Diagnosis Of Disease, Brain Disorders, Medical Field, Disease Prediction, Fuzzy Logic, Human Experts, Artificial Intelligence Techniques, Breast Cancer, Neural Network, Learning Algorithms, Deep Network, Artificial Neural Network, Deep Neural Network, Fuzzy System, Artificial Intelligence Methods, Artificial Intelligence In Healthcare, Periodontitis, Fuzzy Method, Definition Of Disease, Deep Models, Artificial Intelligence Applications, Diagnosis Process, Detection Of Sepsis, Big data analytics, artificial intelligence, machine learning, deep learning, soft computing, chronic disease, diagnosis, health care prediction",IEEE Access,2025-03-17T00:00:00,7.0,"The research paper on AI techniques for disease diagnosis provides insights into current and previous AI techniques in the medical field, which could be valuable for startups developing medical diagnostic systems."
https://ieeexplore.ieee.org/document/9815071/,IoT-Enabled Smart Waste Management Systems for Smart Cities: A Systematic Review,,"With urbanization, rising income and consumption, the production of waste increases. One of the most important directions in the field of sustainable development is the design and implementation of monitoring and management systems for waste collection and removal. Smart waste management (SWM) involves for example collection and analytics of data from sensors on smart garbage bins (SGBs), management of waste trucks and urban infrastructure; planning and optimization of waste truck routes; etc. The purpose of this paper is to provide a comprehensive overview of the existing research in the field of systems, applications, and approaches vis-à-vis the collection and processing of solid waste in SWM systems. To achieve this objective, we performed a systematic literature review. This study consists of 173 primary studies selected for analysis and data extraction from the 3,732 initially retrieved studies from 5 databases. We 1) identified the main approaches and services that are applied in the city and SGB-level SWM systems, 2) listed sensors and actuators and analyzed their application in various types of SWM systems, 3) listed the direct and indirect stakeholders of the SWM systems, 4) identified the types of data shared between the SWM systems and stakeholders, and 5) identified the main promising directions and research gaps in the field of SWM systems. Based on an analysis of the existing approaches, technologies, and services, we developed recommendations for the implementation of city-level and SGB-level SWM systems.",04 July 2022,"Waste management, Stakeholders, Smart cities, Biological system modeling, Systematics, Sensor systems, Intelligent sensors, Systematic Review, Management System, Waste Management, Smart City, Waste Management System, Literature Review, Urbanization, Research In The Field, Research Gap, Actuator, Field Direction, Pathfinding, Field Of Systems, Urban Infrastructure, Route Planning, Processing Waste, Waste Collection, Implementation Of Monitoring, Main Service, Various Types Of Applications, Waste Separation, Primary Stakeholders, Situation In Cities, Internet Of Things, Gas Sensors, Internet Of Things Technology, Solid Waste Management, Supporting Information, Real-time Data, Search Queries, Smart city, smart waste management, Internet of Things, smart garbage bin",IEEE Access,2025-03-17T00:00:00,5.0,"The paper on smart waste management systems offers a comprehensive overview of existing research, which may be beneficial for startups working on sustainable waste management solutions."
https://ieeexplore.ieee.org/document/8466590/,Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI),,"At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.",16 September 2018,"Conferences, Machine learning, Market research, Prediction algorithms, Machine learning algorithms, Biological system modeling, Artificial Intelligence, Explainable Artificial Intelligence, Machine Learning, Learning Algorithms, Deep Neural Network, Machine Learning Models, Internet Of Things, Technical Challenges, Human-computer Interaction, Intelligent Systems, Applicability Domain, Challenging Issue, General Data Protection Regulation, Human Sciences, Expert System, Artificial Intelligence Systems, Decision-making Algorithm, Neural Net, Artificial Intelligence Research, Papers In The Field, Interpretable Machine Learning, Trade Secrets, Healthcare Domain, Autonomous Vehicles, Artificial Neural Network, Research Community, Decision Tree, Recidivism, Social Sciences, Explainable artificial intelligence, interpretable machine learning, black-box models",IEEE Access,2025-03-17T00:00:00,3.0,"While XAI is an important topic for AI-based systems, the practical implications for early-stage ventures may be limited as they may not be heavily involved in AI development."
https://ieeexplore.ieee.org/document/9311735/,Machine Learning Applications for Precision Agriculture: A Comprehensive Review,,"Agriculture plays a vital role in the economic growth of any country. With the increase of population, frequent changes in climatic conditions and limited resources, it becomes a challenging task to fulfil the food requirement of the present population. Precision agriculture also known as smart farming have emerged as an innovative tool to address current challenges in agricultural sustainability. The mechanism that drives this cutting edge technology is machine learning (ML). It gives the machine ability to learn without being explicitly programmed. ML together with IoT (Internet of Things) enabled farm machinery are key components of the next agriculture revolution. In this article, authors present a systematic review of ML applications in the field of agriculture. The areas that are focused are prediction of soil parameters such as organic carbon and moisture content, crop yield prediction, disease and weed detection in crops and species detection. ML with computer vision are reviewed for the classification of a different set of crop images in order to monitor the crop quality and yield assessment. This approach can be integrated for enhanced livestock production by predicting fertility patterns, diagnosing eating disorders, cattle behaviour based on ML models using data collected by collar sensors, etc. Intelligent irrigation which includes drip irrigation and intelligent harvesting techniques are also reviewed that reduces human labour to a great extent. This article demonstrates how knowledge-based agriculture can improve the sustainable productivity and quality of the product.",31 December 2020,"Agriculture, Artificial intelligence, Internet of Things, Irrigation, Wireless sensor networks, Soil, Sensors, Machine Learning, Machine Learning Applications, Precision Agriculture, Climatic Conditions, Crop Yield, Computer Vision, Machine Learning Models, Internet Of Things, Agricultural Fields, Disease Detection, Livestock Production, Yield Prediction, Soil Parameters, Crop Diseases, Intelligence Techniques, Drip Irrigation, Harvesting Techniques, Crop Weed, Irrigation Techniques, Agricultural Revolution, Learning Algorithms, Livestock Management, Extreme Learning Machine, Unmanned Aerial Vehicles, Regression Algorithm, Disease Identification, Subclinical Mastitis, Partial Least Squares Regression, Support Vector Regression, Prediction Algorithms, Agricultural engineering, machine learning, intelligent irrigation, IoT, prediction",IEEE Access,2025-03-17T00:00:00,6.0,"Precision agriculture using ML and IoT can have a significant impact on agricultural sustainability and production, which can benefit European early-stage ventures in the agri-tech sector."
https://ieeexplore.ieee.org/document/9083958/,An Overview on Edge Computing Research,,"With the rapid development of the Internet of Everything (IoE), the number of smart devices connected to the Internet is increasing, resulting in large-scale data, which has caused problems such as bandwidth load, slow response speed, poor security, and poor privacy in traditional cloud computing models. Traditional cloud computing is no longer sufficient to support the diverse needs of today's intelligent society for data processing, so edge computing technologies have emerged. It is a new computing paradigm for performing calculations at the edge of the network. Unlike cloud computing, it emphasizes closer to the user and closer to the source of the data. At the edge of the network, it is lightweight for local, small-scale data storage and processing. This article mainly reviews the related research and results of edge computing. First, it summarizes the concept of edge computing and compares it with cloud computing. Then summarize the architecture of edge computing, keyword technology, security and privacy protection, and finally summarize the applications of edge computing.",01 May 2020,"Cloud computing, Edge computing, Real-time systems, Internet of Things, Bandwidth, Security, Data privacy, Edge Computing, Data Processing, Computational Model, Data Storage, Cloud Computing, Internet Of Things, Computer Technology, Privacy Protection, Security Protection, Large Amount Of Data, Data Privacy, Data Security, Access Control, Mobile Network, Edge Nodes, User Equipment, Edge Devices, Mobile Edge Computing, Data Privacy Protection, Identity Authentication, Offloading Decision, Mobile Edge Computing Server, Location Privacy, Computation Offloading, Attribute-based Encryption, Service Layer, Predictive Maintenance, Edge Layer, Live Broadcast, Intelligence Analysis, Edge computing, cloud computing, Internet of Things",IEEE Access,2025-03-17T00:00:00,6.0,"Edge computing can provide solutions to current challenges in data processing and security, which can be valuable for European startups looking to leverage IoT and smart devices."
https://www.sciencedirect.com/science/article/pii/S0950584925000400,"Metaverse Applications: Challenges, Limitations and Opportunities - A Systematic Literature Review",María José=Escalona: mjescalona@us.es; Elena=Enamorado-Díaz: eenamorado@us.es; Julián A.=García-García: juliangg@us.es; David=Lizcano-Casas: david.lizcano@udima.es,"Abstract
Context:
The metaverse, an emerging concept at the intersection of digital technology and society, is gaining relevance in multiple domains, including education, entertainment and healthcare. Shared virtual spaces allow users to interact in innovative ways, but the design and development of these environments pose significant challenges for software engineering teams as well as users.
Objective:
The objective of this study is to provide a comprehensive systematic literature review of metaverse applications over the past decade. The review aims to identify key areas of application, technologies employed, virtualized elements, and economic aspects, as well as to explore the objectives, motivations, scope, challenges, and limitations faced in Software Engineering when conceptualizing metaverse environments. Additionally, the study examines the nature, knowledge area, type, and validation of the studies included in the review.
Methods:
This study was conducted using the Kitchenham methodology for systematic literature reviews (SLR). A total of 35 primary studies were selected from major scientific databases, including IEEE, ACM Digital Library, PubMed, ScienceDirect, and Scopus. These studies were evaluated to extract relevant data.
Results:
We have identified application areas, technologies used, virtualized elements and economic aspects used, as well as the objectives, motivations, scope, challenges and limitations in Software Engineering related to the conceptualization of environments and non-functional characteristics of the metaverse. The nature, area of knowledge, type and validation of the studies chosen in this review are also analyzed.
Conclusion:
The study concludes that while the metaverse presents huge opportunities across multiple domains, its development faces significant challenges, particularly in software engineering related to the non-functional aspects of these environments. To address these challenges, future research should focus on the application of the Model Driven Engineering (MDE) paradigm, which could optimize development processes and better manage the complexities of the metaverse.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The study on metaverse applications provides valuable insights into challenges faced in software engineering, offering potential solutions for the development of metaverse environments with a focus on non-functional aspects, which can be beneficial for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584925000448,Cascading failure prediction and recovery in large-scale critical infrastructure networks: A survey,Wei=Hu: weihu@nwpu.edu.cn,"Abstract
Context:
Large-scale critical infrastructure (CI) networks are crucial to society but prone to cascading failures due to their dynamic and interconnected characteristics. Recent research focuses on their reliability, using network theories and real-world data to develop recovery functions and crash warning indicators.
Objective:
This review evaluates cascading failure prediction and recovery trends, examines verification methods, and addresses challenges in enhancing network reliability and topology recovery within CI systems.
Methods:
A comprehensive survey explores cascading failure prediction and recovery from two perspectives: inter-network and inter-module structures. It summarizes recent research trends, common verification platforms, and datasets for predicting and recovering from cascading failures.
Results:
The review focuses on low-dimensional static networks, revealing significant challenges in dynamic environments. It underscores the necessity for improved recovery techniques and enhanced network reliability.
Conclusion:
This article identifies future research directions and unresolved issues by analyzing existing work in cascading failure prediction and recovery. Understanding cascading failure mechanisms aims to inspire the design of more resilient and reliable network systems, contributing to developing cohesive and low-coupling CI systems.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The review on cascading failures in critical infrastructure networks offers valuable insights into recovery trends and challenges, which could provide useful knowledge for European startups operating in sectors dependent on critical infrastructure networks."
https://www.sciencedirect.com/science/article/pii/S0950584925000461,A review of backdoor attacks and defenses in code large language models: Implications for security measures,Yubin=Qu: quyubin@hotmail.com,"Abstract
Context:
Large Language Models (LLMS) have revolutionized software engineering by bridging human language understanding and complex problem solving. However, resource constraints often lead users to rely on open-source models or third-party platforms for training and prompt engineering, introducing significant security vulnerabilities.
Objective:
This study provides a comprehensive analysis of backdoor attacks targeting LLMS in software engineering, with a particular focus on fine-tuning methods. Our work addresses a critical gap in existing literature by proposing a novel three-category framework for backdoor attacks: full-parameter fine-tuning, parameter-efficient fine-tuning, and no-tuning attacks.
Methods:
We systematically reviewed existing studies and analyzed attack success rates across different methods. Full-parameter fine-tuning generally achieves high success rates but requires significant computational resources. Parameter-efficient fine-tuning offers comparable success rates with lower resource demands, while no-tuning attacks exhibit variable success rates depending on prompt design, posing unique challenges due to their minimal resource requirements.
Results:
Our findings underscore the evolving landscape of backdoor attacks, highlighting the shift towards more resource-efficient and stealthy methods. These trends emphasize the need for advanced detection mechanisms and robust defense strategies.
Conclusion:
By focusing on code-specific threats, this study provides unique insights into securing LLMS in software engineering. Our work lays the foundation for future research on developing sophisticated defense mechanisms and understanding stealthy backdoor attacks.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The analysis of backdoor attacks targeting Large Language Models in software engineering provides crucial insights into security vulnerabilities and defense strategies, which can be relevant for European early-stage ventures dealing with sensitive data and intellectual property."
https://www.sciencedirect.com/science/article/pii/S0950584925000588,Dynamic information utilization for securing Ethereum smart contracts: A literature review,Li=Bixin: bx.li@seu.edu.cn; Tianyuan=Hu: tianyuan.hu@njtech.edu.cn,"Abstract
Smart contracts, self-executing programs that govern digital assets on blockchain platforms, have gained widespread adoption due to their automation and transparency. However, vulnerabilities in smart contracts can lead to financial losses and reputational damage, making their security a critical concern. Static code auditing methods are prone to false positives and false negatives, as they fail to account for real-time execution conditions. The integration of dynamic information offers a promising avenue for addressing these limitations and enhancing smart contract security. Ethereum, the most widely used blockchain platform, provides a wealth of publicly available data and has attracted significant attention from researchers due to its security problems. This paper presents a systematic mapping study focused on Ethereum, reviewing the existing literature on the use of dynamic information for enhancing the security of smart contracts. It offers a comprehensive overview of security problems, dynamic information types, technical approaches, and validation methods. Furthermore, we examine the implications and limitations of current research and propose future directions for further exploration in the field of Ethereum smart contract protection.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The systematic mapping study on Ethereum smart contracts offers a comprehensive overview of security issues and dynamic information utilization, which could be valuable for startups in the blockchain space looking to enhance the security of their smart contracts."
https://www.sciencedirect.com/science/article/pii/S0950584925000667,A systematic literature review of agile software development projects,Soumya Prakash=Rath: ephd22soumya@iimnagpur.ac.in; Nikunj Kumar=Jain: nikunj@iimnagpur.ac.in,"Abstract
Context
Agile software development (ASD) is gaining prominence as the leading methodology for modern software development organizations because it enables a fast, effective, and customer-centric approach in the current disruptive and dynamic work environment.
Objective
Despite increasing interest in ASD as a research area, the extant literature remains scattered and lacks convergence. This study provides a detailed account of all aspects of ASD, including emerging agile concepts, such as agile governance and large-scale agile implementations.
Method
A systematic literature review (SLR) technique identifies 208 relevant articles. The study included papers published between 1999 and 2024.
Results
This SLR provides a concise overview of the various theories applied in the context of ASD. The study classifies previous literature into numerous different facets of ASD. In addition, the paper has prepared an extensive list of relevant research questions for future investigations in each domain of ASD.
Conclusion
This study offers scholars insights into the status of ASD research as well as the current trends in ASD. Furthermore, the proposed future research questions provide researchers with precise direction for delving deeper into different facets of ASD.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The systematic literature review on Agile software development provides a detailed account of emerging agile concepts, offering scholars and researchers insights into current trends and research questions, which can benefit European startups adopting agile methodologies for software development."
https://www.sciencedirect.com/science/article/pii/S095058492500045X,JIT-CF: Integrating contrastive learning with feature fusion for enhanced just-in-time defect prediction,Xiang=Chen: xchencs@ntu.edu.cn; Xiaolin=Ju: ju.xl@ntu.edu.cn; Yi=Cao: ntucaoyi@outlook.com; Lina=Gong: gonglina@nuaa.edu.cn; Vaskar=Chakma: vaskarchakma7@gmail.com; Xin=Zhou: xinzhountu@hotmail.com,"Abstract
Context:
Just-in-time defect prediction (JIT-DP) is a crucial process in software development that focuses on identifying potential defects during code changes, facilitating early mitigation and quality assurance. Pre-trained language models like CodeBERT have shown promise in various applications but often struggle to distinguish between defective and non-defective code, especially when dealing with noisy labels.
Objective:
The primary aim of this study is to enhance the robustness of pre-trained language models in identifying software defects by developing an innovative framework that leverages contrastive learning and feature fusion.
Method:
We introduce JIT-CF, a framework that improves model robustness by employing contrastive learning to maximize similarity within positive pairs and minimize it between negative pairs, thereby enhancing the model’s ability to detect subtle differences in code changes. Additionally, feature fusion is used to combine semantic and expert features, enabling the model to capture richer contextual information. This integrated approach aims to improve the identification and resolution of code defects.
Results:
JIT-CF was evaluated using the JIT-Defects4J dataset, which includes 23,379 code commits from 21 projects. The results indicate substantial performance improvements over seven state-of-the-art baselines, with enhancements of up to 13.9% in F1-score, 8% in AUC, and 11% in Recall@20%E. The study also explores the impact of specific customization enhancements, demonstrating the potential for improved just-in-time defect localization.
Conclusion:
The proposed JIT-CF framework significantly advances the field of just-in-time defect prediction by effectively addressing the challenges encountered by pre-trained models in distinguishing code defects. The integration of contrastive learning and feature fusion not only enhances the model’s robustness but also leads to notable improvements in prediction accuracy, offering valuable insights for future applications in software development.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The study addresses an important aspect of software development and proposes an innovative framework that shows substantial performance improvements over existing baselines, offering valuable insights for future applications."
https://www.sciencedirect.com/science/article/pii/S0950584925000497,Fairness-aware practices from developers’ perspective: A survey,Filomena=Ferrucci: fferrucci@unisa.it; Fabio=Palomba: fpalomba@unisa.it; Gianmario=Voria: gvoria@unisa.it; Giulia=Sellitto: gisellitto@unisa.it; Carmine=Ferrara: cferrara@unisa.it; Francesco=Abate: f.abate20@studenti.unisa.it; Andrea=De Lucia: adelucia@unisa.it; Gemma=Catolino: gcatolino@unisa.it,"Abstract
Context:
Machine Learning (ML) technologies have shown great promise in many areas, but when used without proper oversight, they can produce biased results that discriminate against historically underrepresented groups. In recent years, the software engineering research community has contributed to addressing the need for ethical machine learning by proposing a number of fairness-aware practices, e.g., fair data balancing or testing approaches, that may support the management of fairness requirements throughout the software lifecycle. Nonetheless, the actual validity of these practices, in terms of practical application, impact, and effort, from the developers’ perspective has not been investigated yet.
Objective:
This paper addresses this limitation, assessing the developers’ perspective of a set of 28 fairness practices collected from the literature.
Methods:
We perform a survey study involving 155 practitioners who have been working on the development and maintenance of ML-enabled systems, analyzing the answers via statistical and clustering analysis to group fairness-aware practices based on their application frequency, impact on bias mitigation, and effort required for their application.
Results:
While all the practices are deemed relevant by developers, those applied at the early stages of development appear to be the most impactful. More importantly, the effort required to implement the practices is average and sometimes high, with a subsequent average application.
Conclusion:
The findings highlight the need for effort-aware automated approaches that ease the application of the available practices, as well as recommendation systems that may suggest when and how to apply fairness-aware practices throughout the software lifecycle.",June 2025,"Software engineering for artificial intelligence, Machine learning fairness engineering, Survey studies, Empirical software engineering",Information and Software Technology,2025-03-21T00:00:00,6.0,"The paper explores fairness practices in ML development, providing insights from developers' perspective. While the findings are relevant, the impact on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584925000485,Unveiling security weaknesses in autonomous driving systems: An in-depth empirical study,Peng=Liang: liangp@whu.edu.cn; Zengyang=Li: zengyangli@ccnu.edu.cn; Ran=Mo: moran@ccnu.edu.cn; Hui=Liu: hliu@hust.edu.cn; Wenyuan=Cheng: closerecover@mails.ccnu.edu.cn,"Abstract
Context:
The advent of Autonomous Driving Systems (ADS) has marked a significant shift towards intelligent transportation, with implications for public safety and traffic efficiency. While these systems integrate a variety of technologies and offer numerous benefits, their security is paramount, as vulnerabilities can have severe consequences for safety and trust.
Objective:
This study aims to systematically investigate potential security weaknesses in the codebases of prominent open-source ADS projects using CodeQL, a static code analysis tool. The goal is to identify common vulnerabilities, their distribution and persistence across versions to enhance the security of ADS.
Methods:
We selected three representative open-source ADS projects, Autoware, AirSim, and Apollo, based on their high GitHub star counts and Level 4 autonomous driving capabilities. Using CodeQL, we analyzed multiple versions of these projects to identify vulnerabilities, focusing on CWE categories such as CWE-190 (Integer Overflow or Wraparound) and CWE-20 (Improper Input Validation). We also tracked the lifecycle of these vulnerabilities across software versions. This approach allows us to systematically analyze vulnerabilities in projects, which has not been extensively explored in previous ADS research.
Results:
Our analysis revealed that specific CWE categories, particularly CWE-190 (59.6%) and CWE-20 (16.1%), were prevalent across the selected ADS projects. These vulnerabilities often persisted for over six months, spanning multiple version iterations. The empirical assessment showed a direct link between the severity of these vulnerabilities and their tangible effects on ADS performance.
Conclusions:
These security issues among ADS still remain to be resolved. Our findings highlight the need for integrating static code analysis into ADS development to detect and mitigate common vulnerabilities. Meanwhile, proactive protection strategies, such as regular update of third-party libraries, are essential to improve ADS security. And regulatory bodies can play a crucial role in promoting the use of static code analysis tools and setting industry security standards.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The investigation of security vulnerabilities in open-source ADS projects using CodeQL is crucial for ensuring public safety and trust in autonomous driving systems. The findings highlight the importance of integrating static code analysis and proactive protection strategies.
https://www.sciencedirect.com/science/article/pii/S0950584925000473,Investigating the relationship between coordination strategy and coordination effectiveness in agile software development projects,Geetha=Kanaparan: geetha.kanaparan@xmu.edu.my; Diane E.=Strode: diane.strode@alumni.unimelb.edu.au,"Abstract
Context
Agile software development (ASD) provides a way to coordinate teams and projects. Coordination is achieved by adopting a set of agile practices; however, these agile practices may differ for each project. The chosen assemblage of practices can be considered an agile project coordination strategy. The current body of knowledge about coordinative practices and theories of coordination in ASD is almost exclusively based on case studies. A validated model is currently lacking.
Objective
The objective is to validate a theoretical model to explain coordination in ASD, particularly the relationship between coordination strategy and coordination effectiveness.
Method
We validate this relationship based on an international survey of 340 agile practitioners and use PLS-SEM to estimate the relationships.
Results
The results show that an agile coordination strategy, that includes synchronisation, structure, and boundary-spanning, has a positive relationship with coordination effectiveness (implicit and explicit). Customer involvement moderates the relationship between coordination strategy and coordination effectiveness. These results are primarily supported by evidence from virtual work arrangements.
Conclusion
This research provides a validated coordination theory and information on what agile practices are related to effective coordination in agile software development. This coordination theory can be used to investigate coordination in future agile method variants used in system and software development projects.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The research validates a theoretical model for coordination in agile software development, offering insights into coordination strategies and effectiveness. While the results are valuable, the practical impact on European early-stage ventures may be moderate."
https://www.sciencedirect.com/science/article/pii/S0950584925000424,A software vulnerability detection method based on multi-modality with unified processing,Lipeng=Gao: gaolipeng@nwpu.edu.cn,"Abstract
With the development of the Internet and the Internet of Things, software has become an indispensable part, making software vulnerabilities one of the main threats to computer security. In recent years, a multitude of deep learning-based software vulnerability detection methods have been proposed, especially those based on multimodal approaches. Although these multimodal methods have proven to be effective, they often treat each modality separately. We propose a novel multimodal deep learning method for software vulnerability detection that achieves unified processing of various modalities. This method uses complex network analysis to convert the Code Property Graph into an image-like matrix, obtains key fragments from the source code using code slicing, and then uses a Transformer for function-level vulnerability detection. This enables deeper integration of information from multiple modalities, enhancing detection accuracy. Additionally, it significantly simplifies the model architecture. The result shows that compared to the state-of-the-art methods, our method has improved accuracy by 3%. Furthermore, our approach is capable of detecting some of the vulnerabilities recently released by CVE.",June 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposed multimodal deep learning method for software vulnerability detection presents a novel approach with improved accuracy compared to existing methods. The integration of information from multiple modalities enhances detection accuracy, making it impactful for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584925000230,Practical assessment of the e-commerce multivariant user interface,Adam=Wasilewski: adam.wasilewski@pwr.edu.pl,"Abstract
Context:
Personalization is recognized as one of the key trends in e-commerce development, often including the personalization of offers and prices. However, a rarely used and underestimated personalization opportunity is the customization of the user interface provided to customers. Customers of e-shops differ in their behaviors and usage patterns, yet there is no clear evidence verifying the potential of the user interface to influence the performance indicators of e-shops.
Objective:
The research discussed in this paper aims to verify the impact of a dedicated interface on the most common indicators describing e-commerce performance and to identify limitations to the use of user interface personalization in e-commerce.
Method:
To achieve this, a solution was developed to collect information about e-commerce customer behavior, segment customers using clustering methods, and provide a dedicated user interface. During the pilot implementation, data was collected to verify the impact of the dedicated interface on the purchasing behavior of customer groups.
Results:
The results showed that a dedicated interface can significantly improve the conversion rate(by 46% in the analyzed group) and average order value (11%).
Conclusion:
These findings confirm that tailored UI variants can positively influence customer behavior in e-shops by increasing key performance indicators.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The research on the impact of customized user interfaces in e-commerce can provide valuable insights for startups looking to improve performance indicators and customer behavior.
https://www.sciencedirect.com/science/article/pii/S0950584925000205,Why and how do organizations create user-led open source consortia? A systematic literature review,Elçin=Yenişen Yavuz: elcin.yenisen@fau.de; Dirk=Riehle: dirk@riehle.org,"Abstract
Context
User-led open source (OS) consortia (foundations) consist of organizations from industries beyond the software industry collaborating to create open-source software solutions for their internal processes. Initially pioneered by higher education organizations in the 2000s, this concept has gained traction in recent years across various industries.
Objective
This study has two research objectives. The first objective is to provide an overview of the current state of the art in this field by identifying previously studied topics and gathering examples from different industries. The second objective is to understand the structure of user-led OS consortia and the motivations of organizations for participating in such consortia.
Method
To gain a comprehensive understanding of this phenomenon, we conducted a systematic literature review, covering the years 2000 to 2023. Furthermore, we performed thematic analysis on 43 selected studies to identify and examine the key characteristics, ecosystems, and the benefits organizations gain from involvement in user-led OS consortia.
Results
We identified 43 unique papers on user-led OS consortia and provided details on 14 sample user-led OS consortia projects. We defined 19 characteristics of user-led OS consortia and 16 benefits for organizations’ involvement. Additionally, we outlined the key actors and their roles in user-led OS consortia.
Conclusion
We provided an overview of the current state of the art in this field. We identified the structure of user-led OS consortia and the organizations’ motivations for participating in such consortia.",May 2025,"Open source foundations, User-led open source consortia, Collaborative software development, Open-source software projects, User-driven open-source software development, Community-source software development, Coopetition, SLR, Systematic literature review",Information and Software Technology,2025-03-21T00:00:00,6.0,"The study on user-led open source consortia can offer insights for startups interested in collaborating with other industries to create open-source solutions, but the practical implications may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584925000175,Classification and challenges of non-functional requirements in ML-enabled systems: A systematic literature review,Fabio=Palomba: fpalomba@unisa.it; Vincenzo=De Martino: vdemartino@unisa.it,"Abstract
Context:
Machine learning (ML) is nowadays so pervasive and diffused that virtually no application can avoid its use. Nonetheless, its enormous potential is often tempered by the need to manage non-functional requirements (NFRs) and navigate pressing, contrasting trade-offs.
Objective:
In this respect, we notice a lack of systematic synthesis of challenges explicitly tied to achieving and managing NFRs in ML-enabled systems. Such a synthesis may not only provide a comprehensive summary of the state of the art but also drive further research on the analysis, management, and optimization of NFRS of ML-enabled systems.
Method:
In this paper, we propose a systematic literature review targeting two key aspects such as (1) the classification of the NFRs investigated so far, and (2) the challenges associated with achieving and managing NFRs in ML-enabled systems during model development Through the combination of well-established guidelines for conducting systematic literature reviews and additional search criteria, we survey a total amount of 130 research articles.
Results:
Our findings report that current research identified 31 different NFRs, which can be grouped into six main classes. We also compiled a catalog of 26 software engineering challenges, emphasizing the need for further research to systematically address, prioritize, and balance NFRs in ML-enabled systems.
Conclusion:
We conclude our work by distilling implications and a future outlook on the topic.",May 2025,"Software engineering for artificial intelligence, Non-functional requirements, Systematic literature reviews",Information and Software Technology,2025-03-21T00:00:00,7.0,"The systematic review on managing non-functional requirements in ML-enabled systems can provide valuable guidance for startups incorporating machine learning in their products, enhancing their understanding of challenges and trade-offs."
https://www.sciencedirect.com/science/article/pii/S0950584925000163,Mining software repositories for software architecture — A systematic mapping study,Ivano=Malavolta: i.malavolta@vu.nl,"Abstract
Context:
A growing number of researchers are investigating how Mining Software Repositories (MSR) approaches can support software architecture activities, such as architecture recovery, tactics identification, architectural smell detection, and others. However, as of today, it is difficult to have a clear view of existing research on MSR for software architecture.
Objectives:
The objective of this study is to identify, classify, and summarize the state-of-the-art MSR approaches applied to software architecture (MSR4SA).
Methods:
This study is designed according to the 
systematic mapping study
 research method. Specifically, out of 2442 potentially relevant studies, we systematically identify 151 primary studies where MSR approaches are applied to perform software architecture activities. Then, we rigorously extract relevant data from each primary study and synthesize the obtained results to produce a clear map of reasons for adopting MSR approaches to support architecting activities, used data sources, applied MSR techniques, and captured architectural information.
Results:
The major reasons to adopt MSR4SA techniques are about addressing industrial concerns like 
achieving quality attributes
 and 
minimizing practitioners’ efforts
. Most MSR4SA studies support architectural analysis, while architectural synthesis and evaluation are not commonly supported in MSR4SA studies. The most frequently mined data sources are 
source code repositories
 and 
issue trackers
, which are also commonly mined together. Most of the MSR4SA studies apply more than one mining technique, where the most common MSR techniques are: (
source code analysis
, 
model analysis
, 
statistical analysis
), (
machine learning
, 
NLP
). 
Architectural quality issues
 and 
components
 are the mostly mined type of information.
Conclusion:
Our results give a solid foundation for researchers and practitioners towards future research and applications of MSR approaches for software architecture.",May 2025,"Mining software repositories, Software architecture, Empirical research",Information and Software Technology,2025-03-21T00:00:00,8.0,"The mapping study on mining software repositories for software architecture can offer startups valuable insights into leveraging MSR approaches to support software architecture activities, aiding in improving software quality and minimizing efforts."
https://www.sciencedirect.com/science/article/pii/S0950584925000151,Beyond the lab: An in-depth analysis of real-world practices in government-to-citizen software user documentation,Francesco=Sovrano: francesco.sovrano@uzh.ch; Sandro=Vonlanthen: sandro.vonlanthen@uzh.ch; Alberto=Bacchelli: alberto.bacchelli@uzh.ch,"Abstract
Context:
Governments, including Switzerland through its 
Digital Switzerland Strategy
, are using new technologies to improve public services. However, unclear user guides often lead people to prefer expensive help desk services. Current research on software documentation is limited by small-scale surveys that do not reflect real-world challenges. This paper addresses these gaps by examining the limitations of user guides in a more practical context.
Objective:
Building on the identified need for a more comprehensive understanding of user documentation in real-world applications, this study aims to critically analyse user documentation in government-to-citizen (G2C) interactions within Switzerland. We intend to identify both common and critical issues in existing documentation to direct future research towards substantial improvements. By doing so, this research will contribute to the development of more effective user guides, ultimately improving the digital experience for citizens and reducing reliance on costly help desk support.
Methods:
Our research methodology involved a thorough analysis of user documentation in German-speaking Swiss cantons. We began with around 5’000 links from official cantonal websites and narrowed it down to nearly 600 user guides relevant to G2C applications. The study progressed in phases: we first assessed the content to identify real-world documentation characteristics, then compared these with common issues from academic research to pinpoint frequent problems. Finally, we analysed the data to identify overarching trends in the documentation characteristics and issues.
Results:
Our analyses, which linked guide features to documentation issues, uncovered prevalent real-world issue trends, characterized by significant statistical correlations (
p
<
.
05
) with the socioeconomic status of the cantons, such as their wealth and population size.
Conclusions:
Identifying these trends will help researchers and practitioners concentrate on the most common and critical issues encountered in practice. This, in turn, holds the potential to drive the development of more effective technology for documenting software. 
Data and Materials:
 
https://doi.org/10.5281/zenodo.10592871",May 2025,"User documentation, Digital transformation, Digital switzerland strategy, Data analysis",Information and Software Technology,2025-03-21T00:00:00,9.0,"The critical analysis of user documentation in government-to-citizen interactions within Switzerland can be highly beneficial for startups aiming to enhance user guides and digital experiences, potentially reducing reliance on costly help desk support."
https://www.sciencedirect.com/science/article/pii/S095058492500014X,A more accurate bug localization technique for bugs with multiple buggy code files,Hui=Xu: lyraxv@nuaa.edu.cn; Zhaodan=Wang: wangzhaodan@nuaa.edu.cn; Weiqin=Zou: weiqin@nuaa.edu.cn,"Abstract
Context:
Bug localization is a key step in bug fixing. Despite considerable progress, existing bug localization techniques still perform unsatisfactorily in situations where the complete fix to a bug involves touching multiple buggy code files. That is, for such bugs, those techniques tend to locate correctly only one or at least not all buggy code files, leaving other buggy code files undetected.
Objective:
This study aims to improve bug localization in cases where resolving a bug requires modifications to multiple buggy code files by proposing HitMore to rank more truly buggy files higher in the recommendation list.
Method:
The basic idea of HitMore is to attempt to retrieve a subset of truly buggy code files first, then use these files to retrieve other buggy code files based on code relation analysis. For the first part, we designed three kinds of domain-specific features to build a machine-learning model to identify the truly buggy code file subset. For the second part, we make use of three types of code relations between the code base and the buggy file subset to better retrieve the remaining truly buggy code files.
Results:
The experiments on six widely open-source projects show that: Our technique is effective in identifying the subset of truly buggy code files, with a weighted prediction F1-Score of 86.1%–92.1%. By leveraging the code relations to the retrieved subset and the code base, our HitMore could retrieve all truly buggy code files for 29.31%–69.56% of bugs across six projects. For multiple-buggy-code-file bugs, HitMore could completely localize such bugs by up to 15.38%, 19.36%, and 11.86% more than three representative IRBL baselines across six projects.
Conclusion:
The experimental results demonstrate the potential of HitMore in reducing developers’ burden of locating and further fixing relatively complex bugs such as those with multiple buggy code files in practice.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The study addresses a practical and significant issue in bug localization for software development, providing a novel HitMore technique that shows promising results in improving bug localization for multiple-buggy-code-file bugs, which can reduce developers' burden and enhance bug-fixing efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584925000102,Test smell: A parasitic energy consumer in software testing,Iftekhar=Ahmed: iftekha@uci.edu; Md Rakib Hossain=Misu: mdrh@uci.edu; Jiawei=Li: jiawl28@uci.edu; Adithya=Bhattiprolu: abhattip@uci.edu; Yang=Liu: yangl73@uci.edu; Eduardo Santana=de Almeida: eduardo.almeida@ufba.br,"Abstract
Context:
Traditionally, energy efficiency research has focused on reducing energy consumption at the hardware level and, more recently, in the design and coding phases of the software development life cycle. However, software testing’s impact on energy consumption did not receive attention from the research community. Specifically, how test code design quality and test smell (e.g., sub-optimal design and bad practices in test code) impact energy consumption has not been investigated yet.
Objective:
This study aims to examine open-source software projects to analyze the association between test smell and its effects on energy consumption in software testing.
Methods:
We conducted a mixed-method empirical analysis from two perspectives; software (data mining in 12 Apache projects) and developers’ views (a survey of 62 software practitioners).
Results:
Our findings show that: (1) test smell is associated with energy consumption in software testing. Specifically, the smelly part of a test case consumes more energy compared to the non-smelly part. (2) certain test smells are more energy-hungry than others, (3) refactored test cases tend to consume less energy than their smelly counterparts, and (4) most developers (45
%
 of the survey respondents) lack knowledge about test smells’ impact on energy consumption.
Conclusion:
Based on the results, we emphasize raising developers awareness regarding the impact of test smells on energy consumption. Additionally we present several observations that can direct future research and developments.",May 2025,"Test smell, Energy efficiency, Test smell refactoring, Sustainable software engineering, Green software engineering",Information and Software Technology,2025-03-21T00:00:00,7.0,"The research sheds light on the impact of test smells on energy consumption in software testing, providing valuable insights for developers to optimize test code design quality. The findings can potentially lead to more energy-efficient software testing practices and raise awareness among developers."
https://www.sciencedirect.com/science/article/pii/S0950584925000242,Production and test bug report classification based on transfer learning,Eunseok=Lee: leees@skku.edu; Misoo=Kim: misoo.kim@jnu.ac.kr; Youngkyoung=Kim: agness66@skku.edu,"Abstract
Context:
Recent studies indicate that the classification of production and test bug reports can substantially enhance the accuracy of performance evaluation and the effectiveness of information retrieval–based bug localization (IRBL) for software reliability.
Objective:
However, manually classifying these bug reports is time-consuming for developers. This study introduces a production and test bug report classification (ProTeC) framework for automatically classifying these reports.
Methods:
The framework’s novelty lies in leveraging a set of production- and test-source files and employing transfer learning to address the issue of insufficient and sparse bug reports in machine-learning applications. The ProTeC framework trains and fine-tunes a source file classifier to develop a bug report classifier by transferring production-test distinguishing knowledge.
Results:
To validate the effectiveness and general practicality of ProTeC, we conducted large-scale experiments using 2,522 bug reports across 12 machine/deep learning model variations to train an automatic classifier. Our results, on average, demonstrate that ProTeC’s macro F1-score is 28.6% higher than that of a bug report-based classifier, and it can improve the mean average precision of IRBL by 17.6%.
Conclusion:
These positive trends were observed in most model variations, indicating that ProTeC consistently performs well in classifying bug reports regardless of the model used, thereby improving IRBL performance.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The ProTeC framework introduces an innovative approach to automatically classify production and test bug reports, which can significantly enhance bug localization performance. The results demonstrate the practicality and effectiveness of ProTeC in improving bug report classification for software reliability."
https://www.sciencedirect.com/science/article/pii/S0950584925000199,Process mining for agile software process assessment and improvement,Katiane Oliveira Alpes=da Silva: koas@cin.ufpe.br; Ricardo Massa Ferreira=Lima: rmfl@cin.ufpe.br; Vanderson Botelho=da Silva: vanderson.silva@serpro.gov.br,"Abstract
Context:
Agile software processes, designed for flexibility and continuous improvement, pose challenges in extracting actionable insights from event logs due to their inherent unstructured nature.
Objective:
The study evaluates whether existing process mining techniques can effectively uncover reliable and insightful information on software development processes adopting agile methodologies.
Method:
The work uses various algorithms to analyze procedural flows and business rules within an event log containing data from 3,418 agile software development projects at a company with over 1,500 employees. By categorizing processes according to project size, our analysis aimed to determine the kind of insights these algorithms could reveal. We specifically focused on algorithms that produced high-quality insights for a deeper examination of aspects like effort rate, frequency of activities, and relationships between activities. Subsequently, technical and managerial staff reviewed the results to assess the quality and relevance of the insights generated. Validation involved a semi-structured interview with managers and technicians to ensure the relevance and applicability of the findings.
Results:
The analysis demonstrates the efficacy of declarative business process techniques in extracting actionable insights from agile development teams’ data. Such techniques accurately capture the daily routines and documented processes of the teams. High-performing teams typically followed fewer rules, had less job rotation, involved fewer individuals, and engaged in a more limited range of activities. Domain experts and team managers found these insights to be coherent and potentially valuable for enhancing the performance of software development processes.
Conclusions:
Declarative modeling is particularly adept at revealing the patterns of flexible software development workflows, presenting initial support for teams, managers, and decision-makers through both descriptive and prescriptive analysis.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The study evaluates process mining techniques in agile software development processes, uncovering valuable insights for improving software development workflows. The findings contribute to enhancing performance and flexibility in agile projects, although the impact may vary based on project size and team dynamics."
https://www.sciencedirect.com/science/article/pii/S0950584925000187,Re-evaluating metamorphic testing of chess engines: A replication study,Mathieu=Acher: mathieu.acher@irisa.fr,"Abstract
Context:
This study aims to confirm, replicate and extend the findings of a previous article entitled 
”Metamorphic Testing of Chess Engines”
 that reported inconsistencies in the analyses provided by 
Stockfish
, the most widely used chess engine, for transformed chess positions that are fundamentally identical. Initial findings, under conditions strictly identical to those of the original study, corroborate the reported inconsistencies.
Objective:
However, the original article considers a specific dataset (including randomly generated chess positions, end-games, or checkmate problems) and very low analysis depth (10 plies,
1
 corresponding to 5 moves). These decisions pose threats that limit generalizability of the results, but also their practical usefulness both for chess players and maintainers of Stockfish. Thus, we replicate the original study.
Methods:
We consider this time (1) positions derived from actual chess games, (2) analyses at appropriate and larger depths, and (3) different versions of Stockfish. We conduct novel experiments on thousands of positions, employing significantly deeper searches.
Results:
The replication results show that the Stockfish chess engines demonstrate significantly greater consistency in its evaluations. The metamorphic relations are not as effective as in the original article, especially on realistic chess positions. We also demonstrate that, for any given position, there exists a depth threshold beyond which further increases in depth do not result in any evaluation differences for the studied metamorphic relations. We perform an in-depth analysis to identify and clarify the implementation reasons behind Stockfish’s inconsistencies when dealing with transformed positions.
Conclusion:
A first concrete result is thus that metamorphic testing of chess engines is not yet an effective technique for finding faults of Stockfish. Another result is the lessons learned through this replication effort: metamorphic relations must be verified in the context of the domain’s specificities; without such contextual validation, they may lead to misleading or irrelevant conclusions; changes in parameters and input dataset can drastically alter the effectiveness of a testing method.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The replication study on metamorphic testing of chess engines provides insights on the limitations and effectiveness of the technique. While the findings contribute to understanding the evaluation consistency of Stockfish, the practical implications for chess players and engine maintainers may be limited due to specific experimental conditions and results."
https://www.sciencedirect.com/science/article/pii/S0950584925000229,BinOpLeR: Optimization level recovery from binaries based on rich semantic instruction image and weighted voting,Guimin=Zhang: zh.guimin@163.com,"Abstract
Context:
Compiler toolchain differences result in binary code diversity, wherein the impacts of different optimization levels on binary code severely constrains the performance improvement of software security detection tasks such as malware detection, software copyright protection, and vulnerability homology detection. However, binaries compiled with different optimization levels often contain numerous identical or similar code fragments, posing severe challenges to recovering the optimization levels from binaries.
Objective:
The existing optimization level detection methods based on statistical features have poor generalization capabilities, and those based on automated learning have low detection accuracy due to using coarse-grained instruction normalization. To improve accuracy and generalization capabilities, this paper proposes BinOpLeR, a binary optimization level recovery method based on rich semantic instruction images and weighted voting.
Method:
In this paper, we perform fine-grained normalization on disassembly instructions to retain the elements that reflect instruction semantics and code execution characteristics, and utilize the mappings from the ASCII code values of assembly codes to pixel grayscale values to convert functions into grayscale images. Then, a balanced dataset is constructed using the grayscale images of functions to train a convolutional neural network model with adaptive pooling to capture optimization level-related features. Finally, a weighted voting scheme that incorporates prediction probabilities and function lengths is innovatively introduced to infer the optimization levels of binaries.
Results:
We evaluate the performance of BinOpLeR on the public dataset of ARM and MIPS binaries using precision, accuracy, recall and F1 score. The results show that BinOpLeR outperforms the comparison methods in prediction performance.
Conclusion:
The findings indicate that: BinOpLeR effectively improves the accuracy of the optimization levels recovery from binaries. It exhibits stable performance across different compiler versions. The granularity and normalization significantly influence feature extraction, and function lengths along with prediction probabilities are crucial factors in inferring the optimization level of binaries.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposal of BinOpLeR, a method for binary optimization level recovery using rich semantic instruction images and weighted voting, shows promising results in outperforming comparison methods. This could have a significant impact on software security tasks for startups."
https://www.sciencedirect.com/science/article/pii/S0950584925000370,Different and similar perceptions of communication among software developers,Martin=Obaidi: martin.obaidi@inf.uni-hannover.de; Jil=Klünder: jil.kluender@inf.uni-hannover.de; Marc=Herrmann: marc.herrmann@inf.uni-hannover.de,"Abstract
Context:
Software development is a collaborative task involving different persons. Development team members are often diverse in regard to several aspects, including experience, (soft) skills, and communication habits. Different preferences in what adequate communication looks like influence how communication is perceived and interpreted by team members.
Objective:
In this paper, we investigate differences and similarities in how software developers with varying levels of experience and skills perceive statements from exemplary software project communication.
Methods:
By applying hierarchical cluster analysis on the perception data of 94 software developers, we aim to find groups of developers sharing similar perceptions towards statements from software project communication, and to identify factors that influence this perception.
Results:
We contribute the following key findings: (1) We statistically identify two groups of software developers whose perceptions differ significantly for about 65% of statements from software project communication; (2) For a logistic regression model, five polarizing statements suffice to assign each participant to their group; (3) Although there is a significant difference in the communication perception, there are no demographic characteristics that differ notably across the two groups.
Conclusion:
From our results, we conclude that different perceptions of software project communication during collaboration within development teams are a potential risk for the teams’ mood and the project success. We outline how our results can serve use cases like the application of sentiment analysis in software engineering and mindful communication in software teams in general.",May 2025,"Perception, Software developer, Software project, Development team, Social aspects, Personality, Human values, Exploratory data analysis, Cluster analysis",Information and Software Technology,2025-03-21T00:00:00,5.0,"Investigating how software developers perceive communication in development teams, while interesting, may not have a direct practical impact on early-stage ventures or startups in terms of improving their operations or outcomes."
https://www.sciencedirect.com/science/article/pii/S0950584925000382,Assessing and improving syntactic adversarial robustness of pre-trained models for code translation,Xiang=Chen: xchencs@ntu.edu.cn; Yu=Zhou: zhouyu@nuaa.edu.cn; Guang=Yang: yang.guang@nuaa.edu.cn; Xiangyu=Zhang: zhangx1angyu@nuaa.edu.cn; Tingting=Han: t.han@bbk.ac.uk; Taolue=Chen: t.chen@bbk.ac.uk,"Abstract
Context:
Pre-trained models (PTMs) have demonstrated significant potential in automatic code translation. However, the vulnerability of these models in translation tasks, particularly in terms of syntax, has not been extensively investigated.
Objective:
To fill this gap, our study aims to propose a novel approach 
CoTR
 to assess and improve the syntactic adversarial robustness of PTMs in code translation.
Methods:
CoTR
 consists of two components: 
CoTR-A
 and 
CoTR-D
. 
CoTR-A
 generates adversarial examples by transforming programs, while 
CoTR-D
 proposes a semantic distance-based sampling data augmentation method and adversarial training method to improve the model’s robustness and generalization capabilities. The Pass@1 metric is used by 
CoTR
 to assess the performance of PTMs, which is more suitable for code translation tasks and offers a more precise evaluation in real-world scenarios.
Results:
The effectiveness of 
CoTR
 is evaluated through experiments on real-world Java
↔
Python datasets. The results demonstrate that 
CoTR-A
 can significantly reduce the performance of existing PTMs, while 
CoTR-D
 effectively improves the robustness of PTMs.
Conclusion:
Our study identifies the limitations of current PTMs, including large language models, in code translation tasks. It highlights the potential of 
CoTR
 as an effective solution to enhance the robustness of PTMs for code translation tasks.",May 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The study focusing on improving the syntactic adversarial robustness of pre-trained models in code translation tasks through CoTR offers a potential solution to enhance the performance of PTMs. This could be beneficial for startups dealing with code translation tasks.
https://www.sciencedirect.com/science/article/pii/S0950584925000217,"Exploring the means to measure explainability: Metrics, heuristics and questionnaires",Martin=Obaidi: martin.obaidi@inf.uni-hannover.de; Hannah=Deters: hannah.deters@inf.uni-hannover.de; Jakob=Droste: jakob.droste@inf.uni-hannover.de; Kurt=Schneider: kurt.schneider@inf.uni-hannover.de,"Abstract
Context:
As the complexity of modern software is steadily growing, these systems become increasingly difficult to understand for their stakeholders. At the same time, opaque and artificially intelligent systems permeate a growing number of safety-critical areas, such as medicine and finance. As a result, explainability is becoming more important as a software quality aspect and non-functional requirement.
Objective:
Contemporary research has mainly focused on making artificial intelligence and its decision-making processes more understandable. However, explainability has also gained traction in recent requirements engineering research. This work aims to contribute to that body of research by providing a quality model for explainability as a software quality aspect. Quality models provide means and measures to specify and evaluate quality requirements.
Method:
In order to design a user-centered quality model for explainability, we conducted a literature review.
Results:
We identified ten fundamental aspects of explainability. Furthermore, we aggregated criteria and metrics to measure them as well as alternative means of evaluation in the form of heuristics and questionnaires.
Conclusion:
Our quality model and the related means of evaluation enable software engineers to develop and validate explainable systems in accordance with their explainability goals and intentions. This is achieved by offering a view from different angles at fundamental aspects of explainability and the related development goals. Thus, we provide a foundation that improves the management and verification of explainability requirements.",May 2025,"Explainability, Requirements engineering, Quality models, Metrics, Heuristics, Literature studies",Information and Software Technology,2025-03-21T00:00:00,6.0,"The quality model for explainability in software systems, while important, may have a more indirect impact on early-stage ventures compared to other abstracts that directly address software security tasks or code optimization."
https://www.sciencedirect.com/science/article/pii/S0950584925000369,Formal requirements engineering and large language models: A two-way roadmap,Paola=Spoletini: pspoleti@kennesaw.edu; Alessio=Ferrari: alessio.ferrari@isti.cnr.it,"Abstract
Context:
Large Language Models (LLMs) have made remarkable advancements in emulating human linguistic capabilities, showing potential also in executing various requirements engineering (RE) tasks. However, despite their generally good performance, the adoption of LLM-generated solutions and artefacts prompts concerns about their correctness, fairness, and trustworthiness.
Objective:
This paper aims to address the concerns associated with the use of LLMs in RE activities. Specifically, it seeks to develop a roadmap that leverages formal methods (FMs) to provide guarantees of correctness, fairness, and trustworthiness when LLMs are utilised in RE. Symmetrically, it aims to explore how LLMs can be employed to make FMs more accessible.
Methods:
We use two sets of examples to show the current limits of FMs when used in software development and of LLMs when used for RE tasks. The highlighted limitations are addressed by proposing two roadmaps grounded in the current literature and technologies.
Results:
The proposed examples show the potential and limits of FMs in supporting software development and of LLMs when used for RE tasks. The initial investigation into how these limitations can be overcome has been concretised in two detailed roadmaps for the RE and, more largely, the software engineering community.
Conclusion:
The proposed roadmaps offer a promising approach to address the concerns of correctness, fairness, and trustworthiness associated with the use of LLMs in RE tasks through the use of FMs and to enhance the accessibility of FMs by utilising LLMs.",May 2025,"Requirements engineering, Formal methods, Large language models, LLMs, Natural language processing, NLP, NLP4RE, Prompt engineering, Prompt requirements engineering",Information and Software Technology,2025-03-21T00:00:00,8.0,"This abstract addresses important concerns in the field of requirements engineering and software development, providing a roadmap for leveraging formal methods to ensure correctness, fairness, and trustworthiness in LLM-generated solutions. The practical implications and impact on early-stage ventures are significant."
https://www.sciencedirect.com/science/article/pii/S0950584924002532,Concept definition review: A method for studying terminology in software engineering,Sabine=Molenaar: s.molenaar@uu.nl,"Abstract
Context:
In scientific domains, definitions provide a precise description of fundamental concepts. Although the debate within the philosophy of computer science regarding the scientific nature of software engineering (SE) is inconclusive, SE researchers have laid down important steps toward treating SE as a scientific paradigm.
Objective:
We aim to support precise and effective communication among SE researchers and practitioners by providing a systematic process for the identification and analysis of definitions, in order to support the selection of a suitable definition for a certain use case.
Method:
Inspired by methods for the planning and execution of systematic literature reviews, we construct a method that is specific for concept definition reviews (CDRs). These reviews are performed whenever a research team wishes to obtain a detailed understanding of an SE concept that may have been characterized by dozens, if not hundreds, definitions.
Results:
We built our method via two 
design science
 iterations. The first one focused on the concept 
feature
 and resulted in the definitive version of the CDR method presented in this paper. We then applied the revised method to two, related concepts: 
quality requirement
 and 
non-functional requirement
. Besides showing the applicability of the CDR method, our results include findings regarding the characteristics and evolution of the terms.
Conclusions:
The two applications of the CDR method highlight the existence and citation of hundreds of definitions, many of which are nearly (but not exactly) identical. We put forward our method for other researchers to shed light on the key terminology in other sub-fields of SE.",April 2025,"Literature review, Research method, Concept definition, Software engineering, Requirements engineering",Information and Software Technology,2025-03-21T00:00:00,4.0,"While the systematic process for identifying and analyzing definitions in software engineering is valuable for SE researchers and practitioners, the practical impact on early-stage ventures and startups may not be as immediate or significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924002647,MT-Nod: Metamorphic testing for detecting non-optimal decisions of autonomous driving systems in interactive scenarios,Tongtong=Bai: btt070619@163.com; Song=Huang: huangsong@aeu.edu.cn; Xingya=Wang: xingyawang@outlook.com; Zhen=Yang: yangzhen@aeu.edu.cn; Yang=Wang: wangy621@aeu.edu.cn,"Abstract
Context:
Autonomous driving technology advances into daily life, with expectations for autonomous driving systems (ADSs) to make optimal, human-like decisions. However, ADSs often exhibit “unintelligent” behaviors like inefficient path choices, significantly impacting travel efficiency and potentially causing delays. Therefore, testing the decision optimality of ADSs is critically urgent. However, the testing process faces a significant “testing oracle” problem, and current methods overlook behavior interactions, which do not reflect real-world traffic scenarios.
Objective:
To assess the performance and reliability of ADSs in optimal decision-making, mitigate test oracle problems, and detect non-optimal decisions without calculating the optimal path.
Method:
This paper proposes a metamorphic testing method for optimal decision-making in autonomous driving under interactive scenarios, MT-Nod. Our method introduces a novel metamorphic relation to evaluate the optimality of path directions, along with a follow-up scenario generation method. The scenario generation method includes mutation points selection based on key behaviors, scenario mutation based on behavioral interactions, and road accessibility assessment, to generate scenarios with dynamic interactions. Additionally, a scenario scheduling strategy is designed to prioritize and schedule scenarios based on the priority of mutation points.
Results:
We evaluate MT-Nod extensively on the advanced Apollo ADS. Across four source scenarios, it generates 69.3 non-optimal decision scenarios (NoDSs), classified into eight types. Compared to baselines, MT-Nod efficiently produces and detects a greater variety and quantity of NoDSs.
Conclusion:
The proposed method for optimal decision testing under interactive scenarios, MT-Nod, effectively detects non-optimal decisions of ADSs. These “unintelligent” behaviors are crucial for enhancing the performance and reliability of ADSs.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposed metamorphic testing method for optimal decision-making in autonomous driving systems addresses a critical issue in the field, showing promising results in enhancing the performance and reliability of ADSs. The impact on European early-stage ventures, especially in the tech and automotive sectors, is substantial."
https://www.sciencedirect.com/science/article/pii/S0950584924002659,Boosting mutation-based fault localization by effectively generating Higher-Order Mutants,Shumei=Wu: wsm@mail.buct.edu.cn; Zheng=Li: lizheng@mail.buct.edu.cn; Yong=Liu: lyong@mail.buct.edu.cn,"Abstract
Context:
Fault Localization (FL) is an important and tedious phase of software debugging. Among various FL techniques, Mutation-Based Fault Localization (MBFL) demonstrates promising FL accuracy utilizing impact information of statements provided by First-Order-Mutants (FOMs). Despite its success in Single-Fault Scenarios (SFSs), it fails to achieve satisfactory performance in Multiple-Fault Scenarios (MFSs). Higher-Order-Mutants (HOMs) provide a solution for MFSs. However, existing work on HOM generation is inadequate and ignores the correlation among faults in MFSs.
Objective:
In this article, we systematically analyze three relationships among single-faults in MFSs, and further propose three HOM generation methods (i.e., SFClu, SFDis, and SFDen) to simulate different multiple-faults and improve the effectiveness of MBFL in MFSs.
Method:
We investigate the multiple-fault composition on real-world 393 faulty programs from Defects4J, and then apply our methods to generate HOMs for FL. Specifically, SFClu focuses on generating appropriate HOMs for Multi-Single-Source Fault (MSSF) scenarios, where each single-fault is responsible for different observed failures. SFDis is well-suited for Multi-Coupled-Source Fault (MCSF) scenarios where at least two single-faults can interact with each other, leading to certain failures either being observable or masked. SFDen aims to generate suitable HOMs for Single-Coupled-Source Fault (SCSF) scenarios with multiple single-faults that occur within a statement.
Results:
(1) The proportion of MFSs is as high as 63.10% in real-world programs, with MSSF, MCSF , and SCSF scenarios accounting for 35.08%, 53.23%, and 11.69%, respectively. (2) Compared to the best-performing mutant generation method Neural-MBFL, SFClu, SFDis, and SFDen can improve the FL performance for MBFL by 36.78%, 49.80%, and 16.36% in 
T
o
p
-1, respectively, outperforming eight established SBFL and MBFL techniques. (3) SFClu, SFDis, and SFDen are more suitable for MSSF, MCSF, and SCSF scenarios, respectively, which aligns with their design intend. (4) Their combination further enhances FL accuracy, achieving up to 85 faults successfully localized and an average improvement of 29.54% in 
T
o
p
-1. Finally, extensive evaluations on SIR with artificial faults and Codeflaws containing student programs demonstrate the generalization of SFClu, the applicability of SFDis on real faults, and the suitability of SFDen for student programs.
Conclusion:
Empirical studies have confirmed the prevalence of MFSs, highlighting the significance of multi-fault localization. Moreover, our proposed three HOM generation methods can further enhance the performance of MBFL with HOMs in MFSs, showing their effectiveness and applicability.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The systematic analysis of fault localization techniques and the proposal of new methods to improve the effectiveness of MBFL in multiple-fault scenarios have practical value for software debugging and development. While the impact on European early-stage ventures is significant, it may not be as immediate as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584924002660,An input-denoising-based defense against stealthy backdoor attacks in large language models for code,Song=Huang: huangsong@aeu.edu.cn,"Abstract
Context:
Large Language Models are becoming integral to software development. They are trained on open data from platforms like GitHub, making them vulnerable to poisoning attacks. Research shows that backdoor attacks with traditional static triggers using fixed code patterns are relatively easy to detect. The novel attack approach uses specific Syntax Tree structures as triggers, offering greater stealthiness while maintaining explicit code structures. This method poses new challenges for backdoor detection.
Objective:
We propose an 
I
nput-
D
 enoising-based defense against stealthy 
B
ackdoor 
A
ttacks with dynamic triggers (
IDBA
) in Large Language Models for Code.
Method:
We overlay a set of malicious code segments onto the code segment with dynamic triggers, convert the output state of the input code into a random walk graph neural network, calculate the expected value of the final state through particle filtering, and thus detect the existence of a backdoor attack.
Results:
Empirical studies are conducted on Codebert, GraphCodebert, and CodeT5 for vulnerability and code clone detection tasks. Our results show that 
IDBA
 achieves an average detection rate of 73.75% and 68.12% for vulnerability and code clone detection tasks, respectively.
Conclusion:
Detecting backdoor attacks using 
IDBA
 on code models allows for the early identification of potential backdoor threats after model deployment, enhancing the security of code models.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The defense against stealthy backdoor attacks in Large Language Models for code using IDBA is an important contribution to the field. While the practical implications for software security are noteworthy, the direct impact on European early-stage ventures may be more indirect."
https://www.sciencedirect.com/science/article/pii/S0950584925000096,MPCA: Constructing the APTs provenance graphs through multi-perspective confidence and association,Limin=Pan: panlimin2016@gmail.com,"Abstract
The forensic analysis of Advanced Persistent Threats (APTs) attacks is crucial for maintaining cybersecurity. To address the challenges posed by the high complexity and strong concealment of APT attacks, provenance graph based on inter entity dependencies are used for forensic investigation. However, under long-term persistent attacks, entities with semantically consistent behavior patterns become excessively redundant, leading to an explosion of inter entity dependencies and a decrease in forensic efficiency. In addition, the implicit relationships within and between events are not fully represented, and alarm information spreads to neighboring benign events, making it difficult to accurately reconstruct attack scenario. In this paper, we propose an APT attack attribution method MPCA that combines multi-perspective confidence and association. Firstly, by merging parallel branches with semantically consistent behavior patterns in the process connected subgraph, redundant entities and their dependencies are reduced. Secondly, event confidence is estimated to exclude benign events, the association between events and alarms is analyzed to highlight attack events. Experimental results demonstrate that MPCA achieves state-of-the-art performance. MPCA can improve the efficiency of constructing attack scenario graphs, reduce false positive and false negative rates, and demonstrate greater adaptability in attack attribution tasks.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The proposed APT attack attribution method MPCA demonstrates state-of-the-art performance and can improve efficiency in constructing attack scenario graphs, reducing false positives and negatives. This can have a significant impact on early-stage ventures dealing with cybersecurity issues."
https://www.sciencedirect.com/science/article/pii/S0950584925000126,Alleviating class imbalance in Feature Envy prediction: An oversampling technique based on code entity attributes,Zuohua=Ding: zouhuading@hotmail.com; Mingyue=Jiang: mjiang@zstu.edu.cn; Jiamin=Guo: jiaminguo822@163.com; Yangyang=Zhao: yangyangzhao@zstu.edu.cn; Tao=Zheng: z337997332@163.com; Zhifei=Chen: chenzhifei@njust.edu.cn,"Abstract
Context:
Feature Envy is a common code smell that occurs when a method heavily relies on data or functionality from other classes. Detecting Feature Envy is essential for improving software modularity and reducing technical debt. However, real-world datasets often exhibit severe class imbalance, with far fewer Feature Envy instances than non-smelly ones, posing challenges for prediction models. Traditional oversampling techniques attempt to address this issue by relying solely on numerical vectors but often fail to capture the complex relationships between code entities, potentially deviating from the nature of Feature Envy.
Objective:
This study introduces STANDER, a novel oversampling technique based on code entity similarity, designed to handle class imbalance in Feature Envy prediction by generating synthetic samples that better reflect the characteristics of Feature Envy.
Method:
STANDER creates synthetic samples by leveraging multidimensional code entity similarity, incorporating attributes such as dependency relationships, historical changes and code text. It was evaluated on five datasets using five classifiers: Naive Bayes, Logistic Regression, Support Vector Machine, Random Forest, and Decision Tree. Its performance was compared to baseline over-sampling techniques based on precision, recall, F1-score, and Matthews Correlation Coefficient.
Results:
STANDER enhances dataset diversity while maintaining clear boundaries between minority and majority classes, as reflected by higher Nearest Neighbor Diversity and Silhouette Score values. Models balanced with STANDER exhibited significant improvements in predictive performance, particularly in recall, F1-score, and Matthews Correlation Coefficient. Compared to the other oversampling techniques, STANDER demonstrated advantages in handling imbalanced datasets, especially in the Logistic Regression and Decision Tree classifiers. Statistical results confirm significant performance improvements across most models, highlighting its effectiveness and applicability.
Conclusion:
STANDER is an effective solution to alleviate class imbalance problem in Feature Envy detection by generating more representative synthetic samples that improve prediction performance.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"STANDER, a novel oversampling technique for Feature Envy prediction, shows significant improvements in predictive performance, especially in recall, F1-score, and Matthews Correlation Coefficient. This can greatly benefit startups aiming to improve software modularity and reduce technical debt."
https://www.sciencedirect.com/science/article/pii/S0950584925000138,XL-HQL: A HQL query generation method via XLNet and column attention,Rongcun=Wang: rcwang@cumt.edu.cn,"Abstract
Context:
Object-relational mapping (ORM) tools, like Hibernate, are widely used to facilitate the development of database applications by bridging the gap between object-oriented programming (OOP) and relational database management systems (DBMS). These ORM tools simplify the process of mapping OOP objects to relational tables, addressing issues of data inconsistency and performance. However, they also introduce the need to write queries in specific languages, such as Hibernate Query Language (HQL), to manage data interactions within the database.
Objective:
These query languages can be difficult to write and error-prone due to the complexities of accurately mapping object models to relational schema with intricate relationships and inheritance hierarchies. To mitigate this issue, a recent study introduced the task of automated HQL query generation, i.e., automatically generating HQL from program context (target method’s signature, properties, and optional method comments and call context). However, the existing solution, HQLgen, has shown limited performance, with an accuracy of 34.52%.
Method:
In this paper, we propose a novel HQL query generation approach named XL-HQL. XL-HQL aims to address two main challenges in HQL query generation: limited context information and large search space. Specifically, XL-HQL contains a pre-trained model-based encoder, rules defined to reduce search space, and a column-attention-enabled decoder, which is shown to be effective in SQL generation approaches.
Result:
To evaluate the effectiveness of XL-HQL, we designed and conducted experiments on an existing HQL query generation benchmark, which contains 24,118 HQL queries extracted from 3,481 open-source projects. The experimental results show that our approach achieves 66.93% and 64.47% accuracy on mixed and cross-project datasets, respectively, nearly doubling the performance of the state-of-the-art (SOTA) baseline.
Conclusions:
The application of pre-trained models that are suitable for handling long sequences for the HQL query generation task shows great potential. Moreover, the defined rules based on OOP knowledge are effective for reducing search space and improving the performance of the task.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"XL-HQL, a novel approach for HQL query generation, achieves a significant increase in accuracy compared to the state-of-the-art baseline. This can be valuable for startups dealing with database applications and ORM tools, improving query writing efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584925000114,Towards an understanding of requirements management in software ecosystems,Paulo=Malcher: malcher@edu.unirio.br,"Abstract
Context:
Software ecosystems (SECO) have introduced complexity in requirements management due to multiple actors’ collaboration through several organizational boundaries.
Objective:
The main contribution of this article is to improve the understanding of requirements management in SECO. We propose a conceptual model whose concepts, definitions, and relationships are grounded in the literature and the modern software industry’s practices.
Methods:
We applied Design Science to build the conceptual model and conducted a Delphi study with 22 experts to assess it. We performed two rounds and adjusted our model according to the experts’ judgment.
Results:
We reached a conceptual model comprising 43 concepts and their relationships that help to understand requirements management in SECO. Moreover, we provided a glossary with a definition of each concept. This conceptual model can help abstract the complexity of the requirements management in SECO.
Conclusions:
By organizing concepts and relationships in requirements management in SECO, this conceptual model makes it possible to expand the body of knowledge in the area and serves as a basis for new solutions to support requirements management in SECO.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The conceptual model proposed for requirements management in software ecosystems can help abstract complexity, expand knowledge in the area, and provide a basis for new solutions. While valuable, the practical impact on early-stage ventures may be less direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S095058492400257X,Data analytics in software startups: Understanding key concepts and critical challenges,Usman=Rafiq: Usman.Rafiq@unibz.it,"Abstract
Context:
The continuous proliferation of data nowadays has inspired companies to make data-informed decisions. Despite the acknowledged benefits of analytics, there is a persistent question about how companies, especially software startup companies with distinguishing characteristics, can effectively create value from it. In the startup context, analytics refers to the use of startup data and insights to inform strategies and tactics across startup business, product, team, sales, and marketing dimensions.
Objective:
In this study, we aim to bridge the knowledge gap by eliciting an understanding of the analytics that software startup companies hold and identifying critical challenges they face in the realm of analytics.
Method:
We conducted a multiple-case study with eight software startups at different startup stages. In addition to the data collected through semi-structured interviews, we considered other data sources such as analytics dashboards and online data about the startups, including websites and social media platforms. We analyzed the data using thematic analysis.
Results:
Our results firstly revealed a divergent understanding of analytics by software startups, based on which we reported essential characteristics of analytics perceived by them. Then we identified 22 analytics challenges classified into six main themes. The themes encompass data capture and access challenges, data interpretation and bias, communication challenges, cultural challenges, external influences and constraints, and analytics implementation challenges.
Conclusions:
Our findings contribute to a conceptual understanding of analytics in software startups and the identification of critical challenges faced by these startups across different stages. The conceptual understanding lays the foundation for comprehending what constitutes analytics for software startups, while the identification of challenges anticipates critical barriers to the adoption and implementation of analytics. We also provide practical implications to both researchers and practitioners.",April 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The study on analytics challenges faced by software startups provides valuable insights into critical barriers to adoption and implementation of analytics. This can offer practical implications for startups looking to effectively create value from analytics.
https://www.sciencedirect.com/science/article/pii/S0950584924002544,Exploring the impact of feedback on remote SW development teams,Ana Beatriz=Cavalcanti: abcr@cin.ufpe.br,"Abstract
Context
Feedback is essential in the routine of software development teams. It provides information on professionals’ performance, align goals, and manage conflicts. The growing adoption of the remote work model has created new challenges for the effective use of feedback by organizations. Despite the recognized importance of feedback, few studies focused on understanding how feedback practices are currently conducted in remote software development teams.
Objective
This work aims to explore the impact of feedback on software development teams working remotely. In addition, we aim to provide valuable insights on how teams can optimize the outcomes of feedback practices.
Method
We adopted a mixed-method approach to investigate how feedback practices are conducted in remote software development teams. We performed a multivocal literature review to map the benefits, challenges, and good practices mentioned in the literature. Then, we conducted semi-structured interviews with 10 leaders and managers to understand their perceptions about feedback practices. Finally, we surveyed 83 team members to understand their perceptions and feelings about receiving feedback.
Results
We found out that the key benefits of feedback include a boost in individual engagement and team performance. In contrast, common challenges involved in remote feedback are communication gaps due to the adoption of digital channels and difficulty in providing and receiving negative feedback. Finally, our study proposes good practices to improve the feedback outcomes, such as: using multidimensional indicators to evaluate team members, providing a tangible goal-oriented development plan, and adopting continuous feedback follow-up.
Conclusion
We synthesized evidence from multiple sources by adopting three research methods to understand the effects of feedback on remote software development teams. Finally, we provided a set of actionable insights on how to optimize the feedback on remote software development teams.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The study on feedback practices in remote software development teams provides actionable insights that can benefit early-stage ventures and startups by improving team performance and engagement.
https://www.sciencedirect.com/science/article/pii/S0950584924002465,Performance regression testing initiatives: a systematic mapping,Luciana Brasil Rebelo=dos Santos: luciana.rebelo@gssi.it; Érica Ferreira=de Souza: ericasouza@utfpr.edu.br; André Takeshi=Endo: andreendo@ufscar.br; Catia=Trubiani: catia.trubiani@gssi.it; Riccardo=Pinciroli: riccardo.pinciroli@gssi.it; Nandamudi Lankalapalli=Vijaykumar: vijay.nl@inpe.br,"Abstract
Context:
Issues related to the performance of software systems are crucial, as they have the potential to impede the effective utilization of products, compromise user satisfaction, escalate costs, and lead to failures. Performance regression testing has been identified as a prominent research domain, since it aims to prevent anomalies and substantial slowdowns.
Objective:
The objective of this paper is to examine recent approaches proposed in the literature concerning performance regression testing. Our interest lies in contributing insights that offer a forward-looking perspective on what is essential in this promising research domain.
Methods:
We carried out a systematic mapping study with the objective of gathering information on various initiatives related to performance regression testing. Our methodology follows the state-of-the-art guidelines for systematic mappings comprising planning, conducting, and reporting activities, thus obtaining a comprehensive set of selected studies.
Results:
Our selection includes 68 papers, and our analysis focuses on four key research questions, delving into (i) publication trends, (ii) developed approaches, (iii) conducted evaluations, and (iv) challenges. As a result of this investigation, we present a roadmap highlighting research opportunities.
Conclusion:
This flourishing research field entails a broad set of challenges, such as deciding the granularity of tests and the frequency of launching the performance regression process. Consequently, there is still much work to be undertaken to trade-off between the accuracy and the efficiency of capturing complex performance issues across diverse application domains and/or execution environments.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The research on performance regression testing offers valuable insights for software systems, which can be beneficial for startups looking to enhance their product performance and prevent failures."
https://www.sciencedirect.com/science/article/pii/S0950584924002556,Industry 4.0/IIoT Platforms for manufacturing systems — A systematic review contrasting the scientific and the industrial side,Holger=Eichelberger: eichelberger@sse.uni-hildesheim.de,"Abstract
Context:
IIoT, Industry 4.0 or CPPS software platforms are cornerstones of smart manufacturing production systems. Such platforms integrate machines, IIoT and edge devices, realize distributed (management) functionality and provide the basis for user-defined IIoT applications. Individual instances in research and industrial practice do share commonalities while they also differ significantly.
Objective:
A detailed overview of the platform landscape is fundamental for innovative research. However, actual surveys and literature reviews concentrate on specific aspects and usually focus only on the research works, neglecting specific aspects of the industrial use of IIoT platforms. We aim at a systematic overview of the functionalities and approaches of scientific and industrial IIoT platforms along 16 analysis dimensions and thereby exposing gaps between the focuses of research on IIoT platforms and actual industrial IIoT platforms in use. By doing so we are able to highlight future areas of interest to research as well as indicating potentially over-researched areas which are of less interest in actual industrial IIoT platforms.
Method:
We combine a systematic literature review of scientific IIoT platform research with a systematic analysis of industrial IIoT platforms.
Results:
We start off with 1620 research papers plus 70 from snowballing that we systematically filter down to 36 papers (plus 11 added by a SLR update) providing sufficient information for a data extraction, which we analyze along 16 topics to extract actual capabilities and differences of relevant platform approaches. In a second step, we contrast these results with an analysis of 21 industrial platforms.
Conclusion:
Similar approaches, differences and topics for future are exhibited. In comparison with 21 industrial platforms along the same analysis topics, we distill various commonalities, differences, trends and gaps.",March 2025,"0000, 1111",Information and Software Technology,2025-03-21T00:00:00,5.0,"The overview of IIoT platforms in research and industrial use exposes potential gaps and future areas of interest, providing moderate value for early-stage ventures in the manufacturing sector."
https://www.sciencedirect.com/science/article/pii/S0950584924002441,Solutions toCybersecurity Challenges in Secure Vehicle-to-Vehicle Communications: A Multivocal Literature Review.,Naeem=Ullah: Naeemullah72@gmail.com; Siffat Ullah=Khan: siffatullah@uom.edu.pk,"Abstract
Context
Vehicle-to-Vehicle (V2V) technology is evolving rapidly, meeting modern transportation needs and driving economic and technological progress. V2V brings numerous benefits, enabling vehicles to communicate with each other and with infrastructure like Roadside Units (RSUs), which helps minimize collisions, reduce fatalities, and boost road safety for passengers, drivers, and pedestrians alike. Beyond safety, V2V improves traffic management and optimizes routes. However, these advancements also introduce new challenges. Greater reliance on IT makes vehicles more vulnerable to cyber-attacks and increases costs related to system installation and maintenance. This highlights a pressing need to advance V2V technology to enhance overall safety.
Objective
This research focuses on identifying the primary challenges and effective practices within Vehicle-to-Vehicle (V2V) communication.
Method
We conducted a Multivocal Literature Review (MLR) using tailored search strings derived from our research questions. This process adhered to all standard MLR steps, including protocol development, initial and final selection, quality assessment, data extraction, and synthesis.
Results
We have identified a list of 18 challenges in the context of V2V communication. 10 of these challenges were marked as critical challenges based on the criterion of ≥20 % occurrences in both formal and grey literature. We also identified related practices for the identified critical challenges. The identified challenges were further analyzed based on different variables such as publication periods and study strategies.
Conclusion
We recommend that automotive industries should prioritize addressing these challenges to enhance their readiness for secure V2V communication. Our overarching goal is to develop a Cybersecurity Challenges Mitigation Model (CCMM) based on MLR findings and industrial survey outcomes, assisting companies in the automobile sector to assess their readiness for secure V2V communication development.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The study on V2V communication challenges and practices is highly relevant for startups in the automotive industry, offering insights on improving road safety and cybersecurity in their products."
https://www.sciencedirect.com/science/article/pii/S0950584924002453,DeepCNP: An efficient white-box testing of deep neural networks by aligning critical neuron paths,Limin=Pan: panlimin2016@gmail.com; Weiguang=Liu: 3220235389@bit.edu.cn; Senlin=Luo: luosenlin2019@126.com; Zhao=Zhang: zzhao8735@163.com,"Abstract
Context
Erroneous decisions of Deep Neural Networks may pose a significant threat to Deep Learning systems deployed in security-critical domains. The key to testing DNNs is to propose a testing technique to generate test cases that can detect more defects of the models. It has been demonstrated that coverage-guided fuzz testing methods are difficult to detect the correctness defects of model's decision logic. Meanwhile, the neuron activation threshold is set based on experience, which increases the uncertainty of the test even more. In addition, the randomly selected seed mutations are prone to generate a large number of invalid test cases, which has a great impact on the testing efficiency.
Objective
This paper introduces DeepCNP, a method that combines Critical Neuron Paths alignment and dynamic seeds selection strategy, which can comprehensively and efficiently test all the decision paths of DNN and generate as many different classes of test cases as possible to expose misbehaviors of the model and thus finding defects.
Method
DeepCNP utilizes training data to construct decision paths determined by the neuron output distribution, and aligns different decision paths in order to generate test cases. Seeds that are easy to align are dynamically selected based on the decision paths to be tested, and the labeling of seed mutations is specified during the path alignment process, thus improving the efficiency of fuzz testing.
Results
Experimental results show that DeepCNP achieves new state-of-the-art results, pioneering the testing of all decision logics of the model through critical neuron path alignment, which greatly enhances the number of defects found, the efficiency and number of generated test cases.
Conclusion
DeepCNP comprehensively tests the decision logic of DNNs, efficiently generating a large number of test cases of different categories to expose model's misbehaviors and thus finding additional defects.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The DeepCNP method for testing DNNs introduces innovative techniques that can significantly benefit startups in security-critical domains by enhancing testing efficiency and detecting defects.
https://www.sciencedirect.com/science/article/pii/S0950584924002477,Improving bug triage with the bug personalized tossing relationship,Wei=Wei: weiwei961112@163.com; Haojie=Li: lihaojie@qust.edu.cn; Xinshuang=Ren: 1317467738@qq.com; Feng=Jiang: jiangfeng@qust.edu.cn; Xu=Yu: yuxu0532@upc.edu.cn; Xingyu=Gao: gxy9910@gmail.com; Junwei=Du: djwqd@163.com,"Abstract
Background:
In open-source software projects, the main task of bug triage is accurately assigning bugs to appropriate developers. Statistics indicate that about 50% of bugs are reassigned (also called “tossed”) at least once, greatly extending the time for bug fixing. Research studies have shown that combining historical tossing relationships can significantly improve bug triage performance.
Objective:
The current research on utilizing bug tossing relationships can be mainly divided into two categories: (1) During the reassignment phase, only developers with the highest probability of tossing relationships are selected. (2) Use attribute filtering mechanism to filter and match developers. However, these approaches fail to fully consider the matching degree between developers’ abilities and the knowledge required to fix current bugs. We are attempting to propose an approach to address the above problem.
Approach:
We propose an approach to improve bug triage with the Bug Personalized Tossing Relationship (BPTRM). It uses a tossing transition probability matrix derived from historical tossing paths to help recommend suitable developers for solving bug reports.
Result:
Experimental results from various data sets within Eclipse and Mozilla indicate that BPTRM improves average recommendation performance by at least 14.38% compared to different initial assignment approaches. In addition, compared to baselines, BPTRM improves the average accuracy by 14.66% and shortens the average bug tossing length by 16.19%.
Conclusion:
1. The BPTRM approach, combined with personalized bug tossing relationships, precisely matches developers’ abilities and the knowledge required to fix current bugs. 2. This effectively improves the bug triage’s accuracy and shortens the bug tossing’s length.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The research on bug triage performance improvement through personalized tossing relationships can greatly benefit early-stage ventures by enhancing bug fixing efficiency and accuracy.
https://www.sciencedirect.com/science/article/pii/S0950584924002520,Why do software developers like working from the office?,Nurit=Zaidman: zeidman@bgu.ac.il; Dina=Van Dijk: dinav@bgu.ac.il,"Abstract
Context
The inquiry of the optimal number of working days per week for home-based (versus office-based) work, poses a challenge for many organizations within the high-tech sector. Studies in this area tend to overlook the responses and preferences of specific populations, and there is a lack of contextualization in the discussion. Given that software developers' needs have an impact on their performance, turnover, and well-being, it is important to understand their needs in relation to where work should be accomplished. Research that illuminates this topic can lead to different presumptions regarding developers’ preferences for home and/or office work.
Objective
To analyze preferences for home- versus office-based work among Scrum team software developers employed in a multinational organization.
Method
To achieve a broad, global scope and an in-depth understanding of developers’ preferences for work that was office-based or home-based, we used a combination of two data collection methods: a survey administered to 651 employees and in-depth interviews conducted with 35 employees from the same organization.
Results
The results show that the employees preferred to work from home for the majority of weekdays, yet, about 70 % of them preferred to come to the office at least once a week. The main reasons for home-based preference were “no commuting,” and “more productive and concentrated work”, more time for myself, and a relaxed comfortable environment. The reasons for office-based preference were to socialize with colleagues, to engage in work interactions, and to enjoy the ambiance and facilities available at the workplace.
Conclusions
The study illuminates developers' social preferences and their work motivations as related to their need for peer interaction, which contrasts the dominant argument in existing research that portrays developers as having a low need for social interaction. Second, the study depicts a contextual factor, working in Scrum teams, as an explaining variable to the developers’ preferences for office social interaction.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"Understanding software developers' preferences for home vs. office work can provide insights for startup culture, but the practical impact may vary for different ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924002568,Improving seed quality with historical fuzzing results,Yang=Li: chrisly@hdu.edu.cn; Yingpei=Zeng: yzeng@hdu.edu.cn; Xiangpu=Song: songxiangpu@sdu.edu.cn; Shanqing=Guo: guoshanqing@sdu.edu.cn,"Abstract
Context:
Coverage-guided fuzzing (CGF) has achieved great success in discovering software vulnerabilities. The efficiency of CGF highly relies on the quality of the initial seed corpus. Although there have been some works in recent years investigating the initial seed selection, usually only the corpus given by developers or downloaded from the Internet is used to get the initial seed corpus.
Objective:
We assess several existing corpus minimization tools and find that none of them effectively leverage information contained in historical fuzzing results. The historical fuzzing results may come from previous fuzz testing or the emerging continuous fuzzing integration in the software development cycle. Therefore, we want to utilize history fuzzing results to generate a high-quality initial corpus to enhance the fuzzing performance. Besides, the size of the initial corpus will affect the fuzzing efficiency, so using a minimization tool to extract valuable seeds from historical results is essential.
Method:
We propose to use historical fuzzing results to help construct the initial seed corpus and further develop a corpus minimization tool named MCM (multiple corpora minimization), which can analyze multiple fuzzing results and use information including edge appearance frequency to help seed selection.
Results:
We implement a prototype of MCM and evaluate it on 10 open-source programs. Our experiments show that by using historical fuzzing results to expand the size of the initial seed corpus even a small number, e.g., from 20 to only 100, the branch coverage improves up to 14%. Meanwhile, MCM can achieve higher code coverage than existing corpus minimization tools, including AFL-CMIN and OPTIMIN.
Conclusion:
Our study shows using historical results to generate a high-quality initial corpus is practical and can effectively improve the fuzzing performance.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,Utilizing historical fuzzing results to enhance fuzzing performance can be valuable for cybersecurity startups focused on developing secure software products.
https://www.sciencedirect.com/science/article/pii/S0950584924002581,Energy attack method for adaptive multi-exit neural networks,Dongfang=Du: 21212010012@m.fudan.edu.cn; Chaofeng=Sha: cfsha@fudan.edu.cn; Xin=Peng: pengxin@fudan.edu.cn,"Abstract
Context:
Adaptive Multi-Exit Neural Networks (AMENNs) have emerged as a promising solution for energy-efficient and faster inference in resource-constrained environments. To ensure that these networks meet performance requirements, evaluating their energy robustness is essential. Recent works have focused on energy attacks against models in both white-box and black-box scenarios. However, existing approaches in a black-box scenarios require a significant amount of additional training data to train auxiliary models, resulting in prohibitively high costs for the attacks.
Objectives:
In this work, we leverage genetic algorithm (GA) to search for high-energy samples to conduct attacks and evaluate the energy robustness of the AMENN models directly in black-box scenario, named 
E
nergy 
A
ttack using 
G
enetic 
A
lgorithm (EAGA).
Methods:
In the context of black-box scenarios, we propose an energy attack method based on genetic algorithm for AMENNs used in image classification tasks. By enhancing the fitness function to target high-energy consumption samples and improving population initialization and crossover mutation operations, we ensure a diverse and rich sample space for robust evaluation.
Results:
The results show that EAGA outperforms current baseline methods, demonstrating an average improvement of over 17% in the mean percentage increase in energy consumption of AMENNs. Furthermore, we guarantee the high quality of the generated attack inputs by ensuring sufficient similarity between the original image and the attack image.
Conclusion:
EAGA introduces a novel and efficient method for assessing the energy robustness of AMENNs in a black-box setting, devoid of the need for local gradient information. Through the utilization of genetic algorithms, this approach allows for a direct evaluation of model performance in resource-constrained environments. The study emphasizes the importance of EAGA in enhancing the evaluation process of AMENN models and underscores its potential to advance energy-efficient neural network deployments.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The evaluation of energy robustness in AMENNs through EAGA can be beneficial for startups working on resource-constrained neural network deployments.
https://www.sciencedirect.com/science/article/pii/S0950584924002519,DHG-BiGRU: Dual-attention based hierarchical gated BiGRU for software defect prediction,Ruchika=Malhotra: ruchikamalhotra2004@yahoo.com; Priya=Singh: priya.singh.academia@gmail.com,"Abstract
Context:
Software defect prediction (SDP) is a prominent research area focussed on anticipating defects early in the software lifecycle. Traditional machine learning models are based on static features, which are not enough to capture contextual information in the source code. In recent years, researchers have also developed deep learning models that extract semantic information from source code using the abstract syntax tree (AST). These approaches often combine static and semantic features by a simple merger operation.
Objective:
The article aims to address the limitations of the existing models by utilizing advanced feature extraction and integration techniques. It develops a deep learning model that can effectively prioritize the crucial features and intelligently combine the static and semantic features to provide robust predictions
Method:
The article proposes a novel model namely, dual-attention-based hierarchical gated BiGRU (DHG-BiGRU). The model first employs a static feature extractor (StatFE) and a semantic feature extractor (SemFE) to capture static and semantic features, respectively. Next, the outputs from StatFE and SemFE are passed to individual BiGRUs. The BiGRU output associated with the semantic features is subsequently processed by a dual attention mechanism (DAM), that captures the complex semantic information with emphasis on the most crucial features. Afterward, the hierarchical gated fusion (HGF) meticulously merges the static and semantic features. Finally, these integrated features are passed through a sigmoid function to predict defects.
Results:
The extensive experiments on extensively utilized datasets from the PROMISE repository reveal that DHG-BiGRU performs significantly better than the most advanced models and consistently achieves higher precision, recall and f-measure, demonstrating a reliable prediction capability.
Conclusion:
The results of the study underscore the potential advanced feature extraction and integration techniques for SDP. By achieving considerable improvements over state-of-the-art techniques, the proposed approach paves the way for sophisticated defect prediction models to improve software quality and reliability.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The advanced feature extraction and integration techniques proposed for software defect prediction can offer startups improved software quality and reliability, enhancing their competitiveness."
https://www.sciencedirect.com/science/article/pii/S0950584924002611,Automated detection of inter-language design smells in multi-language deep learning frameworks,Peng=Liang: liangp@whu.edu.cn; Zengyang=Li: zengyangli@ccnu.edu.cn; Ran=Mo: moran@ccnu.edu.cn; Hui=Liu: hliu@hust.edu.cn; Xiaoyong=Zhang: charles@mails.ccnu.edu.cn; Wenshuo=Wang: wenshuowang@mails.ccnu.edu.cn; Jie=Tan: j.tanjie@outlook.com,"Abstract
Context:
Nowadays, most deep learning frameworks (DLFs) use multilingual programming of Python and C/C++, facilitating the flexibility and performance of the DLF. However, inappropriate inter-language interaction may introduce design smells involving multiple programming languages (PLs), i.e., Inter-Language Design Smells (ILDS). Despite the negative impact of ILDS on multi-language DLFs, there is a lack of an automated approach for detecting ILDS in multi-language DLFs and a comprehensive understanding on ILDS in such DLFs.
Objective:
This work aims to automatically detect ILDS in multi-language DLFs written in the combination of Python and C/C++, and to obtain a comprehensive understanding on such ILDS in DLFs.
Methods:
We first developed an approach to automatically detecting ILDS in the multi-language DLFs written in the combination of Python and C/C++, including a number of ILDS and their detection rules defined based on inter-language communication mechanisms and code analysis. Then, we developed the 
CPsmell
 tool that implements detection rules for automatically detecting such ILDS, and manually validated the accuracy of the tool. Finally, we performed an empirical study to evaluate the ILDS in multi-language DLFs.
Results:
We proposed seven ILDS and achieved an accuracy of 98.17% in the manual validation of 
CPsmell
 in 5 popular multi-language DLFs. The study results revealed that among the 5 DLFs, TensorFlow, PyTorch, and PaddlePaddle exhibit relatively high prevalence of ILDS; each smelly file contains around 5 ILDS instances on average, with ILDS 
Long Lambda Function For Inter-language Binding
 and 
Unused Native Entity
 being relatively prominent; throughout the evolution process of the 5 DLFs, some ILDS were resolved to a certain extent, but the overall count of ILDS instances shows an upward trend.
Conclusions:
The automated detection of the proposed ILDS achieved a high accuracy, and the empirical study provides a comprehensive understanding on ILDS in the multi-language DLFs.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,4.0,The work addresses an important issue of design smells in deep learning frameworks but may have limited practical impact on European startups.
https://www.sciencedirect.com/science/article/pii/S2352673420300299,Permission to hustle: Igniting entrepreneurship in an organization,Greg=Fisher: fisherg@indiana.edu; Regan=Stevenson: rstev@indiana.edu; Devin=Burnell: dsburnel@iu.edu,"Abstract
Perceived institutional barriers, especially in existing organizations, often impede 
entrepreneurial action
 in the face of crisis and uncertainty. Understanding how collective entrepreneurial action occurs despite deeply institutionalized 
mindsets
 is important to advance 
entrepreneurship theory
. We report on an autoethnographic account of an entrepreneurship professor and several colleagues who gave themselves 
permission to hustle
 to overcome perceived institutional barriers to entrepreneurial action. As the findings reveal, a permission to hustle mindset provided a platform for the group of professors to act entrepreneurially in response to the COVID-19 pandemic. In a matter of several days, the group acted under uncertainty to create a new “idea blitz” program which attracted over 150 participants from around the world. We argue that permission to hustle is an important sense-breaking device that ignites and sustains entrepreneurial action by breaking taken-for-granted assumptions about institutionalized practices and redirecting attention toward urgent and creative action, especially in existing organizations where institutional barriers are perceived to impede such action.",November 2020,"Hustle, Entrepreneurial action, Ethnography, Corporate entrepreneurship, Crisis response",Business Venturing Insights,2025-03-21T00:00:00,9.0,"This abstract offers a compelling account of how entrepreneurial action can overcome institutional barriers, specifically in response to the COVID-19 pandemic. The insights can be highly relevant for European early-stage ventures facing similar challenges."
https://www.sciencedirect.com/science/article/pii/S0950584924002507,Robustness evaluation of code generation systems via concretizing instructions,Junjie=Chen: junjiechen@tju.edu.cn; Ming=Yan: yanming@tju.edu.cn; Jie M.=Zhang: jie.zhang@kcl.ac.uk; Xuejie=Cao: caoxuejie@tju.edu.cn; Chen=Yang: yangchenyc@tju.edu.cn; Mark=Harman: mark.harman@ucl.ac.uk,"Abstract
Context:
Code generation systems have been extensively developed in recent years to generate source code based on natural language instructions. However, despite their advancements, these systems still face robustness issues where even slightly different instructions can result in significantly different code semantics. Robustness is critical for code generation systems, as it can have significant impacts on software development, software quality, and trust in the generated code. Although existing testing techniques for general text-to-text software can detect some robustness issues, they can produce many false positives and are limited in effectiveness due to ignoring the characteristics of this kind of systems.
Objective:
To better evaluate (and further enhance) the robustness of code generation systems, in this work, we conducted the first exploration by carefully considering the characteristics of code generation systems. Specifically, we propose such a novel technique (called COCO) and perform an extensive study to evaluate the robustness of code generation systems with COCO.
Method:
COCO exploits the usage scenario of code generation systems to make the original programming instruction more concrete by incorporating features known to be present in the original code. A robust system should maintain code semantics for the concretized instruction, and COCO detects robustness inconsistencies when it does not. In the extensive study, we evaluated the robustness of eight advanced code generation systems (including commercial tools Copilot and ChatGPT) with COCO, using two widely-used datasets.
Results:
Our results demonstrate the effectiveness of COCO. It does not produce any false positive, ensuring the accuracy of robustness evaluation. Additionally, it outperforms the two baselines adopted from general text-to-text software testing, detecting 440.31% and 95.81% more inconsistencies, respectively. Concretized instructions generated by COCO can further help reduce robustness inconsistencies by 21.90% to 60.18% via fine-tuning.
Conclusions:
COCO is effective in detecting robust inconsistencies in code generation systems and significantly outperforms baselines. Additionally, fine-tuning code generation systems with the concretized instructions provided by COCO can largely enhance their robustness.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposed COCO technique has a significant impact on enhancing the robustness of code generation systems, which is highly relevant for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492400260X,What are the emotions of developers towards deep learning documentation? — An exploratory study on Stack Overflow posts,Akhila Sri Manasa=Venigalla: cs19d504@iittp.ac.in; Sridhar=Chimalakonda: ch@iittp.ac.in,"Abstract
Context:
Non native machine learning and deep learning (DL) developers face several challenges in using DL frameworks owing to the issues persistent in DL documentation. However, there are no studies that explore the reasons for issues in documentation.
Objective:
Investigating the underlying emotions in developer discussions on documentation could help in identifying reasons for issues in documentation. Hence, in this study, we analyse emotions of Stack Overflow posts corresponding to documentation of DL frameworks.
Methodology:
We identify relevant deep-learning related tags using integrated snowballing approach and extract 159.2K posts related to DL. We then identify documentation related posts among these using keyword matching approach, which resulted in 13,572 DL documentation related posts. We use Random Forest Classifier to build six emotion classifier models based on Gold Label Dataset for emotions. We then classify the extracted posts into each of the six emotions — 
Anger
, 
Fear
, 
Love
, 
Joy
, 
Sadness
 and 
Surprise
 using the classifier models, and curate the results.
Results:
We observe a large expression of anger and sadness, with more than half of posts having ‘yolo’ and ‘activation-function’ tags exhibiting these emotions, while 
Love
 emotion is predominantly present in posts with ‘theano’ tag. During our analysis, we observed that 40% of ‘Body’ and ‘Answer’ posts exhibited anger and sadness emotions.
Conclusion:
Our study reveals the large presence of Anger, Fear and Sadness emphasizing the need to improve DL framework documentation. Specifically, maintainers of the ‘yolo’ and ‘matcaffe’ libraries could improve their documentation, as the corresponding posts exhibit more of 
Anger
 and 
Sadness
.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,3.0,"While the study on emotions in developer discussions is interesting, the direct practical application to startups may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584924002623,Instance gravity oversampling method for software defect prediction,Yu=Tang: yutang@bjtu.edu.cn; Yang=Zhou: 23120496@bjtu.edu.cn; Cheng=Yang: 23115081@bjtu.edu.cn; Ye=Du: ydu@bjtu.edu.cn; Ming-song=Yang: 21281204@bjtu.edu.cn,"Abstract
Context
In the software defect datasets, the number of defective instances is significantly lower than that of non-defective instances. This imbalance adversely impacts the predictive performance of the model. Oversampling methods can effectively balance datasets. However, traditional oversampling methods often struggle to capture the underlying relationships between features and are prone to introducing noise during instance synthesis.
Objective
Inspired by the law of gravity, we propose a novel oversampling method based on instance gravity (MOSIG).
Method
This method begins by introducing a new metric, instance gravity, to measure the similarity between instances. Subsequently, feature models are constructed, and instance groups are generated. Instances that meet specific conditions based on instance gravity are then identified within different instance groups. Finally, we propose a novel method for synthesizing defective instances by assigning weights to instances according to their gravity.
Results
Experimental results demonstrate that MOSIG significantly enhances the predictive performance of both the CART decision tree and Naive Bayes models across 21 publicly available software defect datasets. The experimental results are further validated using the Friedman ranking and Nemenyi post-hoc test, confirming that MOSIG is statistically significant.
Conclusion
MOSIG represents a more promising oversampling method.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The MOSIG oversampling method shows promising results in enhancing predictive performance, which could benefit European startups in software defect prediction."
https://www.sciencedirect.com/science/article/pii/S0950584924002593,Reinforcement learning for test case prioritization based on LLEed K-means clustering and dynamic priority factor,Qingyuan=Yu: 2202210067@stu.jxufe.edu.cn,"Abstract
Integrating reinforcement learning (RL) into test case prioritization (TCP) aims to cope with the dynamic nature and time constraints of continuous integration (CI) testing. However, achieving optimal ranking across CI cycles is challenging if the RL agent starts from an unfavorable initial environment and deals with a dynamic environment characterized by continuous errors during learning. To mitigate the influence of adverse environments, this work proposes an approach to 
T
est 
C
ase 
P
rioritization which incorporates Locally Linear Embedding-based 
K
-means Clustering and 
D
ynamic Priority Factor into 
R
einforcement 
L
earning (
TCP-KDRL
). Firstly, we exploit the K-means clustering method with Locally Linear Embedding (LLE) to mine the relationships between test cases, followed by assigning initial priority factors to the test cases. These test cases are ranked based on their initial factors, providing an improved initial learning environment for the agent in RL. Secondly, with the agent learning the ranking strategy in various cycles, we design a comprehensive reward indicator by considering running discrepancy and the position between test cases. Additionally, based on the reward values, the dynamic priority factors for the ranked test cases in each learning round of RL are adaptively updated and the sequence is locally fine-tuned. The fine-tuning strategy provides ample feedback to the agent and enables real-time correction of the erroneous ranking environment, enhancing the generalization of RL across various cycles. Finally, the experimental results demonstrate that TCP-KDRL, as an enhanced RL-based TCP method, outperforms other competitive TCP approaches. Specifically, incorporating the reward indicator and the fine-tuning strategy components, the results are significantly better than that of combining any other two components. For instance, in 12 projects, the average improvements are 0.1548 in APFD and 0.0793 in NRPA. Compared to other TCP methods, the proposed method achieves notable enhancement, with an increase of 0.6902 in APFD and 0.3816 in NRPA.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The TCP-KDRL approach presents a comprehensive method for test case prioritization, which can greatly benefit European startups involved in continuous integration testing."
https://www.sciencedirect.com/science/article/pii/S2352673420300378,Reorienting entrepreneurial support infrastructure to tackle a social crisis: A rapid response,Trenton Alma=Williams: trenwill@iu.edu; Nick=Williams: N.E.Williams@leeds.ac.uk; Pablo=Muñoz: pmunoz@liverpool.ac.uk; Wim=Naudé: naude@time.rwth-aachen.de; Rodrigo=Frías: rodrigo.frias@corfo.cl,"Abstract
Chile is experiencing its worst economic and social crisis in decades, which is adversely impacting entrepreneurs and SMEs. Chile’s Economic Development Agency is seeking to support recovery efforts by reorienting its entrepreneurship programs and ecosystem support capacity. What makes the reorientation especially challenging is the need to ensure all actions are sensitive to the causes of the social unrest, where arguably extant entrepreneurship policy has played a role. Theory and evidence in entrepreneurship literature seem insufficient to inform immediate actions. In this rapid response paper, we leverage and translate research on ecosystem democracy, spontaneous venturing and entrepreneurship-enabled social cohesion to inform decision-making and contribute to the development of policy solutions. We propose an entrepreneurship policy reorientation model, including interventions during and post crisis, potentially capable of minimizing the effects of the crisis and changing the orientation of future support.",November 2020,"Entrepreneurship, Crisis, Entrepreneurship policy, Rapid response, Chile",Business Venturing Insights,2025-03-21T00:00:00,7.0,"The rapid response paper addressing Chile's economic crisis and entrepreneurship policy reorientation provides valuable insights that could be beneficial for early-stage ventures in Europe, although the direct impact may be more specific to the Chilean context."
https://www.sciencedirect.com/science/article/pii/S0950584924002489,Service engineering for quantum computing: Ensuring high-quality quantum services,Jaime=Alvarado-Valiente: jaimeav@unex.es,"Abstract
Context:
Quantum computing is transforming the world and driving advanced applications in fields such as healthcare and economics. However, ensuring high-quality quantum software remains critical to its adoption across the industry. As quantum technology moves closer to practical applications, it faces significant challenges. Developers face platform-dependent complexities that make the creation of quantum applications a time-consuming process. In addition, the lack of mature tools further hampers progress and can compromise the quality of service.
Objective:
The objective of this paper is to address the pressing need for quantum software quality assurance, presenting a solution for defining and using quantum services, by employing classical service engineering techniques and methods.
Methods:
A process is presented for improving the generation, deployment, and quality assessment of quantum services using an extended OpenAPI Specification and the SonarQube tool. This process also integrates the automatic generation of code for the IBM Quantum provider and its deployment in containers ready for user consumption.
Results:
After a detailed and individualized evaluation of the 40 implementations of quantum algorithms using the developed environment, the results reveal significant variability in the analyzability of the algorithms. This will serve in the future as a reference and guide for the continuous improvement of quantum algorithms in terms of their performance and efficiency in solving complex problems in various quantum application areas.
Conclusions:
This research offers a fundamental contribution to the evolution of quantum computing by introducing a comprehensive framework for quantum software quality assurance. The proposed approach not only addresses some of the existing problems in quantum software, but also paves the way for the development of quantum algorithms and their servitization.",March 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The research addresses a pressing need for quantum software quality assurance, offering a comprehensive framework that can pave the way for the development of quantum algorithms and their servitization."
https://www.sciencedirect.com/science/article/pii/S0950584924002490,Locating requirements in backlog items: Content analysis and experiments with large language models,Fabiano=Dalpiaz: f.dalpiaz@uu.nl; Ashley T.=van Can: a.t.vancan@uu.nl,"Abstract
Context:
As agile development has become mainstream, requirements are increasingly managed via issue tracking systems (ITSs). These systems provide a single point of access to the product and sprint backlogs, bugs, ideas, and tasks for the development team. ITSs do not clearly separate requirements from work items.
Objective:
We first tackle a 
knowledge problem
 concerning how requirements are formulated in ITSs, including their categorization and granularity, the presence of multiple requirements, and the existence of a motivation. Second, to assist practitioners in finding requirements in poorly organized ITSs without changing their way of working, we investigate the potential of automated techniques for identifying and classifying requirements in backlog items.
Method:
Through quantitative content analysis, we analyze 1,636 product backlog items sampled from fourteen projects. To explore automated techniques for identifying requirements, we experiment with large language models (LLMs) due to their recent significance in NLP.
Results:
The labeling of backlog items is largely inconsistent, and user-oriented functional requirements are the prevalent category. A backlog item often contains multiple requirements with different levels of granularity. The experiments with LLMs reveal that encoder-only models (BERT and RoBERTa) are most suitable for extracting and classifying requirements in backlog items compared to decoder-only models (Llama 3, Mistral 7B and ChatGPT with GPT 4).
Conclusion:
We reveal knowledge and patterns about requirements documentation in ITSs, leading to a better empirical understanding of Agile RE. The experimental results with LLMs provide the foundation for developing automated, unobtrusive tools that identify and classify requirements in ITSs.",March 2025,"Agile requirements Engineering, User stories, Backlog items, Issue tracking systems, Content analysis, Large language models",Information and Software Technology,2025-03-21T00:00:00,5.0,"The study provides insights into requirements documentation in Agile RE and experiments with automated techniques for identifying requirements, but the practical impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584924002131,A multivocal literature review on the benefits and limitations of industry-leading AutoML tools,Marcos=Kalinowski: kalinowski@inf.puc-rio.br,"Abstract
Context:
Rapid advancements in Artificial Intelligence (AI) and Machine Learning (ML) are revolutionizing software engineering in every application domain, driving unprecedented transformations and fostering innovation. However, despite these advances, several organizations are experiencing friction in the adoption of ML-based technologies, mainly due to the current shortage of ML professionals. In this context, Automated Machine Learning (AutoML) techniques have been presented as a promising solution to democratize ML adoption, even in the absence of specialized people.
Objective:
Our research aims to provide an overview of the evidence on the benefits and limitations of AutoML tools being adopted in industry.
Methods:
We conducted a Multivocal Literature Review, which allowed us to identify 54 sources from the academic literature and 108 sources from the grey literature reporting on AutoML benefits and limitations. We extracted explicitly reported benefits and limitations from the papers and applied the thematic analysis method for synthesis.
Results:
In general, we identified 18 reported benefits and 25 limitations. Concerning the benefits, we highlight that AutoML tools can help streamline the core steps of ML workflows, namely data preparation, feature engineering, model construction, and hyperparameter tuning—with concrete benefits on model performance, efficiency, and scalability. In addition, AutoML empowers both novice and experienced data scientists, promoting ML accessibility. However, we highlight several limitations that may represent obstacles to the widespread adoption of AutoML. For instance, AutoML tools may introduce barriers to transparency and interoperability, exhibit limited flexibility for complex scenarios, and offer inconsistent coverage of the ML workflow.
Conclusion:
The effectiveness of AutoML in facilitating the adoption of machine learning by users may vary depending on the specific tool and the context in which it is used. Today, AutoML tools are used to increase human expertise rather than replace it and, as such, require skilled users.",February 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The research reviews the benefits and limitations of AutoML tools, highlighting their potential to democratize ML adoption. This can have a significant impact on early-stage ventures facing a shortage of ML professionals."
https://www.sciencedirect.com/science/article/pii/S0950584924002106,FOBICS: Assessing project security level through a metrics framework that evaluates DevSecOps performance,Alessandro=Caniglia: alessandro.caniglia95@gmail.com; Vincenzo=Dentamaro: vincenzo.dentamaro@uniba.it; Stefano=Galantucci: stefano.galantucci@uniba.it; Donato=Impedovo: donato.impedovo@uniba.it,"Abstract
Context:
In today’s software development landscape, the DevSecOps approach has gained traction due to its focus on the software development process and bolstering security measures in projects, a task in light of the ever-evolving cybersecurity threats.
Objective:
This study aims to address the lack of metrics for quantitatively assessing its efficacy from both security and business logic perspectives.
Methods:
To tackle this issue, the research introduces the Framework of Business Index Concerning Security (FOBICS), a set of metrics designed to enable transparent evaluations of project security. FOBICS considers various perspectives relevant to DevSecOps practices. It includes factors such as project duration and financial outcomes, making it appealing for implementation in business settings.
Results:
The effectiveness of FOBICS is validated theoretically and empirically via its application in two real-world projects: the results from these implementations show a correlation between FOBICS metrics and the security strategies employed as the development methodologies adopted by diverse teams throughout the projects.
Conclusion:
Hence, FOBICS emerges as a tool for assessing and continuously monitoring project security, offering insights into areas of strength and areas that may require enhancement. FOBICS is shown to be effective in assessing the level of DevSecOps implementation. The ease of calculating FOBICS metrics makes them easily interpretable and continuously verifiable. Moreover, FOBICS summarizes most of the other quantitative and qualitative metrics in the literature.",February 2025,"DevSecOps, Metrics framework, Project security, Software engineering, Evaluating security, DevOps, Security assessment, Software metrics, Secure software development, Business metrics",Information and Software Technology,2025-03-21T00:00:00,6.0,"The study introduces a framework for assessing DevSecOps efficacy, but the practical application and impact on early-stage ventures may be limited due to its focus on security and business logic perspectives."
https://www.sciencedirect.com/science/article/pii/S2352673420300433,Staying alive during an unfolding crisis: How SMEs ward off impending disaster,Sara=Thorgren: sara.thorgren@ltu.se; Trenton Alma=Williams: trenwill@iu.edu,"Abstract
What measures are SMEs most likely to take in order to make ends meet in the face of a “black swan” external shock? That is the question we explore in this study, drawing upon unique data from 456 SMEs 
in the midst
 of an unfolding crisis. Our findings demonstrate how SMEs acted immediately by deferring investments, reducing 
labor costs
, reducing expenses, and negotiating contracts and terms. Moreover, the data highlight how SMEs in an unfolding crisis are reluctant to commit to any action that will increase their debt-to-equity ratio. The findings suggest new questions to be explored in relation to actions during an unfolding crisis, post-crisis businesses, entrepreneurial failure, and entrepreneur/entrepreneurial team characteristics. Implications for policy and practice are provided.",November 2020,"Shock, Crisis, Entrepreneurship, Coronavirus, COVID-19, Outcome, Actions",Business Venturing Insights,2025-03-21T00:00:00,6.0,"The study on SMEs' actions during a crisis offers some interesting findings, but the practical implications for early-stage ventures in Europe may be limited as it focuses on SMEs in a crisis situation."
https://www.sciencedirect.com/science/article/pii/S0950584924002179,Impact of minimum viable product on software ecosystem failure,Kati=Saarni: katimarika.saarni@gmail.com,"Abstract
Context
Companies are interested in building successful value-producing ecosystems together to offer end users a broader digital service offering and better meet customer needs. However, most ecosystems fail in the early years.
Objective
We investigated one small software ecosystem from the planning phase to the operative phase, where the participating companies left one by one because the software ecosystem was unsuccessful, and the software ecosystem ended after four operative years. The software ecosystem provided a digital service offering based on the defined MVP (Minimum Viable Product). That is why we were interested in understanding the MVP's impact on the ecosystem's failure.
Method
We conducted a case study, the results of which are based on the semi-structured interviews of eight representatives of the software ecosystem.
Results
This study showed that the actors prioritized out functionalities from the MVP, and the MVP was no longer based on the defined value proposition, target customer groups, and customer paths. It was then difficult for the actors to achieve their objectives. The companies’ commitment depended on the set objectives, and when the objectives were not achieved, the actors left the ecosystem, and the software ecosystem failed.
Conclusion
The results show that the MVP can significantly affect the failure of the small software ecosystem, where all actors have a keystone role. The MVP largely defines what kind of digital service offering the software ecosystem provides and whether the actors can achieve the objectives, especially their sales goals. Thus, prioritizing the functionalities of the MVP is a critical activity.",February 2025,Not Found,Information and Software Technology,2025-03-21T00:00:00,4.0,"The case study explores the impact of Minimum Viable Product (MVP) on the failure of a software ecosystem, which may provide insights but lacks a direct practical application and impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924002143,Who uses personas in requirements engineering: The practitioners’ perspective,John=Grundy: john.grundy@monash.edu; Chetan=Arora: chetan.arora@monash.edu; Xiao=Liu: xiao.liu@deakin.edu.au; Yi=Wang: xve@deakin.edu.au; Thuong=Hoang: thuong.hoang@deakin.edu.au; Vasudha=Malhotra: vasu.malhotra@monash.edu; Ben=Cheng: chengye@deakin.edu.au,"Abstract
Context:
Personas are commonly employed in software projects to better understand end-users needs. Despite their frequent usage, there is a limited understanding of their practical application and effectiveness.
Objective:
This paper aims to investigate the current practices, methods, and challenges associated with using personas in software development.
Methods:
A two-step investigation was conducted, comprising interviews with 26 software developers, UI/UX designers, business analysts, and product managers, along with a survey of 203 practitioners.
Results:
The findings reveal variations in the frequency and effectiveness of personas across different software projects and IT companies. Additionally, the study highlights the challenges practitioners face when using personas and the reasons for not using them. Notably, the research shows that some human aspects (e.g., the needs of users with disabilities), often assumed to be a key feature of personas, are frequently not considered for various reasons in requirements engineering.
Conclusions:
The study provides actionable insights for practitioners to overcome challenges in using personas during the requirements engineering stages. Furthermore, it identifies areas for future research to enhance the effectiveness of personas in software development.",February 2025,"Requirements engineering, Personas, Human aspects, Survey, Interviews",Information and Software Technology,2025-03-21T00:00:00,5.0,"The study provides insights into the challenges faced by practitioners in using personas, offering actionable steps for improvement, but the impact on early-stage ventures is not clearly specified."
https://www.sciencedirect.com/science/article/pii/S0950584924001745,"A systematic literature review on Agile, Cloud, and DevOps integration: Challenges, benefits",Karima=Moumane: karima.moumane@ensias.um5.ac.ma,"Abstract
Context:
In today’s fast-paced digital landscape, integrating DevOps, cloud, and agile methodologies is crucial for meeting software demands. However, this integration remains under-researched.
Objective:
This study explores the integration of Agile, Cloud, and DevOps in today’s software development landscape. It aims to analyze the challenges and benefits associated with merging these three approaches, focusing on their impact on software testing and the role of mindset in successful implementation and identifying the most suitable Agile methodologies.
Methods:
This investigation utilizes a Systematic Literature Review(SLR) to enrich comprehension of this integration in current software development practices.
Results:
The analysis of 31 articles highlights benefits such as improved collaboration and accelerated development, despite challenges with tool proliferation. Platforms like Jenkins, GitLab, Kubernetes, and Docker show promise in addressing these complexities. Our study examines the advantages and challenges of this integration, focusing on its impact on software testing and the role of mindset in successful implementation and identifying the most suitable Agile methodologies.
Conclusion:
The integration of Agile, DevOps, and Cloud signifies a vital move towards collaborative, scalable, and automated methods, crucial for swift delivery, enhanced quality, and ongoing competitiveness. This unified approach is fundamental for organizational advancement and innovation in the ever-evolving software development realm. Further research should tackle challenges in merging these methods and delve into their interactions with emerging technologies to refine practices for increased efficiency.",January 2025,"DevOps, Cloud, Agile, Integration, Synergy",Information and Software Technology,2025-03-21T00:00:00,7.0,"The integration of Agile, DevOps, and Cloud is crucial for software development, with a focus on collaborative and scalable methods. This unified approach can benefit early-stage ventures by enhancing quality and competitiveness."
https://www.sciencedirect.com/science/article/pii/S0950584924001484,Automated description generation for software patches,Hieu Dinh=Vo: hieuvd@vnu.edu.vn; Son=Nguyen: sonnguyen@vnu.edu.vn; Thanh Trong=Vu: thanhvu@vnu.edu.vn; Tuan-Dung=Bui: 21020006@vnu.edu.vn; Thanh-Dat=Do: 20020045@vnu.edu.vn; Thu-Trang=Nguyen: trang.nguyen@vnu.edu.vn,"Abstract
Software patches are pivotal in refining and evolving codebases, addressing bugs, vulnerabilities, and optimizations. Patch descriptions provide detailed accounts of changes, aiding comprehension and collaboration among developers. However, manual description creation poses challenges in terms of time consumption and variations in quality and detail. In this paper, we propose 
PatchExplainer
, an approach that addresses these challenges by framing patch description generation as a machine translation task. In 
PatchExplainer
, we leverage explicit representations of critical elements, historical context, and syntactic conventions. Moreover, the translation model in 
PatchExplainer
 is designed with an awareness of description similarity. Particularly, the model is 
explicitly
 trained to recognize and incorporate similarities present in patch descriptions clustered into groups, improving its ability to generate accurate and consistent descriptions across similar patches. The dual objectives maximize similarity and accurately predict affiliating groups. Our experimental results on a large dataset of real-world software patches show that 
PatchExplainer
 consistently outperforms existing methods, with improvements up to 189% in 
BLEU
, 5.7X in 
Exact Match
 rate, and 154% in 
Semantic Similarity
, affirming its effectiveness in generating software patch descriptions.",January 2025,"Software patch, Patch description, Neural machine translation, Code-to-text",Information and Software Technology,2025-03-21T00:00:00,8.0,"PatchExplainer offers a innovative approach to generating software patch descriptions, improving accuracy and consistency significantly. This can have a direct positive impact on software development speed and quality for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924001939,DeepMig: A transformer-based approach to support coupled library and code migrations,Davide=Di Ruscio: davide.diruscio@univaq.it; Massimiliano=Di Penta: dipenta@unisannio.it; Juri=Di Rocco: juri.dirocco@univaq.it; Phuong T.=Nguyen: phuong.nguyen@univaq.it; Claudio=Di Sipio: claudio.disipio@univaq.it; Riccardo=Rubei: riccardo.rubei@univaq.it,"Abstract
Context:
While working on software projects, developers often replace third-party libraries (TPLs) with different ones offering similar functionalities. However, choosing a suitable TPL to migrate to is a complex task. As TPLs provide developers with Application Programming Interfaces (APIs) to allow for the invocation of their functionalities after adopting a new TPL, projects need to be migrated by the methods containing the affected API calls. Altogether, the coupled migration of TPLs and code is a strenuous process, requiring massive development effort. Most of the existing approaches either deal with library or API call migration but usually fail to solve both problems coherently simultaneously.
Objective:
This paper presents DeepMig, a novel approach to the coupled migration of TPLs and API calls. We aim to support developers in managing their projects, at the library and API level, allowing them to increase their productivity.
Methods:
DeepMig is based on a transformer architecture, accepts a set of libraries to predict a new set of libraries. Then, it looks for the changed API calls and recommends a migration plan for the affected methods. We evaluate DeepMig using datasets of Java projects collected from the Maven Central Repository, ensuring an assessment based on real-world dependency configurations.
Results:
Our evaluation reveals promising outcomes: DeepMig recommends both libraries and code; by several projects, it retrieves a perfect match for the recommended items, obtaining an accuracy of 1.0. Moreover, being fed with proper training data, DeepMig provides comparable code migration steps of a static API migrator, a baseline for the code migration task.
Conclusion:
We conclude that DeepMig is capable of recommending both TPL and API migration, providing developers with a practical tool to migrate the entire project.",January 2025,"Recommender system, Library migration, Transformers",Information and Software Technology,2025-03-21T00:00:00,7.0,"DeepMig presents a novel approach to coupled migration of TPLs and API calls, potentially increasing developers' productivity. This tool could provide valuable assistance to early-stage ventures in managing their projects efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584924001551,Bringing architecture-based adaption to the mainstream,Negar=Ghorbani: negargh@uci.edu; Joshua=Garcia: joshug4@uci.edu; Sam=Malek: malek@uci.edu,"Abstract
Software architecture has been shown to provide an appropriate level of granularity for representation of a managed software system and reasoning about the impact of adaptation choices on its properties. Software architecture-based adaptability is the ability to adapt a software system in terms of its architectural elements, such as its components and their interfaces. Despite its promise, architecture-based adaptation has remained largely elusive, mainly because it involves heavy engineering effort of making non-trivial changes to the manner in which a software system is implemented. In this paper, we present 
Acadia
—a framework that automatically enables architecture-based adaptation of practically any Java 9+ application without requiring any changes to the implementation of the application itself. 
Acadia
 builds on the 
Java Platform Module System (JPMS)
, which has brought extensive support for architecture-based development to Java 9 and subsequent versions. 
Acadia
 extends JPMS with the ability to provide and maintain a representation of an application’s architecture and make changes to it at runtime. The results of our experimental evaluation, conducted on three large open-source Java applications, indicate that 
Acadia
 is able to efficiently apply dynamic changes to the architecture of these applications without requiring any changes to their implementation.",December 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"Acadia presents a framework for architecture-based adaptation without changes to application implementation, potentially reducing engineering effort. While promising, the direct impact on early-stage ventures is not explicitly discussed."
https://www.sciencedirect.com/science/article/pii/S0950584924001708,A3Test: Assertion-Augmented Automated Test case generation,Chakkrit=Tantithamthavorn: chakkrit@monash.edu,"Abstract
Context:
Test case generation is a critical yet challenging task in software development. Recently, AthenaTest – a Deep Learning (DL) approach for generating unit test cases has been proposed. However, our revisiting study reveals that AthenaTest can generate less than one-fifth of the test cases correctly, due to a lack of assertion knowledge and test signature verification.
Objective:
This paper introduces A3Test, a novel DL-based approach to the generation of test cases, enhanced with assertion knowledge and a mechanism to verify consistency of the name and signatures of the tests. A3Test aims to adapt domain knowledge from assertion generation to test case generation.
Method:
A3Test employs domain adaptation principles and introduces a verification approach to name consistency and test signatures. We evaluate its effectiveness using 5,278 focal methods from the Defects4j dataset.
Results:
Our findings indicate that A3Test outperforms AthenaTest and ChatUniTest. A3Test generates 2.16% to 395.43% more correct test cases, achieves 2.17% to 34.29% higher method coverage, and 25.64% higher line coverage. A3Test achieves 2.13% to 12.20% higher branch coverage, 2.22% to 12.20% higher mutation scores, and 2.44% to 55.56% more correct assertions compared to both ChatUniTest and AthenaTest respectively for one iteration. When generating multiple test cases per method A3Test still shows improvements and comparable efficacy to ChatUnitTest. A survey of developers reveals that the majority of the participants 70.51% agree that test cases generated by A3Test are more readable than those generated by EvoSuite.
Conclusions:
A3Test significantly enhances test case generation through its incorporation of assertion knowledge and test signature verification, contributing to the generation of correct test cases.",December 2024,"Test case generation, Deep learning",Information and Software Technology,2025-03-21T00:00:00,8.0,"The development of A3Test significantly improves test case generation, leading to more correct test cases and higher coverage metrics. This can have a positive impact on European early-stage ventures by enhancing software quality and reducing defects."
https://www.sciencedirect.com/science/article/pii/S0950584924001575,Perceived impact of agile principles: Insights from a survey-based study on agile software development project success,Sun-Jen=Huang: huangsj@mail.ntust.edu.tw; Yulianus=Palopak: ypalopak@unai.edu,"Abstract
Context
Agile methodology has emerged as a fundamental framework guiding software development projects, emphasizing values and principles for achieving successful project outcomes. Despite the widespread recognition of the importance of agile principles, there remains a gap in empirical research investigating their actual impact on agile project success.
Objective
This research aims to examine the relationship between agile principles and project outcomes and provide empirical evidence supporting the importance of agile principles in achieving success in agile software development (ASD) projects.
Method
A total of 298 Agile project practitioners participated in an online survey between August and September 2023 to test this study's research model using the partial least square structural equation modeling (PLS-SEM) method.
Results
We find a significant relationship between adopting agile principles and project success, with regular delivery, technical excellence, team member proactivity, and customer collaboration showing the highest impact on Agile project success. However, process simplicity was found not to be significant in the study.
Conclusions
Our analysis verifies the importance of Agile principles and suggests areas for further study to successfully understand their impact on Agile projects. The findings contribute to the ongoing discourse on agile principles and their impact on software development project success, opening avenues for future research and the refinement of agile methodologies. These insights could assist organizations in optimizing Agile practices and decision-making, leading to more successful and efficient software development projects.",December 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The study on agile principles and project success provides valuable insights for Agile projects. Understanding the importance of agile principles can contribute to the success of software development projects, which is relevant for European early-stage ventures."
https://ieeexplore.ieee.org/document/10151873/,Crime Prediction Using Machine Learning and Deep Learning: A Systematic Review and Future Directions,,"Predicting crime using machine learning and deep learning techniques has gained considerable attention from researchers in recent years, focusing on identifying patterns and trends in crime occurrences. This review paper examines over 150 articles to explore the various machine learning and deep learning algorithms applied to predict crime. The study provides access to the datasets used for crime prediction by researchers and analyzes prominent approaches applied in machine learning and deep learning algorithms to predict crime, offering insights into different trends and factors related to criminal activities. Additionally, the paper highlights potential gaps and future directions that can enhance the accuracy of crime prediction. Finally, the comprehensive overview of research discussed in this paper on crime prediction using machine learning and deep learning approaches serves as a valuable reference for researchers in this field. By gaining a deeper understanding of crime prediction techniques, law enforcement agencies can develop strategies to prevent and respond to criminal activities more effectively.",14 June 2023,"Deep learning, Prediction algorithms, Machine learning algorithms, Databases, Market research, Predictive models, Urban areas, Machine Learning, Deep Learning, Crime Prevention, Learning Algorithms, Machine Learning Techniques, Machine Learning Approaches, Deep Learning Techniques, Convolutional Neural Network, Classification Task, Research Articles, Recurrent Neural Network, Text Data, Weather Data, Social Media Data, Mean Absolute Percentage Error, Application Of Deep Learning, Machine Learning Prediction, Audio Data, Crime Scene, Combination Of Deep Learning, Neighborhood Crime, Crime Data, Crime Patterns, Crime Reports, New York City, Anomaly Data, SHapley Additive exPlanations, Deep Learning Models, Neural Network, Crime prediction, crime detection, crime datasets, deep learning, machine learning, smart policing, survey",IEEE Access,2025-03-24T00:00:00,5.0,"The abstract contributes to understanding crime prediction using machine learning and deep learning techniques, which could be beneficial for startups working on security solutions."
https://www.sciencedirect.com/science/article/pii/S0950584924001307,The quantum frontier of software engineering: A systematic mapping study,Fabio=Palomba: fpalomba@unisa.it; Andrea=De Lucia: adelucia@unisa.it; Manuel=De Stefano: madestefano@unisa.it; Fabiano=Pecorelli: fpecorelli@unisa.it; Dario=Di Nucci: ddinucci@unisa.it,"Abstract
Context:
Quantum computing is becoming a reality, and quantum software engineering (QSE) is emerging as a new discipline to enable developers to design and develop quantum programs.
Objective:
This paper presents a systematic mapping study of the current state of QSE research, aiming to identify the most investigated topics, the types and number of studies, the main reported results, and the most studied quantum computing tools/frameworks. Additionally, the study aims to explore the research community’s interest in QSE, how it has evolved, and any prior contributions to the discipline before its formal introduction through the Talavera Manifesto.
Method:
We searched for relevant articles in several databases and applied inclusion and exclusion criteria to select the most relevant studies. After evaluating the quality of the selected resources, we extracted relevant data from the primary studies and analyzed them.
Results:
We found that QSE research has primarily focused on software testing, with little attention given to other topics, such as software engineering management. The most commonly studied technology for techniques and tools is Qiskit, although, in most studies, either multiple or none specific technologies were employed. The researchers most interested in QSE are interconnected through direct collaborations, and several strong collaboration clusters have been identified. Most articles in QSE have been published in non-thematic venues, with a preference for conferences.
Conclusions:
The study’s implications are providing a centralized source of information for researchers and practitioners in the field, facilitating knowledge transfer, and contributing to the advancement and growth of QSE.",November 2024,"Quantum computing, Quantum software engineering, Software engineering for quantum programming, Empirical software engineering, Systematic mapping study",Information and Software Technology,2025-03-21T00:00:00,5.0,"The systematic mapping study on Quantum software engineering provides valuable information for researchers and practitioners in the field. While it may not have direct practical impact on European early-stage ventures, it contributes to the growth of the discipline."
https://www.sciencedirect.com/science/article/pii/S0950584924001496,Hidden code vulnerability detection: A study of the Graph-BiLSTM algorithm,Qing-Bang=Han: 20111841@hhu.edu.cn,"Abstract
Context:
The accelerated growth of the Internet and the advent of artificial intelligence have led to a heightened interdependence of open source products, which has in turn resulted in a rise in the frequency of security incidents. Consequently, the cost-effective, fast and efficient detection of hidden code vulnerabilities in open source software products has become an urgent challenge for both academic and engineering communities.
Objectives:
In response to this pressing need, a novel and efficient code vulnerability detection model has been proposed: the Graph-Bi-Directional Long Short-Term Memory Network Algorithm (Graph-BiLSTM). The algorithm is designed to enable the detection of vulnerabilities in Github’s code commit records on a large scale, at low cost and in an efficient manner.
Methods:
In order to extract the most effective code vulnerability features, state-of-the-art vulnerability datasets were compared in order to identify the optimal training dataset. Initially, the Joern tool was employed to transform function-level code blocks into Code Property Graphs (CPGs). Thereafter, structural features (degree centrality, Katz centrality, and closeness centrality) of these CPGs were computed and combined with the embedding features of the node sequences to form a two-dimensional feature vector space for the function-level code blocks. Subsequently, the BiLSTM network algorithm was employed for the automated extraction and iterative model training of a substantial number of vulnerability code samples. Finally, the trained algorithmic model was applied to code commit records of open-source software products on GitHub, achieving effective detection of hidden code vulnerabilities.
Conclusion:
Experimental results indicate that the PrimeVul dataset represents the most optimal resource for vulnerability detection. Moreover, the Graph-BiLSTM model demonstrated superior performance in terms of accuracy, training cost, and inference time when compared to state-of-the-art algorithms for the detection of vulnerabilities in open-source software code on GitHub. This highlights the significant value of the model for engineering applications.",November 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The Graph-BiLSTM model for code vulnerability detection addresses a pressing need in the software development community. The efficient detection of vulnerabilities in open-source software can significantly benefit European early-stage ventures by improving security and reducing risks.
https://www.sciencedirect.com/science/article/pii/S0950584924001241,Towards antifragility of cloud systems: An adaptive chaos driven framework,Amro=Al-Said Ahmad: a.m.al-said.ahmad@keele.ac.uk,"Abstract
Context
Unlike resilience, antifragility describes systems that get stronger rather than weaker under stress and chaos. Antifragile systems have the capacity to overcome stressors and come out stronger, whereas resilient systems are focused on their capacity to return to their previous state following a failure. As technology environments become increasingly complex, there is a great need for developing software systems that can benefit from failures while continuously improving. Most applications nowadays operate in cloud environments. Thus, with this increasing adoption of Cloud-Native Systems they require antifragility due to their distributed nature.
Objective
The paper proposes UNFRAGILE framework, which facilitates the transformation of existing systems into antifragile systems. The framework employs chaos engineering to introduce failures incrementally and assess the 
system's response
 under such perturbation and improves the quality of system response by removing fragilities and introducing adaptive 
fault tolerance
 strategies.
Method
The UNFRAGILE framework's feasibility has been validated by applying it to a cloud-native using a real-world architecture to enhance its antifragility towards long outbound service latencies. The empirical investigation of fragility is undertaken, and the results show how chaos affects application performance metrics and causes disturbances in them. To deal with chaotic 
network latency
, an adaptation phase is put into effect.
Results
The findings indicate that the steady stage's behaviour is like the antifragile stage's behaviour. This suggests that the system could self-stabilise during the chaos without the need to define a 
static configuration
 after determining from the context of the environment that the dependent system was experiencing difficulties.
Conclusion
Overall, this paper contributes to ongoing efforts to develop antifragile software capable of adapting to the rapidly changing complex environment. Overall, the research provides an operational framework for engineering software systems that learn and improve through exposure to failures rather than just surviving them.",October 2024,"Antifragility, Resilience, Chaos engineering, Self-adaptive software, Resilience testing, Cloud computing",Information and Software Technology,2025-03-21T00:00:00,6.0,"The UNFRAGILE framework for developing antifragile software systems presents an innovative approach to software engineering. While the concept is valuable, its direct impact on European early-stage ventures may be limited at the current stage of adoption."
https://www.sciencedirect.com/science/article/pii/S0950584924001265,Towards assessing the quality of knowledge graphs via differential testing,Yang=Feng: fengyang@nju.edu.cn; Jiajun=Tan: jjtan@smail.nju.edu.cn; Dong=Wang: juliawdd@henu.edu.cn; Jingyu=Sun: MF21320132@smail.nju.edu.cn; Zixi=Liu: zxliu@smail.nju.edu.cn; Xiaoruo=Li: lixiaoruo@henu.edu.cn,"Abstract
Knowledge graphs
 (KG) can aggregate data and make information resources easier to calculate and understand. With tremendous advancements in knowledge graphs, they have been incorporated into plenty of software systems to assist various tasks. However, while KGs determine the performance of downstream software systems, their quality is often measured by the accuracy of test data. Considering the limitation of accessible high-quality test data, an automated quality assessment technique could fundamentally improve the testing efficiency of KG-driven software systems and save plenty of manual labeling resources.
In this paper, we propose an automated approach to quantify the quality of KGs via differential testing. It first constructs multiple 
Knowledge Graph Embedding
 Models (KGEM) and conducts head prediction tasks on models. Then, it can produce a differential score that reflects the quality of KGs by comparing the proximity of output results. To validate the effectiveness of this approach, we experiment with four open-sourced knowledge graphs. The experiment results show that our approach is capable of accurately evaluating the quality of KGs and producing reliable results on different datasets. Moreover, we compared our method with existing methods and achieved certain advantages. The potential usefulness of our approach sheds light on the development of various KG-driven software systems.",October 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The automated approach proposed to quantify the quality of KGs can significantly improve the testing efficiency of KG-driven software systems, saving manual labeling resources and shedding light on the development of various software systems."
https://example.com/paper/ai-startups,Dummy Test Exploring the Impact of AI on European Startups,John=Doe: dummy.doe@example.com,"This paper analyzes how artificial intelligence is transforming early-stage ventures in Europe by improving operations, fundraising, and innovation speed.",2024,"string, Dummy",Journal of Startup Research,2025-03-27T11:24:57.296396,8.5,Valuable insights for European tech startups leveraging AI.
https://www.sciencedirect.com/science/article/pii/S0950584924000934,Coverage-enhanced fault diagnosis for Deep Learning programs: A learning-based approach with hybrid metrics,Yanhui=Li: yanhuili@nju.edu.cn,"Abstract
Context:
Given the data-driven paradigm inherent to 
Deep Learning
 (DL), it is inevitable that DL software will exhibit incorrect behavior in real-world applications. DL programs have been identified as a primary source of DL faults. To tackle this, researchers have devised a unique framework that approaches fault diagnosis as a learning task, which leverages runtime data as metrics to construct predictive models, enabling effective fault diagnosis.
Object:
In this paper, we aim to propose new metrics, especially from the coverage view, to enhance the performance of fault diagnosis models.
Method:
We combine coverage criteria and statistical operators to propose 80 coverage metrics, which summarize the trend of coverage values in the model training procedure. We construct hybrid prediction models by combining our new coverage metrics and existing runtime metrics under four widely used classifiers.
Results:
To examine whether adding our new coverage metrics performs well in DL program fault diagnosis, we conduct our experiments on six widely used datasets under four indicators (i.e., accuracy, F1 score, AUC, and MCC). Through the experiments, we observe that (a) coverage metrics are 
not redundant
 with respect to the original runtime metrics, and (b) adding extra coverage metrics can 
significantly enhance
 the performance of fault diagnosis models.
Conclusions:
Our study shows that our proposed coverage metrics are helpful in constructing effective fault diagnosis models for DL programs.",September 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The new coverage metrics proposed to enhance the performance of fault diagnosis models for DL programs show promising results, highlighting the potential for effective fault diagnosis in real-world applications."
https://www.sciencedirect.com/science/article/pii/S095058492400082X,Machine learning for requirements engineering (ML4RE): A systematic literature review complemented by practitioners’ voices from Stack Overflow,Tong=Li: litong@bjut.edu.cn; Xinran=Zhang: zhangxinran028@gmail.com; Yunduo=Wang: wangyunduo@buaa.edu.cn; Qixiang=Zhou: qixiang.zho@gmail.com; Yiting=Wang: wangyiting.official@gmail.com; Fangqi=Dong: dfq902@gmail.com,"Abstract
Context:
The research of 
machine learning
 for 
requirements engineering
 (ML4RE) has attracted more and more attention from researchers and practitioners. Although pioneering research has shown the potential of using 
ML techniques
 to improve RE practices, there lacks a systematic and comprehensive literature review in academia that integrates an industrial perspective. Specifically, none of the reviews available in ML4RE have considered the grey literature, which is primarily from practitioner origin and is more reflective of the real issues and challenges faced in practice.
Objective:
In this paper, we conduct a systematic survey of academic publications in ML4RE and complement it with the practitioners’ voices from Stack Overflow to complete a comprehensive literature review. Our research objective is to provide a comprehensive view of the current research progress in ML4RE, present the main questions and challenges faced in RE practice, understand the gap between research and practice, and provide our insights into how the RE academic domain can pragmatically develop in the future.
Method:
We systematically investigated 207 academic papers on ML4RE from 2010 to 2022, along with 375 questions related to RE practices on Stack Overflow and their corresponding answers. Our analysis encompassed their trends, focused RE activities and tasks, employed solutions, and associated data. Finally, we conducted a 
joint
 analysis, contrasting the outcomes of both parts.
Results:
Based on the statistical results from collected literature, we summarize an academic roadmap and analyse the disparities, offering research recommendations. Our suggestions include the development of intelligent question-answering assistants employing 
large language models
, the integration of machine learning into industrial tools, and the promotion of collaboration between academia and industry.
Conclusion:
This study contributes by providing a holistic view of ML4RE, delineating disparities between research and practice, and proposing pragmatic suggestions to bridge the academia-industry gap.",August 2024,"Requirements engineering, Machine learning, Systematic literature review",Information and Software Technology,2025-03-21T00:00:00,5.0,"The systematic survey of academic publications in ML4RE and the inclusion of practitioners' voices provide valuable insights into the gap between research and practice, offering suggestions for future development."
https://www.sciencedirect.com/science/article/pii/S0950584924000831,Studying and recommending information highlighting in Stack Overflow answers,Shahla Shaan=Ahmed: ahmeds27@myumanitoba.ca; Shaowei=Wang: shaowei.wang@umanitoba.ca; Yuan=Tian: y.tian@queensu.ca; Tse-Hsun (Peter)=Chen: peterc@encs.concordia.ca; Haoxiang=Zhang: haoxiang.zhang@acm.org,"Abstract
Context:
Navigating the knowledge of Stack Overflow (SO) remains challenging. To make the posts vivid to users, SO allows users to write and edit posts with Markdown or 
HTML
 so that users can leverage various formatting styles (e.g., bold, italic, and code) to highlight the important information. Nonetheless, there have been limited studies on the highlighted information.
Objective:
We carried out the first large-scale 
exploratory study
 on the information highlighted in SO answers in our recent study. To extend our previous study, we develop approaches to automatically recommend highlighted content with formatting styles using 
neural network
 architectures initially designed for the 
Named Entity Recognition
 task.
Method:
In this paper, we studied 31,169,429 answers of Stack Overflow. For training recommendation models, we choose CNN-based and BERT-based models for each type of formatting (i.e., Bold, Italic, Code, and Heading) using the information highlighting dataset we collected from SO answers.
Results:
Our models achieve a precision ranging from 0.50 to 0.72 for different formatting types. It is easier to build a model to recommend Code than other types. Models for text formatting types (i.e., Heading, Bold, and Italic) suffer low recall. Our analysis of failure cases indicates that the majority of the failure cases are due to missing identification. One explanation is that the models are easy to learn the frequent highlighted words while struggling to learn less frequent words (i.g., long-tail knowledge).
Conclusion:
Our findings suggest that it is possible to develop recommendation models for highlighting information for answers with different formatting styles on Stack Overflow.",August 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,The large-scale exploratory study on the information highlighted in Stack Overflow answers and the development of recommendation models for formatting styles show potential for improving user experience and accessibility of the platform.
https://www.sciencedirect.com/science/article/pii/S0950584924000648,Architecting for sustainability of and in the cloud: A systematic literature review,Vasilios=Andrikopoulos: v.andrikopoulos@rug.nl; Sahar=Ahmadisakha: s.ahmadisakha@rug.nl,"Abstract
Context:
The interest in the intersection between 
cloud computing
 and 
sustainability
 is naturally growing as the popularity of the former makes it in many cases the 
default model
 for delivering software functionalities to end users. Furthermore, software architecture offers a fundamental route to address sustainability, with the recent shift towards recognizing sustainability as a software quality.
Objective:
Approaching the intersection between sustainability and cloud computing from the perspective of the study of software architectures, in this work we aim to collect the data necessary for us to understand the relation between these two areas as reflected in the literature. Given the lack of suitable surveys for this purpose in this paper we report on our review of the relevant literature, designed to address the question of how 
architectural solutions
 specifically for the cloud are addressing sustainability.
Methods:
Following the steps prescribed by a well-known method for this purpose on running a systematic literature review, we answer our defined research questions using both (qualitative) analysis and synthesis of data.
Results:
As a result of the review process, we are able to identify 10 solution types, 8 recurring design decisions, 11 involved architectural entities, and 17 distinct perceptions of the cloud with respect to sustainability. The adoption of reusable 
architectural tactics
 and patterns has been observed to be less prevalent than anticipated. Furthermore, certain fundamental characteristics of cloud computing, including multi-tenancy, on-demand 
resource provisioning
, and the pay-as-you-go model, have been identified across diverse cloud perceptions.
Conclusion:
Our findings point to the need for more systematic work required on developing architectural solutions specifically for cloud computing incorporating sustainability goals. We also suggest that achieving sustainability through cloud in software architecture may be feasible. Furthermore, we identify a persistent threat to further secondary studies on the same topic due to improper use of terms.",July 2024,"Cloud computing, Sustainability, Survey, Software architecture",Information and Software Technology,2025-03-21T00:00:00,4.0,"The study on the intersection between sustainability and cloud computing from a software architecture perspective provides insights into how architectural solutions are addressing sustainability, but lacks concrete practical implications for startups."
https://www.sciencedirect.com/science/article/pii/S0950584924000764,Not yet another BPM lifecycle: A synthesis of existing approaches using BPMN,Kostas=Vergidis: kvergidis@uom.edu.gr,"Abstract
Context
Business Process Management (BPM) is considered an important management approach that encompasses a set of methods for managing the business processes of an organization. To maximize the benefits of BPM, scholars have conceptualized its steps in schematic diagrams with interrelated phases called BPM lifecycles. As this approach has been established, the phenomenon of perpetual proposition of BPM lifecycles has been observed in relevant literature. This practice obscures what should be relatively straightforward: a consensus among researchers and practitioners regarding the steps that a business process should flow through during its lifecycle.
Objective
The aim of this work is to investigate the existing BPM 
lifecycle models
 proposed in literature, identify convergences and variations in these models, analyze their core components and locate common patterns that will enable the synthesis of a BPM lifecycle that is conceptualized with 
Business Process Model and Notation
 (BPMN), the community de-facto business process modeling notation.
Method
To formalize the research problem and develop the design of a solution, the Design Science Research Process (DSRP) model was adopted. To investigate the perpetual proposition of BPM lifecycles in literature, the authors conducted a Systematic Literature Review (SLR). On whether recurring patterns can emerge from the BPM lifecycles, a normalization process was introduced to homogenize the data and four metrics were used to evaluate the results. The emerging patterns were assembled into a graph that formed the basis for proposing a synthetic BPM lifecycle.
Results
The outcome of the paper is three-fold: First, the identification of four major inefficiencies of existing BPM lifecycles, namely varying 
granularity
, inconsistent nomenclature, subjective polysemy, and lack of formal conceptualization approaches. Also, a standardized definition of the inclusive steps that exist in the lifecycles by clustering the existing ones in a conceptually systematic manner. Finally, a synthetic BPM lifecycle is conceptualized that systematizes the existing concepts and their interrelations based on a formalized BPMN model in two levels of 
granularity
: a basic version that illustrates the functional and control-flow aspects of the BPM lifecycle and an enhanced version incorporating additionally the resource and data perspectives.
Conclusion
This paper proposes a BPMN-based conceptualization of the BPM lifecycle that can facilitate the management of business processes by providing enhanced clarity, improved resource management, and predefined error handling in a BPM initiative. By systematizing the control-flow, data, and resource perspective of the BPM lifecycle, stakeholders can gain a clear understanding of the sequence of steps, the interrelated data flows, and the distribution of work.",July 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The research on synthesizing BPM lifecycles using BPMN notation can provide a structured approach for managing business processes, which can be useful for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492400051X,Search-based approaches to optimizing software product line architectures: A systematic literature review,Sedigheh=Khoshnevis: Sedigheh.Khoshnevis@iau.ac.ir,"Abstract
Context
Software product line architecture (PLA) plays an important role in developing software product lines (SPLs) and other configurable systems. Search-based (SB) approaches can optimize the design of PLAs according to a given set of metrics as fitness functions. Although this area has been explored by researchers, there is a lack of synthesis of search-based PLA (SBPLA) research. A comprehensive review would offer valuable insights into previous contributions and identify areas for further research.
Objective
The objective of this work is to identify and summarize quality-assessed peer-reviewed studies on search-based PLA design from the aspects of the research scope, problems, contributions, evaluation, and open issues.
Methods
We conducted a systematic literature review based on Kitchenham's methodology. Based on a predefined search protocol we identified related studies limited to the ones published between 2000 and 2022 in journals and conference proceedings.
Results
Out of 686 initial search results, 34 papers were finally selected after a set of deep search, and criteria application activities. We provided a taxonomy of optimization problems in SBPLA and found that PLA remodularization and refactoring were the two categories most emphasized by the researchers. We also provided several other categorizations regarding contributions, research design, open issues, and other subjects of interest.
Conclusions
The interest in SBPLA design has been growing since 2014. PLA cloning and re-engineering problems have never been addressed in the literature. Performing subjective evaluation with the participation of experts from the industry will be profitable, as a complementary method to objective experimental evaluation, and therefore carrying out quanti-qualitative research.",June 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The review on search-based PLA design offers insights into optimizing software product lines, which can benefit startups in software development."
https://www.sciencedirect.com/science/article/pii/S0950584924000405,Behaviour-driven development and metrics framework for enhanced agile practices in scrum teams,Shanmugavadivu=Pichai: p.shanmugavadivu@ruraluniv.ac.in,"Abstract
Context
Agile methodologies
 highlight collaborative efforts among 
software engineering
 groups for iterative, high-quality product delivery within short timeframes. However, Scrum teams face persistent challenges in achieving these objectives, stemming from difficulties in seamless collaboration and effective communication among various roles, such as developers and testers. To address these issues, Scrum teams are increasingly adopting Behaviour-Driven Development (BDD), a testing technique fostering collaboration and shared understanding through test scenarios.
Objectives
This research investigates the adoption of BDD practices in Scrum teams and the formulation of a metrics framework tailored for optimizing Scrum practices and 
product quality
.
Methods
Employing action research, this study extends over two and half years, actively engaging Scrum team members and stakeholders to encompass their collaborative contributions, insights, and perspectives. It commences with defining a metrics framework through exploration within agile teams to measure and evaluate Scrum team performance. Subsequently, the focus shifts to implementing BDD practices systematically, employing training sessions, workshops, and iterative refinements.
Results
The results of the study emphasize the substantial role of Behaviour-Driven Development (BDD) in improving collaboration, communication, and the comprehension of requirements within the Scrum team. Concurrently, the tailored metrics framework bolsters quality assurance practices, enhancing software quality and customer satisfaction. BDD adoption expedites automation and product delivery, while the metrics framework enables informed decision-making.
Conclusions
Combining BDD practices with a custom metrics framework offers a holistic strategy for addressing Scrum challenges. Enhanced collaboration, communication, and requirements comprehension, resulting from BDD, synergize with the metrics framework to elevate Scrum teams' performance, software quality, and customer value. This research underlines the importance of adopting BDD as a testing methodology to achieve these improvements in Scrum teams.",June 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The investigation of BDD practices in Scrum teams, along with a metrics framework, can enhance collaboration and product quality, valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584924000119,Context-based statement-level vulnerability localization,Hieu Dinh=Vo: hieuvd@vnu.edu.vn; Thu-Trang=Nguyen: trang.nguyen@vnu.edu.vn,"Abstract
Context:
The number of attacks exploring software vulnerabilities has dramatically increased, which has caused various severe damages. Thus, early and accurately detecting vulnerabilities becomes essential to guarantee software quality and prevent the systems from 
malicious attacks
. Multiple automated 
vulnerability detection
 approaches have been proposed and obtained promising results. However, most studies detect vulnerabilities at a coarse-grained, i.e., file or method level. Thus, developers still have to spend significant investigation efforts on localizing vulnerable statements.
Objective:
In this paper, we introduce 
COSTA
, a novel context-based approach to localize vulnerable statements.
Method:
In particular, given a vulnerable function, 
COSTA
 identifies vulnerable statements based on their suspiciousness scores. Specifically, the suspiciousness of each statement is measured according to its semantics captured by four contexts, including 
operation context, dependence context, surrounding context
, and 
vulnerability type
.
Results:
Our experimental results on a large vulnerability dataset show that 
COSTA
 outperforms the state-of-the-art approaches up to 
96%
 in F1-score and 
167%
 in Accuracy. 
COSTA
 also surpasses these approaches up to 
two times
 in Top-1 Accuracy. Especially, 
COSTA
 obtains about 
80% at Top-3 Recall
. In other words, developers can find about 80% of the vulnerable statements by investigating only three first-ranked statements in each function.
Conclusion:
COSTA
 effectively addresses the challenge of statement-level vulnerability localization by leveraging multiple contextual features. Our experimental results show that 
COSTA
 outperforms existing state-of-the-art approaches. With the ability to accurately and efficiently identify vulnerable statements, developers can better allocate their investigation efforts, reduce the risk of potential security threats, and ensure software quality and security in real-world applications.",May 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The context-based vulnerability detection approach presented can significantly improve software security, which is crucial for startups looking to protect their products."
https://www.sciencedirect.com/science/article/pii/S0950584924000296,"Stakeholders collaborations, challenges and emerging concepts in digital twin ecosystems",Nirnaya=Tripathi: nirnaya.tripathi@oulu.fi,"Abstract
Context:
Digital twin
 (DT) ecosystems are rapidly evolving, connecting many stakeholders, such as manufacturers, customers, and application platform providers. These ecosystems require collaboration and interaction between diverse actors to create value. This study delves into the collaboration of such stakeholders within DT-focused ecosystems.
Objective:
This research aims to understand stakeholder collaboration within DT ecosystems, identify potential challenges, and provide insights for managing these stakeholders. It also seeks to define the DT ecosystem and its implications for both research and practice.
Method:
A systematic literature review was conducted, supplemented by empirical evidence gathered from interviews with DT experts who were knowledgeable about the DT ecosystem. The study also analyzed DT systems, stakeholder roles, and the challenges with ecosystem-focused DT development.
Results:
The study identified various stakeholders and their roles in adding value to a DT ecosystem. It highlighted the benefits of stakeholder collaboration, such as knowledge gain during DT system development. The research also revealed the technical and non-technical challenges encountered in ecosystem-focused DTs, emphasizing the importance of standardization as a solution. A new definition of the DT ecosystem was proposed, emphasizing its data-driven nature, interconnected DTs, stakeholder value creation, and technology enablement.
Conclusion:
Stakeholder collaboration is pivotal in DT ecosystems, with each actor playing a distinct role. Addressing challenges, especially through standardization (OPC UA and ISO 23247), can lead to more efficient and coherent DT ecosystems. The insights provided by this study can guide industries in designing, developing, and maintaining their DT ecosystems, ensuring value creation and stakeholder satisfaction. Future research avenues that emphasize the importance of understanding the challenges involved and deploy appropriate solutions were suggested.",May 2024,"Digital twin, Digital twin ecosystem, Stakeholders, Systematic literature review, Empirical study, Definition, Software development",Information and Software Technology,2025-03-21T00:00:00,6.0,"The study on stakeholder collaboration within DT ecosystems offers insights and challenges for managing diverse actors, relevant for startups engaging in digital twin technologies."
https://www.sciencedirect.com/science/article/pii/S0950584924000132,UXH-GEDAPP: A set of user experience heuristics for evaluating generative design applications,Daniela=Quiñones: daniela.quinones@pucv.cl,"Abstract
Context
Traditional building and infrastructure design methodologies are inflexible and inefficient, leading to high costs and environmental damage. Generative design, with an algorithm that provides multiple options, could be a potential solution. The challenge is creating an intuitive, user-friendly application that optimizes engineers’ time, reducing manual iterations and lead to a good 
user experience
 (UX). A method for evaluating the UX is 
heuristic evaluation
, in which heuristics are used to inspect a software product.
Objective
Since generative design applications have specific features, generic heuristics may not detect all problems related to UX. This article presents a novel set of 9 heuristics to evaluate UX in generative design applications: UXH-GEDAPP. This set is focused on evaluating both UX attributes and specific features of generative design applications.
Method
A formal methodology was used to develop the heuristics, through 7 stages: exploratory, descriptive, correlational, selection, specification, validation, and refinement. We performed 3 iterations and validated UXH-GEDAPP in 2 iterations through: 
heuristic evaluation
, 
expert judgment
, and user test. Since the methodology can be applied iteratively, we validated and refined the set to improve the proposal.
Results
The results obtained in the validation stage indicate that UXH-GEDAPP is useful and more effective than generic heuristics when evaluating generative design applications. UXH-GEDAPP allows to detect specific usability/UX problems as well as more severe problems related to generative design applications. Furthermore, 
evaluators
 made fewer errors associating the detected problems with the proposed heuristics, compared to generic sets.
Conclusion
UXH-GEDAPP is a new set of heuristics that encourages the creation and use of generative design applications with good UX. It can detect usability/UX problems and help correct them, as well as guide the development of new generative design applications for a pleasant and intuitive 
user experience
.",April 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The development of a new set of heuristics for evaluating generative design applications can significantly impact user experience and guide the development of new applications, providing practical value to early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923002306,Technical debt management automation: State of the art and future perspectives,Paris=Avgeriou: p.avgeriou@rug.nl; Elisa Yumi=Nakagawa: elisa@icmc.usp.br; Daniel=Feitosa: d.feitosa@rug.nl; João Paulo=Biazotto: j.p.biazotto@rug.nl,"Abstract
Context:
Technical debt (TD) refers to non-optimal decisions made in software projects that may lead to short-term benefits, but potentially harm the system’s maintenance in the long-term. Technical debt management (TDM) refers to a set of activities that are performed to handle TD, e.g., identification or measurement of TD. These activities typically entail tasks such as code and architectural analysis, which can be time-consuming if done manually. Thus, substantial research work has focused on automating TDM tasks (e.g., automatic identification of code smells). However, there is a lack of studies that summarize current approaches in TDM automation. This can hinder practitioners in selecting optimal automation strategies to efficiently manage TD. It can also prevent researchers from understanding the research landscape and addressing the research problems that matter the most.
Objectives:
The main objective of this study is to provide an overview of the state of the art in TDM automation, analyzing the available tools, their use, and the challenges in automating TDM.
Methods:
We conducted a 
systematic mapping study
 (SMS), following the guidelines proposed by Kitchenham et al. From an initial set of 1086 primary studies, 178 were selected to answer three research questions covering different facets of TDM automation.
Results:
We found 121 automation artifacts that can be used to automate TDM activities. The artifacts were classified in 4 different types (i.e., tools, plugins, scripts, and bots); the inputs/outputs and interfaces were also collected and reported. Finally, a conceptual model is proposed that synthesizes the results and allows to discuss the current state of TDM automation and related challenges.
Conclusion:
The research community has investigated to a large extent how to perform various TDM activities automatically, considering the number of studies and automation artifacts we identified. Nonetheless, more research is needed towards fully automated TDM, specially concerning the integration of the automation artifacts.",March 2024,"Systematic mapping study, Technical debt, Technical debt management, Tools, Automation",Information and Software Technology,2025-03-21T00:00:00,9.0,"The overview of the state of the art in technical debt management automation can greatly benefit startups by helping them select optimal automation strategies for efficient TD management, addressing a crucial need in the industry."
https://www.sciencedirect.com/science/article/pii/S0950584923002197,Experiences from conducting rapid reviews in collaboration with practitioners — Two industrial cases,Nauman Bin=Ali: nauman.ali@bth.se; Emelie=Engström: emelie.engstrom@cs.lth.se; Martin=Höst: martin.host@cs.lth.se; Sergio=Rico: Sergio.Rico@cs.lth.se,"Abstract
Context:
Evidence-based 
software engineering
 (EBSE) aims to improve research utilization in practice. It relies on systematic methods to identify, appraise, and synthesize existing research findings to answer questions of interest for practice. However, the lack of practitioners’ involvement in these studies’ design, execution, and reporting indicates a lack of appreciation for the need for knowledge exchange between researchers and practitioners. The resultant systematic literature studies often lack relevance for practice.
Objective:
This paper explores the use of Rapid Reviews (RRs), in fostering knowledge exchange between academia and 
industry
. Through the lens of two 
case studies
, we delve into the practical application and experience of conducting RRs.
Methods:
We analyzed the conduct of two rapid reviews by two different groups of researchers and practitioners. We 
collected data
 through interviews, and the documents produced during the review (like review protocols, search results, and presentations). The interviews were analyzed using thematic analysis.
Results:
We report how the two groups of researchers and practitioners performed the rapid reviews. We observed some benefits, like promoting dialogue and paving the way for future collaborations. We also found that practitioners entrusted the researchers to develop and follow a rigorous approach and were more interested in the applicability of the findings in their context. The problems investigated in these two cases were relevant but not the most immediate ones. Therefore, rapidness was not a priority for the practitioners.
Conclusion:
The study illustrates that rapid reviews can support researcher-practitioner communication and industry-academia collaboration. Furthermore, the recommendations based on the experiences from the two cases complement the detailed guidelines researchers and practitioners may follow to increase interaction and knowledge exchange.",March 2024,"Literature reviews, Systematic review, Rapid reviews, Research relevance, Industry-academia collaboration",Information and Software Technology,2025-03-21T00:00:00,8.0,"The study on Rapid Reviews in fostering knowledge exchange between academia and industry can provide valuable insights for startups looking to bridge the gap between research and practice, enhancing the impact of EBSE in early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923002318,Towards automating self-admitted technical debt repayment,Hoa Khanh=Dam: hoa@uow.edu.au; Aditya=Ghose: aditya@uow.edu.au; Abdulaziz=Alhefdhi: aa043@uowmail.edu.au,"Abstract
Context:
Self-Admitted Technical Debt (SATD) refers to the technical debt in software that is explicitly flagged, typically by the 
source code
 comment. The SATD literature has mainly focused on comprehending, describing, detecting, and recommending SATD. Most recently, there have been efforts to study the state of the code before and after removing the SATD comment. While these efforts serve as a preliminary step towards the repayment of SATD, actual attempts towards automating SATD repayment, to the best of our knowledge, are yet to be made.
Objective:
In this paper, we propose the first attempt towards direct, complete, and automated SATD repayment by providing two main contributions. The first contribution is an empirical study of how the SATD comment relates to repaying the debt. The second contribution is 
DLRepay
, our deep 
learning approach
 for SATD repayment.
Method:
We developed a SATD Repayment dataset, namely SATD-R, and established a taxonomy based on the relationship and helpfulness of the SATD comment to/in repaying the debt. In addition, we developed 
DLRepay
 which takes as an input a pair of SATD comment and code, and generates a new, TD-free code.
Results:
We found that there are five different categories in which the SATD comment relates to Technical Debt repayment. We also identify when the SATD comment has a positive and logical connection to repaying the debt, both generally and in every category. Furthermore, we illustrate the results of our SATD repayment approach across two datasets, three input types, two output types, and two 
neural networks
.
Conclusion:
The resulting taxonomy of our empirical study paves the way for research to tackle further in-depth questions concerning SATD repayment comprehension, identification, and automation. In addition, the various experimental setups we conduct provide multiple insights regarding the applicability of our SATD repayment approach.",March 2024,"Self-admitted technical debt, Software quality, Software maintenance, Software analytics, Deep learning, Technical debt repayment",Information and Software Technology,2025-03-21T00:00:00,6.0,"The attempt towards automating SATD repayment presents a novel approach, but its impact on early-stage ventures may be limited compared to other abstracts due to the early stage of research in this area."
https://www.sciencedirect.com/science/article/pii/S0950584923002082,Developer and End-User Perspectives on Addressing Human Aspects in Mobile eHealth Apps,Hourieh=Khalajzadeh: hkhalajzadeh@deakin.edu.au; John=Grundy: john.grundy@monash.edu; Li=Li: lilicoding@ieee.org; Md.=Shamsujjoha: md.shamsujjoha@monash.edu; Qinghua=Lu: qinghua.lu@data61.csiro.au,"Abstract
Context:
eHealth apps are mobile apps that help in self-management of critical illnesses, provide home-based disease management, and help with personalized care. Users of eHealth apps are naturally very diverse in terms of their 
human aspects
, e.g., their age, gender, emotional reactions to the apps, cognitive style, physical and mental challenges. Unfortunately, many eHealth apps do not take these user differences sufficiently into account, making them ineffective or even unusable.
Objective:
This paper reports a study from eHealth app stakeholders’ – developers and end-users – perspectives on critical challenges and benefits of better incorporating 
human aspects
 into eHealth app development and usage. We also investigate how different 
human aspects
 are being addressed by developers, which ones are the most important for different user groups, and which ones are currently missing/poorly handled.
Method:
A mixed-method approach that integrates qualitative and quantitative research was used for this study. We gathered and analyzed data from 240 online survey responses and 25 detailed interviews within the same study and validated the results.
Results:
We report key issues encountered in eHealth app design, difficulty in addressing different 
human aspects
, areas requiring further research and practical assistance, and recommend our findings to best address these challenges. We found addressing 
human aspects
 throughout the app development life-cycle is beneficial for more effective eHealth apps. Our findings also suggest the need for improved standards and guidelines, better developer-user collaborative culture, and better 
human aspects
 education to produce more effective eHealth apps.
Conclusion:
This paper investigates current approaches used in the eHealth app domain that take into account the 
human aspects
 of app users. The paper guides eHealth app stakeholders, future researchers, academia and industry partners be aware of 
human aspects
 related challenges and improve produce apps.",February 2024,"eHealth App, Human Aspect, User Study, App Development, Stakeholders Perspectives",Information and Software Technology,2025-03-21T00:00:00,8.0,"The study on incorporating human aspects into eHealth app development addresses critical challenges and benefits, providing practical guidance for startups to create more effective eHealth apps based on user diversity, enhancing their impact in the industry."
https://www.sciencedirect.com/science/article/pii/S0950584923002239,To change or not to change? Modeling software system interactions using Temporal Graphs and Graph Neural Networks: A focus on change propagation,Danielle=Azar: danielle.azar@lau.edu.lb,"Abstract
Context:
The world is quickly adopting new technologies and evolving to rely on software systems for the simplest tasks. This prompts developers to expand their software systems by adding new product features. However, this expansion should be cautiously tackled to prevent the degradation of the quality of the software product.
Objective:
One challenge when modifying code – whether to patch a bug or add a feature – is knowing which components will be affected by the change and amending possible misbehavior. In this context, the study of change propagation or the impact of introducing a change is needed. By investigating how changing one component may impact the functionality of a dependency (another component), developers can prevent unexpected behavior and maintain the quality of their system.
Methods:
In this work, we tackle the change propagation problem by modeling a software system as a 
temporal graph
 where nodes represent system files and edges co-changeability, i.e., the tendency of two files to change together. The 
graph representation
 is temporal so that nodes and edges can change with time, reflecting the addition of files in the system and changes in dependencies. We then employ a Temporal Graph Network and a Long Short-Term Memory model to predict which other files will be impacted by a modification performed on a file.
Results:
We test our model on software systems of different functionality, size, and nature. We compare our results to other published work, and our model shows a significantly higher ability to predict files impacted by a change.
Conclusion:
The proposed approach effectively predicts change propagation in software systems and can guide developers and software engineers in planning the change and estimating the cost in terms of time and money.",February 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The study addresses a crucial aspect of software development, predicting change propagation, which can significantly impact the quality of software systems for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923001933,A systematic mapping study of bug reproduction and localization,Matthias=Galster: matthias.galster@canterbury.ac.nz; Di=Wang: di.wang@pg.canterbury.ac.nz; Miguel=Morales-Trujillo: miguel.morales@canterbury.ac.nz,"Abstract
Context:
Identifying the root cause of a software bug and fixing it is challenging. One reason for this is that many bugs are not reproducible during bug fixing.
Objective:
We aim to provide an overview of existing works on bug reproduction and localization. We ask four research questions: RQ1: What types of problems have been studied in the area of bug reproduction and localization? RQ2: How are problems studied in previous research? RQ3: What are the main findings and outcomes of previous studies? RQ4: What are the gaps and challenges identified in previous studies?
Method:
We conducted a 
systematic mapping study
 analyzing research literature published between 2011 and 2021. The search for primary studies involved four major computer science digital libraries and resulted in 134 studies for analysis.
Results:
Regarding RQ1 we found that many studies focus on information retrieval-based approaches to support bug reproduction and localization. Regarding RQ2 we found that 
bug reports
 and 
source code
 are the typical data sources of bug reproduction and localization. Also, most studies include experiments with historical data but do not investigate ongoing projects. Regarding RQ3 we found that many studies adapt or combine existing approaches for bug reproduction and localization to improve their accuracy or applicability (e.g., combine requirements-related information and bug reports to increase information-retrieval-based techniques). Regarding RQ4 we found that existing solutions for bug reproduction and localization have rarely been integrated into the workflow of developers.
Conclusion:
Although bug reproduction and localization have been studied in quite some detail, new challenges and gaps emerge due to the evolution of software technologies and practices and the practical needs of software developers. For example, bug reproduction approaches for 
traditional web applications
 do not work well with modern “Single Page Web Applications” (SPA) and related technologies, e.g., Angular or React.",January 2024,"Bug reproduction, Bug localization, Bug fixing, Mapping study",Information and Software Technology,2025-03-21T00:00:00,7.0,"Bug reproduction and localization are common challenges in software development, and the study provides insights that can benefit early-stage ventures in improving software quality."
https://www.sciencedirect.com/science/article/pii/S0950584923001891,Microservice-based projects in agile world: A structured interview,Hüseyin=Ünlü: huseyinunlu@iyte.edu.tr,"Abstract
Context
During the last decade
,
 Microservice-based software architecture (MSSA) has been a preferred design paradigm for a growing number of companies. MSSA, specifically in the form of reactive systems, has substantial differences from the more conventional design paradigms, such as object-oriented analysis and design. Therefore, adaptation demands software organizations to transform their culture. However, there is a lack of research studies that explore 
common practices
 utilized by software companies that implement MSSAs.
Objective
In this study
,
 our goal is to get an insight into how practices such as an 
agile methodology
, software analysis, design, test, size measurement, and effort estimation are performed in software projects which embrace the Microservice-based software architecture paradigm. Together with the identification of practices utilized for the MSSA paradigm, we aim to determine the challenges organizations face to adopt microservice-based software architectures.
Method
We performed a structured interview with participants coming from 20 different organizations over different roles, domains, and countries to collect information on their views, experience, and the challenges faced.
Results
Our results reveal that organizations find 
agile development
 compatible with microservices. In general, they continue to use traditional object-oriented 
modeling notations
 for analysis and design in an abstract way. They continue to use the same subjective size measurement and effort estimation approaches that they were using previously in traditional architectures. However, they face unique challenges in developing microservices.
Conclusion
Although organizations face challenges, practitioners continue to use familiar techniques that they have been using for traditional architectures. The results provide a snapshot of the software industry that utilizes microservices.",January 2024,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The study explores the practices of organizations implementing Microservice-based software architecture, which can be valuable for startups looking to adopt this paradigm."
https://www.sciencedirect.com/science/article/pii/S0950584923001416,MDSSED: A safety and security enhanced model-driven development approach for smart home apps,Tong=Ye: yetong@nuaa.edu.cn; Yi=Zhuang: zy16@nuaa.edu.cn; Gongzhe=Qiao: qgz@nuaa.edu.cn,"Abstract
Context:
With the popularization of 
smart home devices
, people rely more on automation functions provided by 
smart home
 apps. This increases the attack surface for safety and security threats. Many of these threats are at the interaction level, caused by unintended or malicious interactions between apps.
Objective:
Most of the current studies focus on identifying unsafe interactions between 
smart home
 apps by code analysis. To the best of our knowledge, none of the existing studies focuses on enhancing the safety and security of smart home apps under interaction threats in the design phase. To fill this gap, this paper presents MDSSED, a safety and security enhanced model-driven development approach for smart home apps.
Method:
First, this paper identifies eleven types of interaction threats faced by smart home apps. Second, the MDSSED profile is proposed to support modeling smart home apps using 
UML
. Third, the MDSSED prototype tool is developed to generate threat models and corresponding safety and security properties automatically. Then, the safety and security properties are automatically verified by model checking. Finally, the MDSSED tool automatically converts the 
UML models
 to the Samsung SmartThings apps.
Results:
To evaluate the accuracy and effectiveness of MDSSED, this paper uses the benchmarks in existing state-of-the-art studies. The results show that MDSSED not only identified the safety and security problems in the existing benchmarks but also pointed out vulnerabilities of apps under other interaction threats identified in this paper.
Conclusion:
To the best of our knowledge, MDSSED is the first model-driven development approach that supports the automatic verification of the safety and security properties of smart home apps under interaction threats. The accuracy, practicality, and efficiency of MDSSED are corroborated by experiments. The 
source code
 of the MDSSED tool and the experimental data are available online.
1",November 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"MDSSED presents a model-driven development approach for enhancing safety and security in smart home apps, addressing interaction threats at the design phase, which is crucial for startups focusing on smart home device development."
https://www.sciencedirect.com/science/article/pii/S0950584923001805,The role of Reinforcement Learning in software testing,Amr=Abo-eleneen: aa1405465@student.qu.edu.qa; Ahammed=Palliyali: ap1304567@student.qu.edu.qa; Cagatay=Catal: ccatal@qu.edu.qa,"Abstract
Context:
Software testing is applied to validate the behavior of the software system and identify flaws and bugs. Different 
machine learning technique
 types such as supervised and 
unsupervised learning
 were utilized in software testing. However, for some complex software testing scenarios, neither supervised nor unsupervised machine learning techniques were adequate. As such, researchers applied 
Reinforcement Learning
 (RL) techniques in some cases. However, a 
systematic overview
 of the state-of-the-art on the role of reinforcement learning in software testing is lacking.
Objective:
The objective of this study is to determine how and to what extent RL was used in software testing.
Methods:
In this study, a Systematic Literature Review (SLR) was conducted on the use of RL in software testing, and 40 primary studies were investigated.
Results:
This study highlights different software testing types to which RL has been applied, commonly used RL algorithms and architecture for learning, challenges faced, advantages and disadvantages of using RL, and the performance comparison of RL-based models against other techniques.
Conclusions:
RL has been widely used in software testing but has almost narrowed to two applications. There is a shortage of papers using advanced RL techniques in addition to multi-agent RL. Several challenges were presented in this study.",December 2023,"Software testing, Machine learning, Reinforcement Learning, Artificial intelligence",Information and Software Technology,2025-03-21T00:00:00,7.0,The use of Reinforcement Learning in software testing is an innovative approach that can benefit early-stage ventures in improving testing efficiency and accuracy.
https://www.sciencedirect.com/science/article/pii/S0950584923001702,Towards a successful secure software acquisition,Mahmood=Niazi: mkniazi@kfupm.edu.sa,"Abstract
Context
Security is a critical attribute 
of software quality
. Organizations invest considerable sums of money in protecting their assets. Despite investing in secure infrastructure, organizations remain prone to security risks and cyberattacks that exploit security flaws. Many factors contribute to the challenges related to software security, e.g., the exponential increase in Internet-enabled applications, threats from hackers, and the susceptibility of inexperienced Internet users. Moreover, organizations tend to procure off-the-shelf software from third-party suppliers. However, gaining a complete understanding of ways to assess suppliers’ readiness to provide secure software before selecting a supplier is imperative.
Objective
We have developed a readiness model for secure software acquisition (RMSSA) to help software organizations select suppliers who can provide secure software.
Method
We employed state-of-the-art techniques based on systematic literature review to determine the best practices undertaken by organizations in terms of acquiring secure software, which depends on six core security knowledge areas: confidentiality, integrity, availability, authorization, 
authentication
, and accountability.
Results
We evaluated the RMSSA theoretically and in a practical environment based on three 
case studies
 with software organizations. Our findings can guide software organizations in selecting the supplier who can develop secure software.
Conclusion
The proposed RMSSA can be used to evaluate suppliers’ readiness to provide secure software.",December 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The readiness model for secure software acquisition (RMSSA) offers valuable insights for organizations looking to enhance their software security measures, which are crucial for startups dealing with sensitive data."
https://www.sciencedirect.com/science/article/pii/S0950584923001635,Auto-COP: Adaptation generation in Context-oriented Programming using Reinforcement Learning options,Nicolás=Cardozo: n.cardozo@uniandes.edu.co; Ivana=Dusparic: ivana.dusparic@scss.tcd.ie,"Abstract
Context:
Self-adaptive software systems continuously adapt in response to internal and external changes in their execution environment, captured as contexts. The Context-oriented Programming (COP) paradigm posits a technique for the development of self-adaptive systems, capturing their main characteristics with specialized programming language constructs. In COP, adaptations are specified as independent modules that are composed in and out of the base system as contexts are activated and deactivated in response to sensed circumstances from the surrounding environment. However, the definition of adaptations, their contexts and associated specialized behavior, need to be specified at design time. In complex cyber–physical systems this is intractable, if not impossible, due to new unpredicted operating conditions arising.
Objective:
In this paper, we propose Auto-COP, a new technique to enable generation of adaptations at run time. Auto-COP uses 
Reinforcement Learning
 (RL) options to build action sequences, based on the previous instances of the system execution (for example, atomic system actions enacted by human operators). Options are further explored in interaction with the environment, and the most suitable options for each context are used to generate the adaptations, exploiting COP abstractions.
Method:
To validate Auto-COP, we present two 
case studies
 exhibiting different system characteristics and application domains: a driving assistant and a robot delivery system. We present examples of Auto-COP to illustrate the types of circumstances (contexts) requiring adaptation at run time, and the corresponding generated adaptations for each context.
Results:
We confirm that the generated adaptations exhibit correct 
system behavior
 measured by domain-specific performance metrics (
e.g.,
 conformance to specified speed limit), while reducing the number of required execution/actuation steps by a factor of two showing that the adaptations are regularly selected by the running system as adaptive behavior is more appropriate than the execution of 
atomic actions
.
Conclusion:
Therefore, we demonstrate that Auto-COP is able to increase system adaptivity by enabling run-time generation of new adaptations for conditions detected at run time, while retaining the modularity offered by COP languages, and reducing the upfront specification required by system developers.",December 2023,"Context-oriented programming, Reinforcement learning, Macro actions, Option learning, Self-adaptive systems",Information and Software Technology,2025-03-21T00:00:00,7.0,"Auto-COP introduces a new technique for run-time generation of adaptations, increasing system adaptivity and reducing upfront specifications, which can benefit early-stage ventures in complex systems."
https://www.sciencedirect.com/science/article/pii/S0950584923001878,Towards accurate recommendations of merge conflicts resolution strategies,Paulo=Elias: pauloe@id.uff.br; Heleno de S.=Campos: helenocampos@id.uff.br; Eduardo=Ogasawara: eogasawara@ieee.org; Leonardo Gresta Paulino=Murta: leomurta@ic.uff.br,"Abstract
Context:
in 
software engineering
, developers working concurrently on a project frequently need to merge changes in the source code. The manual resolution of merge conflicts is a laborious and time-consuming task. Some studies have investigated the nature of merge conflicts and proposed methods to predict, mitigate, and resolve conflicts. However, the automatic resolution of conflicts is still an open problem.
Objective:
in this paper, we design and evaluate MESTRE (MErge STrategy REcommender), a conflict resolution strategy recommender that predicts the merge resolution strategy among version 1, version 2, concatenation of version 1 and 2, concatenation of version 2 and 1, combination of lines from version 1 and 2, and manually writing new code. For the first four strategies, MESTRE is able to not only recommend the strategy but also automatically resolve the conflict.
Methods:
we 
collected data
 from 20 open-source projects with more than 1000 merge conflicts each. Using this data, we trained and evaluated a separate classifier for each project to predict the conflict resolution strategy for a conflicting chunk.
Results:
MESTRE achieved an overall average accuracy of 80.8% among all projects. It represents a normalized improvement of 54.8% over the 
majority class
 baseline. Furthermore, since MESTRE can provide the exact conflict resolution for the most frequent conflict resolution strategies, it could automatically resolve 70.5% of the conflicts. We also found that 
attributes related
 to the conflicting chunk notably impact the 
classification accuracy
 more than those related to the merge and the file.
Conclusion:
This paper makes the following contributions: (1) MESTRE, a tool to predict merge conflict resolutions based on attributes of a Git repository; (2) an analysis of the relevance of attributes to the prediction of resolution strategies; and (3) an ablation study to find the contribution of each group of attributes to MESTRE’s performance.",December 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"MESTRE provides a conflict resolution strategy recommender with high accuracy and automatic resolution capabilities, which can streamline development processes for startups working on collaborative projects."
https://www.sciencedirect.com/science/article/pii/S0950584923001532,Code review guidelines for GUI-based testing artifacts,Riccardo=Coppola: riccardo.coppola@polito.it; Emil=Alégroth: emil.alegroth@bth.se; Tony=Gorschek: tony.gorschek@bth.se; Andreas=Bauer: andreas.bauer@bth.se,"Abstract
Context:
Review of software artifacts, such as source or test code, is a 
common practice
 in industrial practice. However, although review guidelines are available for source and low-level test code, for GUI-based testing artifacts, such guidelines are missing.
Objective:
The goal of this work is to define a set of guidelines from literature about production and test code, that can be mapped to GUI-based testing artifacts.
Method:
A systematic literature review is conducted, using white and gray literature to identify guidelines for source and test code. These synthesized guidelines are then mapped, through examples, to create actionable, and applicable, guidelines for GUI-based testing artifacts.
Results:
The results of the study are 33 guidelines, summarized in nine guideline categories, that are successfully mapped as applicable to GUI-based testing artifacts. Of the collected literature, only 10 sources contained test-specific code review guidelines. These guideline categories are: 
perform automated checks, use checklists, provide context information, utilize metrics, ensure readability, visualize changes, reduce complexity, check conformity with the requirements
 and 
follow design principles and patterns
.
Conclusion:
This pivotal set of guidelines provides an industrial contribution in filling the gap of general guidelines for review of GUI-based testing artifacts. Additionally, this work highlights, from an academic perspective, the need for future research in this area to also develop guidelines for other specific aspects of GUI-based testing practice, and to take into account other facets of the review process not covered by this work, such as reviewer selection.",November 2023,"GUI testing, GUI-based testing, Software testing, Code review, Modern code review, Guidelines, Practices",Information and Software Technology,2025-03-21T00:00:00,5.0,"The guidelines for review of GUI-based testing artifacts can provide valuable insights for software companies, but may have limited direct impact on early-stage ventures compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923001192,Information needs and presentation in agile software development,Henri=Bomström: henri.bomstrom@oulu.fi; Markus=Kelanti: markus.kelanti@oulu.fi; Elina=Annanperä: elina.annanpera@oulu.fi; Kari=Liukkunen: kari.liukkunen@oulu.fi; Terhi=Kilamo: terhi.kilamo@tuni.fi; Outi=Sievi-Korte: outi.sievi-korte@tuni.fi; Kari=Systä: kari.systa@tuni.fi,"Abstract
Context:
Agile software companies applying the 
DevOps
 approach require collaboration and information sharing between practitioners in various roles to produce value. Adopting new development practices affects how practitioners collaborate, requiring companies to form a closer connection between business strategy and software development. However, the types of information management, sales, and development needed to plan, evaluate features, and reconcile their expectations with each other need to be clarified.
Objective:
To support practitioners in collaborating and realizing changes to their practices, we investigated what information is needed and how it should be represented to support different stakeholders in their tasks. Compared to earlier research, we adopted a holistic approach – by including practitioners throughout the 
development process
 – to better understand the information needs from a broader viewpoint.
Method:
We conducted six workshops and 12 semi-structured interviews at three Finnish small and medium-sized enterprises from different software domains. Thematic analysis was used to identify information-related issues and information and visualization needs for daily tasks. Three themes were constructed as the result of our analysis.
Results:
Visual information representation catalyzes stakeholder discussion, and supporting information exchange between 
stakeholder groups
 is vital for efficient collaboration in software product development. Additionally, user-centric data collection practices are needed to understand how software products are used and to support practitioners’ daily information needs. We also found that a passive way of representing information, such as a dashboard that would disturb practitioners only when attention is needed, was preferred for daily information needs.
Conclusion:
The 
software engineering
 community should consider reviewing the information needs of practitioners from a more holistic view to better understand how tooling support can benefit information exchange between stakeholder groups when making product development decisions and how those tools should be built to accommodate different stakeholder views.",October 2023,"Software engineering, Agile software development, DevOps, Information needs, Visualization",Information and Software Technology,2025-03-21T00:00:00,4.0,"The investigation on information needs for collaboration in software development, while important, may have a more indirect impact on startups compared to other more specific and actionable abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000988,A mixed method study of DevOps challenges,Minaoar Hossain=Tanzil: minaoar.tanzil@ucalgary.ca,"Abstract
Context:
DevOps
 practices combine software development and IT (Information Technology) operations. The continuous needs for rapid but quality software development requires the adoption of high-quality 
DevOps
 tools. There is a growing number of DevOps related posts in popular online developer forum Stack Overflow (SO). While previous research analyzed SO posts related to build/release engineering, we are aware of no research that specifically focused on DevOps related discussions.
Objective:
This paper aims to learn the challenges developers face while using the currently available DevOps tools and techniques along with the organizational challenges in DevOps practices.
Method:
We conduct an empirical study by applying 
topic modeling
 on 174K SO posts that contain DevOps discussions. We then validate and extend the empirical study findings with a survey of 21 professional DevOps practitioners.
Results:
We find that: (1) There are 23 DevOps topics grouped into four categories: Cloud & CI/CD Tools, Infrastructure as Code, Container & Orchestration, and Quality Assurance. (2) The topic category ‘Cloud & CI/CD Tools’ contains the highest number of topics (10) which cover 48.6% of all questions in our dataset, followed by the category Infrastructure as Code (28.9%). (3) The file management is the most popular topic followed by Jenkins Pipeline, while infrastructural Exception Handling and Jenkins Distributed Architecture are the most difficult topics (with least accepted answers). (4) In the survey, developers mention that it requires hands-on experience before current DevOps tools can be considered easy. They raised the needs for better documentation and learning resources to learn the rapidly changing DevOps tools and techniques. Practitioners also emphasized on the formal training approach by the organizations for DevOps skill development.
Conclusion:
Architects and managers can use the findings of this research to adopt appropriate DevOps technologies, and organizations can design tool or process specific DevOps training programs.",September 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The research on DevOps challenges and practices can provide valuable insights for early-stage ventures in improving software development processes and tool adoption.
https://www.sciencedirect.com/science/article/pii/S095058492300071X,BERT- and TF-IDF-based feature extraction for long-lived bug prediction in FLOSS: A comparative study,Luiz Alberto Ferreira=Gomes: luizgomes@pucpcaldas.br; Ricardo=da Silva Torres: ricardo.torres@ntnu.no; Mario Lúcio=Côrtes: cortes@ic.unicamp.br,"Abstract
Context:
The correct prediction of long-lived bugs could help 
maintenance teams
 to build their plan and to fix more bugs that often adversely affect software quality and disturb the 
user experience
 across versions in Free/Libre Open-Source Software (FLOSS). 
Machine Learning
 and Text Mining methods have been applied to solve many real-world prediction problems, including 
bug report
 handling.
Objective:
Our research aims to compare the accuracy of ML classifiers on long-lived bug prediction in FLOSS using 
Bidirectional Encoder Representations from Transformers
 (BERT)- and Term Frequency - 
Inverse Document Frequency
 (TF-IDF)-based feature extraction. Besides that, we aim to investigate BERT variants on the same task.
Method:
We collected bug reports from six popular FLOSS and used the 
Machine Learning
 classifiers to predict long-lived bugs. Furthermore, we compare different feature extractors, based on BERT and TF-IDF methods, in long-lived bug prediction.
Results:
We found that long-lived bug prediction using BERT-based feature extraction systematically outperformed the TF-IDF. The 
SVM
 and 
Random Forest
 outperformed other classifiers in almost all datasets using BERT. Furthermore, smaller BERT architectures show themselves as competitive.
Conclusion:
Our results demonstrated a promising avenue to predict long-lived bugs based on BERT contextual embedding features and fine-tuning procedures.",August 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The use of Machine Learning techniques and BERT for bug prediction in FLOSS can significantly impact the quality and maintenance of software, which can benefit early-stage ventures in improving their software products."
https://www.sciencedirect.com/science/article/pii/S0950584923000708,The lifecycle of Technical Debt that manifests in both source code and issue trackers,Paris=Avgeriou: p.avgeriou@rug.nl; Daniel=Feitosa: d.feitosa@rug.nl; Jie=Tan: j.tanjie@outlook.com,"Abstract
Context:
Although Technical Debt (TD) has increasingly gained attention in recent years, most studies exploring TD are based on a single source (e.g., source code, code comments or issue trackers).
Objective:
Investigating information combined from different sources may yield insight that is more than the sum of its parts. In particular, we argue that exploring how TD items are managed in both issue trackers and software repositories (including source code and commit messages) can shed some light on what happens between the commits that incur TD and those that pay it back.
Method:
To this end, we randomly selected 3,000 issues from the trackers of five projects, manually analyzed 300 issues that contained TD information, and identified and investigated the lifecycle of 312 TD items.
Results:
The results indicate that most of the TD items marked as resolved in issue trackers are also paid back in source code, although many are not discussed after being identified in the issue tracker. Test Debt items are the least likely to be paid back in source code. We also learned that although TD items may be resolved a few days after being identified, it often takes a long time to be identified (around one year). In general, time is reduced if the same developer is involved in consecutive moments (i.e., introduction, identification, repayment decision-making and remediation), but whether the developer who paid back the item is involved in discussing the TD item does not seem to affect how quickly it is resolved.
Conclusions:
Investigating how developers manage TD across both 
source code repositories
 and issue trackers can lead to a more comprehensive oversight of this activity and support efforts to shorten the lifecycle of undesirable debt.",July 2023,"Technical Debt, Source code, Issue tracker",Information and Software Technology,2025-03-21T00:00:00,6.0,"The study on Technical Debt management can provide valuable insights for startups on how to effectively manage technical debt in their software development process, thereby improving product quality and reducing maintenance costs."
https://www.sciencedirect.com/science/article/pii/S0950584923000289,Double-counting in software engineering tertiary studies — An overlooked threat to validity,Jürgen=Börstler: jurgen.borstler@bth.se; Nauman Bin=Ali: nauman.ali@bth.se; Kai=Petersen: kai.petersen@bth.se,"Abstract
Context:
Double-counting in a literature review occurs when the same data, population, or evidence is erroneously counted multiple times during synthesis. Detecting and mitigating the threat of double-counting is particularly challenging in tertiary studies. Although this topic has received much attention in the health sciences, it seems to have been overlooked in 
software engineering
.
Objective:
We describe issues with double-counting in tertiary studies, investigate the prevalence of the issue in software engineering, and propose ways to identify and address the issue.
Method:
We analyze 47 tertiary studies in software engineering to investigate in which ways they address double-counting and whether double-counting might be a threat to validity in them.
Results:
In 19 of the 47 tertiary studies, double-counting might bias their results. Of those 19 tertiary studies, only 5 consider double-counting a threat to their validity, and 7 suggest strategies to address the issue. Overall, only 9 of the 47 tertiary studies, acknowledge double-counting as a potential general threat to validity for tertiary studies.
Conclusions:
Double-counting is an overlooked issue in tertiary studies in software engineering, and existing design and evaluation guidelines do not address it sufficiently. Therefore, we propose recommendations that may help to identify and mitigate double-counting in tertiary studies.",June 2023,"Bias, Double-counting, Empirical, Guidelines, Meta-review, Overview of reviews, Recommendations, Research methods, Review of reviews, Tertiary review, Tertiary study, Umbrella review",Information and Software Technology,2025-03-21T00:00:00,5.0,"The investigation on double-counting in tertiary studies in software engineering may have limited direct practical impact on early-stage ventures, as the issue is more academic in nature."
https://www.sciencedirect.com/science/article/pii/S0950584923000228,SedSVD: Statement-level software vulnerability detection based on Relational Graph Convolutional Network with subgraph embedding,Yukun=Dong: dongyk@upc.edu.cn,"Abstract
Context:
Current deep-learning based 
vulnerability detection
 methods have been proven more automatic and correct to a certain extent, nonetheless, they are limited to detect at function-level or file-level, which can hinder software developers from acquiring more detailed information and conducting more targeted repairs. Graph-based detection methods have shown dominant performance over others. Unfortunately, the information they reveal has not been fully utilized.
Objective:
We design SedSVD (Subgraph embedding driven Statement-level Vulnerability Detection) with two objectives: (i) to better utilize the information the code-related graphs can reflect; (ii) to detect vulnerabilities at a finer-grained level.
Method:
In our work, we propose a novel graph-based detection framework that embeds graphs at subgraph-level to realize statement-level detection. It first leverages Code Property Graph (CPG) to learn both semantic and 
syntactic information
 from source code, and then selects several center nodes (code elements) in CPG to build their subgraphs. After embedding each subgraph with its nodes and edges, we apply Relational 
Graph Convolutional Network
 (RGCN) to process different edges differently. A Multi-Layer 
Perceptron
 (MLP) layer is further added to ensure its prediction performance.
Results:
We conduct our experiments on C/C++ projects from NVD and SARD. Experimental results show that SedSVD achieves 95.15% in F1-measure which proves our work to be more effective.
Conclusion:
Our work detects at a finer-grained level and achieves higher F1-measure than existing state-of-art 
vulnerability detection
 techniques. Besides, we provide a more detailed detection report pointing the specific error code elements within statements.",June 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The development of SedSVD for statement-level vulnerability detection with high F1-measure can greatly benefit startups by providing more accurate and detailed vulnerability detection in their software products.
https://www.sciencedirect.com/science/article/pii/S0950584923000265,Scripted and scriptless GUI testing for web applications: An industrial case,,"Abstract
Context:
Automation is required in the software development to reduce the high costs of producing software and to address the short release cycles of modern 
development processes
. Lot of effort has been performed to automate testing, which is one of the most resource-consuming development phases. Automation of testing through the Graphical User Interface (GUI) has been researched to improve the system testing.
Objective:
We aim to evaluate the complementarity of automated GUI testing tools in a real industrial context, which refers to the capability of the tools to work usefully together.
Methods:
To address the objective, we conduct an exploratory 
case study
 in an IT development company from The Netherlands. We select two representative tools for automated GUI testing, one for scripted and another for scriptless testing. We measure the complementarity by measuring the effectiveness, the efficiency, and 
subjective satisfaction
 of the tools.
Results:
It can be observed that the scripted tool performs better in detecting process failures, and the scriptless tool performs better in detecting visible failures and also reaching higher coverage. Both tools perform in a similar way in terms of efficiency. Additionally, both tools were perceived to be useful in the survey performed for the subjective satisfaction.
Conclusion:
We conclude that scriptless and scripted testing approaches are complementary, and they can improve the effectiveness compared to manual testing processes performed in an industrial context by detecting different failures and reducing the effort and time to find these failures and to reproduce them.",June 2023,"Case study, Complementarity, Scriptless testing, Scripted testing",Information and Software Technology,2025-03-21T00:00:00,6.0,The evaluation of automated GUI testing tools in an industrial context can provide valuable insights for startups looking to streamline their testing processes.
https://www.sciencedirect.com/science/article/pii/S0950584923000435,Application of Project-Based Learning to a Software Engineering course in a hybrid class environment,Edgar=Ceh-Varela: eduardo.ceh@enmu.edu; Carlos=Canto-Bonilla: carlos.canto@utmetropolitana.edu.mx; Dhimitraq=Duni: dhimitraq.duni@enmu.edu,"Abstract
Context:
This paper centers on Project-Based Learning (PBL). In PBL, the student is now the center of the whole 
teaching and learning
 process, while the instructor‘s role is now of a facilitator presenting to the students the resources and guidance to solve the given problem. Most existing studies, apply PBL to courses having in-person students.
Objective:
The paper presents the application of a 
PBL approach
 to a Software Engineering (SE) course having a hybrid class environment (i.e., online and in-person students). The main objective of this paper is to analyze the students’ attitudes after experiencing working on a real-life problem as part of our 
PBL approach
 in a hybrid class environment.
Methods:
We propose a 
relaxed plan-based
 software development model as basis for guiding the project execution. At the end of the course, we applied a survey to the students to evaluate their experience in the course.
Results:
We obtained the answers of 70.8% of students taking a 
SE
 course. With these answers, we could measure the students’ perception of using PBL in a 
SE
 course and how this strategy helped them to gain soft and hard skills in software development. We divided the answers for their analysis into different categories: soft skills, technical skills, 
learning experience
, and other results. Moreover, we compare the performance of the teams and students based on their type (i.e., online and in-person).
Conclusion:
We found qualitative differences in the experience of online and in-person students. Based on our experience with this study, we provide guidelines for applying PBL in a hybrid environment. Overall, our study has demonstrated a positive contribution in supporting teaching SE using a PBL in a hybrid class environment.",June 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The application of PBL in a hybrid class environment for teaching SE can offer useful guidelines for startups focusing on innovative educational approaches.
https://www.sciencedirect.com/science/article/pii/S0950584922002415,An expressive and modular layer activation mechanism for Context-Oriented Programming,Paul=Leger: pleger@ucn.cl,"Abstract
Context.
There is a trend in the software industry towards 
building systems
 that dynamically adapt their behavior in response to their surrounding environment, given the proliferation of various technological devices, such as notebooks, smartphones, and wearables, capable of capturing their execution context. Context-oriented Programming (COP) allows developers to use layer abstractions to adapt software behavior to the context. A layer is associated with a context and can be dynamically activated in direct response to gathered information from its surrounding execution environment. However, most existing layer activation mechanisms have been tailored specifically to address a particular concern; implying that developers need to tweak layer definitions in contortive ways or create new specialized activation mechanisms altogether if their specific needs are not supported.
Objective.
Complementing ideas to expressively declare activation mechanism models with interfaces that define conditionals of activation mechanisms modularly, this paper proposes an Expressive and Modular Activation mechanism, named EMA.
Method.
To propose EMA, we analyze existing activation mechanisms in COP regarding activation features and scope strategies. After, we propose the design of EMA and validate it with a 
case study
 discussion.
Results.
Using a concrete JavaScript implementation of EMA, named EMAjs, we can implement two Web applications: a 
smartphone application
 as an example to illustrate EMAjs in action, and an application of home automation to discuss and compare our proposal.
Conclusions.
Our proposed mechanism allows developers to instantiate different activation scope strategies and interfaces to decouple the declaration of activation mechanism conditionals from the base code.",April 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The proposed EMA mechanism can be insightful for startups developing adaptive software systems, but may have limited immediate practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000010,How SonarQube-identified technical debt is prioritized: An exploratory case study,Reem=Alfayez: reealfayez@ksu.edu.sa,"Abstract
Context:
Repaying all technical debt (TD) in a system may be unviable, as there is typically a shortage of resources allocated for 
TD repayment
 activities. Therefore, TD prioritization is essential to best allocate such limited resources. Fortunately, one can utilize a 
static code analysis tool
, such as SonarQube, to aid in expediting the TD prioritization process.
Objective:
Given that SonarQube is one of the most utilized tools in the context of TD, this exploratory 
case study
 seeks to explore how SonarQube-identified TD items are perceived and prioritized for repayment.
Methods:
The study was designed, replicated, and conducted in four companies and a master’s level course, with a total of 89 participants. The participants were requested to select TD items to include for repayment under a 
resources constraint
.
Results:
The results revealed that the overwhelming majority of participants prioritized TD by factoring in a TD item’s value and cost, a smaller number prioritized higher value TD items, and only one participant prioritized lower cost TD items. Furthermore, it was revealed that the value of a TD item is subjective and context-dependent, and the majority of participants perceive the 
cost estimations
 provided by SonarQube for repaying TD items to be reliable and trustworthy when prioritizing TD.
Conclusion:
Based on the results, one can conclude that there is no silver bullet TD prioritization approach that addresses all of a developer’s objectives and needs. New TD prioritization approaches should be designed without concentrating on a specific prioritization perspective and should be independent of value estimation methods.",April 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The exploration of TD prioritization using SonarQube can directly benefit startups dealing with resource constraints and technical debt management.
https://www.sciencedirect.com/science/article/pii/S095058492200252X,Probabilistic program performance analysis with confidence intervals,Ioannis=Stefanakos: ioannis.stefanakos@york.ac.uk,"Abstract
Context:
More often than not, the algorithms implemented by software systems continue to operate correctly when executed on different platforms or with different inputs, and can be easily replaced with functionally equivalent ones. However, such changes can have a significant and difficult to predict impact on the software performance, resource use, and other key quality properties.
Objective:
The paper introduces a method for the formal analysis of timing, resource use, cost and other 
quality aspects
 of computer programs, and a tool that automates the application of the method to Java code.
Method:
A tool-supported 
p
robabilistic p
ro
gram 
per
formance analysis (PROPER) method was developed, and was evaluated using Java code from the Apache Commons Math library, the 
Android
 messaging app Telegram, and open-source implementations of the 
knapsack
, binary search, and minimum path sum algorithms. PROPER synthesises a parametric Markov-chain model of the analysed code, uses information from program logs to calculate confidence intervals for the parameters of this model, and employs 
formal verification
 with confidence intervals to obtain confidence intervals for the performance properties of interest. A PROPER variant that operates with point estimates instead of confidence intervals can be used when large program logs are available.
Results:
The PROPER point estimates for the analysed performance properties were accurate within 7.9% and 1.75% of the ground truth when using program logs with 
 and 
 entries, respectively. All PROPER confidence intervals for these properties contained the true property value, and became narrower when larger logs were used in the analysis. The analyses were completed in under 15 ms for point estimates, and in between 6.7 s and 7.8 s for confidence intervals on a regular laptop computer.
Conclusion:
PROPER can synthesise and reuse a parametric Markov model to accurately predict how software performance would change if the code ran on a different hardware platform, used a new function library, or had a different usage profile—supporting practitioners who are interested in these analyses.",April 2023,"Program quality analysis, Software performance, Discrete-time Markov chains, Probabilistic model checking, Formal verification with confidence intervals",Information and Software Technology,2025-03-21T00:00:00,4.0,The formal analysis method for computer program quality aspects may have limited applicability and immediate impact for startups in early stages.
https://www.sciencedirect.com/science/article/pii/S0950584922002208,Detecting code smells in React-based Web apps,Fabio=Ferreira: fabio.ferreira@ifsudestemg.edu.br,"Abstract
Context:
Facebook’s 
React
 is a widely popular 
JavaScript library
 to build rich and 
interactive user interfaces
 (UI). However, due to the complexity of modern Web UIs, 
React
 applications can have hundreds of components and 
source code
 files. Therefore, front-end developers are facing increasing challenges when designing and modularizing 
React
-based applications. As a result, it is natural to expect 
maintainability
 problems in 
React
-based UIs due to suboptimal design decisions.
Objective:
To help developers with these problems, we propose a catalog with twelve 
React
-related code smells and a prototype tool to detect the proposed smells in 
React
-based Web apps.
Method:
The smells were identified by conducting a grey literature review and by interviewing six professional software developers. We also use the tool in the top-10 most popular GitHub projects that use 
React
 and conducted a historical analysis to check how often developers remove the proposed smells.
Results:
We detect 2,565 instances of the proposed code smells. The results show that the removal rates range from 0.9% to 50.5%. The smell with the most significant removal rate is 
Large File
 (50.5%). The smells with the lowest removal rates are 
Inheritance Instead of Composition (IIC)
 (0.9%), and 
Direct DOM Manipulation
 (14.7%).
Conclusion:
The list of 
React
 smells proposed in this paper as well as the tool to detect them can assist developers to improve the 
source code
 quality of 
React
 applications. While the catalog describes common problems with 
React
 applications, our tool helps to detect them. Our historical analysis also shows the importance of each smell from the developers’ perspective, showing how often each smell is removed.",March 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The study provides valuable insights into common Code Smells in React applications and offers a tool to help developers improve source code quality, which can be beneficial for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002178,Enterprise architecture artifacts as boundary objects: An empirical analysis,Svyatoslav=Kotusev: kotusev@kotusev.com,"Abstract
Context
Enterprise architecture (EA) is a collection of artifacts describing various aspects of an organization from an integrated business and IT perspective. EA artifacts intend to bridge the communication gap between business and IT stakeholders to improve business and IT alignment in organizations and, therefore, can be considered as 
boundary objects
 between diverse business and IT communities. However, an intentional analysis of EA artifacts as boundary objects in the current EA literature has been rather shallow and insufficient.
Objective
This study aims to explore how exactly EA artifacts as boundary objects facilitate communication between different professional communities. Specifically, it intends to identify what types of EA artifacts represent boundary objects, analyze their properties and 
usage scenarios
, as well as the differences between them.
Method
This study is based on an in-depth case study of an organization with an established EA practice. 
Data collection procedures
 include both interviews with various participants of its EA practice and comprehensive scrutiny of its EA documentation.
Results
We identify five specific types of EA artifacts used in the organization as boundary objects and analyze them in detail. In particular, we analyze their 
informational contents
 and usage scenarios, their target audiences and value for cross-community collaboration, as well as their 
syntactic
, semantic and pragmatic boundary-spanning capacity. Moreover, we also introduce the notion of duality as a characteristic of interpretive flexibility of EA artifacts and distinguish two different types of duality leveraging somewhat different boundary-spanning mechanisms: implicit duality and explicit duality.
Conclusions
This paper provides arguably the first inductive qualitative analysis of EA artifacts as boundary objects available in the existing EA literature. It contributes to our understanding of their boundary-spanning properties, distinctive features and general roles in an EA practice. Also, the concepts of implicit and explicit duality that we introduce further advance the theory of boundary objects.",March 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The research on Enterprise Architecture artifacts as boundary objects contributes to improving communication between business and IT stakeholders, which can have a significant impact on the alignment and success of early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001653,"Concerns identified in code review: A fine-grained, faceted classification",Sanuri=Gunawardena: sanuri.gunawardena@auckland.ac.nz; Ewan=Tempero: e.tempero@auckland.ac.nz; Kelly=Blincoe: k.blincoe@auckland.ac.nz,"Abstract
Context:
Code review is a valuable software process that helps software practitioners to identify a variety of defects in code. Even though many code review tools and 
static analysis
 tools used to improve the efficiency of the process exist, code review is still costly.
Objective:
Understanding the types of defects that code reviews help to identify could reveal other means of cost improvement. Thus, our goal was to identify defect types detected in real-world code reviews, and the extent to which code review can be benefited from defect detection tools.
Method:
To this end, we classified 417 comments from code reviews of 7 OSS Java projects using thematic analysis.
Results:
We identified 116 defect types that we grouped into 15 groups to create a defect classification. Additionally, 38% of these defects could be automatically detected accurately.
Conclusion:
We learnt that even though many capable defect detection tools are available today, a substantial amount of defects that can be detected automatically, reach code review. Also, we identified several code review cost reduction opportunities.",January 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"Identifying defect types in real-world code reviews and the potential for automated detection can help reduce costs and improve software quality, which is relevant for startups looking to optimize their development processes."
https://www.sciencedirect.com/science/article/pii/S0950584922001896,Detecting false-passing products and mitigating their impact on variability fault localization in software product lines,Hieu Dinh=Vo: hieuvd@vnu.edu.vn; Son=Nguyen: sonnguyen@vnu.edu.vn; Thu-Trang=Nguyen: trang.nguyen@vnu.edu.vn; Kien-Tuan=Ngo: tuanngokien@vnu.edu.vn,"Abstract
In a Software Product Line (SPL) system, variability bugs can cause failures in certain products (buggy products), not in the others. In practice, variability bugs are not always exposed, and buggy products can still pass all the tests due to their ineffective test suites (so-called 
false-passing
 products). The misleading indications caused by those 
false-passing
 products’ test results can negatively impact variability fault 
localization performance
. In this paper, we introduce 
Clap
, a novel approach to detect 
false-passing
 products in SPL systems failed by variability bugs. Our key idea is that given a set of tested products of an SPL system, we collect failure indications in failing products based on their implementation and test quality. For a passing product, we evaluate these indications, and the stronger indications, the more likely the product is 
false-passing
. Specifically, the possibility of the product to be false-passing is evaluated based on if it has a large number of the statements which are highly suspicious in the failing products, and if its test suite is in lower quality compared to the failing products’ test suites. We conducted several experiments to evaluate our 
false-passing
 product detection approach on a large benchmark of 14,191 
false-passing
 products and 22,555 
true-passing
 products in 823 buggy versions of the existing SPL systems. The experimental results show that 
Clap
 can effectively detect 
false-passing
 and 
true-passing
 products with the average accuracy of more than 90%. Especially, the precision of 
false-passing
 product detection by 
Clap
 is up to 96%. This means, among 10 products predicted as 
false-passing
 products, more than 9 products are precisely detected. Furthermore, we propose two simple and effective methods to mitigate the 
negative impact
 of 
false-passing
 products on variability 
fault localization
. These methods can improve the performance of the state-of-the-art variability 
fault localization
 techniques by up to 34%.",January 2023,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The detection of false-passing products in SPL systems can greatly enhance the fault localization performance, which is crucial for maintaining product quality and reliability in early-stage startups."
https://www.sciencedirect.com/science/article/pii/S0950584922000222,Collaboration in software ecosystems: A study of work groups in open environment,Lin=Chen: lchen@nju.edu.cn; Zhifei=Chen: chenzhifei@njust.edu.cn; Wanwangying=Ma: wwyma@smail.nju.edu.cn; Wei=Song: wsong@njust.edu.cn,"Abstract
Context:
As a particular type of software ecosystem, an 
open source software
 ecosystem (OSSECO) is a collection of interdependent 
open source software
 (OSS) projects which are developed and evolve together. Events happening within an OSSECO inherently involve the collaboration of participants from multiple OSS projects, forming a temporary work group. However, it is still unclear how different members of a work group collaborate to fix cross-project bugs, a typical event in the maintenance of OSSECOs.
Objective:
This study aims to investigate the characteristics of collaboration within a work group when fixing cross-project bugs in an OSSECO. It involves the participants from the upstream (which caused the bugs) and the downstream (which were affected by the bugs) OSS projects.
Method:
We conducted our study on 236 cross-project bugs from the scientific Python ecosystem, involving 571 participants and 91 OSS projects, to understand open collaboration within a work group. We established a quantitative analysis to investigate the members of a work group, along with a qualitative analysis to understand the roles of the members from different OSS communities.
Results:
The results show that: (1) A typical work group is constituted of four to eight members from the core development teams of the two OSS communities. More members concern with the upstream OSS projects and few can make active contributions to both sides; (2) Distinct responsibilities are taken by the two OSS communities, with the downstream members as the problem-finders and the upstream members as the decision-makers or gatekeepers.
Conclusions:
Our findings reveal the collaborative mechanism and the responsibility allocation between the upstream and downstream OSS communities in the ecosystems.",May 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The study on collaboration within work groups in fixing cross-project bugs in OSSECOs contributes to understanding open collaboration dynamics between upstream and downstream OSS communities.
https://www.sciencedirect.com/science/article/pii/S0950584922001513,Help me with this: A categorization of open source software problems,Nikolaos D.=Tselikas: ntsel@uop.gr,"Abstract
Context:
Free and 
Open Source Software
 is widely used in the research community and the software industry. In this context, developers come across various issues they need to handle in order to use and create software responsibly and without causing legal violations. For instance, using open source software that carries a specific license or how contributions to open source software should be handled are among the issues that need to be considered.
Objective:
As practitioners turn primarily to Q&A sites to seek help, it is important to understand which specific open source software issues they face. In this research, our main objective is to provide a categorization of open source software problems present in the user questions of the Open Source Stack Exchange site and perform a meta-analysis on the encountered questions.
Method:
We have performed a qualitative study analyzing manually 1,500 most popular posts in the Open Source Stack Exchange site and have mapped them to categories and more generic clusters. The coding task was performed in iterations with the participation of three of the authors. Agreement was calculated and cases of disagreement were resolved. Meta-analysis on questions and answers was also performed for discussion purposes.
Results:
We have created 26 categories of problems discussed in the Open Source Stack Exchange site, and grouped them into 6 clusters. Our results show that posts on license texts/conditions and license/copyright notices are more common, whereas posts on license differences are the most popular in terms of views by other users.
Conclusion:
The results can assist any participant of the open source software community to understand on which basic issues she should focus on to gain a good understanding of open source software. They are also useful for improving education on open source software and community support using the implications presented for each category.",December 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The categorization of open source software problems can provide valuable insights for practitioners in the open source community and contribute to the improvement of education and community support.
https://www.sciencedirect.com/science/article/pii/S0950584922001562,Crex: Predicting patch correctness in automated repair of C programs through transfer learning of execution semantics,Dapeng=Yan: dapeng.yan@nuaa.edu.cn; Kui=Liu: brucekuiliu@gmail.com; Yuqing=Niu: 977012358@qq.com; Li=Li: li.li@monash.edu; Zhe=Liu: zhe.liu@nuaa.edu.cn; Zhiming=Liu: zliu@nwpu.edu.cn; Jacques=Klein: jacques.klein@uni.lu; Tegawendé F.=Bissyandé: tegawende.bissyande@uni.lu,"Abstract
A significant body of automated program repair literature relies on test suites to assess the validity of generated patches. Because such oracles are weak, state-of-the-art repair tools can validate some patches that overfit the test cases but are actually incorrect. This situation has become a prime concern in APR, hindering its adoption by the industry. This work investigates execution 
semantic features
 based on micro-traces, a form of under-constrained dynamic traces. We build on 
transfer learning
 to explore function code representations that are amenable to semantic similarity computation and can therefore be leveraged for classifying patch correctness. Our 
Crex
 prototype implementation is based on the 
Trex
 framework. Experimental results on patches generated by the CoCoNut APR tool on CodeFlaws programs indicate that our approach can yield high accuracy in predicting patch correctness. The learned embeddings were proven to capture semantic similarities between functions, which was instrumental in training a classifier that identifies patch correctness by learning to discriminate between correctly patched code and incorrectly patched code based on their semantic similarity with the buggy function.",December 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The investigation into predicting patch correctness using execution semantic features and transfer learning is innovative, but the direct impact on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001550,Influences of UX factors in the Agile UX context of software startups,Luciana=Zaina: lzaina@ufscar.br; Eduardo=Guerra: eduardo.guerra@unibz.it; Alexandre=Alvaro: alvaro@ufscar.br; Joelma=Choma: jchoma@ufscar.br; Roberto=Pereira: rpereira@inf.ufpr.br,"Abstract
Context:
Software startups work under uncertain market conditions, constant time pressures, and extremely limited resources. Startup practitioners commonly adopt agile practices and lean development to build and release software quickly. Within this context, User eXperience (UX) work is critical for generating user value and creating a competitive advantage. However, integrating agile and 
UX
 remains an open question and little explored in software startups.
Objective:
In this study, we investigate how startup practitioners understand the 
UX
 concept and what are the influences of UX factors on the agile context of software startups.
Method:
To achieve this goal, we surveyed software practitioners from software startups in Brazil. We obtained 97 valid responses from professionals working in different areas, in positions of UX experts, software engineers, and managers.
Results:
Our findings show that most software startup practitioners understand UX from a perspective that gives value to the user/customer interaction with the product and company, focusing on achieving a good UX. Regarding the influences of UX factors, we found that most selected factors carried the meaning of delivering value to the business and the user for producing successful products. On the other hand, the lack of resources is a factor that significantly hinders UX work in early-stage startups and with small teams.
Conclusion:
By analyzing our results on four dimensions, covering business & market, product & process, customers & users, and UX work & teams, we provided four takeaways to help practitioners with the adoption of Agile UX in software startups context.",December 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The study focusing on the influences of UX factors on agile in software startups is highly relevant for early-stage ventures. Understanding how to integrate UX effectively within agile practices can have a significant impact on product development and user satisfaction.
https://www.sciencedirect.com/science/article/pii/S0950584922001410,Dealing with imbalanced data for interpretable defect prediction,Yuxiang=Gao: gaoyx@jsnu.edu.cn; Yi=Zhu: zhuy@jsnu.edu.cn; Yu=Zhao: zhaoyu@jsnu.edu.cn,"Abstract
Context
Interpretation has been considered as a key factor to apply 
defect prediction
 in practice. As interpretation from rule-based interpretable models can provide insights about past defects with high quality, many prior studies attempt to construct interpretable models for both accurate prediction and comprehensible interpretation. However, 
class imbalance
 is usually ignored, which may bring huge 
negative impact
 on interpretation.
Objective
In this paper, we are going to investigate resampling techniques, a popular solution to deal with 
imbalanced data
, on interpretation for interpretable models. We also investigate the feasibility to construct interpretable 
defect prediction
 models directly on original data. Further, we are going to propose a rule-based interpretable model which can deal with 
imbalanced data
 directly.
Method
We conduct an empirical study on 47 publicly available datasets to investigate the impact of resampling techniques on rule-based interpretable models and the feasibility to construct such models directly on original data. We also improve gain function and tolerate lower confidence based on 
rule induction
 algorithms to deal with imbalanced data.
Results
We find that (1) resampling techniques impact on interpretable models heavily from both feature importance and model complexity, (2) it is not feasible to construct meaningful interpretable models on original but imbalanced data due to low coverage of defects and poor performance, and (3) our proposed approach is effective to deal with imbalanced data compared with other rule-based models.
Conclusion
Imbalanced data heavily impacts on the interpretable defect prediction models. Resampling techniques tend to shift the learned concept, while constructing rule-based interpretable models on original data may also be infeasible. Thus, it is necessary to construct rule-based models which can deal with imbalanced data well in further studies.",November 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"Investigating the impact of resampling techniques on interpretable defect prediction models for imbalanced data can provide valuable insights for building more effective prediction models in software engineering, contributing to better defect management."
https://www.sciencedirect.com/science/article/pii/S0950584922001045,"Like, dislike, or just do it? How developers approach software development tasks",Zainab=Masood: zmas690@aucklanduni.ac.nz,"Abstract
Context:
Software developers work on various tasks and activities that contribute towards creating and maintaining 
software applications
, frameworks, or other software components. These include technical (e.g., writing code and fixing bugs) and non-technical activities (e.g., communicating within or outside teams to understand, clarify, and resolve issues) as part of their day-to-day responsibilities. Interestingly, there is an aspect of desirability associated with these tasks and activities.
Objective:
However, not all of these tasks are desirable to developers, and yet they still need to be done. This study explores desirability and undesirability of developers for software development tasks.
Method:
Based on semi-structured interviews from 32 software developers and applying a grounded theory research approach, the study investigates what tasks are desirable and undesirable for developers, what makes tasks desirable and undesirable for them, what are the perceived consequences of working on these tasks, and how do they deal with such tasks.
Results:
We identified a set of underlying factors that make tasks (un)desirable for developers, categorised as personal, social, organisational, technical, and operational factors. We also found that working on desirable tasks has positive consequences while working on undesirable tasks has negative consequences. We reported different standard, assisted, and 
mitigation strategies
 that aid software practitioners manage developers’ likes and dislikes.
Conclusion:
Understanding these likes and dislikes, contributing factors, and strategies can help the managers and teams ensure balanced work distribution, developers’ happiness, and productivity, ultimately increasing the value developers add to software products.",October 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,Understanding the desirability and undesirability of software development tasks can provide insights for startups to better manage developer preferences and productivity.
https://www.sciencedirect.com/science/article/pii/S0950584922001173,Towards building a pragmatic cross-project defect prediction model combining non-effort based and effort-based performance measures for a balanced evaluation,Sandeep Kumar=Singh: sandeepk.singh@jiit.ac.in; Yogita=Khatri: 19403019@mail.jiit.ac.in,"Abstract
Context
Recent years have witnessed the growing trend in cross-project defect prediction (CPDP), where the training and the testing data come from different projects having different data distributions. Several CPDP methods have been presented in the literature to overcome differences in their distributions, but the majority of the existing approaches have been evaluated considering the availability of unlimited inspection effort, which is practically impossible, thus leading to fallacious conclusions. Further, they focused more on improving Recall over Precision leading to a high probability of false alarm (PF), causing significant wastage of developer's efforts and time.
Objective
Addressing these issues, we propose a Two-Phase Transfer Boosting (TPTB) model, which aims at improving the performance not only in terms of non-effort based measures (NEBMs) (making a balance between Recall and PF) but also in terms of effort based measures (EBMs), considering the availability of limited inspection effort.
Method
To mitigate the distribution differences, the first phase assigns initial weights to the training modules based on the feature distribution and feature importance. The second phase applies the Dynamic Transfer AdaBoost algorithm to build an ensemble classifier to lessen the impact of contradictory training modules. In addition, a sorting strategy is designed to prioritize the modules for further inspection.
Results
Statistical results on 62 datasets revealed a better-balanced performance of our TPTB model holistically over NN-filter, ManualDown, EASC, and Cruz model with performance comparable to WPDP (Within-project defect prediction) considering NEBMs. Besides, when considering EBMs together, TPTB showed statistically and practically more balanced performance as compared to ManualUP and Cruz with overall performance comparable to EASC.
Conclusions
Our results demonstrate the efficacy of the TPTB model in a practical setting empowering the quality assurance team to predict and prioritize the defective modules allocating limited inspection effort by optimally focusing on highly defective modules.",October 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The Two-Phase Transfer Boosting model addresses practical challenges in cross-project defect prediction, providing a valuable tool for quality assurance teams, although the direct impact on startups may be more limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001070,A deep learning-based automated framework for functional User Interface testing,Zubair=Khaliq: zikayem@gmail.com; Sheikh Umar=Farooq: suf.cs@uok.edu.in; Dawood Ashraf=Khan: dawood.khan@uok.edu.in,"Abstract
Context:
The use of automation tools in software testing helps keep pace with the timeline of the deliverables. Over time with the inclusion of continuous integration/continuous delivery (CI/CD) pipelines, automation tools are becoming less effective. The testing community is turning to 
AI
 to help keep the pace.
Objective:
We study the use of transformers to automate the process of test case generation directly from the User Interface (UI) element description instead of relying on the test specification document from which test cases are extracted manually. We also demonstrate the capability of the proposed approach in repairing flaky tests.
Method:
We employ object 
detection algorithms
 
EfficientDet
 and 
DEtectionTRansformer
 for detecting the elements from an application UI automatically without requiring a tester to locate complex-scripted UI elements. We also use 
Tesseract
 to automatically identify the text present on the UI elements. We transform the generated UI element description to actual test designer-written test cases using text-generation transformers like 
GPT-2
 and 
T5
. The 
generated test cases
 are then translated into executable test scripts using a simple parser. We carry out our 
cases study
 on 30 e-commerce applications.
Results:
The percentage of correct executable test cases generated by the framework employing EfficientDet is 
93.82%
 and employing DEtectionTRansformer is 
98.08%
. The framework eliminates an average of 
96.05%
 flakiness across the applications selected for the study.
Conclusion:
It is concluded that the proposed approach can be used with current automation tools in the industry to enhance their capability in generating test cases and repairing the flaky tests.",October 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The use of transformers for test case generation and flaky test repair shows high accuracy and effectiveness, which could greatly benefit startups in the software testing domain."
https://www.sciencedirect.com/science/article/pii/S0950584922000866,A search-based framework for automatic generation of testing environments for cyber–physical systems,Dmytro=Humeniuk: dmytro.humeniuk@polymtl.ca,"Abstract
Background:
Many modern cyber–physical systems incorporate 
computer vision technologies
, complex sensors and advanced control software, allowing them to interact with the environment autonomously. Examples include drone swarms, self-driving vehicles, autonomous robots, etc. Testing such systems poses numerous challenges: not only should the system inputs be varied, but also the surrounding environment should be accounted for. A number of tools have been developed to test the system model for the possible inputs falsifying its requirements. However, they are not directly applicable to autonomous cyber–physical systems, as the inputs to their models are generated while operating in a virtual environment.
Aims:
In this paper, we aim to design a search-based framework, named AmbieGen, for generating diverse fault-revealing test scenarios for autonomous cyber–physical systems. The scenarios represent an environment in which an 
autonomous agent
 operates. The framework should be applicable to generating different types of environments.
Methods:
To generate the test scenarios, we leverage the NSGA-II algorithm with two objectives. The first objective evaluates the deviation of the observed system’s behaviour from its expected behaviour. The second objective is the test case diversity, calculated as a Jaccard distance with a reference test case. To guide the first objective we are using a simplified system model rather than the full model. The full model is used to run the system in the simulation environment and can take substantial time to execute (several minutes for one scenario). The simplified system model is derived from the full model and can be used to get an 
approximation
 of the results obtained from the full model without running the simulation.
Results:
We evaluate AmbieGen on three scenario generation 
case studies
, namely a smart-thermostat, a robot 
obstacle avoidance
 system, and a vehicle lane-keeping assist system. For all the 
case studies
, our approach outperforms the available baselines in fault revealing and several other metrics such as the diversity of the revealed faults and the proportion of valid test scenarios.
Conclusion:
AmbieGen could find scenarios, revealing failures for all the three autonomous agents considered in our 
case studies
. We compared three configurations of AmbieGen: based on a single objective genetic algorithm, multi-objective, and random search. Both single and multi objective configurations outperform the random search. Multi objective configuration can find the individuals of the same quality as the single objective, producing more unique test scenarios in the same time budget. Our framework can be used to generate virtual environments of different types and complexity and reveal the system’s faults early in the design stage.",September 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"AmbieGen framework significantly outperforms baselines in generating diverse fault-revealing test scenarios for autonomous cyber–physical systems, showing promise in revealing failures early in the design stage."
https://www.sciencedirect.com/science/article/pii/S095058492200091X,The state of the art in measurement-based experiments on the mobile web,Ivano=Malavolta: i.malavolta@vu.nl; Omar=de Munk: o.de.munk@student.vu.nl; Gian Luca=Scoccia: gianluca.scoccia@univaq.it,"Abstract
Context:
Nowadays the majority of all worldwide Web traffic comes from mobile devices, as we tend to primarily rely on the browsers installed on our smartphones and tablets (e.g., Chrome for 
Android
, Safari for iOS) for accessing 
online services
. A market of such a large scale leads to an extremely fierce competition, where it is of 
paramount importance
 that the developed mobile Web apps are of high quality, e.g., in terms of performance, energy consumption, security, usability. In order to objectively assess the quality of mobile Web apps, practitioners and researchers are conducting experiments based on the measurement of run-time metrics such as 
battery discharge
, CPU and memory usage, number and type of network requests, etc.
Objective:
The objective of this work is to identify, classify, and evaluate the state of the art of conducting measurement-based experiments on the mobile Web. Specifically, we focus on (i) which metrics are employed during experimentation, how they are measured, and how they are analyzed; (ii) the platforms chosen to run the experiments; (iii) what subjects are used; (iv) the used tools and environments under which the experiments are run.
Method:
We apply the 
systematic mapping
 methodology. Starting from a search process that identified 786 potentially relevant studies, we selected a set of 33 primary studies following a rigorous 
selection procedure
. We defined and applied a classification framework to them to extract data and gather relevant insights.
Results:
This work contributes with (i) a classification framework for measurement-based experiments on the mobile Web; (ii) a systematic map of current research on the topic; (iii) a discussion of emergent findings and challenges, and resulting implications for future research.
Conclusion:
This study provides a rigorous and replicable map of the state of the art of conducting measurement-based experiments on the mobile Web. Its results can benefit researchers and practitioners by presenting common techniques, empirical practices, and tools to properly conduct measurement-based experiments on the mobile Web.",September 2022,"Measurement-based experiment, Mobile web, Systematic mapping study",Information and Software Technology,2025-03-21T00:00:00,7.0,"The evaluation of measurement-based experiments on the mobile Web provides valuable insights for practitioners and researchers working on mobile Web apps, potentially improving the quality of apps developed by early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000374,Investigating replication challenges through multiple replications of an experiment,Iftekhar=Ahmed: iftekha@uci.edu; Daniel Amador=dos Santos: daniel.amador@email.com; Eduardo Santana=de Almeida: esa@dcc.ufba.br,"Abstract
Context:
As Empirical 
Software Engineering
 grows in maturity and number of publications, more replications are needed to provide a solid grounding to the evidence found through prior research. However, replication studies are scarce in general and some topics suffer more than others with such scarcity. On top, the challenges associated with replicating empirical studies are not well understood.
Objective:
In this study, we aim to fill this gap by investigating difficulties emerging when replicating an experiment.
Method:
We used participants with distinct backgrounds to play the role of a research group attempting to replicate an experimental study addressing Highly-Configurable Systems. Seven external close replications in total were performed. After obtaining the quantitative replication results, a 
focus group session
 was applied to each group inquiring about the replication experience. We used the grounded theory’s constant comparison method for the qualitative analysis.
Results:
We have seen in our study that, in the replications performed, most results hold when comparing them with the baseline. However, the participants reported many difficulties in replicating the original study, mostly related to the lack of clarity of the instructions and the presence of defects on replication artifacts. Based on our findings, we provide recommendations that can help mitigate the problems reported.
Conclusions:
The quality of replication artifacts and the lack of clear instructions might impact an experiment replication. We advocate having good quality replication instructions and well-prepared laboratory packages to foster and enable researchers to perform better replications.",July 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The investigation on replicating experiments in Empirical Software Engineering provides valuable insights, but the practical implications for startups may be limited. Still, the recommendations for clearer instructions and quality replication artifacts can be helpful for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000623,A Systematic Literature Review on prioritizing software test cases using Markov chains,Juliana Marino=Balera: juliana.balera@inpe.br; Érica Ferreira=de Souza: ericasouza@utfpr.edu.br; Nandamudi Lankalapalli=Vijaykumar: vijay.nl@inpe.br; Gerson=Barbosa: gerson.barbosa@unesp.br; Luciana Brasil Rebelo=dos Santos: lurebelo@ifsp.edu.br; Marlon=da Silva: marlon.silva@ifsp.edu.br,"Abstract
Context:
Software Testing is a costly activity since the size of the test case set tends to increase as the construction of the software evolves. Test Case Prioritization (TCP) can reduce the effort and cost of software testing. TCP is an activity where a subset of the existing test cases is selected in order to maximize the possibility of finding defects. On the other hand, 
Markov Chains
 representing a reactive system, when solved, can present the occupation time of each of their states. The idea is to use such information and associate priority to those test cases that consist of states with the highest probabilities.
Objective:
The objective of this paper is to conduct a survey to identify and understand key initiatives for using 
Markov Chains
 in TCP. Aspects such as approaches, developed techniques, programming languages, analytical and simulation results, and validation tests are investigated.
Methods:
A Systematic Literature Review (SLR) was conducted considering studies published up to July 2021 from five different databases to answer the three research questions.
Results:
From SLR, we identified 480 studies addressing 
Markov Chains
 in TCP that have been reviewed in order to extract relevant information on a set of research questions.
Conclusion:
The final 12 studies analyzed use 
Markov Chains
 at some stage of test case prioritization in a distinct way, that is, we found that there is no strong relationship between any of the studies, not only on how the technique was used but also in the context of the application. Concerning the fields of application of this subject, 6 forms of approach were found: Controlled Markov Chain, Usage Model, Model-Based Test, 
Regression Test
, Statistical Test, and 
Random Test
. This demonstrates the versatility and robustness of the tool. A large part of the studies developed some prioritization tool, being its validation done in some cases analytically and in others numerically, such as: Measure of the software specification, Optimal Test Transition Probabilities, Adaptive Software Testing, Automatic Prioritization, 
Ant Colony Optimization
, Model Driven approach, and Monte Carlo Random Testing.",July 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The survey on using Markov Chains in Test Case Prioritization offers valuable insights, but the applicability and impact on startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922000337,Speeding up constraint-based program repair using a search-based technique,Jooyong=Yi: jooyong@unist.ac.kr; Elkhan=Ismayilzada: elkhan@unist.ac.kr,"Abstract
Context:
Constraint-based program repair has been developed as one of the main techniques for automated program repair. Given a buggy program and a test suite, constraint-based program repair first extracts a repair constraint 
φ
, and then synthesizes a patch satisfying 
φ
. Since a patch is synthesized in a correct-by-construction manner (rather than compiling and testing each repair candidate source code), the constraint-based approach, in theory, requires less runtime overhead than the G&V approach. Nevertheless, the performance of existing constraint-based approaches is still suboptimal.
Objective:
In this work, we propose a novel technique to expedite constraint-based program repair. We aim to boost runtime performance without sacrificing repairability and patch quality.
Method:
The existing constraint-based program repair searches for a patch specification in an unguided manner. We introduce a novel guided search algorithm based on 
MCMC
 sampling.
Results:
Our experimental results for the 50 buggy versions of 5 real-world subjects (i.e., 
Libtiff
, 
PHP
, 
GMP
, 
Gzip
, and 
Wireshark
) show that our method named 
FAngelix
 is on average an order of magnitude faster than 
Angelix
 (a state-of-the-art constraint-based program repair tool), showing up to 23 times speed-up. This speed-up is achieved without sacrificing repairability and patch quality.
Conclusion:
This paper proposes a novel technique that expedites constraint-based program repair, using a search-based technique based on 
MCMC
 sampling. Our experimental results show the promise of our approach.",June 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The proposed novel technique for expediting constraint-based program repair in this abstract could have practical value for early-stage ventures by potentially reducing software development time and improving patch quality.
https://www.sciencedirect.com/science/article/pii/S095058492200057X,Predicting reliability of software in industrial systems using a Petri net based approach: A case study on a safety system used in nuclear power plant,Sandeep=Kumar: sandeep.garg@cs.iitr.ac.in,"Abstract
Context
Software reliability
 prediction in the early stages of development can be propitious in many ways. The combinatorial models used to predict reliability using architectures such as fault trees, binary decision diagrams, etc. have limitations in modeling complex system behavior. On the other hand, state-based models such as 
Markov chains
 suffer from the state-space explosion problem, and they need 
transition probability
 among different system states to measure reliability. These probabilities are usually assumed or are obtained from the operational profile for which the system should be used in the field.
Objective
The objective of this paper is to present a method for predicting the reliability of software in industrial systems using a generalized stochastic 
Petri nets
 based approach. The key idea is to violate the assumption of state transition probabilities in the Markov chain. The state transition probabilities are calculated using Petri net transitions’ throughput by performing stationary analysis under the consideration to identify and handle dead markings in the Petri net.
Method
Initially, a generalized stochastic Petri net of the system under consideration is generated from the standard system's specification. Thereafter, dead markings are identified in the Petri net which are further removed to perform steady-state analysis. At last, a Markov model is generated based on the 
reachability
 graph of the Petri net, which is further used to predict the system reliability.
Results
The presented method has been applied to a safety-critical system, Shut Down System-1, of a 
nuclear power plant
, which is operational in the Canada 
Deuterium
 Uranium reactor. The predicted reliability of the system using this method is 99.99966% which has been validated using the specified system requirements. To further validate and generalize the results, sensitivity analysis is performed by varying different system parameters.
Conclusions
The method discussed in this paper presents a step of performing structural analysis on the Petri net of the system under consideration to identify and handle dead markings on the Petri net. It further handles the issue of assuming transition probabilities among the system states by calculating them using Petri net transitions’ throughput.",June 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The method presented for predicting software reliability in industrial systems using Petri nets offers a practical approach that can have a significant impact on early-stage ventures by ensuring system reliability in critical environments.
https://www.sciencedirect.com/science/article/pii/S0950584922000064,Empirically developed framework for building trust in distributed agile teams,Sulabh=Tyagi: sulabhtyagi2k@yahoo.co.in,"Abstract
Background:
Organizations are adopting agile practices in distributed software development in order to develop quality software in less time. Using 
agile software development
 in distributed set up has its own set of challenges pertaining to 
face to face interactions
, collaboration, time zone and cultural differences. A strong presence of trust helps to overcome these challenges. A relatively lesser number of empirical studies on multidimensional perspective of trust in distributed 
agile software development
 has motivated this study.
Objective:
This study aims to develop a comprehensive framework to build trust in distributed agile teams.
Method:
This study is based on Grounded Theory research methodology which involves 40 agile practitioners from diverse domains belonging to 19 different software organizations located across seven different countries. Besides, observations in two different software organizations were also performed to gather data. Data has been gathered in the form of semi-structured interviews and field notes.
Result:
Qualitative data analysis
 resulted into five different contributing categories for building trust amongst distributed agile teams. These categories represent multidimensional perspectives that influence trust building amongst agile team members working across different parts of the world.
Conclusion:
This study culminates into a framework for building trust in distributed agile teams. The proposed framework has been developed empirically and has five components that influence trust building. These components are related to working environment, leadership, organizational, personal and socio cultural perspectives. The multidimensional perspective of trust was investigated from an agile practitioners view through their real-life project experiences. Organizations and software practitioners may utilize the results of this study to create a hospitable environment for building trust while practicing agile in a distributed environment.",May 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,4.0,"While the framework for building trust in distributed agile teams is valuable for software development in distributed setups, its direct impact on early-stage ventures may not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921002147,"Software security patch management - A systematic literature review of challenges, approaches, tools and practices",M. Ali=Babar: ali.babar@adelaide.edu.au; Nesara=Dissanayake: nesara.madugodasdissanayakege@adelaide.edu.au; Asangi=Jayatilaka: asangi.jayatilaka@adelaide.edu.au; Mansooreh=Zahedi: mansooreh.zahedi@unimelb.edu.au,"Abstract
Context:
Software security patch management purports to support the process of patching known software 
security vulnerabilities
. Patching 
security vulnerabilities
 in large and complex systems is a hugely challenging process that involves multiple stakeholders making several interdependent technological and socio-technical decisions. Given the increasing recognition of the importance of software security patch management, it is important and timely to systematically review and synthesise the relevant literature on this topic.
Objective:
This paper aims at systematically reviewing the state of the art of software security patch management to identify the socio-technical challenges in this regard, reported solutions (i.e., approaches, tools, and practices), the rigour of the evaluation and the industrial relevance of the reported solutions, and to identify the gaps for future research.
Method:
We conducted a systematic literature review of 72 studies published from 2002 to March 2020, with extended coverage until September 2020 through forward snowballing.
Results:
We identify 14 socio-technical challenges in software security patch management, 18 solution approaches, tools and practices mapped onto the software security patch management process. We provide a mapping between the solutions and challenges to enable a reader to obtain a holistic overview of the gap areas. The findings also reveal that only 20.8% of the reported solutions have been rigorously evaluated in industrial settings.
Conclusion:
Our results reveal that 50% of the common challenges have not been directly addressed in the solutions and that most of them (38.9%) address the challenges in one phase of the process, namely vulnerability scanning, assessment and prioritisation. Based on the results that highlight the important concerns in software security patch management and the lack of solutions, we recommend a list of future research directions. This study also provides useful insights about different opportunities for practitioners to adopt new solutions and understand the variations of their practical utility.",April 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The systematic review of software security patch management highlights socio-technical challenges and gaps for future research, which can directly impact startups focusing on software security and system maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584921002330,An exploratory study of bug prediction at the method level,Shaozhi=Wei: wsz@mails.ccnu.edu.cn; Ran=Mo: moran@mail.ccnu.edu; Qiong=Feng: qiongfeng@njust.edu.cn; Zengyang=Li: zengyangli@mail.ccnu.edu.cn,"Abstract
Context:
During the past decades, researchers have proposed numerous studies to predict bugs at different 
granularity
 levels, such as the file level, package level, module level, etc. However, the prediction models at the method level are rarely investigated.
Objective:
In this paper, we investigate to predict bug-prone methods based on method-level 
code metrics
 or history measures, and analyze the prediction importance of each metric.
Method:
To proceed our study, we first propose a series of 
code metrics
 and history measures for conducting method-level bug predictions. Next, we compare the performance of different types of prediction models. Finally, we conduct analyses about the prediction power of each metric, based on which, we further analyze whether we can simplify the prediction models.
Results:
Through our evaluation on eighteen large-scale projects, we have presented: (1) conducting method-level bug prediction has potentials of saving a large portion of effort on code reviews and inspections; (2) models using the proposed code metrics or history measures could achieve a good prediction performance; (3) the prediction importance of each metric distributes differently; (4) a highly simplified prediction model could be derived by just using a few important metrics.
Conclusion:
This study presents how to systematically build models for predicting bug-prone methods, and provides empirical evidence for developers to best select metrics to build method-level bug prediction models.",April 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The study on predicting bug-prone methods and identifying important metrics can assist startups in improving software quality assurance processes, potentially saving time and effort on code reviews."
https://www.sciencedirect.com/science/article/pii/S0950584921002123,An Adaptive Penalty based Parallel Tabu Search for Constrained Covering Array Generation,Huayao=Wu: hywu@nju.edu.cn,"Abstract
Context:
The generation of the optimal constrained covering arrays is a key challenge in the research field of combinatorial testing, where a variety of Constrained Covering Array Generation (CCAG) algorithms have been developed. However, existing algorithms typically reuse 
constraint solver
 or forbidden tuple-based techniques to handle constraints, which might restrict their potentials on finding smaller arrays.
Objective:
This work dedicates to exploring more effective constraint handling techniques for CCAG, so that the sizes of constrained covering arrays can be further minimized.
Methods:
We propose a novel Adaptive Penalty based Parallel Tabu Search (APPTS) algorithm to address the CCAG problem. 
APPTS
 incorporates a penalty term into the fitness function to handle the constrained 
search space
, and employs an adaptive penalty mechanism to dynamically adjust the penalty weight in different search phases. Moreover, 
APPTS
 adopts Java Parallel Stream to compute the fitness values of candidate solutions to speed up the generation process.
Results:
The performance of APPTS is evaluated against three alternative tabu search-based algorithms (with different penalty and 
parallelization
 mechanisms), and seven state-of-the-art algorithms for CCAG. The results demonstrate the superiority of APPTS over these existing algorithms. In particular, APPTS finds 22 new upper bounds on the sizes of 2-way and 3-way constrained covering arrays.
Conclusion:
The adaptive penalty mechanism provides an effective choice for handling constraints in CCAG, and the 
parallelization
 can help APPTS reduce the generation cost.",March 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposed algorithm improves constrained covering arrays generation, which can benefit startups in software testing efficiency and optimization."
https://www.sciencedirect.com/science/article/pii/S0950584921002111,Review4Repair: Code review aided automatic program repairing,Faria=Huq: 1505052.fh@ugrad.cse.buet.ac.bd; Masum=Hasan: masum@ra.cse.buet.ac.bd; Md Mahim Anjum=Haque: mahim@vt.edu; Sazan=Mahbub: 1505020.sm@ugrad.cse.buet.ac.bd; Anindya=Iqbal: anindya@cse.buet.ac.bd; Toufique=Ahmed: tfahmed@ucdavis.edu,"Abstract
Context:
Learning-based automatic program repair techniques are showing promise to provide quality fix suggestions for detected bugs in the 
source code
 of the software. These tools mostly exploit 
historical data
 of buggy and fixed code changes and are heavily dependent on bug localizers while applying to a new piece of code. With the increasing popularity of code review, dependency on bug localizers can be reduced. Besides, the code review-based bug localization is more trustworthy since reviewers’ expertise and experience are reflected in these suggestions.
Objective:
The natural language instructions scripted on the review comments are enormous sources of information about the bug’s nature and expected solutions. However, none of the learning-based tools has utilized the review comments to fix programming bugs to the best of our knowledge. In this study, we investigate the 
performance improvement
 of repair techniques using code review comments.
Method:
We train a sequence-to-sequence model on 55,060 code reviews and associated code changes. We also introduce new tokenization and preprocessing approaches that help to achieve significant improvement over state-of-the-art learning-based repair techniques.
Results:
We boost the top-1 accuracy by 20.33% and top-10 accuracy by 34.82%. We could provide a suggestion for stylistics and non-code errors unaddressed by prior techniques.
Conclusion:
We believe that the automatic fix suggestions along with code review generated by our approach would help developers address the review comment quickly and correctly and thus save their time and effort.",March 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The study presents significant improvements in fixing programming bugs by utilizing code review comments which can help developers save time and effort, making it valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921001890,Classifying issue reports according to feature descriptions in a user manual based on a deep learning model,Seonah=Lee: saleese@gnu.ac.kr,"Abstract
Context
Issue reports are documents with which users report problems and state their opinions on a software system. Issue reports are useful for software maintenance, but managing them requires developers’ considerable manual effort. To reduce such effort, previous studies have mostly suggested methods for automatically classifying issue reports. However, most of those studies classify issue reports according to issue types, based only on whether the report is relevant to a bug, whether the report is duplicated, or whether the issue is functional or nonfunctional.
Objective
In this paper, we intend to link issue reports and a user manual and so propose a deep learning model-based method that classifies issue reports according to software features that are described in the user manual in order to help developers relate issue reports to features to make changes to a software system.
Method
In order to classify issue reports according to the feature descriptions in a user manual, our method uses a 
deep learning technique
 with a 
word embedding
 technique. The key insight in our method is that the sections of a user manual that describe software features contain the words and sentences similar to those in issue reports. Based on the insight, we construct a 
classification model
 that learns the feature descriptions (i.e. sections) in a user manual and classifies issue reports according to the feature descriptions.
Results
We evaluate the proposed method by comparing its classification performance with that of the state-of-the-art method, TicketTagger. The experimental results show that the proposed method yields 10% ∼ 24% higher classification f1-score than that of TicketTagger. We also experiment with two deep learning models and four word embedding techniques and find out that the 
Convolution Neural Network model
 with FastText (or GloVe) yields the best performance.
Conclusion
Our study shows the feasibility of classifying issue reports according to software features, which can be the basis for successive studies to classify issue reports into software features.",February 2022,"Deep learning, Classification, Issue reports, User manual, Software features, Data-based software engineering, Convolution neural network, Recurrent neural network, Machine learning",Information and Software Technology,2025-03-21T00:00:00,8.0,"The proposed method of linking issue reports to user manuals using deep learning shows potential to help developers relate issue reports to features and make changes to a software system, with a significant improvement in classification performance over existing methods."
https://www.sciencedirect.com/science/article/pii/S0950584921001919,Understanding in-app advertising issues based on large scale app review analysis,Jichuan=Zeng: jczeng@cse.cuhk.edu.hk; David=Lo: davidlo@smu.edu.sg; Irwin=King: king@cse.cuhk.edu.hk; Michael R.=Lyu: lyu@cse.cuhk.edu.hk; Xin=Xia: xin.xia@monash.edu; Cuiyun=Gao: gaocuiyun@hit.edu.cn,"Abstract
Context:
In-app advertising closely relates to app revenue. Reckless ad integration could adversely impact app quality and 
user experience
, leading to loss of income. It is very challenging to balance the ad revenue and 
user experience
 for app developers.
Objective:
Towards tackling the challenge, we conduct a study on analyzing user concerns about in-app advertisement.
Method:
Specifically, we present a large-scale analysis on ad-related user feedback. The large user feedback data from App Store and Google Play allow us to summarize ad-related app issues comprehensively and thus provide practical ad integration strategies for developers. We first define common ad issues by manually labeling a statistically 
representative sample
 of ad-related feedback, and then build an automatic classifier to categorize ad-related feedback. We study the relations between different ad issues and user ratings to identify the ad issues poorly scored by users. We also explore the fix durations of ad issues across platforms for extracting insights into prioritizing ad issues for ad maintenance.
Results:
(1) We summarize 15 types of ad issues by manually annotating 903 out of 36,309 ad-related user reviews. From a statistical analysis of 36,309 ad-related reviews, we find that users care most about the number of unique ads and ad display frequency during usage. (2) Users tend to give relatively lower ratings when they report the security and notification related issues. (3) Regarding different platforms, we observe that the distributions of ad issues are significantly different between App Store and Google Play. (4) Some ad issue types are addressed more quickly by developers than other ad issues.
Conclusion:
We believe the findings we discovered can benefit app developers towards balancing ad revenue and user experience while ensuring app quality.",February 2022,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The study on in-app advertising and user concerns provides insights into ad-related issues and user ratings, but the impact on startups and early-stage ventures may be limited compared to the other abstracts focusing on software development and prediction models."
https://www.sciencedirect.com/science/article/pii/S0950584921001488,Developing Mobile Applications Via Model Driven Development: A Systematic Literature Review,John=Grundy: john.grundy@monash.edu; Md.=Shamsujjoha: md.shamsujjoha@monash.edu; Qinghua=Lu: qinghua.lu@data61.csiro.au; Li=Li: li.li@monash.edu; Hourieh=Khalajzadeh: hourieh.khalajzadeh@monash.edu,"Abstract
Context:
Mobile applications (known as “apps”) usage continues to rapidly increase, with many new apps being developed and deployed. However, developing a mobile app is challenging due to its dependencies on devices, technologies, platforms, and deadlines to reach the market. One potential approach is to use 
M
odel 
D
riven 
D
evelopment (MDD) techniques that simplify the app 
development process
, reduce complexity, increase abstraction level, help achieve scalable solutions and maximize cost-effectiveness and productivity.
Objective:
This paper systematically investigates what 
MDD
 techniques and methodologies have been used to date to support mobile app development and how these techniques have been employed, to identify key benefits, limitations, gaps and future research potential.
Method:
A Systematic Literature Review approach was used for this study based on a formal protocol. The rigorous search protocol identified a total of 1,042 peer-reviewed academic research papers from four major 
software engineering
 databases. These papers were subsequently filtered, and 55 high quality relevant studies were selected for analysis, synthesis, and reporting.
Results:
We identified the popularity of different applied 
MDD
 approaches, supporting tools, artifacts, and evaluation techniques. Our analysis found that architecture, domain model, and code generation are the most crucial purposes in MDD-based app development. Three qualities – productivity, scalability and reliability – can benefit from these modeling strategies. We then summarize the key collective strengths, limitations, gaps from the studies and made several future recommendations.
Conclusion:
There has been a steady interest in MDD approaches applied to mobile app development over the years. This paper guides future researchers, developers, and stakeholders to improve app development techniques, ultimately that will help end-users in having more effective apps, especially when some recommendations are addressed, e.g., taking into account more human-centric aspects in app development.",December 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The investigation of Model Driven Development (MDD) techniques for mobile app development is highly relevant and practical for European early-stage ventures, as it offers insights into reducing complexity, increasing productivity, and achieving scalable solutions in app development."
https://www.sciencedirect.com/science/article/pii/S0950584921001373,Feature-based insight for forks in social coding platforms,Hamzeh=Eyal Salman: hamzehmu@mutah.edu.jo,"Abstract
Context:
Recently, fork-based development has shown to be an easy and straightforward technique to reuse the 
source code
 of existing projects (upstream projects and their forks) in 
open source communities
 (for example, GitHub) and industry. This technique allows developers to tailor the existing forks to build their applications and thus reduce the development’s burden.
Objective:
However, when the number of forks of a given repository increases, it is difficult to manually maintain and keep track of the development activities across all existing forks. Consequently, this leads to redundant development activities and to lose the efforts of the developers and maintainers. In this article, an automatic approach is proposed to overcome the above-mentioned problems.
Method:
The proposed approach incorporates a mathematical research technique called formal 
concept analysis
 with other proposed algorithms.
Results:
To evaluate the effectiveness of the proposed approach, it is applied on four software projects from different domains and sizes. The results show that the proposed approach gives promising results according to well-known metrics in the subject.
Conclusion:
Also, it significantly outperforms the existing state-of-the-art and gives developers in 
open source communities
 and industry a development overview about forks of a given repository.",December 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The proposed automatic approach to managing forks in open source communities can significantly benefit early-stage ventures by improving development efficiency and reducing redundant activities.
https://www.sciencedirect.com/science/article/pii/S0950584921001464,Sequential coding patterns: How to use them effectively in code recommendation,Leonardo Gresta Paulino=Murta: leomurta@ic.uff.br; Luiz Laerte Nunes=da Silva: luiznunes@id.uff.br; Troy Costa=Kohwalter: troy@ic.uff.br; Alexandre=Plastino: plastino@ic.uff.br,"Abstract
Context:
Some programming constructs frequently appear together in different parts of the code, representing sequential coding patterns throughout the project. These sequential coding patterns can be mined from the project repository and, whenever the code a developer is writing coincides with the beginning of a sequential pattern, the remainder of this pattern can be suggested to the developer. This is equivalent to the usual Code Completion, which suggests 
syntactic
 structures based on the line being programmed. However, instead of providing 
syntactic
 suggestions for completing the current line, such feature suggests code snippets containing multiple lines.
Objective:
This paper contributes with an in-depth study on how code pattern recommendation can be used effectively.
Method:
We answer three research questions through a quantitative study using a robust experimental infrastructure with a corpus of five open-source projects: (1) “In a code recommendation, how many frequent coding patterns should be presented?”, (2) “What is the impact of filtering sequential patterns by their confidence?”, and (3) “Does the effectiveness of the sequential coding patterns degrade over time?”.
Results:
Our study shows that it is possible to achieve correctness above 80% when using suggestions with the highest confidence values and that a threshold confidence of 30% generally provides better outcomes. Furthermore, it shows that frequent code pattern completion effectiveness tends to degrade 50 commits after the patterns have been mined.
Conclusion:
We could observe that: (1) the top five ranked suggestions are the ones that deliver the best results; (2) the code recommendations that deliver the best results are the ones with the highest confidence values; and (3) the code recommendation performance degrades as the source code evolves because patterns become outdated.",December 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The study on code pattern recommendation can provide startups with valuable insights on improving code quality and productivity, which are essential for their growth and success."
https://www.sciencedirect.com/science/article/pii/S0950584921001555,DeepBackground: Metamorphic testing for Deep-Learning-driven image recognition systems accompanied by Background-Relevance,Ziyuan=Wang: wangziyuan@njupt.edu.cn,"Abstract
Context:
Recently, advances in 
Deep Learning
 (DL) have promoted the development of DL-driven image recognition systems in various fields, such as medical treatment, face detection, etc., almost achieving the same level of performance as the human brain. Nevertheless, using DL-driven image recognition systems in these safety-critical domains requires ensuring the accuracy and the stability of these systems. Recent research in this direction mainly focuses on using the image transformations for the overall image to detect the inconsistency of image recognition systems. However, the influence of the image background region (
i
.
e
.
, the region of the image other than the target object) on the recognition result of the systems and the robustness evaluation of the systems are not considered.
Objective:
To evaluate the robustness of DL-driven image recognition systems about image background region changes, this paper introduces DeepBackground, a novel metamorphic 
testing method
 for DL-driven image recognition systems.
Method:
First, we define a new metric, termed Background-Relevance (BRC) to assess the influence degree of the image background region on the recognition result of the image recognition systems. DeepBackground defines a series of domain-specific metamorphic relations (MRs) combined with BRC and automatically generates many follow-up test images based on these MRs. Finally, DeepBackground detects the inconsistency of these systems and evaluates their robustness about image background changes according to BRC.
Results:
Our empirical validation on 3 commercial image recognition services and 6 popular 
convolutional neural networks
 (CNNs) models shows that DeepBackground can not only evaluate the robustness of these image recognition systems about image background changes according to BRC, but also can detect their inconsistent behaviors.
Conclusion:
DeepBackground is capable of automatically generating high-quality test input images to detect the inconsistency of the image recognition systems, and evaluating the robustness of these systems about image background changes according to BRC.",December 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The DeepBackground method for evaluating robustness of image recognition systems provides practical value in ensuring system accuracy and stability, which can be crucial for startups utilizing image recognition technology in various domains."
https://www.sciencedirect.com/science/article/pii/S0950584921001270,The impact of using biased performance metrics on software defect prediction research,Martin=Shepperd: martin.shepperd@brunel.ac.uk; Jingxiu=Yao: JingxiuYao@buaa.edu.cn,"Abstract
Context:
Software engineering
 researchers have undertaken many experiments investigating the potential of software 
defect prediction
 algorithms. Unfortunately some widely used performance metrics are known to be problematic, most notably F1, but nevertheless F1 is widely used.
Objective:
To investigate the potential impact of using F1 on the validity of this large body of research.
Method:
We undertook a 
systematic review
 to locate relevant experiments and then extract all 
pairwise comparisons
 of 
defect prediction
 performance using F1 and the unbiased Matthews 
correlation coefficient
 (MCC).
Results:
We found a total of 38 primary studies. These contain 12,471 pairs of results. Of these comparisons, 21.95% changed direction when the MCC metric is used instead of the biased F1 metric. Unfortunately, we also found evidence suggesting that F1 remains widely used in 
software defect
 prediction research.
Conclusion:
We reiterate the concerns of statisticians that the F1 is a problematic metric outside of an information retrieval context, since we are concerned about both classes (defect-prone and not defect-prone units). This inappropriate usage has led to a substantial number (more than one fifth) of erroneous (in terms of direction) results. Therefore we urge researchers to (i) use an unbiased metric and (ii) publish detailed results including 
confusion matrices
 such that alternative analyses become possible.",November 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The investigation of the impact of using F1 metrics on software defect prediction research, while important, may have less immediate practical value for startups compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921000999,RBAC protection-impacting changes identification: A case study of the security evolution of two PHP applications,Marc-André=Laverdière: marc-andre.laverdiere-papineau@polymtl.ca; Karl=Julien: karl.julien@polymtl.ca; Ettore=Merlo: ettore.merlo@polymtl.ca,"Abstract
Abstract:
Web applications often use Role-Based Access Control (RBAC) to restrict operations and protect security 
sensitive information
 and resources.
Context:
Web applications’ RBAC security may be affected by 
source code
 changes between releases. Developers should re-validate their application prior to release, but this may be labor and resource-intensive.
Objective:
Among all changes between two versions during software evolution, we define Protection-Impacting Changes (PICs) as changed statements that potentially alter privilege protection of other statement(s). PICs may focus the attention of developers towards root cause candidates for security protection changes, especially when these protection changes are unexpected.
Method:
The proposed automated 
static analysis
 identifies PICs between two versions of an application. It is based on the interprocedural 
flow graph
 
reachability
 analysis of security checks and statements.
Results:
We examined the software evolution of two PHP web applications. We examined 210 versions of WordPress, and 192 versions of MediaWiki. Additional experiments have been performed on 19 fix commits corresponding to Common Vulnerabilities and Exposures CVEs from WordPress. They are presented and discussed in this paper and show that PICs contain 98.2% of the CVE oracle root causes.
Conclusion:
PICs represent overall only 8% and 2% of total code changes, respectively for WordPress and MediaWiki. PICs may help developers to focus onto a smaller number of candidate security-related problems, during software evolution. Consequently, developers may re-validate application security and perform repairs more efficiently.",November 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The proposed automated analysis for identifying Protection-Impacting Changes (PICs) can significantly help developers focus on security-related issues during software evolution, thus improving application security efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584921001300,Crowdsourced test report prioritization considering bug severity,Xiaofang=Zhang: xfzhang@suda.edu.cn,"Abstract
In crowdsourced testing, a large number of test reports will be generated in a short time. How to efficiently inspect these reports becomes one of the critical steps in the testing process. In recent years, many automated techniques like clustering, classification, and prioritization have emerged to provide an automated inspection order over test reports. Even though these methods have achieved 
good performance
, they did not consider the priority to image and text information. Simultaneously, existing prioritization approaches only focus on the rate of detecting faults but ignore the severity of the faults. In fact, bug severity is a vital indicator that the users provide to flag the 
criticality
 of a bug, so developers can then use it to set their priority for the resolution process. For these reasons, this paper presents a novel prioritization approach for crowdsourcing test reports. It extracts features from text and screenshot information of the test reports, uses the hash technique to index test reports, and finally designs a prioritization algorithm. To validate our approach, we conducted experiments on six industrial projects. The results and the hypotheses analysis show that our approach can detect all faults faster in a limited time and can prioritize reports that have higher severity faults compared with the existing methods.",November 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The prioritization approach for crowdsourced test reports considers both text and image information, as well as bug severity, but the impact may be limited compared to other abstracts in terms of practical value for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921001324,The organization of software teams in the quest for continuous delivery: A grounded theory approach,Leonardo=Leite: leofl@ime.usp.br,"Abstract
Context:
To accelerate time-to-market and improve customer satisfaction, software-producing organizations have adopted continuous delivery practices, impacting the relations between development and infrastructure professionals. Yet, no substantial literature has substantially tackled how the software industry structures the organization of development and infrastructure teams.
Objective:
In this study, we investigate how software-producing organizations structure their development and infrastructure teams, specifically how is the division of labor among these groups and how they interact.
Method:
After brainstorming with 7 
DevOps
 experts to better formulate our research and procedures, we collected and analyzed data from 37 semi-structured interviews with IT professionals, following Grounded Theory guidelines.
Results:
After a careful analysis, we identified four common organizational structures: (1) siloed departments, (2) classical 
DevOps
, (3) cross-functional teams, and (4) platform teams. We also observed that some companies are transitioning between these structures.
Conclusion:
The main contribution of this study is a theory in the form of a taxonomy that organizes the found structures along with their properties. This theory could guide researchers and practitioners to think about how to better structure development and infrastructure professionals in software-producing organizations.",November 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,3.0,"While studying the structure of development and infrastructure teams is valuable, the direct impact on early-stage ventures may be more theoretical than immediately applicable."
https://www.sciencedirect.com/science/article/pii/S0950584921000902,Predicting long-time contributors for GitHub projects using machine learning,Vijaya Kumar=Eluri: eluri@gwu.edu; Thomas A.=Mazzuchi: mazzu@gwu.edu; Shahram=Sarkani: sarkani@gwu.edu,"Abstract
Context:
Many organizations develop software systems using 
open source software
 (OSS), which is risky due to the high possibility of losing support. Contributors are critical for the survival of 
OSS projects
, but very few new contributors remain with OSS projects to become long-time contributors (LTCs). Identification of factors that contribute to become an LTC can help OSS project owners utilize limited resources to retain new contributors.
Objective:
In this paper, we investigate whether we can effectively predict new contributors to OSS repositories becoming long time contributors based on repository and contributor meta-data collected from GitHub.
Method:
We construct a dataset containing 70,899 observations from 888 most popular repositories with 56,766 contributors. Each observation represents a contributor who joined the repository and is categorized as either an LTC or a non-LTC, depending on whether their project tenure is longer than 3 years. Each observation has 31 features that are calculated using the information of the new contributor and the repository when a new contributor joins the project. We build several 
machine learning
 models, including 
naive Bayes
, k-nearest neighbor, 
logistic regression
, 
decision tree
, and 
random forest
 to predict LTC validated using 10-fold cross-validation. We compare our best model with state of the art model in terms of precision, recall, F1-score, Matthews 
correlation coefficient
 (MCC), and area under the curve (AUC).
Results:
In 10-fold cross-validation, the precision, recall, F1-score, MCC, and AUC of our best model (random forest) are 0.695, 0.079, 0.140, 0.226, and 0.913, respectively. These values are 27.29%, 92.68%, 86.67%, 56.94%, and 0.55%, respectively better than the best 
baseline state
 of the art model (random forest).
Conclusion:
Compared to state of the art models, the models built using our approach use less than 50% features (31 vs 63), have no wait time of one month after the contributor joins to predict future LTC status, and produce better results.",October 2021,"Long-time contributor, GitHub, GHTorrent, BigQuery, Machine learning models",Information and Software Technology,2025-03-21T00:00:00,8.0,"The research offers a practical approach to predicting long-time contributors to OSS repositories, which can significantly benefit European startups relying on open source software for development."
https://www.sciencedirect.com/science/article/pii/S0950584921001002,Visual Resume: Exploring developers’ online contributions for hiring,Sandeep Kaur=Kuttal: sandeep-kuttal@utulsa.edu,"Abstract
Context:
Recruiters and practitioners are increasingly relying on online activities of developers to find a suitable candidate. Past empirical studies have identified technical and soft skills that managers use in online peer 
production sites
 when making hiring decisions. However, finding candidates with relevant skills is a labor-intensive task for managers, due to the sheer amount of information online peer 
production sites
 contain.
Objective:
We designed a profile aggregation tool—Visual Resume—that aggregates contribution information across two types of peer production sites: a code hosting site (GitHub) and a technical Q&A forum (Stack Overflow). Visual Resume displays summaries of developers’ contributions and allows easy access to their contribution details. It also facilitates 
pairwise comparisons
 of candidates through a card-based design. We present the motivation for such a design and design guidelines for creating such recruitment tool.
Methods:
We performed a scenario-based evaluation to identify how participants use developers’ online contributions in peer production sites as well as how they used Visual Resume when making hiring decisions.
Results:
Our analysis helped in identifying the technical and soft skill cues that were most useful to our participants when making hiring decisions in online production sites. We also identified the information features that participants used and the ways the participants accessed that information to select a candidate.
Conclusions:
Our results suggest that Visual Resume helps in participants evaluate cues for technical and soft skills more efficiently as it presents an aggregated view of candidate’s contributions, allows drill down to details about contributions, and allows easy comparison of candidates via movable cards that could be arranged to match participants’ needs.",October 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The Visual Resume tool for aggregating developer contributions from online peer production sites can significantly impact recruitment processes for startups, making it a valuable tool for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921000471,A practical algorithm for learning disjunctive abstraction heuristics in static program analysis,Donghoon=Jeon: donghoon_jeon@korea.ac.kr; Minseok=Jeon: minseok_jeon@korea.ac.kr; Hakjoo=Oh: hakjoo_oh@korea.ac.kr,"Abstract
Context:
The precision and cost of 
static analysis
 are determined by abstraction heuristics (e.g., strategies for abstracting calling contexts, heap locations, etc.), but manually designing effective abstraction heuristics requires a huge amount of engineering effort and domain knowledge. Recently, data-driven 
static analysis
 has emerged to address this challenge by learning such heuristics automatically from a set of training programs.
Objective:
We present a practical algorithm for learning disjunctive abstraction heuristics in data-driven static analysis. We build on a recently proposed approach that can learn nontrivial program properties by disjunctive 
boolean functions
. However, the existing approach is practically limited as it assumes that the most precise abstraction is cheap for the training programs; the algorithm is inapplicable if the most precise abstraction is not scalable. The objective of this paper is to mitigate this limitation.
Method:
Our algorithm overcomes the limitation with two new ideas. It systematically decomposes the learning problem into feasible 
subproblems
, and it can search through the abstraction space from the coarse- to fine-grained abstractions. With this approach, our algorithm is able to learn heuristics when static analysis with the most precise abstraction is not scalable over the training programs.
Results:
We show our approach is effective and generally applicable. We applied our approach to a context-sensitive points-to analysis for Java and a flow-sensitive interval analysis for C. Experimental results show that our algorithm is efficient. For example, our algorithm can learn heuristics for 3-object-sensitive analysis for which the existing learning algorithm is too expensive to learn any useful heuristics.
Conclusion:
Our algorithm makes a state-of-the-art technique for data-driven static analysis more practical.",July 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The algorithm for learning disjunctive abstraction heuristics in data-driven static analysis improves on existing approaches, making it more effective and generally applicable. This could provide valuable insights for European startups dealing with static analysis."
https://www.sciencedirect.com/science/article/pii/S0950584921000896,Evaluating and comparing memory error vulnerability detectors,Li=Li: Li.Li@monash.edu; Haipeng=Cai: haipeng.cai@wsu.edu; Yu=Nong: yu.nong@wsu.edu; Pengfei=Ye: pengfei.ye@wsu.edu; Feng=Chen: Feng.Chen@utdallas.edu,"Abstract
Context:
Memory error vulnerabilities have been consequential and several well-known, open-source memory error vulnerability detectors exist, built on static and/or dynamic code analysis. Yet there is a lack of assessment of such detectors based on rigorous, quantitative accuracy and efficiency measures while not being limited to 
specific application domains
.
Objective:
Our study aims to assess and explain the 
strengths
 and weaknesses of state-of-the-art memory error vulnerability detectors based on static and/or dynamic code analysis, so as to inform tool selection by practitioners and future design of better detectors by researchers and tool developers.
Method:
We empirically evaluated and compared five state-of-the-art memory error vulnerability detectors against two benchmark datasets of 520 and 474 C/C++ programs, respectively. We conducted 
case studies
 to gain in-depth explanations of successes and failures of individual tools.
Results:
While generally fast, these detectors had largely varied accuracy across different vulnerability categories and moderate overall accuracy. Complex code (e.g., deep loops and recursions) and data (e.g., deeply embedded linked lists) structures appeared to be common, major barriers. Hybrid analysis did not always outperform purely static or dynamic analysis for memory error 
vulnerability detection
. Yet the evaluation results were noticeably different between the two datasets used. Our 
case studies
 further explained the performance variations among these detectors and enabled additional actionable insights and recommendations for improvements.
Conclusion:
There was no single most effective tool among the five studied. For future research, integrating different techniques is a promising direction, yet simply combining different classes of code analysis (e.g., static and dynamic) may not. For practitioners to choose right tools, making various tradeoffs (e.g., between precision and recall) might be inevitable.",September 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The assessment of memory error vulnerability detectors provides insights for developers and researchers, though the impact on startups may be somewhat limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584921000690,Automation of systematic literature reviews: A systematic literature review,Bedir=Tekinerdogan: bedir.tekinerdogan@wur.nl; Cagatay=Catal: ccatal@qu.edu.qa; Raymon=van Dinter: raymon.vandinter@wur.nl,"Abstract
Context
Systematic Literature Review (SLR) studies aim to identify relevant primary papers, extract the required data, analyze, and synthesize results to gain further and broader insight into the investigated domain. Multiple SLR studies have been conducted in several domains, such as 
software engineering
, medicine, and pharmacy. Conducting an SLR is a time-consuming, laborious, and costly effort. As such, several researchers developed different techniques to automate the SLR process. However, a 
systematic overview
 of the current state-of-the-art in SLR automation seems to be lacking.
Objective
This study aims to collect and synthesize the studies that focus on the automation of SLR to pave the way for further research.
Method
A systematic literature review is conducted on published primary studies on the automation of SLR studies, in which 41 primary studies have been analyzed.
Results
This SLR identifies the objectives of automation studies, application domains, automated steps of the SLR, automation techniques, and challenges and solution directions.
Conclusion
According to our study, the leading automated step is the 
Selection of Primary Studies
. Although many studies have provided automation approaches for systematic literature reviews, no study has been found to apply automation techniques in the planning and reporting phase. Further research is needed to support the automation of the other activities of the SLR process.",August 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The abstract focuses on the automation of Systematic Literature Review (SLR) studies, which can streamline the research process for academics and professionals. While automation techniques are valuable, the direct impact on early-stage ventures or startups might be limited."
https://www.sciencedirect.com/science/article/pii/S0950584921000665,Exploring the communication functions of comments during bug fixing in Open Source Software projects,Sandra L.=Ramírez-Mora: sandra.ramirez@ciencias.unam.mx,"Abstract
Context:
Bug fixing is a frequent and important task in 
Open Source Software
 (OSS) development and involves the communication of messages, which can serve for multiple purposes and affect the efficiency and effectiveness of corrective software activities.
Objective:
This work is aimed at studying the communication functions of bug comments and their associations with fast and complete bug fixing in 
OSS
 development.
Method:
Over 500K comments and 89K bugs of 100 
OSS projects
 were extracted from three Issue Tracking Systems. Six thousand comments were manually tagged to create a corpus of communication functions. The extracted comments were automatically tagged using 
machine learning algorithms
 and the corpus of communication functions. Statistical and correlation analyses were performed and the most frequent comments communicated during fast and successful bug fixing were identified.
Results:
Significant differences in the distribution of comments of fixed and not fixed bugs were found. Variations in the distribution of comments of bugs with different fixing time were also found. Referential comments that provided objective information were found to be the most frequent messages. Results showed that the percentages of conative and emotive comments are greater when bugs are resolved without the requested fixes and when fixes are implemented in a long time.
Conclusion:
Associations between communication functions and bug fixing exist. The results of this work could be used to improve corrective tasks in 
OSS
 development and some other specific linguistic aspects should be studied in detail in OSS communities.",August 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"Studying bug comments' communication functions can improve bug fixing efficiency, but the direct impact on early-stage ventures may be limited. The results provide insights for OSS development but may not have immediate practical applications for startups."
https://www.sciencedirect.com/science/article/pii/S0950584921000410,Generating feasible protocol test sequences from EFSM models using Monte Carlo tree search,Zuohua=Ding: zouhuading@hotmail.com; Ting=Shu: shuting@zstu.edu.cn; Yechao=Huang: 1766254653@qq.com; Jinsong=Xia: js_xia@126.com; Mingyue=Jiang: jiang_my@126.com,"Abstract
Context:
Feasible test sequences generation is a key step in protocol conformance testing based on the Extended 
Finite State Machine
 (EFSM) model. To guarantee the feasibility of generated test sequences, transition executability analysis (TEA) technique is widely applied in automatic test derivation. However, the TEA method often suffers from the famous state explosion problem, which has become a major obstacle to its efficient application.
Objective:
In order to mitigate this issue, this paper proposed a novel heuristic TEA method (MTEA) that uses Monte Carlo tree search (MCTS) to guide the TEA tree expansion for efficiently deriving feasible test sequences.
Method:
The approach first provides a framework to apply the MCTS algorithm based on multiple decision subtrees, in the context of test sequence generation for EFSM-specified systems, to more efficiently expanding the TEA tree with huge state space, and thus alleviating the problem of state explosion. To achieve this, we then design a reward function to calculate the fitness of nodes currently being expanded in the TEA tree and heuristically direct the search towards a near-optimal solution. Next, an adaptive reduction mechanism of search budget is also introduced to accelerate the convergence of the analysis. Finally, a MTEA-based algorithm for automatically generating feasible test sequences is presented under a specific transition coverage criterion.
Results:
A detailed 
case study
 on 6 popular EFSMs was carried out to evaluate the effectiveness and efficiency of our method. Experimental results show that the MTEA significantly outperforms Breadth-First-Search based TEA method (BTEA) and the standard MCTS-based method (SMCTS), regarding time and space performance. Compared with the BTEA, SMCTS and random TEA method (RTEA), the success rate of test generation of MTEA (98.14% on average) is approximately 2, 1.85 and 3 times higher, respectively. For successful test derivation, MTEA only needs to explore on average 9.95% of the nodes and consume on average 61.68% of the runtime of the BTEA method.
Conclusion:
The experiments illustrate the promise of our approach for alleviating the state explosion problem in test generation for EFSM-specified systems.",July 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The proposed heuristic TEA method for test sequence generation addresses a key challenge in protocol conformance testing. The significant improvement in success rate and exploration efficiency provides practical value, but the application may be more specialized for certain ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921000240,Stakeholder engagement in enterprise architecture practice: What inhibitors are there?,Svyatoslav=Kotusev: kotusev@kotusev.com; Sherah=Kurnia: sherahk@unimelb.edu.au; Graeme=Shanks: gshanks@unimelb.edu.au; Rod=Dilnutt: rpd@unimelb.edu.au; Simon=Milton: simon.milton@unimelb.edu.au,"Abstract
Context
Enterprise
 architecture (EA) is a collection of artifacts describing various aspects of an organization from an integrated business and IT perspective. EA practice is an organizational activity that implies using EA artifacts for facilitating decision-making and improving business and IT alignment. EA practice involves numerous participants ranging from C-level executives to project teams and effective engagement between these stakeholders and architects is critically important for success. Moreover, many practical problems with EA practice can be also attributed to insufficient engagement between architects and other EA stakeholders. However, the notion of engagement received only limited attention in the EA literature and the problem of establishing engagement has not been intentionally studied.
Objective
This paper intends to explore in detail the problem of achieving effective engagement between architects and other EA stakeholders in an organization, identify the main inhibitors of engagement and present a theoretical model explaining the problem of establishing engagement in practice.
Method
This paper is based on a single in-depth revelatory 
case study
 including nine interviews with different participants of EA practice (e.g. architects and other EA stakeholders) and documentation analysis. It leverages the 
grounded theory method
 to construct a conceptual model explaining the problem of engagement in the studied organization.
Results
This paper identifies 28 direct and indirect inhibitors of engagement and unifies them into a holistic conceptual model addressing the problem of achieving engagement that covers the factors undermining both strategic and initiative-based engagement between architects and other EA stakeholders.
Conclusions
This paper focuses on the notion of engagement and offers arguably the first available theoretical model that explains how typical engagement problems between architects and other stakeholders inhibit the realization of value from EA practice. However, the developed model has a number of limitations and we call for further empirical research on engagement problems in EA practice and coping strategies for addressing these problems.",June 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The exploration of achieving effective engagement between architects and EA stakeholders is valuable, but the practical application and impact on early-stage ventures might be limited."
https://www.sciencedirect.com/science/article/pii/S0950584921000409,Challenges and recommendations to publishing and using credible evidence in software engineering,Claes=Wohlin: claes.wohlin@bth.se,"Abstract
Context:
An evidence-based 
scientific discipline
 should produce, consume and disseminate credible evidence. Unfortunately, mistakes are sometimes made, resulting in the production, consumption and dissemination of invalid or otherwise questionable evidence. In the worst cases, such questionable evidence achieves the status of accepted knowledge. There is, therefore, the need to ensure that producers and consumers seek to identify and rectify such situations.
Objectives:
To raise awareness of the 
negative impact
 of misinterpreting evidence and of propagating that misinterpreted evidence, and to provide guidance on how to improve on the type of issues identified.
Methods:
We use a case-based approach to present and analyse the production, consumption and dissemination of evidence. The cases are based on the literature and our professional experience. These cases illustrate a range of challenges confronting evidence-based researchers as well as the consequences to research when invalid evidence is not corrected in a timely way.
Results:
We use the cases and the challenges to formulate a framework and a set of recommendations to help the community in producing and consuming credible evidence.
Conclusions:
We encourage the community to collectively remain alert to the emergence and dissemination of invalid, or otherwise questionable, evidence, and to proactively seek to identify and rectify it.",June 2021,"Evidence-based software engineering, EBSE, Credible evidence, Validity, Relevance",Information and Software Technology,2025-03-21T00:00:00,5.0,"While highlighting the negative impact of misinterpreting evidence is important, the practical guidance provided may have limited direct impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921000288,Self-Attention Networks for Code Search,Tao=Zhang: tazhang@must.edu.mo; Yepang=Liu: liuyp1@sustech.edu.cn,"Abstract
Context:
Developers tend to search and reuse code snippets from a large-scale codebase when they want to implement some functions that exist in the previous projects, which can enhance the efficiency of software development.
Objective:
As the first deep learning-based code search model, DeepCS outperforms prior models such as Sourcere and CodeHow. However, it utilizes two separate 
LSTM
 to represent code snippets and natural language descriptions respectively, which ignores 
semantic relations
 between code snippets and their descriptions. Consequently, the performance of DeepCS falls into the bottleneck, and thus our objective is to break this bottleneck.
Method:
We propose a self-attention 
joint
 
representation learning
 model, named SAN-CS (
S
elf-
A
ttention 
N
etwork for 
C
ode 
S
earch). Comparing with DeepCS, we directly utilize the self-attention network to construct our code search model. By a weighted average operation, self-attention networks can fully capture the contextual information of code snippets and their descriptions. We first utilize two individual self-attention networks to represent code snippets and their descriptions, respectively, and then we utilize the self-attention network to conduct an extra 
joint
 representation network for code snippets and their descriptions, which can build 
semantic relationships
 between code snippets and their descriptions. Therefore, SAN-CS can break the 
performance bottleneck
 of DeepCS.
Results:
We evaluate SAN-CS on the dataset shared by 
Gu et al.
 and choose two 
baseline models
, DeepCS and CARLCS-CNN. Experimental results demonstrate that SAN-CS achieves significantly better performance than DeepCS and CARLCS-CNN. In addition, SAN-CS has better execution efficiency than DeepCS at the training and testing phase.
Conclusion:
This paper proposes a code search model, SAN-CS. It utilizes the self-attention network to perform the joint attention representations for code snippets and their descriptions, respectively. Experimental results verify the effectiveness and efficiency of SAN-CS.",June 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,10.0,"The proposal of SAN-CS as a code search model that outperforms prior models, with improved performance and efficiency, can directly benefit European early-stage ventures in enhancing software development."
https://www.sciencedirect.com/science/article/pii/S0950584921000021,Spectrum-based multi-fault localization using Chaotic Genetic Algorithm,Debolina=Ghosh: debolina442@gmail.com; Jagannath=Singh: jagannath.singhfcs@kiit.ac.in,"Abstract
Context:
In the field of 
software engineering
, the most complex and time consuming activity is fault-finding. Due to increasing size and complexity of software, there is a necessity of automated fault detection tool which can detect fault with minimal human intervention. A programmer spends a lot of time and effort on 
software fault
 localization. Various Spectrum Based Fault Localization (SBFL) techniques have already been developed to automate the 
fault localization
 in single-fault software. But, there is a scarcity of 
fault localization
 technique for multi-fault software. In our study, we have found that pure SBFL is not always sufficient for effective fault localization in multi-fault programs.
Objective:
To address the above challenge, we propose an automated framework using Chaos-based 
Genetic Algorithm
 for Multi-fault Localization (CGAML) based on SBFL technique.
Methods:
Traditional 
Genetic Algorithm
 (GA) sometimes stuck in local optima, and it takes more time to converge. Different chaos 
mapping functions
 have been applied to GA for better performance. We have used logistic mapping function to achieve 
chaotic sequence
. The proposed technique CGAML first calculates the 
suspiciousness
 score for each program statement and then assigns ranks according to that score. The statements having smaller rank means there is a high probability of the statements to be faulty.
Results:
Five open-source 
benchmark programs
 are tested to evaluate the efficiency of CGAML technique. The experimental results show CGAML gives better results for both single-fault and multi-fault programs in comparison with existing spectrum-based fault localization techniques.
Conclusion:
E
X
A
M
 metric is used to compare the performance of our proposed technique with other existing techniques. Smaller 
E
X
A
M
 score denotes the higher accuracy of the technique. The proposed framework generates smaller 
E
X
A
M
 score in comparison with other existing techniques. We found that, overall CGAML works on an average 8.5% better than GA for both single-fault and multi-fault software.",May 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposed automated framework using Chaos-based Genetic Algorithm for fault localization has a high practical value for startups in software development, improving the efficiency of fault detection in multi-fault programs."
https://www.sciencedirect.com/science/article/pii/S0950584920302184,Industry-Academia research collaboration in software engineering: The Certus model,Dusica=Marijan: dusica@simula.no,"Abstract
Context
Research collaborations between 
software engineering
 industry and academia can provide significant benefits to both sides, including improved innovation capacity for industry, and real-world environment for motivating and validating research ideas. However, building scalable and effective research collaborations in software engineering is known to be challenging. While such challenges can be varied and many, in this paper we focus on the challenges of achieving participative knowledge creation supported by active dialog between industry and academia and continuous commitment to 
joint
 problem solving.
Objective
This paper aims to understand what are the elements of a successful industry-academia collaboration that enable the culture of participative knowledge creation.
Method
We conducted participant observation collecting qualitative data spanning 8 years of collaborative research between a software engineering research group on software V&V and the Norwegian IT sector. The 
collected data
 was analyzed and synthesized into a practical collaboration model, named the Certus Model.
Results
The model is structured in seven phases, describing activities from setting up research projects to the exploitation of 
research results
. As such, the Certus model advances other collaborations models from literature by delineating different phases covering the complete life cycle of participative research knowledge creation.
Conclusion
The Certus model describes the elements of a research collaboration process between researchers and practitioners in software engineering, grounded on the principles of research knowledge co-creation and continuous commitment to joint problem solving. The model can be applied and tested in other contexts where it may be adapted to the local context through experimentation.",April 2021,"Software engineering, Industry-academia collaboration, Research collaboration, Research knowledge co-creation, Collaboration model, Technology transfer, Knowledge transfer, Research exploitation, Research-based innovation",Information and Software Technology,2025-03-21T00:00:00,7.0,"The research emphasizes successful industry-academia collaborations in software engineering, providing a practical model for participative knowledge creation. This could potentially benefit European startups by enhancing innovation capacity and problem-solving capabilities."
https://www.sciencedirect.com/science/article/pii/S0950584920302317,Exploring the software repositories of embedded systems: An industrial experience,Janusz=Sosnowski: j.sosnowski@ii.pw.edu.pl,"Abstract
Context
Tracing reports for software repositories have attracted many researchers. Most of them have focused on defect analysis and development processes in relation to open source programs. There exists a gap between open source and industrial software projects, which, in particular, relates to different schemes for creating software repositories and development schemes. This is especially true for embedded systems that gain large markets and become more complex.
Objective
The aim is to explore the software repositories of industrial embedded systems and derive characteristic features in order to evaluate quality and identify problems to do with development processes.
Method
In this paper we have proposed a novel approach to software repository analysis based on the fine grained exploration of issue tracking and code control repositories. In particular, we distinguish the various activities of project actors (e.g. creating new functions, correcting defects, improving performance, modifying tests) and analyse them in a context, not only of a single project, but also a set of correlated projects that have been developed in the company. These issues have been neglected in the literature. These analyses needed new holistic schemes for repository exploration, including various statistical metrics, text mining, and machine learning techniques.
Results
In exploring selected industrial projects we have identified that only 40–75% of issues relate to defects; the issue reports and commit descriptions included here comprise a lot of data that has been disregarded in the literature. These data allow us to trace diverse types of code changes and identify imperfections in software repositories.
Conclusion
We show that fine grained repository analysis gives a broader and more complete view of project development, which may lead to its improvement.",March 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The novel approach to software repository analysis provides a broader view of project development, which can potentially impact the quality and problem identification in early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302287,A study of effectiveness of deep learning in locating real faults,Yan=Lei: yanlei@cqu.edu.cn; Meng=Yan: mengy@cqu.edu.cn; Xiaohong=Zhang: xhongz@cqu.edu.cn; Zhuo=Zhang: zz8477@126.com; Xiaoguang=Mao: xgmao@nudt.edu.cn; Ling=Xu: xuling@cqu.edu.cn,"Abstract
Context:
 The recent progress of 
deep learning
 has shown its promising learning ability in making sense of data, and many fields have utilized this learning ability to learn an effective model, successfully solving their problems. 
Fault localization
 has explored and used 
deep learning
 to server an aid in debugging, showing the promising results on fault localization. However, as far as we know, there is no detailed studies on evaluating the benefits of using 
deep learning
 for locating real faults present in programs. 
Objective:
 To understand the benefits of 
deep learning
 in locating real faults, this paper explores more about 
deep learning
 by studying the effectiveness of fault localization using 
deep learning
 for a set of real bugs reported in the widely used programs. 
Method:
 We use three representative deep learning architectures (
i.e.
 
convolutional neural network
, 
recurrent neural network
 and multi-layer perceptron) for fault localization, and conduct large-scale experiments on 8 real-world programs equipped with all real faults to evaluate their effectiveness on fault localization. 
Results:
 We observe that the localization effectiveness varies considerably among three 
neural networks
 in the context of real faults. Specifically, convolutional 
neural network
 performs the best in locating real faults, showing an average of 38.97% and 26.22% saving over multi-layer 
perceptron
 and 
recurrent neural network
 respectively; 
recurrent neural network
 and multi-layer 
perceptron
 yield comparable effectiveness even if the effectiveness of 
recurrent neural network
 is marginally higher than multi-layer 
perceptron
. 
Conclusion:
 In context of real faults, 
convolutional neural network
 is the most effective for fault localization among the investigated architectures, and we suggest potential factors of deep learning for improving fault localization.",March 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The study on fault localization using deep learning is relevant for startups dealing with software development, but the focus on deep learning architectures may limit the practical application for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302251,Improving requirements specification use by transferring attention with eye tracking data,Kurt=Schneider: kurt.schneider@inf.uni-hannover.de; Maike=Ahrens: maike.ahrens@inf.uni-hannover.de,"Abstract
Context
Software requirements specifications are the main point of reference in traditional software projects. Especially in large projects, these documents get read by multiple people, multiple times. Several guidelines and templates already exist to support writing a 
good specification
. However, not much research has been done in investigating how to support the use of specifications and help readers to find relevant information and navigate in the document more efficiently.
Objective
We aim to ease the reading process of requirements specifications by making use of previously recorded attention data. Therefore, we created three different attention transfer features based on eye tracking data obtained from observing readers when using specifications.
Method
In a student experiment, we evaluated if these attention visualizations positively affect the roles software architect, UI-designer and tester when reading a specification for the first time.
Results
The results show that the attention visualizations did not decrease navigation effort, but helped to draw the readers’ attention towards highlighted parts and decreased the average time spent on pages. They were mostly perceived as valuable by the readers.
Conclusions
We explored and evaluated the approach of visualizing other readers’ 
attention focus
 to help support new readers. Our results include interesting findings on what works well, what does not and what could be enhanced. We present several suggestions on how attention data could be used to fasten document navigation, direct reading and facilitate user-specific reading.",March 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The use of attention visualizations based on eye tracking data to support reading software requirements specifications can enhance document navigation and reader attention, providing practical value for startups in the software development space."
https://www.sciencedirect.com/science/article/pii/S0950584920301968,An empirical study of performance using Clone & Own and Software Product Lines in an industrial context,Francisca=Pérez: mfperez@usj.es; Carlos=Cetina: ccetina@usj.es; José Ignacio=Panach: joigpana@uv.es; Jorge=Echeverría: jecheverria@usj.es,"Abstract
Context:
Clone and Own (CaO) is a widespread approach to generate new software products from existing software products by adding small changes. The Software Product Line (SPL) approach addresses the development of families of products with similar features, moving away from the production of isolated products. Despite the popularity of both approaches, no experiment has yet compared them directly.
Objective:
The goal of this paper is to know the different performances of software engineers in the software 
products development process
 using two different approaches (SPL and CaO).
Method:
We conducted an experiment in the induction hobs software environment with software engineers. This experiment is a single factor experiment where the factor is the approach that is used to develop software products, with two treatments: (SPL or CaO). We compared the results obtained by the software engineers when they develop software products related to effectiveness, efficiency, and satisfaction.
Results:
The findings show that: (1) the SPL approach is more efficient even though the number of checking actions required by this approach is greater than the number required by the CaO approach; (2) the SPL approach offers more possibilities than software engineers need to perform their daily tasks; and (3) software engineers require better search capabilities in the CaO approach. The possible explanations for these results are presented in the paper.
Conclusions:
The results show that there are significant differences in effectiveness, efficiency, and satisfaction, with the SPL approach yielding the best results.",February 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The comparison between the Software Product Line and Clone and Own approaches for software development shows significant differences in effectiveness, efficiency, and satisfaction. This study provides practical insights that can benefit early-stage ventures in making informed decisions."
https://www.sciencedirect.com/science/article/pii/S095058492030197X,Test data generation using genetic programming,M.=Nosrati: mohammad.nosrati@gmail.com; H.=Haghighi: h_haghighi@sbu.ac.ir; M.=Vahidi Asl: m.vahidi.asl@gmail.com,"Abstract
Context:
Typically, search-based test data generation methods search on a population of program input values. Program input values can be regarded as solutions to underlying path constraints over program input parameters. One way to discover these path constraints is to use the symbolic execution method. Search-based methods attempt to find input values which are solutions to these path constraints, without knowing the actual constraints.
Objective:
In this paper, we show that we can search for the underlying path constraints using search-based methods, without resorting to symbolic execution. Trying to discover the exact or a good enough 
approximation
 of the underlying constraints may lead to a more targeted search, compared to directly searching for program input values. Besides, the construction of approximate constraints by searching may help to avoid some problems of symbolic execution.
Method:
The proposed method uses 
genetic programming
 for 
learning constraints
 on program input parameters.
Results:
To evaluate the performance of the proposed approach, a series of experiments have been conducted on a number of different 
benchmark programs
. For 91.8% of 
benchmark programs
, the proposed method achieved the best efficiency among the competitive algorithms.
Conclusion:
The results show that, if constraint solving can be provided for some or all parameter types of the methods of programs under test, our approach can improve the efficiency and effectiveness of search-based test data generation.",February 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The proposed method can improve the efficiency of search-based test data generation in software programs, which can be valuable for early-stage ventures in optimizing their testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584920301944,Revisiting heterogeneous defect prediction methods: How far are we?,Xiang=Chen: xchencs@ntu.edu.cn; Zhanqi=Cui: czq@bistu.edu.cn; Chao=Ni: jacknichao920209@gmail.com; Yanzhou=Mu: myz_2019218009@tju.edu.cn; Ke=Liu: l51415370@163.com,"Abstract
Context:
 Cross-project 
defect prediction
 applies to the scenarios that the target projects are new projects. Most of the previous studies tried to utilize the 
training data
 from other projects (i.e., the source projects). However, metrics used by practitioners to measure the extracted program modules from different projects may not be the same, and performing heterogeneous 
defect prediction
 (HDP) is challenging.
Objective:
 Researchers have proposed many novel HDP methods with promising performance until now. Recently, unsupervised defect prediction (UDP) methods have received more attention and show competitive performance. However, to our best knowledge, whether HDP methods can perform significantly better than UDP methods has not yet been thoroughly investigated.
Method:
 In this article, we perform a comparative study to have a holistic look at this issue. Specifically, we compare five HDP methods with four UDP methods on 34 projects in five groups under the same experimental setup from three different perspectives: non-effort-aware performance indicators (NPIs), effort-aware performance indicators (EPIs) and diversity analysis on identifying defective modules.
Result:
 We have the following findings: (1) HDP methods do not perform significantly better than some of UDP methods in terms of two NPIs and four EPIs. (2) According to two satisfactory criteria recommended by previous studies, the satisfactory ratio of existing HDP methods is pessimistic. (3) The diversity of prediction for defective modules across HDP 
vs
. UDP methods is more than that within HDP methods or UDP methods.
Conclusion:
 The above findings implicate there is still a long way for the HDP issue to go. Given this, we present some observations about the road ahead for HDP.",February 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The study on defect prediction methods has practical implications for software development, especially for early-stage ventures looking to improve their product quality."
https://www.sciencedirect.com/science/article/pii/S0950584920301725,Architectural decision-making as a financial investment: An industrial case study,Apostolos=Ampatzoglou: a.ampatzoglou@uom.edu.gr; Alexander=Chatzigeorgiou: achat@uom.edu.gr; Elvira-Maria=Arvanitou: e.arvanitou@uom.edu.gr; Areti=Ampatzoglou: areti.ampatzoglou@rug.nl; Paris=Avgeriou: paris@cs.rug.nl,"Abstract
Context
Making 
architectural decisions
 is a crucial task but also very difficult, considering the scope of the decisions and their impact on 
quality attributes
. To make matters worse, 
architectural decisions
 need to combine both technical and business factors, which are very dissimilar by nature.
Objectives
We provide a cost-benefit approach and supporting tooling that treats architectural decisions as financial investments by: (a) combining both technical and business factors; and (b) transforming the involved factors into currency, allowing their uniform aggregation. Apart from illustrating the method, we validate both the proposed approach and the tool, in terms of fitness for purpose, usability, and potential limitations.
Method
To validate the approach, we have performed a 
case study
 in a software development company, in the domain of low-energy embedded systems. We employed triangulation in the 
data collection phase
 of the 
case study
, by performing interviews, focus groups, an observational session, and questionnaires.
Results
The results of the study suggested that the proposed approach: (a) provides a structured process for systematizing decision-making; (b) enables the involvement of multiple stakeholders, distributing the decision-making responsibility to more knowledgeable people; (c) uses monetized representations that are important for assessing decisions in a unified manner; and (d) enables decision reuse and documentation.
Conclusions
The results of the study suggest that architectural decision-making can benefit from treating this activity as a financial investment. The various benefits that have been identified from mixing financial and technological aspects are well-accepted from 
industrial stakeholders
.",January 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The cost-benefit approach to architectural decision-making provides a structured process and involvement of multiple stakeholders, which can be valuable for startups. The results suggest benefits from treating architectural decisions as financial investments."
https://www.sciencedirect.com/science/article/pii/S0950584920301464,The effectiveness of data augmentation in code readability classification,Yan=Xiao: dcsxan@nus.edu.sg; Qing=Mi: miqing@bjut.edu.cn; Zhi=Cai: caiz@bjut.edu.cn; Xibin=Jia: jiaxibin@bjut.edu.cn,"Abstract
Context:
 Training 
deep learning
 models for code readability classification requires large datasets of quality pre-labeled data. However, it is almost always time-consuming and expensive to acquire readability data with manual labels.
Objective:
 We thus propose to introduce 
data augmentation
 approaches to artificially increase the size of training set, this is to reduce the risk of overfitting caused by the lack of readability data and further improve the 
classification accuracy
 as the ultimate goal.
Method:
 We create transformed versions of code snippets by manipulating original data from aspects such as comments, indentations, and names of classes/methods/variables based on domain-specific knowledge. In addition to basic transformations, we also explore the use of Auxiliary Classifier 
GANs
 to produce 
synthetic data
.
Results:
 To evaluate the proposed approach, we conduct a set of experiments. The results show that the classification performance of 
deep neural networks
 can be significantly improved when they are trained on the augmented corpus, achieving a state-of-the-art accuracy of 87.38%.
Conclusion:
We consider the findings of this study as primary evidence of the effectiveness of 
data augmentation
 in the field of code readability classification.",January 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The introduction of data augmentation approaches for deep learning models in code readability classification can be beneficial for startups looking to improve classification accuracy without requiring large amounts of manually labeled data.
https://www.sciencedirect.com/science/article/pii/S0950584920301907,Archetypes of delay: An analysis of online developer conversations on delayed work items in IBM Jazz,Abdoul-Djawadou=Salaou: adsalaou@unistra.fr; Daniela=Damian: Daniela.damian@uvic.ca; Casper=Lassenius: casper.lassenius@aalto.fi; Dragoş=Voda: dragos.voda@aalto.fi; Pierre=Gançarski: gancarski@unistra.fr,"Abstract
Context.
A widely adopted methodology, 
agile software development
 provides enhanced flexibility to actively adjust a project scope. In agile teams, particularly in distributed environment, developers interact, manage requirements knowledge, and coordinate primarily in online collaboration tools. Developer conversations become invaluable sources to track and understand developers’ interactions around implementation of requirements, as well as the progress of implementation relative to the project scope and the planned iterations in agile projects. Although extensive research around iteration planning exists, there is a lack of research that leverages developer conversation data to understand delays in implementing planned requirements in agile projects.
Objective.
By using developer conversations in a large agile project at IBM, this work aims to analyze conversation in work items (WIs) that are delayed and derive patterns that suggest reasons for delay in the project.
Method.
We conducted a 
case study
 of the IBM Jazz project, and used thematic analysis to code the developer conversations as time-series, and cluster analysis to identify patterns that differentiated the evolution of discussions in WIs that were late vs. not late in the project.
Results.
We identified six main patterns of WI delay. Through semantic analysis of developer conversations within particular clusters we were able to explain the reasons for delays in each pattern. In comparison to non-late WIs, we find that the major reason for delay is a lack of frequent communication associated with a poor project management of WIs. Similarly, non-late tasks more often delegate to children tasks to accelerate the implementation of requirements, in addition to processing requests quickly to resolve bottlenecks in implementation.
Conclusion.
Our study complements existing research in bringing evidence that developer conversations are a useful resource that can highlight delays in requirement implementation, as well as recommend patterns in the dynamics of developers interactions relevant to such delays.",January 2021,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The analysis of developer conversations in agile projects to understand delays in requirement implementation is insightful, but may have limited immediate application for early-stage ventures compared to the other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920301567,Exploring the Relation between Technical Debt Principal and Interest: An Empirical Approach,Nikolaos=Mittas: nmittas@chem.ihu.gr; Lefteris=Angelis: lef@csd.auth.gr; Apostolos=Ampatzoglou: a.ampatzoglou@uom.edu.gr; Alexander=Chatzigeorgiou: achat@uom.edu.gr; Angeliki-Agathi=Tsintzira: angeliki.agathi.tsintzira@gmail.com; Areti=Ampatzoglou: areti.ampatzoglou@rug.nl; Paris=Avgeriou: paris@cs.rug.nl; Elvira-Maria=Arvanitou: earvanitoy@gmail.com,"Abstract
Context
The cornerstones of technical debt (TD) are two concepts borrowed from economics: principal and interest. Although in economics the two terms are related, in TD there is no study on this direction so as to validate the strength of the metaphor.
Objective
We study the relation between Principal and Interest, and subsequently dig further into the ‘ingredients’ of each concept (since they are multi-faceted). In particular, we investigate if artifacts with similar levels of TD Principal exhibit a similar amount of TD Interest, and vice-versa.
Method
To achieve this goal, we performed an empirical study, analyzing the dataset using the Mantel test. Through the Mantel test, we examined the relation between TD Principal and Interest, and identified aspects that are able to denote proximity of artifacts, with respect to TD. Next, through Linear Mixed Effects (LME) modelling we studied the 
generalizability
 of the results.
Results
The results of the study suggest that TD Principal and Interest are related, in the sense that classes with similar levels of TD Principal tend to have similar levels of Interest. Additionally, we have reached the conclusion that aggregated measures of TD Principal or Interest are more capable of identifying proximate artifacts, compared to isolated metrics. Finally, we have provided empirical evidence on the fact that improving certain quality properties (e.g., size and coupling) should be prioritized while ranking refactoring opportunities in the sense that high values of these properties are in most of the cases related to artifacts with higher levels of TD Principal.
Conclusions
The findings shed light on the relations between the two concepts, and can be useful for both researchers and practitioners: the former can get a 
deeper understanding
 of the concepts, whereas the latter can use our findings to guide their TD management processes such as prioritization and repayment.",December 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The study sheds light on the relation between Principal and Interest in technical debt, providing insights that can be valuable for startups navigating technical debt management."
https://www.sciencedirect.com/science/article/pii/S0950584920301579,Predicting continuous integration build failures using evolutionary search,Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Islem=Saidani: islem.saidani.1@ens.etsmlt.ca; Moataz=Chouchen: moataz.chouchen.1@ens.etsmtl.ca,"Abstract
Context:
 Continuous Integration (CI) is a 
common practice
 in modern software development and it is increasingly adopted in the open-source as well as the software industry markets. CI aims at supporting developers in integrating code changes constantly and quickly through an automated build process. However, in such context, the build process is typically time and resource-consuming which requires a high maintenance effort to avoid build failure.
Objective:
 The goal of this study is to introduce an automated approach to cut the expenses of CI build time and provide support tools to developers by predicting the CI build outcome.
Method:
 In this paper, we address problem of CI build failure by introducing a novel search-based approach based on Multi-Objective 
Genetic Programming
 (MOGP) to build a CI build failure prediction model. Our approach aims at finding the best combination of CI built features and their appropriate threshold values, based on two conflicting objective functions to deal with both failed and passed builds.
Results:
 We evaluated our approach on a benchmark of 56,019 builds from 10 large-scale and long-lived software projects that use the Travis CI build system. The statistical results reveal that our approach outperforms the state-of-the-art techniques based on 
machine learning
 by providing a better balance between both failed and passed builds. Furthermore, we use the generated prediction rules to investigate which factors impact the CI build results, and found that features related to (1) specific statistics about the project such as team size, (2) last build information in the current build and (3) the types of changed files are the most influential to indicate the potential failure of a given build.
Conclusion:
 This paper proposes a multi-objective search-based approach for the problem of CI build failure prediction. The performances of the models developed using our MOGP approach were statistically better than models developed using 
machine learning techniques
. The experimental results show that our approach can effectively reduce both 
false negative
 rate and false positive rate of CI build failures in highly imbalanced datasets.",December 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The automated approach for CI build failure prediction can significantly benefit early-stage ventures by reducing false negative and false positive rates, improving efficiency in software development."
https://www.sciencedirect.com/science/article/pii/S0950584920301592,Reducing efforts of software engineering systematic literature reviews updates using text classification,Katia Romero=Felizardo: katiascannavino@utfpr.edu.br; Érica Ferreira=de Souza: ericasouza@utfpr.edu.br; Nandamudi Lankalapalli=Vijaykumar: vijay.nl@inpe.br; Willian Massami=Watanabe: http://www.wwatana.be/; Arnaldo=Candido: arnaldoc@utfpr.edu.br,"Abstract
Context
Systematic Literature Reviews (SLRs) are frequently used to synthesize evidence in 
Software Engineering
 (SE), however replicating and keeping SLRs up-to-date is a major challenge. The activity of studies selection in SLR is labor intensive due to the large number of studies that must be analyzed. Different approaches have been investigated to support SLR processes, such as: Visual Text Mining or 
Text Classification
. But acquiring the initial dataset is time-consuming and labor intensive.
Objective
In this work, we proposed and evaluated the use of 
Text Classification
 to support the studies selection activity of new evidences to update SLRs in SE.
Method
We applied Text 
Classification techniques
 to investigate how effective and how much effort could be spared during the studies selection phase of an SLR update. Considering the SLRs update scenario, the studies analyzed in the primary SLR could be used as a 
classified dataset
 to train Supervised 
Machine Learning algorithms
. We conducted an experiment with 8 
Software Engineering
 SLRs. In the experiments, we investigated the use of multiple preprocessing and feature extraction tasks such as tokenization, stop words removal, word lemmatization, TF-IDF (Term-Frequency/Inverse-Document-Frequency) with 
Decision Tree
 and 
Support Vector Machines
 as 
classification algorithms
. Furthermore, we configured the classifier activation threshold for maximizing Recall, hence reducing the number of Missed selected studies.
Results
The techniques accuracies were measured and the results achieved on average a F-Score of 0.92 and 62% of exclusion rate when varying the activation threshold of the classifiers, with a 4% average number of Missed selected studies. Both the Exclusion rate and number of Missed selected studies were significantly different when compared to classifier which did not use the configuration of the activation threshold.
Conclusion
The results showed the potential of the techniques in reducing the effort required of SLRs updates.",December 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The use of Text Classification to support SLR processes can save effort and reduce the labor-intensive nature of studies selection, which can be a valuable tool for startups conducting systematic literature reviews in SE."
https://www.sciencedirect.com/science/article/pii/S0950584920301555,Empirical software product line engineering: A systematic literature review,Ana Eva=Chacón-Luna: achaconl1@unemi.edu.ec; Antonio Manuel=Gutiérrez: antonio.gutierrez@isis-papyrus.com; José A.=Galindo: jagalindo@us.es; David=Benavides: benavides@us.es,"Abstract
Context:
The adoption of 
Software Product Line Engineering
 (SPLE) is usually only based on its theoretical benefits instead of empirical evidences. In fact, there is no work that synthesizes the empirical studies on SPLE. This makes it difficult for researchers to base their contributions on previous works validated with an empirical strategy.
Objective:
The objective of this work is to discover and summarize the studies that have used empirical evidences in SPLE limited to those ones with the intervention of humans. This will allow evaluating the quality and to know the scope of these studies over time. Doing so, research opportunities can arise
Methods:
A 
systematic literature review
 was conducted. The scope of the work focuses on those studies in which there is human intervention and were published between 2000 and 2018. We considered peer-reviewed papers from journals and top 
software engineering
 conferences.
Results:
Out of a total of 1880 studies in the initial set, a total of 62 primary studies were selected after applying a series of inclusion and exclusion criteria. We found that, approximately 56% of the studies used the empirical 
case study
 strategy while the rest used experimental strategies. Around 86% of the case studies were performed in an industrial environment showing the penetration of SPLE in 
industry
.
Conclusion:
The interest of empirical studies has been growing since 2008. Around 95.16% of the studies address aspects related to domain engineering while application engineering received less attention. Most of the experiments and 
case study
 evaluated showed an 
acceptable level
 of quality. The first study found dates from 2005 and since then, the interest in the empirical SPLE has increased.",December 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The synthesis of empirical studies on SPLE can provide valuable insights for researchers, but the direct practical impact on early-stage ventures might be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920301609,A revised open source usability defect classification taxonomy,John=Grundy: john.grundy@monash.edu; Nor Shahida Mohamad=Yusop: nor_shahida@uitm.edu.my; Rajesh=Vasa: rajesh.vasa@deakin.edu.au,"Abstract
Context
: Reporting usability defects is a critical part of improving software. Accurately classifying these reported usability defects is critical for reporting, understanding, triaging, prioritizing and ultimately fixing such defects. However, existing usability defect 
classification taxonomies
 have several limitations when used for open source software (OSS) development. This includes incomplete coverage of usability defect problems, unclear 
criticality
 of defects, lack of formal usability training of most 
OSS
 defect reporters and developers, and inconsistent terminology and descriptions.
Objective
: To address this gap, as part of our wider usability defect reporting research, we have developed a new usability defect taxonomy specifically designed for use on 
OSS projects
.
Method
: We used 
Usability Problem
 Taxonomy (UPT) to classify 377 usability 
defect reports
 from 
Mozilla Thunderbird
, Firefox for 
Android
, and the 
Eclipse Platform
. At the same time, we also used the card-sorting technique to group defects that could not be classified using UPT. We looked for commonalities and similarities to further group the defects within each category as well as across categories.
Results
: We constructed a new taxonomy for classifying 
OSS
 usability defects, called Open Source Usability Defect Classification (OSUDC). OSUDC was developed by incorporating 
software engineering
 and 
usability engineering
 needs to make it feasible to be used in 
open source software development
. The use of the taxonomy has been validated on five real cases of usability defects. However, evaluation results using the OSUDC were only moderately successful.
Conclusion
: The OSUDC serves as a common vocabulary to describe and classify usability defects with respect to graphical user interface issues. It may help software developers to better understand usability defects and prioritize them accordingly. For researchers, the OSUDC will be helpful when investigating both trends of usability defect types and understanding the root cause of usability defect problems.",December 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The development of a new taxonomy for classifying OSS usability defects can have a significant impact on software development processes, helping developers better prioritize and understand defects."
https://www.sciencedirect.com/science/article/pii/S0950584920301695,The impact of personality traits and knowledge collection behavior on programmer creativity,Aamir=Amin: aamir@utar.edu.my,"Abstract
Context: Creativity is one of the essential ingredients in successful software engineering. However, majority of the work related to creativity in software engineering has focused on creativity in requirement engineering. Furthermore, there are very few studies that examine programmer creativity and the impact of individual and contextual factors on it.
Objective: The objective of the study is to analyze the impact of the 
big five personality traits
 including extraversion, agreeableness, conscientiousness, 
neuroticism
 and openness to experience, as well as knowledge collection behavior on a programmer's creativity intention.
Method: A quantitative survey was conducted and data from 294 programmers, working in offshore software development projects, was collected. The data was later analyzed using Smart-PLS (3.0).
Results and Conclusions: The results indicated that openness to experience, extraversion, conscientiousness and knowledge collection behavior positively predicted a programmer's creativity intention. On the other hand, 
neuroticism
 negatively predicts creativity intention of the programmer. The study also concluded that all of the independent variables, except the agreeableness trait, significantly predict creativity intention which in turn significantly predicts creativity. As a result, our conclusions indicate that programmer's 
personality traits
 and knowledge collection behavior play a key role in shaping their intention to be creative. Hence, 
personality traits
 and knowledge collection behavior should be given due attention during the hiring process of creativity-oriented software companies.",December 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,Analyzing the impact of personality traits on programmer creativity intention can provide valuable insights for creativity-oriented software companies during the hiring process.
https://www.sciencedirect.com/science/article/pii/S0950584920301300,From software architecture to analysis models and back: Model-driven refactoring aimed at availability improvement,Vittorio=Cortellessa: vittorio.cortellessa@univaq.it; Romina=Eramo: romina.eramo@univaq.it; Michele=Tucci: michele.tucci@univaq.it,"Abstract
Context
With the ever-increasing evolution of software systems, their architecture is subject to frequent changes due to multiple reasons, such as new requirements. Appropriate architectural changes driven by non-functional requirements are particularly challenging to identify because they concern quantitative analyses that are usually carried out with specific languages and tools. A considerable number of approaches have been proposed in the last decades to derive non-functional analysis models from architectural ones. However, there is an evident lack of automation in the backward path that brings the analysis results back to the software architecture.
Objective
In this paper, we propose a model-driven approach to support designers in improving the availability of their software systems through refactoring actions.
Method
The proposed framework makes use of bidirectional model transformations to map UML models onto Generalized 
Stochastic Petri Nets
 (GSPN) analysis models and vice versa. In particular, after availability analysis, our approach enables the application of model refactoring, possibly based on well-known fault tolerance patterns, aimed at improving the availability of the 
architectural model
.
Results
We validated the effectiveness of our approach on an 
Environmental Control System
. Our results show that the approach can generate: (i) an analyzable availability model from a software architecture description, and (ii) valid software architecture models back from availability models. Finally, our results highlight that the application of fault tolerance patterns significantly improves the availability in each considered scenario.
Conclusion
The approach integrates bidirectional model transformation and fault 
tolerance techniques
 to support the availability-driven refactoring of architectural models. The results of our experiment showed the effectiveness of the approach in improving the software availability of the system.",November 2020,"Software architecture, Availability, Bidirectional model transformation, Refactoring",Information and Software Technology,2025-03-21T00:00:00,9.0,The model-driven approach for improving software system availability through refactoring actions is highly impactful for startups dealing with evolving software architecture and non-functional requirements.
https://www.sciencedirect.com/science/article/pii/S0950584920301361,PostFinder: Mining Stack Overflow posts to support software developers,Davide=Di Ruscio: davide.diruscio@univaq.it; Juri=Di Rocco: juri.dirocco@univaq.it; Phuong T.=Nguyen: phuong.nguyen@univaq.it; Claudio=Di Sipio: claudio.disipio@univaq.it; Riccardo=Rubei: riccardo.rubei@univaq.it,"Abstract
Context –
 During the development of complex software systems, programmers look for external resources to understand better how to use specific APIs and to get advice related to their current tasks. Stack Overflow provides developers with a broader insight into API usage as well as useful code examples. Given the circumstances, tools and techniques for mining Stack Overflow are highly desirable. 
Objective –
 In this paper, we introduce PostFinder, an approach that analyzes the project under development to extract suitable context, and allows developers to retrieve messages from Stack Overflow being relevant to the API function calls that have already been invoked. 
Method –
 PostFinder augments posts with additional data to make them more exposed to queries. On the client side, it boosts the context code with various factors to construct a query containing information needed for matching against the stored indexes. Multiple facets of the data available are used to optimize the search process, with the ultimate aim of recommending highly relevant SO posts. 
Results –
 The approach has been validated utilizing a user study involving a group of 12 developers to evaluate 500 posts for 50 contexts. Experimental results indicate the suitability of PostFinder to recommend relevant Stack Overflow posts and concurrently show that the tool outperforms a well-established baseline. 
Conclusions –
 We conclude that PostFinder can be deployed to assist developers in selecting relevant Stack Overflow posts while they are programming as well as to replace the module for searching posts in a code-to-code search engine.",November 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"PostFinder offers a useful tool for developers to retrieve relevant Stack Overflow posts related to their programming tasks, improving efficiency and providing more insights into API usage."
https://www.sciencedirect.com/science/article/pii/S0950584920301373,Large-scale machine learning systems in real-world industrial settings: A review of challenges and solutions,Lucy Ellen=Lwakatare: llucy@chalmers.se,"Abstract
Background
: Developing and maintaining large scale 
machine learning
 (ML) based software systems in an industrial setting is challenging. There are no well-established development guidelines, but the literature contains reports on how companies develop and maintain deployed ML-based software systems.
Objective
: This study aims to survey the literature related to development and maintenance of large scale ML-based systems in industrial settings in order to provide a synthesis of the challenges that practitioners face. In addition, we identify solutions used to address some of these challenges.
Method
: A systematic literature review was conducted and we identified 72 papers related to development and maintenance of large scale ML-based software systems in industrial settings. The selected articles were qualitatively analyzed by extracting challenges and solutions. The challenges and solutions were thematically synthesized into four 
quality attributes
: adaptability, scalability, safety and privacy. The analysis was done in relation to ML workflow, i.e. data acquisition, training, evaluation, and deployment.
Results
: We identified a total of 23 challenges and 8 solutions related to development and maintenance of large scale ML-based software systems in industrial settings including six different domains. Challenges were most often reported in relation to adaptability and scalability. Safety and privacy challenges had the least reported solutions.
Conclusion
: The development and maintenance on large-scale ML-based systems in industrial settings introduce new challenges specific for ML, and for the known challenges characteristic for these types of systems, require new methods in overcoming the challenges. The identified challenges highlight important concerns in 
ML system
 development practice and the lack of solutions point to directions for future research.",November 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The challenges and solutions identified in the development and maintenance of large scale ML-based software systems provide valuable insights for European startups working in industries with ML applications. The identified challenges highlight practical concerns for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S095058492030118X,An empirical evaluation of the use of models to improve the understanding of safety compliance needs,Jose Luis=de la Vara: joseluis.delavara@uclm.es; Beatriz=Marín: beatriz.marin@mail.udp.cl; Clara=Ayora: claraayora@gmail.com; Giovanni=Giachetti: ggiachetti@inacap.cl,"Abstract
Context
Critical systems in application domains such as automotive, railway, aerospace, and healthcare are required to comply with safety standards. The understanding of the safety compliance needs specified in these standards can be difficult from their text. A possible solution is to use models.
Objective
We aim to evaluate the use of models to understand safety compliance needs.
Method
We have studied the effectiveness, efficiency, and perceived benefits in understanding these needs, with models and with the text of safety standards, by means of an experiment. The standards considered are DO-178C and EN 50128. We use SPEM-like diagrams to graphically represent the models.
Results
The mean effectiveness of 20 undergraduate students in understanding the needs and the mean efficiency were higher with models (22% and 38%, respectively), and the difference is statistically significant (p-value ≤ 0.02). Most of the students agreed upon the ease of understanding the structure of safety compliance needs with models when compared to the text, but on average, the students were undecided about whether the models are easy to understand or easier to understand than the text.
Conclusions
The results allow us to claim that the use of models can improve the understanding of safety compliance needs. Nonetheless, there seems to be room for improvement in relation to the perceived benefits. It must be noted that our conclusions may differ if the subjects were experienced practitioners.",October 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"While the use of models to understand safety compliance needs is important, the practical impact on early-stage ventures may be limited, as the study focuses more on compliance with safety standards in critical systems."
https://www.sciencedirect.com/science/article/pii/S0950584920301117,Efficient feature extraction model for validation performance improvement of duplicate bug report detection in software bug triage systems,Seyed Morteza=Babamir: babamir@kashanu.ac.ir,"Abstract
Context
There are many duplicate 
bug reports
 in the semi-structured software repository of various software bug triage systems. The duplicate bug report detection (DBRD) process is a significant problem in software triage systems.
Objective
The DBRD problem has many issues, such as efficient feature extraction to calculate similarities between 
bug reports
 accurately, building a high-performance duplicate detector model, and handling continuous real-time queries. Feature extraction is a technique that converts unstructured data to structured data. The main objective of this study is to improve the validation performance of DBRD using a feature extraction model.
Method
This research focuses on feature extraction to build a new general model containing all types of features. Moreover, it introduces a new feature extractor method to describe a new viewpoint of similarity between texts. The proposed method introduces new textual features based on the aggregation of term frequency and 
inverse document frequency
 of text fields of bug reports in uni-gram and bi-gram forms. Further, a new hybrid measurement metric is proposed for detecting efficient features, whereby it is used to evaluate the efficiency of all features, including the proposed ones.
Results
The validation performance of DBRD was compared for the proposed features and state-of-the-art features. To show the effectiveness of our model, we applied it and other related studies to DBRD of the 
Android
, Eclipse, Mozilla, and Open Office datasets and compared the results. The comparisons showed that our proposed model achieved (i) approximately 2% improvement for 
accuracy
 and 
precision
 and more than 4.5% and 5.9% improvement for 
recall
 and 
F1-measure
, respectively, by applying the linear regression (LR) and decision tree (DT) classifiers and (ii) a performance of 91%−99% (average ~97%) for the four metrics, by applying the DT classifier as the best classifier.
Conclusion
Our proposed features improved the validation performance of DBRD concerning runtime performance. The pre-processing methods (primarily stemming) could improve the validation performance of DBRD slightly (up to 0.3%), but rule-based 
machine learning algorithms
 are more useful for the DBRD problem. The results showed that our proposed model is more effective both for the datasets for which state-of-the-art approaches were effective (i.e., Mozilla Firefox) and those for which state-of-the-art approaches were less effective (i.e., Android). The results also showed that the combination of all types of features could improve the validation performance of DBRD even for the LR classifier with less validation performance, which can be implemented easily for software bug triage systems. Without using the longest common subsequence (LCS) feature, which is effective but time-consuming, our proposed features could cover the effectiveness of LCS with lower time-complexity and runtime overhead. In addition, a statistical analysis shows that the results are reliable and can be generalized to other datasets or similar classifiers.",October 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,10.0,"The proposed feature extraction model for duplicate bug report detection significantly improves validation performance, achieving notable improvements in accuracy, precision, recall, and F1-measure using advanced techniques and classifiers, offering practical value for software triage systems."
https://www.sciencedirect.com/science/article/pii/S0950584920300732,Semantically find similar binary codes with mixed key instruction sequence,Yuancheng=Li: yuancheng@ncepu.cn,"Abstract
Context
Software similarity comparison has always been a common technique for 
software reuse
 detection, 
plagiarism detection
, and defect detection.
Objective
Considering the role of API calls and 
arithmetic operations
 in software execution, a semantic-based dynamic software analysis method–mixed key instruction sequence (MKIS) is proposed.
Method
MKIS embeds key value sets into a vector and constructs a novel software execution sequence that contains API calls and 
arithmetic operations
 during software execution. To determine the location of key values, a key-value equivalent 
matching algorithm
 is proposed, combined with the longest common subsequence algorithm to optimize the software execution sequence.
Results
Experiments show that MKIS can accurately compare the similarity of binary programs without obtaining the software source code, and has better resiliency and credibility.
Conclusion
Moreover, in the case when the software source code is changed with some main function-independent modification and code obfuscator, 
software reuse
 can be successfully detected.",September 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The proposed semantic-based dynamic software analysis method has the potential to impact software reuse and plagiarism detection, though the practical application for startups may require further validation and adaptation."
https://www.sciencedirect.com/science/article/pii/S0950584920301038,Developer portraying: A quick approach to understanding developers on OSS platforms,Wenhua=Yang: ywh@nuaa.edu.cn; Minxue=Pan: mxp@nju.edu.cn; Zhiqiu=Huang: zqhuang@nuaa.edu.cn; Yu=Zhou: zhouyu@nju.edu.cn,"Abstract
Context
Millions of software developers are using open-source software (OSS) platforms to host their code and collaborate with each other. They possess different programming skills, styles, and preferences, etc., and it is important to understand them for making collaborative decisions such as programming task assignment. Existing OSS platforms do not provide sufficient information about developers, and we need to spend significant effort in searching the OSS platforms for such information.
Objective
Different than the basic developer information displayed on OSS platforms, we propose portraying developers as a quick approach for characterizing and understanding them. We discuss how to build developer portraits to make them concise yet informative.
Method
We propose a multi-dimensional developer portrait model to specify the attributes of various aspects concerning software development about developers. Then, a method that leverages text analysis, web data analysis, and code analysis techniques is presented to analyze a developer’s various sources of data on OSS platforms for constructing the portrait.
Results
The constructed portraits can be vividly displayed on the web to help people quickly understand developers and make better decisions during 
collaborative software development
. 
Case studies
 on two representative problems in the 
software engineering
 area—code recommendation and programming task assignment—are conducted, and the results show the improvement in recommendation and the potential for proper assignments when using our portraits.
Conclusion
The developer portrait is an effective form to characterize developers. It can help people quickly understand the developers and can be applied to various applications in the software development process.",September 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The developer portrait model proposed in this study can significantly aid collaborative decision-making in software development by providing concise yet informative representations of developers. This can be highly valuable for startups looking to optimize team dynamics.
https://www.sciencedirect.com/science/article/pii/S0950584920300434,Software product line applied to the internet of things: A systematic literature review,Ricardo Theis=Geraldi: ricardo.geraldi@ppgia.pucpr.br; Sheila=Reinehr: sheila.reinehr@pucpr.br; Andreia=Malucelli: malu@ppgia.pucpr.br,"Abstract
Context
Internet of Things
 (IoT) is a promising paradigm due to the growing number of devices that may be connected, defined as “things”. Managing these “things” is still considered a challenge. One way to overcome this challenge may be by adopting the software product line (SPL) paradigm and the variability management (VM) activity. 
SPL engineering
 consists of mechanisms that provide identification, representation, and traceability, which may be helpful to “things” management supported by VM organizational and technical activities.
Objective
This research aims to investigate how SPL engineering has been applied along with the IoT paradigm, as well as how VM is being carried out.
Method
A systematic literature review (SLR) was conducted considering papers available until March 2019. This systematic review identified 1039 papers. After eliminating the duplicated titles and the ones not related to the review, 112 papers remained. The number of papers was narrowed to 56 after applying the exclusion criteria.
Results
The results provide evidence on the diversity of proposed SPLs used to specify approaches for managing IoT systems. However, most SPLs and research developed for IoT lack a systematic and detailed specification to ensure their quality, as well as tailoring guidelines for further use.",August 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"Investigating the application of SPL engineering and VM in IoT systems has the potential to offer insights into managing IoT devices efficiently. The findings could be beneficial for startups in the IoT sector, although the direct impact may vary."
https://www.sciencedirect.com/science/article/pii/S0950584920300446,On the performance of hybrid search strategies for systematic literature reviews in software engineering,Marcos=Kalinowski: kalinowski@inf.puc-rio.br; Erica=Mourão: ericamourao@id.uff.br,"Abstract
Context
When conducting a Systematic Literature Review (SLR), researchers usually face the challenge of designing a search strategy that appropriately balances result quality and review effort. Using digital library (or database) searches or snowballing alone may not be enough to achieve high-quality results. On the other hand, using both digital library searches and snowballing together may increase the overall review effort.
Objective
The goal of this research is to propose and evaluate hybrid search strategies that selectively combine database searches with snowballing.
Method
We propose four hybrid search strategies combining database searches in digital libraries with iterative, parallel, or sequential backward and forward snowballing. We simulated the strategies over three existing SLRs in SE that adopted both database searches and snowballing. We compared the outcome of digital library searches, snowballing, and 
hybrid strategies
 using precision, recall, and F-measure to investigate the performance of each strategy.
Results
Our results show that, for the analyzed SLRs, combining database searches from the Scopus digital library with parallel or sequential snowballing achieved the most appropriate balance of precision and recall.
Conclusion
We put forward that, depending on the goals of the SLR and the available resources, using a hybrid search strategy involving a representative digital library and parallel or sequential snowballing tends to represent an appropriate alternative to be used when searching for evidence in SLRs.",July 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The proposal and evaluation of hybrid search strategies for conducting Systematic Literature Reviews (SLRs) offer a practical approach to balancing review quality and effort. This can benefit early-stage ventures by providing efficient ways to gather evidence and information.
https://www.sciencedirect.com/science/article/pii/S0950584920300264,A systematic literature review on automated log abstraction techniques,Fabio=Petrillo: fabio@petrillo.com; Yann-Gaël=Guéhéneuc: yann-gael.gueheneuc@concordia.ca; Abdelwahab=Hamou-Lhadj: wahab.hamou-lhadj@concordia.ca; Diana=El-Masri: diana.el-masri@polymtl.ca; Anas=Bouziane: anas.bouziane@polymtl.ca,"Abstract
Context:
 Logs are often the first and only information available to software engineers to understand and debug their systems. Automated log-analysis techniques help software engineers gain insights into large log data. These techniques have several steps, among which log abstraction is the most important because it transforms raw log-data into high-level information. Thus, log abstraction allows software engineers to perform further analyses. Existing log-abstraction techniques vary significantly in their designs and performances. To the best of our knowledge, there is no study that examines the performances of these techniques with respect to the following seven 
quality aspects
 concurrently: mode, coverage, delimiter independence, efficiency,scalability, system knowledge independence, and parameter tuning effort.
Objectives:
 We want (1) to build a 
quality model
 for evaluating automated log-abstraction techniques and (2) to evaluate and recommend existing automated log-abstraction techniques using this 
quality model
.
Method:
 We perform a systematic literature review (SLR) of automated log-abstraction techniques. We review 89 research papers out of 2,864 initial papers.
Results:
 Through this SLR, we (1) identify 17 automated log-abstraction techniques, (2) build a quality model composed of seven desirable aspects: mode, coverage, delimiter independence, efficiency, scalability, system knowledge independence, and parameter tuning effort, and (3) make recommendations for researchers on future research directions.
Conclusion:
 Our quality model and recommendations help researchers learn about the state-of-the-art automated log-abstraction techniques, identify research gaps to enhance existing techniques, and develop new ones. We also support software engineers in understanding the advantages and limitations of existing techniques and in choosing the suitable technique to their unique use cases.",June 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The evaluation of log-abstraction techniques and the quality model proposed in this abstract provide valuable guidance for software engineers and researchers. This can benefit early-stage ventures by assisting them in choosing suitable log analysis techniques for their systems.
https://www.sciencedirect.com/science/article/pii/S0950584919302502,"A fine-grained requirement traceability evolutionary algorithm: Kromaia, a commercial video game case study",Carlos=Cetina: ccetina@usj.es; Óscar=Pastor: opastor@dsic.upv.es; Daniel=Blasco: dblasco@usj.es,"Abstract
Context:
Commercial 
video games
 usually feature an extensive 
source code
 and requirements that are related to code lines from multiple methods. Traceability is vital in terms of maintenance and content update, so it is necessary to explore such 
search spaces
 properly.
Objective:
This work presents and evaluates CODFREL (Code Fragment-based Requirement Location), our approach to fine-grained 
requirement traceability
, which lies in an 
evolutionary algorithm
 and includes encoding and genetic operators to manipulate code fragments that are built from 
source code
 lines. We compare it with a baseline approach (Regular-LSI) by configuring both approaches with different 
granularities
 (code lines / complete methods).
Method:
We evaluated our approach and Regular-LSI in the Kromaia video game 
case study
, which is a commercial video game released on PC and PlayStation 4. The approaches are configured with method and code line granularity and work on 20 requirements that are provided by the development company. Our approach and Regular-LSI calculate similarities between requirements and code fragments or methods to propose possible solutions and, in the case of CODFREL, to guide the 
evolutionary algorithm
.
Results:
The results, which compare code line and method granularity configurations of CODFREL with different granularity configurations of Regular-LSI, show that our approach outperforms Regular-LSI in precision and recall, with values that are 26 and 8 times better, respectively, even though it does not achieve the optimal solutions. We make an open-source implementation of CODFREL available.
Conclusions:
Since our approach takes into consideration key issues like the source code size in commercial 
video games
 and the requirement dispersion, it provides better starting points than Regular-LSI in the search for solution candidates for the requirements. However, the results and the influence of domain-specific language on them show that more explicit knowledge is required to improve such results.",March 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The CODFREL approach for fine-grained requirement traceability in commercial video games outperforms the baseline approach, which can be beneficial for startups in the gaming industry."
https://www.sciencedirect.com/science/article/pii/S095058492030029X,Detecting Java software similarities by using different clustering techniques,Davide=Di Ruscio: davide.diruscio@univaq.it; Juri=Di Rocco: juri.dirocco@univaq.it; Phuong T.=Nguyen: phuong.nguyen@univaq.it; Andrea=Capiluppi: andrea.capiluppi@brunel.ac.uk; Nemitari=Ajienka: nemitari.ajienka@edgehill.ac.uk,"Abstract
Background
Research on empirical 
software engineering
 has increasingly been conducted by analysing and measuring vast amounts of software systems. Hundreds, thousands and even millions of systems have been (and are) considered by researchers, and often within the same study, in order to test theories, demonstrate approaches or run prediction models. A much less investigated aspect is whether the collected metrics might be context-specific, or whether systems should be better analysed in clusters.
Objective
The objectives of this study are (i) to define a set of 
clustering techniques
 that might be used to group similar software systems, and (ii) to evaluate whether a suite of well-known object-oriented metrics is context-specific, and its values differ along the defined clusters.
Method
We group software systems based on three different 
clustering techniques
, and we collect the values of the metrics suite in each cluster. We then test whether clusters are statistically different between each other, using the Kolgomorov-Smirnov (KS) hypothesis testing.
Results
Our results show that, for two of the used techniques, the KS null hypothesis (e.g., the clusters come from the same population) is rejected for most of the metrics chosen: the clusters that we extracted, based on application domains, show statistically different 
structural properties
.
Conclusions
The implications for researchers can be profound: metrics and their interpretation might be more sensitive to context than acknowledged so far, and application domains represent a promising filter to cluster similar systems.",June 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The study on clustering techniques and context-specific metrics in software systems offers insights for researchers, but the impact on early-stage ventures may not be as direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920300045,Time pressure in software engineering: A systematic review,Miikka=Kuutila: miikka.kuutila@oulu.fi,"Abstract
Context
Large project overruns and overtime work have been reported in the software industry, resulting in additional expense for companies and personal issues for developers. Experiments and 
case studies
 have investigated the relationship between time pressure and software quality and productivity.
Objective
The present work aims to provide an overview of studies related to time pressure in 
software engineering
; specifically, existing definitions, possible causes, and metrics relevant to time pressure were collected, and a mapping of the studies to software processes and approaches was performed. Moreover, we synthesize results of existing quantitative studies on the effects of time pressure on software development, and offer practical takeaways for practitioners and researchers, based on empirical evidence.
Method
Our search strategy examined 5414 sources, found through repository searches and snowballing. Applying inclusion and exclusion criteria resulted in the selection of 102 papers, which made relevant contributions related to time pressure in 
software engineering
.
Results
The majority of high quality studies report increased productivity and decreased quality under time pressure. The most frequent categories of studies focus on quality assurance, 
cost estimation
, and process simulation. It appears that time pressure is usually caused by errors in 
cost estimation
. The effect of time pressure is most often identified during 
software quality assurance
.
Conclusions
The majority of empirical studies report increased productivity under time pressure, while the most cost estimation and process simulation models assume that compressing the schedule increases the total needed hours. We also find evidence of the mediating effect of knowledge on the effects of time pressure, and that tight deadlines impact tasks with an algorithmic nature more severely. Future research should better contextualize quantitative studies to account for the existing conflicting results and to provide an understanding of situations when time pressure is either beneficial or harmful.",May 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The overview of studies related to time pressure in software engineering and the synthesis of empirical evidence can help early-stage ventures in managing time constraints effectively and improving productivity and software quality.
https://www.sciencedirect.com/science/article/pii/S095058491930271X,"Views on quality requirements in academia and practice: commonalities, differences, and context-dependent grey areas",Andreas=Vogelsang: andreas.vogelsang@tu-berlin.de; Jonas=Eckhardt: jonas@eckhardt.tv; Daniel=Mendez: daniel.mendez@bth.se; Moritz=Berger: moritz.berger@imbie.uni-bonn.de,"Abstract
Context:
 Quality requirements (QRs) are a topic of constant discussions both in industry and academia. Debates entwine around the definition of quality requirements, the way how to handle them, or their importance for project success. While many academic endeavors contribute to the body of knowledge about QRs, practitioners may have different views. In fact, we still lack a consistent body of knowledge on QRs since much of the discussion around this topic is still dominated by observations that are strongly context-dependent. This holds for both academic and practitioners’ views. Our assumption is that, in consequence, those views may differ.
Objective:
 We report on a study to better understand the extent to which available research statements on quality requirements, as found in exemplary peer-reviewed and frequently cited publications, are reflected in the perception of practitioners. Our goal is to analyze differences, commonalities, and context-dependent grey areas in the views of academics and practitioners to allow a discussion on potential misconceptions (on either sides) and opportunities for future research.
Method:
 We conducted a survey with 109 practitioners to assess whether they agree with research statements about QRs reflected in the literature. Based on a statistical model, we evaluate the impact of a set of context factors to the perception of research statements.
Results:
 Our results show that a majority of the statements is well respected by practitioners; however, not all of them. When examining the different groups and backgrounds of respondents, we noticed interesting deviations of perceptions within different groups that may lead to new research questions.
Conclusions:
Our results help identifying prevalent context-dependent differences about how academics and practitioners view QRs and pinpointing statements where further research might be useful.",May 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The research on quality requirements perception between academics and practitioners is interesting, but the direct impact on early-stage ventures may be limited. The findings may lead to future research opportunities but may not provide immediate value to startups."
https://www.sciencedirect.com/science/article/pii/S0950584919302630,Simulation environment for the choice of the decision making algorithm in multi-version real-time system,Mikhail V.=Saramud: msaramud@sfu-kras.ru,"Abstract
Context
Nowadays the most effective way to improve the reliability of software is an approach with the introduction of software redundancy - multi-version programming. The reliability of a multi-version system is determined not only by the reliability of the versions that make it up, but to a greater degree by the decision making algorithm.
Objective
Our objective is evaluation and selection of the most reliable voting algorithms in multi-version environments. In order to get this objective there is a need to check all the algorithms in the execution environment, simulating characteristic of the developed system. Thus, we obtain the characteristics of the quality of the algorithm operation in precisely those conditions in which it will work in the system that is developed.
Method
The article suggests weighted voting algorithms with a forgetting element, as well as modifications of existing voting algorithms. To be able to check the quality of their work, the simulation environment has been implemented that simulates the operation of the software multi-version execution environment.
Results
The article substantiates the use of the most reliable decision making algorithms in the decision block of the real-time operating system. A comparative analysis of decision making algorithms for the operation of the decision making block of the multi-version real-time execution environment has been carried out.
Conclusions
The software implementation of the simulation environment that implements the simulations of versions with given characteristics is considered, not only classical decision making algorithms, but also the author's modifications are investigated. The environment allows to obtain the 
quality characteristics
 of all implemented decision making algorithms with given system characteristics. The modeling results are considered, the dependence of the system 
reliability indicators
 on its input parameters is shown, a comparative analysis of various decision making algorithms based on the modeling results is made.",April 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The evaluation and selection of reliable voting algorithms in multi-version environments is important for software reliability, but the direct practical impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0883902625000102,"Time to say goodbye? The role of SBIR funding, VC rounds, and initial alliance for director exit in new ventures",Vilma=Chila: v.chila@uva.nl; Koen=van den Oever: k.f.vdnoever@tilburguniversity.edu,"Abstract
Despite the significant interest in the composition and dynamics of new venture boards, our understanding of when directors exit the boards of new ventures is limited. Drawing on the organizational life cycles framework and resource dependence arguments, we posit that key life cycle events alter a venture's resource needs and dependencies on the board, occasioning director exit. Specifically, we argue that SBIR funding, Venture Capital rounds of funding, and first alliance act as markers of new venture evolution that render existing dependencies obsolete, increasing the likelihood of director exit. Interviews with board members in the semiconductor industry informed and substantiated our theoretical claims. The results show that SBIR funding and subsequent rounds of VC funding are linked to an increased likelihood of director exit, whereas a venture's first alliance is not. The paper sheds light on the interdependencies between the board's life cycle and the life cycle of the new venture.",May 2025,"Venture boards, Venture board turnover, Governmental funding, VC funding, Alliances, Early stage ventures, Board life cycle, New venture life cycle",Business Venturing,2025-03-21T00:00:00,9.0,"The study on when directors exit new venture boards based on key life cycle events offers practical implications for startups, helping them understand the dynamics of board composition and resource dependencies, which can be crucial for the growth and success of early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302575,An empirically evaluated checklist for surveys in software engineering,Jefferson Seide=Molléri: jefferson@simula.no,"Abstract
Context:
 Over the past decade 
Software Engineering
 research has seen a steady increase in survey-based studies, and there are several guidelines providing support for those willing to carry out surveys. The need for auditing survey research has been raised in the literature. Checklists have been used both to conduct and to assess different types of empirical studies, such as experiments and 
case studies
.
Objective:
 To operationalize the assessment of survey studies by means of a checklist. To fulfill such goal, we aim to derive a checklist from standards for survey research and further evaluate the appropriateness of the checklist in the context of software engineering research.
Method:
 We systematically aggregated knowledge from 12 methodological studies supporting survey-based research in software engineering. We identified the key stages of the survey process and its recommended practices through thematic analysis and vote counting. We evaluated the checklist by applying it to existing surveys and analyzed the results. Thereafter, we gathered the feedback of experts (the surveys’ authors) on our analysis and used the feedback to improve the survey checklist.
Results:
 The evaluation provided insights regarding limitations of the checklist in relation to its understanding and objectivity. In particular, 19 of the 38 checklist items were improved according to the feedback received from experts.
Conclusion:
 The proposed checklist is appropriate for auditing survey reports as well as a support tool to guide ongoing research with regard to the survey design process. A discussion on how to use the checklist and what its implications are for research practice is also provided.",March 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The checklist proposed for auditing survey reports can be a useful tool for software engineering research. While it provides support for survey design processes, its impact on early-stage ventures may not be as significant compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919302034,Assisting engineers extracting requirements on components from domain documents,Li=Zhang: lily@buaa.edu.cn; Xiaoli=Lian: lianxiaoli@buaa.edu.cn; Wenchuang=Liu: liuwenchuang@bytedance.com,"Abstract
Context
: When entering an unfamiliar domain, organizations usually have to invest significant time and effort performing domain analysis with the purpose of acquiring 
system requirements
. This process usually involves collecting domain documents extensively, retrieving and reviewing the related ones carefully, searching for the requirements knowledge, then extracting and specifying 
system requirements
. Furthermore, the task must often be performed repeatedly throughout the early phases of projects. Depending on the nature of the domain and the availability of documentation, this process is extremely time-consuming and may require non-trivial human effort.
Objective
: In order to assist engineers identifying requirements knowledge from a collect of domain documents, previously we proposed an approach MaRK in the Conference RE’16 which ranks the domain documents by their relevance to components and highlights the content that are likely to contain component-related information. Experiments showed MaRK can almost identify the top and bottom documents in the reference list. However, it tends to underestimate the relevance of the domain documents that have a number of sections with medium knowledge density.
Method
: We improve the ranking algorithm in MaRK and propose MaRK-II. In addition, to assist engineers locating the relevant information in lengthy documents, we preserve the highlighting work in MaRK and strengthen MaRK-II by extracting the summary of component-related text. MaRK-II is evaluated with the documents in three domains.
Results
: We found that MaRK-II significantly outperforms MaRK and 
VSM
 on ranking the documents by their relevance. And a user study showed that MaRK-II is indeed helpful for engineers to extract requirements on components.
Conclusions
: Our approach provides three mechanisms including documents ranking, pertinent content highlighting and summarizing to help engineers obtaining requirements from a collection of domain documents.",February 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The MaRK-II approach, which assists engineers in identifying requirements knowledge from domain documents, can have a high practical value for European early-stage ventures. By significantly outperforming previous methods and aiding in requirements extraction, it can save time and effort for startup projects."
https://www.sciencedirect.com/science/article/pii/S0950584919302095,Toward recursion aware complexity metrics,Gordana=Rakić: gordana.rakic@dmi.uns.ac.rs; Melinda=Tóth: tothmelinda@elte.hu; Zoran=Budimac: zoran.budimac@dmi.uns.ac.rs,"Abstract
Context
: Software developers spend a significant amount of time on reading, comprehending, and debugging of 
source code
. Numerous software metrics can give us awareness of incomprehensible functions or of flaws in their collaboration. Invocation chains, especially recursive ones, affect solution complexity, readability, and 
understandability
. Even though decomposed and recursive solutions are characterized as short and clear in comparison with iterative ones, they hide the complexity of the observed problem and solution. As the collaboration between functions can strongly depend on context, difficulties are usually detected in debugging, testing or by 
static analysis
, while metrics support is still very weak.
Objective
: We introduce a new complexity metric, called Overall Path Complexity (OPC), which is aware of (recursive) call chains in the observed 
source code
. As invocations are basic collaboration mechanism and recursions are broadly accepted, the OPC metric is intended to be applicable independently on programming language and paradigm.
Method
: We propose four different versions of the OPC calculation algorithm and explore and discuss their suitability. We have validated proposed metrics based on a Framework specially designed for evaluation and validation of software complexity metrics and accordingly performed theoretical, empirical and practical validation. Practical validation was performed on toy examples and industrial cases (47012 LOCs, 2899 functions, and 758 recursive paths) written in Erlang.
Result
: Based on our analysis we selected the most suitable (of 4 proposed) OPC calculation formula, and showed that the new metric expresses advanced properties of the software in comparison with other available metrics that was confirmed by 
low correlation
.
Conclusion
: We introduced the OPC metric calculated on the Overall Control 
Flow Graph
 as an extension of 
Cyclomatic Complexity
 by adding awareness of (recursive) invocations. The values of the new metric can lead us to find the problematic fragments of the code or of the execution paths.",February 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The introduction of a new complexity metric, Overall Path Complexity (OPC), has practical implications for software developers, enhancing the understanding of source code and identifying problematic fragments or execution paths."
https://www.sciencedirect.com/science/article/pii/S0950584919302290,A focus area maturity model for software ecosystem governance,Slinger=Jansen: slinger.jansen@uu.nl,"Abstract
Context
Increasingly, software companies are realizing that they can no longer compete through product excellence alone. The ecosystems that surround platforms, such as operating systems, enterprise applications, and even social networks are undeniably responsible for a large part of a platform’s success. With this realization, software producing organizations need to devise tools and strategies to improve their ecosystems and reinvent tools that others have invented many times before.
Objective
In this article, the software ecosystem governance maturity model (SEG-
M
2
) is presented, which has been designed along the principles of a focus area maturity model. The SEG-
M
2
 has been designed for software producing organizations to assess their ecosystem governance practices, set a goal for improvement, and execute an improvement plan.
Method
The model has been created following an established focus area maturity model design method. The model has been evaluated in six evaluating 
case studies
 with practitioners, first by applying the model to their organizations and secondly by evaluating with the practitioners whether the evaluation and improvement advice from the model is valid, useful, and effective.
Result
The model is extensively described and illustrated using six desk studies and six 
case studies
.
Conclusions
The model is evaluated by both researchers and practitioners as a useful collection of practices that enable decision making about software ecosystem governance. We find that maturity models are an effective tool in disseminating a large collection of knowledge, but that research and creation tooling for maturity models is limited.",February 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,4.0,"The software ecosystem governance maturity model (SEG-M2) provides a framework for software producing organizations to assess their ecosystem governance practices, but the overall impact on early-stage ventures may be less direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584919302010,Requirements specification for developers in agile projects: Evaluation by two industrial case studies,Juliana=Medeiros: juliana.medeiros@ifpb.edu.br; Alexandre=Vasconcelos: amlv@cin.ufpe.br; Carla=Silva: ctlls@cin.ufpe.br; Miguel=Goulão: mgoul@fct.unl.pt,"Abstract
Context
An inadequate requirements specification activity acts as a catalyst to other problems, such as low team productivity and difficulty in maintaining software. Although 
Agile Software Development
 (ASD) has grown in recent years, research pointed out several limitations concerning its 
requirements engineering
 activities, such as Software Requirements Specification (SRS) provided in high level and targeted to the customer, lack of information required to perform design activities and low availability of the customer. To overcome these issues, the RSD (Requirements Specification for Developers) approach was proposed to create an SRS that provides information closer to development needs. In addition, existing literature reviews identify a demand for more empirical studies on the requirements specification activity in ASD.
Objective
Face to this, this work presents the evaluation of the RSD approach with respect to how it affects the teamwork and to identify its strengths and limitations.
Methods
This evaluation was performed by means of two industrial 
case studies
 conducted using a multiple-case design, focusing on software engineers as the analysis unit. Data were collected during 15 months from documents, observations, and interviews. They were triangulated, analyzed, and synthesized using techniques of grounded theory.
Results
The findings pointed out that the readability of SRS was compromised when several requirements are specified in the same RSD artifact. Evaluation also indicated the need of prioritization and categorization of the 
acceptance criteria
, a tool for creating, searching and tracing the artifacts, and obtaining 
acceptance tests
 from 
acceptance criteria
. On the other hand, the findings showed that the practices used to specify requirements using the RSD approach have the potential to produce a more objective SRS, tailored for the development team.
Conclusion
As a consequence, the structure of the RSD artifact was considered as a factor that improved the team performance in the two 
case studies
.",January 2020,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The evaluation of the RSD approach can provide valuable lessons for improving teamwork and requirements specification in Agile Software Development, which can be beneficial for early-stage ventures adopting Agile methodologies."
https://www.sciencedirect.com/science/article/pii/S0950584919301685,Package-Level stability evaluation of object-oriented systems,Sajjad=Mahmood: smahmood@kfupm.edu.sa,"Abstract
Context
Software stability is an important object-oriented design characteristic that contributes to the 
maintainability
 
quality attribute
. Software stability quantifies a given systems sensitivity to change between different versions. Stable software tends to reduce the maintenance effort. Assessing software stability during the object-oriented design phase is one of the measures to obtain maintainable software. To determine software stability, there are several metrics at the architecture, system and class levels, but few studies have investigated stability at the package level.
Objective
In this paper, we propose a new package stability metrics (PSM) based on the notion of change between package contents, intra-package connections and inter-package connections.
Method
We validate the PSM theoretically and empirically. The theoretical validation is based on a study of the 
mathematical properties
 of the metrics. The empirical validation is carried out using five 
open source software
 programs and we also present a comparison with comparable existing stability metrics packages. For the empirical validation, we perform correlation analysis, 
principal component
 analysis and prediction analysis.
Results
Correlation analysis shows that our proposed metrics provides a better indication of package stability than the existing stability metrics and they are negatively correlated with the maintenance effort. Principal component analysis shows that the proposed metrics captures new dimensions of package stability and helps to increase the maintenance prediction accuracy.
Conclusion
We found there was a negative correlation between our metric and maintenance effort. We also found a 
positive correlation
 between the existing package stability metrics which are based on changes in lines of code and class names.",December 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The introduction of package stability metrics at different levels and validation through theoretical and empirical analysis presents a significant contribution to software stability and maintainability.
https://www.sciencedirect.com/science/article/pii/S0950584919301703,Evaluating probabilistic software development effort estimates: Maximizing informativeness subject to calibration,Magne=Jørgensen: magnej@simula.no,"Abstract
Context
Probabilistic effort estimates inform about the uncertainty and may give useful input to plans, budgets and investment analyses.
Objective & method
This paper introduces, motivates and illustrates two principles on how to evaluate the accuracy and other performance criteria of probabilistic effort estimates in software development contexts.
Results
The first principle emphasizes a consistency between the 
estimation error
 measure and the loss function of the chosen type of probabilistic single point effort estimates. The second 
principle points
 at the importance of not just measuring calibration, but also informativeness of estimated prediction intervals and distributions. The relevance of the evaluation principles is illustrated by a performance evaluation of estimates from twenty-eight software professionals using two different uncertainty assessment methods to estimate the effort of the same thirty software maintenance tasks.",November 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The principles introduced for evaluating probabilistic effort estimates in software development contexts provide valuable guidelines for assessing accuracy and performance criteria, contributing to better planning, budgets, and investment analyses."
https://www.sciencedirect.com/science/article/pii/S0950584919301375,Model driven transformation development (MDTD): An approach for developing model to model transformation,Ana Patrícia Fontes=Magalhaes: apmagalhaes@uneb.br,"Abstract
Context
In the Model Driven Development (MDD) approach, model transformations are responsible for the semi-automation of software development process converting models between different abstraction levels. The development of model transformations involves a complexity inherent to the transformation domain, in addition to the complexity of software development in general. Therefore, the construction of model transformations requires software engineering feature such as processes and languages to facilitate its development and maintenance.
Objective
This paper presents a framework to develop unidirectional relational model transformation using the MDD approach itself, which integrates: (i) a software development process suitable for the model transformation domain (ii) a Domain specific language for transformation modeling (iii) a transformation chain, to (semi) automate the proposed process, and (iv) a development environment to support it.
Methods
The proposal systematizes the development of model transformation, following the MDD principles. An iterative and incremental process guides transformation development from requirement specification to transformation codification. The proposal has been evaluated through a 
case study
 and a controlled experiment.
Results
The framework enables model transformation specification at a high abstraction level and (semi) automatically transforms it into models at a low abstraction level until the transformation code. The results of the case study showed that people with different levels of knowledge of MDD, or without experience in transformation languages, were able to develop transformations through the framework and generated executable code.
Conclusions
The framework integrates the essential elements involved in the development of model transformation and enables the abstraction of technological details. The results of the case study and controlled experiment showed the feasibility of the proposal and its use in dealing with the complexity involved in model transformation development.",October 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The framework for model transformation development using MDD principles could offer valuable automation and abstraction benefits to European startups, enhancing their software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584919301429,Log mining to re-construct system behavior: An exploratory study on a large telescope system,Juan Pablo=Gil: juan.gil@alma.cl; Patricio=Galeas: patricio.galeas@ufrontera.cl; Barbara=Russo: barbara.russo@unibz.it,"Abstract
Context
A large amount of information about 
system behavior
 is stored in logs that record system changes. Such information can be exploited to discover anomalies of a system and the operations that cause them. Given their large size, manual inspection of logs is hard and infeasible in a desired timeframe (e.g., real-time), especially for 
critical systems
.
Objective
This study proposes a semi-automated method for reconstructing sequences of tasks of a system, revealing system anomalies, and associating tasks and anomalies to code components.
Method
The proposed approach uses unsupervised 
machine learning
 (Latent Dirichlet Allocation) to discover latent topics in messages of log events and introduces a novel technique based on pattern recognition to derive the semantic of such topics (topic labelling). The approach has been applied to the 
big data
 generated by the ALMA telescope system consisting of more than 2000 log events collected in about five hours of telescope operation.
Results
With the application of our approach to such data, we were able to model the behavior of the telescope over 16 different observations. We found five different behavior models and three different types of errors. We use the models to interpret each error and discuss its cause.
Conclusions
With this work, we have also been able to discuss some of the known challenges in log mining. The experience we gather has been then summarized in lessons learned.",October 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The semi-automated method for reconstructing sequences of tasks of a system and discovering system anomalies using machine learning can provide valuable insights for European startups dealing with critical systems and real-time data analysis.
https://www.sciencedirect.com/science/article/pii/S0950584919301442,A conceptual perspective on interoperability in context-aware software systems,Rebeca C.=Motta: rmotta@cos.ufrj.br,"Abstract
Context
Context-aware software systems can interact with different devices to complete their tasks and act according to the context, regardless of their development and organizational differences. Interoperability is a big challenge in the engineering of such systems.
Objective
To discuss how interoperability has been addressed in context-aware software systems, strengthening the scientific basis for its understanding and conceptualization.
Method
A 
quasi
-systematic literature review was undertaken to observe interoperability in such context-aware software systems to support the discussions. Its dataset includes 17 from 408 papers identified in the technical literature. The extracted information was qualitatively analyzed by following the principles of Grounded Theory.
Results
The analysis allowed to identify ten interoperability concepts, organized into a Theoretical Framework according to structural and behavioral perspectives, which deals with interoperability as the ability of things (an object, a place, an application or anything that can engage interaction with a system) to interact for a particular purpose, once their differences (development platforms, 
data formats
, culture, legal issues) have been overcome. Once the interoperability is established from structural concepts (context, perspective, purpose, the level of provided support and system attributes), it can be measured, improved and observed from the behavioral concepts (evaluation method, challenges, issues, and benefits).
Conclusions
The Interoperability Theoretical Framework provides relevant information to organize the knowledge related to interoperability, considering context, and can be used to guide the evolution of software systems regarding changes focused on interoperability.",October 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The abstract discusses the challenges of interoperability in context-aware software systems, providing a theoretical framework for understanding and improving it. While relevant for software systems, the impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584919301004,Interactive semi-automated specification mining for debugging: An experience report,Mohammad Jafar=Mashhadi: mohammadjafar.mashha@ucalgary.ca; Taha R.=Siddiqui: trsiddiqui1989@gmail.com; Hadi=Hemmati: hadi.hemmati@ucalgary.ca; Howard=Loewen: hloewen@micropilot.com,"Abstract
Context
Specification mining techniques are typically used to extract the specification of a software in the absence of (up-to-date) specification documents. This is useful for 
program comprehension
, testing, and 
anomaly detection
. However, specification mining can also potentially be used for debugging, where a faulty behavior is abstracted to give developers a context about the bug and help them locating it.
Objective
In this project, we investigate this idea in an industrial setting. We propose a very basic semi-automated specification mining approach for debugging and apply that on real reported issues from an AutoPilot software system from our industry partner, MicroPilot Inc. The objective is to assess the feasibility and usefulness of the approach in a real-world setting.
Method
The approach is developed as a prototype tool, working on C code, which accept a set of relevant state fields and functions, per issue, and generates an extended 
finite state machine
 that represents the faulty behavior, abstracted with respect to the relevant context (the selected fields and functions).
Results
We qualitatively evaluate the approach by a set of interviews (including observational studies) with the company’s developers on their real-world reported bugs. The results show that (a) our approach is feasible, (b) it can be automated to some extent, and (c) brings advantages over only using their code-level debugging tools. We also compared this approach with traditional fully automated state-merging algorithms and reported several issues when applying those techniques on a real-world debugging context.
Conclusion
The main conclusion of this study is that the idea of an “interactive” specification mining rather than a fully automated mining tool is NOT impractical and indeed is useful for the debugging use case.",September 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The research on semi-automated specification mining for debugging in an industrial setting provides a tangible and potentially useful tool for European early-stage ventures to improve software development processes.
https://www.sciencedirect.com/science/article/pii/S0950584919301247,M-Lean: An end-to-end development framework for predictive models in B2B scenarios,James=Miller: jimm@ualberta.ca; Mona=Nashaat: nashaata@ualberta.ca,"Abstract
Context
The need for 
business intelligence
 has led to advances in 
machine learning
 in the business domain, especially with the rise of 
big data analytics
. However, the resulting predictive systems often fail to maintain a satisfactory level of performance in production. Besides, for predictive systems used in business-to-business scenarios, user trust is subject to the model performance. Therefore, the processes of creating, evaluating, and deploying machine 
learning systems
 in the business domain need innovative solutions to solve the critical challenges of assuring the quality of the resulting systems.
Objective
Applying 
machine learning
 in business-to-business situations imposes specific requirements. This paper aims at providing an integrated solution to businesses to help them transform their data into actions.
Method
The paper presents 
MLean
, an end-to-end framework, that aims at guiding businesses in designing, developing, evaluating, and deploying business-to-business predictive systems. The framework employs the 
Lean Startup
 methodology and aims at maximizing the business value while eliminating wasteful development practices.
Results
To evaluate the proposed framework, with the help of our industrial partner, we applied the framework to a 
case study
 to build a predictive product. The 
case study
 resulted in a predictive system to predict the risks of software license cancellations. The system was iteratively developed and evaluated while adopting the management and end-user perspectives.
Conclusion
It is concluded that, in industry, it is important to be aware of the businesses requirements before considering the application of machine learning. The framework accommodates business perspective from the beginning to produce a holistic product. From the results of the case study, we think that this framework can help businesses define the right opportunities for applying machine learning, developing solutions, evaluating the effectiveness of these solutions, and maintaining their performance in production.",September 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The MLean framework aiming to guide businesses in designing, developing, evaluating, and deploying predictive systems could provide valuable insights to startups on transforming data into actions, but the impact may be limited compared to other abstracts focusing directly on software development."
https://www.sciencedirect.com/science/article/pii/S0950584919300710,Selecting component sourcing options: A survey of software engineering’s broader make-or-buy decisions,Markus=Borg: markus.borg@ri.se,"Abstract
Context
Component-based software engineering (CBSE) is a common approach to develop and evolve contemporary software systems. When evolving a system based on components, make-or-buy decisions are frequent, i.e., whether to develop components internally or to acquire them from 
external sources
. In CBSE, several different sourcing options are available: (1) developing software in-house, (2) outsourcing development, (3) buying commercial-off-the-shelf software, and (4) integrating 
open source software
 components.
Objective
Unfortunately, there is little available research on how organizations select component sourcing options (CSO) in industry practice. In this work, we seek to contribute empirical evidence to CSO selection.
Method
We conduct a cross-domain survey on CSO selection in industry, implemented as an online questionnaire.
Results
Based on 188 responses, we find that most organizations consider multiple CSOs during software evolution, and that the CSO decisions in industry are dominated by 
expert judgment
. When choosing between candidate components, functional suitability acts as an initial filter, then reliability is the most important quality.
Conclusion
We stress that future solution-oriented work on decision support has to account for the dominance of expert judgment in industry. Moreover, we identify considerable variation in CSO decision processes in industry. Finally, we encourage software development organizations to reflect on their decision processes when choosing whether to make or buy components, and we recommend using our survey for a first benchmarking.",August 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,5.0,"The research on component sourcing options (CSO) selection in industry provides valuable insights, but the practical impact on startups may be limited compared to other abstracts focusing on specific software development processes and improvements."
https://www.sciencedirect.com/science/article/pii/S0950584919300916,Using a many-objective approach to investigate automated refactoring,Des=Greer: des.greer@qub.ac.uk,"Abstract
Context
Software maintenance is expensive and so anything that can be done to reduce its cost is potentially of huge benefit. However, it is recognised that some maintenance, especially refactoring, can be automated. Given the number of possible refactorings and combinations of refactorings, a search-based approach may provide the means to optimise refactorings.
Objective
This paper describes the investigation of a many-objective 
genetic algorithm
 used to automate software refactoring, implemented as a Java tool, MultiRefactor.
Method
The approach and tool is evaluated using a set of open source Java programs. The tool contains four separate measures of software looking at the software quality as well as measures of code priority, refactoring coverage and element recentness. The many-objective algorithm combines the four objectives to improve the software in a holistic manner. An experiment has been constructed to compare the many-objective approach against a mono-objective approach that only uses a single objective to measure software quality. Different permutations of the objectives are also tested and compared to see how well the different objectives can work together in a multi-objective refactoring approach. The eight approaches are tested on six different open source Java programs.
Results
The many-objective approach is found to give better objective scores on average than the mono-objective approach and in less time. However, the priority and element recentness objectives are both found to be less successful in multi/many-objective setups when they are used together.
Conclusion
A many-objective approach is suitable and effective for optimising 
automated refactoring
 to improve quality. Including other objectives does not unduly degrade the quality improvements, but is less effective for those objectives than if they were used in a mono-objective approach.",August 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,4.0,"The investigation of a many-objective genetic algorithm for automating software refactoring is valuable for reducing maintenance costs, but the direct impact on early-stage ventures may be limited as they might not be heavily involved in software maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584919300977,A bug finder refined by a large set of open-source projects,Jaechang=Nam: jcnam@handong.edu; Song=Wang: song.wang@uwaterloo.ca; Yuan=Xi: y25xi@uwaterloo.ca; Lin=Tan: lintan@uwaterloo.ca,"Abstract
Context
Static bug detection techniques are commonly used to automatically detect software bugs. The biggest obstacle to the wider adoption of static bug detection tools is 
false positives
, i.e., reported bugs that developers do not have to act on.
Objective
The objective of this study is to reduce 
false positives
 resulting from static bug detection tools and to detect new bugs by exploring the effectiveness of a feedback-based bug detection rule design.
Method
We explored a large number of software projects and applied an iterative feedback-based process to design bug detection rules. The outcome of the process is a set of ten bug detection rules, which we used to build a feedback-based bug finder, 
FeeFin
. Specifically, we manually examined 1622 patches to identify bugs and fix patterns, and implement bug detection rules. Then, we refined the rules by repeatedly using feedback from a large number of software projects.
Results
We applied 
FeeFin
 to the latest versions of the 1880 projects on GitHub to detect previously unknown bugs. 
FeeFin
 detected 98 new bugs, 63 of which have been reviewed by developers: 57 were confirmed as true bugs, and 9 were confirmed as false positives. In addition, we investigated the benefits of our 
FeeFin
 process in terms of new and improved bug patterns. We verified our bug patterns with four existing tools, namely PMD, FindBugs, Facebook Infer, and Google Error Prone, and found that our FeeFin process has the potential to identify new bug patterns and also to improve existing bug patterns.
Conclusion
Based on the results, we suggest that static bug detection tool designers identify new bug patterns by mining real-world patches from a large number of software projects. In addition, the 
FeeFin
 process is helpful in mitigating false positives generated from existing tools by refining their bug detection rules.",August 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The feedback-based bug detection rule design proposed in this study can help reduce false positives in static bug detection tools, leading to more efficient bug detection in software projects, which is valuable for startups."
https://www.sciencedirect.com/science/article/pii/S0950584919300540,Search-based test case implantation for testing untested configurations,Shuai=Wang: shuai.wang@testify.no; Dipesh=Pradhan: dipesh@simula.no; Tao=Yue: tao@simula.no; Shaukat=Ali: shaukat@simula.no; Marius=Liaaen: marliaae@cisco.com,"Abstract
Context
Modern large-scale software systems are highly configurable, and thus require a large number of test cases to be implemented and revised for testing a variety of system configurations. This makes testing highly configurable systems very expensive and time-consuming.
Objective
Driven by our industrial collaboration with a video conferencing company, we aim to automatically analyze and implant existing test cases (i.e., an original test suite) to test the untested configurations.
Method
We propose a search-based test case implantation approach (named as SBI) consisting of two key components: 1) 
Test case analyzer
 that statically analyzes each test case in the original test suite to obtain the program 
dependence graph
 for test case statements and 2) 
Test case implanter
 that uses multi-objective search to select suitable test cases for implantation using three operators, i.e., selection, crossover, and mutation (at the test suite level) and implants the selected test cases using a 
mutation operator
 at the test case level including three operations (i.e., addition, modification, and deletion).
Results
We empirically evaluated SBI with an industrial 
case study
 and an open source 
case study
 by comparing the implanted test suites produced by three variants of SBI with the original test suite using 
evaluation metrics
 such as 
statement coverage
 (
SC
), branch coverage (
BC
), and mutation score (
MS
). Results show that for both the case studies, the test suites implanted by the three variants of SBI performed significantly better than the original test suites. The best variant of SBI achieved on average 19.3% higher coverage of configuration 
variable values
 for both the case studies. Moreover, for the open source case study, the best variant of SBI managed to improve 
SC, BC
, and 
MS
 with 5.0%, 7.9%, and 3.2%, respectively.
Conclusion
SBI can be applied to automatically implant a test suite with the aim of testing untested configurations and thus achieving higher configuration coverage.",July 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The SBI approach for automatic test case implantation shows promising results for improving configuration coverage, which can be highly beneficial for early-stage ventures in software testing."
https://www.sciencedirect.com/science/article/pii/S0950584919300606,A domain analysis of resource and requirements monitoring: Towards a comprehensive model of the software monitoring domain,Holger=Eichelberger: eichelberger@sse.uni-hildesheim.de; Klaus=Schmid: schmid@sse.uni-hildesheim.de; Rick=Rabiser: rick.rabiser@jku.at; Michael=Vierhauser: mvierhau@nd.edu; Sam=Guinea: sam.guinea@polimi.it; Paul=Grünbacher: paul.gruenbacher@jku.at,"Abstract
[Context]
 Complex and heterogeneous software systems need to be monitored as their full behavior often only emerges at runtime, e.g., when interacting with other systems or the environment. Software monitoring approaches observe and check properties or quality attributes of software systems during operation. Such approaches have been developed in diverse communities for various kinds of systems and purposes. For instance, requirements monitoring aims to check at runtime whether a software system adheres to its requirements, while resource or performance monitoring collects information about the consumption of computing resources by the monitored system. Many venues publish research on software monitoring, often using diverse terminology, and focusing on different monitoring aspects and phases. The lack of a comprehensive overview of existing research often leads to re-inventing the wheel. 
[Objective]
 We provide a domain model to structure and systematize the field of software monitoring, starting with requirements and resource monitoring. 
[Method]
 We developed an initial domain model based on (i) our extensive experiences with requirements and resource monitoring, (ii) earlier efforts to develop a comparison framework for monitoring approaches, and (iii) an earlier systematic literature review on requirements monitoring frameworks. We then systematically analyzed 47 existing requirements and resource monitoring approaches to iteratively refine the domain model and to develop a reference architecture for software monitoring approaches. 
[Results]
 Our domain model covers the key elements of monitoring approaches and allows analyzing their commonalities and differences. Together with the reference architecture, our domain model supports the development of integrated monitoring solutions. We provide details on 47 approaches we analyzed with the model to assess its coverage. We also evaluate the reference architecture by instantiating it for five different monitoring solutions. 
[Conclusions]
 We conclude that requirements and resource monitoring have more commonalities than differences, which is promising for the future integration of existing monitoring solutions.",July 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The domain model and reference architecture developed for software monitoring provide a comprehensive overview to prevent reinventing the wheel, which can greatly benefit the development of monitoring solutions."
https://www.sciencedirect.com/science/article/pii/S0950584918301344,GoalD: A Goal-Driven deployment framework for dynamic and heterogeneous computing environments,Alessia=Knauss: alessia.knauss@chalmers.se; Raian=Ali: rali@bournemouth.ac.uk; Hugo=Andrade: sica@chalmers.se; Gabriel S.=Rodrigues: gabrielsr@aluno.unb.br; Felipe P.=Guimarães: felipe.guimaraes@aeb.gov.br; Genaína N.=Rodrigues: genaina@unb.br,"Abstract
Context
Emerging paradigms like 
Internet of Things
 and Smart Cities utilize advanced sensing and communication infrastructures, where heterogeneity is an inherited feature. Applications targeting such environments require adaptability and context-sensitivity to uncertain availability and failures in resources and their ad-hoc networks. Such heterogeneity is often hard to predict, making the 
deployment process
 a challenging task.
Objective
This paper proposes GoalD as a goal-driven framework to support autonomous deployment of heterogeneous 
computational resources
 to fulfill requirements, seen as goals, and their correlated components on one hand, and the variability space of the hosting computing and sensing environment on the other hand.
Method
GoalD comprises an offline and an online stage to fulfill autonomous deployment by leveraging the use of goals. Deployment configuration strategies arise from the variability structure of the Contextual Goal Model as an underlying structure to guide autonomous planning by selecting available as well as suitable resources at runtime.
Results
We evaluate GoalD on an existing exemplar from the self-adaptive systems community – the Tele Assistance Service provided by Weyns and Calinescu [1]. Furthermore, we evaluate the scalability of GoalD on a repository consisting of 430,500 artifacts. The evaluation results demonstrate the usefulness and scalability of GoalD in planning the deployment of a system with thousands of components in a few milliseconds.
Conclusion
GoalD is a framework to systematically tackle autonomous deployment in highly 
heterogeneous computing
 environments, partially unknown at design-time following a goal-oriented approach to achieve the user goals in a target environment. GoalD has demonstrated itself able to scale for deployment planning dealing with thousands of components in a few milliseconds.",July 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The framework proposed in this abstract can significantly impact early-stage ventures by supporting autonomous deployment in heterogeneous computing environments, demonstrating scalability and efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584919300436,FineLocator: A novel approach to method-level fine-grained bug localization by query expansion,Qing=Wang: wq@itechs.iscas.ac.cn; Wen=Zhang: zhangwen@bjut.buct.edu.cn; Ziqiang=Li: 2016200859@mail.buct.edu.cn; Juan=Li: lijuan@bjut.edu.cn,"Abstract
Context
Bug localization, namely, to locate suspicious snippets from 
source code
 files for developers to fix the bug, is crucial for 
software quality assurance
 and software maintenance. Effective bug localization technique is desirable for software developers to reduce the effort involved in bug resolution. State-of-the-art bug localization techniques concentrate on file-level coarse-grained localization by lexical matching 
bug reports
 and 
source code files
. However, this would bring about a heavy burden for developers to locate feasible code snippets to make change with the goal of fixing the bug.
Objective
This paper proposes a novel approach called FineLocator to method-level fine-grained bug localization by using semantic similarity, temporal proximity and call dependency for method expansion.
Method
Firstly, the 
bug reports
 and the methods of 
source code
 are represented by numeric vectors using 
word embedding
 (word2vec) and the TF-IDF method. Secondly, we propose three 
query expansion
 scores as semantic similarity score, temporal proximity score and call dependency score to address the representation sparseness problem caused by the short lengths of methods in the source code. Then, the representation of a method with short length is augmented by elements of its neighboring methods with 
query expansion
. Thirdly, when a new bug report is incoming, FineLocator will retrieve the methods in source code by similarity ranking on the bug report and the augmented methods for bug localization.
Results
We collect bug repositories of ArgoUML, Maven, Kylin, Ant and AspectJ projects to investigate the performance of the proposed FineLocator approach. Experimental results demonstrate that the proposed FineLocator approach can improve the performances of method-level bug localization at average by 20%, 21% and 17% measured by Top-N indicator, 
MAP
 and MRR respectively, in comparison with state-of-the-art techniques.
Conclusion
This is the first paper to demonstrate how to make use of method expansion to address the representation sparseness problem for method-level fine-grained bug localization.",June 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposed FineLocator approach for method-level bug localization demonstrates significant performance improvements, which can be valuable for startups aiming to enhance software quality assurance."
https://www.sciencedirect.com/science/article/pii/S0950584919300527,Reference Coupling: An exploration of inter-project technical dependencies and their characteristics within large software ecosystems,Kelly=Blincoe: kblincoe@acm.org; Francis=Harrison: francish@uvic.ca; Navpreet=Kaur: nkaur@uvic.ca; Daniela=Damian: danielad@uvic.ca,"Abstract
Context
Software projects often depend on other projects or are developed in tandem with other projects. Within such software ecosystems, knowledge of cross-project technical dependencies is important for (1) practitioners understanding of the impact of their code change and coordination needs within the ecosystem and (2) researchers in exploring properties of software ecosystems based on these technical dependencies. However, identifying technical dependencies at the ecosystem level can be challenging.
Objective
In this paper, we describe Reference Coupling, a new method that uses solely the information in developers online interactions to detect technical dependencies between projects. The method establishes dependencies through user-specified cross-references between projects. We then use the output of this method to explore the properties of large software ecosystems.
Method
We validate our method on two datasets — one from open-source projects hosted on GitHub and one commercial dataset of IBM projects. We manually analyze the identified dependencies, categorize them, and compare them to dependencies specified by the development team. We examine the types of projects involved in the identified ecosystems, the structure of the identified ecosystems, and how the ecosystems structure compares with the social behavior of project contributors and owners.
Results
We find that our Reference Coupling method often identifies technical dependencies between projects that are untracked by developers. We describe empirical insights about the characteristics of large software ecosystems. We find that most ecosystems are centered around one project and are interconnected with other ecosystems. By exploring the socio-technical alignment within the GitHub ecosystems, we also found that the project owners social behavior aligns well with the technical dependencies within the ecosystem, but the project contributors social behavior does not align with these dependencies.
Conclusions
We conclude with a discussion on future research that is enabled by our Reference Coupling method.",June 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,10.0,The Reference Coupling method for detecting technical dependencies between projects using developers' interactions can have a significant impact on startups by providing insights into software ecosystems and improving coordination needs.
https://www.sciencedirect.com/science/article/pii/S0950584919300035,Deriving architectural models from requirements specifications: A systematic mapping study,Miguel=Goulão: mgoul@fct.unl.pt; Eric=Souza: er.souza@campus.fct.unl.pt; Ana=Moreira: amm@fct.unl.pt,"Abstract
Context
Software architecture design
 creates and documents the high-level structure of a software system. Such structure, expressed in 
architectural models
, comprises software elements, relations among them, and properties of these elements and relations. Existing software architecture methods offer ways to derive 
architectural models
 from requirements specifications. These models must balance different forces that should be analyzed during this derivation process, such as those imposed by different application domains and quality attributes. Such balance is difficult to achieve, requiring skilled and experienced architects.
Object
The purpose of this paper is to provide a comprehensive overview of the existing methods to derive architectural models from requirements specifications and offer a research roadmap to challenge the community to address the identified limitations and open issues that require further investigation.
Method
To achieve this goal, we performed a 
systematic mapping study
 following the good practices from the Evidence-Based 
Software Engineering
 field.
Results
This study resulted in 39 primary studies selected for analysis and data extraction, from the 2575 initially retrieved.
Conclusion
The major findings indicate that current architectural derivation methods rely heavily on the architects’ 
tacit knowledge
 (experience and intuition), do not offer sufficient support for inexperienced architects, and lack explicit evaluation mechanisms. These and other findings are synthesized in a research roadmap which results would benefit researchers and practitioners.",May 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,3.0,"While providing an overview of existing methods for deriving architectural models, the paper focuses more on research challenges and lacks direct practical application for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919300084,Mining software repositories for adaptive change commits using machine learning techniques,Omar=Meqdadi: ommeqdadi@just.edu.jo; Nouh=Alhindawi: hindawi@jadara.edu.jo; Jamal=Alsakran: j.alsakran@ju.edu.jo; Ahmad=Saifan: ahmads@yu.edu.jo; Hatim=Migdadi: hatims@hu.edu.jo,"Abstract
Context
Version Control Systems, such as Subversion, are standard repositories that preserve all of the maintenance changes undertaken to source code artifacts during the evolution of a software system. The documented data of the version history are organized as commits; however, these commits do not keep a tag that would identify the purpose of the relevant undertaken change of a commit, thus, there is rarely enough detail to clearly direct developers to the changes associated with a specific type of maintenance.
Objective
This work examines the version histories of an 
open source system
 to automatically classify version commits into one of two categories, namely adaptive commits and non-adaptive commits.
Method
We collected the commits from the version history of three open source systems, then we obtained eight different code change metrics related to, for example, the number of changed statements, methods, hunks, and files. Based on these change metrics, we built a 
machine learning approach
 to classify whether a commit was adaptive or not.
Results
It is observed that code change metrics can be indicative of adaptive maintenance activities. Also, the classification findings show that the 
machine learning
 classifier developed has approximately 75% prediction accuracy within labeled change histories.
Conclusion
The proposed method automates the process of examining the version history of a software system and identifies which commits to the system are related to an adaptive maintenance task. The evaluation of the method supports its applicability and efficiency. Although the evaluation of the proposed classifier on unlabeled change histories shows that it is not much better than the random guessing in terms of 
F
-measure, we feel that our classifier would serve as a better basis for developing advanced classifiers that have 
predictive power
 of adaptive commits without the need of manual efforts.",May 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The automated classification of version commits into adaptive and non-adaptive categories using machine learning can significantly streamline software development processes for startups.
https://www.sciencedirect.com/science/article/pii/S0883902625000126,Outside board director experience and the growth of new ventures,Tatevik=Harutyunyan: Tatevik.Harutyunyan@kristiania.no; Bram=Timmermans: Bram.Timmermans@nhh.no; Lars=Frederiksen: L.Frederiksen@mgmt.au.dk,"Abstract
Most research on entrepreneurship focuses on entrepreneurs' human and social capital as the drivers of new venture performance. However, less is known about how much the endowments of other strategic human resources, namely board directors, influence new venture performance. To generate new insights on this topic, we theorize and empirically investigate to what extent, and under which conditions, the experience of outside board directors affects new venture growth. Our analysis of Norwegian registry data on 15,594 new ventures does not provide immediate evidence that the presence of outside board directors or their experiences drive new venture growth. However, post hoc analysis suggests that the timing of board entry, combined with industry and directorial experience, plays a significant role in shaping growth outcomes. Additionally, the impact of industrial and directorial experience varies depending on the industry environment.",May 2025,"Board of directors, Industry experience, Directorial experience, New ventures, New venture growth, Environmental characteristics",Business Venturing,2025-03-21T00:00:00,7.0,"The study provides insights on the impact of outside board directors on new venture growth, highlighting the importance of timing, industry, and experiential factors. This knowledge can benefit early-stage ventures by optimizing board composition and entry strategies."
https://www.sciencedirect.com/science/article/pii/S0950584918302489,Software feature refinement prioritization based on online user review mining,Jianzhang=Zhang: jianzhang.zhang2017@gmail.com; Yinglin=Wang: wang.yinglin@shufe.edu.cn; Tian=Xie: xietiansh@gmail.com,"Abstract
Context
Online software reviews have provided a wealth of user feedback on 
software applications
. User reviews along with ratings have been influential in a series of 
software engineering
 tasks e.g. software maintenance and release planning.
Objective
Our research aims to assist managers in prioritizing features to be refined in next release from the perspective of enhancing user ratings via mining online reviews.
Method
We first extract software features from user reviews and determine their probability distribution in each review with 
LDA
. Then the ground truth rating of each feature is estimated by linear regression under the assumption that the software functionality rating is a 
convex combination
 of all feature ratings weighted by their distribution probabilities over the review. Finally, we formalize feature refinement prioritization as an 
optimization problem
 which maximizes user group’s rating on the software functionality under the constraint of development budget.
Results
The proposed approach can use topic model to jointly extract features from user reviews semi-supervisedly and determine each feature’s weight in each user’s rating on the software functionality. The estimated ground truth ratings of all features reveal how reviewer group evaluate those features. Finally, we provide an illustrative example to demonstrate the key idea of our framework.
Conclusion
Our proposed framework is general to various software products with mass user reviews and semi-automatic without much human efforts and intervention. The framework’s 
interpretability
 helps managers better understand user feedback on the software functionality and make feature refinement plan for the upcoming releases.",April 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,"The research on prioritizing feature refinements based on user ratings from online reviews can assist software managers in making data-driven decisions for product enhancement, offering practical value to startups."
https://www.sciencedirect.com/science/article/pii/S095058491830243X,Little’s law based validation framework for load testing,Raghu=Ramakrishnan: raghuramakrishnan71@gmail.com; Arvinder=Kaur: arvinder70@gmail.com,"Abstract
Context:
 Performance is a key quality consideration for large-scale software systems which supports thousands of concurrent users. Load testing is an integral part of the 
development lifecycle
 and is used to address performance issues before deploying the system in production. But, how do we validate the output reported by load testing tools? Little’s Law is useful for validating the accuracy of load testing output. Though IT industry is flooded with various enterprise and 
open source tools
 for load testing, but they do not offer support for validation of its result using Little’s Law. 
Manual validation
 is time intensive and infeasible with increase in the complexity of testing scripts.
Objective:
 In this paper we provide a Little’s law-based validation framework which will enable the researchers and industry practitioners to validate load testing results. The implementation of the framework is also demonstrated.
Method:
 To understand the constructs commonly used in 
load test
 scripts, we analysed scripts of two open source 
benchmark applications
 and eight large-scale software systems used in industry. We found that transactions are arranged using control flow patterns like sequential, loop and conditional. Based on the analysis, we devised the framework.
Results:
 The efficacy of the proposed framework is successfully evaluated on two systems - an open source Dell DVD Store benchmarking application and a real-world 
large scale system
 used in industry. The framework is independent of load testing tool used and can be used with complex testing scripts.
Conclusions
 There are no known frameworks or inbuilt support in existing load testing tools for guiding practitioners on applying Little’s Law using output generated by tools. We address this significant gap by providing a framework which combines information from test scripts/reports and Little’s Law to determine whether the results are valid. The provided implementation can be easily integrated with existing load testing tools.",April 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,The Little's law-based validation framework for load testing results fills a significant gap in the industry. The practical application and successful evaluation on real-world systems highlight its potential impact on improving performance testing practices for startups and early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584918302222,API recommendation for event-driven Android application development,Weizhao=Yuan: weizhaoy@163.com; Hoang H.=Nguyen: mr.erichoang@gmail.com; Lingxiao=Jiang: lxjiang@smu.edu.sg; Yuting=Chen: chenyt@cs.sjtu.edu.cn; Jianjun=Zhao: zhao@ait.kyushu-u.ac.jp; Haibo=Yu: haibo_yu@sjtu.edu.cn,"Abstract
Context
Software development is increasingly dependent on existing libraries. Developers need help to find suitable library APIs. Although many studies have been proposed to recommend relevant functional APIs that can be invoked for implementing a functionality, few studies have paid attention to an orthogonal need associated with event-driven programming frameworks, such as the 
Android
 framework. In addition to invoking functional APIs, Android developers need to know where to place functional code according to various events that may be triggered within the framework.
Objective
This paper aims to develop an API recommendation engine for 
Android application
 development that can recommend both (1) functional APIs for implementing a functionality and (2) the event callback APIs that are to be overridden to contain the functional code.
Method
We carry out an empirical study on actual Android programming questions from StackOverflow to confirm the need of recommending callbacks. Then we build Android-specific API databases to contain the correlations among various functionalities and APIs, based on customized 
parsing
 of code snippets and 
natural language processing
 of texts in Android tutorials and SDK documents, and then textual and code similarity metrics are adapted for recommending relevant APIs.
Results
We have evaluated our prototype recommendation engine, named LibraryGuru, with about 1500 questions on Android programming from StackOverflow, and demonstrated that our top-5 results on recommending callbacks and functional APIs can on estimate achieve up to 43.5% and 50.9% respectively in precision, 24.6% and 32.5% respectively in 
mean average precision
 (MAP) scores, and 51.1% and 44.0% respectively in recall.
Conclusion
We conclude that it is important and possible to recommend both functional APIs and callbacks for 
Android application
 development, and future work is needed to take more data sources into consideration to make more relevant recommendations for developers’ needs.",March 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The abstract presents an API recommendation engine for Android application development, addressing the need for recommending functional APIs and event callback APIs. While the results show promising precision, recall, and MAP scores, the practical impact may be more specific to Android developers and may have a narrower focus compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584918302404,Athena: A framework to automatically generate security test oracle via extracting policies from source code and intended software behaviour,Hossein=Homaei: homayi@aut.ac.ir; Hamid Reza=Shahriari: shahriari@aut.ac.ir,"Abstract
Context:
 Software security testing aims to check the security behaviour of a program. To determine whether the program behaves securely on a particular execution, we need an oracle who knows the expected security behaviour. Security test oracle decides whether test cases violate the intended security policies of the program. Thus, it is necessary for the oracle to model the detailed security policies. Unfortunately, these policies are usually poorly documented. Even worse, in some cases, the source code is the only available document of the program.
Objective:
 We propose a method to automatically extract the intended security policies of the program under test from the source code and expected execution traces. We introduce a security test oracle, Athena, which utilises these policies to differentiate between the secure and potentially insecure behaviour of the program.
Method:
 We use a hybrid analysis approach to obtain the intended security policies. We investigate the program statements (gates) in which the software communicates with the environment. We analyse the transmitted messages in the gates and the control and data flow of the program to extract some security properties. Moreover, we specify the intended navigation paths of the program. These properties and paths form the expected security policies. Athena utilises these policies to detect potential 
security breaches
.
Results:
 Investigating common types of software vulnerabilities illustrates the flexibility of Athena in modelling various kinds of security policies. Moreover, we show the usefulness of the method by applying it to the real web applications and evaluating its capability to detect actual attacks.
Conclusions:
 Our proposed approach takes a step towards solving the test oracle automation problem in the domain of security testing.",March 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The proposed method for automatically extracting security policies from source code for security testing can be crucial for startups to ensure the security of their programs and detect potential breaches.
https://www.sciencedirect.com/science/article/pii/S0883902624000880,Atypical entrepreneurs in the venture idea elaboration phase,Saggi=Nevo: nevos@rpi.edu,"Highlights
•
The paper explains why atypical nascent entrepreneurs may not receive the feedback they need for elaborating a venture idea.
•
The paper shows that a Black/White woman nascent entrepreneur is likely to be sanctioned for entering a profession with which she is seen as incongruent.
•
Although both are atypical entrepreneurs, nascent Black and White women entrepreneurs are associated with different stereotypes and receive different types of venture-related feedback.
•
Feedback providers are influenced by ingroup consensus, which can reduce their susceptibility to social stereotypes.",March 2025,"Venture idea elaboration, Nascent entrepreneurs, Atypical entrepreneurship, Social group stereotypes, Person-profession congruence, Feedback types",Business Venturing,2025-03-21T00:00:00,3.0,The focus on stereotype impacts on feedback for atypical entrepreneurs may have limited direct practical implications for early-stage ventures in Europe.
https://www.sciencedirect.com/science/article/pii/S0950584918302453,VFL: Variable-based fault localization,Eunseok=Lee: leees@skku.edu; Jeongho=Kim: jeonghodot@skku.edu; Jindae=Kim: jdkim@cse.ust.hk,"ABSTRACT
Context
Fault localization
 is one of the most important debugging tasks. Hence, many automatic fault localization techniques have been proposed to reduce the burden on developers for such tasks. Among them, Spectrum-based Fault Localization (SFL) techniques leverage coverage information and localize faults based on the coverage difference between the failed and passed test cases.
Objective
However, such SFL techniques cannot localize faults effectively when coverage differences are not clear. To address this issue and improve the fault localization performance of the SFL techniques, we propose a Variable-based Fault Localization (VFL) technique.
Method
The VFL technique identifies suspicious variables and uses them to generate a ranked list of suspicious source code lines. Since it only requires additional information about variables that are also available in the SFL techniques, the proposed technique is lightweight and can be used to improve the performance of existing the SFL techniques.
Results
In an evaluation with 224 real Java faults and 120 C faults, the VFL technique outperforms the SFL techniques using the same similarity coefficient. The average Exam scores of the VFL techniques are reduced by more than 55% compared to the SFL techniques, and the VFL techniques localize faults at a lower rank than the SFL techniques for about 73% of the 344 faults.
Conclusion
We proposed a novel variable-based fault localization technique for more effective debugging. The VFL technique has better performance than the existing techniques and the results were more useful for actual fault localization tasks. In addition, this technique is very lightweight and scalable, so it is very easy to collaborate with other fault localization techniques.",March 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The VFL technique offers a novel approach to fault localization, outperforming existing SFL techniques in terms of effectiveness and efficiency. The lightweight and scalable nature of the proposed technique makes it particularly valuable for early-stage ventures looking to enhance debugging processes."
https://www.sciencedirect.com/science/article/pii/S0950584918301915,Automated metamodel/model co-evolution: A search-based approach,Wael=Kessentini: kessentw@iro.umontreal.ca,"Abstract
Context:
 Metamodels evolve over time to accommodate new features, improve existing designs, and fix errors identified in previous releases. One of the obstacles that may limit the adaptation of new metamodels by developers is the extensive manual changes that have been applied to migrate existing models. Recent studies addressed the problem of automating the metamodel/model co-evolution based on manually defined migration rules. The definition of these rules requires the list of changes at the metamodel level which are difficult to fully identify. Furthermore, different possible alternatives may be available to translate a metamodel change to a model change. Thus, it is hard to generalize these co-evolution rules.
Objective:
 We propose an alternative automated approach for the metamodel/model co-evolution. The proposed approach refines an initial model instantiated from the previous metamodel version to make it as conformant as possible to the new metamodel version by finding the best compromise between three objectives, namely minimizing (
i
) the non-conformities with new metamodel version, (
ii
) the changes to existing models, and (
iii
) the textual and structural dissimilarities between the initial and revised models.
Method:
 We formulated the metamodel/model co-evolution as a multi-objective 
optimization problem
 to handle the different conflicting objectives using the Non-dominated Sorting Genetic Algorithm II (NSGA-II) and the Multi-Objective 
Particle Swarm Optimization
 (MOPSO).
Results:
 We evaluated our approach on several evolution scenarios extracted from different widely used metamodels. The results confirm the effectiveness of our approach with average manual correctness, precision and recall respectively higher than 91%, 88% and 89% on the different co-evolution scenarios.
Conclusion:
 A comparison with our previous work confirms the out-performance of our multi-objective formulation.",February 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,The proposed approach for metamodel/model co-evolution addresses a common challenge in software development and offers an automated solution. This could have a practical impact on startups by reducing manual efforts and improving efficiency.
https://www.sciencedirect.com/science/article/pii/S0950584918301940,A pilot empirical study of applying a usability technique in an open source software project,Silvia T.=Acuña: silvia.acunna@uam.es; Lucrecia=Llerena: lucrecia.llerena@estudiante.uam.es; John W.=Castro: john.castro@alumni.uam.es,"Abstract
Context
The growth in the number of non-technical 
open source software
 (OSS) application users and the escalating use of these applications have redoubled the need for, and interest in, developing usable OSS. OSS communities are unclear about which techniques to use in each 
development process
 activity.
Objective
The aim of our research is to adapt a usability technique (visual brainstorming) to an 
OSS project
 and evaluate the feasibility of its application.
Method
We used the 
case study
 research method to investigate technique application and participation in a project. To do this, we participated as volunteers in the HistoryCal project.
Results
We identified adverse conditions that were an obstacle to technique application (like it was not easy to recruit OSS users to participate) and modified the technique to make it applicable.
Conclusion
We conclude that these changes were helpful for applying the technique using web artifacts like blogs.",February 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,7.0,"The research on adapting usability techniques for OSS projects can potentially enhance the user experience and development process, which is beneficial for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584918302088,Software defect prediction based on kernel PCA and weighted extreme learning machine,Jin=Liu: jinliu@whu.edu.cn,"Abstract
Context
Software 
defect prediction
 strives to detect defect-prone software modules by mining the 
historical data
. Effective prediction enables reasonable testing 
resource allocation
, which eventually leads to a more reliable software.
Objective
The complex structures and the imbalanced class distribution in software defect data make it challenging to obtain suitable data features and learn an effective 
defect prediction
 model. In this paper, we propose a method to address these two challenges.
Method
We propose a defect prediction framework called 
KPWE
 that combines two techniques, i.e., 
Kernel 
Principal Component
 A
nalysis (
KPCA
) and 
Weighted 
Extreme Learning Machine
 (
WELM
). Our framework consists of two major stages. In the first stage, KPWE aims to extract representative data features. It leverages the KPCA technique to project the original data into a latent 
feature space
 by 
nonlinear mapping
. In the second stage, KPWE aims to alleviate the 
class imbalance
. It exploits the WELM technique to learn an effective defect prediction model with a weighting-based scheme.
Results
We have conducted extensive experiments on 34 projects from the PROMISE dataset and 10 projects from the NASA dataset. The experimental results show that KPWE achieves promising performance compared with 41 
baseline methods
, including seven basic classifiers with KPCA, five variants of KPWE, eight representative feature selection methods with WELM, 21 imbalanced learning methods.
Conclusion
In this paper, we propose KPWE, a new software defect prediction framework that considers the feature extraction and 
class imbalance
 issues. The empirical study on 44 software projects indicate that KPWE is superior to the 
baseline methods
 in most cases.",February 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,9.0,"The proposal of KPWE framework to address challenges in software defect prediction, along with promising experimental results, offers startups a valuable tool to enhance defect prediction and improve software quality."
https://www.sciencedirect.com/science/article/pii/S0883902624000892,The leisure paradox for entrepreneurs: A neo-institutional theory perspective of disclosing leisure activities in crowdfunding pitches,Aaron H.=Anglin: a.anglin@tcu.edu; Jeffrey A.=Chandler: jeffrey.chandler@unt.edu; Jacob A.=Waddingham: jwaddingham@txstate.edu; Katherine C.=Alexander: kalexander7@luc.edu; Sana=Zafar: szafar@georgiasouthern.edu,"Abstract
Drawing from neo-institutional theory, we examine how entrepreneurs' disclosure of leisure activities influences the performance of their crowdfunding campaigns. We propose that entrepreneurs' disclosure of leisure activities in their campaigns negatively impacts crowdfunding performance because an institutional norm exists pressuring early-stage entrepreneurs to conform to workaholism. Using a sample of 8511 Kickstarter campaigns and a randomized experiment (
n
 = 436), we find evidence that entrepreneurs who disclose leisure activities are viewed as less workaholic. This, in turn, hurts backers' perceptions of the entrepreneurs' legitimacy, leading to lower crowdfunding performance. We also find women backers are more tolerant of entrepreneurs disclosing their leisure activities than men.",March 2025,Not Found,Business Venturing,2025-03-21T00:00:00,4.0,"The study on leisure activities disclosure in crowdfunding campaigns sheds light on how perceptions affect campaign performance, which could be relevant for European startups seeking crowdfunding."
https://www.sciencedirect.com/science/article/pii/S0950584918301654,Improving bug localization with word embedding and enhanced convolutional neural networks,Jacky Wai=Keung: Jacky.Keung@cityu.edu.hk; Yan=Xiao: yanxiao6-c@my.cityu.edu.hk; Kwabena E.=Bennin: kebennin2-c@my.cityu.edu.hk; Qing=Mi: Qing.Mi@my.cityu.edu.hk,"Abstract
Context:
 Automatic localization of buggy files can speed up the process of bug fixing to improve the efficiency and productivity of 
software quality assurance
 teams. Useful 
semantic information
 is available in 
bug reports
 and 
source code
, but it is usually underutilized by existing bug localization approaches.
Objective:
 To improve the performance of bug localization, we propose DeepLoc, a novel deep learning-based model that makes full use of 
semantic information
.
Method:
 DeepLoc is composed of an enhanced convolutional 
neural network
 (CNN) that considers bug-fixing recency and frequency, together with word-embedding and feature-detecting techniques. DeepLoc uses word embeddings to represent the words in 
bug reports
 and source files that retain their semantic information, and different CNNs to detect features from them. DeepLoc is evaluated on over 18,500 bug reports extracted from AspectJ, Eclipse, JDT, SWT, and Tomcat projects.
Results:
 The experimental results show that DeepLoc achieves 10.87%–13.4% higher MAP (mean average precision) than conventional CNN. DeepLoc outperforms four current state-of-the-art approaches (DeepLocator, HyLoc, LR+WE, and BugLocator) in terms of Accuracy@k (the percentage of bug reports for which at least one real buggy file is located within the top 
k
 rank), MAP, and MRR (mean reciprocal rank) using less 
computation time
.
Conclusion:
 DeepLoc is capable of automatically connecting bug reports to the corresponding buggy files and achieves better performance than four state-of-the-art approaches based on a 
deep understanding
 of semantics in bug reports and 
source code
.",January 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,10.0,"The proposal of DeepLoc, a deep learning-based bug localization model, offers a novel approach to improving software quality assurance processes, which can greatly benefit early-stage ventures by enhancing bug-fixing efficiency and productivity."
https://www.sciencedirect.com/science/article/pii/S095058491830171X,An exploratory study of waste in software development organizations using agile or lean approaches: A multiple case study at 14 organizations,Tony=Gorschek: tony.gorschek@bth.se; Hiva=Alahyari: hiva@chalmers.se; Richard=Berntsson Svensson: richard.berntsson.svensson@bth.se,"Abstract
Context
The principal focus of lean is the identification and elimination of waste from the process with respect to maximizing customer value. Similarly, the purpose of agile is to maximize customer value and minimize unnecessary work and 
time delays
. In both cases the concept of waste is important. Through an empirical study, we explore how waste is approached in 
agile software development
 organizations.
Objective
This paper explores the concept of waste in agile/lean software development organizations and how it is defined, used, prioritized, reduced, or eliminated in practice
Method
The data were collected using semi-structured open-interviews. 23 practitioners from 14 
embedded software
 development organizations were interviewed representing two core roles in each organization.
Results
Various wastes, categorized in 10 different categories, were identified by the respondents. From the mentioned wastes, not all were necessarily waste per se but could be symptoms caused by wastes. From the seven wastes of lean, Task-switching was ranked as the most important, and Extra-features, as the least important wastes according to the respondents’ opinion. However, most companies do not have their own or use an established definition of waste, more importantly, very few actively identify or try to eliminate waste in their organizations beyond local initiatives on project level.
Conclusion
In order to identify, recognize and eliminate waste, a common understanding, and a 
joint
 and holistic view of the concept is needed. It is also important to optimize the whole organization and the whole product, as waste on one level can be important on another, thus sub-optimization should be avoided. Furthermore, to achieve a sustainable and effective waste handling, both the short-term and the long-term perspectives need to be considered.",January 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,6.0,"The exploration of waste in agile software development organizations can provide insights for startups in improving efficiency, but the direct impact on early-stage ventures might not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584918301861,Adaptive monitoring: A systematic mapping,Edith=Zavala: zavala@essi.upc.edu; Xavier=Franch: franch@essi.upc.edu; Jordi=Marco: jmarco@cs.upc.edu,"Abstract
Context
Adaptive monitoring is a method used in a variety of domains for responding to changing conditions. It has been applied in different ways, from monitoring systems’ 
customization
 to re-composition, in different application domains. However, to the best of our knowledge, there are no studies analyzing how adaptive monitoring differs or resembles among the existing approaches.
Objective
To characterize the current state of the art on adaptive monitoring, specifically to: (a) identify the main concepts in the adaptive monitoring topic; (b) determine the demographic characteristics of the studies published in this topic; (c) identify how adaptive monitoring is conducted and evaluated by the different approaches; (d) identify patterns in the approaches supporting adaptive monitoring.
Method
We have conducted a 
systematic mapping study
 of adaptive monitoring approaches following recommended practices. We have applied automatic search and snowballing sampling on different sources and used rigorous selection criteria to retrieve the final set of papers. Moreover, we have used an existing qualitative analysis method for extracting relevant data from studies. Finally, we have applied 
data mining
 techniques for identifying patterns in the solutions.
Results
We have evaluated 110 studies organized in 81 approaches that support adaptive monitoring. By analyzing them, we have: (1) surveyed related terms and definitions of adaptive monitoring and proposed a generic one; (2) visualized studies’ demographic data and arranged the studies into approaches; (3) characterized the main approaches’ contributions; (4) determined how approaches conduct the adaptation process and evaluate their solutions.
Conclusions
This cross-domain overview of the current state of the art on adaptive monitoring may be a solid and comprehensive baseline for researchers and practitioners in the field. Especially, it may help in identifying opportunities of research; for instance, the need of proposing generic and flexible 
software engineering
 solutions for supporting adaptive monitoring in a variety of systems.",January 2019,Not Found,Information and Software Technology,2025-03-21T00:00:00,8.0,The study on adaptive monitoring provides valuable insights into different approaches and patterns that can be applied to improve monitoring systems in early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0883902625000138,Journal of Business Venturing 2024 year in review: The year of exercising entrepreneurial agency in response to crises,Jeffery S.=McMullen: mcmullej@iu.edu; Scott L.=Newbert: scott.newbert@baruch.cuny.edu; Christian=Schwens: schwens@wiso.uni-koeln.de; Oana=Branzei: obranzei@ivey.ca,"Abstract
When various forms of crisis hit, they can stimulate changes in entrepreneurial agency – the capacity to act (or choose not to) – and the actions entrepreneurs take to mitigate the threats and pursue the new opportunities those crises create. While assessing articles for the 
Journal of Business Venturing
's annual “Best Paper” award, we observed this to be a recurring theme across a significant number of the studies published in 2024. Inspired by this research, we summarize the 17 articles that explored this theme and develop a framework that highlights material, relational, and discursive concerns brought about by crises. In response entrepreneurs across individual or collective levels take action to preserve or cultivate distinct forms of entrepreneurial agency – adaptive, allied, and censored – and to resolve various paradoxes of entrepreneurial agency. We close with a brief discussion of the growing relevance of a social symbolic lens in reconciling how entrepreneurs construe and respond to crises and how the specific forms of agency and paradox identified could inform theory both within and beyond entrepreneurship.
Executive summary
This article began as a search for the “Best Paper” published in 
Journal of Business Venturing (JBV)
 in 2024. The editor-in-chief selected a panel of editors who then reviewed each of the 49 articles published in volume 39, issues 1–6, to identify those that were bold, broad, and rigorous. We arrived at a shortlist of five articles that best exemplified these criteria, from which the entire 
JBV
 editorial team voted for the winner: “Sight unseen: The visibility paradox of entrepreneurship in an informal economy,” by Robert Nason, Siddharth Vedula, Joel Bothello, Sophie Bacq, and Andrew Charman.
In addition to enabling the selection of a best paper, this process revealed a common theme cutting across more than one-third of the articles published throughout the year; namely, “how entrepreneurs exercise agency in response to crises.” Traditionally, crises have been defined as periods of turmoil that disrupt patterns of economic activities and represent acute potential threats to the livelihoods of those affected. Over the past decade, however, scholars (both within and outside the field of entrepreneurship) have gradually shifted attention from single, separate, and short-lasting episodes that momentarily disrupt entrepreneurial endeavors (
Doern et al., 2016
) to plural, entangled and long-lasting combinations, sometimes referred to as poly-crises (
Klyver and McMullen, 2025
). To consider both conceptualizations, we take a broader perspective of crisis, using the term holistically to include both acute and enduring widespread structural challenges. We reason that, by defying conformity and attempting actions that question a society's taken for granted assumptions about how the world works, entrepreneurs embody and enact a paradox of agency in which restrictions on their capacity to act – which dispirit, discourage, or even devastate most people – instead stimulate them to seek to preserve or cultivate their agency not only by mitigating the threats that crises can pose, but also by leveraging them as opportunities to improve their situation.
We proceed as follows. After a brief introduction, we summarize how each individual article reflects and contributes unique insights to the overarching theme of exercising entrepreneurial agency in response to crises. Grouping the articles according to the type of crisis examined, we sensitize ourselves to the underlying mechanisms that entrepreneurs use in response by adopting a social symbolic lens (
Lawrence and Phillips, 2019
). Specifically, we hone our attention to the relative importance and interplay of material, relational, and discursive dimensions of social symbolic work as entrepreneurs construe and respond to different types of crises. We suggest that entrepreneurs encounter various limitations to and paradoxes of agency that they seek to resolve by 
adapting, allying,
 or 
censoring
 their capacity to act. Finally, we conclude by articulating potential avenues for scholars to elaborate on this tri-dimensional approach to entrepreneurial agency both within and beyond entrepreneurship theory and practice.",July 2025,Not Found,Business Venturing,2025-03-21T00:00:00,10.0,"The study on how entrepreneurs exercise agency in response to crises provides critical insights for early-stage ventures facing challenges, offering a valuable framework to understand and navigate crisis situations, thereby making a significant impact on startups."
https://www.sciencedirect.com/science/article/pii/S088390262500014X,"The rise and fall of the girlboss: Gender, social expectations and entrepreneurial hype",Janice=Byrne: jbyrne@ivey.ca; Antonio Paco=Giuliani: antonio.giuliani@unibo.it,"Abstract
Hype is a collective vision and promise of a possible future, around which attention, excitement, and expectations increase over time (Logue & Grimes, 2022). Entrepreneurs employ cultural strategies, using framing to legitimize their endeavors and sustain the surrounding hype. Despite the importance of media in entrepreneurial hype, extant literature has yet to investigate media framing devices and how they shape and inform social expectations in the hype cycle. We also know that framing efforts are shaped by discursive struggles between actors (Kriechbaum et al., 2021) and that under-represented social groups are more constrained by dominant discourses. Yet, extant literature on entrepreneurial hype has thus far undertheorized power and inequality. We focus on one under-represented group - women – as they embody a glaring example of how media influence the social expectations associated with their entrepreneurial endeavors. Specifically, this study investigates how the media employ framing devices to generate social expectations for non-dominant groups (women entrepreneurs in our case) - and shape the hype cycle. To do so, we empirically analyze the evolution of the ‘girlboss’ hype, through a content analysis of 2671 media articles. Our contributions advance studies on entrepreneurial hype by explicating the role of media in the construction of hype. We contend that gender affords a critical power lens in the study of entrepreneurial hype that can be transferred to other contexts mired by inequality. We advance that feminist interrogations of media and entrepreneurship can contribute to understanding and addressing issues beyond gender.",July 2025,"Hype, Hype cycle, Women's entrepreneurship, Gender, Feminist perspectives, Postfeminism, Media, Social expectations",Business Venturing,2025-03-21T00:00:00,6.0,"The investigation into how media framing shapes social expectations in entrepreneurial hype, particularly focusing on women entrepreneurs, has theoretical value but may have limited immediate practical impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673425000010,Opportunity amidst explosions: How armed conflicts spark informal entrepreneurship in emerging economies,Esther=Salvi: esther.salvi@imd.org; Diana M.=Hechavarria: dhechavarria@babson.edu; Daniela=Gimenez-Jimenez: daniela.gimenez@tu-dortmund.de,"Abstract
Armed conflicts, such as a surge in bombings, shelling, and other violent outbreaks, dramatically affect national economies and business activities. This article aims to merge the previously separate research streams on foreign direct investment (FDI) and informal entrepreneurship, illustrating how these elements interact within the context of armed conflict. Utilizing data from eight emerging economies over 16 years, we construct a two-step mediation model to demonstrate that increased armed conflict reduces FDI, enabling informal entrepreneurship. Our study offers two important insights: First, it introduces a novel perspective on armed conflict as an external enabler of informal entrepreneurship. Second, it uncovers three pivotal mechanisms—
legitimation, demand substitution,
 and 
resource access
—through which the decline in FDI resulting from armed conflict intensification stimulates informal entrepreneurial activity. The findings of this study contribute not only to academic discourse at the intersection of international business and entrepreneurship, but also provide practical insights that are essential for shaping policies, guiding international business strategies, and fostering economic resilience in regions affected by violence and instability.",June 2025,"Armed conflict, FDI, Informal entrepreneurship, Emerging economies, External enablers",Business Venturing Insights,2025-03-21T00:00:00,7.0,"The research linking armed conflict, FDI, and informal entrepreneurship provides important perspectives for understanding economic dynamics in conflict-affected regions, with implications for startup strategies."
https://www.sciencedirect.com/science/article/pii/S2352673425000022,Jingle bells and juggling stress: An IPA analysis of well-being and ill-being among market entrepreneurs in outdoor finnish christmas markets,Regina=Casteleijn-Osorno: racaos@utu.fi; Linh=Duong: linh.duong@abo.fi,"Abstract
Christmas markets evoke joyful, emotional, and nostalgic impressions to just about everyone. But what about the people behind the booths? Through semi-structured interviews with six sellers and a market organizer in Finland, we apply an interpretive phenomenological analysis (IPA) approach to illustrate that positive and detrimental effects on hedonic and eudaimonic well-being co-exist, addressing both physical and emotional stressors of entrepreneurs when selling at Christmas markets. Also, the results showcase well-being trade-offs that bring the sense of fulfillment when doing entrepreneurial activities. This study contributes to entrepreneurship well-being research and research concerning societal implications to the market seller community.",June 2025,"IPA analysis, Well-being, Ill-being, Market entrepreneurs, Outdoor markets, Christmas",Business Venturing Insights,2025-03-21T00:00:00,5.0,"While the study on Christmas markets provides interesting insights on well-being and entrepreneurship, its direct practical implications for startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673425000046,Sexual harassment by multiple stakeholders in entrepreneurship: The case of Japan,Takanori=Kashino: kashino@eireneuniversity.org,"Abstract
Sexual harassment in entrepreneurial contexts remains a critical yet underexplored issue. While workplace harassment in traditional employment settings has been widely researched, little is known about how power dynamics and cultural norms shape the sexual harassment risks faced by entrepreneurs. To address this gap, we conducted an exploratory study within Japan's entrepreneurial context, where cultural norms and limited institutional protections create distinct vulnerabilities. Through an anonymous online survey of 197 participants (105 of whom identified as female entrepreneurs), we collected both quantitative and qualitative data. We found that 52.4% of female entrepreneurs reported experiencing sexual harassment by multiple stakeholders in the past year. Investors emerged as the primary perpetrators (43.2% of cases), followed by customers, mentors, and members of entrepreneurial support organizations. Qualitative insights suggest that power asymmetries, especially in funding and mentorship relationships—create unique vulnerabilities for entrepreneurs to sexual harassment that differ from those in a traditional workplace. Our study not only advances research on Japanese entrepreneurship, but also provides actionable insights for other contexts with similar cultural and institutional barriers. These findings can inform efforts to combat gender stereotypes and strengthen legal protections against harassment.",June 2025,Not Found,Business Venturing Insights,2025-03-21T00:00:00,9.0,"The exploration of sexual harassment in entrepreneurial contexts offers crucial insights for startup founders, addressing a pressing issue and providing actionable recommendations."
https://www.sciencedirect.com/science/article/pii/S2352673425000034,"“I could, but why should I?”: Entrepreneurial women's career pathways and how founding fits in (or doesn't)",Hana=Milanov: hana.milanov@tum.de,"Abstract
Why do highly qualified women with entrepreneurial self-efficacy choose not to pursue tech-venture founding? We adopt a career-perspective and interview 17 female Stanford engineering graduates—women who possess high entrepreneurial self-efficacy (ESE), educational prestige, access to Silicon Valley's entrepreneurial networks, and who already overcame hurdles associated with entering and succeeding in a gender-incongruent setting. Despite these seemingly uniform conditions for tech entrepreneurship, we reveal four distinct career pathways: Skill Hunters, Life Masters, Strategists, and Idealists. While Skill Hunters remain attracted to entrepreneurship, the other groups are disillusioned with it, despite having experience as corporate entrepreneurs, business owners, and founders of not-for-profits. Our findings demonstrate how (in)congruency of women's career principles and context-based entrepreneurial outcome expectations shapes their entrepreneurial engagement.",June 2025,"Social cognitive career theory (SCCT), Entrepreneurial self-efficacy, Women's entrepreneurship, Careers, STEM, Career success",Business Venturing Insights,2025-03-21T00:00:00,6.0,"The study on women with entrepreneurial self-efficacy provides valuable insights, but its focus on career pathways may have slightly less immediate practical relevance for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S235267342500006X,"Too nice, but not too wise: The curvilinear effects of employee orientation on new venture performance",Myeongho David=Park: myepark@okstate.edu,"Abstract
This paper examines the mechanisms of stakeholder management within the context of entrepreneurship, with a particular focus on a primary stakeholder group: employees. We propose a novel curvilinear relationship between employee orientation and new venture performance and further explore the moderating role of entrepreneurial team human capital. Using longitudinal data from the Kauffman Firm Survey, we confirm the presence of an inverted U-shaped relationship between employee orientation and new venture performance. We also find that the human capital of entrepreneurial teams moderates this curvilinear relationship, shifting the optimal point of the curve toward a lower employee orientation. Our study contributes to the literature on the intersection of stakeholder management and entrepreneurship.",June 2025,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"The study provides valuable insights into stakeholder management within entrepreneurship and how it impacts new venture performance, with practical implications for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673425000058,Weathering the pivot: Stability and turnover in new venture teams,Jeffrey=Hornsby: hornsbyj@umkc.edu; Griffin W.=Cottle: gcottle@umassd.edu; Jessica=Jones: jessica.jones@utk.edu; Brian S.=Anderson: brian.anderson@ku.edu,"Abstract
Research on strategic change and NVT turnover suggests that members of the new venture team are likely to depart during a pivot as a result of structural changes within the firm. However, this perspective overlooks the relational aspect of venturing, which bonds team members to their ventures. Although NVT members are critical to both the creation of economic profit and the operational viability of the firm, at present we have little understanding of whether the decision to pivot strengthens or weakens their commitment to the firm. Using the employment data of 91 new venture teams that underwent a pivot, we examine how the sudden changes that are brought about affect the stability of the team in the 12-weeks leading up to and following their occurrence. In doing so we help integrate the literature on NVT turnover and entrepreneurial bonding, and provide a fuller distribution of the outcomes that accompany new venture pivots.",June 2025,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"Examining the impact of sudden changes in new venture teams during a pivot provides relevant information for startups, although the practical applications may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673425000083,Close but not nearby? Rethinking proximity in the digital era of entrepreneurial ecosystems,Olivier=Lamotte: olamotte@em-normandie.fr,"Abstract
Recent literature has increasingly challenged the traditional view of entrepreneurial ecosystems (EEs) as geographically bounded entities, highlighting how entrepreneurial activities span spatial boundaries through networks, digital platforms, and various forms of collaboration. Building on these insights, this article proposes an analytical framework based on the proximity approach to understand better how EEs function in an increasingly digitalized world. We argue that while geographic proximity remains relevant, other forms of proximity (cognitive, social, organizational, and institutional) are equally crucial in shaping resource interactions and coordination within EEs. We also examine how digitalization transforms these proximity dynamics, creating new possibilities for entrepreneurial activities while potentially reducing the importance of geographic proximity. The key insight of our study is that beyond mere geographic closeness, diverse forms of proximity shape actors’ interactions within EEs, while digitalization reconfigures these dynamics, extending EEs boundaries. This research contributes to the literature by offering a more nuanced theoretical framework for understanding the spatial and non-spatial dimensions of EEs, with implications for both research and policy.",June 2025,"Entrepreneurial ecosystems, Proximity, Digitalization",Business Venturing Insights,2025-03-21T00:00:00,7.0,"The proposed analytical framework for understanding entrepreneurial ecosystems in a digitalized world is insightful, but the direct impact on European early-stage ventures may be somewhat abstract."
https://www.sciencedirect.com/science/article/pii/S2352673424000374,Gender effects and firm financial performance: A SUMAD meta-analysis of social responsibility and family-to-work conflict,Mark=Geiger: geigerm1@duq.edu,"Abstract
The current study uses 
SUMAD
 meta-analytic methods (Oh, 2020) to examine 
gender differences
 in social responsibility and family-to-work conflict. Synthesizing evidence from across social science literature, the results of this study provide an evidence-based foundation to support more theorizing and practical discourse regarding gender effects in entrepreneurship. As explained by theories of socialization and social roles, 
gender differences
 in (a) socially responsible attitudes and behaviors and (b) the balance between family and work responsibilities, are likely two of the more pervasive gender effects that influence entrepreneurial careers. The goal of this study is to motivate more research and practical discussion on these and related gender effects to improve our understanding of entrepreneurship phenomena. Using firm performance as an example, the results of the 
SUMAD
 meta-analysis suggest that gender effects related to social responsibility and family-to-work conflict have significant consequences for entrepreneurship outcomes. Based on the evidence and theory rooted in socialization and social roles, the current study calls for more theorizing and primary-level studies on these and related gender effects in entrepreneurship research.
Comment to Readers:
 
Does gender matter? Of course it does (depending on the issue).
 A simple search of “does gender matter” reveals ample discussion on this topic across a variety of gender issues. In this article I highlight 
gender
 regarding differences between women and men in social responsibility and family-to-work conflict. As the evidence suggests, gender does indeed matter as women – on average – are more socially responsible and have more family-to-work conflict than their men counterparts. The results of this study show that greater social responsibility is tied to better business performance whereas greater family-to-work conflict is tied to worse business performance. So, what should we do? First, acknowledge the fact that women and men are different in the contexts of social issues and family matters to clear the way for constructive discourse about these 
gender differences
. Second, embrace that women are higher than men in socially responsible attitudes and behaviors, and that more women in business could inherently result in more socially responsible business practices. Moreover, while this is a 
societal win
 in and of itself, the results suggest it could also carry over to improved financial and economic performance. Lastly, focus more on “why” there are differences between women and men regarding family-to-work conflict. Specifically, emphasize both societal-driven influences (e.g., stereotypes; biases) and individual-driven influences (e.g., individual differences; personal preferences). Understanding these influences, which are not mutually exclusive, is key for maximizing the personal and professional well-being of both women and men.",November 2024,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"While the study on gender differences in social responsibility and family-to-work conflict is relevant, the direct impact on practical applications for European early-stage ventures, especially startups, may be less pronounced compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673424000477,Extending behavioral theory of the firm to new ventures: Dispositional optimism as a moderating influence on new product introductions in high-tech ventures,R. Isil=Yavuz: ryavuz@bryant.edu; Dev K.=Dutta: dev.dutta@unh.edu; Mehmet A.=Soytas: mehmet.soytas@kfupm.edu.sa,"Abstract
Extant literature has typically drawn from the behavioral theory of the firm (BTOF) to examine new product introductions in the context of well-established companies. This paper extends the behavioral theory of the firm to entrepreneurial firms and argues that jointly considering founders' dispositional optimism together with the performance feedback promises to yield a better understanding of new product introductions in new ventures. We analyze a longitudinal dataset on the activities of 344 newly founded high technology ventures in the United States. The key insight of our study is that when BTOF is applied to the context of nascent, entrepreneurial ventures, the personality and dispositional characteristics of the entrepreneur must be considered. Specifically, we find that performance attainment discrepancy leads to new product introductions, but only when the entrepreneur's dispositional optimism level is high.",November 2024,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"This abstract provides valuable insights into the impact of founders' dispositional optimism on new product introductions in entrepreneurial ventures, which is crucial for early-stage startups."
https://www.sciencedirect.com/science/article/pii/S2352673424000519,Uncovering wellbeing: The complex realities of mompreneurs with additional needs children through Lego® Serious Play®,Regina=Casteleijn-Osorno: racaos@utu.fi,"Abstract
This paper explores the complexities of identifying the wellbeing of mompreneurs (mother-entrepreneurs) who are also caregivers to children with additional needs. A social constructionist perspective, Lego® Serious Play® was employed in individual interviews to uncover their complex wellbeing realities while pursuing entrepreneurship. A hermeneutic constructivist lens was applied to further conceptualize the language behind their experiences. The findings present three dimensions of wellbeing: 1) Internal conflict and self-neglect 2) Empowerment, Independence, Fulfilment 3) Resilient Control: Keeping the Balance. These dimensions provide an idiographic understanding, contributing to the broader knowledge of wellbeing as a component of entrepreneurship alongside caregiving responsibilities.",November 2024,"Lego® Serious Play®, Mompreneur, Wellbeing, Additional needs, Disability, Sensitive topics, Hermeneutic constructivist, Social constructionist, Caregiving, Entrepreneur",Business Venturing Insights,2025-03-21T00:00:00,5.0,"While exploring the wellbeing of mompreneurs is important, the practical application and impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673424000520,How sector fluidity (knowledge-intensiveness and innovation) shapes startups’ resilience during crises,Asif=Tanveer: muhammadasif.tanveer@hdr.qut.edu.au; Rui=Torres de Oliveira: rui.torresdeoliveira@deakin.edu.au; Shaheer=Rizvi: shaheer.rizvi@iub.edu.pk,"Abstract
In the context of the crises, this study sheds light on the varying impact of crises on startups in different sectors and outlines the specific resilience practices utilized in response, recovery, and growth phases. The research team conducted qualitative analysis on 18 public discussion interviews featuring key stakeholders in the Indian startup ecosystem, which included 51 chief executive officers, founders, cofounders, and venture capitalists who reflected on COVID-19. The study found that high-fluidity sectors (highly knowledge-intensive and innovative) leverage their agility through resourcefulness and customer value creation. In contrast, low-fluidity sectors (low in knowledge intensiveness) primarily focus on operational adjustments. As the transition goes from response to recovery, high-fluidity sectors prioritize digital transformation and strategic shifts, while low-fluidity sectors continue to cope. In the growth phase, high-fluidity startups exhibit growth aspirations, while low-fluidity ones emphasize business model innovation. This research provides valuable sector-specific insights into resilience and highlights the evolution of these strategies throughout a crisis, thereby enhancing our understanding of startup resilience in the context of the crisis.",November 2024,"Resilience, Value for customers, Digital transformation, Startups, Business models, COVID-19",Business Venturing Insights,2025-03-21T00:00:00,8.0,"This abstract offers sector-specific insights into startup resilience during crises, which can greatly benefit early-stage ventures in understanding and navigating challenging times."
https://www.sciencedirect.com/science/article/pii/S2352673424000507,Entrepreneurial finance and sustainability: Do institutional investors impact the ESG performance of SMEs?,Paul P.=Momtaz: momtaz@tum.de,"Abstract
Institutional investors improve the environmental, social, and governance (ESG) performance of small- and medium-sized enterprises (SMEs). Our difference-in-differences framework shows that the backing from private equity and venture capital funds leads to an increase in SMEs’ externally validated ESG scores compared to their matched non-investor-backed peers. Consistent with “ESG-as-insurance” theory, the ESG performance of SMEs with a higher probability of failure is more likely to benefit from the backing of institutional investors. This positive effect is heterogeneous; while SMEs with high ex-ante ESG performance further improve their ESG performance following institutional investor backing, SMEs with low ex-ante ESG performance are unlikely to implement any improvements. Entrepreneurial finance seems to help sustainable entrepreneurs transform into “sustainability champions,” while neglecting the betterment of non-sustainable SMEs.",November 2024,"Entrepreneurial finance, Venture capital, Private equity, Sustainability, Environmental, social, and governance (ESG), Corporate social responsibility (CSR)",Business Venturing Insights,2025-03-21T00:00:00,6.0,"The study on institutional investors and ESG performance is relevant, but the focus on small- and medium-sized enterprises may limit its direct applicability to early-stage startups."
https://www.sciencedirect.com/science/article/pii/S2352673424000556,What’s the risk? It depends. Entrepreneurs’ and employees’ perceptions of domestic city-level institutional risk,Kaitlyn=DeGhetto: kdeghetto1@udayton.edu; Zachary A.=Russell: russellz1@xavier.edu,"Abstract
With a focus on entrepreneurs' decisions related to domestic location choices, this study draws from the international business institutional risk literature to evaluate city-level risk perceptions while accounting for individual-level political views. Specifically, we surveyed entrepreneurs and prospective employees in an effort to evaluate how important 1) safety risk, 2) political risk, and 3) social risk are when considering where to live, work, and start businesses. This process also included a comparison to ease of doing business, a previously studied driver of investment decisions. To identify low (and high) risk domestic investment locations, we had participants rate 25 large U.S. cities on the risk factors. Our findings indicate that entrepreneurs and prospective employees care about the city-level institutional risk factors. However, the focus and perceptions of entrepreneurs and prospective employees are greatly influenced by political views, perceptions do not always mirror objective data, and the two groups weight risk differently. The key insight of our study is that, in order to access and maintain valuable human capital, entrepreneurs should begin considering employees' perceptions related to city-level institutional risk. Importantly, these perceptions are biased by factors such as one's political views. Likewise, to attract business investment, city leaders should consider these risk perceptions.",November 2024,Not Found,Business Venturing Insights,2025-03-21T00:00:00,4.0,"While evaluating city-level risk perceptions is interesting, the direct impact on European early-stage ventures may be less significant compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S2352673423000732,Pouring the Paycheck Protection Program into craft beer: PPP employment effects in service-intensive industries,Aaron J.=Staples: astaples@utk.edu,"Abstract
Small businesses in the food and beverage service 
industry
 are particularly vulnerable to crises such as the COVID-19 pandemic. One of the most salient vulnerabilities was the drastic decline in consumer spending at eating and drinking places, generating unprecedented swings in employment in this service-intensive sector. Governments across the globe implemented rapid response fiscal policies to mitigate these economic damages and improve small business crisis management. One such policy was the Paycheck Protection Program (PPP) in the United States. This study links restricted microdata from the Colorado Quarterly Census of Employment and Wages to microdata on PPP loan recipients to assess whether the loan program effectively reduced unemployment rates in Colorado's craft beer 
industry
. The results of a staggered difference-in-differences framework indicate immediate and longer-term positive and statistically significant effects of the loan program on employment outcomes, with employment effects ranging from 16.8 to 19.5%. These results emphasize the importance of understanding the loan program’s effectiveness among hard-hit industries comprised of small businesses.",June 2024,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"This study provides valuable insights into the effectiveness of government policies, such as the Paycheck Protection Program, in supporting small businesses in the food and beverage industry during crises like the COVID-19 pandemic. The findings can be informative for European early-stage ventures facing similar challenges."
https://www.sciencedirect.com/science/article/pii/S2352673424000040,How and why do social entrepreneurs experience goal conflict differently?,Rebecca=Pieniazek: R.Pieniazek@leeds.ac.uk,"Abstract
It is well-known that the need for both social and financial missions creates tension within social enterprises. Less well-known are the specifics around how and why social entrepreneurs themselves construct and experience their situation. Given people vary in their psychological representations of their goals from concrete (i.e., tasks) to more abstract (i.e., values), we anticipated that goal conflict with engaging in financial activities could vary along these lines, leading to potentially different solutions for support. Through collecting interviews and focus group data using goal hierarchies from 37 social entrepreneurs, we find six constructed realities with different salient goals at different levels of cognitive abstraction which either dictate, conflict with, or are dissociated from financial activities. These can explain why social entrepreneurs perceive their financial activities differently – financial activities as out of sight out of mind, aversive, a ball to juggle, a necessary evil, part and parcel, and as king - which are associated with four experiences of goal conflict (i.e., goal conflict as continual questioning, inevitable, manageable, and irrelevant).",June 2024,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"While the study sheds light on the internal conflicts faced by social entrepreneurs in balancing social and financial goals, the practical implications for European early-stage ventures, especially startups, may be limited as it focuses more on psychological representations and goal conflicts."
https://www.sciencedirect.com/science/article/pii/S2352673424000143,"Upward, downward or steady: How social class experience shapes transnational social venturing",Nkosana=Mafico: nkosana.mafico@ed.ac.uk,"Abstract
Transnational social entrepreneurs leverage their cross-border knowledge and experiences to create and exploit opportunities in multiple markets. However, this knowledge and experience is not homogeneous or equally distributed among them. In this paper, we examine how the social class experiences of 18 transnational social entrepreneurs from the African diaspora living in the West influence their transnational social venturing. We identify four types of Transnational Social Class Experience (TSCE)—Grounded, Elite, Fallen and Elevated—each associated with a different approach to transnational social venturing. Our key contribution is introducing and unpacking the concept of Transnational Social Venturing Advantage (TSVA): the unique benefits that transnational social entrepreneurs can gain when their economic experiences across multiple countries intersect with the varied sociocultural environments they encounter. We also develop a framework that elucidates the connections between TSCE and social venturing approaches through TSVA. Taken together, our study advances the literature on transnational social venturing by unpacking the social class experience dynamics that enable transnational social entrepreneurs to access resources and understand their beneficiaries. It also advocates for a shift beyond a low versus high social class 
dichotomy
 in the broader (transnational) entrepreneurship discourse to a spectrum-based approach that accounts for social class experiences gained across borders.",June 2024,"Social class, Social mobility, Venturing, Transnational, Entrepreneur",Business Venturing Insights,2025-03-21T00:00:00,8.0,The examination of how social class experiences influence transnational social venturing provides actionable insights for European early-stage ventures looking to enter multiple markets. The concept of Transnational Social Venturing Advantage (TSVA) can be particularly valuable for startups seeking to expand globally.
https://www.sciencedirect.com/science/article/pii/S2352673424000209,Unbinding ideology: The impact of communist indoctrination revocation in polish schools on later life self-employment,Pankaj C.=Patel: pankaj.patel@villanova.edu,"Abstract
Given communist ideologies discourage individual 
enterprise
, this research investigates whether eliminating compulsory Marxist-Leninist indoctrination from schools influences later life self-employment. Focusing on a mid-1950s reform in Poland that revoked the Communist indoctrination curriculum while holding other aspects constant, the study leverages variation in exposure based on annual 
school enrollment
 cut-off birthdates. Contrary to expectation, the empirical analysis finds no discernible effect of indoctrination removal on later-life self-employment. Additionally, the study examines whether Polish immigrants exposed to reform and arriving in the US after 1960 exhibit increased self-employment propensity, but finds no significant differences. Overall, the study's findings highlight negligible impacts of the revocation of Communist indoctrination in Polish schools on self-employment.",June 2024,Not Found,Business Venturing Insights,2025-03-21T00:00:00,3.0,"While the research investigates the impact of Communist indoctrination on self-employment, the findings may have limited relevance for European early-stage ventures or startups in the present context. The negligible effects observed may not provide significant practical value."
https://www.sciencedirect.com/science/article/pii/S2352673423000379,Startup grants and the development of academic startup projects during funding: Quasi-experimental evidence from the German ‘EXIST – Business startup grant’,Christoph E.=Mueller: chr.mueller@fz-juelich.de,"Abstract
Public support programs for (academic) startups are an important component of innovation and technology policy. There are many types of startup policy instrument, one of which is supporting prospective founders with startup grants. The present study contributes to the literature by examining the effectiveness of a specific startup grant entitled ‘EXIST – Business Startup Grant’. This measure is Germany’s largest public startup support program and aims to increase the number of technology-oriented and knowledge-based academic startups. The present research investigates the extent to which products of funded startups, the projects’ business planning, the founders’ skills, the degree of networking, and the uptake of external funding evolve over the duration of the grant. Evidence of the effects on these variables is generated by means of a pipeline-based comparison group design. Findings indicate that the startup grant contributes substantially to the development of the products and the business planning of the funded startups, moderately increases their degree of networking and their uptake of external funding, and slightly improves the skills of the founding team during the funding period. Several robustness checks – including a replication by another type of research design, namely a pre-post comparison – strongly support the findings. Hence it is very likely that the program advances startups in their development and thus contributes to later economic success.",November 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,9.0,The study on the effectiveness of a startup support program in Germany can provide valuable insights for European early-stage ventures and startups.
https://www.sciencedirect.com/science/article/pii/S235267342300046X,Finding the sweet spot: Evaluating the role of structured idea-generation framework in generating high-quality new venture ideas,Puspa=Shah: shahp@uwosh.edu; Nischal=Thapa: thapan@uwgb.edu,"Abstract
Previous research has predominantly focused on cognitive antecedents related to the quality of new venture ideas (NVIs), resulting in a notable gap in understanding the influence of structural elements on NVIs. Drawing upon activation theory, we examine how the structure of the idea-generation framework, a dimension of routinization, influences NVI outcomes. To investigate this relationship, we conduct two separate studies: the first involving a student sample and the second involving practicing entrepreneurs. Our findings demonstrate an inverse U-shaped relationship between the structure in the idea-generation framework and the quality/quantity of NVIs. These findings contribute to the understanding of the antecedents that shape NVIs.",November 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,Understanding how the structure of idea-generation frameworks influences new venture ideas can offer practical guidance for European startups.
https://www.sciencedirect.com/science/article/pii/S2352673423000537,CEO's industry experience and emerging market SME performance: The effects of corruption and political uncertainty,Arkangel M.=Cordero: arkangel.cordero@utsa.edu; Juan Carlos=Morales-Solis: jcmorales@wtamu.edu; Vincent L.=Barker III: vbarker3@ku.edu,"Abstract
We examine how Chief Executive Officer (CEO) industry-specific experience influences firm performance in small and medium 
enterprises
 (SMEs) in emerging markets. Drawing on the upper echelons perspective and learning theory, we propose an inverted U-shaped relationship between an SME CEO's industry-specific experience and firm performance. We also argue that country 
corruption
 and political instability moderate this relationship, resulting in lower performance for SME CEOs with little 
industry
 experience or many years of 
industry
 experience in countries with high 
corruption
 or political instability. We test our hypotheses using data from the World Bank's Enterprise Survey of firms in emerging economies from 2006 to 2019. The results support our hypotheses that corruption and political instability primarily hurt the performance of SMEs with CEOs having very long industry experience. We discuss implications of this research for scholars studying SMEs in lesser-developed institutional environments and how leaders may influence SME performance.",November 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,Examining how CEO industry-specific experience impacts SME performance in emerging markets can be relevant for early-stage ventures in Europe.
https://www.sciencedirect.com/science/article/pii/S2352673423000549,Students' assumptions of Entrepreneurs’ performance: The paradox of excess entry and missed opportunity,Kaushik=Gala: kgala@iastate.edu,"Abstract
Most variables in entrepreneurship are not distributed normally. Instead, they are characterized by positive skew and heavy 
tails
 featuring influential outliers. Yet, this fundamental asymmetry in entrepreneurial endeavors is rarely discussed in 
entrepreneurship education
, which often oscillates between highlighting everyday entrepreneurs and high-growth ‘unicorn’ startups while overlooking the distributional context for these extremes. Therefore, this paper explores whether students accurately comprehend the non-normality that pervades entrepreneurship. We conducted two studies wherein undergraduate business students at a large, public university in the Midwest US estimated entrepreneurial performance. We elicited students' estimates of the range of performance exhibited by entrepreneurs using a real-world vignette and performance data for an online learning platform. By providing empirical evidence that students may carry largely 
in
accurate assumptions of performance distributions, this paper highlights the paradoxical risks of excess entrepreneurial entry on the one hand and missed opportunity on the other.",November 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"The exploration of non-normality in entrepreneurship education is insightful, but may have limited immediate impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673423000616,Health resourcefulness behaviors: Implications of work-health resource trade-offs for the self-employed,Timothy L.=Michaelis: tmichaelis@niu.edu; Michael P.=Lerman: mlerman@iastate.edu; Jon C.=Carr: jccarr@ncsu.edu; Alexander=McKelvie: mckelvie@syr.edu; April=Spivack: april.spivack@hanken.fi,"Abstract
In this paper, we present an exploratory study to investigate why those who are self-employed in the United States may make more personal health-related trade-offs than adults working in traditional wage-employment jobs. A random sample of 10,663 working adults in the United States indicate that the self-employed engage in higher amounts of health-related resourcefulness behaviors than wage employees (e.g., skipping medication to save money). We find that concerns over healthcare access and 
affordability
 serve as antecedents to health resourcefulness behaviors among all working adults, but that age moderates these relationships differently for the self-employed. Specifically, younger self-employed adults engage in health resourcefulness behaviors due to healthcare 
affordability
 concerns while older self-employed adults engage in such behaviors due to healthcare 
access
 concerns. In sum, we contribute to the entrepreneurial resourcefulness literature and well-being literature by highlighting data on how the self-employed make trade-offs with their personal health resources. We offer multiple directions for theory development, future research, and implications for healthcare policy.",November 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"This abstract provides valuable insights into the trade-offs made by self-employed individuals regarding personal health resources, which could be relevant for European early-stage ventures in terms of understanding different aspects of entrepreneurship."
https://www.sciencedirect.com/science/article/pii/S235267342300015X,"Creating economic, social, and environmental change through entrepreneurship: An entrepreneurial autonomy perspective informed by Paulo Freire",Benson=Honig: bhonig@mcmaster.ca; Ana Cristina O.=Siqueira: siqueiraa@wpunj.edu; Sandra=Mariano: sandramariano@id.uff.br; Joysi=Moraes: jmoraes@id.uff.br; Robson Moreira=Cunha: robsoncunha@id.uff.br,"Abstract
We extend to the context of entrepreneurship Paulo Freire's concepts including “limit-situation” representing constraints to be surpassed, such as inequalities or crises, “untested feasibility” representing a new vision based on awareness that a given reality can be altered, and “limit-acts” representing actions to change reality. In our abductive analysis, we focus on Brazilian women technology entrepreneurs as individuals transcending barriers such as 
gender inequality
. Our entrepreneurial 
autonomy
 perspective represents a process in which individuals (1) identify economic, social, and/or 
environmental issues
 that they can improve via entrepreneurship, (2) develop a new vision that articulates better economic, social, and/or environmental conditions, and (3) take actions to enhance these conditions and benefit diverse stakeholders by creating a nonprofit or for-profit 
enterprise
. We provide future directions for the integration of Freire's concepts and the entrepreneurial autonomy perspective in research, and offer our entrepreneurial autonomy worksheet for educators to empower individuals to develop ideas of socially responsible new ventures that create value for diverse stakeholders.",June 2023,"Social responsibility, Environmental sustainability, Women entrepreneurs, Paulo freire, Entrepreneurial autonomy, Sustainable development",Business Venturing Insights,2025-03-21T00:00:00,7.0,"The study focuses on Brazilian women technology entrepreneurs transcending barriers and providing a perspective on entrepreneurial autonomy, offering future directions for research and an entrepreneurial autonomy worksheet for empowerment."
https://www.sciencedirect.com/science/article/pii/S2352673423000227,Keep on keeping on: A psychological approach to entrepreneurial persistence,Jiaju=Yan: Justin_Yan@baylor.edu; Alan D.=Boss: adboss@ualr.edu; Rhonda K.=Reger: Rhonda.Reger@unt.edu,"Abstract
Persistence typifies the behavior of most successful entrepreneurs. Yet systematic theory about entrepreneurial persistence is lacking. This paper theorizes about psychological differences that lead some entrepreneurs to persist appropriately while others quit too soon or persist excessively. Building on self-regulation literature, we develop a theory of entrepreneurial persistence, called entrepreneurial psychological resource approach. Our paper makes two primary contributions to guide future research: a research model expanding upon the resource-based perspective in entrepreneurship research, and an evaluative component relating psychological resources to entrepreneurial persistence.",June 2023,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"The paper develops a theory of entrepreneurial persistence based on psychological resources, contributing to the understanding of why some entrepreneurs persist while others quit, providing a research model and evaluative component for future studies."
https://www.sciencedirect.com/science/article/pii/S235267342200035X,The values work of restorative ventures: The role of founders’ embodied embeddedness with at-risk social groups,Mohamed Hassan=Awad: mawad5@calstatela.edu; Mabel=Sanchez: msanch173@calstatela.edu; Matthew A.=Abikenari: matthewabi@g.ucla.edu,"Abstract
In line with the recent turn to pro-social ventures, restorative entrepreneuring is a promising approach for delivering social impact to marginalized and at-risk social groups with its focus on establishing ventures to rehabilitate and integrate individuals back into the community. However, the restorative project requires entrepreneurs to engage broadly with diverse sets of stakeholders with divergent worldviews, ideologies, and interests, many of which were the causes of 
marginalization
 and stigma for the at-risk social groups the entrepreneurs seek to serve. In this 
case study
, we focus on the role of values as a critical arena where entrepreneurs navigate 
stakeholders engagement
. We analyze Occupy Medical, a restorative venture in Oregon, United States, which provides healthcare services to the unhoused. We analyze how the founders captured and enacted values to establish and sustain the venture in a resource-constrained and often hostile environment. We identify a unique form of values work, embodied 
embeddedness
, as central to these efforts. Our study unpacks the role of values in restorative entrepreneuring as a tool for mitigating social exclusion of at-risk groups, enabling community reclamation of the social problem, and maneuvering local pushback and stigma.",November 2022,"Restorative entrepreneuring, Values, Work, Stakeholders, Qualitative, Homelessness",Business Venturing Insights,2025-03-21T00:00:00,9.0,"The case study provides valuable insights into restorative entrepreneuring, focusing on values as a critical aspect for engaging stakeholders in delivering social impact to marginalized groups, offering a unique perspective on values work in establishing and sustaining ventures."
https://www.sciencedirect.com/science/article/pii/S2352673422000439,Entrepreneurial miasma: Organizational miasma as a theoretical lens for increasing the odds of venture survival after the founder exits,James J.=Hoffman: jhoffman@nmsu.edu; Michaela=Driver: mdriver@nmsu.edu,"Abstract
The present study offers new insights on ventures undergoing founder exit. Specifically, it explores miasma as one potentially negative outcome. Miasma, a concept adapted from the organizational literature, refers to a state of contagion or pollution that affects all members of an organization causing potentially irreparable damage. This study develops a model of miasma in venture contexts when founders exit, a term we refer to as entrepreneurial miasma. This model includes the antecedents, moderating and mediating variables and outcomes of miasma. The purpose of this model is to develop insights into how miasma may be prevented and how ventures may work through it once it has occurred. Specifically, the study offers guidance for new management leading ventures on how to best understand, reestablish and build relationships with employees who are struggling with the exit of the founder to protect employee productivity and firm performance. The study also contributes to the organizational miasma literature by strengthening and clarifying the construct and its implications in both organizational and venture contexts.",November 2022,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"The study explores the concept of entrepreneurial miasma in venture contexts when founders exit, providing insights into how miasma may be prevented and managed, offering guidance for new management leading ventures in protecting employee productivity and firm performance."
https://www.sciencedirect.com/science/article/pii/S235267342200049X,Linking passion to performance in the social commerce community: The role of collaborative information exchange,Yiwen=Chen: yiwenchen@sfsu.edu; Li=Chen: lchen28@suffolk.edu; Robert=Smith: rssmith@suffolk.edu,"Abstract
The proliferation of 
social commerce
 has enabled millions of passionate entrepreneurs to launch businesses. Yet, literature is sparse regarding whether and how passionate entrepreneurs succeed in this new context. Through an in-depth analysis of the social commerce community, this study articulates the role of 
collaborative information exchange
 as one behavioral mechanism through which entrepreneurial passion translates into performance. Using both primary survey data and secondary store traffic and trade volume data from a social commerce website, the authors find that collaborative information exchange partially mediates the effect of passion on entrepreneurs’ business satisfaction (subjective performance) and fully mediates the effect of passion on store traffic and trade volume (objective performance). This study deepens our understanding of entrepreneurial passion by identifying an important mechanism that is specific to the digital entrepreneurship domain and provides practical implications to both individual entrepreneurs and social commerce platforms.",November 2022,"Entrepreneurial passion, Collaborative information exchange, Social commerce, Digital entrepreneurship",Business Venturing Insights,2025-03-21T00:00:00,8.0,"This study deepens our understanding of entrepreneurial passion in the context of social commerce, providing practical implications for individual entrepreneurs and platforms."
https://www.sciencedirect.com/science/article/pii/S2352673421000809,Giving colour to emotions in entrepreneurship,Bernadetta A.=Ginting-Szczesny: bernadetta.ginting@aalto.fi,"Abstract
This paper introduces colour as a visual resource for accessing the emotional experience of entrepreneurs. Colour has been demonstrated throughout the past decades to contain strong affective meanings and the ability to communicate specific emotional experiences. In this paper I show how colours are used by entrepreneurs through the colour timeline approach as a tool to facilitate the process of making sense of and expressing emotion. In particular, I show how colour can give form to complex emotions, draw out significant emotional events, and provide visual space for holistic reflection. This paper thus highlights the potential of colour for research on emotion in the context of entrepreneurship.",June 2022,"Emotion, Entrepreneurship, Colour, Visual methodology, Multimodality",Business Venturing Insights,2025-03-21T00:00:00,5.0,"While exploring the use of color in entrepreneurship is interesting, the practical value and impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S235267342100072X,Psychological well-being of hybrid entrepreneurs,Martin=Obschonka: martin.obschonka@qut.edu.au; Retno=Ardianti: retnoa@petra.ac.id,"Abstract
Although the phenomenon of hybrid entrepreneurs—individuals who work in paid and self-employment simultaneously—is prevalent, the psychological well-being of hybrid entrepreneurs has not been researched systematically to date. This is unlike research on paid employment and (assumed) full-time entrepreneurship, where psychological well-being has been researched as a key factor. Using data from the United Kingdom Household Longitudinal Survey, we address this void by studying whether hybrid entrepreneurs display distinct psychological well-being patterns (measured via mental strain, job satisfaction, and life satisfaction), utilizing a comparison with full-time paid employed, full-time self-employed and individuals working in two paid jobs. We further examine whether the specific work arrangements of hybrid entrepreneurs shape their well-being. To this end, we study the changes in well-being of hybrid entrepreneurs and other individuals in the comparison groups who switch to other jobs. For this purpose, we employed matching (entropy balancing approach) to account for self-selection effects. Our results suggest that the well-being of hybrid entrepreneurs is indeed distinct and can be explained by both self-selection effects and unique aspects of their work arrangements. Our study is thus the first to deliver evidence showing that hybrid entrepreneurs need to be studied as a separate group in entrepreneurship research concerned with well-being and psychological functioning. Our results have important implications not only for future research but also for practice.",June 2022,Not Found,Business Venturing Insights,2025-03-21T00:00:00,9.0,"This study addresses a significant gap in research regarding the psychological well-being of hybrid entrepreneurs, providing important implications for future research and practice."
https://www.sciencedirect.com/science/article/pii/S2352673421000767,Lassie shrugged: The premise and importance of considering non-human entrepreneurial action,Richard A.=Hunt: rickhunt@vt.edu; Daniel A.=Lerner: Daniel.Lerner@ie.edu; Avery=Ortiz-Hunt: avery_ortiz-hun1@baylor.edu,"Abstract
While management and entrepreneurship scholars have displayed comfort in and receptivity towards anthropomorphizing organizations, technologies, and even algorithms, our field has not yet grappled with a mountain of empirical evidence gathered over decades of research in the natural sciences that non-humans may behave entrepreneurially. For reflection and valuable perspective, our study relaxes the central assumption that entrepreneurial behaviors are the exclusive domain of human beings. Doing so invites fresh insights concerning the transversal nature of 
entrepreneurial action
, the biological origins of innovation and entrepreneurship, the categorical assumptions demarcating the field of entrepreneurship, and the persistent emphases on intendedly rational conceptions of 
entrepreneurial action
. The inspiration for our study involves “moving back from the species,” as E.O. Wilson advised. Through this “more distanced view” and by focusing on the reproducible benefits of entrepreneurship rather than narrower, human-centric conceptions of firm formation and profit generation, we find that the consideration of non-human behaviors contributes to the evolving definitions and future study of entrepreneurial action.",June 2022,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"The exploration of non-human entrepreneurial behaviors provides valuable perspective, but the immediate practical implications for early-stage ventures may be less direct."
https://www.sciencedirect.com/science/article/pii/S235267342200004X,Informal competition and product innovation decisions of new ventures and incumbents across developing and transitioning countries,Punyashlok=Dwibedy: punyashlok.dwibedy@ahduni.edu.in,"Abstract
While existing research has found that informal competition positively impacts 
product innovation
 by formal firms in developing and transitioning countries, there is a lack of understanding of how this decision to innovate varies between incumbents and new ventures. Through replication and extension of the work by McCann and Bahl (2017), the article primarily tries to address this significant gap by analyzing the differential impact of informal competition on 
product innovation
 decisions of incumbents and new ventures. Using data from the latest round of the World Bank 
Enterprise
 Surveys, 2019–2020, conducted across multiple transitioning and developing countries and logistic regression as the method of analysis, this study finds that (a) informal competition positively impacts the likelihood of product innovation by formal firms, confirming the results of McCann and Bahl (2017) and (b) new ventures are less likely to engage in product innovation than incumbents when competing with informal firms. The article contributes to the literature by trying to empirically resolve the friction between Attention-Based View of the firm and liability of newness. This paper argues that when facing informal competition, new ventures are less likely to respond through innovation compared to incumbents due to competing resource requirements that limit their attention towards competition from informal firms.",June 2022,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"While the study contributes to the literature on informal competition and product innovation, the focus on incumbents and new ventures may have limited direct impact on early-stage startups."
https://www.sciencedirect.com/science/article/pii/S2352673422000142,Green start-ups and the role of founder personality,Hanna=Hottenrott: hanna.hottenrott@tum.de; Gary=Chapman: gary.chapman@dmu.ac.uk,"Abstract
Green start-ups play a vital role in the needed transition towards more environmentally sustainable economies. Yet our understanding of why some founders start green ventures and others do not remains incomplete. We build on the cognitive and decision-making perspectives on start-ups pro-environmental engagement to shed light on the role of founders' 
personality traits
 - focusing on the ‘Big 5’ and risk tolerance - in explaining whether founders' start new ventures with 
environmentally friendly products
. Our analysis of a large, representative, manufacturing and 
service sector
 sample of German start-ups illustrates the important role of founder 
personality traits
. Specifically, openness and extraversion promote environmentally friendly products while 
neuroticism
 inhibits them. We discuss the implications of these insights.",June 2022,"Emission reduction, Environmentally friendly products, Green innovation, Big five personality traits, Sustainability",Business Venturing Insights,2025-03-21T00:00:00,8.0,"This abstract focuses on the role of founder personality traits in environmentally friendly start-ups, providing valuable insights for early-stage ventures in the European market."
https://www.sciencedirect.com/science/article/pii/S2352673421000317,Are behavioral and electrophysiological measures of impulsivity useful for predicting entrepreneurship?,Roy=Thurik: thurik@ese.eur.nl,"Abstract
We examine the association between several behavioral and electrophysiological indices of impulsivity-related constructs and multiple entrepreneurial constructs. Specifically, we investigate if these behavioral and electrophysiological measures are more useful as predictors of entrepreneurship than self-reported measures of impulsivity. Our findings are based on two datasets (
n
 = 133 and 
n
 = 142) and indicate that behavioral and electrophysiological impulsivity measures are not robustly associated with entrepreneurship constructs, in contrast to self-reported measures of impulsivity. Though disappointing at first, our findings pave the way for future research on the relevance of behavioral and electrophysiological measures for entrepreneurship.",November 2021,"Entrepreneurship, Impulsivity, EEG, Eriksen flanker task, Go/no-go task, Reward task, Balloon analogue risk task",Business Venturing Insights,2025-03-21T00:00:00,4.0,"While the research on impulsivity and entrepreneurship is interesting, the findings do not directly impact practical implications for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673420300482,A dynamic analysis of the role of entrepreneurial ecosystems in reducing innovation obstacles for startups,Franco-Leal=Noelia: noelia.franco@uca.es; Diaz-Carrion=Rosalia: rosaliadiaz@us.es,"Abstract
Innovative startups 
face
 serious obstacles in their innovation processes because of the high costs of innovations, lack of commercial and managerial competencies, and difficulties in cooperating with industrial agents. Understanding the evolution of these obstacles, the dynamic nature of 
entrepreneurial ecosystems
, and how such ecosystems can reduce obstacles to innovation becomes crucial for managers and policymakers. This research examines the evolution of different types of obstacles innovative startups 
face
 and analyzes the effects market and research resources have on the entrepreneurial ecosystem in reducing these obstacles over time. Linear mixed models are used to analyze the evolution of the influence of the entrepreneurial ecosystem on the innovation obstacles of 911 Spanish innovative startups. The results indicate that different obstacles display different patterns over time. We found that the role played by market and/or research sources on the entrepreneurial ecosystem in reducing different obstacles to innovation could be linked to the tendency of these obstacles to diminish over time. The results point to the need for a set of agents to reinforce each other by creating an ecosystem in which innovation obstacles faced by startups are reduced over time.",November 2020,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"This research examines the evolution of obstacles faced by innovative startups and the role of entrepreneurial ecosystems in reducing these obstacles over time, providing valuable insights for startup managers and policymakers."
https://www.sciencedirect.com/science/article/pii/S235267342030055X,Classifying self-employed persons using segmentation criteria available in the Labour Force Survey (LFS) data,Ondřej=Dvouletý: ondrej.dvoulety@vse.cz,"Abstract
This paper responds to the call of researchers, business practitioners, and policymakers to treat different kinds of entrepreneurs separately by the empirical implementation of Cieślik and Dvouletý (2019) segmentation criteria for classifying self-employed persons. The article shows how the segmentation variables (i.e. work engagement; skills and job classification; growth aspirations and economic dependency) might be used when working with the European 
Labour Force Survey
 (LFS) data set. The paper exploits the Czech sample of the ad-hoc module 2017 data set, and it shows differences between various types of entrepreneurs by using tools of applied statistical techniques (Chi-Square tests of association, Cramer’s V and t-tests). The article contributes to the community by showing how to use the segmentation variables in their own empirical research. The study encourages all researchers to explore the diversity of self-employment to advance the entrepreneurship field further forward. The article also includes several recommendations and directions for future research at the individual, regional, country or cross-country levels.",November 2020,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"This paper explores the segmentation of self-employed persons in Europe, which could provide some insights for policymakers and researchers, but may have a more limited impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673420300585,The practice of “we”: A framework for balancing rigour and relevance in entrepreneurship scholarship,Isla=Kapasi: i.kapasi@leeds.ac.uk; Ainurul=Rosli: Ainurul.rosli@brunel.ac.uk,"Abstract
The rigour-relevance divide remains a longstanding concern for the entrepreneurship field. In this article we elucidate the practice of “we” in entrepreneurship scholarship and propose a means to encourage and realise it. Our contribution is in the combination of reflection (content reflection, process reflection, and premise reflection) and design science phases; thus, we develop and outline the concept and communal practice of entrepreneur
ial
 scholarship informed by a structured reflection framework. Our original model and related framework detail a series of overlapping phases of inquiry and questioning, demonstrating how can we work together with non-academics to collectively strengthen the relevance of entrepreneurship scholarship and, ultimately, be more accountable and relevant to those whom we research.",November 2020,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"By proposing a structured reflection framework for entrepreneurial scholarship, this article offers a practical approach to strengthen the relevance of entrepreneurship research, potentially benefiting early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673420300640,Disinhibition predicts both psychopathy and entrepreneurial intentions,Benjamin R.=Walker: ben.walker1@monash.edu; Chris J.=Jackson: c.jackson@unsw.edu.au; Genevieve=Sovereign: genevieve.sovereign@alumni.utoronto.ca,"Abstract
Most research has suggested that 
disinhibition
, defined as persistence despite negative feedback, generally leads to dysfunctional outcomes. However, some traits related to 
disinhibition
 such as sensation seeking, impulsivity, and risk-taking are also associated with functional outcomes. This study examined 157 full-time workers to determine whether disinhibition positively predicted 
psychopathy
 and entrepreneurial intentions, using an adapted Balloon Analogue Risk Task (BART) as a measure of disinhibition. This approach was then replicated in a sample of 143 university staff and students. Across both samples, disinhibition was found to predict both subclinical 
psychopathy
 and entrepreneurial intentions. These results suggest disinhibition can be a driver that potentially leads to entrepreneurial action or antisocial outcomes.",November 2020,Not Found,Business Venturing Insights,2025-03-21T00:00:00,9.0,"This study on disinhibition, psychopathy, and entrepreneurial intentions provides valuable insights for understanding the psychological traits associated with entrepreneurship, which could have a significant impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673419300629,Psychiatric symptoms and entrepreneurial intention: The role of the behavioral activation system,Roy=Thurik: thurik@ese.eur.nl,"Abstract
Both the scientific literature and the popular press have recently started to associate entrepreneurship with symptoms of mental disorders. In addition, there is an emerging stream of literature devoted to the non-intendedly rational logic of entrepreneurs. Despite the high co-occurrence rate of psychiatric symptoms, prior research has only examined the independent effects of psychiatric symptoms. Furthermore, the two emerging literature streams remain largely independent. In the present study, we investigate the independent and joint association of four psychiatric symptoms (i.e., inattention, hyperactivity, 
narcissism
, and hypomania) and entrepreneurial intention. Drawing on the 
reinforcement sensitivity theory
, we explore whether the relationship between psychiatric symptoms and entrepreneurial intention is mediated by the behavioral activation system (BAS). Using the survey responses of 182 university students, our results show differential findings between the independent and joint effects of psychiatric symptoms on entrepreneurial intention. Importantly, we find support for the mediating role of BAS. Overall, our results suggest that BAS may serve as a unifying theoretical construct that helps to understand the relationship between multiple psychiatric symptoms and entrepreneurial intention.",June 2020,"Behavioral activation system, ADHD, Narcissism, Hypomania, Mental disorders, Entrepreneurial intention",Business Venturing Insights,2025-03-21T00:00:00,6.0,"Investigating the relationship between psychiatric symptoms and entrepreneurial intention, this study contributes to understanding the psychological aspects of entrepreneurship, which may have some relevance for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S2352673419300587,Resilience as a moderator of government and family support in explaining entrepreneurial interest and readiness among single mothers,Yulita=Not Found: yulita@umt.edu.my,"Abstract
Resilience is the individual’s ability to cope with, adapt to and recover from stressful or 
traumatic experiences
. It is considered crucial in various fields, and particularly in entrepreneurship. In the current study, we sought to deepen our understanding of the role of an individual’s resilience in moderating the interaction between government support and family support to predict entrepreneurial-related outcomes. Specifically, using self-determination theory (SDT) and the social support perspective, we proposed that a positive beneficial three-way interaction effect, stated as resilience*government support*family support, would enhance the level of single mothers’ entrepreneurial interest and readiness for entrepreneurial challenge. Data collected from 519 Malaysian single mothers in Malaysia’s East Coast region were analysed using IBM 
SPSS Statistics
 software. The results showed that resilience moderated government support and family support interaction to predict both entrepreneurial interest and readiness for entrepreneurial challenge. Although both types of support were viewed as important, they were more effective for individuals who were highly resilient than for those who were not. These findings support the important role of resilience as ‘a moderator of the moderator’ and of government support as an external source of motivation, with both complementing the positive beneficial outcomes of family support.",June 2020,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"The study provides valuable insights into the role of resilience in moderating the interaction between government support and family support for single mothers' entrepreneurial outcomes, contributing to the understanding of entrepreneurial success factors."
https://www.sciencedirect.com/science/article/pii/S2352673420300202,Towards an integrative definition of scaling social impact in social enterprises,Syrus M.=Islam: syrus.islam@aut.ac.nz,"Abstract
Scaling social impact is a key concept in the social 
enterprise
 literature. While central, the wide range of meanings and the lack of conceptual uniformity detract from its usefulness. To tackle this issue, this paper conducts a 
systematic review
 to derive an integrative definition of scaling social impact: Scaling social impact is an ongoing process of increasing the magnitude of both quantitative and qualitative positive changes in society by addressing pressing social problems at individual and/or systemic levels through one or more scaling paths. Alongside improving conceptual clarity, the definition offers an operational structure with five underlying elements, setting the basis for new empirical work and theorising in social 
enterprise
 research.",June 2020,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"The paper addresses the lack of clarity in defining scaling social impact in social enterprise literature, offering a structured definition that can potentially enhance future empirical work and research in the field."
https://www.sciencedirect.com/science/article/pii/S2352673420300238,A meta-analysis of the gender gap(s) in venture funding: Funder- and entrepreneur-driven perspectives,Mark=Geiger: geigerm1@duq.edu,"Abstract
Using gender homophily and 
gender socialization
 as theoretical foundations, the current study takes the position that both funder-driven (supply-side) and entrepreneur-driven (demand-side) processes perpetuate the gender gap in venture funding. Using this positional anchor, I performed a meta-analysis on gender-funding associations. The results show that gender-funding associations are different across funding contexts, which is consistent with what gender homophily and a funder-driven perspective might suggest. However, the nature of the difference depends on whether the outcome is funding amount or funding success. In addition, business size and 
industry
 sector were found to fully mediate the relation between entrepreneur gender and funding needed. This finding is consistent with what 
gender socialization
 and an entrepreneur-driven perspective might suggest. The mediation results ultimately suggest that female entrepreneurs need less funding for their ventures, which in turn results in less funding amounts but greater funding success. As such, there is one gender gap to the disadvantage of female entrepreneurs (funding amount) and another gender gap to the advantage of female entrepreneurs (funding success). Together, the perspectives and findings presented in this paper provide insights for both research and practice on the gender 
gap(s)
 in venture funding.",June 2020,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"The study sheds light on gender gaps in venture funding based on different funding contexts and perspectives, offering insights for research and practice, but the practical implications for European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S2352673419300344,Political climate and academic entrepreneurship: The case of strange bedfellows?,Peter T.=Gianiodis: gianiodisp@duq.edu; William R.=Meek: wmeek1@udayton.edu; Wendy=Chen: dchen16@gmu.edu,"Abstract
Universities have fully embraced academic entrepreneurship, transforming their structures, systems, and processes to generate licensing revenues and create new ventures. While prior research has mainly focused on the relationship between public policy and 
entrepreneurial activities
, this study examines a major gap – the performance implications of regional politics on academic entrepreneurship. We use a unique data set of U.S. universities and their regional governments to test how the influence of two elements of a region's political climate – consensus and stability – affects entrepreneurial and commercial performance. Our results suggest that political consensus and stability are positively associated with higher licensing revenues, while political stability is negatively associated with new venture creation. Our results reveal how regional politics influence university commercial outcomes, which suggests that entrepreneurship-enhancing public policy is intimately linked to the regional political process. We discuss the implications for theory and practice, and suggest possible future research directions.",November 2019,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"The research explores the impact of regional politics on academic entrepreneurship, revealing the associations between political climate elements and entrepreneurial performance in universities, providing implications for theory and practice in the field."
https://www.sciencedirect.com/science/article/pii/S2352673419300010,A chip off the old block? How parent-child interactions affect the intergenerational transmission of entrepreneurial intentions,Christian=Hopp: hopp@time.rwth-aachen.de; Dana=Minarikova: minarikova@time.rwth-aachen.de; Alexander=Speil: speil@time.rwth-aachen.de,"Abstract
Entrepreneurial parents can serve as sources of information and inspiration to transmit entrepreneurial intentions to their 
offspring
. Yet we find that role modelling is not purely observational, but it requires social interactions between parents and children to take effect. Our results using more than 2,500 child-parent dyads from the German socio-economic panel show that only if the socialization intensity between self-employed parents and their child is high entrepreneurial intentions will be transmitted. The intergenerational transmission of entrepreneurial intentions is dependent on the socialization intensity of the parents. The opportunity to share experiences with the children influences children's forming of 
entrepreneurial attitudes
 especially within same-sex parent-child dyads.",June 2019,Not Found,Business Venturing Insights,2025-03-21T00:00:00,4.0,"The study highlights the importance of social interactions between entrepreneurial parents and children in transmitting entrepreneurial intentions, but the focus on intergenerational transmission may have limited direct implications for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S235267341830132X,"The tacit knowledge of entrepreneurial design: Interrelating theory, practice and prescription in entrepreneurship research",Paul D.=Selden: paul.d.selden@gmail.com; Denise E.=Fletcher: denise.fletcher@uni.lu,"Abstract
An important challenge facing entrepreneurship researchers is the “three-body” knowledge problem of how to use “theoretical knowledge” to produce “prescriptive knowledge” that communicates the “practical knowledge” of situated practice to students and practitioners of entrepreneurship. We argue that a contribution can be made to solving this problem by theorizing practical knowledge as the “know-how” to do a situated entrepreneurial practice. “Know-how” is a cognitive “capacity to act” that 
prescribes
 for a practitioner how to produce a type of outcome in a range of circumstances. This “know-how” can potentially, therefore, be reconstructed theoretically as explicit micro-prescriptive guidelines for third-party practice. To exploit this connection between practical knowledge and prescriptive knowledge, however, we first need to overcome the problem that “know-how” is largely 
tacit
 in the moment of real-time forward-looking practice. In other words, the practitioner is not directly aware of their tacit “know-how”, or “tacit knowledge”, at the time of practice. In this article, we explore the contribution design theory can make to empirically eliciting, and conceptually inferring, the real-time “tacit knowledge” of entrepreneurial practice as a precursor to producing micro-prescriptive knowledge.",June 2019,Not Found,Business Venturing Insights,2025-03-21T00:00:00,5.0,"The abstract discusses theoretical concepts related to practical knowledge, which may have limited direct impact on early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S2352673418300933,Identifying design principles for business incubation in the European space sector,Joep=Cornelissen: cornelissen@rsm.nl; Daniel=Sagath: d.sagath@vu.nl; Elco=van Burg: j.c.van.burg@vu.nl; Christina=Giannopapa: Christina.giannopapa@esa.in,"Abstract
Organizations and policy makers seek to support business and entrepreneurship through facilitating new product and service development, for instance in business incubators. Taking stock of existing research and combining this with practitioner's insights, this study aims to identify a comprehensive set of design principles for incubation practices in a particular sector, the European space sector. We provide a synthesis of business incubation practices, resulting in a set of actionable design principles that also serves to tailor solutions for other contexts.",June 2019,Not Found,Business Venturing Insights,2025-03-21T00:00:00,7.0,"This abstract focuses on identifying design principles for incubation practices in the European space sector, providing actionable insights that could benefit early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S2352673418301112,Further exploring international entrepreneurial cognitions: The case of the Middle-East,J. Brock=Smith: smithb@uvic.ca; Hamid=Vahidnia: hvahidnia@tulane.edu; J. Robert=Mitchell: rmitchell@ivey.uwo.ca; Abdallah M.=Assaf: abdallah.assaf@ttu.edu; Ronald K.=Mitchell: ronald.mitchell@ttu.edu; Özlem=Araci: ozlem.araci@istanbul.edu.tr,"Abstract
Scholars argue that at least some entrepreneurial cognition is global; but there is little evidence to test this claim in the Middle East. For this region, composed of several countries with distinct socioeconomic contexts, even baseline descriptions are rare. Indeed, some have used the case of Middle East to challenge the global nature of entrepreneurial cognitions among individual entrepreneurs. Using data from 577 entrepreneurs and professionals in Egypt, Iran, 
Saudi Arabia
, and Turkey, four of the largest countries in the region, we study the extent to which entrepreneurial cognitions occur and explain an entrepreneurial 
mindset
 in this context.",June 2019,Not Found,Business Venturing Insights,2025-03-21T00:00:00,6.0,"The study on entrepreneurial cognitions in the Middle East may have relevance to European early-stage ventures, but the impact may be somewhat limited given the regional focus."
https://www.sciencedirect.com/science/article/pii/S2352673418301021,Understanding the design of opportunities: Re-evaluating the agent-opportunity nexus through a design lens,Thomas=Ding: thomas.ding@strath.ac.uk,"Abstract
This paper reassesses the fundamental tenets of the opportunity construct from a design perspective. It acknowledges the incommensurability between the opportunity discovery and creation views, and uses a processual approach based on ontological pragmatism to conceptualize an opportunity. In essence, this paper outlines the associative nature of an opportunity and its implications to elucidate its ephemerality and its dependence on human agency for materialization.",June 2019,Not Found,Business Venturing Insights,2025-03-21T00:00:00,8.0,"This abstract reassesses the opportunity construct from a design perspective, offering insights that could be valuable for European early-stage ventures and startups in understanding and exploiting opportunities."
https://ieeexplore.ieee.org/document/9875264/,Explainable Artificial Intelligence Applications in Cyber Security: State-of-the-Art in Research,,"This survey presents a comprehensive review of current literature on Explainable Artificial Intelligence (XAI) methods for cyber security applications. Due to the rapid development of Internet-connected systems and Artificial Intelligence in recent years, Artificial Intelligence including Machine Learning (ML) and Deep Learning (DL) has been widely utilized in the fields of cyber security including intrusion detection, malware detection, and spam filtering. However, although Artificial Intelligence-based approaches for the detection and defense of cyber attacks and threats are more advanced and efficient compared to the conventional signature-based and rule-based cyber security strategies, most ML-based techniques and DL-based techniques are deployed in the “black-box” manner, meaning that security experts and customers are unable to explain how such procedures reach particular conclusions. The deficiencies of transparencies and interpretability of existing Artificial Intelligence techniques would decrease human users’ confidence in the models utilized for the defense against cyber attacks, especially in current situations where cyber attacks become increasingly diverse and complicated. Therefore, it is essential to apply XAI in the establishment of cyber security models to create more explainable models while maintaining high accuracy and allowing human users to comprehend, trust, and manage the next generation of cyber defense mechanisms. Although there are papers reviewing Artificial Intelligence applications in cyber security areas and the vast literature on applying XAI in many fields including healthcare, financial services, and criminal justice, the surprising fact is that there are currently no survey research articles that concentrate on XAI applications in cyber security. Therefore, the motivation behind the survey is to bridge the research gap by presenting a detailed and up-to-date survey of XAI approaches applicable to issues in the cyber security field...",05 September 2022,"Computer crime, Cyberattack, Computer security, Deep learning, Medical services, Malware, Intrusion detection, Artificial intelligence, Unsolicited e-mail, Information filters, Artificial Intelligence, Artificial Intelligence Applications, Explainable Artificial Intelligence, Deep Learning, Defense Mechanisms, Black Box, Application Areas, Model Confidence, Intrusion Detection, Area Of Security, Learning Algorithms, Deep Neural Network, Machine Learning Models, Internet Of Things, Privacy Issues, SHapley Additive exPlanations, Adversarial Attacks, Vehicular Ad Hoc Networks, Intrusion Detection System, Local Explanations, Fraud Detection, Real-world Datasets, Massive Open Online Courses, Denial Of Service, Deep Neural Network Model, Artificial intelligence, cyber security, deep learning, explanation artificial intelligence, intrusion detection, machine learning, malware detection, spam filtering",IEEE Access,2025-03-24T00:00:00,9.0,"The abstract addresses a critical gap in XAI applications for cyber security, providing valuable insights for startups focusing on security solutions in European markets."
https://ieeexplore.ieee.org/document/9620068/,A Comprehensive Review on Fake News Detection With Deep Learning,,"A protuberant issue of the present time is that, organizations from different domains are struggling to obtain effective solutions for detecting online-based fake news. It is quite thought-provoking to distinguish fake information on the internet as it is often written to deceive users. Compared with many machine learning techniques, deep learning-based techniques are capable of detecting fake news more accurately. Previous review papers were based on data mining and machine learning techniques, scarcely exploring the deep learning techniques for fake news detection. However, emerging deep learning-based approaches such as Attention, Generative Adversarial Networks, and Bidirectional Encoder Representations for Transformers are absent from previous surveys. This study attempts to investigate advanced and state-of-the-art fake news detection mechanisms pensively. We begin with highlighting the fake news consequences. Then, we proceed with the discussion on the dataset used in previous research and their NLP techniques. A comprehensive overview of deep learning-based techniques has been bestowed to organize representative methods into various categories. The prominent evaluation metrics in fake news detection are also discussed. Nevertheless, we suggest further recommendations to improve fake news detection mechanisms in future research directions.",18 November 2021,"Social networking (online), Deep learning, Natural language processing, Machine learning, Convolutional neural networks, Terminology, Feature extraction, Deep Learning, Fake News, Fake News Detection, Machine Learning, Misinformation, Generative Adversarial Networks, Natural Language Processing Techniques, Neural Network, Social Media, Receiver Operating Characteristic Curve, Convolutional Neural Network, Deep Neural Network, Validation Set, Deep Learning Models, Recurrent Network, Long Short-term Memory, Recurrent Neural Network, Attention Mechanism, Convolutional Neural Network Model, Gated Recurrent Unit, Graph Neural Networks, Graph Convolutional Network, Long Short-term Memory Model, News Content, Word Embedding, Bidirectional Long Short-term Memory, Deep Learning-based Models, Data Split, Data Pre-processing, Natural language processing, machine learning, deep learning, fake news",IEEE Access,2025-03-24T00:00:00,7.0,"The abstract delves into advanced deep learning techniques for fake news detection, offering potential directions for startups working on online content authenticity verification."
https://ieeexplore.ieee.org/document/10595068/,"Deep Learning for Credit Card Fraud Detection: A Review of Algorithms, Challenges, and Solutions",,"Deep learning (DL), a branch of machine learning (ML), is the core technology in today’s technological advancements and innovations. Deep learning-based approaches are the state-of-the-art methods used to analyse and detect complex patterns in large datasets, such as credit card transactions. However, most credit card fraud models in the literature are based on traditional ML algorithms, and recently, there has been a rise in applications based on deep learning techniques. This study reviews the recent DL-based literature and presents a concise description and performance comparison of the widely used DL techniques, including convolutional neural network (CNN), simple recurrent neural network (RNN), long short-term memory (LSTM), and gated recurrent unit (GRU). Additionally, an attempt is made to discuss suitable performance metrics, common challenges encountered when training credit card fraud models using DL architectures and potential solutions, which are lacking in previous studies and would benefit deep learning researchers and practitioners. Meanwhile, the experimental results and analysis using a real-world dataset indicate the robustness of the deep learning architectures in credit card fraud detection.",11 July 2024,"Fraud, Credit cards, Reviews, Deep learning, Long short term memory, Machine learning algorithms, Hidden Markov models, Convolutional neural networks, Deep Learning, Credit Card, Fraud Detection, Credit Card Fraud Detection, Neural Network, Machine Learning, Learning Algorithms, Convolutional Neural Network, Short-term Memory, Performance Metrics, Long Short-term Memory, Recurrent Neural Network, Long Memory, Deep Learning Techniques, Deep Architecture, Real-world Datasets, Deep Learning Architectures, Gated Recurrent Unit, Traditional Machine Learning Algorithms, Support Vector Machine, Deep Learning Models, Long Short-term Memory Model, Minority Class, Long Short-term Memory Network, Hidden Layer, Transformer Model, Multilayer Perceptron, Convolutional Neural Network Model, Deep Neural Network, Machine Learning Models, Credit card, CNN, deep learning, fraud detection, GRU, LSTM, machine learning",IEEE Access,2025-03-24T00:00:00,8.0,"The abstract highlights the importance of using deep learning techniques for credit card fraud detection, providing valuable insights for startups operating in the fintech sector."
https://ieeexplore.ieee.org/document/10403908/,A Comprehensive Survey: Evaluating the Efficiency of Artificial Intelligence and Machine Learning Techniques on Cyber Security Solutions,,"Given the continually rising frequency of cyberattacks, the adoption of artificial intelligence methods, particularly Machine Learning (ML), Deep Learning (DL), and Reinforcement Learning (RL), has become essential in the realm of cybersecurity. These techniques have proven to be effective in detecting and mitigating cyberattacks, which can cause significant harm to individuals, organizations, and even countries. Machine learning algorithms use statistical methods to identify patterns and anomalies in large datasets, enabling security analysts to detect previously unknown threats. Deep learning, a subfield of ML, has shown great potential in improving the accuracy and efficiency of cybersecurity systems, particularly in image and speech recognition. On the other hand, RL is again a subfield of machine learning that trains algorithms to learn through trial and error, making it particularly effective in dynamic environments. We also evaluated the usage of ChatGPT-like AI tools in cyber-related problem domains on both sides, positive and negative. This article provides an overview of how ML, DL, and RL are applied in cybersecurity, including their usage in malware detection, intrusion detection, vulnerability assessment, and other areas. The paper also specifies several research questions to provide a more comprehensive framework to investigate the efficiency of AI and ML models in the cybersecurity domain. The state-of-the-art studies using ML, DL, and RL models are evaluated in each Section based on the main idea, techniques, and important findings. It also discusses these techniques’ challenges and limitations, including data quality, interpretability, and adversarial attacks. Overall, the use of ML, DL, and RL in cybersecurity holds great promise for improving the effectiveness of security systems and enhancing our ability to protect against cyberattacks. Therefore, it is essential to continue developing and refining these techniques to address the ever-evolving na...",18 January 2024,"Computer security, Deep learning, Security, Fraud, Prediction algorithms, Telecommunication traffic, Reinforcement learning, Machine learning, Artificial intelligence, Machine Learning, Machine Learning Techniques, Artificial Intelligence Techniques, Large Datasets, Deep Learning, Learning Algorithms, Machine Learning Models, Deep Learning Models, Dynamic Environment, Speech Recognition, Image Recognition, Vulnerability Assessment, Artificial Intelligence Models, Intrusion Detection, Adversarial Attacks, Artificial Intelligence Tools, Use Of Deep Learning, Deep Reinforcement Learning, DoS Attacks, Internet Of Things Devices, Distributed Denial Of Service, Convolutional Neural Network, Denial Of Service, Internet Of Things, Intrusion Detection System, Anomaly Detection, Neural Network, Cyberattacks and solutions, deep learning, machine learning, reinforcement learning, AI tools",IEEE Access,2025-03-24T00:00:00,8.0,"This abstract provides valuable insights into the application of ML, DL, and RL in cybersecurity, highlighting their effectiveness and potential to improve security systems. It addresses important research questions and challenges in the field."
https://ieeexplore.ieee.org/document/10849561/,Agentic AI: Autonomous Intelligence for Complex Goals—A Comprehensive Survey,,"Agentic AI, an emerging paradigm in artificial intelligence, refers to autonomous systems designed to pursue complex goals with minimal human intervention. Unlike traditional AI, which depends on structured instructions and close oversight, Agentic AI demonstrates adaptability, advanced decision-making capabilities and self-sufficiency, enabling it to operate dynamically in evolving environments. This survey thoroughly explores the foundational concepts, unique characteristics, and core methodologies driving the development of Agentic AI. We examine its current and potential applications across various fields, including healthcare, finance, and adaptive software systems, emphasizing the advantages of deploying agentic systems in real-world scenarios. The paper also addresses the ethical challenges posed by Agentic AI, proposing solutions for goal alignment, resource constraints, and environmental adaptability. We outline a framework for safely and effectively integrating Agentic AI into society, highlighting the need for further research on ethical considerations to ensure beneficial societal impacts. This survey serves as a comprehensive introduction to Agentic AI, guiding researchers, developers, and policymakers in engaging with its transformative potential responsibly and creatively.",22 January 2025,"Artificial intelligence, Surveys, Ethics, Reinforcement learning, Hands, Adaptation models, Medical services, Automation, Translation, Systematic literature review, Intelligence, Agentic, Autonomic System, Human Intervention, Environmental Adaptation, Goal Alignment, Accountability, Scalable, Ethical Issues, Diverse Environments, Autonomous Vehicles, Moral Judgment, General Data Protection Regulation, Human Values, Multi-agent Systems, Smart City, Ethical Framework, Multi-task Learning, Multiple Goals, Federated Learning, AI Systems, AI Models, Inverse Reinforcement Learning, Predictive Maintenance, Real-time Decision-making, Multi-party Computation, Deep Reinforcement Learning, Sensitive Tasks, Effective Deployment, Agentic AI, autonomous systems, human-AI collaboration, adaptability, governance frameworks, ethical AI",IEEE Access,2025-03-24T00:00:00,9.0,"Agentic AI is presented as an emerging paradigm with advanced decision-making capabilities and self-sufficiency, showcasing its potential across various fields. The paper also discusses ethical considerations, providing a comprehensive framework for integration and societal impact."
https://ieeexplore.ieee.org/document/10747338/,AI Enabled Threat Detection: Leveraging Artificial Intelligence for Advanced Security and Cyber Threat Mitigation,,"This comprehensive review examines the role of artificial intelligence (AI) in enhancing threat detection and cybersecurity, focusing on recent advancements and ongoing challenges in this dynamic field. The ability to identify and counteract cybersecurity threats including network breaches, adversarial assaults, and zero-day vulnerabilities has significantly increased with the inclusion of AI, especially machine learning and deep learning techniques. The review underscores the critical role of explainability and resilience in AI models to ensure trustworthiness and reliability in AI-driven security solutions. The studies analyzed span a wide range of sectors, including Industry 5.0, the Internet of Things (IoT), 5G networks, and autonomous vehicles, illustrating AI’s adaptability in tackling unique security issues across these domains. Cutting-edge approaches, such as transformer-based models, federated learning, and blockchain integration, are advancing the development of more robust and real-time threat detection systems. However, challenges persist, particularly in managing large-scale data, enabling real-time processing, and ensuring privacy and security. The review concludes that although substantial progress has been achieved, ongoing research and collaboration are vital to fully harness AI’s potential in securing digital landscapes.",08 November 2024,"Artificial intelligence, Computer security, Data models, Threat assessment, Adaptation models, Internet of Things, Deep learning, Accuracy, Complexity theory, Analytical models, Intrusion detection, Blockchains, Artificial Intelligence, Threat Detection, Machine Learning, Detection System, Deep Learning, Assault, Internet Of Things, Deep Learning Techniques, Autonomous Vehicles, Artificial Intelligence Models, 5G Networks, Federated Learning, Internet Of Vehicles, Convolutional Neural Network, Support Vector Machine, Random Forest, Deep Learning Models, Long Short-term Memory, Recurrent Neural Network, AI Models, Integration Of Artificial Intelligence, Distributed Denial Of Service, Intrusion Detection System, Explainable Artificial Intelligence, Generative Adversarial Networks, Adversarial Examples, Simulation Environment, Denial Of Service, Artificial Intelligence Approaches, Zero-day vulnerabilities, network intrusion detection, federated learning, blockchain, Internet of Things (IoT), adversarial attacks",IEEE Access,2025-03-24T00:00:00,7.0,"This review offers a comprehensive analysis of AI's role in threat detection and cybersecurity, emphasizing the importance of explainability and resilience in AI models. It delves into cutting-edge approaches and ongoing challenges in the field."
https://ieeexplore.ieee.org/document/10583885/,Deep Learning Models for Time Series Forecasting: A Review,,"Time series forecasting involves justifying assertions scientifically regarding potential states or predicting future trends of an event based on historical data recorded at various time intervals. The field of time series forecasting, supported by diverse deep learning models, has made significant advancements, rendering it a prominent research area. The broad spectra of available time series datasets serve as valuable resources for conducting extensive studies in time series analysis with varied objectives. However, the complexity and scale of time series data present challenges in constructing reliable prediction models. In this paper, our objectives are to introduce and review methodologies for modeling time series data, outline the commonly used time series forecasting datasets and different evaluation metrics. We delve into the essential architectures for trending an input dataset and offer a comprehensive assessment of the recently developed deep learning prediction models. In general, different models likely serve different design goals. We boldly examine the performance of these models under the same time series input dataset with an identical hardware computing system. The measured performance may reflect the design flexibility among all the ranked models. And through our experiments, the SCINet model performs the best in accuracy with the ETT energy input dataset. The results we obtain could give a glimpse in understanding the model design and performance relationship. Upon concluding the paper, we shall provide further discussion on future deep learning research directions in the realm of time series forecasting.",03 July 2024,"Time series analysis, Forecasting, Predictive models, Autoregressive processes, Electricity, Meteorology, Deep learning, Performance evaluation, Neural networks, Transformers, Time Series, Deep Learning, Deep Learning Models, Forecasting Model, Time Series Prediction, Model Performance, Deep Models, Time Series Data, Model Design, Time Series Analysis, Future Trends, Time Series Models, Time Series Dataset, Time Step, Convolutional Network, Convolutional Neural Network, Mean Absolute Error, Long Short-term Memory, Recurrent Neural Network, Attention Mechanism, Long-term Forecasting, Graph Neural Networks, Traffic Prediction, Graph Convolutional Network, Traditional Recurrent Neural Network, Autoregressive Integrated Moving Average, Transformer Model, Recurrent Neural Network Model, Seq2seq Model, Stationary Time Series, Dataset, deep learning, evaluation metrics, neural network models, time series forecasting, Transformer models",IEEE Access,2025-03-24T00:00:00,6.0,"The abstract explores time series forecasting with deep learning models, discussing methodologies, datasets, and model performance. While it offers insights into model design and future research directions, it lacks a clear demonstration of practical application impact on startups."
https://ieeexplore.ieee.org/document/10440330/,"Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations",,"Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.",20 February 2024,"Medical services, Chatbots, Medical diagnostic imaging, Data models, Generative AI, Training, Solid modeling, Generative adversarial networks, Artificial intelligence, Drugs, Visualization, Artificial Intelligence In Healthcare, Clinical Trials, Mental Health, Patient Care, Drug Discovery, Patient Data, Medical Imaging, Medical Education, Dentists, Data Privacy, Real-world Scenarios, Human Movement, Mental Health Support, Artificial Intelligence Systems, Surgical Simulation, Personalized Treatment Of Patients, Healthcare Operations, Training Data, Decision-making Process, Drug Development, Artificial Intelligence Models, Language Model, Generative Adversarial Networks, Variational Autoencoder, Medical Data, Virtual Patients, Virtual Assistant, Electronic Health Records, Rehabilitation Robots, Conditional Variational Autoencoder, Generative AI, ChatGPT, healthcare, LLMs, applications",IEEE Access,2025-03-24T00:00:00,8.0,"The research on the applications and scope of GAI in healthcare can have a significant impact on early-stage ventures, especially startups in the healthcare industry. The exploration of real-world scenarios and limitations of GAI in healthcare provides valuable insights for practical implementation."
https://ieeexplore.ieee.org/document/9513281/,"Grid Forming Inverter Modeling, Control, and Applications",,"This paper surveys current literature on modeling methods, control techniques, protection schemes, applications, and real-world implementations pertaining to grid forming inverters (GFMIs). Electric power systems are increasingly being augmented with inverter-based resources (IBRs). While having a growing share of IBRs, conventional synchronous generator-based voltage and frequency control mechanisms are still prevalent in the power industry. Therefore, IBRs are experiencing a growing demand for mimicking the behavior of synchronous generators, which is not possible with conventional grid following inverters (GFLIs). As a solution, the concept of GFMIs is currently emerging, which is drawing increased attention from academia and the industry. This paper presents a comprehensive review of GFMIs covering recent advancements in control technologies, fault ride-through capabilities, stability enhancement measures, and practical implementations. Moreover, the challenges in adding GFMIs into existing power systems, including a seamless transition from grid-connected mode to the standalone mode and vice versa, are also discussed in detail. Recently commissioned projects in Australia, the UK, and the US are taken as examples to highlight the trend in the power industry in adding GFMIs to address issues related to weak grid scenarios. Research directions in terms of voltage control, frequency control, system strength improvement, and regulatory framework are also discussed. This paper serves as a resource for researchers and power system engineers exploring solutions to the emerging problems with high penetration of IBRs, focusing on GFMIs.",13 August 2021,"Inverters, Power system stability, Voltage control, Reactive power, Frequency control, Stability analysis, Synchronous generators, Grid-forming, Inverter Control, Grid-forming Inverters, Power System, Control Techniques, Frequency Control, Voltage Control, Synchronous Generator, System Strength, Electric Power System, Seamless Transition, Synchronization Mechanism, Weak Grid, Grid-connected Mode, Standalone Mode, Current Limitations, Current Control, Power Control, Voltage Regulation, Wind Farm, Droop Control, Transient Stability, Point Of Common Coupling, Phase-locked Loop, Frequency Regulation, Active Power Control, Maximum Power Point Tracking, Synchronous Motor, Overcurrent Protection, Grid Voltage, Current control, fault ride-through, grid forming inverters, power synchronization control, small-signal and transient stability, virtual inertia",IEEE Access,2025-03-24T00:00:00,5.0,"The survey on grid forming inverters (GFMIs) is relevant in the context of the power industry, but may have limited direct impact on European early-stage ventures and startups. The practical implementations and challenges discussed are informative but may not directly benefit startups in other industries."
https://ieeexplore.ieee.org/document/10787131/,Maximum Extractable Value (MEV) Mitigation Approaches in Ethereum and Layer-2 Chains: A Comprehensive Survey,,"Maximal Extractable Value (MEV) represents a pivotal challenge within the Ethereum ecosystem; it impacts the fairness, security, and efficiency of both Layer 1 (L1) and Layer 2 (L2) networks. MEV arises when miners or validators manipulate transaction ordering (e.g., front-running) to extract additional value, often at the expense of other network participants. This not only affects user experience by introducing unpredictability and potential financial losses but also threatens the underlying principles of decentralization and trust. Given the growing complexity of blockchain applications, particularly with the increase of Decentralized Finance (DeFi) protocols, it is crucial to address the issue and reduce the impact of MEV. This paper presents a comprehensive survey of MEV mitigation techniques as applied to both Ethereum’s L1 and various L2 solutions. We provide a novel categorization of mitigation strategies. We also describe the challenges, ranging from transaction sequencing and cryptographic methods to reconfiguring decentralized applications (DApps) to reduce front-running opportunities. We investigate their effectiveness, implementation challenges, and impact on network performance. By synthesizing current research, real-world applications, and emerging trends, this paper aims to provide a detailed roadmap for researchers, developers, and policymakers to understand and combat MEV in an evolving blockchain landscape.",09 December 2024,"Prevention and mitigation, Blockchains, Surveys, Taxonomy, Chatbots, Smart contracts, Finance, Decentralized applications, Sequential analysis, Monitoring, Mitigation Approaches, Mitigation Strategies, Single Node, Types Of Attacks, Secret Key, Public Key, Symmetric Encryption, Network Participants, Higher Fees, Certain Amount Of Time, Policies In Order, Key Generation, Smart Contracts, Single Point Of Failure, Relay Nodes, Secure Channel, Encryption Key, Decryption Process, Decryption Key, Zero-knowledge Proof, Transaction Fees, Blockchain Network, Network Congestion, Partial Order, Byzantine Fault Tolerance, Committee Members, Multiple Parties, Second Category, Blockchain System, Blockchain technology, DeFi protocols, Ethereum, fair ordering, MEV, privacy-preserving methods",IEEE Access,2025-03-24T00:00:00,7.0,The study on Maximal Extractable Value (MEV) in the Ethereum ecosystem addresses a crucial challenge with implications for decentralized finance (DeFi) protocols. Understanding and mitigating MEV can provide important insights for startups exploring blockchain applications. The detailed roadmap offered in the paper can guide startups in developing strategies to combat MEV.
https://ieeexplore.ieee.org/document/10485402/,Data-Driven Modeling of Grid-Forming Inverter Dynamics Using Power Hardware-in-the-Loop Experimentation,,"Recently, there is rapid integration of power electronic converter (PECs) into the power grid. Most of these PECs are grid-following inverters, where weak grid operation becomes an issue. Research is now shifting focus to grid-forming (GFM) inverters, resembling synchronous generators. The shift towards converter-based generation necessitates accurate PEC models for assessing system dynamics that were previously ignored in conventional power systems. Data-driven modeling (DDM) techniques are becoming valuable tools for capturing the dynamic behavior of advanced control strategies for PECs. This paper proposes using power hardware-in-the-loop experiments to capture dynamic GFM data in the application of DDM techniques. Furthermore, the paper derives an analytical approach to obtaining a mathematical model of GFM inverter dynamics and compares it with the DDM. A square-chirp probing signal was employed to perturb the active and reactive power of the load inside an Opal-RT model. The dynamic response of the GFM inverter, including changes in frequency and voltage, was recorded. This data was then used in a system identification algorithm to derive the GFM DDMs. The effectiveness of DDM is cross-validated with an analytical approach through experimental simulation studies, and the goodness-of-fit for both approaches is compared. Both approaches show more than 85% accuracy in capturing the dynamic response of GFM inverters under different loading conditions.",29 March 2024,"Inverters, Voltage control, Power system dynamics, Frequency control, Integrated circuit modeling, Analytical models, Load modeling, Data models, Power grids, Hardware-in-the-loop simulation, System identification, Data-driven Models, Grid-forming Inverters, Inverter Dynamics, Analysis Approach, Accuracy Of Model, System Dynamics, Changes In Frequency, Power System, Modeling Techniques, System Identification, Power Grid, Application Of Data, Power Electronics, Load Power, Probe Signal, Synchronous Generator, Power Electronic Converters, Modeling Approach, Training Dataset, Renewable Energy, Droop Control, Output Frequency, Signal Frequency, Grid Frequency, Poles And Zeros, Point Of Common Coupling, Phase-locked Loop, Voltage Control, Chirp Signal, Normalized Root Mean Square Error, Data-driven modeling, grid-forming inverter, power hardware-in-the-loop, power system dynamics, real-time digital simulator, system identification",IEEE Access,2025-03-24T00:00:00,7.0,"This abstract presents valuable research on power electronic converters (PECs) and their impact on grid operations. The shift towards grid-forming inverters and the use of data-driven modeling techniques are important for advancing power system dynamics. The proposed experimental approach adds practical value to the research. However, the niche focus on power systems may limit its direct impact on a broader range of early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584925000266,An empirical study on the impact of code duplication-aware refactoring practices on quality metrics,Eman Abdullah=AlOmar: ealomar@stevens.edu,"Abstract
Context:
Code refactoring is widely recognized as an essential software engineering practice that improves the understandability and maintainability of source code. Several studies attempted to detect refactoring activities through mining software repositories, allowing one to collect, analyze, and get actionable data-driven insights about refactoring practices within software projects.
Objective:
Our goal is to identify, among the various quality models presented in the literature, the ones that align with the developer’s vision of eliminating duplicates of code, when they explicitly mention that they refactor the code to improve them.
Method:
We extract a corpus of 332 refactoring commits applied and documented by developers during their daily changes from 128 open-source Java projects. In particular, we extract 32 structural metrics from which we identify code duplicate removal commits with their corresponding refactoring operations, as perceived by software engineers. Thereafter, we empirically analyze the impact of these refactoring operations on a set of common state-of-the-art design quality metrics.
Results:
The statistical analysis of the results obtained shows that (i) some state-of-the-art metrics are capable of capturing the developer’s intention of removing code duplication; and (ii) some metrics are being more emphasized than others. We confirm that various structural metrics can effectively represent code duplication, leading to different impacts on software quality. Some metrics contribute to improvements, while others may lead to degradation.
Conclusion:
Most of the mapped metrics associated with the main quality attributes successfully capture developers’ intentions for removing code duplicates, as is evident from the commit messages. However, certain metrics do not fully capture these intentions.",June 2025,Not Found,Information and Software Technology,2025-03-24T00:00:00,7.0,"This abstract provides valuable insights into the impact of code duplication removal on software quality, which can be crucial for early-stage ventures aiming to improve the maintainability of their codebase."
https://www.sciencedirect.com/science/article/pii/S0950584925000412,Beyond domain dependency in security requirements identification,Carmine=Gravino: gravino@unisa.it; Francesco=Casillo: fcasillo@unisa.it; Vincenzo=Deufemia: deufemia@unisa.it,"Abstract
Context:
Early security requirements identification is crucial in software development, facilitating the integration of security measures into IT networks and reducing time and costs throughout software life-cycle.
Objectives:
This paper addresses the limitations of existing methods that leverage Natural Language Processing (NLP) and machine learning techniques for detecting security requirements. These methods often fall short in capturing syntactic and semantic relationships, face challenges in adapting across domains, and rely heavily on extensive domain-specific data. In this paper we focus on identifying the most effective approaches for this task, highlighting both domain-specific and domain-independent strategies.
Method:
Our methodology encompasses two primary streams of investigation. First, we explore shallow machine learning techniques, leveraging word embeddings. We test ensemble methods and grid search within and across domains, evaluating on three industrial datasets. Next, we develop several domain-independent models based on BERT, tailored to better detect security requirements by incorporating data on software weaknesses and vulnerabilities.
Results:
Our findings reveal that ensemble and grid search methods prove effective in domain-specific and domain-independent experiments, respectively. However, our custom BERT models showcase domain independence and adaptability. Notably, the CweCveCodeBERT model excels in Precision and F1-score, outperforming existing approaches significantly. It improves F1-score by 
∼
3% and Precision by 
∼
14% over the best approach currently in the literature.
Conclusion:
BERT-based models, especially with specialized pre-training, show promise for automating security requirement detection. This establishes a foundation for software engineering researchers and practitioners to utilize advanced NLP to improve security in early development phases, fostering the adoption of these state-of-the-art methods in real-world scenarios.",June 2025,"Security Requirements Classification, Natural Language Processing, Machine Learning, Transformers",Information and Software Technology,2025-03-24T00:00:00,8.0,"The abstract offers innovative methods for detecting security requirements using advanced NLP techniques, which could have a significant impact on the security posture of European startups in early development phases."
https://www.sciencedirect.com/science/article/pii/S0950584925000606,Personalization goals for run-time adaptation of IoT-based assistance applications for the elderly,Luca=Sabatucci: luca.sabatucci@icar.cnr.it; Claudia=Di Napoli: claudia.dinapoli@icar.cnr.it,"Abstract
Context:
the increasing demand for Ambient Assisted Living (AAL) applications has led to the need for personalized assistive tasks that can adapt to individual users’ needs.
Objectives:
we aim to balance design-time personalization with techniques of run-time adaptation for designing and executing assistive AAL applications, personalized to both users’ specific needs and environmental conditions.
Methods:
we propose a personalization process based on: (1) representing assistive tasks as workflows initially defined at a high level of abstraction that specifies their functional components, (2) providing an instrument for specifying how to customize these workflows for individual users, and (3) a supporting architecture that enables the run-time transformation of high-level specifications into executable workflows.
Results:
our empirical evaluation demonstrates that the proposed personalization goals effectively support designers in creating adaptable workflows, showing improved quality scores in personalization compared to traditional BPMN practices, without increasing design effort. Performance analysis also shows the feasibility of our run-time adaptation approach with linear scaling as the number of personalization goals increases.
Conclusion:
a personalization process for modelling personalizable workflows may be a flexible instrument for designers to conceive assistive applications that are automatically adapted to individual users’ needs at run-time, allowing for balancing the benefits of design-time and run-time personalization techniques.",June 2025,"Personalized Ambient Assisted Living, Goal modelling, Internet of Things",Information and Software Technology,2025-03-24T00:00:00,6.0,"The abstract introduces a novel approach to personalization in AAL applications, which could be beneficial for startups developing assistive technologies tailored to individual users' needs."
https://www.sciencedirect.com/science/article/pii/S0950584925000631,Requirements engineering for no-code development (RE4NCD): Case studies of rapid application development during crisis,Meira=Levy: lmeira@shenkar.ac.il,"Abstract
Context
In recent years, a new development approach has emerged, for rapid application development (RAD) supported by platforms that enable low or no-code development (NCD). This approach is designed for developers with limited or no coding expertise and for achieving a very short time-to-deployment. The requirements engineering (RE) and design phases are typically omitted during RAD, thus posing challenges in ensuring a rigorous, sustainable, and flexible application.
Objective
To propose an RE method for NCD (RE4NCD) that would respect the limitations in which NCD is conducted yet ensure more rigorous development and outcome.
Method
A participatory case study aimed to explore RAD processes as performed with the ""Monday"" NCD platform and, accordingly, to develop the RE4NCD method. This study was followed by multiple (non-participatory) case studies for the refinement and validation of the proposed method. All case studies focused on civilian management systems that were developed rapidly during a time of war and included qualitative data collection and thematic analysis.
Results
The thematic analysis resulted in categories of RE activities to be included in the RE4NCD method, leading to its construction in the first case study, and its refinement and validation in the follow-up case studies.
Conclusion
The paper highlights the theoretical and practical implications of RE4NCD, underscoring the potential transformative impact of NCD on the software development industry. It also proposes future research aimed at refining and validating the RE4NCD method, tracking the adoption and evolution of applications in diverse organizations, and applying the method to additional case studies for evaluation and validation.",June 2025,Not Found,Information and Software Technology,2025-03-24T00:00:00,5.0,"The abstract presents an interesting proposal for addressing the challenges of rapid application development with a focus on requirements engineering, which may be relevant for startups using low or no-code platforms."
https://www.sciencedirect.com/science/article/pii/S0883902625000254,Ethnic fractionalization and informal entrepreneurship: An institutional logics perspective,Mark R.=Mallon: mallonm@fau.edu,"Abstract
Research is needed to uncover the sociocultural influences of informal entrepreneurship, or starting a legally unregistered but otherwise legitimate business. Using the institutional logics perspective, we posit that ethnic fractionalization increases the likelihood that entrepreneurs will not register their ventures because it fosters a clan logic and embeddedness in one's ethnic group. Entrepreneurs may not readily access knowledge regarding registration because the ethnic group can provide some of the benefits associated with registration. However, the clan logic is mitigated for entrepreneurs who receive advice from lawyers or businesspeople because these advisors are associated with the state or market logics, respectively, making knowledge of registration more accessible to entrepreneurs. We find support for these arguments using a sample of over 5000 entrepreneurs in 29 countries.",July 2025,Not Found,Business Venturing,2025-03-24T00:00:00,4.0,"While the abstract offers an intriguing perspective on informal entrepreneurship, the direct practical value for European early-stage ventures may be limited compared to the other abstracts."
https://ieeexplore.ieee.org/document/10786986/,An Empirical Analysis of Above-Ground Biomass and Carbon Sequestration Using UAV Photogrammetry and Machine Learning Techniques,,"This research aims to analyze above-ground biomass and carbon sequestration using unmanned aerial vehicle (UAV) photogrammetry and machine learning methods, focusing on a case study of the dry dipterocarp forest in the Ban Hin Lat and Hin Lat Phatthana Community Forests. The methodology involved conducting field surveys and data analysis to estimate biomass using allometric equations and UAV photogrammetry data. The estimated biomass from both methods was then analyzed to determine carbon sequestration. Field survey results identified a total of 1,241 trees across 39 species. The analysis using allometric equations found a total above-ground biomass of 454,310.54 kg (454.31 tons), with a carbon sequestration of 213,525.95 kgCO2e (213.52 tCO2e). In contrast, the machine learning analysis using the Deepness technique from UAV data estimated an above-ground biomass of 463,689.13 kg (463.68 tons), with a carbon sequestration of 217,933.89 kgCO2e (217.93 tCO2e). The difference in carbon sequestration estimates between field data and UAV photogrammetry was 4.4 tons, indicating a relatively low error margin of 9.39%. Additionally, the results for the assessment data across different histogram intervals revealed a detection accuracy of tree crowns using UAV photogrammetry at 0.594, with a precision of 0.798, recall of 0.699, and F1 score of 0.745.",09 December 2024,"Vegetation, Forestry, Carbon, Biomass, Mathematical models, Autonomous aerial vehicles, Carbon sequestration, Photogrammetry, Surveys, Data models, Machine Learning, Carbon Sequestration, Aboveground Biomass, Using Unmanned Aerial Vehicles, Aboveground Carbon, Machine Learning Methods, Field Data, F1 Score, Field Survey, Unmanned Aerial Vehicles, Forest Communities, Allometric Equations, Field Of Data Analysis, Dipterocarp, Deep Learning, Deep Neural Network, Deep Models, Digital Elevation Model, Aerial Images, Sample Plots, Tree Height, Canopy Size, Tree Canopy, Diameter At Breast Height, Crown Length, Canopy Height, Canopy Height Model, Tons Of Carbon, Larger Circumference, East West Direction, Remote sensing, aerial image processing, machine learning, above ground biomass, carbon sequestrations",IEEE Access,2025-03-25T00:00:00,7.0,The research provides valuable insights into carbon sequestration using innovative methods like UAV photogrammetry and machine learning. The results show a relatively low error margin and could contribute to environmental conservation efforts.
https://ieeexplore.ieee.org/document/9399342/,Plant Disease Detection and Classification by Deep Learning—A Review,,"Deep learning is a branch of artificial intelligence. In recent years, with the advantages of automatic learning and feature extraction, it has been widely concerned by academic and industrial circles. It has been widely used in image and video processing, voice processing, and natural language processing. At the same time, it has also become a research hotspot in the field of agricultural plant protection, such as plant disease recognition and pest range assessment, etc. The application of deep learning in plant disease recognition can avoid the disadvantages caused by artificial selection of disease spot features, make plant disease feature extraction more objective, and improve the research efficiency and technology transformation speed. This review provides the research progress of deep learning technology in the field of crop leaf disease identification in recent years. In this paper, we present the current trends and challenges for the detection of plant leaf disease using deep learning and advanced imaging techniques. We hope that this work will be a valuable resource for researchers who study the detection of plant diseases and insect pests. At the same time, we also discussed some of the current challenges and problems that need to be resolved.",08 April 2021,"Diseases, Deep learning, Feature extraction, Image recognition, Plants (biology), Agriculture, Image color analysis, Deep Learning, Plant Disease, Disease Detection, Plant Disease Classification, Image Processing, Imaging Techniques, E-learning, Plant Leaves, Pest Species, Insect Pests, Deep Learning Techniques, Disease Identification, Application Of Deep Learning, Deep Learning Technology, Disease Recognition, Leaf Diseases, Branch Of Artificial Intelligence, Pest Detection, Disease Spots, Accuracy Of Model, Kinds Of Diseases, Average Accuracy, Convolutional Neural Network, Crop Diseases, Transfer Learning, Faster R-CNN, Mosaic Disease, Early Detection, Few-shot Learning, Complex Background, Deep learning, plant leaf disease detection, visualization, small sample, hyperspectral imaging",IEEE Access,2025-03-25T00:00:00,5.0,"While the abstract discusses the application of deep learning in plant disease recognition, it lacks specific details on practical implementation and impact on early-stage ventures or startups. The review serves as a general overview but does not offer concrete insights for the targeted audience."
https://ieeexplore.ieee.org/document/9712265/,DeepFake Detection for Human Face Images and Videos: A Survey,,"Techniques for creating and manipulating multimedia information have progressed to the point where they can now ensure a high degree of realism. DeepFake is a generative deep learning algorithm that creates or modifies face features in a superrealistic form, in which it is difficult to distinguish between real and fake features. This technology has greatly advanced and promotes a wide range of applications in TV channels, video game industries, and cinema, such as improving visual effects in movies, as well as a variety of criminal activities, such as misinformation generation by mimicking famous people. To identify and classify DeepFakes, research in DeepFake detection using deep neural networks (DNNs) has attracted increased interest. Basically, DeepFake is the regenerated media that is obtained by injecting or replacing some information within the DNN model. In this survey, we will summarize the DeepFake detection methods in face images and videos on the basis of their results, performance, methodology used and detection type. We will review the existing types of DeepFake creation techniques and sort them into five major categories. Generally, DeepFake models are trained on DeepFake datasets and tested with experiments. Moreover, we will summarize the available DeepFake dataset trends, focusing on their improvements. Additionally, the issue of how DeepFake detection aims to generate a generalized DeepFake detection model will be analyzed. Finally, the challenges related to DeepFake creation and detection will be discussed. We hope that the knowledge encompassed in this survey will accelerate the use of deep learning in face image and video DeepFake detection methods.",11 February 2022,"Information integrity, Videos, Deep learning, Media, Kernel, Forensics, Faces, Face Images, Human Faces, Deepfake Detection, Neural Network, Deep Learning, Detection Methods, Deep Neural Network, Facial Features, Deep Neural Network Model, Use Of Deep Learning, Video Game Industry, Model Performance, Support Vector Machine, Nonlinear Function, Feature Maps, Facial Expressions, Small Datasets, Long Short-term Memory, Biometric, Types Of Datasets, Type Of Manipulation, Fast Gradient Sign Method, Adversarial Perturbations, Fake Images, CNN Model, Passive Techniques, Kinds Of Datasets, Capsule Network, Siamese Network, Aspects Of Image, Deep learning, DeepFake, CNNs, GANs",IEEE Access,2025-03-25T00:00:00,8.0,"The abstract presents a detailed overview of DeepFake technology, its applications, detection methods, and challenges. While the topic is relevant and important, the practical value for European early-stage ventures may be limited as it mostly focuses on detection methods rather than practical implementation for startups."
