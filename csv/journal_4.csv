link,title,published_year,keywords,author_email,abstract,publication_title,created_on,score,justification
https://ieeexplore.ieee.org/document/9046805/,A Survey of Autonomous Driving: Common Practices and Emerging Technologies,25 March 2020,"Automation, Task analysis, Systems architecture, Accidents, Planning, Vehicle dynamics, Robot sensing systems, System Architecture, Automated Vehicles, Deep Learning, Convolutional Neural Network, Deep Neural Network, Urban Planning, Object Detection, Pedestrian, Point Cloud, Deep Reinforcement Learning, Object Tracking, Single Camera, Dynamic Objects, Simultaneous Localization And Mapping, Radar Sensor, Deep Q-network, Vehicular Ad Hoc Networks, 3D Object Detection, Dead Reckoning, You Only Look Once, Dynamic Vision Sensor, Rapidly-exploring Random Tree, Deep Convolutional Neural Network, 3D Detection, Semantic Segmentation, Inertial Measurement Unit, Image-based Detection, Multiple Object Tracking, Hidden Markov Model, Region Proposal Network, Autonomous vehicles, control, robotics, automation, intelligent vehicles, intelligent transportation systems",Ekim=Yurtsever: Not Found; Jacob=Lambert: Not Found; Alexander=Carballo: Not Found; Kazuya=Takeda: Not Found,"Automated driving systems (ADSs) promise a safe, comfortable and efficient driving experience. However, fatalities involving vehicles equipped with ADSs are on the rise. The full potential of ADSs cannot be realized unless the robustness of state-of-the-art is improved further. This paper discusses unsolved problems and surveys the technical aspect of automated driving. Studies regarding present challenges, high-level system architectures, emerging methodologies and core functions including localization, mapping, perception, planning, and human machine interfaces, were thoroughly reviewed. Furthermore, many state-of-the-art algorithms were implemented and compared on our own platform in a real-world driving setting. The paper concludes with an overview of available datasets and tools for ADS development.",IEEE Access,17 Mar 2025,5,"While the topic of automated driving systems is important for the future of transportation, the practical value for European early-stage ventures might be limited as the focus is more on technical aspects than on startup applications."
https://ieeexplore.ieee.org/document/8352646/,Multi-Agent Systems: A Survey,30 April 2018,"Task analysis, Multi-agent systems, Computer science, Security, Australia, Computational modeling, Decision making, Multi-agent Systems, Digital Networks, History Of Activity, Smart Grid, Task Allocation, Reference For Further Studies, Neighboring Agents, Energy Production, Cloud Computing, Number Of Agents, Group Of Agents, Virtual Machines, Wireless Sensor Networks, Expert System, Communication Overhead, Low-cost Solution, Position Of Agent, Intrusion Detection System, Vehicular Ad Hoc Networks, Cloud Providers, Mobile Agents, Decisions Of Agents, Multi-agent Reinforcement Learning, Processing Overhead, Agent Communication, Reliable Route, Software Agents, Probabilistic Neural Network, Social Networks, Fundamental Method, Multi-agent systems, survey, MAS applications, challenges",Ali=Dorri: Not Found; Salil=S. Kanhere: Not Found; Raja=Jurdak: Not Found,"Multi-agent systems (MASs) have received tremendous attention from scholars in different disciplines, including computer science and civil engineering, as a means to solve complex problems by subdividing them into smaller tasks. The individual tasks are allocated to autonomous entities, known as agents. Each agent decides on a proper action to solve the task using multiple inputs, e.g., history of actions, interactions with its neighboring agents, and its goal. The MAS has found multiple applications, including modeling complex systems, smart grids, and computer networks. Despite their wide applicability, there are still a number of challenges faced by MAS, including coordination between agents, security, and task allocation. This survey provides a comprehensive discussion of all aspects of MAS, starting from definitions, features, applications, challenges, and communications to evaluation. A classification on MAS applications and challenges is provided along with references for further studies. We expect this paper to serve as an insightful and comprehensive resource on the MAS for researchers and practitioners in the area.",IEEE Access,17 Mar 2025,6,"The discussion on multi-agent systems provides a good overview of a relevant topic with potential applications for startups. However, the challenges faced by MAS might not directly impact European early-stage ventures at the moment."
https://ieeexplore.ieee.org/document/9523565/,"Deep Learning for Anomaly Detection in Time-Series Data: Review, Analysis, and Guidelines",26 August 2021,"Anomaly detection, Time series analysis, Guidelines, Deep learning, Data models, Biological system modeling, Time factors, Deep Learning, Time Series Data, Anomaly Detection, Detection In Time Series Data, Training Strategy, Multivariate Data, Benchmark Datasets, Time Series Models, Temporal Dependencies, Unsupervised Manner, Multivariate Time Series, Guidelines For Selection, Multivariate Time Series Data, Convolutional Neural Network, Prediction Error, Long Short-term Memory, Recurrent Neural Network, Temporality, Detection Model, Generative Adversarial Networks, Gated Recurrent Unit, Automated Guided Vehicles, Anomaly Data, Temporal Convolutional Network, Incremental Update, Autoregressive Integrated Moving Average, Anomaly Detection Methods, Water Distribution, Structural Health Monitoring, Deep Learning-based Methods, Anomaly detection, deep learning, fault diagnosis, industry applications, Internet-of-Things (IoT), time series analysis",Kukjin=Choi: Not Found; Jihun=Yi: Not Found; Changhwa=Park: Not Found; Sungroh=Yoon: Not Found,"As industries become automated and connectivity technologies advance, a wide range of systems continues to generate massive amounts of data. Many approaches have been proposed to extract principal indicators from the vast sea of data to represent the entire system state. Detecting anomalies using these indicators on time prevent potential accidents and economic losses. Anomaly detection in multivariate time series data poses a particular challenge because it requires simultaneous consideration of temporal dependencies and relationships between variables. Recent deep learning-based works have made impressive progress in this field. They are highly capable of learning representations of the large-scaled sequences in an unsupervised manner and identifying anomalies from the data. However, most of them are highly specific to the individual use case and thus require domain knowledge for appropriate deployment. This review provides a background on anomaly detection in time-series data and reviews the latest applications in the real world. Also, we comparatively analyze state-of-the-art deep-anomaly-detection models for time series with several benchmark datasets. Finally, we offer guidelines for appropriate model selection and training strategy for deep learning-based time series anomaly detection.",IEEE Access,17 Mar 2025,7,The review on anomaly detection in time-series data using deep learning has practical implications for startups dealing with vast amounts of data. The guidelines provided can be valuable for European early-stage ventures in implementing anomaly detection.
https://ieeexplore.ieee.org/document/10098596/,"Object Detection Using Deep Learning, CNNs and Vision Transformers: A Review",10 April 2023,"Object detection, Deep learning, Transformers, Feature extraction, Detectors, Convolutional neural networks, Visualization, Neural networks, Deep Learning, Convolutional Neural Network, Object Detection, Deep Convolutional Neural Network, Vision Transformer, Convolutional Network, Image Object, Detection Model, Object Detection Model, Object Detection Network, Loss Function, Convolutional Layers, Feature Maps, Negative Samples, Intersection Over Union, Bounding Box, Entire Image, Fully-connected Layer, Convolutional Neural Network Architecture, Region Proposal, You Only Look Once, Single Shot Multibox Detector, Anchor Boxes, MS COCO Dataset, Feature Pyramid Network, Object Detection Task, Region Proposal Network, Predicted Bounding Box, 3D Object Detection, Multiple Convolutional Layers, Object detection, deep learning, review, convolutional neural networks, transformers, survey, neural networks",Ayoub=Benali Amjoud: Not Found; Mustapha=Amrouch: Not Found,"Detecting objects remains one of computer vision and image understanding applications’ most fundamental and challenging aspects. Significant advances in object detection have been achieved through improved object representation and the use of deep neural network models. This paper examines more closely how object detection has evolved in the era of deep learning over the past years. We present a literature review on various state-of-the-art object detection algorithms and the underlying concepts behind these methods. We classify these methods into three main groups: anchor-based, anchor-free, and transformer-based detectors. Those approaches are distinct in the way they identify objects in the image. We discuss the insights behind these algorithms and experimental analyses to compare quality metrics, speed/accuracy tradeoffs, and training methodologies. The survey compares the major convolutional neural networks for object detection. It also covers the strengths and limitations of each object detector model and draws significant conclusions. We provide simple graphical illustrations summarising the development of object detection methods under deep learning. Finally, we identify where future research will be conducted.",IEEE Access,17 Mar 2025,8,Object detection using deep learning has significant practical value for startups working on computer vision applications. The comparison of state-of-the-art algorithms and insights can directly impact European early-stage ventures in this field.
https://ieeexplore.ieee.org/document/9142202/,Data Security and Privacy Protection for Cloud Storage: A Survey,16 July 2020,"Cloud computing, Encryption, Data privacy, Secure storage, Memory, Cloud Computing, Data Privacy, Data Security, Privacy Protection, Security Protection, Data Privacy Protection, Data Storage, Internet Of Things, Massive Data, Privacy Issues, Security Issues, Individual Users, Information Leakage, Smart City, Encrypted Data, Protection Methods, Digital Economy, Cloud Applications, Data Security Issues, Data Privacy Issues, Attribute-based Encryption, Secret Key, Encrypted File, Cloud Data, Public Key, Data Owner, Public Cloud, Encryption Scheme, Decryption Key, Access Control, Cloud storage, data security, cryptography, access control, privacy protection",Pan=Yang: Not Found; Naixue=Xiong: Not Found; Jingli=Ren: Not Found,"The new development trends including Internet of Things (IoT), smart city, enterprises digital transformation and world’s digital economy are at the top of the tide. The continuous growth of data storage pressure drives the rapid development of the entire storage market on account of massive data generated. By providing data storage and management, cloud storage system becomes an indispensable part of the new era. Currently, the governments, enterprises and individual users are actively migrating their data to the cloud. Such a huge amount of data can create magnanimous wealth. However, this increases the possible risk, for instance, unauthorized access, data leakage, sensitive information disclosure and privacy disclosure. Although there are some studies on data security and privacy protection, there is still a lack of systematic surveys on the subject in cloud storage system. In this paper, we make a comprehensive review of the literatures on data security and privacy issues, data encryption technology, and applicable countermeasures in cloud storage system. Specifically, we first make an overview of cloud storage, including definition, classification, architecture and applications. Secondly, we give a detailed analysis on challenges and requirements of data security and privacy protection in cloud storage system. Thirdly, data encryption technologies and protection methods are summarized. Finally, we discuss several open research topics of data security for cloud storage.",IEEE Access,17 Mar 2025,4,"While data security and privacy in cloud storage is crucial, the focus of this paper might not have a direct impact on European early-stage ventures, as the survey covers a broad topic that might not be immediately applicable to startups."
https://ieeexplore.ieee.org/document/10319418/,Artificial Intelligence in Accounting and Finance: Challenges and Opportunities,16 November 2023,"Artificial intelligence, Finance, Investment, Forecasting, Business, Decision making, Pricing, Machine learning, Computational modeling, Artificial Intelligence, Financial Problems, Artificial Intelligence Applications, Artificial Intelligence Technology, Artificial Intelligence Techniques, Accounting Research, Artificial Intelligence Methods, Traditional Finance, Traditional Accounting, Neural Network, Deep Learning, Support Vector Machine, Artificial Neural Network, Financial Statements, Multi-objective Optimization, Cash Flow, Textual Information, Stock Price, Deep Reinforcement Learning, Optimal Portfolio, Financial Fraud, Fraud Detection, Analysis Of Statements, GARCH Model, Capital Structure, Money Laundering, Financial Crime, Corporate Finance, Option Pricing, Financial Measures, Artificial intelligence, computational finance, accounting, machine learning, computational model",Ziwei=Yi: Not Found; Xinwei=Cao: Not Found; Zuyan=Chen: Not Found; Shuai=Li: Not Found,"The rapid expansion of artificial intelligence (AI) technologies presents novel technical solutions to traditional accounting and finance problems. Despite this, scholars in accounting and finance frequently encounter difficulties navigating the extensive and intricate domain knowledge of AI and its continuously evolving literature. To address this gap, this paper conducts a qualitative survey of the implementation of AI methods in accounting and finance. The paper is structured into four sections. Firstly, we examine the conventional accounting and finance issues and their requirement for AI techniques. Secondly, to inform accounting and finance researchers about the potential of AI, we present broad categories of AI applications. Thirdly, we explore recent research on AI solutions to conventional problems. Finally, we highlight emerging trends and possible research directions.",IEEE Access,17 Mar 2025,7,"The paper addresses a gap in knowledge by conducting a survey on the implementation of AI in accounting and finance, providing insights and research directions for scholars in the field."
https://ieeexplore.ieee.org/document/9721302/,Deepfake Detection: A Systematic Literature Review,24 February 2022,"Videos, Information integrity, Measurement, Faces, Deep learning, Computational modeling, Web pages, Systematic Review, Deepfake Detection, Machine Learning, Deep Learning, Learning-based Methods, Deep Learning-based Methods, Machine Learning-based Methods, Learning Models, Convolutional Neural Network, Support Vector Machine, Deep Models, Deep Learning Models, Detection Techniques, Recurrent Neural Network, Generative Adversarial Networks, Convolutional Neural Network Model, Spatiotemporal Characteristics, Deep Neural Network Model, Learning-based Models, Latent Features, Deep Learning-based Models, Multiple Instance Learning, Head Pose, Maximum Mean Discrepancy, Convolutional Recurrent Neural Network, Blockchain Technology, Public Blockchain, Recurrent Neural Network Model, Video Content, Video Frames, Deepfake detection, video or image manipulation, digital media forensics, systematic literature review",Md=Shohel Rana: Not Found; Mohammad=Nur Nobi: Not Found; Beddhu=Murali: Not Found; Andrew=H. Sung: Not Found,"Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.",IEEE Access,17 Mar 2025,9,"The paper focuses on a critical issue of Deepfake detection, summarizing relevant articles and evaluating different techniques, which can have a significant impact on media and society."
https://ieeexplore.ieee.org/document/9069875/,Artificial Intelligence in Education: A Review,17 April 2020,"Education, Technological innovation, Learning (artificial intelligence), Microcomputers, Robots, Artificial Intelligence, Artificial Intelligence In Education, Intelligence In Education, Cognitive Function, Machine Learning, Scope Of This Study, Education System, Education Institutions, Learning Experiences, Intelligent Systems, Cognitive Learning, Grade Students, Learning Capability, Quality Of Learning, Artificial Intelligence Applications, Web-based System, Use Of Robots, Adaptive Capabilities, Humanoid Robot, Artificial Intelligence Systems, Development Of Artificial Intelligence, Web-based Platform, Use Of Artificial Intelligence, Intelligent Tutoring Systems, Administrative Tasks, Integration Of Artificial Intelligence, Education Sector, Online Learning, Personal Content, Education, artificial intelligence, leaner",Lijia=Chen: Not Found; Pingping=Chen: Not Found; Zhijian=Lin: Not Found,"The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors' duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students' assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students' needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning.",IEEE Access,17 Mar 2025,6,"The study assesses the impact of AI in education, highlighting the various applications of AI in administration, instruction, and learning, contributing to the enhancement of educational processes."
https://ieeexplore.ieee.org/document/9773102/,Zero Trust Architecture (ZTA): A Comprehensive Survey,12 May 2022,"Access control, Authentication, Computer architecture, NIST, Encryption, Critical infrastructure, Automation, Zero Trust Architecture, Access Control, Critical Infrastructure, Authentication Mechanism, Authentication Techniques, Contextual Information, Internet Of Things, Quantum Computing, Internet Of Things Devices, Public Key, Policy Enforcement, Internet Of Things Systems, Access Request, Internet Of Things Networks, Smart Contracts, Security Control, User Authentication, Dynamic Policy, Authentication Scheme, Virtual Network Functions, Physical Unclonable Functions, Blockchain, Mutual Authentication, Access Control Mechanism, Public Key Infrastructure, Identity Management, Static Random Access Memory, Smart Home, Cyber Attacks, Zero trust architecture (ZTA), access control, authentication, micro-segmentation, software-defined parameter (SDP)",Naeem=Firdous Syed: Not Found; Syed=W. Shah: Not Found; Arash=Shaghaghi: Not Found; Adnan=Anwar: Not Found; Zubair=Baig: Not Found; Robin=Doss: Not Found,"We present a detailed survey of the Zero Trust (ZT) security paradigm which has a growing number of advocates in the critical infrastructure risk management space. The article employs a descriptive approach to present the fundamental tenets of ZT and provides a review of numerous potential options available for successful realization of this paradigm. We describe the role of authentication and access control in Zero Trust Architectures (ZTA) and present an in-depth discussion of state-of-the-art techniques for authentication and access control in different scenarios. Furthermore, we comprehensively discuss the conventional approaches to encryption, micro-segmentation, and security automation available for instantiating a ZTA. The article also details various challenges associated with contemporary authentication mechanisms, access control schemes, trust and risk computation techniques, micro-segmentation approaches, and Software-Defined Perimeter, that can impact the implementation of ZT in its true sense. Based upon our analysis, we finally pinpoint the potential future research directions for successful realization of ZT in critical infrastructures.",IEEE Access,17 Mar 2025,8,"The article presents a detailed survey of the Zero Trust security paradigm, discussing authentication, access control, encryption, micro-segmentation, and security automation, which can greatly benefit critical infrastructure risk management."
https://ieeexplore.ieee.org/document/10521640/,"Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers",06 May 2024,"Decoding, Mathematical models, Task analysis, Vectors, Codes, Transformers, Neural networks, Generative AI, Generative adversarial networks, Artificial intelligence, Chatbots, Encoding, Generative Adversarial Networks, Diffusion Model, Generative Pretrained Transformer, Artificial Intelligence, Misinformation, Transformer Model, Variational Autoencoder, Code Generation, Privacy Breaches, Text Generation, Music Composition, Neural Network, Deep Learning, Convolutional Neural Network, Denoising, Computer Vision, Long Short-term Memory, Attention Mechanism, Reversible Process, Real Samples, Stochastic Differential Equations, Input Text, Wasserstein Generative Adversarial Networks, Feed-forward Network, Chatbot, StyleGAN, Industrial Revolution, Latent Vector, Cyber Operations, Vanishing Gradient, Generative AI, GPT, bard, ChatGPT, diffusion model, transformer, GAN, autoencoder, artificial intelligence",Staphord=Bengesi: Not Found; Hoda=El-Sayed: Not Found; MD=Kamruzzaman Sarker: Not Found; Yao=Houkpati: Not Found; John=Irungu: Not Found; Timothy=Oladunni: Not Found,"The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.",IEEE Access,17 Mar 2025,5,"The launch of ChatGPT and other GAI tools is a significant development in the AI field, but the abstract mainly highlights the capabilities and challenges without offering specific practical implications for startups."
https://ieeexplore.ieee.org/document/10102467/,"Review of Electric Vehicle Charging Technologies, Standards, Architectures, and Converter Configurations",14 April 2023,"Electric vehicle charging, Batteries, Power grids, Charging stations, Costs, Reliability, Vehicle-to-grid, Electric Vehicles, Electric Vehicles Charging, Charging Technology, Converter Configuration, Control Strategy, International Standards, State Of Charge, Power Grid, Renewable Energy Sources, Power Conversion, Future Trends, Charging System, Dcdc Converter, Utility Grid, Ancillary Services, Converter Topology, Electric Vehicles Battery, Grid Code, Acdc Converter, High Power, Battery Electric Vehicles, Fast Charging, Multilevel Converter, Plug-in Hybrid Electric Vehicles, Buck Converter, Ultrafast Charge, AC Power, Internal Combustion Engine Vehicles, Hybrid Electric Vehicles, Plug-in Electric Vehicles, Electric vehicle, charging configuration, grid integration, international standards, onboard and offboard charger, power converters",Sithara=S. G. Acharige: Not Found; Md.=Enamul Haque: Not Found; Mohammad=Taufiqul Arif: Not Found; Nasser=Hosseinzadeh: Not Found; Kazi=N. Hasan: Not Found; Aman=Maung Than Oo: Not Found,"Electric Vehicles (EVs) are projected to be one of the major contributors to energy transition in global transportation due to their rapid expansion. High-level EVs integration into the electricity grid will introduce many challenges for the power grid planning, operation, stability, standards, and safety. Therefore, the wide-scale adoption of EVs imposes research and development of charging systems and EV supply equipment (EVSE) to achieve expected charging solutions for EV batteries as well as to improve ancillary services. Analysis of the status of EV charging technologies is important to accelerate EV adoption with advanced control strategies to discover a remedial solution for negative impacts and to enhance desired charging efficiency and grid support. This paper presents a comprehensive review of EV charging technologies, international standards, the architecture of EV charging stations, and the power converter configurations of EV charging systems. The charging systems require a dedicated converter topology, a control strategy, compatibility with standards, and grid codes for charging and discharging to ensure optimum operation and enhance grid support. An overview of different charging systems in terms of onboard and off-board chargers, AC-DC and DC-DC converter configuration, and AC and DC-based charging station architectures are evaluated. In addition, recent charging systems which are integrated with renewable energy sources are presented to identify the power train of modern charging stations. Finally, future trends and challenges in EV charging and grid integration issues are summarized as the future direction of the research.",IEEE Access,17 Mar 2025,7,"The abstract discusses the challenges and advancements in EV charging technologies, which are crucial for the energy transition. It addresses a key aspect of sustainable transportation and grid integration."
https://ieeexplore.ieee.org/document/10354308/,Deepfake Generation and Detection: Case Study and Challenges,12 December 2023,"Deepfakes, Generative adversarial networks, Feature extraction, Artificial intelligence, Convolutional neural networks, Surveys, Fake news, Deepfake Generation, Social Media, Deep Learning Models, Generative Adversarial Networks, Convolutional Neural Network, Deep Neural Network, Convolutional Layers, Long Short-term Memory, Recurrent Neural Network, Detection Model, Ensemble Model, Fake News, Video Content, Dropout Layer, Original Content, Artificial Intelligence Models, Contrastive Loss, Scale-invariant Feature Transform, Type Of Manipulation, Generative Adversarial Networks Model, Audio Content, Real Content, Speeded Up Robust Features, Capsule Network, Residual Block, Open Challenges, Fake Images, Loss Function, Gaussian Mixture Model, Pooling Layer, Artificial intelligence, Deepfake generation, Deepfake detection, fake content, generative adversarial networks",Yogesh=Patel: Not Found; Sudeep=Tanwar: Not Found; Rajesh=Gupta: Not Found; Pronaya=Bhattacharya: Not Found; Innocent=Ewean Davidson: Not Found; Royi=Nyameko: Not Found,"In smart communities, social media allowed users easy access to multimedia content. With recent advancements in computer vision and natural language processing, machine learning (ML), and deep learning (DL) models have evolved. With advancements in generative adversarial networks (GAN), it has become possible to create fake images/audio/and video streams of a person or use some person’s audio and visual details to fit other environments. Thus, deepfakes are specifically used to disseminate fake information and propaganda on social circles that tarnish the reputation of an individual or an organization. Recently, many surveys have focused on generating and detecting deepfake images, audio, and video streams. Existing surveys are mostly aligned toward detecting deepfake contents, but the generation process is not suitably discussed. To address the survey gap, the paper proposes a comprehensive review of deepfake generation and detection and the different ML/DL approaches to synthesize deepfake contents. We discuss a comparative analysis of deepfake models and public datasets present for deepfake detection purposes. We discuss the implementation challenges and future research directions regarding optimized approaches and models. A unique case study, IBMM is discussed, which presents a multi-modal overview of deepfake detection. The proposed survey would benefit researchers, industry, and academia to study deepfake generation and subsequent detection schemes.",IEEE Access,17 Mar 2025,6,"The abstract highlights the issue of deepfakes and their impact on social circles. While the technology is concerning, its direct impact on European early-stage ventures may not be as significant as other topics."
https://ieeexplore.ieee.org/document/10433480/,"A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",13 February 2024,"Cognition, Artificial intelligence, Transformers, Training, Taxonomy, Task analysis, Surveys, Natural language processing, Question answering (information retrieval), Information analysis, Linguistics, Language Model, Open Issues, Large Language Models, Business, Natural Language, Language Processing, Review Paper, Question Answering, Natural Language Processing Tasks, Text Generation, Neural Network, Deep Neural Network, Specific Tasks, Recurrent Neural Network, Text Data, Input Sequence, Range Of Tasks, Transformer Model, Deep Neural Network Model, Sentiment Analysis, Tokenized, Transformer Architecture, Few-shot Learning, Video Summarization, Neural Language Models, Zero-shot, Chatbot, Positional Encoding, Output Embedding, Large language models (LLM), natural language processing (NLP), artificial intelligence, transformer, pre-trained models, taxonomy, application",Mohaimenul=Azam Khan Raiaan: Not Found; Md.=Saddam Hossain Mukta: Not Found; Kaniz=Fatema: Not Found; Nur=Mohammad Fahad: Not Found; Sadman=Sakib: Not Found; Most=Marufatul Jannat Mim: Not Found,"Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolut...",IEEE Access,17 Mar 2025,9,Large Language Models (LLMs) are important in various NLP tasks with wide-ranging applications. Understanding their impacts and challenges can benefit startups in developing AI-driven solutions.
https://ieeexplore.ieee.org/document/8721134/,"Towards Sustainable Energy: A Systematic Review of Renewable Energy Sources, Technologies, and Public Opinions",23 May 2019,"Fossil fuels, Systematics, Information technology, Computer science, Wind, Biomass, Systematic Review, Energy Source, Renewable Energy, Public Opinion, Energy Development, Renewable Energy Sources, Renewable Energy Technologies, Fossil Fuels, Renewable Sources, Power Generation, Energy Deficit, Technology Acceptance, Renewable Energy Resources, Lack Of Public Awareness, Greenhouse Gas, Thermal Energy, Energy Use, Solar Energy, Wind Power, Solar System, Solar Heating, Wind Farm, Use Of Renewable Energy, Analysis Rules, Ocean Energy, Renewable Energy Projects, Energy Security, Solar Thermal, Offshore Wind, Solar Panels, Energy policies, public opinion, renewable energy sources (RES), renewable energy technology (RET), solar energy, wind energy",Atika=Qazi: Not Found; Fayaz=Hussain: Not Found; Nasrudin=ABD. Rahim: Not Found; Glenn=Hardaker: Not Found; Daniyal=Alghazzawi: Not Found; Khaled=Shaban: Not Found,"The use of renewable energy resources, such as solar, wind, and biomass will not diminish their availability. Sunlight being a constant source of energy is used to meet the ever-increasing energy need. This review discusses the world's energy needs, renewable energy technologies for domestic use, and highlights public opinions on renewable energy. A systematic review of the literature was conducted from 2009 to 2018. During this process, more than 300 articles were classified and 42 papers were filtered for critical review. The literature analysis showed that despite serious efforts at all levels to reduce reliance on fossil fuels by promoting renewable energy as its alternative, fossil fuels continue to contribute 73.5% to the worldwide electricity production in 2017. Conversely, renewable sources contributed only 26.5%. Furthermore, this study highlights that the lack of public awareness is a major barrier to the acceptance of renewable energy technologies. The results of this study show that worldwide energy crises can be managed by integrating renewable energy sources in the power generation. Moreover, in order to facilitate the development of renewable energy technologies, this systematic review has highlighted the importance of public opinion and performed a real-time analysis of public tweets. This example of tweet analysis is a relatively novel initiative in a review study that will seek to direct the attention of future researchers and policymakers toward public opinion and recommend the implications to both academia and industries.",IEEE Access,17 Mar 2025,5,"The abstract addresses renewable energy technologies and public opinions but lacks a direct focus on early-stage ventures. While renewable energy is important, the practical impact on startups is not explicitly discussed."
https://ieeexplore.ieee.org/document/10638538/,Does ChatGPT Help Novice Programmers Write Better Code? Results From Static Code Analysis,19 August 2024,"Codes, Chatbots, Programming, Programming profession, Education, Complexity theory, Java, Novice Programmers, Treatment Groups, Prior Experience, Source Code, Educational Contexts, Static Analysis, Object-oriented, Students In Courses, Student Understanding, Cognitive Complexity, Introductory Course, Rule Violations, Software Quality, Introduction Of Programs, Java Programming, Part-time Students, Complexity Metrics, Non-parametric, Critical Thinking, Group Of Students, Significant Differences In Adherence, Low Complexity, Differences In Adherence, Code Generation, Complexity Of Students, Coding Efficiency, Stream Of Research, Chatbot, Programming Tasks, Alternative Hypothesis H1, Programming education, ChatGPT large language models, static code analysis",Philipp=Haindl: Not Found; Gerald=Weinberger: Not Found,"In the realm of AI-enhanced programming education, there is growing interest in using such tools to help students understand good coding principles. This study investigates the impact of ChatGPT on code quality among part-time undergraduate students in introductory Java programming courses, who lack prior Java experience. The source code of 16 students from the control group (without ChatGPT) and 22 students from the treatment group (with ChatGPT) who completed identical programming exercises focused on coding conventions was analyzed. Static code analysis tools assessed adherence to a common coding convention ruleset and calculated cyclomatic and cognitive complexity metrics. The comparative analysis shows that the ChatGPT-assisted group significantly improved code quality, with fewer rule violations and reduced cyclomatic and cognitive complexities. The treatment group adhered more closely to coding standards and produced less complex code. Violations primarily occurred in line length, final parameters, and the extensibility of object-oriented programming (OOP). These findings suggest that ChatGPT can be beneficial in programming education by helping students write cleaner, less complex code and adhere to coding conventions. However, the study’s limitations, such as the small sample size and novice status of participants, call for further research with larger, more diverse populations and different educational contexts.",IEEE Access,17 Mar 2025,6,"The study evaluates the impact of ChatGPT on code quality in programming education. While relevant for AI-enhanced education, the direct impact on early-stage ventures may be limited."
https://ieeexplore.ieee.org/document/10604830/,Explainable Artificial Intelligence for Autonomous Driving: A Comprehensive Overview and Field Guide for Future Research Directions,19 July 2024,"Visualization, Autonomous vehicles, Safety, Artificial intelligence, Accidents, Regulation, Standards, Autonomous driving, Explainable AI, Intelligence, Autonomous Vehicles, Explainable Artificial Intelligence, Research And Development, Conceptual Framework, Artificial Intelligence Techniques, Artificial Intelligence Approaches, Real-time Decision, Safe Decisions, User Study, Work Context, Semantic Segmentation, General Data Protection Regulation, Lead Time, Self-driving, Traffic Safety, Learning Software, Automated Vehicles, Regulatory Compliance, Road Vehicles, Imitation Learning, Human Drivers, Need For Explanation, Vehicular Ad Hoc Networks, Trolley Problem, Visual Question Answering, Visual Explanation, Emergent Need, Traffic Rules, Road Users, Autonomous driving, explainable artificial intelligence, intelligent transportation systems, regulatory compliance, safety",Shahin=Atakishiyev: Not Found; Mohammad=Salameh: Not Found; Hengshuai=Yao: Not Found; Randy=Goebel: Not Found,"Autonomous driving has achieved significant milestones in research and development over the last two decades. There is increasing interest in the field as the deployment of autonomous vehicles (AVs) promises safer and more ecologically friendly transportation systems. With the rapid progress in computationally powerful artificial intelligence (AI) techniques, AVs can sense their environment with high precision, make safe real-time decisions, and operate reliably without human intervention. However, intelligent decision-making in such vehicles is not generally understandable by humans in the current state of the art, and such deficiency hinders this technology from being socially acceptable. Hence, aside from making safe real-time decisions, AVs must also explain their AI-guided decision-making process in order to be regulatory-compliant across many jurisdictions. Our study sheds comprehensive light on the development of explainable artificial intelligence (XAI) approaches for AVs. In particular, we make the following contributions. First, we provide a thorough overview of the state-of-the-art and emerging approaches for XAI-based autonomous driving. We then propose a conceptual framework considering the essential elements for explainable end-to-end autonomous driving. Finally, we present XAI-based prospective directions and emerging paradigms for future directions that hold promise for enhancing transparency, trustworthiness, and societal acceptance of AVs.",IEEE Access,17 Mar 2025,9,"The development of explainable AI approaches for autonomous vehicles is crucial for societal acceptance and regulatory compliance, impacting the future of transportation systems."
https://ieeexplore.ieee.org/document/8694781/citations?tabFilter=patents#anchor-patent-citations,Review of Deep Learning Algorithms and Architectures,22 April 2019,"Deep learning, Training, Computer architecture, Feature extraction, Recurrent neural networks, Feedforward neural networks, Deep Learning, Learning Algorithms, Neural Network, Training Data, Deep Network, Deep Neural Network, Training Time, Recurrent Neural Network, Autoencoder, Speech Recognition, Training Algorithm, Variational Autoencoder, Units In Layer, Deep Residual Network, Gradient Descent, Convolutional Layers, Sigmoid Function, Hidden Layer, Unsupervised Learning, Long Short-term Memory, Restricted Boltzmann Machine, Feed-forward Network, Deep Reinforcement Learning, Implementation Of Neural Networks, Extreme Learning Machine, Unlabeled Data, Image Recognition, Deep Belief Network, MNIST Dataset, Proper Orthogonal Decomposition, Machine learning algorithm, optimization, artificial intelligence, deep neural network architectures, convolution neural network, backpropagation, supervised and unsupervised learning",Ajay=Shrestha: Not Found; Ausif=Mahmood: Not Found,"Deep learning (DL) is playing an increasingly important role in our lives. It has already made a huge impact in areas, such as cancer diagnosis, precision medicine, self-driving cars, predictive forecasting, and speech recognition. The painstakingly handcrafted feature extractors used in traditional learning, classification, and pattern recognition systems are not scalable for large-sized data sets. In many cases, depending on the problem complexity, DL can also overcome the limitations of earlier shallow networks that prevented efficient training and abstractions of hierarchical representations of multi-dimensional training data. Deep neural network (DNN) uses multiple (deep) layers of units with highly optimized algorithms and architectures. This paper reviews several optimization methods to improve the accuracy of the training and to reduce training time. We delve into the math behind training algorithms used in recent deep networks. We describe current shortcomings, enhancements, and implementations. The review also covers different types of deep architectures, such as deep convolution networks, deep residual networks, recurrent neural networks, reinforcement learning, variational autoencoders, and others.",IEEE Access,17 Mar 2025,7,The review of optimization methods for deep learning networks is valuable for improving accuracy and reducing training time across various applications.
https://ieeexplore.ieee.org/document/10695056/,A Comprehensive Review on Generative AI for Education,26 September 2024,"Artificial intelligence, Education, Computational modeling, Solid modeling, Videos, Three-dimensional displays, Metaverse, Learning systems, Generative AI, Learning Experiences, Generative Adversarial Networks, Individual Students, Adaptive Learning, Teaching Methods, Field Of Education, Language Teaching, Learning Styles, Early Education, Language Model, Artificial Intelligence Technology, Artificial Intelligence Algorithms, Content Creation, Artificial Intelligence Models, Latent Dirichlet Allocation, Student Confidence, Privacy Breaches, Text Generation, Entrepreneurship Education, Video Simulation, Deepfake, Educational Endeavors, Learning Pace, Immersive Learning, Training Data, Model Bias, Skills Of Students, Language Learning, Interactive, Educational Contexts, GAI, education, applications, case studies, challenges, metaverse",Uday=Mittal: Not Found; Siva=Sai: Not Found; Vinay=Chamola: Not Found; Devika=Sangwan: Not Found,"Artificial Intelligence (AI) has immense potential for personalized learning experiences, content generation, and vivid educational support. This paper delves into generative AI (GAI) and its potential applications within GAI, specifically mentioning generative adversarial networks (GANs). The article delves into the transformative impact of GAI in education, underscoring its expertise in creating diverse instructional materials, from texts and images to videos. Adaptive learning, one of the chief abilities of GAI, has been highlighted, emphasizing its capability to select content customized to individual student profiles, learning habits, and preferences. The paper further explores the fusion of GAI with innovative education systems, highlighting how these models can mimic conversational interfaces, promoting an engaging, customized learning journey. The exploration doesn’t stop at the benefits; it delves into challenges like ensuring data privacy, mitigating biases, and ensuring accountability in AI-driven educational systems. The conclusion contemplates the potential limitations and assurances of embedding GAI within educational setups. An appeal has been made for more profound research and enhancement of AI’s educational function. The intersection of pedagogical insights and effective human-AI collaboration is pivotal in this journey. This paper serves as a compass, guiding educators, researchers, and policymakers toward harnessing GAI’s potential to sculpt enriched, immersive educational landscapes.",IEEE Access,17 Mar 2025,8,The exploration of generative AI in education and the challenges it poses offers insights into the potential of personalized learning experiences and the importance of human-AI collaboration.
https://ieeexplore.ieee.org/document/9439459/,Machine Learning for Anomaly Detection: A Systematic Review,24 May 2021,"Anomaly detection, Machine learning, Intrusion detection, Systematics, Training, Bibliographies, Analytical models, Systematic Review, Machine Learning, Anomaly Detection, Machine Learning Models, Research Articles, Performance Metrics, Machine Learning Techniques, Research Papers, Model Metrics, Learning Algorithms, Training Dataset, Search Terms, Machine Learning Methods, Data Mining, Unsupervised Learning, Detection Techniques, Filtering Process, Hybrid Model, False Alarm Rate, Intrusion Detection, Percentage Of Papers, Anomaly Detection Methods, Intrusion Detection System, Fraud Detection, Real-life Datasets, Contextual Dimensions, Semi-supervised Learning, Performance Of Machine Learning Models, Deep Learning Techniques, Anomaly detection, machine learning, security and privacy protection",Ali=Bou Nassif: Not Found; Manar=Abu Talib: Not Found; Qassim=Nasir: Not Found; Fatima=Mohamad Dakalbab: Not Found,"Anomaly detection has been used for decades to identify and extract anomalous components from data. Many techniques have been used to detect anomalies. One of the increasingly significant techniques is Machine Learning (ML), which plays an important role in this area. In this research paper, we conduct a Systematic Literature Review (SLR) which analyzes ML models that detect anomalies in their application. Our review analyzes the models from four perspectives; the applications of anomaly detection, ML techniques, performance metrics for ML models, and the classification of anomaly detection. In our review, we have identified 290 research articles, written from 2000-2020, that discuss ML techniques for anomaly detection. After analyzing the selected research articles, we present 43 different applications of anomaly detection found in the selected research articles. Moreover, we identify 29 distinct ML models used in the identification of anomalies. Finally, we present 22 different datasets that are applied in experiments on anomaly detection, as well as many other general datasets. In addition, we observe that unsupervised anomaly detection has been adopted by researchers more than other classification anomaly detection systems. Detection of anomalies using ML models is a promising area of research, and there are a lot of ML models that have been implemented by researchers. Therefore, we provide researchers with recommendations and guidelines based on this review.",IEEE Access,17 Mar 2025,6,"The systematic literature review on anomaly detection using ML models provides valuable insights, but the practical implications for European early-stage ventures may vary."
https://ieeexplore.ieee.org/document/10500411/,"GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions",15 April 2024,"Natural language processing, Solid modeling, Artificial intelligence, Surveys, Task analysis, Reviews, Transformers, Enabling Technologies, Generative Pretrained Transformer, Natural Language, Transformer Architecture, Social Media, Marketing, Training Data, Large Amount Of Data, Cloud Computing, Customer Service, Language Model, Sentiment Analysis, Text Classification, Content Creation, Customer Experience, Customer Orientation, Text Generation, Virtual Assistant, AI Models, Chatbot, NLP Tasks, AI Techniques, Data Analysis Capabilities, Business, Intelligent Tutoring Systems, Real-time Data, Data Privacy, Edge Devices, Generative pre-trained transformer, natural language processing, artificial intelligence",Gokul=Yenduri: Not Found; M.=Ramalingam: Not Found; G.=Chemmalar Selvi: Not Found; Y.=Supriya: Not Found; Gautam=Srivastava: Not Found; Praveen=Kumar Reddy Maddikunta: Not Found,"The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.",IEEE Access,17 Mar 2025,7,The detailed overview of Generative Pre-trained Transformer (GPT) and its impact on natural language processing tasks has significance for startups working in language-related applications.
https://ieeexplore.ieee.org/document/10409290/,CIFAKE: Image Classification and Explainable Identification of AI-Generated Synthetic Images,19 January 2024,"Artificial intelligence, Visualization, Data models, Image recognition, Computational modeling, Synthetic data, Image classification, Image Classification, Synthetic Images, Neural Network, Convolutional Network, Convolutional Neural Network, Computer Vision, Binary Classification, Authentication, Hyperparameter Tuning, Image Generation, Binary Classification Problem, Message Authentication, Explainable Artificial Intelligence, Artificial Neural Network, Photography, F1 Score, Feature Maps, Precision And Recall, Human Eye, Diffusion Model, Synthetic Generation, Valuable Resource For Research, Trustworthiness Of The Data, Image Collection, Fake News, Matter Of Seconds, Depth Of Field, Photo-realistic Images, Human Faces, Validation Metrics, AI-generated images, generative AI, image classification, latent diffusion",Jordan=J. Bird: Not Found; Ahmad=Lotfi: Not Found,"Recent advances in synthetic data have enabled the generation of images with such high quality that human beings cannot distinguish the difference between real-life photographs and Artificial Intelligence (AI) generated images. Given the critical necessity of data reliability and authentication, this article proposes to enhance our ability to recognise AI-generated images through computer vision. Initially, a synthetic dataset is generated that mirrors the ten classes of the already available CIFAR-10 dataset with latent diffusion, providing a contrasting set of images for comparison to real photographs. The model is capable of generating complex visual attributes, such as photorealistic reflections in water. The two sets of data present as a binary classification problem with regard to whether the photograph is real or generated by AI. This study then proposes the use of a Convolutional Neural Network (CNN) to classify the images into two categories; Real or Fake. Following hyperparameter tuning and the training of 36 individual network topologies, the optimal approach could correctly classify the images with 92.98% accuracy. Finally, this study implements explainable AI via Gradient Class Activation Mapping to explore which features within the images are useful for classification. Interpretation reveals interesting concepts within the image, in particular, noting that the actual entity itself does not hold useful information for classification; instead, the model focuses on small visual imperfections in the background of the images. The complete dataset engineered for this study, referred to as the CIFAKE dataset, is made publicly available to the research community for future work.",IEEE Access,17 Mar 2025,8,"This abstract presents a significant advancement in AI-generated image recognition, which can have practical applications in various industries, including startups working with image processing technologies."
https://ieeexplore.ieee.org/document/9774372/,"A Review of BLDC Motor: State of Art, Advanced Control Techniques, and Applications",13 May 2022,"Induction motors, Brushless DC motors, Hysteresis motors, Electromagnetic interference, Industries, Rotors, Torque measurement, Control Techniques, Brushless DC, Brushless Direct Current Motor, Control Strategy, Vector Control, Motor Control, Direct Control, Fault-tolerant, Input Voltage, Electromagnetic Interference, Closed-loop Control, Intelligent Control, Torque Control, Induction Motor, Fault-tolerant Control, Acoustic Noise, Torque Ripple, Motor Type, Field-oriented Control, Fault-tolerant Capability, Back Electromotive Force, Pulsewidth Modulation Scheme, Magnetic Rotor, Pulse Width, Electric Vehicles, Flux Linkage, Rotor Position, Voltage Vector, Permanent Magnet, Three-phase Motor, BLDC motor, torque ripple, current shaping techniques, controlling input voltage, direct torque control, drive-inverter topology, field orientation control, motor design, fault tolerance control, electromagnetic interference reduction",Deepak=Mohanraj: Not Found; Ranjeev=Aruldavid: Not Found; Rajesh=Verma: Not Found; K.=Sathiyasekar: Not Found; Abdulwasa=B. Barnawi: Not Found; Bharatiraja=Chokkalingam: Not Found,"Brushless direct current (BLDC) motors are mostly preferred for dynamic applications such as automotive industries, pumping industries, and rolling industries. It is predicted that by 2030, BLDC motors will become mainstream of power transmission in industries replacing traditional induction motors. Though the BLDC motors are gaining interest in industrial and commercial applications, the future of BLDC motors faces indispensable concerns and open research challenges. Considering the case of reliability and durability, the BLDC motor fails to yield improved fault tolerance capability, reduced electromagnetic interference, reduced acoustic noise, reduced flux ripple, and reduced torque ripple. To address these issues, closed-loop vector control is a promising methodology for BLDC motors. In the literature survey of the past five years, limited surveys were conducted on BLDC motor controllers and designing. Moreover, vital problems such as comparison between existing vector control schemes, fault tolerance control improvement, reduction in electromagnetic interference in BLDC motor controller, and other issues are not addressed. This encourages the author in conducting this survey of addressing the critical challenges of BLDC motors. Furthermore, comprehensive study on various advanced controls of BLDC motors such as fault tolerance control, Electromagnetic interference reduction, field orientation control (FOC), direct torque control (DTC), current shaping, input voltage control, intelligent control, drive-inverter topology, and its principle of operation in reducing torque ripples are discussed in detail. This paper also discusses BLDC motor history, types of BLDC motor, BLDC motor structure, Mathematical modeling of BLDC and BLDC motor standards for various applications.",IEEE Access,17 Mar 2025,5,"While the abstract discusses important challenges in BLDC motors, the practical value for startups and early-stage ventures in Europe may be limited as it focuses more on industrial applications."
https://ieeexplore.ieee.org/document/9840390/,"AI-Based Personalized E-Learning Systems: Issues, Challenges, and Solutions",26 July 2022,"Electronic learning, Education, Videos, Adaptation models, Object recognition, Artificial intelligence, Learning (artificial intelligence), Recommender systems, Data mining, E-learning System, Learning Models, Research Papers, Level Of Understanding, Individual Learning, Learning Module, Learning Content, Adaptive Learning, Content Delivery, Personal Education, Adaptive Modulation, Adaptive System, Unsupervised Learning, Long Short-term Memory, Recurrent Neural Network, Learning Performance, Learning Styles, Cognitive Components, Recommender Systems, Levels Of Learning, Personal Content, Personalized Recommendations, Learning Path, Behaviorism, Level Of Mastery, Item Response Theory, Graph Neural Networks, Recurrent Model, Continuous Data Collection, Collaborative Filtering, Adaptability, artificial intelligence, educational data mining, knowledge tracing, personalized e-learning, recommender systems",Mir=Murtaza: Not Found; Yamna=Ahmed: Not Found; Jawwad=Ahmed Shamsi: Not Found; Fahad=Sherwani: Not Found; Mariam=Usman: Not Found,"A personalized e-learning system is effective in imparting enhanced learning to its users. As compared to a conventional e-learning system, which provides similar contents to each learner, a personalized learning system provides specific learning contents and assessments to the learners. Personalization is based on Artificial Intelligence (AI) based techniques in which appropriate contents for each learner are determined using the level of comprehension of the learner and the preferred modes of learning. This paper presents requirements and challenges for a personalized e-learning system. The paper is focused in elaborating four research questions, which are related to identifying key factors of personalized education, elaborating on state of the art research in the domain, utilizing benefits of AI in personalized education, and determining future research directions. The paper utilizes an in-depth survey of current research papers in answering these questions. It provides a comprehensive review of existing solutions in offering personalized e-learning solutions. It also elaborates on different learning models and learning theories, which are significant in providing personalized education. It proposes an efficient framework, which can offer personalized e-learning to each learner. The proposed framework includes five modules i.e Data Module, Adaptive Learning Module, Adaptable Learning Module, Recommender Module, Content and Assessment Delivery Module. Our work also identifies significant directions for future research. The paper is beneficial for academicians and researchers in understanding the requirements of such a system, comprehending its methodologies, and identifying challenges which are needed to be addressed.",IEEE Access,17 Mar 2025,7,"The personalized e-learning system proposed in this abstract could have a positive impact on educational technology startups in Europe, offering a tailored learning experience for users."
https://ieeexplore.ieee.org/document/8972389/,"Internet of Things (IoT) for Next-Generation Smart Systems: A Review of Current Challenges, Future Trends and Prospects for Emerging 5G-IoT Scenarios",28 January 2020,"5G mobile communication, Market research, Protocols, Internet of Things, Quality of service, Security, Next generation networking, Internet Of Things, Standardised, Machine Learning, Deep Learning, Artificial Intelligence, Service Quality, Wireless Networks, Detailed Overview, Multiple-input Multiple-output, Low Latency, Heterogeneous Network, Internet Of Things Devices, High Data Rate, Large Bandwidth, Wireless Sensor Networks, Service Requirements, Internet Of Things Technology, Quality Of Service Requirements, Cognitive Radio, Internet Of Things Nodes, Internet Of Things Architecture, Wireless Technologies, Internet Of Things Applications, 5G Technology, Internet Of Things Networks, Big Data, Control Plane, D2D Communication, High-quality Services, Internet of Things (IoT), 5G, carrier aggregation, CoMP, CRAN, CRs, HetNets, MIMO, M-MIMO, NFV, SD-WSN, QoS",Kinza=Shafique: Not Found; Bilal=A. Khawaja: Not Found; Farah=Sabir: Not Found; Sameer=Qazi: Not Found; Muhammad=Mustaqim: Not Found,"The Internet of Things (IoT)-centric concepts like augmented reality, high-resolution video streaming, self-driven cars, smart environment, e-health care, etc. have a ubiquitous presence now. These applications require higher data-rates, large bandwidth, increased capacity, low latency and high throughput. In light of these emerging concepts, IoT has revolutionized the world by providing seamless connectivity between heterogeneous networks (HetNets). The eventual aim of IoT is to introduce the plug and play technology providing the end-user, ease of operation, remotely access control and configurability. This paper presents the IoT technology from a bird's eye view covering its statistical/architectural trends, use cases, challenges and future prospects. The paper also presents a detailed and extensive overview of the emerging 5G-IoT scenario. Fifth Generation (5G) cellular networks provide key enabling technologies for ubiquitous deployment of the IoT technology. These include carrier aggregation, multiple-input multiple-output (MIMO), massive-MIMO (M-MIMO), coordinated multipoint processing (CoMP), device-to-device (D2D) communications, centralized radio access network (CRAN), software-defined wireless sensor networking (SD-WSN), network function virtualization (NFV) and cognitive radios (CRs). This paper presents an exhaustive review for these key enabling technologies and also discusses the new emerging use cases of 5G-IoT driven by the advances in artificial intelligence, machine and deep learning, ongoing 5G initiatives, quality of service (QoS) requirements in 5G and its standardization issues. Finally, the paper discusses challenges in the implementation of 5G-IoT due to high data-rates requiring both cloud-based platforms and IoT devices based edge computing.",IEEE Access,17 Mar 2025,6,"The overview of IoT and 5G technologies presents valuable insights for startups engaged in IoT solutions, showcasing the potential for innovation in connectivity and network technologies."
https://ieeexplore.ieee.org/document/9852458/,Explainable AI for Healthcare 5.0: Opportunities and Challenges,08 August 2022,"Medical services, Artificial intelligence, Predictive models, Analytical models, Prediction algorithms, Medical diagnostic imaging, Deep learning, Explainable Artificial Intelligence, Artificial Intelligence In Healthcare, Privacy, Prediction Model, Deep Learning, Big Data, Machine Learning Models, Image Classification, Image Segmentation, Deep Learning Models, Model Interpretation, Artificial Intelligence Models, Federated Learning, Healthcare Domain, Electrocardiogram Monitoring, Model Explainability, Learning Algorithms, Convolutional Neural Network, Convolutional Layers, Local Data, Artificial Intelligence Systems, Electrocardiogram Signals, Virtual Network Functions, Class Activation Maps, Future Scope, Local Explanations, Human-machine Interaction, SHapley Additive exPlanations, Open Challenges, Healthcare Applications, Explainable AI, healthcare 50, metrics, deep learning",Deepti=Saraswat: Not Found; Pronaya=Bhattacharya: Not Found; Ashwin=Verma: Not Found; Vivek=Kumar Prasad: Not Found; Sudeep=Tanwar: Not Found; Gulshan=Sharma: Not Found,"In the healthcare domain, a transformative shift is envisioned towards Healthcare 5.0. It expands the operational boundaries of Healthcare 4.0 and leverages patient-centric digital wellness. Healthcare 5.0 focuses on real-time patient monitoring, ambient control and wellness, and privacy compliance through assisted technologies like artificial intelligence (AI), Internet-of-Things (IoT), big data, and assisted networking channels. However, healthcare operational procedures, verifiability of prediction models, resilience, and lack of ethical and regulatory frameworks are potential hindrances to the realization of Healthcare 5.0. Recently, explainable AI (EXAI) has been a disruptive trend in AI that focuses on the explainability of traditional AI models by leveraging the decision-making of the models and prediction outputs. The explainability factor opens new opportunities to the black-box models and brings confidence in healthcare stakeholders to interpret the machine learning (ML) and deep learning (DL) models. EXAI is focused on improving clinical health practices and brings transparency to the predictive analysis, which is crucial in the healthcare domain. Recent surveys on EXAI in healthcare have not significantly focused on the data analysis and interpretation of models, which lowers its practical deployment opportunities. Owing to the gap, the proposed survey explicitly details the requirements of EXAI in Healthcare 5.0, the operational and data collection process. Based on the review method and presented research questions, systematically, the article unfolds a proposed architecture that presents an EXAI ensemble on the computerized tomography (CT) image classification and segmentation process. A solution taxonomy of EXAI in Healthcare 5.0 is proposed, and operational challenges are presented. A supported case study on electrocardiogram (ECG) monitoring is presented that preserves the privacy of local models via federated learning (FL) and EXAI for metric vali...",IEEE Access,17 Mar 2025,9,"The Healthcare 5.0 concept and the focus on explainable AI in healthcare present a high practical value for startups in the health tech sector in Europe, addressing key issues and paving the way for ethical AI implementation in healthcare."
https://ieeexplore.ieee.org/document/9446143/,U-Net and Its Variants for Medical Image Segmentation: A Review of Theory and Applications,03 June 2021,"Image segmentation, Convolution, Biomedical imaging, Three-dimensional displays, Logic gates, Deep learning, Computer architecture, Medical Imaging, Image Segmentation, Medical Image Segmentation, Magnetic Resonance Imaging, Computed Tomography, Deep Learning, Imaging Modalities, Application Areas, Segmentation Task, U-Net Architecture, Convolutional Layers, Feature Maps, Deep Learning Models, Recurrent Neural Network, Image Object, Age-related Macular Degeneration, Generative Adversarial Networks, Deep Learning Techniques, Skip Connections, Retinal Vessels, U-Net Model, Expansive Path, Attention Gate, Fully Convolutional Network, 3D U-Net, Medical Image Analysis, U-Net For Segmentation, Feature Pyramid Network, Identity Mapping, Dice Similarity Coefficient, Biomedical imaging, deep learning, neural network architecture, segmentation, U-net",Nahian=Siddique: Not Found; Sidike=Paheding: Not Found; Colin=P. Elkin: Not Found; Vijay=Devabhaktuni: Not Found,"U-net is an image segmentation technique developed primarily for image segmentation tasks. These traits provide U-net with a high utility within the medical imaging community and have resulted in extensive adoption of U-net as the primary tool for segmentation tasks in medical imaging. The success of U-net is evident in its widespread use in nearly all major image modalities, from CT scans and MRI to X-rays and microscopy. Furthermore, while U-net is largely a segmentation tool, there have been instances of the use of U-net in other applications. Given that U-net's potential is still increasing, this narrative literature review examines the numerous developments and breakthroughs in the U-net architecture and provides observations on recent trends. We also discuss the many innovations that have advanced in deep learning and discuss how these tools facilitate U-net. In addition, we review the different image modalities and application areas that have been enhanced by U-net.",IEEE Access,17 Mar 2025,8,"The abstract explores the practical applications of U-net in medical imaging, highlighting its widespread use across different modalities. The discussion on recent developments and breakthroughs in U-net architecture provides valuable insights for startups looking to innovate in the medical imaging field."
https://ieeexplore.ieee.org/document/8949524/,A Comprehensive Review on Malware Detection Approaches,03 January 2020,"Computer viruses, Feature extraction, Encryption, Internet, Detection Approach, Detection Methods, Challenging Task, Deep Learning-based Approaches, Neural Network, Deep Learning, Learning Algorithms, Support Vector Machine, Mobile Devices, Encryption, Internet Of Things, Application Programming Interface, Internet Of Things Devices, Automatic Generation, Model Checking, Benign Samples, Malicious Behavior, System Calls, Control Flow Graph, Signature Generation, Data Mining Algorithms, Graph Kernel, Use Of New Techniques, Ransomware, Detection Accuracy, Virus Detection, Hybrid Feature, Cyber security, malware classification, malware detection approaches, malware features",Ömer=Aslan Aslan: Not Found; Refik=Samet: Not Found,"According to the recent studies, malicious software (malware) is increasing at an alarming rate, and some malware can hide in the system by using different obfuscation techniques. In order to protect computer systems and the Internet from the malware, the malware needs to be detected before it affects a large number of systems. Recently, there have been made several studies on malware detection approaches. However, the detection of malware still remains problematic. Signature-based and heuristic-based detection approaches are fast and efficient to detect known malware, but especially signature-based detection approach has failed to detect unknown malware. On the other hand, behavior-based, model checking-based, and cloud-based approaches perform well for unknown and complicated malware; and deep learning-based, mobile devices-based, and IoT-based approaches also emerge to detect some portion of known and unknown malware. However, no approach can detect all malware in the wild. This shows that to build an effective method to detect malware is a very challenging task, and there is a huge gap for new studies and methods. This paper presents a detailed review on malware detection approaches and recent detection methods which use these approaches. Paper goal is to help researchers to have a general idea of the malware detection approaches, pros and cons of each detection approach, and methods that are used in these approaches.",IEEE Access,17 Mar 2025,5,"The abstract addresses the pressing issue of malware detection, discussing various approaches and the challenges faced. While relevant for cybersecurity startups, the lack of specific new breakthroughs or innovations may limit its immediate impact on early-stage ventures."
https://ieeexplore.ieee.org/document/9893798/,"A Survey of Ensemble Learning: Concepts, Algorithms, Applications, and Prospects",16 September 2022,"Boosting, Classification algorithms, Prediction algorithms, Machine learning algorithms, Computational modeling, Bagging, Machine learning, Learning systems, Machine Learning, Random Forest, Machine Learning Applications, Ensemble Method, Gradient Boosting, AdaBoost, Ensemble Learning Techniques, Learning Algorithms, Decision Tree, Machine Learning Models, Recurrent Neural Network, Final Prediction, Ensemble Model, Majority Voting, Random Forest Algorithm, Sentiment Analysis, Base Learners, Gradient Boosting Decision Tree, Subset Of Models, Ensemble Technique, Ensemble Learning Method, Conventional Machine Learning Algorithms, Fraud Detection, Dynamic Selection, Ensemble Learning Algorithm, Ensemble Diversity, Weak Learners, Long Short-term Memory, Individual Models, Misclassified Samples, Algorithms, classification, ensemble learning, fraud detection, machine learning, medical diagnosis",Ibomoiye=Domor Mienye: Not Found; Yanxia=Sun: Not Found,"Ensemble learning techniques have achieved state-of-the-art performance in diverse machine learning applications by combining the predictions from two or more base models. This paper presents a concise overview of ensemble learning, covering the three main ensemble methods: bagging, boosting, and stacking, their early development to the recent state-of-the-art algorithms. The study focuses on the widely used ensemble algorithms, including random forest, adaptive boosting (AdaBoost), gradient boosting, extreme gradient boosting (XGBoost), light gradient boosting machine (LightGBM), and categorical boosting (CatBoost). An attempt is made to concisely cover their mathematical and algorithmic representations, which is lacking in the existing literature and would be beneficial to machine learning researchers and practitioners.",IEEE Access,17 Mar 2025,9,"The abstract presents a comprehensive overview of ensemble learning techniques, focusing on state-of-the-art algorithms. This valuable resource can benefit startups in machine learning applications by providing insights into the mathematical and algorithmic representations of ensemble methods."
https://ieeexplore.ieee.org/document/9103025/,"Digital Twin: Enabling Technologies, Challenges and Open Research",28 May 2020,"Smart cities, Data analysis, Manufacturing, Data models, Internet of Things, Computational modeling, Open Research, Digital Twin, Enabling Technologies, Area Of Research, Artificial Intelligence, Digital Technologies, Internet Of Things, Manufacturing Industry, Smart City, Machine Learning, Learning Algorithms, Manufacturing Process, Digital Model, Physical System, Broad Areas, Data Fusion, Internet Of Things Devices, Artificial Intelligence Algorithms, Cyber-physical Systems, Smart Manufacturing, Smart City Development, Internet Of Things Sensors, Internet Of Things Systems, Remaining Useful Life, Internet Of Things Technology, Blockchain, Predictive Maintenance, Manufacturing Environment, Industrial Internet Of Things, Digital twins, applications, enabling technologies, industrial Internet of Things (IIoT), Internet of Things (IoT), machine learning, deep learning, literature review",Aidan=Fuller: Not Found; Zhong=Fan: Not Found; Charles=Day: Not Found; Chris=Barlow: Not Found,"Digital Twin technology is an emerging concept that has become the centre of attention for industry and, in more recent years, academia. The advancements in industry 4.0 concepts have facilitated its growth, particularly in the manufacturing industry. The Digital Twin is defined extensively but is best described as the effortless integration of data between a physical and virtual machine in either direction. The challenges, applications, and enabling technologies for Artificial Intelligence, Internet of Things (IoT) and Digital Twins are presented. A review of publications relating to Digital Twins is performed, producing a categorical review of recent papers. The review has categorised them by research areas: manufacturing, healthcare and smart cities, discussing a range of papers that reflect these areas and the current state of research. The paper provides an assessment of the enabling technologies, challenges and open research for Digital Twins.",IEEE Access,17 Mar 2025,7,The abstract highlights the emerging concept of Digital Twin technology and its applications in various industries. The discussion on enabling technologies and research areas provides a solid foundation for startups interested in leveraging Digital Twins for innovation.
https://ieeexplore.ieee.org/document/10478883/,Privacy and Security Concerns in Generative AI: A Comprehensive Survey,25 March 2024,"Security, Generative AI, Privacy, Surveys, Data privacy, Data models, Computational modeling, Artificial intelligence, Generative adversarial networks, Deep learning, Ethics, Computer security, Threat assessment, Fake news, Homomorphic encryption, Privacy Issues, Comprehensive Survey, Security Concern, Privacy Challenges, Personal Data, Data Generation, Internet Of Things, Data Privacy, Recurrent Neural Network, Generative Adversarial Networks, Data Security, Anomaly Detection, Fake News, Artificial Intelligence Applications, Variational Autoencoder, Ethical Perspective, Adversarial Training, Federated Learning, Adversarial Attacks, Differential Privacy, Adversarial Examples, Generative Adversarial Network Framework, Multi-party Computation, AI Systems, Neural Network, Data Distribution, Data Storage, General Data Protection Regulation, Data Protection, User Perspective, Generative artificial intelligence, privacy concerns, security concerns, deep learning, adversarial attacks, synthetic data, Deepfake, ethical implications, cybersecurity, machine learning, privacy protection, ethical responsibility, misinformation, social engineering, regulatory compliance, artificial intelligence, privacy preservation, data security, threat analysis",Abenezer=Golda: Not Found; Kidus=Mekonen: Not Found; Amit=Pandey: Not Found; Anushka=Singh: Not Found; Vikas=Hassija: Not Found; Vinay=Chamola: Not Found,"Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.",IEEE Access,17 Mar 2025,6,"The abstract delves into the transformative impact of Generative Artificial Intelligence (GAI) across different domains. While the discussion on privacy and security challenges is relevant, the lack of specific practical applications or new advancements may limit its immediate relevance to early-stage ventures."
https://ieeexplore.ieee.org/document/8740989/,Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques,19 June 2019,"Diseases, Heart, Data mining, Support vector machines, Feature extraction, Machine learning, Predictive models, Cardiovascular Disease, Machine Learning, Machine Learning Techniques, Disease Prediction, Heart Disease Prediction, Hybrid Machine Learning Techniques, Prediction Accuracy, Random Forest, Health Sector, Internet Of Things, Predictor Of Cardiovascular Disease, Different Combinations Of Features, Disease Severity, Neural Network, Diagnosis Of Disease, Convolutional Neural Network, Decision Tree, Data Mining, Results Of Method, Internet Of Things Devices, Presence Of Heart Disease, Absence Of Heart Disease, Heart Disease Patients, Multivariate Adaptive Regression Splines, Carotid Artery Stenting, Random Forest Method, UCI Machine Learning Repository, Radial Basis Function Network, Right Bundle Branch Block, Premature Ventricular Complexes, Machine learning, heart disease prediction, feature selection, prediction model, classification algorithms, cardiovascular disease (CVD)",Senthilkumar=Mohan: Not Found; Chandrasegar=Thirumalai: Not Found; Gautam=Srivastava: Not Found,"Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM).",IEEE Access,17 Mar 2025,7,The research on improving accuracy in the prediction of cardiovascular disease using machine learning techniques can have a significant impact on the healthcare industry and early-stage ventures focusing on healthcare technology.
https://ieeexplore.ieee.org/document/10198233/,From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy,01 August 2023,"Chatbots, Artificial intelligence, Computer security, Hidden Markov models, Privacy, Ethics, Switches, Generative adversarial networks, Open Challenges, Ethical Implications, Artificial Intelligence Models, Development Of Artificial Intelligence, Legal Implications, Code Generation, Incident Response, Injection Attacks, Encryption, Hallucinations, Sensitive Data, Language Model, General Data Protection Regulation, Large Volumes Of Data, Security Vulnerabilities, Artificial Intelligence Systems, Use Of Artificial Intelligence, Distributed Denial Of Service, Code Snippets, Piece Of Code, Code Review, Chatbot, Encrypted File, Use Of Personal Information, Malicious Activities, Intrusion Detection System, Text Generation, Generative AI, GenAI and cybersecurity, ChatGPT, Google bard, cyber offense, cyber defense, ethical GenAI, privacy, artificial intelligence, cybersecurity, jailbreaking",Maanak=Gupta: Not Found; Charankumar=Akiri: Not Found; Kshitiz=Aryal: Not Found; Eli=Parker: Not Found; Lopamudra=Praharaj: Not Found,"Undoubtedly, the evolution of Generative AI (GenAI) models has been the highlight of digital transformation in the year 2022. As the different GenAI models like ChatGPT and Google Bard continue to foster their complexity and capability, it’s critical to understand its consequences from a cybersecurity perspective. Several instances recently have demonstrated the use of GenAI tools in both the defensive and offensive side of cybersecurity, and focusing on the social, ethical and privacy implications this technology possesses. This research paper highlights the limitations, challenges, potential risks, and opportunities of GenAI in the domain of cybersecurity and privacy. The work presents the vulnerabilities of ChatGPT, which can be exploited by malicious users to exfiltrate malicious information bypassing the ethical constraints on the model. This paper demonstrates successful example attacks like Jailbreaks, reverse psychology, and prompt injection attacks on the ChatGPT. The paper also investigates how cyber offenders can use the GenAI tools in developing cyber attacks, and explore the scenarios where ChatGPT can be used by adversaries to create social engineering attacks, phishing attacks, automated hacking, attack payload generation, malware creation, and polymorphic malware. This paper then examines defense techniques and uses GenAI tools to improve security measures, including cyber defense automation, reporting, threat intelligence, secure code generation and detection, attack identification, developing ethical guidelines, incidence response plans, and malware detection. We will also discuss the social, legal, and ethical implications of ChatGPT. In conclusion, the paper highlights open challenges and future directions to make this GenAI secure, safe, trustworthy, and ethical as the community understands its cybersecurity impacts.",IEEE Access,17 Mar 2025,9,"The exploration of GenAI models in cybersecurity and privacy, along with the discussion on potential attacks and defense techniques, addresses a critical issue with high practical value in the context of European startups dealing with cybersecurity threats."
https://ieeexplore.ieee.org/document/9072123/,Unsupervised K-Means Clustering Algorithm,20 April 2020,"Clustering algorithms, Indexes, Linear programming, Entropy, Clustering methods, Unsupervised learning, Machine learning algorithms, Clustering Algorithm, Unsupervised Clustering, K-means Algorithm, Unsupervised K-means, Unsupervised K-means Clustering, Clustering Method, Unsupervised Learning, Parameter Selection, Objective Function, Bayesian Information Criterion, Clustering Results, Number Of Data Points, Number Range, Validity Index, Cluster Centers, Cluster Membership, Gaussian Mixture Model, True Number, Cluster C, Partitioning Method, Silhouette Width, Average Accuracy Rate, Lung Datasets, UCI Machine Learning Repository, Gap Statistic, Davies-Bouldin Index, Clusters In Dataset, Internal Index, Correct Number, Cluster Validity, Clustering, K-means, number of clusters, initializations, unsupervised learning schema, Unsupervised k-means (U-k-means)",Kristina=P. Sinaga: Not Found; Miin-Shen=Yang: Not Found,"The k-means algorithm is generally the most known and used clustering method. There are various extensions of k-means to be proposed in the literature. Although it is an unsupervised learning to clustering in pattern recognition and machine learning, the k-means algorithm and its extensions are always influenced by initializations with a necessary number of clusters a priori. That is, the k-means algorithm is not exactly an unsupervised clustering method. In this paper, we construct an unsupervised learning schema for the k-means algorithm so that it is free of initializations without parameter selection and can also simultaneously find an optimal number of clusters. That is, we propose a novel unsupervised k-means (U-k-means) clustering algorithm with automatically finding an optimal number of clusters without giving any initialization and parameter selection. The computational complexity of the proposed U-k-means clustering algorithm is also analyzed. Comparisons between the proposed U-k-means and other existing methods are made. Experimental results and comparisons actually demonstrate these good aspects of the proposed U-k-means clustering algorithm.",IEEE Access,17 Mar 2025,5,"While the development of an unsupervised k-means clustering algorithm is relevant in machine learning, its impact on European early-stage ventures may not be as immediate or significant compared to other abstracts."
https://ieeexplore.ieee.org/document/7169508/citations?tabFilter=patents#anchor-patent-citations,A Survey of 5G Network: Architecture and Emerging Technologies,28 July 2015,"5G mobile communication, Cloud computing, MIMO, Radio access networks, Cellular networks, 5G Networks, Data Rate, Service Quality, Small Cell, Cloud Computing, Cellular Networks, Internet Of Things, General Architecture, Cellular Architecture, Device-to-device, User Demand, Radio Access Network, Cognitive Radio, 5G Technology, Interference Management, Ultra-dense Networks, Wireless Networks, Cellular Systems, Base Station, Massive MIMO, User Equipment, Type Of Communication, Virtual Network Functions, Large Antenna Arrays, Millimeter Wave Communication, Attainment Rates, Code Division Multiple Access, Wireless Systems, Resource Block, 5G, Cloud, D2D, Massive MIMO, mm-wave, Relay, Small-cel, 5G, cloud, D2D, massive MIMO, mm-wave, relay, small-cell",A.=Gupta: Not Found; R.=K. Jha: Not Found,"In the near future, i.e., beyond 4G, some of the prime objectives or demands that need to be addressed are increased capacity, improved data rate, decreased latency, and better quality of service. To meet these demands, drastic improvements need to be made in cellular network architecture. This paper presents the results of a detailed survey on the fifth generation (5G) cellular network architecture and some of the key emerging technologies that are helpful in improving the architecture and meeting the demands of users. In this detailed survey, the prime focus is on the 5G cellular network architecture, massive multiple input multiple output technology, and device-to-device communication (D2D). Along with this, some of the emerging technologies that are addressed in this paper include interference management, spectrum sharing with cognitive radio, ultra-dense networks, multi-radio access technology association, full duplex radios, millimeter wave solutions for 5G cellular networks, and cloud technologies for 5G radio access networks and software defined networks. In this paper, a general probable 5G cellular network architecture is proposed, which shows that D2D, small cell access points, network cloud, and the Internet of Things can be a part of 5G cellular network architecture. A detailed survey is included regarding current research projects being conducted in different countries by research groups and institutions that are working on 5G technologies.",IEEE Access,17 Mar 2025,8,"The detailed survey on 5G cellular network architecture and emerging technologies can provide valuable insights for startups working on improving network capabilities, making it highly relevant and impactful for the European market."
https://ieeexplore.ieee.org/document/9110603/,The Impact of Artificial Intelligence and Blockchain on the Accounting Profession,08 June 2020,"Big Data, Blockchain, Machine learning, Finance, Artificial Intelligence, Professional Accountability, Impact Of Artificial Intelligence, Machine Learning, Development Of Technology, Big Data, Artificial Intelligence Applications, Recent Technological Developments, Development Of Artificial Intelligence, Big Machine, Development Of Big Data, IT Professionals, Artificial Neural Network, Professional Knowledge, Data Security, Machine Learning Applications, Real-time Information, General Data Protection Regulation, Radio Frequency Identification, Artificial Intelligence Technology, Machine Learning Technology, Blockchain Technology, Smart Contracts, Liberal Education, Text Generation, Fraud Detection, Message Authentication, Natural Language Processing Technologies, Programming Skills, Tax Returns, Accounting profession, artificial intelligence, big data, blockchain, machine learning",Yingying=Zhang: Not Found; Feng=Xiong: Not Found; Yi=Xie: Not Found; Xuan=Fan: Not Found; Haifeng=Gu: Not Found,"Recent developments in technology have introduced dramatic changes to the practice of the accounting profession. This paper provides a comprehensive review of current developments in big data, machine learning, artificial intelligence, and blockchain utilized in general business practice and by specialized practitioners in the accounting profession worldwide. This paper explores the evolution of the accounting profession following these recent technological developments and assesses the impact of future developments. Inherent challenges and opportunities posed by these new technologies pertaining to accounting professionals and accounting educators are also examined, including an increased demand for IT professionals with accounting experience as opposed to accounting major graduates. Considering the dramatic changes and developments of AI applications in accounting, this paper reflects how all these technologies and the associated requirements of job candidates will affect the desired capabilities of accounting graduates and provides further discussion regarding what higher institutions and their accounting graduates can do to adopt such changes.",IEEE Access,17 Mar 2025,6,"The review of technological developments in accounting may have an impact on accounting professionals, but its immediate practical value for European early-stage ventures may be limited compared to other abstracts."
https://ieeexplore.ieee.org/document/9831441/,Artificial Intelligence Crime: An Overview of Malicious Use and Abuse of AI,18 July 2022,"Artificial intelligence, Data models, Computer crime, Training data, Taxonomy, Machine learning, Legislation, Use Of Artificial Intelligence, Malicious Use, Use Of Systems, Civil Society, Body Of Knowledge, Sectors Of Society, Trading System, Harmful Actions, Types Of Abuse, Social Engineering, Unintended Outcomes, Malicious Activities, Artificial Intelligence Capabilities, Machine Learning, Election, European Union, Social Media Platforms, Generative Adversarial Networks, Dividend, Fake News, Artificial Intelligence Systems, Adversarial Examples, Malware, Artificial Intelligence Techniques, Brute-force Attacks, Cybercrime, Phishing, Information Literacy, Stop Sign, Malicious Intent, Artificial intelligence, artificial intelligence typology, computer crime, malicious artificial intelligence, security, social implications of technology",Taís=Fernanda Blauth: Not Found; Oskar=Josef Gstrein: Not Found; Andrej=Zwitter: Not Found,"The capabilities of Artificial Intelligence (AI) evolve rapidly and affect almost all sectors of society. AI has been increasingly integrated into criminal and harmful activities, expanding existing vulnerabilities, and introducing new threats. This article reviews the relevant literature, reports, and representative incidents which allows to construct a typology of the malicious use and abuse of systems with AI capabilities. The main objective is to clarify the types of activities and corresponding risks. Our starting point is to identify the vulnerabilities of AI models and outline how malicious actors can abuse them. Subsequently, we explore AI-enabled and AI-enhanced attacks. While we present a comprehensive overview, we do not aim for a conclusive and exhaustive classification. Rather, we provide an overview of the risks of enhanced AI application, that contributes to the growing body of knowledge on the issue. Specifically, we suggest four types of malicious abuse of AI (integrity attacks, unintended AI outcomes, algorithmic trading, membership inference attacks) and four types of malicious use of AI (social engineering, misinformation/fake news, hacking, autonomous weapon systems). Mapping these threats enables advanced reflection of governance strategies, policies, and activities that can be developed or improved to minimize risks and avoid harmful consequences. Enhanced collaboration among governments, industries, and civil society actors is vital to increase preparedness and resilience against malicious use and abuse of AI.",IEEE Access,17 Mar 2025,2,"While the abstract touches on important issues related to the malicious use and abuse of AI, the practical value for European early-stage ventures and startups is limited."
https://ieeexplore.ieee.org/document/8694781/,Review of Deep Learning Algorithms and Architectures,22 April 2019,"Deep learning, Training, Computer architecture, Feature extraction, Recurrent neural networks, Feedforward neural networks, Deep Learning, Learning Algorithms, Neural Network, Training Data, Deep Network, Deep Neural Network, Training Time, Recurrent Neural Network, Autoencoder, Speech Recognition, Training Algorithm, Variational Autoencoder, Units In Layer, Deep Residual Network, Gradient Descent, Convolutional Layers, Sigmoid Function, Hidden Layer, Unsupervised Learning, Long Short-term Memory, Restricted Boltzmann Machine, Feed-forward Network, Deep Reinforcement Learning, Implementation Of Neural Networks, Extreme Learning Machine, Unlabeled Data, Image Recognition, Deep Belief Network, MNIST Dataset, Proper Orthogonal Decomposition, Machine learning algorithm, optimization, artificial intelligence, deep neural network architectures, convolution neural network, backpropagation, supervised and unsupervised learning",Ajay=Shrestha: Not Found; Ausif=Mahmood: Not Found,"Deep learning (DL) is playing an increasingly important role in our lives. It has already made a huge impact in areas, such as cancer diagnosis, precision medicine, self-driving cars, predictive forecasting, and speech recognition. The painstakingly handcrafted feature extractors used in traditional learning, classification, and pattern recognition systems are not scalable for large-sized data sets. In many cases, depending on the problem complexity, DL can also overcome the limitations of earlier shallow networks that prevented efficient training and abstractions of hierarchical representations of multi-dimensional training data. Deep neural network (DNN) uses multiple (deep) layers of units with highly optimized algorithms and architectures. This paper reviews several optimization methods to improve the accuracy of the training and to reduce training time. We delve into the math behind training algorithms used in recent deep networks. We describe current shortcomings, enhancements, and implementations. The review also covers different types of deep architectures, such as deep convolution networks, deep residual networks, recurrent neural networks, reinforcement learning, variational autoencoders, and others.",IEEE Access,17 Mar 2025,5,"Deep learning's impact on various sectors and optimization methods discussed can potentially benefit European startups, but the abstract lacks a direct focus on practical applications for early-stage ventures."
https://ieeexplore.ieee.org/document/9755930/,Credit Card Fraud Detection Using State-of-the-Art Machine Learning and Deep Learning Algorithms,12 April 2022,"Credit cards, Deep learning, Support vector machines, Prediction algorithms, Machine learning algorithms, Machine learning, Classification algorithms, Machine Learning, Deep Learning, Learning Algorithms, Credit Card, Fraud Detection, Credit Card Fraud Detection, Logistic Regression, Neural Network, Convolutional Neural Network, Support Vector Machine, Random Forest, Decision Tree, Hidden Layer, XGBoost, Machine Learning Analysis, Artificial Neural Network, Convolutional Layers, Machine Learning Models, Machine Learning Techniques, Long Short-term Memory, ReLU Activation Function, Batch Normalization Layer, Dropout Layer, Convolutional Neural Network Model, Generative Adversarial Networks, Dense Layer, Recurrent Neural Network, Restricted Boltzmann Machine, Node Parameters, Deep Belief Network, Fraud detection, deep learning, machine learning, online fraud, credit card frauds, transaction data analysis",Fawaz=Khaled Alarfaj: Not Found; Iqra=Malik: Not Found; Hikmat=Ullah Khan: Not Found; Naif=Almusallam: Not Found; Muhammad=Ramzan: Not Found; Muzamil=Ahmed: Not Found,"People can use credit cards for online transactions as it provides an efficient and easy-to-use facility. With the increase in usage of credit cards, the capacity of credit card misuse has also enhanced. Credit card frauds cause significant financial losses for both credit card holders and financial companies. In this research study, the main aim is to detect such frauds, including the accessibility of public data, high-class imbalance data, the changes in fraud nature, and high rates of false alarm. The relevant literature presents many machines learning based approaches for credit card detection, such as Extreme Learning Method, Decision Tree, Random Forest, Support Vector Machine, Logistic Regression and XG Boost. However, due to low accuracy, there is still a need to apply state of the art deep learning algorithms to reduce fraud losses. The main focus has been to apply the recent development of deep learning algorithms for this purpose. Comparative analysis of both machine learning and deep learning algorithms was performed to find efficient outcomes. The detailed empirical analysis is carried out using the European card benchmark dataset for fraud detection. A machine learning algorithm was first applied to the dataset, which improved the accuracy of detection of the frauds to some extent. Later, three architectures based on a convolutional neural network are applied to improve fraud detection performance. Further addition of layers further increased the accuracy of detection. A comprehensive empirical analysis has been carried out by applying variations in the number of hidden layers, epochs and applying the latest models. The evaluation of research work shows the improved results achieved, such as accuracy, f1-score, precision and AUC Curves having optimized values of 99.9%,85.71%,93%, and 98%, respectively. The proposed model outperforms the state-of-the-art machine learning and deep learning algorithms for credit card detection problems. In addition, we ha...",IEEE Access,17 Mar 2025,8,"The research on credit card fraud detection using deep learning algorithms has a high practical value for European startups, especially in the financial sector, to reduce fraud losses and improve detection accuracy."
https://ieeexplore.ieee.org/document/10549884/,EXplainable Artificial Intelligence (XAI)—From Theory to Methods and Applications,05 June 2024,"Machine learning, Explainable AI, Predictive models, Computational modeling, Machine learning algorithms, Data models, Closed box, Artificial Intelligence, Explainable Artificial Intelligence, Machine Learning, Decision-making Process, Important Characteristics, Black Box, Performance Metrics, Learning-based Models, Application Of Intelligence, SHapley Additive exPlanations, Linear Model, Neural Network, Learning Models, Complex Models, Learning Algorithms, Convolutional Neural Network, Deep Neural Network, Deep Models, Input Features, Visualization Tool, Shapley Value, Local Explanations, Transparent Model, Model Interpretation, Monte Carlo Tree Search, Exploratory Methods, General Data Protection Regulation, Graph Neural Networks, Partial Dependence Plots, Decision Boundary, Black-box models, explainability, explainable machine learning, interpretability, interpretable machine learning",Evandro=S. Ortigossa: Not Found; Thales=Gonçalves: Not Found; Luis=Gustavo Nonato: Not Found,"Intelligent applications supported by Machine Learning have achieved remarkable performance rates for a wide range of tasks in many domains. However, understanding why a trained algorithm makes a particular decision remains problematic. Given the growing interest in the application of learning-based models, some concerns arise in the dealing with sensible environments, which may impact users’ lives. The complex nature of those models’ decision mechanisms makes them the so-called “black boxes,” in which the understanding of the logic behind automated decision-making processes by humans is not trivial. Furthermore, the reasoning that leads a model to provide a specific prediction can be more important than performance metrics, which introduces a trade-off between interpretability and model accuracy. Explaining intelligent computer decisions can be regarded as a way to justify their reliability and establish trust. In this sense, explanations are critical tools that verify predictions to discover errors and biases previously hidden within the models’ complex structures, opening up vast possibilities for more responsible applications. In this review, we provide theoretical foundations of Explainable Artificial Intelligence (XAI), clarifying diffuse definitions and identifying research objectives, challenges, and future research lines related to turning opaque machine learning outputs into more transparent decisions. We also present a careful overview of the state-of-the-art explainability approaches, with a particular analysis of methods based on feature importance, such as the well-known LIME and SHAP. As a result, we highlight practical applications of the successful use of XAI.",IEEE Access,17 Mar 2025,5,"The focus on Explainable AI (XAI) and transparency in decision-making has relevance for European startups using ML applications, but the abstract could provide more specific examples or applications for early-stage ventures."
https://ieeexplore.ieee.org/document/8325446/,Artificial Intelligence in the 21st Century,26 March 2018,"Artificial intelligence, Conferences, Computer vision, Statistical analysis, Cognition, Collaboration, Market research, Artificial Intelligence, Development Of Artificial Intelligence, Behavioral Perspective, Field Of Artificial Intelligence, Machine Learning, Deep Learning, Field Of Science, Internal Validity, Data Mining, Computer Vision, Number Of Papers, Conference Papers, Number Of Authors, Relevant Topics, Number Of Citations, Journal Papers, Popular Topics, Influence Of Institutions, Beginning Of This Century, Total Number Of Publications, Average Number Of Citations, Total Number Of Papers, Total Number Of Citations, Publications In This Area, Reference Number, Construct Validity, Programming Language, North America, Citations Of Papers, Development Of The Discipline, Artificial intelligence, data analytics, scientific impact, science of science, data science",Jiaying=Liu: Not Found; Xiangjie=Kong: Not Found; Feng=Xia: Not Found; Xiaomei=Bai: Not Found; Lei=Wang: Not Found; Qing=Qing: Not Found,"The field of artificial intelligence (AI) has shown an upward trend of growth in the 21st century (from 2000 to 2015). The evolution in AI has advanced the development of human society in our own time, with dramatic revolutions shaped by both theories and techniques. However, the multidisciplinary and fast-growing features make AI a field in which it is difficult to be well understood. In this paper, we study the evolution of AI at the beginning of the 21st century using publication metadata extracted from 9 top-tier journals and 12 top-tier conferences of this discipline. We find that the area is in the sustainable development and its impact continues to grow. From the perspective of reference behavior, the decrease in self-references indicates that the AI is becoming more and more open-minded. The influential papers/researchers/institutions we identified outline landmarks in the development of this field. Last but not least, we explore the inner structure in terms of topics’ evolution over time. We have quantified the temporal trends at the topic level and discovered the inner connection among these topics. These findings provide deep insights into the current scientific innovations, as well as shedding light on funding policies.",IEEE Access,17 Mar 2025,3,The study on the evolution of AI in the 21st century provides interesting insights but lacks direct practical implications for European early-stage ventures or startups.
https://ieeexplore.ieee.org/document/7169508/,A Survey of 5G Network: Architecture and Emerging Technologies,28 July 2015,"5G mobile communication, Cloud computing, MIMO, Radio access networks, Cellular networks, 5G Networks, Data Rate, Service Quality, Small Cell, Cloud Computing, Cellular Networks, Internet Of Things, General Architecture, Cellular Architecture, Device-to-device, User Demand, Radio Access Network, Cognitive Radio, 5G Technology, Interference Management, Ultra-dense Networks, Wireless Networks, Cellular Systems, Base Station, Massive MIMO, User Equipment, Type Of Communication, Virtual Network Functions, Large Antenna Arrays, Millimeter Wave Communication, Attainment Rates, Code Division Multiple Access, Wireless Systems, Resource Block, 5G, Cloud, D2D, Massive MIMO, mm-wave, Relay, Small-cel, 5G, cloud, D2D, massive MIMO, mm-wave, relay, small-cell",A.=Gupta: Not Found; R.=K. Jha: Not Found,"In the near future, i.e., beyond 4G, some of the prime objectives or demands that need to be addressed are increased capacity, improved data rate, decreased latency, and better quality of service. To meet these demands, drastic improvements need to be made in cellular network architecture. This paper presents the results of a detailed survey on the fifth generation (5G) cellular network architecture and some of the key emerging technologies that are helpful in improving the architecture and meeting the demands of users. In this detailed survey, the prime focus is on the 5G cellular network architecture, massive multiple input multiple output technology, and device-to-device communication (D2D). Along with this, some of the emerging technologies that are addressed in this paper include interference management, spectrum sharing with cognitive radio, ultra-dense networks, multi-radio access technology association, full duplex radios, millimeter wave solutions for 5G cellular networks, and cloud technologies for 5G radio access networks and software defined networks. In this paper, a general probable 5G cellular network architecture is proposed, which shows that D2D, small cell access points, network cloud, and the Internet of Things can be a part of 5G cellular network architecture. A detailed survey is included regarding current research projects being conducted in different countries by research groups and institutions that are working on 5G technologies.",IEEE Access,17 Mar 2025,6,"The paper presents a detailed survey on 5G cellular network architecture and key emerging technologies, which could provide valuable insights for startups working in the telecommunications sector."
https://ieeexplore.ieee.org/document/9404177/,A Systematic Literature Review on Cloud Computing Security: Threats and Mitigation Strategies,14 April 2021,"Cloud computing, Security, Computational modeling, Information technology, Law, Cloud computing security, Authentication, Systematic Review, Cloud Computing, Mitigation Strategies, Multi-party Computation, Cloud Computing Security, Service Providers, Data Integration, Data Storage, Confidential Information, Digital Library, Information Leakage, Security Threats, Consumption Of Services, Security Risks, Paper Surveys, Security Challenges, Cloud Users, Internet Of Things, Data Privacy, Intrusion Detection System, Blockchain Technology, Security Issues, Cloud Providers, Security Approach, Smart Contracts, Virtual Machines, Identity Management, Intrusion Detection, Data Security, Auditing, cloud computing, cloud models, decryption, encryption, malicious behavior, intrusion, secured communication",Bader=Alouffi: Not Found; Muhammad=Hasnain: Not Found; Abdullah=Alharbi: Not Found; Wael=Alosaimi: Not Found; Hashem=Alyami: Not Found; Muhammad=Ayaz: Not Found,"Cloud computing has become a widely exploited research area in academia and industry. Cloud computing benefits both cloud services providers (CSPs) and consumers. The security challenges associated with cloud computing have been widely studied in the literature. This systematic literature review (SLR) is aimed to review the existing research studies on cloud computing security, threats, and challenges. This SLR examined the research studies published between 2010 and 2020 within the popular digital libraries. We selected 80 papers after a meticulous screening of published works to answer the proposed research questions. The outcomes of this SLR reported seven major security threats to cloud computing services. The results showed that data tampering and leakage were among the highly discussed topics in the chosen literature. Other identified security risks were associated with the data intrusion and data storage in the cloud computing environment. This SLR’s results also indicated that consumers’ data outsourcing remains a challenge for both CSPs and cloud users. Our survey paper identified the blockchain as a partnering technology to alleviate security concerns. The SLR findings reveal some suggestions to be carried out in future works to bring data confidentiality, data integrity, and availability.",IEEE Access,17 Mar 2025,5,"The systematic literature review on cloud computing security identifies major threats and suggests blockchain as a partnering technology, which may be beneficial for startups focusing on cloud services and security."
https://ieeexplore.ieee.org/document/10258162/,"Advances in Batteries, Battery Modeling, Battery Management System, Battery Thermal Management, SOC, SOH, and Charge/Discharge Characteristics in EV Applications",22 September 2023,"Batteries, Battery management systems, State of charge, Renewable energy sources, Discharges (electric), Voltage control, Kalman filters, Electric vehicles, Thermal management, Health Status, State Of Charge, Thermal Management, Battery Model, Battery Management, Battery Management System, EV Applications, Battery Thermal, Renewable Energy, Electric Vehicles, Energy Storage Systems, Thermal Model, Cell Voltage, Battery Charging, Battery State, Energy Density, Kalman Filter, Data-driven Models, Internal Resistance, Equivalent Circuit Model, Battery State Of Charge, Battery Temperature, Thermal Runaway, Battery Current, Extended Kalman Filter, Electrochemical Model, Unscented Kalman Filter, Battery Capacity, Charging Rate, Battery Performance, Electric vehicle, battery management, battery modelling, state of charge, state of health, cell balancing, battery thermal management system",R.=Ranjith Kumar: Not Found; C.=Bharatiraja: Not Found; K.=Udhayakumar: Not Found; S.=Devakirubakaran: Not Found; K.=Sathiya Sekar: Not Found; Lucian=Mihet-Popa: Not Found,"The second-generation hybrid and Electric Vehicles are currently leading the paradigm shift in the automobile industry, replacing conventional diesel and gasoline-powered vehicles. The Battery Management System is crucial in these electric vehicles and also essential for renewable energy storage systems. This review paper focuses on batteries and addresses concerns, difficulties, and solutions associated with them. It explores key technologies of Battery Management System, including battery modeling, state estimation, and battery charging. A thorough analysis of numerous battery models, including electric, thermal, and electro-thermal models, is provided in the article. Additionally, it surveys battery state estimations for a charge and health. Furthermore, the different battery charging approaches and optimization methods are discussed. The Battery Management System performs a wide range of tasks, including as monitoring voltage and current, estimating charge and discharge, equalizing and protecting the battery, managing temperature conditions, and managing battery data. It also looks at various cell balancing circuit types, current and voltage stressors, control reliability, power loss, efficiency, as well as their advantages and disadvantages. The paper also discusses research gaps in battery management systems.",IEEE Access,17 Mar 2025,7,"The review paper on Battery Management System for electric vehicles addresses key technologies, concerns, and solutions, offering practical information for startups in the electric vehicle industry."
https://ieeexplore.ieee.org/document/9279211/,Medical Diagnostic Systems Using Artificial Intelligence (AI) Algorithms: Principles and Perspectives,03 December 2020,"Diseases, Artificial intelligence, Medical diagnostic imaging, Medical services, Fuzzy logic, Deep learning, Medical diagnosis, Diagnostic Systems, Artificial Intelligence Algorithms, Medical Diagnostic Systems, Cardiovascular Disease, Machine Learning, Kidney Disease, Deep Learning, Diagnosis Of Disease, Brain Disorders, Medical Field, Disease Prediction, Fuzzy Logic, Human Experts, Artificial Intelligence Techniques, Breast Cancer, Neural Network, Learning Algorithms, Deep Network, Artificial Neural Network, Deep Neural Network, Fuzzy System, Artificial Intelligence Methods, Artificial Intelligence In Healthcare, Periodontitis, Fuzzy Method, Definition Of Disease, Deep Models, Artificial Intelligence Applications, Diagnosis Process, Detection Of Sepsis, Big data analytics, artificial intelligence, machine learning, deep learning, soft computing, chronic disease, diagnosis, health care prediction",Simarjeet=Kaur: Not Found; Jimmy=Singla: Not Found; Lewis=Nkenyereye: Not Found; Sudan=Jha: Not Found; Deepak=Prashar: Not Found; Gyanendra=Prasad Joshi: Not Found,"Disease diagnosis is the identification of an health issue, disease, disorder, or other condition that a person may have. Disease diagnoses could be sometimes very easy tasks, while others may be a bit trickier. There are large data sets available; however, there is a limitation of tools that can accurately determine the patterns and make predictions. The traditional methods which are used to diagnose a disease are manual and error-prone. Usage of Artificial Intelligence (AI) predictive techniques enables auto diagnosis and reduces detection errors compared to exclusive human expertise. In this paper, we have reviewed the current literature for the last 10 years, from January 2009 to December 2019. The study considered eight most frequently used databases, in which a total of 105 articles were found. A detailed analysis of those articles was conducted in order to classify most used AI techniques for medical diagnostic systems. We further discuss various diseases along with corresponding techniques of AI, including Fuzzy Logic, Machine Learning, and Deep Learning. This research paper aims to reveal some important insights into current and previous different AI techniques in the medical field used in today’s medical research, particularly in heart disease prediction, brain disease, prostate, liver disease, and kidney disease. Finally, the paper also provides some avenues for future research on AI-based diagnostics systems based on a set of open problems and challenges.",IEEE Access,17 Mar 2025,7,"The research paper on AI techniques for disease diagnosis provides insights into current and previous AI techniques in the medical field, which could be valuable for startups developing medical diagnostic systems."
https://ieeexplore.ieee.org/document/9815071/,IoT-Enabled Smart Waste Management Systems for Smart Cities: A Systematic Review,04 July 2022,"Waste management, Stakeholders, Smart cities, Biological system modeling, Systematics, Sensor systems, Intelligent sensors, Systematic Review, Management System, Waste Management, Smart City, Waste Management System, Literature Review, Urbanization, Research In The Field, Research Gap, Actuator, Field Direction, Pathfinding, Field Of Systems, Urban Infrastructure, Route Planning, Processing Waste, Waste Collection, Implementation Of Monitoring, Main Service, Various Types Of Applications, Waste Separation, Primary Stakeholders, Situation In Cities, Internet Of Things, Gas Sensors, Internet Of Things Technology, Solid Waste Management, Supporting Information, Real-time Data, Search Queries, Smart city, smart waste management, Internet of Things, smart garbage bin",Inna=Sosunova: Not Found; Jari=Porras: Not Found,"With urbanization, rising income and consumption, the production of waste increases. One of the most important directions in the field of sustainable development is the design and implementation of monitoring and management systems for waste collection and removal. Smart waste management (SWM) involves for example collection and analytics of data from sensors on smart garbage bins (SGBs), management of waste trucks and urban infrastructure; planning and optimization of waste truck routes; etc. The purpose of this paper is to provide a comprehensive overview of the existing research in the field of systems, applications, and approaches vis-à-vis the collection and processing of solid waste in SWM systems. To achieve this objective, we performed a systematic literature review. This study consists of 173 primary studies selected for analysis and data extraction from the 3,732 initially retrieved studies from 5 databases. We 1) identified the main approaches and services that are applied in the city and SGB-level SWM systems, 2) listed sensors and actuators and analyzed their application in various types of SWM systems, 3) listed the direct and indirect stakeholders of the SWM systems, 4) identified the types of data shared between the SWM systems and stakeholders, and 5) identified the main promising directions and research gaps in the field of SWM systems. Based on an analysis of the existing approaches, technologies, and services, we developed recommendations for the implementation of city-level and SGB-level SWM systems.",IEEE Access,17 Mar 2025,5,"The paper on smart waste management systems offers a comprehensive overview of existing research, which may be beneficial for startups working on sustainable waste management solutions."
https://ieeexplore.ieee.org/document/8466590/,Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI),16 September 2018,"Conferences, Machine learning, Market research, Prediction algorithms, Machine learning algorithms, Biological system modeling, Artificial Intelligence, Explainable Artificial Intelligence, Machine Learning, Learning Algorithms, Deep Neural Network, Machine Learning Models, Internet Of Things, Technical Challenges, Human-computer Interaction, Intelligent Systems, Applicability Domain, Challenging Issue, General Data Protection Regulation, Human Sciences, Expert System, Artificial Intelligence Systems, Decision-making Algorithm, Neural Net, Artificial Intelligence Research, Papers In The Field, Interpretable Machine Learning, Trade Secrets, Healthcare Domain, Autonomous Vehicles, Artificial Neural Network, Research Community, Decision Tree, Recidivism, Social Sciences, Explainable artificial intelligence, interpretable machine learning, black-box models",Amina=Adadi: Not Found; Mohammed=Berrada: Not Found,"At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.",IEEE Access,17 Mar 2025,3,"While XAI is an important topic for AI-based systems, the practical implications for early-stage ventures may be limited as they may not be heavily involved in AI development."
https://ieeexplore.ieee.org/document/9311735/,Machine Learning Applications for Precision Agriculture: A Comprehensive Review,31 December 2020,"Agriculture, Artificial intelligence, Internet of Things, Irrigation, Wireless sensor networks, Soil, Sensors, Machine Learning, Machine Learning Applications, Precision Agriculture, Climatic Conditions, Crop Yield, Computer Vision, Machine Learning Models, Internet Of Things, Agricultural Fields, Disease Detection, Livestock Production, Yield Prediction, Soil Parameters, Crop Diseases, Intelligence Techniques, Drip Irrigation, Harvesting Techniques, Crop Weed, Irrigation Techniques, Agricultural Revolution, Learning Algorithms, Livestock Management, Extreme Learning Machine, Unmanned Aerial Vehicles, Regression Algorithm, Disease Identification, Subclinical Mastitis, Partial Least Squares Regression, Support Vector Regression, Prediction Algorithms, Agricultural engineering, machine learning, intelligent irrigation, IoT, prediction",Abhinav=Sharma: Not Found; Arpit=Jain: Not Found; Prateek=Gupta: Not Found; Vinay=Chowdary: Not Found,"Agriculture plays a vital role in the economic growth of any country. With the increase of population, frequent changes in climatic conditions and limited resources, it becomes a challenging task to fulfil the food requirement of the present population. Precision agriculture also known as smart farming have emerged as an innovative tool to address current challenges in agricultural sustainability. The mechanism that drives this cutting edge technology is machine learning (ML). It gives the machine ability to learn without being explicitly programmed. ML together with IoT (Internet of Things) enabled farm machinery are key components of the next agriculture revolution. In this article, authors present a systematic review of ML applications in the field of agriculture. The areas that are focused are prediction of soil parameters such as organic carbon and moisture content, crop yield prediction, disease and weed detection in crops and species detection. ML with computer vision are reviewed for the classification of a different set of crop images in order to monitor the crop quality and yield assessment. This approach can be integrated for enhanced livestock production by predicting fertility patterns, diagnosing eating disorders, cattle behaviour based on ML models using data collected by collar sensors, etc. Intelligent irrigation which includes drip irrigation and intelligent harvesting techniques are also reviewed that reduces human labour to a great extent. This article demonstrates how knowledge-based agriculture can improve the sustainable productivity and quality of the product.",IEEE Access,17 Mar 2025,6,"Precision agriculture using ML and IoT can have a significant impact on agricultural sustainability and production, which can benefit European early-stage ventures in the agri-tech sector."
https://ieeexplore.ieee.org/document/9083958/,An Overview on Edge Computing Research,01 May 2020,"Cloud computing, Edge computing, Real-time systems, Internet of Things, Bandwidth, Security, Data privacy, Edge Computing, Data Processing, Computational Model, Data Storage, Cloud Computing, Internet Of Things, Computer Technology, Privacy Protection, Security Protection, Large Amount Of Data, Data Privacy, Data Security, Access Control, Mobile Network, Edge Nodes, User Equipment, Edge Devices, Mobile Edge Computing, Data Privacy Protection, Identity Authentication, Offloading Decision, Mobile Edge Computing Server, Location Privacy, Computation Offloading, Attribute-based Encryption, Service Layer, Predictive Maintenance, Edge Layer, Live Broadcast, Intelligence Analysis, Edge computing, cloud computing, Internet of Things",Keyan=Cao: Not Found; Yefan=Liu: Not Found; Gongjie=Meng: Not Found; Qimeng=Sun: Not Found,"With the rapid development of the Internet of Everything (IoE), the number of smart devices connected to the Internet is increasing, resulting in large-scale data, which has caused problems such as bandwidth load, slow response speed, poor security, and poor privacy in traditional cloud computing models. Traditional cloud computing is no longer sufficient to support the diverse needs of today's intelligent society for data processing, so edge computing technologies have emerged. It is a new computing paradigm for performing calculations at the edge of the network. Unlike cloud computing, it emphasizes closer to the user and closer to the source of the data. At the edge of the network, it is lightweight for local, small-scale data storage and processing. This article mainly reviews the related research and results of edge computing. First, it summarizes the concept of edge computing and compares it with cloud computing. Then summarize the architecture of edge computing, keyword technology, security and privacy protection, and finally summarize the applications of edge computing.",IEEE Access,17 Mar 2025,6,"Edge computing can provide solutions to current challenges in data processing and security, which can be valuable for European startups looking to leverage IoT and smart devices."
https://ieeexplore.ieee.org/document/10081336/,"Machine Learning Operations (MLOps): Overview, Definition, and Architecture",27 March 2023,"Interviews, Machine learning, Training, Collaboration, Bibliographies, Automation, Codes, Machine Learning, Machine Learning Operations, Best Practices, Set Of Concepts, Feedback Loop, Machine Learning Models, Performance Metrics, Software Development, Software Engineering, Continuous Training, Open-source Tool, Feature Engineering, System Challenges, Directed Acyclic Graph, Step Test, Train Machine Learning, Organizational Challenges, Machine Learning Systems, Train Machine Learning Models, Continuous Delivery, Monitoring Component, Concept Drift, Continuous Integration, Apache Spark, Best-performing Algorithm, Inference Rules, Data Streams, Credit Risk, Business, Proof Of Concept, CI/CD, DevOps, machine learning, MLOps, operations, workflow orchestration",Dominik=Kreuzberger: Not Found; Niklas=Kühl: Not Found; Sebastian=Hirschl: Not Found,"The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we contribute to the body of knowledge by providing an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we provide a comprehensive definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.",IEEE Access,17 Mar 2025,5,"MLOps can help automate ML processes and bring products into production efficiently, which can be beneficial for startups working on ML projects."
https://ieeexplore.ieee.org/document/10438431/,The Impact of Artificial Intelligence on Language Translation: A Review,16 February 2024,"Artificial intelligence, Machine translation, Natural language processing, Fuzzy logic, Feature extraction, Deep learning, Training, Language Translation, Translation System, Neural Network, Deep Learning, Deep Neural Network, Attention Mechanism, Areas For Improvement, Fuzzy Logic, Language Model, English Translation, Parallel Data, Fuzzy Theory, Translation Accuracy, Machine Translation, Use Of Neural Networks, Named Entity Recognition, Language Pairs, Parallel Corpus, Field Of Translation, Neural Machine Translation, Translation Technique, Google Translate, Natural Language Processing Techniques, Recurrent Neural Network, Deep Learning Techniques, Use Of Machines, English Text, Conditional Random Field, Artificial intelligence, language translation, machine translation",Yasir=Abdelgadir Mohamed: Not Found; Akbar=Khanan: Not Found; Mohamed=Bashir: Not Found; Abdul=Hakim H. M. Mohamed: Not Found; Mousab=A. E. Adiel: Not Found; Muawia=A. Elsadig: Not Found,"In the context of a more linked and globalized society, the significance of proficient cross-cultural communication has been increasing to a position of utmost importance. Language functions as a crucial medium that establishes connections among people, corporations, and countries, demanding the implementation of precise and effective translation systems. This comprehensive review paper aims to contribute to the evolving landscape of AI-driven language translation by critically examining the existing literature, identifying key debates, and uncovering areas of innovation and limitations. The primary objective is to provide a nuanced understanding of the current state of AI-driven language translation, emphasizing the advancements, challenges, and ethical considerations. In this review, ongoing debates surrounding AI-driven language translations were actively involved. By evaluating different viewpoints and methodologies, insights into unresolved questions that contribute to a broader discourse in the field were provided. The future trajectory of this study involves the incorporation of cross-lingual dialect adaptability and the advancement of Artificial Intelligence translation systems, with a focus on prioritizing inclusion and cultural understanding.",IEEE Access,17 Mar 2025,3,"While AI-driven language translation is important for global communication, the direct impact on European early-stage ventures may be limited unless they are specifically focused on language technology."
https://ieeexplore.ieee.org/document/9145558/,A Review of Face Recognition Technology,21 July 2020,"Face recognition, Face, Principal component analysis, Feature extraction, Support vector machines, Machine learning, Biological neural networks, Face Recognition, Facial Recognition Technology, Real Conditions, Facial Features, Face Images, Biometric Technologies, Neural Network, Training Data, Deep Learning, Convolutional Neural Network, Support Vector Machine, Dimensionality Reduction, Performance Of Algorithm, Deep Models, Facial Expressions, Linear Discriminant Analysis, Generative Adversarial Networks, Non-negative Matrix Factorization, Recognition Effect, Face Detection, Scale-invariant Feature Transform, Gabor Filters, Face Recognition Task, AdaBoost Classifier, Non-ideal Conditions, Facial Shape, Artificial Features, Face Position, Face Recognition Performance, Video Surveillance, Face recognition, image processing, neural network, artificial intelligence",Lixiang=Li: Not Found; Xiaohui=Mu: Not Found; Siying=Li: Not Found; Haipeng=Peng: Not Found,"Face recognition technology is a biometric technology, which is based on the identification of facial features of a person. People collect the face images, and the recognition equipment automatically processes the images. The paper introduces the related researches of face recognition from different perspectives. The paper describes the development stages and the related technologies of face recognition. We introduce the research of face recognition for real conditions, and we introduce the general evaluation standards and the general databases of face recognition. We give a forward-looking view of face recognition. Face recognition has become the future development direction and has many potential application prospects.",IEEE Access,17 Mar 2025,6,"The abstract provides an overview of face recognition technology and its potential applications, which could be relevant for startups working in the biometric or security sectors. However, it lacks specific details or actionable insights for early-stage ventures."
