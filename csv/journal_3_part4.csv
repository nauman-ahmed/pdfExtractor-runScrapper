link,title,published_year,keywords,author_email,abstract,publication_title,created_on,score,justification
https://www.sciencedirect.com/science/article/pii/S095058492100001X,Bridging the state-of-the-art and the state-of-the-practice of SaaS pricing: A multivocal literature review,May 2021,"Software-as-a-Service, SaaS, Pricing, Software Economics, Software Product Management, Multi-vocal Literature Review",Andrey=Saltan: andrey.saltan@lut.fi; Kari=Smolander: Not Found,"Abstract
Context
Pricing
 is an essential element of software 
business strategy
 and tactics. Informed pricing decision-making requires the involvement of different stakeholders and comprehensive data analysis. Achieving both appears to be challenging, and pricing remains one of the most under-managed processes in the software business. Simultaneously, a coherent 
SaaS
 pricing body of knowledge and verified solutions to assist SaaS providers while designing and implementing pricing are missing.
Objective
There is a lack of integration among different research areas focused on SaaS pricing and, more importantly, between academia and 
industry
. The primary aim of this paper is to clarify this misconception by classifying, thematically analyzing, and putting in correspondent academic state-of-the-art and industrial state-of-the-practice of SaaS pricing.
Method
A multivocal literature review (MLR) approach was used for the study, exploring both “white” literature as well as “grey” literature. The body of literature of 387 
bibliography
 items was collected using a formal protocol. Of these, 57 were white literature items, and 330 were grey. A multistage content analysis process was implemented to classify the rich literature body across multiple dimensions with further mapping, synthesis, and reporting.
Results
A taxonomy of pricing-related concepts was created. It classifies SaaS pricing aspects, affecting factors, and challenges facing SaaS providers. The findings and interpretations are summarized to emphasize the major research themes and practical challenges of SaaS pricing practices’ transformation and provide further research guidelines in this area.
Conclusion
SaaS pricing is a maturing and prominent area of research that requires further investigation. The conducted MLR formed a clear picture of SaaS pricing research and practice and identified different SaaS pricing aspects and affecting factors. The study will enable both scholars and practitioners to assess the current state-of-the-art in research and practice.",Information and Software Technology,18 Mar 2025,7.0,"The study addresses the important issue of SaaS pricing, providing a taxonomy of pricing-related concepts and practical challenges, which can be beneficial for startups in the software business."
https://www.sciencedirect.com/science/article/pii/S0950584920302457,Rigorous code review by reverse engineering,May 2021,Not Found,Shaoying=Liu: sliu@hiroshima-u.ac.jp; Honghui=Li: Not Found; Zhouxian=Jiang: Not Found; Xiuru=Li: Not Found; Feng=Liu: Not Found; Yan=Zhong: Not Found,"Abstract
Context:
Agile 
software development methods
 advocate the importance of producing working software without comprehensive documentation. While this approach seems to suit the evolutionary nature of realistic software development for many applications, even including safety-critical systems, it faces two major challenges. One is the lack of a comprehensible specification for code evolution and future maintenance, and the other is the potentially huge cost in code verification.
Objective:
To address this problem, we believe that supporting the efficient production of system specification by reversing the program constructed as the result of an 
agile development
 will be a useful solution. The reverse engineering of specifications from programs will not only help us produce the necessary specification for future program evolution, but more importantly can help us rigorously review the program to detect bugs for the enhancement of program quality.
Method:
In this paper, we put forward a novel method for rigorously reviewing code by reversing it into a comprehensible, formal specification. We elaborate on the principle of translating code into a specification and discuss how the translation process helps detect bugs in programs. We demonstrate how the proposed method works in practice with examples. We also present an experiment to evaluate the performance of the method by comparing it with existing checklist-based inspection.
Conclusions:
How to utilize reverse engineering of formal specifications from programs as a means to review the program for bug detection is an almost unexplored topic in 
software engineering
. In this paper, we have described a specific method called RCRRE to reverse engineering of SOFL formal specifications from code and discussed how the reverse 
engineering process
 can be taken as an effective means to review the program for bug detection. The principle of converting code to a SOFL specification is reflected by a set of translation patterns and a two-step approach to construct a SOFL specification is established. To evaluate the performance, we have carried out an experiment on the effectiveness of our RCRRE method by comparing it with the CBI approach. The result of the experiment indicates that using our RCRRE method can effectively help the reviewer scrutinize the code and therefore find more bugs than the CBI when the reviewer is rather familiar with the SOFL specification language and skills. In the meanwhile, it also shows that the effectiveness of our RCRRE method may be affected in the situation where the reviewer lacks sufficient understanding and experience of SOFL, and using our RCRRE method may in general take a little longer time than the CBI.",Information and Software Technology,18 Mar 2025,8.0,"The paper introduces a novel method (RCRRE) for reviewing code to detect bugs, which could be valuable for startups in agile software development, improving program quality and maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584920302147,A graph-based clustering algorithm for software systems modularization,May 2021,Not Found,Babak=Pourasghar: Not Found; Habib=Izadkhah: izadkhah@tabrizu.ac.ir; Ayaz=Isazadeh: Not Found; Shahriar=Lotfi: Not Found,"Abstract
Context:
Clustering algorithms
, as a modularization technique, are used to modularize a program aiming to understand large software systems as well as software refactoring. These algorithms partition the 
source code
 of the software system into smaller and easy-to-manage modules (clusters). The resulting decomposition is called the software system structure (or software architecture). Due to the NP-hardness of the modularization problem, evolutionary 
clustering approaches
 such as the 
genetic algorithm
 have been used to solve this problem. These methods do not make much use of the information and knowledge available in the artifact 
dependency graph
 which is extracted from the 
source code
.
Objective:
To overcome the limitations of the existing modularization techniques, this paper presents a new modularization technique named GMA (Graph-based Modularization Algorithm).
Methods:
In this paper, a new graph-based clustering algorithm is presented for software modularization. To this end, the depth of relationships is used to compute the similarity between artifacts, as well as seven new criteria are proposed to evaluate the quality of a modularization. The similarity presented in this paper enables the algorithm to use graph-theoretic information.
Results:
To demonstrate the applicability of the proposed algorithm, ten folders of Mozilla Firefox with different domains and functions, along with four other applications, are selected. The experimental results demonstrate that the proposed algorithm produces modularization closer to the human expert’s decomposition (i.e., directory structure) than the other existing algorithms.
Conclusion:
The proposed algorithm is expected to help a software designer in the software reverse 
engineering process
 to extract easy-to-manage and understandable modules from 
source code
.",Information and Software Technology,18 Mar 2025,9.0,"The proposed GMA algorithm for modularization aims to help software designers in reverse engineering, producing modularization closer to human expert's decomposition, which can be highly impactful for startups dealing with large software systems."
https://www.sciencedirect.com/science/article/pii/S0950584920302111,Understanding Hypotheses Engineering in Software Startups through a Gray Literature Review,May 2021,Not Found,Jorge=Melegati: jmelegatigoncalves@unibz.it; Eduardo=Guerra: eduardo.guerra@unibz.it; Xiaofeng=Wang: xiaofeng.wang@unibz.it,"Abstract
Context
The 
higher availability
 of software usage data and the influence of the Lean Startup led to the rise of experimentation in 
software engineering
, a new approach for development based on experiments to understand the user needs. In the models proposed to guide this approach, the first step is generally to identify, prioritize, and specify the hypotheses that will be tested through experimentation. However, although practitioners have proposed several techniques to handle hypotheses, the scientific literature is still scarce.
Objective
The goal of this study is to understand what activities, as proposed in industry, are entailed to handle hypotheses, facilitating the comparison, creation, and evaluation of relevant techniques.
Methods
We performed a gray literature review (GLR) on the practices proposed by practitioners to handle hypotheses in the context of software startups. We analyzed the identified documents using thematic synthesis.
Results
The analysis revealed that techniques proposed for software startups in practice compress five different activities: elicitation, prioritization, specification, analysis, and management. It also showed that practitioners often classify hypotheses in types and which qualities they aim for these statements.
Conclusion
Our results represent the first description for hypotheses engineering grounded in practice data. This mapping of the state-of-practice indicates how research could go forward in investigating hypotheses for experimentation in the context of software startups. For practitioners, they represent a catalog of available practices to be used in this context.",Information and Software Technology,18 Mar 2025,6.0,"The study examines techniques for handling hypotheses in software startups, providing a catalog of available practices, which could benefit startups in experimentation and understanding user needs."
https://www.sciencedirect.com/science/article/pii/S095058492030094X,Context-Oriented Behavioral Programming,May 2021,"Behavioral programming, Scenario-based programming, Programming paradigm, Context awareness, Context-oriented programming, Context-Oriented Behavioral Programming",Achiya=Elyasaf: achiya@bgu.ac.il,"Abstract
Context:
Modern systems require programmers to develop code that dynamically adapts to different contexts, leading to the evolution of new 
context-oriented
 programming languages. These languages introduce new software-engineering challenges, such as: how to maintain the separation of concerns of the codebase? how to model the changing behaviors? how to verify the 
system behavior
? and more.
Objective:
This paper introduces 
Context-Oriented Behavioral Programming
 (COBP) — a novel paradigm for developing context-aware systems, centered on natural and incremental specification of context-dependent behaviors. As the name suggests, we combine 
behavioral-programming
 (BP) — a scenario-based modeling paradigm — with context idioms that explicitly specify when scenarios are relevant and what information they need. The core idea is to connect the behavioral model with a data model that represents the context, allowing an intuitive connection between the models via update and select queries. Combining behavioral-programming with context-oriented programming brings the best of the two worlds, solving issues that arise when using each of the approaches in separation.
Methods:
We begin with providing abstract semantics for COBP and two implementations for the semantics, laying the foundations for applying 
reasoning algorithms
 to context-aware behavioral programs. Next, we exemplify the semantics with formal specifications of systems, including a variant of Conway’s 
Game of Life
. Then, we provide two 
case studies
 of real-life context-aware systems (one in robotics and another in IoT) that were developed using this tool. Throughout the examples and 
case studies
, we provide 
design patterns
 and a methodology for coping with the above challenges.
Results:
The case studies show that the proposed approach is applicable for developing real-life systems, and presents measurable advantages over the alternatives — behavioral programming alone and context-oriented programming alone.
Conclusion:
We present a paradigm allowing programmers and system engineers to capture complex context-dependent requirements and align their code with such requirements.",Information and Software Technology,18 Mar 2025,9.0,"The COBP paradigm introduced in the paper offers a novel approach for developing context-aware systems, combining behavioral programming with context-oriented programming, which could greatly benefit startups in developing modern systems."
https://www.sciencedirect.com/science/article/pii/S095058492030094X,Context-Oriented Behavioral Programming,May 2021,"Behavioral programming, Scenario-based programming, Programming paradigm, Context awareness, Context-oriented programming, Context-Oriented Behavioral Programming",Achiya=Elyasaf: achiya@bgu.ac.il,"Abstract
Context:
Modern systems require programmers to develop code that dynamically adapts to different contexts, leading to the evolution of new 
context-oriented
 programming languages. These languages introduce new software-engineering challenges, such as: how to maintain the separation of concerns of the codebase? how to model the changing behaviors? how to verify the 
system behavior
? and more.
Objective:
This paper introduces 
Context-Oriented Behavioral Programming
 (COBP) — a novel paradigm for developing context-aware systems, centered on natural and incremental specification of context-dependent behaviors. As the name suggests, we combine 
behavioral-programming
 (BP) — a scenario-based modeling paradigm — with context idioms that explicitly specify when scenarios are relevant and what information they need. The core idea is to connect the behavioral model with a data model that represents the context, allowing an intuitive connection between the models via update and select queries. Combining behavioral-programming with context-oriented programming brings the best of the two worlds, solving issues that arise when using each of the approaches in separation.
Methods:
We begin with providing abstract semantics for COBP and two implementations for the semantics, laying the foundations for applying 
reasoning algorithms
 to context-aware behavioral programs. Next, we exemplify the semantics with formal specifications of systems, including a variant of Conway’s 
Game of Life
. Then, we provide two 
case studies
 of real-life context-aware systems (one in robotics and another in IoT) that were developed using this tool. Throughout the examples and 
case studies
, we provide 
design patterns
 and a methodology for coping with the above challenges.
Results:
The case studies show that the proposed approach is applicable for developing real-life systems, and presents measurable advantages over the alternatives — behavioral programming alone and context-oriented programming alone.
Conclusion:
We present a paradigm allowing programmers and system engineers to capture complex context-dependent requirements and align their code with such requirements.",Information and Software Technology,18 Mar 2025,8.0,"The proposed COBP paradigm addresses significant challenges in developing context-aware systems, offering practical benefits to early-stage ventures by improving code alignment with complex requirements."
https://www.sciencedirect.com/science/article/pii/S0950584921000185,Improving high-impact bug report prediction with combination of interactive machine learning and active learning,May 2021,Not Found,Xiaoxue=Wu: Not Found; Wei=Zheng: wzheng@nwpu.edu.cn; Xiang=Chen: Not Found; Yu=Zhao: Not Found; Tingting=Yu: Not Found; Dejun=Mu: Not Found,"Abstract
Context:
Bug reports
 record issues found during software development and maintenance. A high-impact bug report (HBR) describes an issue that can cause severe damage once occurred after deployment. Identifying HBRs from the bug repository as early as possible is crucial for guaranteeing software quality.
Objective:
In recent years, many machine learning-based approaches have been proposed for HBR prediction, and most of them are based on supervised 
machine learning
. However, the assumption of supervised 
machine learning
 is that it needs a large number of labeled data, which is often difficult to gather in practice.
Method:
In this paper, we propose hbrPredictor, which combines interactive machine learning and active learning to HBR prediction. On the one hand, it can dramatically reduce the number of bug reports required for prediction model training; on the other hand, it improves the diversity and 
generalization ability
 of 
training samples
 via 
uncertainty sampling
.
Result:
We take security bug report (SBR) prediction as an example of HBR prediction and perform a large-scale experimental evaluation on datasets from different open-source projects. The results show: (1) hbrPredictor substantially outperforms the two baselines and obtains the maximum values of F1-score (0.7939) and AUC (0.8789); (2) with the dynamic 
stop criteria
, hbrPredictor could reach its best performance with only 45% and 13% of the total bug reports for small-sized datasets and large-sized datasets, respectively.
Conclusion:
By reducing the number of required 
training samples
, hbrPredictor could substantially save the data labeling effort without decreasing the effectiveness of the model.",Information and Software Technology,18 Mar 2025,9.0,"hbrPredictor introduces a novel approach to predicting high-impact bug reports, demonstrating substantial performance improvements and data labeling savings, which can greatly benefit startups in ensuring software quality."
https://www.sciencedirect.com/science/article/pii/S0950584921000185,Improving high-impact bug report prediction with combination of interactive machine learning and active learning,May 2021,Not Found,Xiaoxue=Wu: Not Found; Wei=Zheng: wzheng@nwpu.edu.cn; Xiang=Chen: Not Found; Yu=Zhao: Not Found; Tingting=Yu: Not Found; Dejun=Mu: Not Found,"Abstract
Context:
Bug reports
 record issues found during software development and maintenance. A high-impact bug report (HBR) describes an issue that can cause severe damage once occurred after deployment. Identifying HBRs from the bug repository as early as possible is crucial for guaranteeing software quality.
Objective:
In recent years, many machine learning-based approaches have been proposed for HBR prediction, and most of them are based on supervised 
machine learning
. However, the assumption of supervised 
machine learning
 is that it needs a large number of labeled data, which is often difficult to gather in practice.
Method:
In this paper, we propose hbrPredictor, which combines interactive machine learning and active learning to HBR prediction. On the one hand, it can dramatically reduce the number of bug reports required for prediction model training; on the other hand, it improves the diversity and 
generalization ability
 of 
training samples
 via 
uncertainty sampling
.
Result:
We take security bug report (SBR) prediction as an example of HBR prediction and perform a large-scale experimental evaluation on datasets from different open-source projects. The results show: (1) hbrPredictor substantially outperforms the two baselines and obtains the maximum values of F1-score (0.7939) and AUC (0.8789); (2) with the dynamic 
stop criteria
, hbrPredictor could reach its best performance with only 45% and 13% of the total bug reports for small-sized datasets and large-sized datasets, respectively.
Conclusion:
By reducing the number of required 
training samples
, hbrPredictor could substantially save the data labeling effort without decreasing the effectiveness of the model.",Information and Software Technology,18 Mar 2025,9.0,"hbrPredictor presents an innovative method for predicting high-impact bug reports with impressive performance results and reduced training sample requirements, providing valuable practical implications for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584921000239,Alignment and granularity of requirements and architecture in agile development: A functional perspective,May 2021,"Requirements engineering, Software architecture, Twin Peaks, Alignment, Granularity, Case study, Agile development",Tjerk=Spijkman: tjerk@fizor.io; Sabine=Molenaar: Not Found; Fabiano=Dalpiaz: Not Found; Sjaak=Brinkkemper: Not Found,"Abstract
Context:
Requirements engineering
 and software architecture are tightly linked disciplines. The Twin Peaks model suggests that requirements and architectural components should stay aligned while the system is designed and as the level of detail increases. Unfortunately, this is hardly the case in practical settings.
Objective:
We surmise that a reason for the absence of conjoint evolution is that existing models, such as the Twin Peaks, do not provide concrete guidance for practitioners. We propose the Requirements Engineering for Software Architecture (RE4SA) model to assist in analyzing the alignment and the 
granularity
 of functional requirements and architectural components.
Methods:
After detailing the RE4SA model in notation-independent terms, we propose a concrete instance, called RE4SA-Agile, that connects common artifacts in 
agile development
, such as user stories and features. We introduce metrics that measure the alignment between the requirements and architecture, and we define 
granularity
 smells to pinpoint situation in which the granularity of one high-level requirement or high-level component is not uniform with the norm. We show two applications of RE4SA-Agile, including the use of the metrics, to real-world 
case studies
.
Results:
Our applications of RE4SA-Agile, which were discussed with representatives from the development teams, prove to be able to pinpoint problematic situations regarding the relationship between functional requirements and architecture.
Conclusion:
RE4SA and its metrics can be seen as a first attempt to provide a concrete approach for supporting the application of the Twin Peaks model. We expect future research to apply our metrics to additional cases and to provide variants for RE4SA that support different concrete notations, and extend the perspective beyond the functional perspective of this research, similar to what we did with RE4SA-Agile in this paper.",Information and Software Technology,18 Mar 2025,7.0,"RE4SA model offers concrete guidance for aligning requirements and architecture, helping practitioners analyze relationship granularity, although the immediate impact on startups may be less pronounced compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302172,Leveraging Small Sample Learning for Business Process Management,April 2021,Not Found,Martin=Käppel: martin.kaeppel@uni-bayreuth.de; Stefan=Schönig: stefan.schoenig@ur.de; Stefan=Jablonski: stefan.jablonski@uni-bayreuth.de,"Abstract
Context:
 Tool support for business process management (BPM) is improving more and more. Often, 
machine learning techniques
 are used to recognize certain execution patterns, to optimize workflows and to observe or predict processes. Frequently, many organisations cannot meet the fundamental prerequisites of 
machine learning
 methods since less data is recorded and therefore available for analysis. Most 
machine learning techniques
 rely on big and sufficient data source sets that can be analyzed. Small Sample Learning (SSL) tackles the issue of implementing 
machine learning
 methods in environments where only quantitatively insufficient datasets are available. These methods are strongly tailored to computer vision or 
natural language processing
 problems, which is why they are still neglected in the BPM area.
Objective:
 This paper motivates the use of SSL methods in the BPM area and fosters a research stream that is concerned with the transferability to and the application of these methods in the BPM area.
Method:
 We propose a concept for leveraging SSL methods in BPM and illustrate the idea exemplarly in the field of process mining.
Results:
 Reasons for the need of SSL methods in the BPM area and a conceptual approach for transferring existing SSL methods to the BPM area. The feasibility of our apprach is shown by a brief overview of a primary study leveraging SSL methods for process prediction.
Conclusions:
 Many areas of process mining or BPM in general depend on a sufficient amount of (training) data. Often 
small and medium sized companies
 lack ”big data”, which is why advantages of machine learning and data analysis in the context of BPM cannot be applied. Existing methods that deal with insufficient data are very domain-specific and must be transferred to the process mining area respectively the BPM area.",Information and Software Technology,18 Mar 2025,6.0,"SSL methods in BPM area show potential for leveraging machine learning in environments with limited data, but the direct impact on European early-stage ventures is more indirect and may require further research and application."
https://www.sciencedirect.com/science/article/pii/S0950584920302172,Leveraging Small Sample Learning for Business Process Management,April 2021,Not Found,Martin=Käppel: martin.kaeppel@uni-bayreuth.de; Stefan=Schönig: stefan.schoenig@ur.de; Stefan=Jablonski: stefan.jablonski@uni-bayreuth.de,"Abstract
Context:
 Tool support for business process management (BPM) is improving more and more. Often, 
machine learning techniques
 are used to recognize certain execution patterns, to optimize workflows and to observe or predict processes. Frequently, many organisations cannot meet the fundamental prerequisites of 
machine learning
 methods since less data is recorded and therefore available for analysis. Most 
machine learning techniques
 rely on big and sufficient data source sets that can be analyzed. Small Sample Learning (SSL) tackles the issue of implementing 
machine learning
 methods in environments where only quantitatively insufficient datasets are available. These methods are strongly tailored to computer vision or 
natural language processing
 problems, which is why they are still neglected in the BPM area.
Objective:
 This paper motivates the use of SSL methods in the BPM area and fosters a research stream that is concerned with the transferability to and the application of these methods in the BPM area.
Method:
 We propose a concept for leveraging SSL methods in BPM and illustrate the idea exemplarly in the field of process mining.
Results:
 Reasons for the need of SSL methods in the BPM area and a conceptual approach for transferring existing SSL methods to the BPM area. The feasibility of our apprach is shown by a brief overview of a primary study leveraging SSL methods for process prediction.
Conclusions:
 Many areas of process mining or BPM in general depend on a sufficient amount of (training) data. Often 
small and medium sized companies
 lack ”big data”, which is why advantages of machine learning and data analysis in the context of BPM cannot be applied. Existing methods that deal with insufficient data are very domain-specific and must be transferred to the process mining area respectively the BPM area.",Information and Software Technology,18 Mar 2025,7.0,"The use of Small Sample Learning methods in BPM area can address challenges faced by small and medium sized companies lacking big data, showing potential impact on startups."
https://www.sciencedirect.com/science/article/pii/S0950584920302214,A systematic review of scheduling approaches on multi-tenancy cloud platforms,April 2021,Not Found,Ru=Jia: jiaruweiwei@gmail.com; Yun=Yang: yyang@swin.edu.au; John=Grundy: john.grundy@monash.edu; Jacky=Keung: Jacky.Keung@cityu.edu.hk; Li=Hao: liucoolhao@gmail.com,"Abstract
Context:
Scheduling in cloud is complicated as a result of multi-tenancy. Diverse tenants have different requirements, including service functions, response time, QoS and throughput. Diverse tenants require different scheduling capabilities, resource consumption and competition. Multi-tenancy scheduling approaches have been developed for different service models, such as 
Software as a Service
 (SaaS), Platform as a service (PaaS), Infrastructure as a Service (IaaS), and Database as a Service (DBaaS).
Objective:
In this paper, we survey the current landscape of multi-tenancy scheduling, laying out the challenges and complexity of 
software engineering
 where multi-tenancy issues are involved. This study emphasises scheduling policies, cloud provisioning and deployment with regards to multi-tenancy issues. We conduct a systematic literature review of research studies related to multi-tenancy scheduling approaches on cloud platforms determine the primary scheduling approaches currently used and the challenges for addressing key multi-tenancy scheduling issues.
Method:
We adopted a systematic literature review method to search and review many major journal and 
conference papers
 on four major online electronic databases, which address our four predefined research questions. Defining inclusion and exclusion criteria was the initial step before extracting data from the selected papers and deriving answers addressing our enquiries.
Results:
Finally, 53 papers were selected, of which 62 approaches were identified. Most of these methods are developed without cloud layers’ limitation (43.40%) and on SaaS, most of scheduling approaches are oriented to framework design (43.75%).
Conclusion:
The results have demonstrated most of multi-tenancy scheduling solutions can work at any delivery layer. With the difference of tenants’ requirements and functionalities, the choice of cloud service delivery models is changed. Based on our study, designing a multi-tenancy scheduling framework should consider the following 3 factors: computing, QoS and storage resource. One of the potential research foci of multi-tenancy scheduling approaches is on GPU scheduling.",Information and Software Technology,18 Mar 2025,8.0,"Multi-tenancy scheduling approaches for cloud platforms are crucial for different service models, offering valuable insights for startups working on cloud-based solutions."
https://www.sciencedirect.com/science/article/pii/S0950584920301981,Big Data analytics in Agile software development: A systematic mapping study,April 2021,Not Found,Katarzyna=Biesialska: katarzyna.biesialska@upc.edu; Xavier=Franch: Not Found; Victor=Muntés-Mulero: Not Found,"Abstract
Context:
Over the last decade, Agile methods have changed the software development process in an unparalleled way and with the increasing popularity of Big Data, optimizing 
development cycles
 through 
data analytics
 is becoming a commodity.
Objective:
Although a myriad of research exists on 
software analytics
 as well as on 
Agile software development
 (ASD) practice on itself, there exists no 
systematic overview
 of the research done on ASD from a 
data analytics
 perspective. Therefore, the objective of this work is to make progress by linking ASD with 
Big Data analytics
 (BDA).
Method:
As the primary method to find relevant literature on the topic, we performed manual search and snowballing on papers published between 2011 and 2019.
Results:
In total, 88 primary studies were selected and analyzed. Our results show that BDA is employed throughout the whole 
ASD lifecycle
. The results reveal that data-driven software development is focused on the following areas: code repository analytics, defects/bug fixing, testing, project management analytics, and application usage analytics.
Conclusions:
As BDA and ASD are fast-developing areas, improving the productivity of software development teams is one of the most important objectives BDA is facing in the industry. This study provides scholars with information about the state of 
software analytics
 research and the current trends as well as applications in the business environment. Whereas, thanks to this literature review, practitioners should be able to understand better how to obtain actionable insights from their software artifacts and on which aspects of data analytics to focus when investing in such initiatives.",Information and Software Technology,18 Mar 2025,9.0,"Linking Agile Software Development with Big Data analytics can significantly impact software development teams' productivity, presenting valuable information for startups in software industry."
https://www.sciencedirect.com/science/article/pii/S095058492030238X,Identifying method-level mutation subsumption relations using Z3,April 2021,Not Found,Rohit=Gheyi: rohit@dsc.ufcg.edu.br; Márcio=Ribeiro: marcio@ic.ufal.br; Beatriz=Souza: beatriz.souza@ccc.ufcg.edu.br; Marcio=Guimarães: masg@ic.ufal.br; Leo=Fernandes: leonardo.oliveira@ifal.edu.br; Marcelo=d’Amorim: damorim@cin.ufpe.br; Vander=Alves: valves@unb.br; Leopoldo=Teixeira: lmt@cin.ufpe.br; Baldoino=Fonseca: baldoino@ic.ufal.br,"Abstract
Context:
Mutation analysis is a popular but costly approach to assess the quality of test suites. One recent promising direction in reducing costs of mutation analysis is to identify redundant mutations, i.e., mutations that are subsumed by some other mutations. A previous approach found redundant mutants manually through truth tables but it cannot be applied to all mutations. Another work derives them using automatic test suite generators but it is a time consuming task to generate mutants and tests, and to execute tests.
Objective:
This article proposes an approach to discover redundant mutants by proving 
subsumption relations
 among method-level 
mutation operators
 using weak mutation testing.
Method:
We conceive and encode a theory of 
subsumption relations
 in the Z3 
theorem prover
 for 37 mutation targets (mutations of an expression or statement).
Results:
We automatically identify and prove a number of subsumption relations using Z3, and reduce the number of mutations in a number of mutation targets. To evaluate our approach, we modified 
MuJava
 to include the results of 24 mutation targets and evaluate our approach in 125 classes of 5 large open source popular projects used in prior work. Our approach correctly discards mutations in 75.93% of the cases, and reduces the number of mutations by 71.38%.
Conclusions:
Our approach offers a good balance between the effort required to derive subsumption relations and the effectiveness for the targets considered in our evaluation in the context of strong mutation testing.",Information and Software Technology,18 Mar 2025,9.0,"The approach to discover redundant mutants using weak mutation testing can provide cost-effective solutions for assessing test suite quality, which can benefit startups with limited resources."
https://www.sciencedirect.com/science/article/pii/S0950584920302445,Spectral clustering based mutant reduction for mutation testing,April 2021,Not Found,Changqing=Wei: Not Found; Xiangjuan=Yao: yaoxj@cumt.edu.cn; Dunwei=Gong: Not Found; Huai=Liu: Not Found,"Abstract
Context:
Mutation testing techniques, which attempt to construct a set of so-called mutants by seeding various faults into the software under test, have been widely used to generate test cases as well as to evaluate the effectiveness of a test suite. Its popularity in practice is significantly hindered by its high cost, majorly caused by the large number of mutants generated by the technique.
Objective:
It is always a challenging task to reduce the number of mutants while preserving the effectiveness of mutation testing. In this paper, we make use of an intelligent technique, namely 
spectral clustering
, to improve the efficacy of mutant reduction.
Method:
First of all, we give a family of definitions and the method to calculate the distance between mutants according to the weak mutation testing criteria. Then we propose a mutant reduction method based on 
spectral clustering
 (SCMT), including the determination method of the number of clusters, spectral clustering of mutants, and selection of representative mutants.
Results:
The experimental studies based on 12 object programs show that the new approach can significantly reduce the number of mutants without jeopardizing the performance of mutation testing. As compared with other benchmark techniques, the new approach based on weak mutation testing criteria cannot only consistently deliver high effectiveness of mutation testing, but also help significantly reduce the time-cost of mutation testing.
Conclusion:
It is clearly demonstrated that the use of spectral clustering can help enhance the cost-effectiveness of mutation testing. The research reveals some potential research directions for not only mutation testing but also the broad area of software testing.",Information and Software Technology,18 Mar 2025,8.0,"The use of spectral clustering to improve mutation testing efficacy can lead to cost-effectiveness in software testing, offering potential benefits for startups looking to optimize their testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584920302408,Using mutual information to test from Finite State Machines: Test suite selection,April 2021,Not Found,Alfredo=Ibias: aibias@ucm.es; Manuel=Núñez: mn@sip.ucm.es; Robert M.=Hierons: r.hierons@sheffield.ac.uk,"Abstract
Context:
Mutual Information
 is an information 
theoretic measure
 designed to quantify the amount of similarity between two 
random variables
 ranging over two sets. In this paper, we adapt this concept and show how it can be used to select a 
good
 test suite to test from a 
Finite State Machine
 (
FSM
) based on a 
maximise diversity
 approach.
Objective:
The main goal of this paper is to use 
Mutual Information
 in order to select test suites to test from 
FSM
s and evaluate whether we obtain better results, concerning the quality of the selected test suite, than current state-of-the-art measures.
Method:
First, we defined our scenario. We considered the case where we receive two (or more) test suites and we have to choose between them. We were interested in this scenario because it is a 
recurrent
 case in regression testing. Second, we defined our notion based on 
Mutual Information
: Biased 
Mutual Information
. Finally, we carried out experiments in order to evaluate the measure.
Results:
We obtained experimental evidence that demonstrates the potential value of the measure. We also showed that the time needed to compute the measure is negligible when compare to the time needed to apply extra testing. We compared our measure with a state-of-the-art test selection measure and showed that our proposal outperforms it. Finally, we have compared our measure with a notion of transition coverage. Our experiments showed that our measure is slightly worse than transition coverage, as expected, but its computation is 10 times faster.
Conclusion:
Our experiments showed that Biased Mutual Information is a good measure for selecting test suites, outperforming the current state-of-the-art measure, and having a (negative) correlation to fault coverage. Therefore, we can conclude that our new measure can be used to select the test suite that is likely to find more faults. As a result, it has the potential to be used to automate test generation.",Information and Software Technology,18 Mar 2025,7.0,"The paper presents a new measure for selecting test suites, which outperforms current state-of-the-art measures and has potential to automate test generation, benefiting early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302470,Validating class integration test order generation systems with Metamorphic Testing,April 2021,Not Found,Miao=Zhang: miazhang9-c@my.cityu.edu.hk; Jacky Wai=Keung: jacky.Keung@cityu.edu.hk; Tsong Yueh=Chen: tychen@swin.edu.au; Yan=Xiao: dcsxan@nus.edu.sg,"Abstract
Context:
Previous studies proposed different kinds of approaches for class integration test order generation, and corresponding systems can be implemented based on these approaches. Such class integration test order generation systems can facilitate the process of software integration testing if they are implemented correctly.
Objective:
However, a test oracle problem exists in the class integration test order generation systems. Since these approaches for class integration test order generation normally deliver a local optimum rather than a global optimum, there are no practically feasible ways to validate their generated class integration test orders, that is, these implementation systems are untestable.
Method:
To address the test oracle problem, we apply Metamorphic Testing (MT) to validate class integration test order generation systems. Metamorphic Relations (MRs), which are the key components of MT, reason about relations between test outputs of a system. Five effective MRs are developed to ensure the quality of the class integration test order generation systems. In these proposed MRs, follow-up test inputs are generated by modifying classes or class dependencies in the source test inputs while some characteristics of the source test outputs are preserved, for example, the same class integration test order or the equal stubbing cost. Faults can be detected in systems if an individual MR is violated for certain tests.
Results:
Failure detection of MT has been successfully demonstrated in empirical experiments on three systems implementing different typical class integration test order generation approaches. More than 84% of faulty programs can be detected by all MRs, for three class integration test order generation systems under investigation.
Conclusion:
The experimental results show that the proposed MRs are able to systematically and effectively detect faults in class integration test order generation systems. This study explores a new application domain in MT and further extends its applications in 
Software Engineering
.",Information and Software Technology,18 Mar 2025,8.0,"The study introduces a new application of Metamorphic Testing to detect faults in class integration test order generation systems, showing effectiveness in fault detection, which can be valuable for startups in improving software testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584920302044,Fast and curious: A model for building efficient monitoring- and decision-making frameworks based on quantitative data,April 2021,Not Found,Iris=Figalist: iris.figalist@siemens.com; Christoph=Elsner: Not Found; Jan=Bosch: Not Found; Helena Holmström=Olsson: Not Found,"Abstract
Context:
Nowadays, the hype around 
artificial intelligence
 is at its absolute peak. Large amounts of data are collected every second of the day and a variety of tools exists to enable easy 
analysis of data
. In practice, however, making meaningful use of it is way more challenging. For instance, affected stakeholders often struggle to specify their information needs and to interpret the results of such analyses.
Objective:
In this study we investigate how to enable continuous monitoring of information needs, and the generation of knowledge and insights for various stakeholders involved in the lifecycle of software-intensive products. The overarching goal is to support their decision making by providing relevant insights related to their area of responsibility.
Methods:
We implement multiple monitoring- and decision-making frameworks for six individual, real-world cases selected from three different platforms and covering four types of stakeholders. We compare the individual procedures to derive a 
generic process
 for instantiating such frameworks as well as a model to scale it up for multiple stakeholders.
Results:
For one, we discovered that information needs of stakeholders are often related to a limited subset of 
data sources
 and should be specified in stages. For another, stakeholders often benefit from sharing and reusing existing components among themselves in later phases. Specifically, we identify three types of reuse: (1) Data and knowledge, (2) tools and methods, and (3) concepts. As a result, key aspects of our model are iterative feedback and specification cycles as well as the reuse of appropriate components to speed up the 
instantiation
 process and maximize the efficiency of the model.
Conclusion:
Our results indicate that knowledge and insights can be generated much faster and stakeholders feel the benefits of the analysis very early on by iteratively specifying information needs and by systematically sharing and reusing knowledge, tools and concepts.",Information and Software Technology,18 Mar 2025,6.0,"The research provides insights on enabling continuous monitoring of information needs for stakeholders in software-intensive products, offering a generic process that could potentially enhance decision-making processes for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302160,Do users care about ad’s performance costs? Exploring the effects of the performance costs of in-app ads on user experience,April 2021,Not Found,Cuiyun=Gao: cygao@cse.cuhk.edu.hk; Jichuan=Zeng: jczeng@cse.cuhk.edu.hk; Federica=Sarro: f.sarro@ucl.ac.uk; David=Lo: davidlo@smu.edu.sg; Irwin=King: king@cse.cuhk.edu.hk; Michael R.=Lyu: lyu@cse.cuhk.edu.hk,"Abstract
Context:
 In-app advertising is the primary source of revenue for many mobile apps. The cost of advertising (ad cost) is non-negligible for app developers to ensure a good 
user experience
 and continuous profits. Previous studies mainly focus on addressing the hidden performance costs generated by ads, including consumption of memory, CPU, data traffic, and 
battery
. However, there is no research on analyzing users’ perceptions of ads’ performance costs to our knowledge.
Objective:
 To fill this gap and better understand the effects of performance costs of in-app ads on 
user experience
, we conduct a study on analyzing user concerns about ads’ performance costs.
Method:
 First, we propose RankMiner, an approach to quantify user concerns about specific app issues, including performance costs. Then, based on the usage traces of 20 subject apps, we measure the performance costs of ads. Finally, we conduct correlation analysis on the performance costs and quantified user concerns to explore whether users complain more for higher performance costs.
Results:
 Our findings include the following: (1) RankMiner can quantify users’ concerns better than baselines by an improvement of 214% and 2.5% in terms of 
Pearson
 
correlation coefficient
 (a metric for computing correlations between two variables) and NDCG score (a metric for computing accuracy in prioritizing issues), respectively. (2) The performance costs of the with-ads versions are statistically significantly larger than those of no-ads versions with 
negligible effect
 size; (3) Users are more concerned about the battery costs of ads, and tend to be insensitive to ads’ data traffic costs.
Conclusion:
 Our study is complementary to previous work on in-app ads, and can encourage developers to pay more attention to alleviating the most user-concerned performance costs, such as battery cost.",Information and Software Technology,18 Mar 2025,7.0,"The study analyzes users' perceptions of in-app ads' performance costs, introducing a new approach to quantify user concerns and providing valuable insights for app developers to improve user experience, which can be beneficial for startups focused on optimizing revenue."
https://www.sciencedirect.com/science/article/pii/S0950584920302299,"A methodical framework for service oriented architecture adoption: Guidelines, building blocks, and method fragments",April 2021,Not Found,Supriya=Pulparambil: s.pulparambil@squ.edu.com; Youcef=Baghdadi: ybaghdadi@squ.edu.om; Camille=Salinesi: camille.salinesi@univ-paris1.fr,"Abstract
Context
Rapidly-changing business requirements expect high business process flexibility that can be achieved using 
service oriented architecture
 (SOA). This requires enterprises to adopt SOA and assess their SOA adoption maturity to achieve continuous improvement. SOA realization demands service development with varying levels of 
granularity
.
Objectives
The research aims to develop a methodical framework for SOA realization based on Welke's SOA maturity model, a model that assumes a methodology dimension. The framework is concerned with formalizing knowledge on how to identify and shape the main 
building blocks
 of a method at each maturity level.
Methods
The research applies the principles of 
design science research
 and method engineering to develop a methodical framework for SOA realization.
Results
The research identifies the gaps in SOA realization methods and illustrates how a methodical framework based on a maturity model facilitates the SOA adoption process. The evaluation results revealed that the framework would help enterprises to select method fragments required at each maturity level to accomplish business excellence.
Conclusion
The implications of this research are twofold: from a theoretical perspective, the researchers or practitioners can use the results for further study. From a practical standpoint, enterprises can use the methodical guidelines to assess their current maturity level and select and implement the required method fragments from the method base provided in the proposed framework.",Information and Software Technology,18 Mar 2025,5.0,"The framework developed for SOA realization based on a maturity model may provide some guidance for enterprises, but the practical value for early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302482,On the prediction of long-lived bugs: An analysis and comparative study using FLOSS projects,April 2021,Not Found,Luiz Alberto Ferreira=Gomes: luizgomes@pucpcaldas.br; Ricardo=da Silva Torres: ricardo.torres@ntnu.no; Mario Lúcio=Côrtes: cortes@ic.unicamp.br,"Abstract
Context:
Software evolution and maintenance activities in today’s Free/Libre 
Open Source Software
 (FLOSS) rely primarily on information extracted from 
bug reports
 registered in 
bug tracking systems
. Many studies point out that most bugs that adversely affect the user’s experience across versions of 
FLOSS projects
 are long-lived bugs. However, proposed approaches that support bug fixing procedures do not consider the real-world lifecycle of a bug, in which bugs are often fixed very fast. This may lead to useless efforts to automate the bug management process.
Objective:
This study aims to confirm whether the number of long-lived bugs is significantly high in popular open-source projects and to characterize the population of long-lived bugs by considering the attributes of 
bug reports
. We also aim to conduct a comparative study evaluating the prediction accuracy of five well-known 
machine learning algorithms
 and text mining techniques in the task of predicting long-lived bugs.
Methods:
We collected bug reports from six popular open-source projects repositories (Eclipse, Freedesktop, Gnome, GCC, Mozilla, and WineHQ) and used the following 
machine learning algorithms
 to predict long-lived bugs: K-Nearest Neighbor, Naïve Bayes, 
Neural Networks
, 
Random Forest
, and 
Support Vector Machines
.
Results:
Our results show that long-lived bugs are relatively frequent (varying from 7.2% to 40.7%) and have unique characteristics, confirming the need to study solutions to support bug fixing management. We found that the Neural Network classifier yielded the best results in comparison to the other algorithms evaluated.
Conclusion:
Research efforts regarding long-lived bugs are needed and our results demonstrate that it is possible to predict long-lived bugs with a high accuracy (around 70.7%) despite the use of simple prediction algorithms and text mining methods.",Information and Software Technology,18 Mar 2025,8.0,The study addresses a significant issue in FLOSS projects regarding bug management and provides practical insights for improving bug fixing procedures using machine learning algorithms.
https://www.sciencedirect.com/science/article/pii/S0950584920302469,Multifaceted infrastructure for self-adaptive IoT systems,April 2021,Not Found,Rossana M.C.=Andrade: rossana@great.ufc.br; Belmondo R.=Aragão: belmondorodrigues@great.ufc.br; Pedro Almir M.=Oliveira: pedromartins@great.ufc.br; Marcio E.F.=Maia: marcio@great.ufc.br; Windson=Viana: windson@great.ufc.br; Tales P.=Nogueira: tales@great.ufc.br,"Abstract
Background:
Internet of Things
 (IoT) enables the interaction among objects to provide services to their users. Areas such as eHealth, smart energy, and smart buildings have been benefiting from the IoT potential. However, the development of IoT systems is still complex because it deals with a highly dynamic, volatile, and heterogeneous environment. These characteristics require discovering devices, managing these devices’ context, and self-adapt their behavior.
Goal
: In this work, we propose a self-adaptive IoT infrastructure to support multiple facets, 
i.e.
, the contextual discovery of smart objects, the context management, and the self-adaptation process of the development of these systems.
Methods
: We evaluated the proposed infrastructure by developing a smart building application with and without it. The evaluation focused on four issues: the feasibility of integrating the context management through middleware platforms with adaptation based on workflows in a request/response communication model, the impact of our infrastructure on the development of self-adaptive IoT systems considering 
cyclomatic complexity
 and coupling 
code metrics
; the impact of using contextual filters on the orchestrator of self-adaptation; and the impact on the quality of the self-adaptation.
Results
: The results suggest that: (i) it is feasible to use the proposed infrastructure in the development of self-adaptive IoT systems; (ii) there is a reduction in the 
cyclomatic complexity
 and the coupling with our approach, (iii) there is a considerable decrease in the number of rules evaluated at runtime, (iv) our infrastructure reduces the execution time of the adaptations when using contextual filters, and (v) the self-adaptation process was effective when using the orchestrator of self-adaptations.
Conclusion
: With these results, we observed that the proposed multifaceted infrastructure could reduce the complexity related to the development of IoT systems, in addition to optimizing their self-adaptation process.",Information and Software Technology,18 Mar 2025,6.0,"The proposed self-adaptive IoT infrastructure shows potential for simplifying the development of IoT systems, but the impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920301993,Understanding and addressing quality attributes of microservices architecture: A Systematic literature review,March 2021,Not Found,Shanshan=Li: Not Found; He=Zhang: dr.hezhang@gmail.com; Zijia=Jia: Not Found; Chenxing=Zhong: Not Found; Cheng=Zhang: Not Found; Zhihao=Shan: Not Found; Jinfeng=Shen: Not Found; Muhammad Ali=Babar: Not Found,"Abstract
Context
: As a rapidly adopted 
architectural style
 in 
software engineering
, 
Microservices Architecture
 (MSA) advocates implementing small-scale and independently distributed services, rather than binding all functions into one monolith. Although many initiatives have contributed to the quality improvement of microservices-based systems, there is still a lack of a systematic understanding of the Quality Attributes (QAs) associated with MSA.
Objective
: This study aims to investigate the evidence-based state-of-the-art of QAs of microservices-based systems.
Method
: We carried out a Systematic Literature Review (SLR) to identify and synthesize the relevant studies that report evidence related to QAs of MSA.
Results
: Based on the data extracted from the 72 selected primary studies, we portray an overview of the six identified QAs most concerned in MSA, 
scalability, performance, availability, monitorability, security
, and 
testability
. We identify 19 tactics that architecturally address the critical QAs in MSA, including two tactics for 
scalability
, four for 
performance
, four for 
availability
, four for 
monitorability
, three for 
security
, and two for 
testability
.
Conclusion
: This SLR concludes that for MSA-based systems: 1) Although 
scalability
 is the commonly acknowledged benefit of MSA, it is still an indispensable concern among the identified QAs, especially when trading-off with other QAs, e.g., 
performance
. Apart from the six identified QAs in this study, other QAs for MSA like 
maintainability
 need more attention for effective improvement and evaluation in the future. 3) Practitioners need to carefully make the decision of migrating to MSA based on the 
return on investment
, since this 
architectural style
 additionally cause some pains in practice.",Information and Software Technology,18 Mar 2025,7.0,"The investigation of Quality Attributes in Microservices Architecture contributes to the understanding of MSA quality concerns, but the practical impact on European startups may vary."
https://www.sciencedirect.com/science/article/pii/S0950584920301993,Understanding and addressing quality attributes of microservices architecture: A Systematic literature review,March 2021,Not Found,Shanshan=Li: Not Found; He=Zhang: dr.hezhang@gmail.com; Zijia=Jia: Not Found; Chenxing=Zhong: Not Found; Cheng=Zhang: Not Found; Zhihao=Shan: Not Found; Jinfeng=Shen: Not Found; Muhammad Ali=Babar: Not Found,"Abstract
Context
: As a rapidly adopted 
architectural style
 in 
software engineering
, 
Microservices Architecture
 (MSA) advocates implementing small-scale and independently distributed services, rather than binding all functions into one monolith. Although many initiatives have contributed to the quality improvement of microservices-based systems, there is still a lack of a systematic understanding of the Quality Attributes (QAs) associated with MSA.
Objective
: This study aims to investigate the evidence-based state-of-the-art of QAs of microservices-based systems.
Method
: We carried out a Systematic Literature Review (SLR) to identify and synthesize the relevant studies that report evidence related to QAs of MSA.
Results
: Based on the data extracted from the 72 selected primary studies, we portray an overview of the six identified QAs most concerned in MSA, 
scalability, performance, availability, monitorability, security
, and 
testability
. We identify 19 tactics that architecturally address the critical QAs in MSA, including two tactics for 
scalability
, four for 
performance
, four for 
availability
, four for 
monitorability
, three for 
security
, and two for 
testability
.
Conclusion
: This SLR concludes that for MSA-based systems: 1) Although 
scalability
 is the commonly acknowledged benefit of MSA, it is still an indispensable concern among the identified QAs, especially when trading-off with other QAs, e.g., 
performance
. Apart from the six identified QAs in this study, other QAs for MSA like 
maintainability
 need more attention for effective improvement and evaluation in the future. 3) Practitioners need to carefully make the decision of migrating to MSA based on the 
return on investment
, since this 
architectural style
 additionally cause some pains in practice.",Information and Software Technology,18 Mar 2025,7.0,"The investigation of Quality Attributes in Microservices Architecture contributes to the understanding of MSA quality concerns, but the practical impact on European startups may vary."
https://www.sciencedirect.com/science/article/pii/S0950584920302019,Feature selection and embedding based cross project framework for identifying crashing fault residence,March 2021,Not Found,Zhou=Xu: Not Found; Tao=Zhang: Not Found; Jacky=Keung: Not Found; Meng=Yan: mengy@cqu.edu.cn; Xiapu=Luo: csxluo@comp.polyu.edu.hk; Xiaohong=Zhang: Not Found; Ling=Xu: Not Found; Yutian=Tang: Not Found,"Abstract
Context: The automatically produced crash reports are able to analyze the root of fault causing the crash (crashing fault for short) which is a critical activity for 
software quality assurance
.
Objective: Correctly predicting the existence of crashing fault residence in stack traces of crash report can speed up 
program debugging
 process and optimize debugging efforts. Existing work focused on the collected label information from bug-fixing logs, and the extracted features of crash instances from stack traces and 
source code
 for 
I
dentification of 
C
rashing 
F
ault 
R
esidence (
ICFR
) of newly-submitted crashes. This work develops a novel cross project ICFR framework to address the data scarcity problem by using labeled crash data of other project for the ICFR task of the project at hand. This framework removes irrelevant features, reduces distribution differences, and eases the 
class imbalance
 issue of cross project data since these factors may negatively impact the ICFR performance.
Method: The proposed framework, called 
FSE
, combines 
F
eature 
S
election and feature 
E
mbedding techniques. The FSE framework first uses an 
information gain
 ratio based feature ranking method to select a relevant feature subset for cross project data, and then employs a state-of-the-art 
W
eighted 
B
alanced 
D
istribution 
A
daptation (
WBDA
) method to map features of cross project data into a common space. WBDA considers both marginal and conditional distributions as well as their weights to reduce 
data distribution
 discrepancies. Besides, WBDA balances the class proportion of each project data to alleviate the 
class imbalance
 issue.
Results: We conduct experiments on 7 projects to evaluate the performance of our FSE framework. The results show that FSE outperforms 25 methods under comparison.
Conclusion: This work proposes a cross project learning framework for ICFR, which uses feature selection and embedding to remove irrelevant features and reduce distribution differences, respectively. The results illustrate the performance superiority of our FSE framework.",Information and Software Technology,18 Mar 2025,9.0,"The proposed cross project learning framework for ICFR demonstrates superior performance and addresses a critical issue in software quality assurance, making it highly relevant for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920302202,A decentralized approach for discovering runtime software architectural models of distributed software systems,March 2021,Not Found,Jason=Porter: jason.porter@ung.edu; Daniel A.=Menascé: menasce@gmu.edu,"Abstract
Context:
Runtime software 
architectural models
 of self-adaptive systems are needed for making adaptation decisions in architecture-based self-adaptive systems. However, when these systems are distributed and highly dynamic, there is an added need to discover the system’s software architecture model at runtime. Current methods of runtime architecture discovery use a 
centralized approach
, in which the process is carried out from a single location. These methods are inadequate for large distributed software systems because they do not scale up well and have a 
single point of failure
.
Objective and Method:
This paper describes DeSARM (Decentralized Software Architecture discoveRy Mechanism), a completely decentralized and automated approach, based on gossiping and message tracing, for runtime discovery of software architecture models of distributed software systems. DeSARM is able to identify at runtime important architectural characteristics such as components and connectors, in addition to 
synchronous and asynchronous communication
 patterns. Furthermore, through its use of gossiping, DeSARM exhibits the properties of scalability, global consistency among participating nodes, and resiliency to failures. This paper demonstrates DeSARM’s properties and answers key research questions through experimentation with software architectures of varying sizes and complexities executing within a computer cluster.
Results:
DeSARM enables the decentralized discovery of runtime software 
architectural models
 of distributed software systems while exhibiting the properties of scalability, global consistency among participating nodes and resiliency to failures. Scalability is achieved through DeSARM’s ability to successfully discover software architectures of increasing sizes and complexities executing across node counts of increasing sizes. Global consistency among participating nodes is achieved by each node within the system discovering the complete software architecture independently but in coordination with each other. Finally, resiliency to failures is achieved by DeSARM successfully discovering the software architecture of the system in the presence of component failures.",Information and Software Technology,18 Mar 2025,8.0,"Decentralized runtime discovery of software architecture models for distributed systems with properties of scalability, global consistency, and resiliency to failures has significant practical value for early-stage ventures developing complex software systems."
https://www.sciencedirect.com/science/article/pii/S0950584920302275,Mining the Technical Roles of GitHub Users,March 2021,Not Found,João Eduardo=Montandon: joao.montandon@dcc.ufmg.br; Marco Tulio=Valente: mtov@dcc.ufmg.br; Luciana L.=Silva: luciana.lourdes.silva@ifmg.edu.br,"Abstract
Context:
Modern software development demands high levels of technical specialization. These conditions make IT companies focus on creating cross-functional teams, such as frontend, backend, and mobile developers. In this context, the success of software projects is highly influenced by the expertise of these teams in each field.
Objective:
In this paper, we investigate machine-learning based approaches to automatically identify the technical roles of open source developers.
Method:
For this, we first build a ground truth with 2284 developers labeled in six different roles: backend, frontend, full-stack, mobile, devops, and data science. Then, we build three different machine-learning models used to identify these roles.
Results:
These models presented competitive results for precision (0.88) and AUC (0.89) when identifying all six roles. Moreover, our results show that programming-languages are the most relevant features to predict the investigated roles.
Conclusion:
The approach proposed in this paper can assist companies during their hiring process, such as by recommending developers with the expertise required by job positions.",Information and Software Technology,18 Mar 2025,7.0,"Machine learning-based approaches to automatically identify technical roles of developers can assist startups in building cross-functional teams, but the direct impact on European early-stage ventures may be slightly limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302305,Security in agile software development: A practitioner survey,March 2021,"Survey, Security engineering, Agile software development, Software security, Security standards, Security assurance",Kalle=Rindell: kakrind@utu.fi; Jukka=Ruohonen: Not Found; Johannes=Holvitie: Not Found; Sami=Hyrynsalmi: Not Found; Ville=Leppänen: Not Found,"Abstract
Context:
 Software 
security engineering
 provides the means to define, implement and verify security in software products. Software security engineering is performed by following a software security 
development life cycle
 model or a security 
capability maturity model
. However, agile 
software development methods
 and processes, dominant in the software industry, are viewed to be in conflict with these security practices and the security requirements.
Objective:
 Empirically verify the use and impact of software security engineering activities in the context of 
agile software development
, as practiced by software developer professionals.
Method:
 A survey (
N
=
61
) was performed among software practitioners in Finland regarding their use of 40 common security engineering practices and their perceived security impact, in conjunction with the use of 16 agile software development items and activities.
Results:
 The use of agile items and activities had a measurable effect on the selection of security engineering practices. Perceived impact of the security practices was lower than the rate of use would imply: This was taken to indicate a selection bias, caused by e.g. developers’ awareness of only certain security engineering practices, or by difficulties in applying the security engineering practices into an iterative software development workflow. Security practices deemed to have most impact were proactive and took place in the early phases of software development.
Conclusion:
 Systematic use of agile practices conformed, and was observed to take place in conjunction with the use of security practices. Security activities were most common in the requirement and implementation phases. In general, the activities taking place early in the life cycle were also considered most impactful. A discrepancy between the level of use and the perceived security impact of many security activities was observed. This prompts research and methodological development for better integration of security engineering activities into software development processes, methods, and tools.",Information and Software Technology,18 Mar 2025,6.0,"Empirical verification of software security engineering activities in agile software development can be relevant to European startups, but the impact on practical application may be moderate compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920302433,SRPTackle: A semi-automated requirements prioritisation technique for scalable requirements of software system projects,March 2021,Not Found,Fadhl=Hujainah: fadelhogina@gmail.com; Rohani=Binti Abu Bakar: Not Found; Abdullah B.=Nasser: Not Found; Basheer=Al-haimi: Not Found; Kamal Z.=Zamli: Not Found,"Abstract
Context
Requirement prioritisation (RP) is often used to select the most important 
system requirements
 as perceived by system stakeholders. RP plays a vital role in ensuring the development of a quality system with defined constraints. However, a closer look at existing RP techniques reveals that these techniques suffer from some key challenges, such as scalability, lack of quantification, insufficient prioritisation of participating stakeholders, overreliance on the participation of professional expertise, lack of automation and excessive time consumption. These key challenges serve as the motivation for the present research.
Objective
This study aims to propose a new semiautomated scalable prioritisation technique called ‘SRPTackle’ to address the key challenges.
Method
SRPTackle provides a semiautomated process based on a combination of a constructed requirement priority value formulation function using a multi-criteria decision-making method (i.e. weighted sum model), 
clustering algorithms
 (K-means and K-means++) and a 
binary search tree
 to minimise the need for expert involvement and increase efficiency. The effectiveness of SRPTackle is assessed by conducting seven experiments using a benchmark dataset from a large actual software project.
Results
Experiment results reveal that SRPTackle can obtain 93.0% and 94.65% as minimum and maximum accuracy percentages, respectively. These values are better than those of alternative techniques. The findings also demonstrate the capability of SRPTackle to prioritise large-scale requirements with reduced time consumption and its effectiveness in addressing the key challenges in comparison with other techniques.
Conclusion
With the time effectiveness, ability to scale well with numerous requirements, automation and clear implementation guidelines of SRPTackle, project managers can perform RP for large-scale requirements in a proper manner, without necessitating an extensive amount of effort (e.g. tedious manual processes, need for the involvement of experts and time workload).",Information and Software Technology,18 Mar 2025,9.0,"Proposing a new semiautomated scalable prioritization technique for system requirements with high accuracy percentages, reduced time consumption, and clear implementation guidelines can have a significant positive impact on European early-stage ventures in managing large-scale requirements efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584920302159,Dynamic random testing with test case clustering and distance-based parameter adjustment,March 2021,Not Found,Hanyu=Pei: peihanyu@buaa.edu.cn; Beibei=Yin: yinbeibei@buaa.edu.cn; Kai-Yuan=Cai: kycai@buaa.edu.cn,"Abstract
Context
Software testing is essential in 
software engineering
 to improve 
software reliability
. One goal of software testing strategies is to detect faults faster. Dynamic Random Testing (DRT) strategy uses the testing results to guide the selection of test cases, which has shown to be effective in the 
fault detection
 process.
Objective
Previous studies have demonstrated that DRT is greatly affected by the test case classification and the process of adjusting the testing profile. In this paper, we propose Distance-based DRT (D-DRT) strategies, aiming at enhancing the 
fault detection
 effectiveness of DRT.
Method
D-DRT strategies utilize distance information of inputs into the test case classification and the testing profile adjustment process. The test cases are vectorized based on the input parameters and classified into disjoint 
subdomains
 through certain 
clustering methods
. And the distance information of 
subdomains
, along with testing results, are used to adjust the testing profile, such that test cases that are closer to failure-causing subdomains are more likely to be selected.
Results
We conduct empirical studies to evaluate the performance of the proposed algorithms using 12 versions of 4 open-source programs. The experimental results show that, compared with Random Testing (RT), Random Partition Testing (RPT), DRT and Adaptive Testing (AT), our strategies achieve greater fault detection effectiveness with a low computational cost. Moreover, the distance-based testing profile adjustment method is the dominant factor in the improvement of the D-DRT strategy.
Conclusion
D-DRT strategies are effective testing strategies, and the distance-based testing profile adjustment method plays a crucial role.",Information and Software Technology,18 Mar 2025,7.0,"Introducing Distance-based Dynamic Random Testing strategies for enhancing fault detection effectiveness in software testing can be beneficial for startups, but the practical impact compared to other abstracts may be slightly lower."
https://www.sciencedirect.com/science/article/pii/S0950584920302196,Method-level bug localization using hybrid multi-objective search,March 2021,Not Found,Rafi=Almhana: ralmhana@umich.edu; Marouane=Kessentini: marouane@umich.edu; Wiem=Mkaouer: mwmvse@rit.edu,"Abstract
Context:
 One of the time-consuming maintenance tasks is the localization of bugs especially in large software systems. Developers have to follow a tedious process to reproduce the abnormal behavior then inspect a large number of files. While several studies have been proposed for bugs localization, the majority of them are recommending classes/files as outputs which may still require high inspection effort. Furthermore, there is a significant difference between the natural language used in 
bug reports
 and the programming language which limits the efficiency of existing approaches since most of them are mainly based on lexical similarity.
Objective:
 In this paper, we propose an automated approach to find and rank the potential methods in order to localize the source of a bug based on a bug report description.
Method:
 Our approach finds a good balance between minimizing the number of recommended classes and maximizing the relevance of the proposed solution using a hybrid multi-objective 
optimization algorithm
 combining local and global search. The relevance of the recommended code fragments is estimated based on the use of the history of changes and bug-fixing, and the lexical similarity between the bug report description and the API documentation. Our approach operates on two main steps. The first step is to find the best set of classes satisfying the two conflicting criteria of relevance and the number of classes to recommend using a global search based on NSGA-II. The second step is to locate the most appropriate methods to inspect, using a local multi-objective search based on Simulated Annealing (MOSA) from the list of classes recommended by the first step.
Results:
 We evaluated our system on 6 open source Java projects, using the version of the project before fixing the bug of many 
bug reports
. Our hybrid multi-objective approach is able to successfully locate the true buggy methods within the top 10 recommendations for over 78% of the bug reports leading to a significant reduction of developers’ effort comparing to class-level bug localization techniques.
Conclusion:
 The experimental results show that the search-based approach significantly outperforms four state-of-the-art methods in recommending relevant files for bug reports.",Information and Software Technology,18 Mar 2025,8.0,The automated approach proposed for bug localization can significantly reduce developers' effort leading to a practical impact on early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584920302391,A risk prediction model for software project management based on similarity analysis of context histories,March 2021,Not Found,Alexsandro Souza=Filippetto: alexsandrofilippetto@gmail.com; Robson=Lima: robsonklima@gmail.com; Jorge Luis Victória=Barbosa: jbarbosa@unisinos.br,"Abstract
Context
Risk event management has become strategic in Project Management, where uncertainties are inevitable. In this sense, the use of concepts of ubiquitous computing, such as contexts, context histories, and mobile computing can assist in proactive project management.
Objective
This paper proposes a computational model for the reduction of the probability of project failure through the prediction of risks. The purpose of the study is to show a model to assist teams to identify and monitor risks at different points in the life cycle of projects. The work presents as scientific contribution to the use of context histories to infer the recommendation of risks to new projects.
Method
The research conducted a case study in a software development company. The study was applied in two scenarios. The first involved two teams that assessed the use of the prototype during the implementation of 5 projects. The second scenario considered 17 completed projects to assess the recommendations made by the Átropos model comparing the recommendations with the risks in the original projects. In this scenario, Átropos used 70% of each project's execution as learning for the recommendations of risks generated to the same projects. Thus, the scenario aimed to assess whether the recommended risks are contained in the remaining 30% of the executed projects. We used as context histories, a database with 153 software projects from a financial company.
Results
A project team with 18 professionals assessed the recommendations, obtaining a result of 73% acceptance and 83% accuracy when compared to projects already being executed. The results demonstrated a high percentage of acceptance of the recommendation of risks compared to the other models that do not use the characteristics and similarities of projects.
Conclusion
The results show the applicability of the risk recommendation to new projects, based on the similarity analysis of context histories. This study applies inferences on context histories in the development and planning of projects, focusing on risk recommendation. Thus, with recommendations considering the characteristics of each new project, the manager starts with a larger set of information to make more assertive project planning.",Information and Software Technology,18 Mar 2025,6.0,"The computational model for risk prediction in project management can assist in proactive management, but its impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920302263,On deriving conceptual models from user requirements: An empirical study,March 2021,"Requirements engineering, Conceptual modeling, Use cases, User stories, Derivation process",Fabiano=Dalpiaz: f.dalpiaz@uu.nl; Patrizia=Gieske: Not Found; Arnon=Sturm: Not Found,"Abstract
Context:
 There are numerous textual notations and techniques that can be used in requirements engineering. Currently, practitioners make a choice without having scientific evidence regarding their suitability for given tasks. This uninformed choice may affect task performance. 
Objective:
 In this research, we investigate the adequacy of two well-known notations: use cases and user stories, as a starting point for the manual derivation of a structural conceptual model that represents the domain of the system. We also examine other factors that may affect the performance of this task. 
Methods:
 This work relies on two experiments. The first is a controlled classroom experiment. The second one is a quasi-experiment, conducted over multiple weeks, that aims at evaluating the quality of the derived conceptual model in light of the notation used, the adopted derivation process, and the complexity of the system to be. We 
measure quality
 in terms of validity and completeness of the conceptual model. 
Results:
 The results of the controlled experiment indicate that, for deriving conceptual models, user stories fit better than use cases. Yet, the second experiment indicates that the quality of the derived conceptual models is affected mainly by the derivation process and by the complexity of the case rather than the notation used. 
Contribution:
 We present evidence that the task of deriving a conceptual model is affected significantly by additional factors other than requirements notations. Furthermore, we propose implications and hypotheses that pave the way for further studies that compare alternative notations for the same task as well as for other tasks. Practitioners may use our findings to analyze the factors that affect the quality of the conceptual model when choosing a requirements notation and an 
elicitation
 technique that best fit their needs.",Information and Software Technology,18 Mar 2025,7.0,"The investigation into the adequacy of requirements engineering notations provides valuable insights for practitioners, albeit with moderate immediate practical value."
https://www.sciencedirect.com/science/article/pii/S0950584920302263,On deriving conceptual models from user requirements: An empirical study,March 2021,"Requirements engineering, Conceptual modeling, Use cases, User stories, Derivation process",Fabiano=Dalpiaz: f.dalpiaz@uu.nl; Patrizia=Gieske: Not Found; Arnon=Sturm: Not Found,"Abstract
Context:
 There are numerous textual notations and techniques that can be used in requirements engineering. Currently, practitioners make a choice without having scientific evidence regarding their suitability for given tasks. This uninformed choice may affect task performance. 
Objective:
 In this research, we investigate the adequacy of two well-known notations: use cases and user stories, as a starting point for the manual derivation of a structural conceptual model that represents the domain of the system. We also examine other factors that may affect the performance of this task. 
Methods:
 This work relies on two experiments. The first is a controlled classroom experiment. The second one is a quasi-experiment, conducted over multiple weeks, that aims at evaluating the quality of the derived conceptual model in light of the notation used, the adopted derivation process, and the complexity of the system to be. We 
measure quality
 in terms of validity and completeness of the conceptual model. 
Results:
 The results of the controlled experiment indicate that, for deriving conceptual models, user stories fit better than use cases. Yet, the second experiment indicates that the quality of the derived conceptual models is affected mainly by the derivation process and by the complexity of the case rather than the notation used. 
Contribution:
 We present evidence that the task of deriving a conceptual model is affected significantly by additional factors other than requirements notations. Furthermore, we propose implications and hypotheses that pave the way for further studies that compare alternative notations for the same task as well as for other tasks. Practitioners may use our findings to analyze the factors that affect the quality of the conceptual model when choosing a requirements notation and an 
elicitation
 technique that best fit their needs.",Information and Software Technology,18 Mar 2025,7.0,"The investigation into the adequacy of requirements engineering notations provides valuable insights for practitioners, albeit with moderate immediate practical value."
https://www.sciencedirect.com/science/article/pii/S0950584920301002,Runtime testing of context-aware variability in adaptive systems,March 2021,Not Found,Erick Barros dos=Santos: erickbarros@great.ufc.br; Rossana M.C.=Andrade: rossana@great.ufc.br; Ismayle de Sousa=Santos: ismaylesantos@great.ufc.br,"Abstract
Context:
 A Dynamically Adaptive System (DAS) supports runtime adaptations to handle changes in the 
operational environment
. These adaptations can change the system’s structure or behavior and even the logic of its adaptation mechanism. However, these adaptations may insert defects, leading the system to fail at runtime.
Objective:
 Aiming to identify these failures, testing can be executed to verify the system at runtime. Studies in the literature mostly focus on testing to verify the adaptations at design-time or functionalities at runtime, rather than exercising the adaptation mechanism at runtime. So, we propose RETAkE (RuntimE Testing of dynamically Adaptive systEms).
Method:
 RETAkE is an approach to perform the runtime testing based on the system’s context variability and feature modeling. RETAkE tests the adaptation mechanism, enabling the verification of its adaptation rules with the system’s variability model. The runtime testing is supported by the verification of behavioral properties. For the evaluation, we used the mutation testing technique with two DAS. We also conducted an evaluation to measure the overhead introduced when RETAkE is integrated to the DAS.
Results:
 RETAkE identified the mutants in the two mobile DAS, but the results vary due to the probabilistic nature of the approach to generate test sequences. Regarding the overhead, test sequences of size 30 had a low impact. However, bigger test sequences increase the overhead.
Conclusion:
 The integration of RETAkE to the DAS adaptation mechanism can support the discovery of adaptation failures that occur at runtime. Furthermore, the results of the evaluation suggest its feasibility to perform runtime testing.",Information and Software Technology,18 Mar 2025,8.0,"The RETAkE approach for runtime testing of Dynamically Adaptive Systems can support the discovery of adaptation failures, which can be beneficial for early-stage ventures relying on such systems."
https://www.sciencedirect.com/science/article/pii/S0950584920301002,Runtime testing of context-aware variability in adaptive systems,March 2021,Not Found,Erick Barros dos=Santos: erickbarros@great.ufc.br; Rossana M.C.=Andrade: rossana@great.ufc.br; Ismayle de Sousa=Santos: ismaylesantos@great.ufc.br,"Abstract
Context:
 A Dynamically Adaptive System (DAS) supports runtime adaptations to handle changes in the 
operational environment
. These adaptations can change the system’s structure or behavior and even the logic of its adaptation mechanism. However, these adaptations may insert defects, leading the system to fail at runtime.
Objective:
 Aiming to identify these failures, testing can be executed to verify the system at runtime. Studies in the literature mostly focus on testing to verify the adaptations at design-time or functionalities at runtime, rather than exercising the adaptation mechanism at runtime. So, we propose RETAkE (RuntimE Testing of dynamically Adaptive systEms).
Method:
 RETAkE is an approach to perform the runtime testing based on the system’s context variability and feature modeling. RETAkE tests the adaptation mechanism, enabling the verification of its adaptation rules with the system’s variability model. The runtime testing is supported by the verification of behavioral properties. For the evaluation, we used the mutation testing technique with two DAS. We also conducted an evaluation to measure the overhead introduced when RETAkE is integrated to the DAS.
Results:
 RETAkE identified the mutants in the two mobile DAS, but the results vary due to the probabilistic nature of the approach to generate test sequences. Regarding the overhead, test sequences of size 30 had a low impact. However, bigger test sequences increase the overhead.
Conclusion:
 The integration of RETAkE to the DAS adaptation mechanism can support the discovery of adaptation failures that occur at runtime. Furthermore, the results of the evaluation suggest its feasibility to perform runtime testing.",Information and Software Technology,18 Mar 2025,7.0,"The proposed approach RETAkE addresses a critical issue of identifying failures in dynamically adaptive systems at runtime, which can have a significant impact on early-stage ventures utilizing such systems."
https://www.sciencedirect.com/science/article/pii/S0950584920301610,Quality Assessment in Systematic Literature Reviews: A Software Engineering Perspective,February 2021,Not Found,Lanxin=Yang: yang931001@outlook.com; He=Zhang: hezhang@nju.edu.cn; Haifeng=Shen: Haifeng.Shen@acu.edu.au; Xin=Huang: njuhuangx@outlook.com; Xin=Zhou: job@wetist.com; Guoping=Rong: ronggp@nju.edu.cn; Dong=Shao: dongshao@nju.edu.cn,"Abstract
Context
: Quality Assessment (QA) of reviewed literature is paramount to a 
Systematic Literature Review
 (SLR) as the quality of conclusions completely depends on the quality of selected literature. A number of researchers in 
Software Engineering
 (SE) have developed a variety of QA instruments and also reported their challenges. We previously conducted a tertiary study on SLRs with QA from 2004 to 2013, and reported the findings in 2015.
Objective
: With the widespread use of SLRs in SE and the increasing adoption of QA in these SLRs in recent years, it is necessary to empirically investigate whether the previous conclusions are still valid and whether there are new insights to the subject in question using a larger and a more up-to-date SLR set. More importantly, we aim to depict a clear picture of QA used in SLRs in SE by aggregating and distilling good practices, including the commonly used QA instruments as well as the major roles and aspects of QA in research.
Method
: An extended tertiary study was conducted with the newly collected SLRs from 2014 to 2018 and the original SLRs from 2004 to 2013 to systematically review the QA used by SLRs in SE during the 15-year period from 2004 to 2018. In addition, this extended study also compared and contrasted the findings of the previous study conducted in 2015.
Results
: A total of 241 SLRs between 2004 and 2018 were included, from which we identified a number of QA instruments. These instruments are generally designed to focus on the rationality of study design, the rigor of study execution and analysis, and the credibility and contribution of study findings and conclusions, with the emphasis largely placed on its rigor. The quality data is mainly used for literature selection or as evidence to support conclusions.
Conclusions
: QA has received much attention in SE in more recent years and the improvement is evident since the last study in 2015. New findings show that the aims are more concise, the instruments are more diverse and rigorous, and the criteria are more thoughtful.",Information and Software Technology,18 Mar 2025,6.0,"The study on Quality Assessment in Systematic Literature Reviews provides valuable insights, but the practical impact on early-stage ventures or startups may not be as direct as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920301737,Boundary sampling to boost mutation testing for deep learning models,February 2021,Not Found,Weijun=Shen: Not Found; Yanhui=Li: yanhuili@nju.edu.cn; Yuanlei=Han: Not Found; Lin=Chen: Not Found; Di=Wu: Not Found; Yuming=Zhou: Not Found; Baowen=Xu: Not Found,"Abstract
Context: The prevalent application of 
Deep Learning
 (DL) models has raised concerns about their reliability. Due to the data-driven programming paradigm, the quality of 
test datasets
 is extremely important to gain accurate assessment of 
DL
 models. Recently, researchers have introduced mutation testing into 
DL
 testing, which applies 
mutation operators
 to generate mutants from DL models, and observes whether the 
test data
 can identify mutants to check the quality of test dataset. However, there still exist many factors (e.g., huge labeling efforts and high running cost) hindering the implementation of mutation testing for DL models.
Objective: We desire for an approach to selecting a smaller, sensitive, representative and efficient subset of the whole test dataset to promote the current mutation testing (e.g., reduce labeling and running cost) for DL Models.
Method: We propose boundary sample selection (BSS), which employs the distance of samples to decision boundary of DL models as the indicator to construct the appropriate subset. To evaluate the performance of BSS, we conduct an extensive empirical study with two widely-used datasets, three popular DL models, and 14 up-to-date DL 
mutation operators
. Results
: We observe that (1) The sizes of our subsets generated by BSS are much smaller (about 3%-20% of the whole test set). (2) Under most 
mutation operators
, our subsets are superior (about 9.94-21.63) than the whole test sets in observing mutation effects. (3) Our subsets could replace the whole test sets to a very high degree (higher than 97%) when considering mutation score. (4) The MRR values of our proposed subsets are clearly better (about 2.28-13.19 times higher) than that of the whole test sets.
Conclusions: The result shows that BSS can help testers save labelling cost, run mutation testing quickly and identify killed mutants early.",Information and Software Technology,18 Mar 2025,8.0,"The BSS approach for selecting a smaller, efficient subset of test datasets for Deep Learning models can greatly benefit startups by reducing costs and improving efficiency in testing."
https://www.sciencedirect.com/science/article/pii/S0950584920301713,Laprob: A Label propagation-Based software bug localization method,February 2021,Not Found,Zhengliang=Li: lzl@smail.nju.edu.cn; Zhiwei=Jiang: jiangzhiwei@outlook.com; Xiang=Chen: xchencs@ntu.edu.cn; Kaibo=Cao: imkbcao@gmail.com; Qing=Gu: guq@nju.edu.cn,"Abstract
Context
Bug localization, which locates suspicious snippets related to the bugs mentioned in the 
bug reports
, is time-consuming and laborious. Many automatic bug 
localization methods
 have been proposed to speed up the process of bug fixing and reduce the burden on developers. However, these methods have not fully utilized the intra-relations and inter-relations among the 
bug reports
 and the source files (i.e., call relationships between the source files).
Objective
In this paper, we propose a novel method LaProb (a label propagation-based software bug localization method) that makes full use of the intra-relations and inter-relations among the bug reports and the source files.
Method
LaProb transforms the problem of bug localization into a multi-label distribution learning problem. LaProb first constructs a BHG (Biparty Hybrid Graph) by analyzing the structures and contents of bug reports and source files, and calculates the intra-relations between pairs of bug reports and source files, as well as the inter-relations between bug reports and source files. Based on BHG, LaProb then predicts the label distribution on source files by using the label 
propagation algorithm
 for the target bug report. Finally, LaProb finishes the bug localization task by sorting the results of label propagation.
Results
The experimental results on nine open-source software projects (i.e., SWT, AspectJ, Eclipse, ZXing, SEC, HIVE, HBASE, WFLY and ROO) show that compared with several state-of-the-art methods (including BugLocator, BRTracer, BLUiR, AmaLgam, Locus and BLIZZARD), LaProb performs the best in terms of all five metrics on average. For 
MAP
 
performance measure
, LaProb achieves an improvement of 30.9%, 36.6%, 28.0%, 22.2%, 20.1% and 53.5%, respectively.
Conclusion
LaProb is capable of making full use of the intra-relations and inter-relations among the bug reports and the source files and achieves better performance than seven state-of-the-art methods.",Information and Software Technology,18 Mar 2025,9.0,"The LaProb bug localization method stands out as it improves bug fixing processes significantly, which is crucial for startups aiming to develop reliable software products efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584920302007,Community detection in software ecosystem by comprehensively evaluating developer cooperation intensity,February 2021,Not Found,Tingting=Hou: Not Found; Xiangjuan=Yao: yaoxj@cumt.edu.cn; Dunwei=Gong: Not Found,"Abstract
Context
: As soon as the concept of software ecosystem was proposed, it has aroused great interest in both academia and industry. Software ecosystem can be described as a special complex network. Community structures are critical towards understanding not only the 
network topology
 but also how the network functions. Traditional community 
detection algorithms
 in complex networks mainly utilize the 
network topology
 to measure the similarities between nodes. Because of the complexity of information interaction in software ecosystem, only considering the topology structure will lead to unreasonable division of communities.
Objective
: For solving community detection in software ecosystem more reasonably, we present a method of community detection by comprehensively evaluating developer cooperation intensity in software ecosystems.
Method
: First, we combine network topology information and developer interaction information to calculate the developer cooperation intensity, so as to deeply explore the relationship between developers from both topological and semantic properties. Then a community detection algorithm ABDCI is proposed based on the cooperation intensity of developers by referring to the 
hierarchical clustering
 idea of Louvain algorithm. Finally, this method is applied to many different types of developer networks in the software ecosystem through GitHub hosting platform.
Results
: Comparing with three classical community 
detection algorithms
, we find that the proposed method can identify a clearer community structure for the developer collaboration network in the software ecosystem.
Conclusion
: Our approach provides an effective and extensible technique for solving the community detection problem of real developer collaboration network in software ecosystem. According to our findings, we conclude that community detection algorithms based on comprehensive topological properties and semantic properties are more suitable for real communities in software ecosystems than traditional single-property algorithms.",Information and Software Technology,18 Mar 2025,5.0,"While the community detection method in software ecosystems is interesting, its practical value for startups may be limited compared to other abstracts that directly impact software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584920301956,Social network analysis of open source software: A review and categorisation,February 2021,Not Found,Kelvin=McClean: Not Found; Des=Greer: des.greer@qub.ac.uk; Anna=Jurek-Loughrey: Not Found,"Abstract
Context:
 As companies have become large users of 
Open Source Software
, it is important that they feel comfortable in their Open Source strategies. One of the critical differences between Open Source and Proprietary Software is the communication networks.
Objective:
 This paper tries to set a base for understanding how open source teams are structured and how they change. This is vital to understanding 
Open Source Software
 Communities.
Method:
 The paper looks into previous research on 
Social Network Analysis
 of Open Source Software, using a systematic literature review. Papers were gathered from Scopus, IEEEXplore and ACM Digital Library, and used or discarded based on predetermined inclusion and exclusion criteria. Research which focuses on the 
success factors
 of Open Source Software through Network Analysis is also examined.
Results:
 A subjective categorisation is established for the papers: Structure, Lifecycle and Communication. It was found that the structure of a project has a large bearing on project success, with developers having previously worked together being indicative of project success. Other structure indicators of success are having a small but structured hierarchy, a diverse user and developer base, and project prominence. However, it was found that information on how these structures appear and evolve over time is lacking, and future research into temporal data models to determine project success information is suggested.
Conclusions:
 A categorisation of existing research on 
Social Network Analysis
 is provided as a basis for further research. Further work into the lifecycle of 
OSS projects
 through Social Network Analysis of temporal project information is suggested.",Information and Software Technology,18 Mar 2025,5.0,The study provides insights into Open Source Software communities but lacks direct practical impact on European early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584920302020,Towards a unified criteria model for usability evaluation in the context of open source software based on a fuzzy Delphi method,February 2021,Not Found,Kareem A.=Dawood: Not Found; Khaironi Y.=Sharif: Not Found; Abdul A.=Ghani: Not Found; H.=Zulzalil: Not Found; A.A.=Zaidan: aws.alaa@fskik.upsi.edu.my; B.B.=Zaidan: Not Found,"Abstract
Context
A plethora of models are available for open-source software (OSS) 
usability evaluation
. However, these models lack consensus between scholars as well as standard bodies on a specific set of 
usability evaluation
 criteria. Retaining irrelevant criteria and omitting essential ones will mislead the direction of the usability evaluation.
Objective
This study introduces a three-step method to develop a usability evaluation model in the context of OSS.
Method
The fuzzy Delphi method has been employed to unify the usability evaluation criteria in the context of OSS. The first step in the method is the usability criteria analysis, which involves redefining and restructuring all collected usability criteria reported in the literature. The second step is fuzzy Delphi analysis, which includes the design and validates the fuzzy Delphi instrument and the utilisation of the fuzzy Delphi method to analyse the fuzziness consensus of experts' opinions on the usability evaluation criteria. The third step is the proposal of the OSS usability evaluation model.
Results
A total of 124 usability criteria were identified, redefined, and restructured by creating groups of related meaning criteria. The result of the groupings generated 11 main criteria; the findings of the fuzzy Delphi narrowed down the criteria to only seven. The final set of criteria was sent back to the panellists for 
reconsideration
 of their responses. The panellists verified that these criteria are suitable in the evaluation of the usability of OSS.
Discussion
The empirical analysis confirmed that the proposed evaluation model is acceptable in assessing the usability of OSS. Therefore, this model can be used as a reference metric for OSS usability evaluation which will have a practical benefit for the community in public and private organisations in helping the decision-maker to select the best OSS software package amongst the alternatives.",Information and Software Technology,18 Mar 2025,8.0,"The usability evaluation model proposed has practical benefits for the community in selecting OSS software, which can have a significant impact on European startups."
https://www.sciencedirect.com/science/article/pii/S0950584920302032,Two-level clustering of UML class diagrams based on semantics and structure,February 2021,Not Found,Zongmin=Ma: Not Found; Zhongchen=Yuan: yuanzhongchen@163.com; Li=Yan: Not Found,"Abstract
Context
The reuse of 
software design
 has been an important issue of 
software reuse
. 
UML
 
class diagrams
 are widely applied in 
software design
 and has become DE factor standard. As a result, the reuse of 
UML
 
class diagrams
 has received more attention. With the increasing number of class diagrams stored in reuse repository, their retrieval becomes a time-consuming job. The clustering can narrow down retrieval range and improve the retrieval efficiency. But few efforts have been done in clustering 
UML
 class diagrams. This paper tries to propose a 
clustering approach
 for 
UML
 class diagrams.
Objective
This paper proposes a two-level clustering of UML class diagrams, namely, semantic clustering and structural clustering. The UML class diagrams stored in reuse repository are clustered into a few domains based on semantics in the first level and a few categories based on structure in the second level.
Method
We propose a 
clustering algorithm
 named 
CUFS
, in which the idea of partitioning and 
hierarchical clustering
 is combined and feature similarity is proposed for the similarity measure between two clusters in order to merge clusters. A better feature representation of a cluster, namely, feature class diagram, is proposed in this paper. In order to form each sub-cluster, the semantic and 
structural similarities
 between UML class diagrams are defined, respectively.
Results
A series of experimental results show that, the proposed feature similarity measure not only speeds up the 
clustering process
, but also expresses the closeness degree between clusters for merging clusters. The proposed algorithm shows a good 
clustering quality
 and efficiency under the condition of different size and distribution of UML class diagrams.
Conclusion
It is concluded that the proposed two-level 
clustering method
 considers both semantics and structure contained in a class diagram, which can flexibly adapt to different clustering requirements. Also, the proposed 
clustering algorithm
 performs better than other related algorithms, regardless of in semantic, structural and hybrid clustering.",Information and Software Technology,18 Mar 2025,7.0,"The two-level clustering approach for UML class diagrams can improve retrieval efficiency, which can benefit European early-stage ventures working with software design and reuse."
https://www.sciencedirect.com/science/article/pii/S0950584920300033,Large-scale intent analysis for identifying large-review-effort code changes,February 2021,Not Found,Song=Wang: wangsong@eecs.yorku.ca; Chetan=Bansal: chetanb@microsoft.com; Nachiappan=Nagappan: nachin@microsoft.com,"Abstract
Context
: Code changes to software occur due to various reasons such as bug fixing, new feature addition, and 
code refactoring
. Change intents have been studied for years to help developers understand the rationale behind code commits. However, in most existing studies, the intent of the change is rarely leveraged to provide more specific, context aware analysis.
Objective
: In this paper, we present the first study to leverage change intent to characterize and identify Large-Review-Effort (
LRE
) changes—changes with large review effort.
Method
: Specifically, we first propose a feedback-driven and heuristics-based approach to identify change intents of code changes. We then characterize the changes regarding review effort by using various features extracted from change metadata and the change intents. We further explore the feasibility of automatically classifying 
LRE
 changes. We conduct our study on four large-scale projects, one from 
Microsoft
 and three are 
open source projects
, i.e., Qt, 
Android
, and OpenStack.
Results
: Our results show that, (i) code changes with some intents (i.e., Feature and Refactor) are more likely to be LRE changes, (ii) 
machine learning
 based prediction models are applicable for identifying 
LRE
 changes, and (iii) prediction models built for code changes with some intents achieve better performance than prediction models without considering the change intent, the improvement in AUC can be up to 19 percentage points and is 7.4 percentage points on average.
Conclusion
: The change intent analysis and its application on LRE identification proposed in this study has already been used in 
Microsoft
 to provide the review effort and intent information of changes for reviewers to accelerate the review process. To show how to deploy our approaches in real-world practice, we report a 
case study
 of developing and deploying the intent analysis system in 
Microsoft
. Moreover, we also evaluate the usefulness of our approaches by using a questionnaire survey. The feedback from developers demonstrate its practical value.",Information and Software Technology,18 Mar 2025,9.0,"The study leverages change intent analysis to identify Large-Review-Effort changes, providing practical value for developers and accelerating the review process, benefiting European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920300021,RSTrace+: Reviewer suggestion using software artifact traceability graphs,February 2021,Not Found,Emre=Sülün: emre.sulun@bilkent.edu.tr; Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr; Uğur=Doğrusöz: ugur@cs.bilkent.edu.tr,"Abstract
Context:
Various types of artifacts (requirements, 
source code
, test cases, documents, etc.) are produced throughout the lifecycle of a software. These artifacts are connected with each other via 
traceability links
 that are stored in modern 
application lifecycle management
 repositories. Throughout the lifecycle of a software, various types of changes can arise in any one of these artifacts. It is important to review such changes to minimize their potential 
negative impacts
. To make sure the review is conducted properly, the reviewer(s) should be chosen appropriately.
Objective:
We previously introduced a novel approach, named RSTrace, to automatically recommend reviewers that are best suited based on their familiarity with a given artifact. In this study, we introduce an advanced version of RSTrace, named RSTrace+ that accounts for recency information of 
traceability links
 including practical tool support for GitHub.
Methods:
In this study, we conducted a series of experiments on finding the appropriate code reviewer(s) using RSTrace+ and provided a comparison with the other code reviewer recommendation approaches.
Results:
We had initially tested RSTrace+ on an 
open source project
 (Qt 3D Studio) and achieved a top-3 accuracy of 0.89 with an MRR (mean reciprocal ranking) of 0.81. In a further empirical evaluation of 40 open source projects, we compared RSTrace+ with Naive-Bayes, RevFinder and Profile based approach, and observed higher accuracies on the average.
Conclusion:
We confirmed that the proposed reviewer recommendation approach yields promising top-k and MRR scores on the average compared to the existing reviewer recommendation approaches. Unlike other code reviewer recommendation approaches, RSTrace+ is not limited to recommending reviewers for 
source code
 artifacts and can potentially be used for recommending reviewers for other types of artifacts. Our approach can also visualize the affected artifacts and help the developer to make assessments of the potential impacts of change to the reviewed artifact.",Information and Software Technology,18 Mar 2025,8.0,"The advanced version of RSTrace for recommending reviewers in software development has practical implications for improving review processes, which can benefit European startups working with software artifacts."
https://www.sciencedirect.com/science/article/pii/S0950584919302204,Performance analysis of out-of-distribution detection on trained neural networks,February 2021,Not Found,Jens=Henriksson: jens.henriksson@semcon.com; Christian=Berger: christian.berger@gu.se; Markus=Borg: Not Found; Lars=Tornberg: Not Found; Sankar Raman=Sathyamoorthy: Not Found; Cristofer=Englund: Not Found,"Abstract
Context
Deep Neural Networks
 (DNN) have shown great promise in various domains, for example to support pattern recognition in medical imagery. However, DNNs need to be tested for robustness before being deployed in safety critical applications. One common challenge occurs when the model is exposed to data samples outside of the 
training data
 domain, which can yield to outputs with high confidence despite no prior knowledge of the given input.
Objective
The aim of this paper is to investigate how the performance of detecting out-of-distribution (OOD) samples changes for 
outlier detection
 methods (e.g., supervisors) when DNNs become better on 
training samples
.
Method
Supervisors are components aiming at detecting out-of-distribution samples for a DNN. The experimental setup in this work compares the performance of supervisors using metrics and datasets that reflect the most common setups in related works. Four different DNNs with three different supervisors are compared during different stages of training, to detect at what point during training the performance of the supervisors begins to deteriorate.
Results
Found that the 
outlier detection
 performance of the supervisors increased as the accuracy of the underlying DNN improved. However, all supervisors showed a large variation in performance, even for variations of network parameters that marginally changed the model accuracy. The results showed that understanding the relationship between training results and supervisor performance is crucial to improve a model’s robustness.
Conclusion
Analyzing DNNs for robustness is a challenging task. Results showed that variations in model parameters that have small variations on model predictions can have a large impact on the out-of-distribution detection performance. This kind of behavior needs to be addressed when DNNs are part of a safety critical application and hence, the necessary safety argumentation for such systems need be structured accordingly.",Information and Software Technology,18 Mar 2025,7.0,"This abstract addresses the crucial issue of detecting out-of-distribution samples in deep neural networks, highlighting the importance of model robustness for safety critical applications."
https://www.sciencedirect.com/science/article/pii/S0950584920301920,Software engineering and advanced applications conference 2019 – selected papers,February 2021,Not Found,Rafael=Capilla: Not Found; Miroslaw=Staron: special_issue@staron.nu,"Abstract
Software Engineering and Advanced Applications (SEAA) is a long-standing international forum for researchers, practitioners, and students to present and discuss the latest innovations, trends, experiences, and concerns in the field of Software Engineering and Advanced Applications in information technology for software-intensive systems. In this special issue, we present a selection of papers which show the current trends in software engineering – improved systematic reviews, deep learning and cloud computing.",Information and Software Technology,18 Mar 2025,5.0,"This abstract discusses general trends in software engineering and advanced applications, but lacks specific impact on early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S0950584920300070,A comprehensive empirical evaluation of generating test suites for mobile applications with diversity,February 2021,Not Found,Thomas=Vogel: thomas.vogel@informatik.hu-berlin.de; Chinh=Tran: mail@chinhtran.de; Lars=Grunske: grunske@informatik.hu-berlin.de,"Abstract
Context:
 In search-based 
software engineering
 we often use popular heuristics with 
default configurations
, which typically lead to suboptimal results, or we perform experiments to identify configurations on a trial-and-error basis, which may lead to better results for a specific problem. We consider the problem of generating test suites for mobile applications (apps) and rely on 
Sapienz
, a state-of-the-art approach to this problem that uses a popular heuristic (NSGA-II) with a default configuration. 
Objective:
 We want to achieve better results in generating test suites with 
Sapienz
 while avoiding trial-and-error experiments to identify a more suitable configuration of 
Sapienz
. 
Method:
 We conducted a fitness landscape analysis of 
Sapienz
 to analytically understand the search problem, which allowed us to make informed decisions about the heuristic and configuration of 
Sapienz
 when developing 
Sapienz
div
. We comprehensively evaluated 
Sapienz
div
 in a head-to-head comparison with 
Sapienz
 on 34 apps. 
Results:
 Analyzing the fitness landscape of 
Sapienz
, we observed a lack of diversity of the evolved test suites and a stagnation of the search after 25 generations. 
Sapienz
div
 realizes mechanisms that preserve the diversity of the test suites being evolved. The evaluation showed that 
Sapienz
div
 achieves better or at least similar test results than 
Sapienz
 concerning coverage and the number of revealed faults. However, 
Sapienz
div
 typically produces longer test sequences and requires more 
execution time
 than 
Sapienz
. 
Conclusions:
 The understanding of the search problem obtained by the fitness landscape analysis helped us to find a more suitable configuration of 
Sapienz
 without trial-and-error experiments. By promoting diversity of test suites during the search, improved or at least similar test results in terms of faults and coverage can be achieved.",Information and Software Technology,18 Mar 2025,8.0,"This abstract presents a practical approach to improving test suites for mobile applications, focusing on avoiding trial-and-error experiments and achieving better results."
https://www.sciencedirect.com/science/article/pii/S0950584920300069,A Systematic Comparison of search-Based approaches for LDA hyperparameter tuning,February 2021,"Topic modeling, Latent dirichlet allocation, Search-based software engineering, Metaheuristic search, Duplicate bug report, Hyperparameter optimization",Annibale=Panichella: a.panichella@tudelft.nl,"Abstract
Context:
Latent Dirichlet Allocation
 (LDA) has been successfully used in the literature to extract topics from software documents and support developers in various 
software engineering
 tasks. While LDA has been mostly used with default settings, previous studies showed that default hyperparameter values generate sub-optimal topics from software documents.
Objective:
 Recent studies applied meta-heuristic search (mostly evolutionary algorithms) to configure LDA in an unsupervised and automated fashion. However, previous work advocated for different meta-heuristics and surrogate metrics to optimize. The objective of this paper is to shed light on the influence of these two factors when tuning LDA for SE tasks.
Method:
We empirically evaluated and compared seven state-of-the-art meta-heuristics and three alternative surrogate metrics (i.e., fitness functions) to solve the problem of identifying duplicate 
bug reports
 with LDA. The benchmark consists of ten real-world and open-source projects from the 
Bench4BL
 dataset.
Results:
Our results indicate that (1) meta-heuristics are mostly comparable to one another (except for random search and CMA-ES), and (2) the choice of the surrogate metric impacts the quality of the generated topics and the tuning overhead. Furthermore, calibrating LDA helps identify twice as many duplicates than untuned LDA when inspecting the top five past similar reports.
Conclusion:
No meta-heuristic and/or fitness function outperforms all the others, as advocated in prior studies. However, we can make recommendations for some combinations of meta-heuristics and fitness functions over others for practical use. Future work should focus on improving the surrogate metrics used to calibrate/tune LDA in an unsupervised fashion.",Information and Software Technology,18 Mar 2025,6.0,"This abstract delves into the optimization of Latent Dirichlet Allocation for software engineering tasks, providing insights but lacking a direct impact on startups or early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584920301580,Recommending tags for pull requests in GitHub,January 2021,Not Found,Jing=Jiang: jiangjing@buaa.edu.cn; Qiudi=Wu: 1040814720@qq.com; Jin=Cao: 13277061183@163.com; Xin=Xia: xin.xia@monash.edu; Li=Zhang: lily@buaa.edu.cn,"Abstract
Context
In GitHub, contributors make code changes, then create and 
submit
 pull requests to projects. Tags are a simple and effective way to attach additional information to pull requests and facilitate their organization. However, little effort has been devoted to study pull requests’ tags in GitHub.
Objective
Our objective in this paper is to propose an approach which automatically recommends tags for pull requests in GitHub.
Method
We make a survey on the usage of tags in pull requests. Survey results show that tags are useful for developers to track, search or classify pull requests. But some respondents think that it is difficult to choose right tags and keep consistency of tags. 60.61% of respondents think that a 
tag recommendation
 tool is useful. In order to help developers choose tags, we propose a method FNNRec which uses feed-forward neural network to analyze titles, description, file paths and contributors.
Results
We evaluate the effectiveness of FNNRec on 10 projects containing 68,497 tagged pull requests. The experimental results show that on average, FNNRec outperforms approach TagDeepRec and TagMulRec by 62.985% and 24.953% in terms of 
F
1
−
s
c
o
r
e
@
3
,
 respectively.
Conclusion
FNNRec is useful to find appropriate tags and improve tag setting process in GitHub.",Information and Software Technology,18 Mar 2025,9.0,"This abstract introduces a method to recommend tags for pull requests in GitHub, demonstrating clear practical value and potential impact on software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584920301701,Integrated framework for incorporating sustainability design in software engineering life-cycle: An empirical study,January 2021,Not Found,Theresia Ratih Dewi=Saputri: trdsaputri@ajou.ac.kr; Seok-Won=Lee: leesw@ajou.ac.kr,"Abstract
Context:
Owing to the critical role of software-intensive systems in society, software engineers have the accountability to consider sustainability as a goal while structuring a software system. However, there are no 
practical guidelines
 providing a tangible decomposition of the sustainability aspect. Moreover, there are limited quantifiable methods to support 
sustainable design
 and analysis.
Objectives:
The purpose of this study is to help software practitioners to take sustainability into account by providing systematic guidelines for the software 
engineering process
. We propose a framework that presents a meta model to decompose sustainability requirements and an assessment approach to evaluate sustainability achievements.
Method:
This work presents an integrated framework that combines a goal-based approach, scenario-based approach, and feature modeling to gather sustainability 
related requirements
 and corresponding features. For sustainability assessment, software analysis and 
machine learning techniques
 are utilized to analyze software products based on sustainability metrics and criteria.
Results and Conclusions:
The empirical study conducted with participants from academia and industry revealed that the proposed framework improves participant’s ability to consider sustainability aspect in their 
software engineering
 tasks through focusing on requirements, design, and evaluation. With the provided sustainability meta-model, the participants could extract more stakeholders, requirements, and features in shorter time. Moreover, the empirical study result also demonstrated that this study is capable to indicate specific scenarios that should be redesigned to improve the sustainability achievements level.",Information and Software Technology,18 Mar 2025,6.0,"The study provides systematic guidelines for software practitioners to consider sustainability in software engineering processes, which could benefit early-stage ventures by promoting sustainable practices."
https://www.sciencedirect.com/science/article/pii/S0950584920301749,Governance and Management of Green IT: A Multi-Case Study,January 2021,Not Found,J. David=Patón-Romero: JoseDavid.Paton@gmail.com; Maria Teresa=Baldassarre: mariateresa.baldassarre@uniba.it; Moisés=Rodríguez: mrodriguez@aqclab.es; Per=Runeson: per.runeson@cs.lth.se; Martin=Höst: martin.host@cs.lth.se; Mario=Piattini: Mario.Piattini@uclm.es,"Abstract
Context
The changes that are taking place with respect to environmental sensitivity are forcing organizations to adopt a new approach to this problem. Implementing 
sustainability
 initiatives has become a priority for the social and environmental awareness of organizations that want to stay ahead of the curve. One of the business areas that has, more than others, proven to be a vital asset and a potential ally of the environment, is the area of Information Technology (IT). Through this area, Green IT practices advocate 
sustainability
 in and by IT. However, organizations have a significant handicap in this regard, due to the lack of specific Green IT standards and frameworks that help them carry out this type of sustainability practices.
Objective
We have developed the 
“Governance and Management Framework for Green IT”
 (GMGIT), which establishes the necessary characteristics to implement Green IT in organizations, from the point of view of the governance and management of this area. After developing and validating a first version of this framework, we have performed a set of improvements, obtaining the GMGIT 2.0, which we want to validate.
Method
We have conducted a series of empirical validations at international level based on 
case studies
, whose characteristics and results are presented in this study.
Results
The results of this multi-case study show an example of the current situation of organizations in Green IT, as well as the resolution of problems encountered during the validations conducted with the GMGIT 1.0.
Conclusion
The findings obtained demonstrate the usefulness, applicability, and validity of the framework when implementing, auditing, and improving Green IT in organizations in a systematic and progressive manner.",Information and Software Technology,18 Mar 2025,4.0,"The framework for Green IT governance and management could have some impact on European early-stage ventures, but the lack of specific Green IT standards may limit its immediate practical value."
https://www.sciencedirect.com/science/article/pii/S0950584920301841,Statement frequency coverage: A code coverage criterion for assessing test suite effectiveness,January 2021,Not Found,Alireza=Aghamohammadi: aaghamohammadi@ce.sharif.edu; Seyed-Hassan=Mirian-Hosseinabadi: hmirian@sharif.edu; Sajad=Jalali: sajalali@ce.sharif.edu,"Abstract
Context:
Software testing is a pivotal activity in the development of high-quality software. As software is evolving through its life cycle, the need for a fault-revealing criterion assessing the effectiveness of the test suite grows. Over the years, researchers have proposed coverage-based criteria, including statement and branch coverage, to solve this issue. In literature, the effectiveness of such criteria is attested in terms of their correlations with the mutation score.
Objective:
In this paper, we aim at proposing a coverage-based criterion named statement frequency coverage, which outperforms statement and branch coverage in terms of correlation with mutation score.
Method:
To this end, we incorporated the frequency of executed statements into 
statement coverage
 and created a coverage-based criterion for assessing test suite effectiveness. Statement frequency coverage assigns a continuous value to a statement whose value is proportional to the number of times executed during test execution. We evaluated our approach on 22 real-world Python projects with more than 118 000 source lines of code (without blank lines, comments, and test cases) and 21 000 test cases through measuring the correlation between statement frequency coverage and corresponding mutation score.
Results:
The results show that statement frequency coverage outperforms statement and branch coverage criteria. The correlation between it and the corresponding mutation score is higher than the correlation of statement and branch coverage with their mutation score. The results also show that unlike statement and branch coverage, there is no statistical difference between statement frequency coverage and mutation score.
Conclusion:
Statement frequency coverage is a better choice compared to statement and branch coverage in assessing test suite effectiveness in the real-world setting. Furthermore, we demonstrate that although statement frequency coverage subsumes 
statement coverage
, it is incomparable to branch coverage under the adequate test suite condition.",Information and Software Technology,18 Mar 2025,8.0,The proposed coverage-based criterion for assessing test suite effectiveness could greatly benefit European early-stage ventures by improving software quality and efficiency.
https://www.sciencedirect.com/science/article/pii/S0950584920301853,A unified framework for declarative debugging and testing,January 2021,Not Found,Rafael=Caballero: rafacr@ucm.es; Enrique=Martin-Martin: emartinm@ucm.es; Salvador=Tamarit: stamarit@dsic.upv.es,"Abstract
Context:
Debugging is the most challenging and time consuming task in software development. However, it is not properly integrated in the software 
development cycle
, because the result of so much effort is not available in further iterations of the cycle, and the debugging process itself does not benefit from the outcome of other phases such as testing.
Objective:
We propose to integrate debugging and testing within a single unified framework where each phase generates useful information for the other and the outcomes of each phase are reused.
Method:
We consider a declarative debugging setting that employs tests to automatically entail the validity of some subcomputations, thus decreasing the time and effort needed to find a bug. Additionally, the 
debugger
 stores as new tests the information collected from the user during the debugging phase. This information becomes part of the program test suite, and can be used in future 
debugging sessions
, and also as 
regression tests
.
Results:
We define a general framework where declarative debugging establishes a bidirectional collaboration with testing. The new setting preserves the properties of the underlying declarative debugging framework (weak completeness and soundness) while generating test cases that can be used later in other 
debugging sessions
 or even in other cycles of the software development. The proposed framework is general enough to be instantiated to very different programming languages: Erlang (functional), Java (imperative, object-oriented), and 
SQL
 (data query); and the experimental results obtained for Erlang programs validate the effectiveness of the framework.
Conclusion:
We propose a general unified framework for debugging and testing that simplifies each phase and maximizes the 
reusability
 of the outcomes in the different phases of the software 
development cycle
, therefore reducing the overall effort.",Information and Software Technology,18 Mar 2025,7.0,"Integrating debugging and testing within a unified framework could streamline software development processes for early-stage ventures, potentially saving time and effort in debugging cycles."
https://www.sciencedirect.com/science/article/pii/S0950584920301877,What skills do IT companies look for in new developers? A study with Stack Overflow jobs,January 2021,Not Found,João Eduardo=Montandon: joao.montandon@dcc.ufmg.br; Cristiano=Politowski: Not Found; Luciana Lourdes=Silva: Not Found; Marco Tulio=Valente: Not Found; Fabio=Petrillo: Not Found; Yann-Gaël=Guéhéneuc: Not Found,"Abstract
Context:
 There is a growing demand for information on how IT companies look for candidates to their open positions. 
Objective:
 This paper investigates which hard and soft skills are more required in IT companies by analyzing the description of 20,000 job opportunities. 
Method:
 We applied open card sorting to perform a high-level analysis on which types of hard skills are more requested. Further, we manually analyzed the most mentioned soft skills. 
Results:
 Programming languages are the most demanded hard skills. Communication, collaboration, and problem-solving are the most demanded soft skills. 
Conclusion:
 We recommend developers to organize their resumé according to the positions they are applying. We also highlight the importance of soft skills, as they appear in many job opportunities.",Information and Software Technology,18 Mar 2025,5.0,"Analyzing the skills required in IT job opportunities may provide some insights for European early-stage ventures, but the practical impact on startups may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920301865,On the influence of model fragment properties on a machine learning-based approach for feature location,January 2021,Not Found,Manuel=Ballarín: mballarin@usj.es; Ana C.=Marcén: acmarcen@usj.es; Vicente=Pelechano: pele@dsic.upv.es; Carlos=Cetina: ccetina@usj.es,"Abstract
Context:
Leveraging 
machine learning techniques
 to address feature location on models has been gaining attention. Machine learning techniques empower software product companies to take advantage of the knowledge and the experience to improve the performance of the feature location process. Most of the machine learning-based works for feature location on models report the 
machine learning techniques
 and the tuning parameters in detail. However, these works focus on the size and the distribution of the data sets, neglecting the properties of their contents.
Objective:
In this paper, we analyze the influence of three model fragment properties (density, multiplicity, and dispersion) on a machine learning-based approach for feature location.
Method:
The analysis of these properties is based on an industrial case provided by CAF, a worldwide provider of railway solutions. The test cases were evaluated through a 
machine learning
 technique that uses different subsets of a 
knowledge base
 to learn how to locate unknown features.
Results:
Results show that the density and dispersion properties have a direct impact on the results. In our 
case study
, the model fragments with extra-small density values achieve results with up to 43% more precision, 41% more recall, 42% more F-measure, and 0.53 more Matthews 
Correlation Coefficient
 (MCC) than the model fragments with other density values. On the other hand, the model fragments with extra-small and small dispersion values achieve results with up to 53% more precision, 52% more recall, 52% more F-measure, and 0.57 more MCC than the model fragments with other dispersion values.
Conclusions:
The analysis of the results shows that both density and dispersion properties significantly influence the results. These results can serve not only to improve the reports by means of the model fragment properties, but also to be able to compare machine learning-based feature location approaches fairly improving the feature location results.",Information and Software Technology,18 Mar 2025,7.0,"The analysis of model fragment properties in feature location can significantly improve machine learning-based approaches, providing practical value for improving feature location results in software product companies."
https://www.sciencedirect.com/science/article/pii/S0950584920301889,COSTE: Complexity-based OverSampling TEchnique to alleviate the class imbalance problem in software defect prediction,January 2021,Not Found,Shuo=Feng: shuofeng5-c@my.cityu.edu.hk; Jacky=Keung: jacky.keung@cityu.edu.hk; Xiao=Yu: xyu224-c@my.cityu.edu.hk; Yan=Xiao: xiaoyan.hhu@gmail.com; Kwabena Ebo=Bennin: kwabena.bennin@wur.nl; Md Alamgir=Kabir: makabir4-c@my.cityu.edu.hk; Miao=Zhang: miazhang9-c@my.cityu.edu.hk,"Abstract
Context:
Generally, there are more non-defective instances than defective instances in the datasets used for 
software defect
 prediction (SDP), which is referred to as the 
class imbalance problem
. Oversampling techniques are frequently adopted to alleviate the problem by generating new synthetic defective instances. Existing techniques generate either near-duplicated instances which result in overgeneralization (high probability of false alarm, 
p
f
) or overly diverse instances which hurt the prediction model’s ability to find defects (resulting in low probability of detection, 
p
d
). Furthermore, when existing oversampling techniques are applied in SDP, the effort needed to inspect the instances with different complexity is not taken into consideration.
Objective:
In this study, we introduce Complexity-based OverSampling TEchnique (COSTE), a novel oversampling technique that can achieve low 
p
f
 and high 
p
d
 simultaneously. Meanwhile, COSTE also performs better in terms of 
N
o
r
m
(
p
o
p
t
)
 and 
A
C
C
, two effort-aware measures that consider the testing effort.
Method:
COSTE combines pairs of defective instances with similar complexity to generate synthetic instances, which improves the diversity within the data, maintains the ability of prediction models to find defects, and takes the different testing effort needed for different instances into consideration. We conduct experiments to compare COSTE with Synthetic Minority Oversampling TEchnique, Borderline-SMOTE, Majority Weighted Minority Oversampling TEchnique and MAHAKIL.
Results:
The experimental results on 23 releases of 10 projects show that COSTE greatly improves the diversity of the synthetic instances without compromising the ability of prediction models to find defects. In addition, COSTE outperforms the other oversampling techniques under the same testing effort. The statistical analysis indicates that COSTE’s ability to outperform the other oversampling techniques is significant under the statistical Wilcoxon rank sum test and Cliff’s effect size.
Conclusion:
COSTE is recommended as an efficient alternative to address the class imbalance problem in SDP.",Information and Software Technology,18 Mar 2025,9.0,"The COSTE oversampling technique addresses the class imbalance problem in software defect prediction, achieving low false alarm rates and high detection rates while considering testing effort, providing a practical and efficient solution."
https://www.sciencedirect.com/science/article/pii/S0950584920301919,Evaluating the effects of similar-class combination on class integration test order generation,January 2021,Not Found,Miao=Zhang: miazhang9-c@my.cityu.edu.hk; Jacky Wai=Keung: jacky.Keung@cityu.edu.hk; Yan=Xiao: dcsxan@nus.edu.sg; Md Alamgir=Kabir: makabir4-c@my.cityu.edu.hk,"Abstract
Context:
In integration testing, the order in which classes are integrated and tested is significant for the construction of test stubs. With the existing approaches, it is usually difficult to generate the sub-optimal test orders for real applications, which have large numbers of classes.
Objective:
There exist moderately large numbers of classes in software systems, which is one of the main factors that complicate the generation of class integration test order (CITO). The main objectives of this study are reducing the problem space for CITO generation, and minimizing the stubbing cost of the generated test orders.
Method:
The approach proposed in this study is based on the hypothesis that similar-class combination can remove class dependencies and yield a smaller problem space. Identical class dependence and symmetric classes are the two main properties that are used to identify similar classes. In addition, a new cycle-breaking algorithm is introduced to minimize the stubbing cost of the generated test orders, which fully considers the two factors (number of test stubs and the corresponding stubbing complexity) that affect the overall stubbing cost. Empirical experiments are conducted on nine open-source Java programs to evaluate the performance of the proposed approach.
Results:
With similar-class combination, the proposed approach reduced the numbers of classes and class dependencies by over 10% and 6%, respectively, for six programs. Moreover, for four programs, the proposed approach reduced the number of cycles among class dependencies by more than 20%. The cycle-breaking algorithm achieved reduction of more than 13% in the stubbing cost, thus outperforming other competing techniques.
Conclusions:
The proposed method relies on the two aforementioned important properties to identify similar classes, and these properties are known to significantly improve the performance of CITO generation. The results obtained in this study confirmed the capability of the proposed approach in terms of minimizing the number of classes and class dependencies in programs. It outperformed other competing methods in minimizing the stubbing costs of the generated test orders.",Information and Software Technology,18 Mar 2025,6.0,"The proposed method for class integration test order generation shows improvements in reducing class dependencies and stubbing costs, which can benefit integration testing in software systems with moderately large numbers of classes."
https://www.sciencedirect.com/science/article/pii/S0950584920301890,A Method to Estimate Software Strategic Indicators in Software Development: An Industrial Application,January 2021,Not Found,Martí=Manzano: mmanzano@essi.upc.edu; Claudia=Ayala: Not Found; Cristina=Gómez: Not Found; Antonin=Abherve: Not Found; Xavier=Franch: Not Found; Emilia=Mendes: Not Found,"Abstract
Context
Exploiting software development related data from software-development intensive organizations to support tactical and strategic decision making is a challenge. Combining data-driven approaches with expert knowledge has been highlighted as a sensible approach for leading software-development intensive organizations to rightful decision-making improvements. However, most of the existing proposals lack of important aspects that hinders their industrial uptake such as: 
customization
 guidelines to fit the proposals to other contexts and/or automatic or semi-automatic data collection support for putting them forward in a real organization. As a result, existing proposals are rarely used in the industrial context.
Objective
Support software-development intensive organizations with guidance and tools for exploiting software development related data and expert knowledge to improve their decision making.
Method
We have developed a novel method called SESSI (Specification and Estimation of Software Strategic Indicators) that was articulated from industrial experiences with Nokia, Bittium, Softeam and iTTi in the context of Q-Rapids European project following a design science approach. As part of the industrial 
summative evaluation
, we performed the first 
case study
 focused on the application of the method.
Results
We detail the phases and steps of the SESSI method and illustrate its application in the development of ModelioNG, a software product of Modeliosoft development firm.
Conclusion
The application of the SESSI method in the context of ModelioNG 
case study
 has provided us with useful feedback to improve the method and has evidenced that applying the method was feasible in this context.",Information and Software Technology,18 Mar 2025,5.0,"The SESSI method aims to support software development intensive organizations with decision-making using software development data, although the industrial application and impact may require further validation and evidence of practical value."
https://www.sciencedirect.com/science/article/pii/S0950584920301476,Exploring software bug-proneness based on evolutionary clique modeling and analysis,December 2020,Not Found,Ran=Mo: moran@mail.ccnu.edu.cn; Zhen=Yin: yinzhen0906@126.com,"Abstract
Context:
Even if evolutionary coupling between files has been widely used for various studies, such as change impact analysis, 
defect prediction
, and 
software design
 analysis etc., there has little work focusing on studying the linkage among evolutionary coupled files.
Objective:
In this paper, we propose a novel model, 
evolutionary clique (EClique)
, to characterize evolutionary coupled files as maintainable groups for bug fixes, analyze their bug-proneness and examine the possible causes of the bug-proneness.
Methods:
To identify ECliques from a project, we propose two history measures to reason about the evolutionary coupling between files, and create a novel 
clustering algorithm
. Given the evolutionary coupling information, our 
clustering algorithm
 will automatically identify ECliques in a project.
Results:
We conduct analyses on 33,099 commits of ten 
open source projects
 to evaluate the usefulness of our 
EClique
 modeling and analysis approach: (1) The results show that files involved in an 
EClique
 are more likely to share similar design characteristics and change together for resolving bugs; (2) The results also show that the identified ECliques significantly contribute to a project’s bug-proneness. Meanwhile, the majority of a project’s bug-proneness can be captured by just a few ECliques which only contain a small portion of files; (3) Finally, we qualitatively demonstrate that bug-prone ECliques often exhibit design problems that propagate changes among files and can potentially be the causes of bug-proneness.
Conclusion:
To reduce the bug-proneness of a software project, practitioners should pay attention to the identified ECliques, and resolve design problems embedded in these ECliques.",Information and Software Technology,18 Mar 2025,8.0,"The EClique model provides a novel approach to characterizing evolutionary coupled files for bug fixes, with significant findings on bug-proneness and design characteristics, offering valuable insights for bug reduction in software projects."
https://www.sciencedirect.com/science/article/pii/S0950584920301476,Exploring software bug-proneness based on evolutionary clique modeling and analysis,December 2020,Not Found,Ran=Mo: moran@mail.ccnu.edu.cn; Zhen=Yin: yinzhen0906@126.com,"Abstract
Context:
Even if evolutionary coupling between files has been widely used for various studies, such as change impact analysis, 
defect prediction
, and 
software design
 analysis etc., there has little work focusing on studying the linkage among evolutionary coupled files.
Objective:
In this paper, we propose a novel model, 
evolutionary clique (EClique)
, to characterize evolutionary coupled files as maintainable groups for bug fixes, analyze their bug-proneness and examine the possible causes of the bug-proneness.
Methods:
To identify ECliques from a project, we propose two history measures to reason about the evolutionary coupling between files, and create a novel 
clustering algorithm
. Given the evolutionary coupling information, our 
clustering algorithm
 will automatically identify ECliques in a project.
Results:
We conduct analyses on 33,099 commits of ten 
open source projects
 to evaluate the usefulness of our 
EClique
 modeling and analysis approach: (1) The results show that files involved in an 
EClique
 are more likely to share similar design characteristics and change together for resolving bugs; (2) The results also show that the identified ECliques significantly contribute to a project’s bug-proneness. Meanwhile, the majority of a project’s bug-proneness can be captured by just a few ECliques which only contain a small portion of files; (3) Finally, we qualitatively demonstrate that bug-prone ECliques often exhibit design problems that propagate changes among files and can potentially be the causes of bug-proneness.
Conclusion:
To reduce the bug-proneness of a software project, practitioners should pay attention to the identified ECliques, and resolve design problems embedded in these ECliques.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584920301579,Predicting continuous integration build failures using evolutionary search,December 2020,Not Found,Islem=Saidani: islem.saidani.1@ens.etsmlt.ca; Moataz=Chouchen: moataz.chouchen.1@ens.etsmtl.ca; Mohamed Wiem=Mkaouer: mwmvse@rit.edu,"Abstract
Context:
 Continuous Integration (CI) is a 
common practice
 in modern software development and it is increasingly adopted in the open-source as well as the software industry markets. CI aims at supporting developers in integrating code changes constantly and quickly through an automated build process. However, in such context, the build process is typically time and resource-consuming which requires a high maintenance effort to avoid build failure.
Objective:
 The goal of this study is to introduce an automated approach to cut the expenses of CI build time and provide support tools to developers by predicting the CI build outcome.
Method:
 In this paper, we address problem of CI build failure by introducing a novel search-based approach based on Multi-Objective 
Genetic Programming
 (MOGP) to build a CI build failure prediction model. Our approach aims at finding the best combination of CI built features and their appropriate threshold values, based on two conflicting objective functions to deal with both failed and passed builds.
Results:
 We evaluated our approach on a benchmark of 56,019 builds from 10 large-scale and long-lived software projects that use the Travis CI build system. The statistical results reveal that our approach outperforms the state-of-the-art techniques based on 
machine learning
 by providing a better balance between both failed and passed builds. Furthermore, we use the generated prediction rules to investigate which factors impact the CI build results, and found that features related to (1) specific statistics about the project such as team size, (2) last build information in the current build and (3) the types of changed files are the most influential to indicate the potential failure of a given build.
Conclusion:
 This paper proposes a multi-objective search-based approach for the problem of CI build failure prediction. The performances of the models developed using our MOGP approach were statistically better than models developed using 
machine learning techniques
. The experimental results show that our approach can effectively reduce both 
false negative
 rate and false positive rate of CI build failures in highly imbalanced datasets.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584920301592,Reducing efforts of software engineering systematic literature reviews updates using text classification,December 2020,Not Found,Willian Massami=Watanabe: http://www.wwatana.be/; Katia Romero=Felizardo: katiascannavino@utfpr.edu.br; Arnaldo=Candido: arnaldoc@utfpr.edu.br; Érica Ferreira=de Souza: ericasouza@utfpr.edu.br; José Ede de Campos=Neto: Not Found; Nandamudi Lankalapalli=Vijaykumar: vijay.nl@inpe.br,"Abstract
Context
Systematic Literature Reviews (SLRs) are frequently used to synthesize evidence in 
Software Engineering
 (SE), however replicating and keeping SLRs up-to-date is a major challenge. The activity of studies selection in SLR is labor intensive due to the large number of studies that must be analyzed. Different approaches have been investigated to support SLR processes, such as: Visual Text Mining or 
Text Classification
. But acquiring the initial dataset is time-consuming and labor intensive.
Objective
In this work, we proposed and evaluated the use of 
Text Classification
 to support the studies selection activity of new evidences to update SLRs in SE.
Method
We applied Text 
Classification techniques
 to investigate how effective and how much effort could be spared during the studies selection phase of an SLR update. Considering the SLRs update scenario, the studies analyzed in the primary SLR could be used as a 
classified dataset
 to train Supervised 
Machine Learning algorithms
. We conducted an experiment with 8 
Software Engineering
 SLRs. In the experiments, we investigated the use of multiple preprocessing and feature extraction tasks such as tokenization, stop words removal, word lemmatization, TF-IDF (Term-Frequency/Inverse-Document-Frequency) with 
Decision Tree
 and 
Support Vector Machines
 as 
classification algorithms
. Furthermore, we configured the classifier activation threshold for maximizing Recall, hence reducing the number of Missed selected studies.
Results
The techniques accuracies were measured and the results achieved on average a F-Score of 0.92 and 62% of exclusion rate when varying the activation threshold of the classifiers, with a 4% average number of Missed selected studies. Both the Exclusion rate and number of Missed selected studies were significantly different when compared to classifier which did not use the configuration of the activation threshold.
Conclusion
The results showed the potential of the techniques in reducing the effort required of SLRs updates.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584920301555,Empirical software product line engineering: A systematic literature review,December 2020,Not Found,Ana Eva=Chacón-Luna: achaconl1@unemi.edu.ec; Antonio Manuel=Gutiérrez: antonio.gutierrez@isis-papyrus.com; José A.=Galindo: jagalindo@us.es; David=Benavides: benavides@us.es,"Abstract
Context:
The adoption of 
Software Product Line Engineering
 (SPLE) is usually only based on its theoretical benefits instead of empirical evidences. In fact, there is no work that synthesizes the empirical studies on SPLE. This makes it difficult for researchers to base their contributions on previous works validated with an empirical strategy.
Objective:
The objective of this work is to discover and summarize the studies that have used empirical evidences in SPLE limited to those ones with the intervention of humans. This will allow evaluating the quality and to know the scope of these studies over time. Doing so, research opportunities can arise
Methods:
A 
systematic literature review
 was conducted. The scope of the work focuses on those studies in which there is human intervention and were published between 2000 and 2018. We considered peer-reviewed papers from journals and top 
software engineering
 conferences.
Results:
Out of a total of 1880 studies in the initial set, a total of 62 primary studies were selected after applying a series of inclusion and exclusion criteria. We found that, approximately 56% of the studies used the empirical 
case study
 strategy while the rest used experimental strategies. Around 86% of the case studies were performed in an industrial environment showing the penetration of SPLE in 
industry
.
Conclusion:
The interest of empirical studies has been growing since 2008. Around 95.16% of the studies address aspects related to domain engineering while application engineering received less attention. Most of the experiments and 
case study
 evaluated showed an 
acceptable level
 of quality. The first study found dates from 2005 and since then, the interest in the empirical SPLE has increased.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584920301609,A revised open source usability defect classification taxonomy,December 2020,Not Found,Nor Shahida Mohamad=Yusop: nor_shahida@uitm.edu.my; John=Grundy: john.grundy@monash.edu; Jean-Guy=Schneider: Not Found; Rajesh=Vasa: rajesh.vasa@deakin.edu.au,"Abstract
Context
: Reporting usability defects is a critical part of improving software. Accurately classifying these reported usability defects is critical for reporting, understanding, triaging, prioritizing and ultimately fixing such defects. However, existing usability defect 
classification taxonomies
 have several limitations when used for open source software (OSS) development. This includes incomplete coverage of usability defect problems, unclear 
criticality
 of defects, lack of formal usability training of most 
OSS
 defect reporters and developers, and inconsistent terminology and descriptions.
Objective
: To address this gap, as part of our wider usability defect reporting research, we have developed a new usability defect taxonomy specifically designed for use on 
OSS projects
.
Method
: We used 
Usability Problem
 Taxonomy (UPT) to classify 377 usability 
defect reports
 from 
Mozilla Thunderbird
, Firefox for 
Android
, and the 
Eclipse Platform
. At the same time, we also used the card-sorting technique to group defects that could not be classified using UPT. We looked for commonalities and similarities to further group the defects within each category as well as across categories.
Results
: We constructed a new taxonomy for classifying 
OSS
 usability defects, called Open Source Usability Defect Classification (OSUDC). OSUDC was developed by incorporating 
software engineering
 and 
usability engineering
 needs to make it feasible to be used in 
open source software development
. The use of the taxonomy has been validated on five real cases of usability defects. However, evaluation results using the OSUDC were only moderately successful.
Conclusion
: The OSUDC serves as a common vocabulary to describe and classify usability defects with respect to graphical user interface issues. It may help software developers to better understand usability defects and prioritize them accordingly. For researchers, the OSUDC will be helpful when investigating both trends of usability defect types and understanding the root cause of usability defect problems.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584919302113,On the diffuseness of technical debt items and accuracy of remediation time when using SonarQube,December 2020,Not Found,Maria Teresa=Baldassarre: mariateresa.baldassarre@uniba.it; Valentina=Lenarduzzi: valentina.lenarduzzi@lut.fi; Simone=Romano: simone.romano@uniba.it; Nyyti=Saarimäki: nyyti.saarimaki@tuni.fi,"Abstract
Context
. Among the 
static analysis
 tools available, SonarQube is one of the most used. SonarQube detects Technical Debt (TD) items—i.e., violations of coding rules—and then estimates TD as the time needed to remedy TD items. However, practitioners are still skeptical about the accuracy of remediation time estimated by the tool. 
Objective
. In this paper, we analyze both diffuseness of TD items and accuracy of remediation time, estimated by SonarQube, to fix TD items on a set of 21 open-source Java projects. 
Method
. We designed and conducted a 
case study
 where we asked 81 junior developers to fix TD items and reduce the TD of 21 projects. 
Results
. We observed that TD items are diffused in the analyzed projects and most items are code smells. Moreover, the results point out that the remediation time estimated by SonarQube is inaccurate and, as compared to the actual time spent to fix TD items, is in most cases overestimated. 
Conclusions
. The results of our study are promising for practitioners and researchers. The former can make more aware decisions during project execution and resource management, the latter can use this study as a starting point for improving TD estimation models.",Information and Software Technology,18 Mar 2025,8.0,"The study addresses the practical concerns of accuracy in technical debt estimation, which can have a significant impact on resource management for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584919302356,Assessing safety-critical systems from operational testing: A study on autonomous vehicles,December 2020,"Autonomous systems, Safety assurance, Statistical testing, Safety-critical systems, Ultra-high reliability, Conservative Bayesian inference, AI safety, Proven in use, Globally at least equivalent, Software reliability growth models",Xingyu=Zhao: xingyu.zhao@hw.ac.uk; Kizito=Salako: k.o.salako@city.ac.uk; Lorenzo=Strigini: l.strigini@city.ac.uk; Valentin=Robu: v.robu@hw.ac.uk; David=Flynn: d.flynn@hw.ac.uk,"Abstract
Context
Demonstrating high reliability and safety for safety-critical systems (SCSs) remains a hard problem. Diverse evidence needs to be combined in a rigorous way: in particular, results of operational testing with other evidence from design and verification. Growing use of 
machine learning
 in SCSs, by precluding most established methods for gaining assurance, makes evidence from operational testing even more important for supporting safety and reliability claims.
Objective
We revisit the problem of using operational testing to demonstrate high reliability. We use Autonomous Vehicles (AVs) as a current example. AVs are making their debut on public roads: methods for assessing whether an AV is safe enough are urgently needed. We demonstrate how to answer 5 questions that would arise in assessing an AV type, starting with those proposed by a highly-cited study.
Method
We apply new theorems extending our Conservative 
Bayesian
 Inference (CBI) approach, which exploit the rigour of 
Bayesian methods
 while reducing the risk of involuntary misuse associated (we argue) with now-common applications of Bayesian inference; we define additional conditions needed for applying these methods to AVs.
Results
Prior knowledge
 can bring substantial advantages if the AV design allows strong expectations of safety before road testing. We also show how naive attempts at conservative assessment may lead to over-optimism instead; why extrapolating the trend of disengagements (take-overs by human drivers) is not suitable for safety claims; use of knowledge that an AV has moved to a “less stressful” environment.
Conclusion
While some reliability targets will remain too high to be practically verifiable, our CBI approach removes a major source of doubt: it allows use of prior knowledge without inducing dangerously optimistic biases. For certain ranges of required reliability and prior beliefs, CBI thus supports feasible, sound arguments. Useful conservative claims can be derived from limited prior knowledge.",Information and Software Technology,18 Mar 2025,9.0,The research on using operational testing for safety-critical systems like Autonomous Vehicles provides valuable insights for startups working in this domain to ensure safety and reliability.
https://www.sciencedirect.com/science/article/pii/S0950584919302101,A dynamic evolutionary multi-objective virtual machine placement heuristic for cloud data centers,December 2020,"VM placement, Multi-objective optimisation, Resource overcommitment, Resource wastage, Live migration, Energy consumption, Pareto optimal set, Genetic algorithm, Data center simulation",Ennio=Torre: Not Found; Juan J.=Durillo: Not Found; Vincenzo=de Maio: Not Found; Prateek=Agrawal: Not Found; Shajulin=Benedict: Not Found; Nishant=Saurabh: Not Found; Radu=Prodan: radu@itec.aau.at,"Abstract
Minimizing the resource wastage reduces the energy cost of operating a 
data center
, but may also lead to a considerably high resource overcommitment affecting the 
Quality of Service
 (QoS) of the running applications. The effective tradeoff between resource wastage and overcommitment is a challenging task in virtualized Clouds and depends on the allocation of virtual machines (VMs) to physical resources. We propose in this paper a multi-objective method for dynamic 
VM placement
, which exploits live migration mechanisms to simultaneously optimize the resource wastage, overcommitment ratio and migration energy. Our 
optimization algorithm
 uses a novel evolutionary meta-heuristic based on an island population model to approximate the 
Pareto optimal set
 of VM placements with good accuracy and diversity. Simulation results using traces collected from a real Google cluster demonstrate that our method outperforms related approaches by reducing the migration energy by up to 57% with a QoS increase below 6%.",Information and Software Technology,18 Mar 2025,7.0,"The multi-objective method for dynamic VM placement in data centers can help startups optimize resource wastage and improve QoS, which is crucial for efficient operations."
https://www.sciencedirect.com/science/article/pii/S0950584920301312,Crowdsourced software testing: A systematic literature review,November 2020,Not Found,Sultan=Alyahya: sualyahya@ksu.edu.sa,"Abstract
Context
Crowdsourced software testing (CST) refers to the use of 
crowdsourcing techniques
 in the domain of software testing. CST is an emerging area with its applications rapidly increasing in the last decade.
Objective
A comprehensive review on CST has been conducted to determine the current studies aiming to improve and assess the value of using CST as well as the challenges identified by these evaluation studies.
Method
We conducted a systematic literature review on CST by searching six popular databases. We identified 50 primary studies that passed our quality assessment criteria and defined two research questions covering the aim of the study.
Results
There are three main process activities that the current literature aims to improve, namely selection of suitable testers, reporting of defects, and validation of submitted defects. In addition, there are 23 CST evaluation studies and most of them involve a large group and real crowd. These studies have identified 27 different challenges encountered during the application of crowdsourcing in software testing.
Conclusions
The improvements achieved for the specific process activities in CST help explore other unexplored process activities. Similarly, knowing the characteristics of the evaluation studies can direct us on what other studies are worth investigating. Additionally, many of the challenges identified by the evaluation studies represent research problems that need better understanding and alternative solutions. This research also offers opportunities for practitioners to understand and apply new solutions proposed in the literature and the variations between them. Moreover, it provides awareness to the related parties regarding the challenges reported in the literature, which they may encounter during CST tasks.",Information and Software Technology,18 Mar 2025,6.0,"The review on crowdsourced software testing offers insights into improving testing processes, but the direct impact on early-stage ventures may not be as immediate as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920301129,BITA*: Business-IT alignment framework of multiple collaborating organisations,November 2020,Not Found,Ayalew=Kassahun: ayalew.kassahun@wur.nl; Bedir=Tekinerdogan: Not Found,"Abstract
Context
Businesses today must collaborate in a coordinated fashion. To collaborate, they must align their business processes and IT by complying to a common reference architecture. The common reference architecture that addresses their specific collaboration requirements is generally an adaptation of an existing generic reference architecture. However, a design framework for adapting reference architectures is lacking.
Objective
In this paper we propose a design framework for aligning business processes and IT across diverse collaborating organisations in order to derive a more specific reference architecture from a generic one.
Method
We developed the design framework using the guidelines of ISO/IEC/IEEE standard for modelling design viewpoints and validated it in a real-life business 
case study
.
Results
We developed an architectural design framework which we call BITA* that is composed of three coherent architectural design viewpoints. The BP2BP alignment viewpoint provides alignment modelling abstractions for business analysts to be used to align business collaboration processes. The IT2IT alignment viewpoint provides alignment modelling abstractions for software architects to be used to align distributed IT systems. The BP2IT alignment viewpoint provides alignment modelling abstractions for interdisciplinary teams of business and IT specialists for aligning the mapping of business collaboration processes and the underlying distributed IT. The modelling abstractions are applied in a case study to derive a reference architecture for meat supply chain transparency systems.
Conclusion
A key challenge in developing the design framework is the difficulty of comparing models of business processes and IT that come from diverse organisations. Our main contribution is the set of modelling abstractions, which enabled us to represent business processes and IT in a uniform and comparable manner, and the systematic approach for applying the modelling abstractions. The framework is applied in the agri-food sector and needs to be evaluated further in multiple case studies from various application domains.",Information and Software Technology,18 Mar 2025,7.0,The design framework for aligning business processes and IT in diverse organizations provides a valuable tool for startups looking to collaborate effectively and integrate their systems.
https://www.sciencedirect.com/science/article/pii/S0950584920301129,BITA*: Business-IT alignment framework of multiple collaborating organisations,November 2020,Not Found,Ayalew=Kassahun: ayalew.kassahun@wur.nl; Bedir=Tekinerdogan: Not Found,"Abstract
Context
Businesses today must collaborate in a coordinated fashion. To collaborate, they must align their business processes and IT by complying to a common reference architecture. The common reference architecture that addresses their specific collaboration requirements is generally an adaptation of an existing generic reference architecture. However, a design framework for adapting reference architectures is lacking.
Objective
In this paper we propose a design framework for aligning business processes and IT across diverse collaborating organisations in order to derive a more specific reference architecture from a generic one.
Method
We developed the design framework using the guidelines of ISO/IEC/IEEE standard for modelling design viewpoints and validated it in a real-life business 
case study
.
Results
We developed an architectural design framework which we call BITA* that is composed of three coherent architectural design viewpoints. The BP2BP alignment viewpoint provides alignment modelling abstractions for business analysts to be used to align business collaboration processes. The IT2IT alignment viewpoint provides alignment modelling abstractions for software architects to be used to align distributed IT systems. The BP2IT alignment viewpoint provides alignment modelling abstractions for interdisciplinary teams of business and IT specialists for aligning the mapping of business collaboration processes and the underlying distributed IT. The modelling abstractions are applied in a case study to derive a reference architecture for meat supply chain transparency systems.
Conclusion
A key challenge in developing the design framework is the difficulty of comparing models of business processes and IT that come from diverse organisations. Our main contribution is the set of modelling abstractions, which enabled us to represent business processes and IT in a uniform and comparable manner, and the systematic approach for applying the modelling abstractions. The framework is applied in the agri-food sector and needs to be evaluated further in multiple case studies from various application domains.",Information and Software Technology,18 Mar 2025,6.0,"The proposed design framework for aligning business processes and IT could be valuable for startups looking to collaborate with diverse organizations, specifically in the agri-food sector. The practical application in a case study adds credibility to the framework."
https://www.sciencedirect.com/science/article/pii/S0950584920301397,A microservice composition approach based on the choreography of BPMN fragments,November 2020,Not Found,Pedro=Valderas: pvalderas@pros.upv.es; Victoria=Torres: vtorres@pros.upv.es; Vicente=Pelechano: pele@pros.upv.es,"Abstract
Context
Microservices
 must be composed to provide users with complex and elaborated functionalities. It seems that the decentralized nature of microservices makes a choreography style more appropriate to achieve such cooperation, where lighter solutions based on asynchronous events are generally used. However, a microservice composition based on choreography distributes the flow logic of the composition among microservices making further analysis and updating difficult, i.e. there is not a big picture of the composition that facilitates these tasks. 
Business Process Model and Notation
 (BPMN) is the OMG standard developed to represent Business Processes (BPs), being widely used to define the big picture of such compositions. However, BPMN is usually considered in orchestration-based solutions, and orchestration can be a drawback to achieve the decoupling pursued by a 
microservice architecture
.
Objective
Defining a microservice composition approach that allows us to create a composition in a BPMN model, which facilitates further analysis for taking engineering decisions, and execute them through an event-based choreography to have a high degree of decoupling and independence among microservices.
Method
We followed a research methodology for 
information systems
 that consists of a 5-step process: awareness of the problem, suggestion, development, evaluation, and conclusion.
Results
We presented a microservice composition approach based on the choreography of BPMN fragments. On the one hand, we propose to describe the big picture of the composition with a BPMN model, providing a valuable mechanism to analyse it when engineering decisions need to be taken. On the other hand, this model is split into fragments in order to be executed through an event-based choreography form, providing the high degree of decoupling among microservices demanded in this type of architecture. This composition approach is supported by a 
microservice architecture
 defined to achieve that both descriptions of a composition (big picture and split one) coexist. A realization of this architecture in Java/Spring technology is also presented.
Conclusions
The evaluation that is done to our work allows us to conclude that the proposed approach for composing microservices is more efficient than solutions based on ad-hoc development.",Information and Software Technology,18 Mar 2025,8.0,The approach of composing microservices using BPMN and choreography provides a practical and efficient way for startups to design their systems with a high degree of decoupling. The evaluation of the approach and the realization in Java/Spring technology demonstrate its feasibility and effectiveness.
https://www.sciencedirect.com/science/article/pii/S0950584920301385,Type slicing: An accurate object oriented slicing based on sub-statement level dependence graph,November 2020,Not Found,Wang=Lulu: Not Found; Li=Bixin: bx.li@seu.edu.cn; Kong=Xianglong: Not Found,"Abstract
Context
Program slicing is very useful in program analysis and software engineering. It computes the slice, which is a part of program and contains all the statements related to the given slicing criterion. The more accurate a slicing technique could be, the smaller the slice is.
Objective
This paper aims to improve the current slicing accuracy for object-oriented programs. The slicing accuracy is mainly related to three factors, the dependency graph (which extracts the inner relationships of source code), the slicing criterion (which determines the slicing requirement), and the slicing algorithm (which computes the slice for the criterion from the dependency graph).
Method
Our method consists of three parts. First, we present a 
Sub-Statement Level Dependence Graph
 (SSLDG), which computes finer-grained dependences for object-oriented programs than mostly-used statement level graph. Second, we present a new type slicing criterion called 
(Sub-statement) Type Slicing Criterion
 (STSC), which supports the user to specify not only the statement and object variable, but also the type of object among its polymorphic types. At last, a corresponding slicing algorithm called 
(Sub-statement) Type Slicing
 (STS) is designed to perform the slicing process.
Results
We implement STS on Java programs as MyJavaSlicer, and run it with ten open source projects and random slicing criteria. The results show that STS slicing algorithm as well as SSLDG would make slices 35.90% smaller than traditional two-phase slicing; additionally using STSC would make the slices 48.4% further smaller; STSC also helps traditional two-phase slices reduced by 56.90%.
Conclusions
STS could provide more accurate slices than traditional two-phase slicing, and it also runs faster on most cases; STSC helps specify the slicing requirement, and roughly halves the size of slices for both slicing algorithms.",Information and Software Technology,18 Mar 2025,7.0,"The improvement in slicing accuracy for object-oriented programs through SSLDG, STSC, and STS could benefit startups working on software development. The results show significant reductions in slice size, indicating a practical application of the proposed method."
https://www.sciencedirect.com/science/article/pii/S0950584920301403,Automated model-based performance analysis of software product lines under uncertainty,November 2020,Not Found,Paolo=Arcaini: arcaini@nii.ac.jp; Omar=Inverso: Not Found; Catia=Trubiani: Not Found,"Abstract
Context:
 A Software Product Line (SPL) can express the variability of a system through the specification of configuration options. Evaluating performance characteristics, such as the 
system response time
 and 
resource utilization
, of a software product is challenging, even more so in the presence of uncertain values of the attributes.
Objective:
 The goal of this paper is to automate the generation of performance models for software products derived from the feature model by selection heuristics. We aim at obtaining model-based predictive results to quantify the correlation between the features, along with their uncertainties, and the 
system performance
. This way, software engineers can be informed on the performance characteristics before implementing the system.
Method:
 We propose a tool-supported framework that, starting from a feature model annotated with performance-related characteristics, derives 
Queueing Network
 (QN) performance models for all the products of the SPL. Model-based performance analysis is carried out on the models obtained by selecting the products that show the maximum and minimum performance-based costs.
Results:
 We applied our approach to almost seven thousand feature models including more than one hundred and seventy features. The generation of QN models is automatically performed in much less than one second, whereas their model-based performance analysis embeds simulation delays and requires about six minutes on average.
Conclusion:
 The experimental results confirm that our approach can be effective on a variety of systems for which software engineers may be provided with early insights on the 
system performance
 in reasonably short times. Software engineers are supported in the task of understanding the performance bounds that may encounter when (de)selecting different configuration options, along with their uncertainties.",Information and Software Technology,18 Mar 2025,9.0,Automating the generation of performance models for software products can greatly benefit startups in understanding the correlation between features and system performance. The tool-supported framework and the application to thousands of feature models demonstrate the potential impact and efficiency of the approach.
https://www.sciencedirect.com/science/article/pii/S0950584920301452,Cloud applications monitoring: An industrial study,November 2020,"Cloud monitoring, Applications monitoring, Incident handling, Rapid response organizational structures, Online survey, Industrial study",Damian A.=Tamburri: d.a.tamburri@tue.nl; Marco=Miglierina: marco.miglierina@contentwise.com; Elisabetta Di=Nitto: elisabetta.dinitto@polimi.it,"Abstract
Context
Modern software systems employ large IT infrastructures hosted in on-premise clouds or using “rented” cloud resources from specific vendors. The unifying force across any cloud strategy is incremental product and application improvement against conservation of those resources. This is where monitoring of cloud applications becomes a key asset
Objective
To shed light over the status of monitoring practices in industry, we study: (a) monitoring practices and tools adoption in industry; (b) size and complexity of industrial monitoring problems; (c) the role of software architecture and software process with respect to monitoring strategies.
Method
We conduct mixed-methods empirical research featuring interviews and a web survey featuring 140+ practitioners from over 70 different organizations.
Results
Even if the market makes available a significant set of monitoring tools, our results show a rather unappealing picture of industrial monitoring: (a) industrial decision-makers do not perceive monitoring as a key asset even though the downtime of their applications correlates heavily with the level of automation and responsiveness enabled by monitoring; (b) monitoring is done with crude technology, mostly MySQL querying or similar (e.g., Nagios); finally, (c) incidents are discovered by clients rather than application owners.
Conclusion
We conclude that the road toward the industrial adoption of cutting-edge monitoring technology is still one of the less travelled, presumably in connection to the considerable investment required. Furthermore, the lack of industrial cloud monitoring standards does not help in addressing the proliferation of multiple tool combinations, with varying effectiveness. Further research should be invested in looking into and addressing these major concerns.",Information and Software Technology,18 Mar 2025,5.0,"The study on monitoring practices in industry provides insights that could be relevant to startups managing cloud applications. However, the lack of adoption of cutting-edge monitoring technology and the challenges in standardization may limit the immediate practical value for startups."
https://www.sciencedirect.com/science/article/pii/S0950584920301427,Towards automatically generating block comments for code snippets,November 2020,Not Found,Yuan=Huang: huangyjn@gmail.com; Shaohao=Huang: huangshh29@mail2.sysu.edu.cn; Huanchao=Chen: fchenhch@mail2.sysu.edu.cn; Xiangping=Chen: chenxp8@mail.sysu.edu.cn; Xiapu=Luo: csxluo@comp.polyu.edu.hk; Nan=Jia: jianan_0101@163.com; Xinyu=Hu: husense@foxmail.com; Xiaocong=Zhou: isszxc@mail.sysu.edu.cn,"Abstract
Code commenting is a common programming practice of practical importance to help developers review and comprehend 
source code
. There are two main types of code comments for a method: header comments that summarize the method functionality located before a method, and block comments that describe the functionality of the code snippets within a method. Inspired by the effectiveness of 
deep learning
 techniques in the NLP field, many studies focus on using the machine 
translation model
 to automatically generate comment for the 
source code
. Because the data set of block comments is difficult to collect, current studies focus more on the automatic generation of header comments than that of block comments. However, block comments are important for 
program comprehension
 due to their explanation role for the code snippets in a method. To fill the gap, we have proposed an approach that combines heuristic rules and learning-based method to collect a large number of comment-code pairs from 1,032 
open source projects
 in our previous study. In this paper, we propose a reinforcement learning-based method, 
RL-BlockCom
, to automatically generate block comments for code snippets based on the collected comment-code pairs. Specifically, we utilize the 
abstract syntax tree
 (i.e., AST) of a code snippet to generate a token sequence with a statement-based traversal way. Then we propose a composite learning model, which combines the actor-critic algorithm of 
reinforcement learning
 with the encoder-decoder algorithm, to generate block comments. On the data set of the comment-code pairs, the BLEU-4 score of our method is 24.28, which outperforms the baselines and state-of-the-art in comment generation.",Information and Software Technology,18 Mar 2025,7.0,The proposed approach of automatically generating block comments for code snippets using reinforcement learning has the potential to enhance program comprehension and improve development efficiency.
https://www.sciencedirect.com/science/article/pii/S0950584920301440,The impact of using a domain language for an agile requirements management,November 2020,Not Found,Matias=Urbieta: murbieta@lifia.info.unlp.edu.ar; Leandro=Antonelli: lanto@lifia.info.unlp.edu.ar; Gustavo=Rossi: gustavo@lifia.info.unlp.edu.ar; Julio Cesar Sampaio=do Prado Leite: http://www.inf.puc-rio.br/julio,"Abstract
Context
: The development of software systems is a complex activity because of its nature and the management of its construction. It is challenging to create and follow a plan. Moreover, budget overrun is a common consequence of this situation. Agile methods, like Scrum, help to mitigate this problem using incremental and 
iterative development
. Agile methods jump start new developments, but it is difficult to be agile after several months when the software has to deal with many requirements that are scattered and tangled across several User Stories written in different Sprints. 
Objective
: In this paper, we propose a traceability approach anchored on an index structure to access specific User Stories from a large set. Our proposed strategy has the goal to consolidate the information dispersed in different User Stories into a particular lexicon: The Language Extended Lexicon (LEL). 
Method
: The proposed approach consists of a set of rules which extract the information dispersed in the User Stories and organize it in symbols of the Lexicon. Thus, the Lexicon supplies a consolidated and organized structure to mitigate the problem of tangled information that generates lack of traceability among different sprints. 
Results
: We assessed how the Lexicon built by our approach improves everyday activities related to requirement management. The assessment is based on a 
quantitative evaluation
 with 36 subjects. 
Conclusion
: The approach presents benefits for requirement tracing in 
agile methodologies
 supported by the preliminary results of the evaluation. We have developed an application (a prototype) that automates the LEL derivation rules from a set of User Stories.",Information and Software Technology,18 Mar 2025,4.0,"While the proposed traceability approach anchored on an index structure is beneficial for consolidating information in agile methodologies, the practical impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584920301439,Effectiveness of Kotlin vs. Java in android app development tasks,November 2020,Not Found,Luca=Ardito: luca.ardito@polito.it; Riccardo=Coppola: riccardo.coppola@polito.it; Giovanni=Malnati: giovanni.malnati@polito.it; Marco=Torchiano: marco.torchiano@polito.it,"Abstract
Context:
Kotlin is a new programming language representing an alternative to Java; they both target the same 
JVM
 and can safely coexist in the same application. Kotlin is advertised as capable to solve several known limitations of Java. Recent surveys show that Kotlin achieved a relevant diffusion among Java developers. 
Goal:
We planned to empirically assess a few typical promises of Kotlin w.r.t. known Java’s limitations, in terms of development effectiveness, 
maintainability
, and ease of development. 
Method:
Our experiment involved 27 teams of 4 people each that completed a set of maintenance tasks (both defect correction and feature addition) on 
Android
 apps written in either Java or Kotlin. In addition to the number of fixed defects, effort, and code size, we collected, though a questionnaire, the participants’ perceptions about the avoidance of known pitfalls. 
Results:
We did not observe any significant difference in terms of 
maintainability
 between the two languages.We found a significant difference regarding the amount of code written, which constitutes evidence of better 
conciseness
 of Kotlin. Concerning ease of development, the frequency of NullPointerExceptions reported by the subjects was significantly lower when developing in Kotlin. On the other hand, no significant difference was found in the occurrence of other common Java pitfalls. Finally, the IDE support was deemed better for Java than Kotlin. 
Conclusions:
Some of the promises of Kotlin to be a ”better Java” have been confirmed by our empirical assessment. Evidence suggests that the effort in transitioning to Kotlin can provide some advantages to Java developers, especially regarding code 
conciseness
.Our results may serve as the basis for further investigations on the properties of the language.",Information and Software Technology,18 Mar 2025,8.0,"The empirical assessment of Kotlin as an alternative to Java in terms of development effectiveness, maintainability, and ease of development provides valuable insights for startups looking to adopt a new programming language."
https://www.sciencedirect.com/science/article/pii/S095058491930223X,Guidelines for the search strategy to update systematic literature reviews in software engineering,November 2020,"Systematic literature review update, Systematic literature reviews, Software engineering, Snowballing, Searching for evidence",Claes=Wohlin: claes.wohlin@bth.se; Emilia=Mendes: emilia.mendes@bth.se; Katia Romero=Felizardo: katiascannavino@utfpr.edu.br; Marcos=Kalinowski: kalinowski@inf.puc-rio.br,"Abstract
Context
Systematic Literature Reviews (SLRs) have been adopted within Software Engineering (SE) for more than a decade to provide meaningful summaries of evidence on several topics. Many of these SLRs are now potentially not fully up-to-date, and there are no standard proposals on how to update SLRs in SE.
Objective
The objective of this paper is to propose guidelines on how to best search for evidence when updating SLRs in SE, and to evaluate these guidelines using an SLR that was not employed during the formulation of the guidelines.
Method
To propose our guidelines, we compare and discuss outcomes from applying different search strategies to identify primary studies in a published SLR, an SLR update, and two replications in the area of effort estimation. These guidelines are then evaluated using an SLR in the area of software ecosystems, its update and a replication.
Results
The use of a single iteration forward snowballing with Google Scholar, and employing as a seed set the original SLR and its primary studies is the most cost-effective way to search for new evidence when updating SLRs. Furthermore, the importance of having more than one researcher involved in the selection of papers when applying the inclusion and exclusion criteria is highlighted through the results.
Conclusions
Our proposed guidelines formulated based upon an effort estimation SLR, its update and two replications, were supported when using an SLR in the area of software ecosystems, its update and a replication. Therefore, we put forward that our guidelines ought to be adopted for updating SLRs in SE.",Information and Software Technology,18 Mar 2025,5.0,"The proposed guidelines for updating Systematic Literature Reviews in Software Engineering offer a standard approach, but the immediate practical value for startups may not be significant."
https://www.sciencedirect.com/science/article/pii/S095058491930223X,Guidelines for the search strategy to update systematic literature reviews in software engineering,November 2020,"Systematic literature review update, Systematic literature reviews, Software engineering, Snowballing, Searching for evidence",Claes=Wohlin: claes.wohlin@bth.se; Emilia=Mendes: emilia.mendes@bth.se; Katia Romero=Felizardo: katiascannavino@utfpr.edu.br; Marcos=Kalinowski: kalinowski@inf.puc-rio.br,"Abstract
Context
Systematic Literature Reviews (SLRs) have been adopted within Software Engineering (SE) for more than a decade to provide meaningful summaries of evidence on several topics. Many of these SLRs are now potentially not fully up-to-date, and there are no standard proposals on how to update SLRs in SE.
Objective
The objective of this paper is to propose guidelines on how to best search for evidence when updating SLRs in SE, and to evaluate these guidelines using an SLR that was not employed during the formulation of the guidelines.
Method
To propose our guidelines, we compare and discuss outcomes from applying different search strategies to identify primary studies in a published SLR, an SLR update, and two replications in the area of effort estimation. These guidelines are then evaluated using an SLR in the area of software ecosystems, its update and a replication.
Results
The use of a single iteration forward snowballing with Google Scholar, and employing as a seed set the original SLR and its primary studies is the most cost-effective way to search for new evidence when updating SLRs. Furthermore, the importance of having more than one researcher involved in the selection of papers when applying the inclusion and exclusion criteria is highlighted through the results.
Conclusions
Our proposed guidelines formulated based upon an effort estimation SLR, its update and two replications, were supported when using an SLR in the area of software ecosystems, its update and a replication. Therefore, we put forward that our guidelines ought to be adopted for updating SLRs in SE.",Information and Software Technology,18 Mar 2025,5.0,"The proposed guidelines for updating Systematic Literature Reviews in Software Engineering offer a standard approach, but the immediate practical value for startups may not be significant."
https://www.sciencedirect.com/science/article/pii/S0950584919301740,"The Symposium on Search-Based Software Engineering: Past, Present and Future",November 2020,Not Found,Thelma Elita=Colanzi: thelma@din.uem.br; Wesley K.G.=Assunção: wesleyk@utfpr.edu.br; Silvia R.=Vergilio: silvia@inf.ufpr.br; Paulo Roberto=Farah: paulo.farah@udesc.br; Giovani=Guizzo: g.guizzo@ucl.ac.uk,"Abstract
Context
Search-Based 
Software Engineering
 (SBSE) is the research field where 
Software Engineering
 (SE) problems are modelled as search problems to be solved by search-based techniques. The Symposium on Search Based Software Engineering (SSBSE) is the premier event on SBSE, which had its 11
th
 edition in 2019.
Objective
In order to better understand the characteristics and evolution of papers published at SSBSE, this work reports results from a mapping study targeting the proceedings of all SSBSE editions. Despite the existing mapping studies on SBSE, our contribution in this work is to provide information to researchers and practitioners willing to enter the SBSE field, being a source of information to strengthen the symposium, guide new studies, and motivate new collaboration among research groups.
Method
A 
systematic mapping study
 was conducted with a set of four research questions, in which 134 studies published in all editions of SSBSE, dated from 2009 to 2019, were evaluated. In a fifth question, 32 papers published in the challenge track were summarised.
Results
Throughout the years, 290 authors from 25 countries have contributed to the main track of the symposium, with the collaboration of at least two institutions in 46.3% of the papers. SSBSE papers have got substantial external visibility, as most citations are from different venues. The SE tasks addressed by SSBSE are mostly related to software testing, 
software debugging
, 
software design
, and maintenance. 
Evolutionary algorithms
 are present in 75% of the papers, being the most common search technique. The evaluation of the SBSE approaches usually includes industrial systems.
Conclusions
SSBSE has helped increase the popularity of SBSE in the SE research community and has played an important role on making SBSE mature. There are still problems and challenges to be addressed in the SBSE field, which can be tackled by SSBSE authors in further studies.",Information and Software Technology,18 Mar 2025,7.0,"The research on Search-Based Software Engineering (SBSE) presented in this abstract can provide valuable insights and information to researchers and practitioners entering this field, thus contributing to the overall growth and collaboration in the SBSE community."
https://www.sciencedirect.com/science/article/pii/S0950584919301740,"The Symposium on Search-Based Software Engineering: Past, Present and Future",November 2020,Not Found,Thelma Elita=Colanzi: thelma@din.uem.br; Wesley K.G.=Assunção: wesleyk@utfpr.edu.br; Silvia R.=Vergilio: silvia@inf.ufpr.br; Paulo Roberto=Farah: paulo.farah@udesc.br; Giovani=Guizzo: g.guizzo@ucl.ac.uk,"Abstract
Context
Search-Based 
Software Engineering
 (SBSE) is the research field where 
Software Engineering
 (SE) problems are modelled as search problems to be solved by search-based techniques. The Symposium on Search Based Software Engineering (SSBSE) is the premier event on SBSE, which had its 11
th
 edition in 2019.
Objective
In order to better understand the characteristics and evolution of papers published at SSBSE, this work reports results from a mapping study targeting the proceedings of all SSBSE editions. Despite the existing mapping studies on SBSE, our contribution in this work is to provide information to researchers and practitioners willing to enter the SBSE field, being a source of information to strengthen the symposium, guide new studies, and motivate new collaboration among research groups.
Method
A 
systematic mapping study
 was conducted with a set of four research questions, in which 134 studies published in all editions of SSBSE, dated from 2009 to 2019, were evaluated. In a fifth question, 32 papers published in the challenge track were summarised.
Results
Throughout the years, 290 authors from 25 countries have contributed to the main track of the symposium, with the collaboration of at least two institutions in 46.3% of the papers. SSBSE papers have got substantial external visibility, as most citations are from different venues. The SE tasks addressed by SSBSE are mostly related to software testing, 
software debugging
, 
software design
, and maintenance. 
Evolutionary algorithms
 are present in 75% of the papers, being the most common search technique. The evaluation of the SBSE approaches usually includes industrial systems.
Conclusions
SSBSE has helped increase the popularity of SBSE in the SE research community and has played an important role on making SBSE mature. There are still problems and challenges to be addressed in the SBSE field, which can be tackled by SSBSE authors in further studies.",Information and Software Technology,18 Mar 2025,7.0,"Similar to abstract 81, this research on SBSE contributes to the field by providing information to researchers and practitioners, fostering collaboration and guiding new studies in SBSE, thus enhancing the maturity of the field."
https://www.sciencedirect.com/science/article/pii/S0950584920300744,NLP-assisted software testing: A systematic mapping of the literature,October 2020,Not Found,Vahid=Garousi: v.garousi@qub.ac.uk; Sara=Bauer: sara.bauer@uibk.ac.at,"Abstract
Context
To reduce manual effort of extracting test cases from natural-language requirements, many approaches based on 
Natural Language Processing
 (NLP) have been proposed in the literature. Given the large amount of approaches in this area, and since many practitioners are eager to utilize such techniques, it is important to synthesize and provide an overview of the state-of-the-art in this area.
Objective
Our objective is to summarize the state-of-the-art in NLP-assisted software testing which could benefit practitioners to potentially utilize those NLP-based techniques. Moreover, this can benefit researchers in providing an overview of the research landscape.
Method
To address the above need, we conducted a survey in the form of a systematic literature mapping (classification). After compiling an initial pool of 95 papers, we conducted a systematic voting, and our final pool included 67 technical papers.
Results
This review paper provides an overview of the contribution types presented in the papers, types of NLP approaches used to assist software testing, types of required input requirements, and a review of tool support in this area. Some key results we have detected are: (1) only four of the 38 tools (11%) presented in the papers are available for download; (2) a larger ratio of the papers (30 of 67) provided a shallow exposure to the NLP aspects (almost no details).
Conclusion
This paper would benefit both practitioners and researchers by serving as an “index” to the body of knowledge in this area. The results could help practitioners utilizing the existing NLP-based techniques; this in turn reduces the cost of test-case design and decreases the amount of human resources spent on test activities. After sharing this review with some of our industrial collaborators, initial insights show that this review can indeed be useful and beneficial to practitioners.",Information and Software Technology,18 Mar 2025,8.0,"The overview of NLP-assisted software testing and the tool support analysis presented in this abstract can greatly benefit practitioners and researchers, reducing the cost of test-case design and optimizing test activities, making it a valuable contribution to the software testing community."
https://www.sciencedirect.com/science/article/pii/S0950584920300744,NLP-assisted software testing: A systematic mapping of the literature,October 2020,Not Found,Vahid=Garousi: v.garousi@qub.ac.uk; Sara=Bauer: sara.bauer@uibk.ac.at,"Abstract
Context
To reduce manual effort of extracting test cases from natural-language requirements, many approaches based on 
Natural Language Processing
 (NLP) have been proposed in the literature. Given the large amount of approaches in this area, and since many practitioners are eager to utilize such techniques, it is important to synthesize and provide an overview of the state-of-the-art in this area.
Objective
Our objective is to summarize the state-of-the-art in NLP-assisted software testing which could benefit practitioners to potentially utilize those NLP-based techniques. Moreover, this can benefit researchers in providing an overview of the research landscape.
Method
To address the above need, we conducted a survey in the form of a systematic literature mapping (classification). After compiling an initial pool of 95 papers, we conducted a systematic voting, and our final pool included 67 technical papers.
Results
This review paper provides an overview of the contribution types presented in the papers, types of NLP approaches used to assist software testing, types of required input requirements, and a review of tool support in this area. Some key results we have detected are: (1) only four of the 38 tools (11%) presented in the papers are available for download; (2) a larger ratio of the papers (30 of 67) provided a shallow exposure to the NLP aspects (almost no details).
Conclusion
This paper would benefit both practitioners and researchers by serving as an “index” to the body of knowledge in this area. The results could help practitioners utilizing the existing NLP-based techniques; this in turn reduces the cost of test-case design and decreases the amount of human resources spent on test activities. After sharing this review with some of our industrial collaborators, initial insights show that this review can indeed be useful and beneficial to practitioners.",Information and Software Technology,18 Mar 2025,8.0,"Similar to abstract 83, this research on NLP-assisted software testing can provide significant benefits to practitioners and researchers by offering insights into the state-of-the-art techniques and tools available, thereby enhancing the efficiency of software testing practices."
https://www.sciencedirect.com/science/article/pii/S0950584920301166,Engineering human-in-the-loop interactions in cyber-physical systems,October 2020,Not Found,Miriam=Gil: mgil@pros.upv.es; Manoli=Albert: malbert@pros.upv.es; Joan=Fons: jjfons@pros.upv.es; Vicente=Pelechano: pele@pros.upv.es,"Abstract
Context:
 Cyber-Physical Systems (CPSs) are gradually and widely introducing autonomous capabilities into everything. However, human participation is required to accomplish tasks that are better performed with humans (often called human-in-the-loop). In this way, human-in-the-loop solutions have the potential to handle complex tasks in unstructured environments, by combining the cognitive skills of humans with 
autonomous systems
 behaviors.
Objective:
 The objective of this paper is to provide appropriate techniques and methods to help designers analyze and design human-in-the-loop solutions. These solutions require interactions that engage the human, provide natural and understandable collaboration, and avoid disturbing the human in order to improve human experience.
Method:
 We have analyzed several works that identified different requirements and critical factors that are relevant to the design of human-in-the-loop solutions. Based on these works, we have defined a set of design principles that are used to build our proposal. Fast-prototyping techniques have been applied to simulate the designed human-in-the-loop solutions and validate them.
Results:
 We have identified the technological challenges of designing human-in-the-loop CPSs and have provided a method that helps designers to identify and specify how the human and the system should work together, focusing on the 
control strategies
 and interactions required.
Conclusions:
 The use of our approach facilitates the design of human-in-the-loop solutions. Our method is practical at earlier stages of the 
software life cycle
 since it allows domain experts to focus on the problem and not on the solution.",Information and Software Technology,18 Mar 2025,6.0,"While the research on human-in-the-loop solutions for Cyber-Physical Systems (CPSs) is important in advancing autonomous capabilities, the practical application of the proposed techniques and methods may be limited to a niche audience, thus potentially impacting a smaller subset of early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584920301142,Refactoring effect on internal quality attributes: What haven’t they told you yet?,October 2020,Not Found,Eduardo=Fernandes: emfernandes@inf.puc-rio.br; Alexander=Chávez: achavez@tecgraf.puc-rio.br; Alessandro=Garcia: afgarcia@inf.puc-rio.br; Isabella=Ferreira: isabella.ferreira@polymtl.ca; Diego=Cedrim: dccedrim@amazon.com; Leonardo=Sousa: leo.sousa@sv.cmu.edu; Willian=Oizumi: woizumi@inf.puc-rio.br,"Abstract
Context
Code refactoring
 was conceived for enhancing code structures, often in terms of internal quality attributes such as cohesion and coupling. Developers may have to apply multiple 
refactoring operations
 to achieve the expected enhancement. Re-refactoring occurs whenever one or more refactoring operations are performed on a previously refactored code element. The literature often assumes each single refactoring improves rather than worsens internal quality attributes, while re-refactoring implies further improvements. Unfortunately, quantitative evidence on this matter is scarce if not nonexistent.
Objective
This paper extends a large quantitative study about the refactoring effect on internal quality attributes with new insights, plus an unprecedented re-refactoring effect analysis. We particularly investigate if re-refactoring operations are more effective in improving attributes when compared to single operations.
Method
We analyzed 23 
open software
 projects with 29,303 refactoring operations, from which nearly 50% constitute re-refactorings. We assessed five attributes: cohesion, complexity, coupling, inheritance, and size. We combined descriptive analysis and statistical tests to deeply understand the effect of both refactoring and re-refactoring on each attribute.
Results
Contrary to current knowledge, our study revealed that 90% of refactoring operations, and 100% of re-refactoring operations, were applied to code elements with at least one critical attribute. Critical attribute is an attribute whose metrics used for computing it have anomalous values, e.g. high coupling. Most operations (65%) improve attributes presumably associated with the refactoring type applied; the other operations (35%) keep those attributes unaffected. Whenever refactoring and re-refactoring operations are applied without additional changes, i.e., root-canal refactoring, attributes tend to improve or at least not worsen. Surprisingly, if these operations occur with additional changes such as feature additions, i.e., floss refactoring, they mostly improve rather than worsen attributes.
Conclusions
Besides revealing the effect of refactoring and re-refactoring on each attribute, we derived insights on leveraging the current refactoring practices.",Information and Software Technology,18 Mar 2025,8.0,"The study provides valuable insights into the effects of refactoring and re-refactoring on code attributes, which can be crucial for startups looking to improve their code quality and practices."
https://www.sciencedirect.com/science/article/pii/S0950584920301130,Using simulated annealing for locating array construction,October 2020,"Locating arrays, Combinatorial interaction testing, Software testing, Simulated annealing",Tatsuya=Konishi: Not Found; Hideharu=Kojima: Not Found; Hiroyuki=Nakagawa: Not Found; Tatsuhiro=Tsuchiya: t-tutiya@ist.osaka-u.ac.jp,"Abstract
Context
Combinatorial interaction testing is known to be an efficient testing strategy for computing and 
information systems
. Locating arrays are mathematical objects that are useful for this testing strategy, as they can be used as a test suite that permits 
fault localization
 as well as fault detection. In this application, each row of an array is used as an individual test.
Objective
This paper proposes an algorithm for constructing locating arrays with a small number of rows. Testing cost increases as the number of tests increases; thus the problem of finding locating arrays of small sizes is of practical importance.
Method
The proposed algorithm uses simulated annealing, a meta-heuristic algorithm, to find locating array of a given size. The whole algorithm repeatedly executes the 
simulated annealing algorithm
 with the input array size being dynamically varied.
Results
Experimental results show (1) that the proposed algorithm is able to construct locating arrays for problem instances of large sizes and (2) that, for problem instances for which nontrivial locating arrays are known, the algorithm is often able to generate locating arrays that are smaller than or at least equal to the known arrays.
Conclusion
Based on the results, we conclude that the proposed algorithm can produce small locating arrays and scale to practical problems.",Information and Software Technology,18 Mar 2025,6.0,"The algorithm proposed for constructing locating arrays can be beneficial for startups involved in testing strategies, but may have a limited impact compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584920300653,"Early prediction of quality of service using interface-level metrics, code-level metrics, and antipatterns",October 2020,Not Found,Chaima=Abid: cabid@umich.edu; Marouane=Kessentini: marouane@umich.edu; Hanzhang=Wang: hanzwang@ebay.com,"Abstract
Context:
 With the current high trends of deploying and using web services in practice, effective techniques for maintaining high quality of Service are becoming critical for both service providers and subscribers/users. Service providers want to predict the quality of service during early stages of development before releasing them to customers. Service clients consider the quality of service when selecting the best one satisfying their preferences in terms of price/budget and quality between the services offering the same features. The majority of existing studies for the prediction of quality of service are based on 
clustering algorithms
 to classify a set of services based on their collected quality attributes. Then, the user can select the best service based on his expectations both in terms of quality and features. However, this assumption requires the deployment of the services before being able to make the prediction and it can be time-consuming to collect the required data of running web services during a period of time. Furthermore, the clustering is only based on well-known quality attributes related to the services performance after deployment. 
Objective:
 In this paper, we start from the hypothesis that the quality of the source code and 
interface design
 can be used as indicators to predict the quality of service attributes without the need to deploy or run the services by the subscribers. 
Method:
 We collected 
training data
 of 707 web services and we used 
machine learning
 to generate 
association rules
 that predict the quality of service based on the interface and code quality metrics, and antipatterns. 
Results:
 The empirical validation of our prediction techniques shows that the generated 
association rules
 have strong support and high confidence which confirms our hypothesis that source code and interface quality metrics/antipatterns are correlated with web service quality attributes which are response time, availability, throughput, successability, reliability, compliance, best practices, latency, and documentation. 
Conclusion:
 To the best of our knowledge, this paper represents the first study to validate the correlation between interface metrics, source 
code metrics
, antipatterns and quality of service. Another contribution of our work consists of generating association rules between the code/interface metrics and quality of service that can be used for prediction purposes before deploying new releases.",Information and Software Technology,18 Mar 2025,9.0,"The paper introduces a novel approach to predicting service quality attributes based on source code and interface design, which can be highly valuable for startups aiming to optimize their services before deployment."
