link,title,published_year,keywords,author_email,abstract,publication_title,created_on,score,justification
https://www.sciencedirect.com/science/article/pii/S0950584923000940,A scientific software ecosystem architecture for the livestock domain,August 2023,Not Found,Jonas=Gomes: Not Found; Izaque=Esteves: Not Found; Valdemar Vicente Graciano Neto=Not Found: valdemarneto@ufg.br; José Maria N.=David: Not Found; Regina=Braga: Not Found; Wagner=Arbex: Not Found; Mohamad=Kassab: Not Found; Roberto Felício=de Oliveira: Not Found,"Abstract
Context:
In the 
livestock
 domain, technologies are developed to sustainably raise animal production. However, the domain is critical, since animals are very sensitive to variables such as temperature and humidity, which can cause diseases and consequent production losses and discomfort. 
Livestock production systems
 then demand monitoring, reasoning, and acting on the environment so that the levels of those variables are preserved in pre-established intervals and undesired conditions are predicted, avoided, and mitigated with automated actions.
Objective:
The main contribution of this article is presenting E-SECO, a software ecosystem platform, and its evolution that encapsulates a new self-adaptive component to tackle animal production decisions, named e-Livestock architecture.
Method:
Two 
case studies
 were conducted involving a real system derived from the E-SECO platform encompassing a Compost 
Barn
 production system, i.e., the environment and surrounding technology where 
bovine milk
 production takes place.
Results:
Results showed the effectiveness of E-SECO to (i) abstract disruptive technologies based on the 
Internet of Things
 (IoT) and 
Artificial Intelligence
 and accommodate them in a single architecture for that specific domain, (ii) support reuse and derivation of a self-adaptive architecture to support engineering a complex system for a 
livestock
 sub-domain (milk production), and (iii) support empirical studies in a real smart farm towards a future transfer of technology to industry.
Conclusion:
The results showed that the E-SECO platform, which encompasses e-livestock architecture, can support monitoring, reasoning, prediction, and automated actions in a milk production/Compost 
Barn
 environment.",Information and Software Technology,18 Mar 2025,8.0,"The development of new technologies for sustainable livestock production has practical value for early-stage ventures in the agriculture sector, especially for startups focusing on smart farming."
https://www.sciencedirect.com/science/article/pii/S0950584923000940,A scientific software ecosystem architecture for the livestock domain,August 2023,Not Found,Jonas=Gomes: Not Found; Izaque=Esteves: Not Found; Valdemar Vicente Graciano Neto=Not Found: valdemarneto@ufg.br; José Maria N.=David: Not Found; Regina=Braga: Not Found; Wagner=Arbex: Not Found; Mohamad=Kassab: Not Found; Roberto Felício=de Oliveira: Not Found,"Abstract
Context:
In the 
livestock
 domain, technologies are developed to sustainably raise animal production. However, the domain is critical, since animals are very sensitive to variables such as temperature and humidity, which can cause diseases and consequent production losses and discomfort. 
Livestock production systems
 then demand monitoring, reasoning, and acting on the environment so that the levels of those variables are preserved in pre-established intervals and undesired conditions are predicted, avoided, and mitigated with automated actions.
Objective:
The main contribution of this article is presenting E-SECO, a software ecosystem platform, and its evolution that encapsulates a new self-adaptive component to tackle animal production decisions, named e-Livestock architecture.
Method:
Two 
case studies
 were conducted involving a real system derived from the E-SECO platform encompassing a Compost 
Barn
 production system, i.e., the environment and surrounding technology where 
bovine milk
 production takes place.
Results:
Results showed the effectiveness of E-SECO to (i) abstract disruptive technologies based on the 
Internet of Things
 (IoT) and 
Artificial Intelligence
 and accommodate them in a single architecture for that specific domain, (ii) support reuse and derivation of a self-adaptive architecture to support engineering a complex system for a 
livestock
 sub-domain (milk production), and (iii) support empirical studies in a real smart farm towards a future transfer of technology to industry.
Conclusion:
The results showed that the E-SECO platform, which encompasses e-livestock architecture, can support monitoring, reasoning, prediction, and automated actions in a milk production/Compost 
Barn
 environment.",Information and Software Technology,18 Mar 2025,8.0,The presentation of E-SECO platform and its implications for livestock production decision-making can benefit startups in the agri-tech industry by providing innovative solutions for monitoring and automation.
https://www.sciencedirect.com/science/article/pii/S0950584923000952,Towards optimization of anomaly detection in DevOps,August 2023,"Microservices, DevOps, Anomaly detection, Deep learning",Adha=Hrusto: adha.hrusto@cs.lth.se; Emelie=Engström: Not Found; Per=Runeson: Not Found,"Abstract
Context:
DevOps
 has recently become a mainstream solution for bridging the gaps between development (Dev) and operations (Ops) enabling cross-functional collaboration. The DevOps concept of continuous monitoring may bring a lot of benefits to development teams such as early detection of run-time errors and various performance anomalies.
Objective:
We aim to explore 
deep learning
 (DL) solutions for detection of anomalous 
systems behavior
 based on collected 
monitoring data
 that consists of applications’ and systems’ performance metrics. Moreover, we specifically address a shortage of approaches for evaluating 
DL models
 without any ground truth data.
Methods:
We perform a 
case study
 in a real DevOps environment, following the principles of the design science paradigm. The research activities span from practice to theory and from problem to solution domain, including problem conceptualization, solution design, 
instantiation
, and empirical validation.
Results:
We proposed and implemented a cloud solution for DL model deployment and evaluation empowered by feedback from the development team. The labeled data generated through the feedback was used for evaluation of current and training of new DL models in several iterations. The overall results showed that reconstruction-based models such as 
autoencoders
, are quite robust to any parameter modification and are among the preferred for 
anomaly detection
 in multivariate monitoring data.
Conclusion:
Leveraging raw monitoring data and DL-inspired solutions, DevOps teams may get critical insights into the software and its operation. In our case, this proved to be an efficient way of discovering early signs of production failures.",Information and Software Technology,18 Mar 2025,4.0,"While the use of deep learning in DevOps environments is interesting, the direct impact on European early-stage ventures, particularly startups, may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000460,Industrial applications of software defect prediction using machine learning: A business-driven systematic literature review,July 2023,"Software defect prediction, Machine learning, Systematic literature review, Effort and cost minimisation, Real-world, Industry",Szymon=Stradowski: Not Found; Lech=Madeyski: lech.madeyski@pwr.edu.pl,"Abstract
Context:
Machine learning
 
software defect
 prediction is a promising field of 
software engineering
, attracting a great deal of attention from the research community; however, its industry application tents to lag behind academic achievements.
Objective:
This study is part of a larger project focused on improving the quality and minimising the cost of software testing of the 5G system at Nokia, and aims to evaluate the business applicability of machine learning software 
defect prediction
 and gather lessons learnt.
Methods:
The systematic literature review was conducted on journal and 
conference papers
 published between 2015 and 2022 in popular online databases (ACM, IEEE, Springer, Scopus, Science Direct, and Google Scholar). A quasi-gold standard procedure was used to validate the search, and SEGRESS guidelines were used for transparency, reporting, and replicability.
Results:
We have selected and analysed 32 publications out of 397 found by our automatic search (and seven by snowballing). We have identified highly relevant evidence of methods, features, frameworks, and datasets used. However, we found a minimal emphasis on practical lessons learnt and cost consciousness — both vital from a business perspective.
Conclusion:
Even though the number of machine learning software defect prediction studies validated in the industry is increasing (and we were able to identify several excellent papers on studies performed in vivo), there is still not enough practical focus on the business aspects of the effort that would help bridge the gap between the needs of the industry and academic research.",Information and Software Technology,18 Mar 2025,4.0,"The study on machine learning software defect prediction, while important for software engineering, may not have a significant immediate impact on European early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000459,A systematic literature review of capstone courses in software engineering,July 2023,"Capstone, Project course, Computer science education, Software engineering education",Saara=Tenhunen: saaraten@gmail.com; Tomi=Männistö: tomi.mannisto@helsinki.fi; Matti=Luukkainen: matti.luukkainen@helsinki.fi; Petri=Ihantola: petri.ihantola@helsinki.fi,"Abstract
Context:
Tertiary education institutions aim to prepare their computer science and 
software engineering
 students for working life. While much of the technical principles are covered in lower-level courses, team-based capstone courses are a common way to provide students with hands-on experience and teach soft skills.
Objective:
This paper explores the characteristics of project-based software engineering capstone courses presented in the literature. The goal of this work is to understand the pros and cons of different approaches by synthesising the various aspects of software engineering capstone courses and related experiences.
Method:
In a 
systematic literature review
 for 2007–2022, we identified 127 articles describing real-world capstone courses. These articles were analysed based on their presented course characteristics and the reported course outcomes.
Results:
The characteristics were synthesised into a taxonomy consisting of duration, team sizes, client and project sources, project implementation, and 
student assessment
. We found out that capstone courses generally last one semester and divide students into groups of 4–5 where they work on a project for a client. For a slight majority of courses, the clients are external to the course staff and students are often expected to produce a proof-of-concept level software product as the main end deliverable. The courses generally include various forms of student assessment both during and at the end of the course.
Conclusions:
This paper provides researchers and educators with a classification of characteristics of software engineering capstone courses based on previous research. We also further synthesise insights on the reported course outcomes. Our review study aims to help educators to identify various ways of organising capstones and effectively plan and deliver their own capstone courses. The characterisation also helps researchers to conduct further studies on software engineering capstones.",Information and Software Technology,18 Mar 2025,6.0,"The exploration of project-based software engineering capstone courses can provide valuable insights for educators and researchers, but the direct impact on early-stage ventures and startups is moderate."
https://www.sciencedirect.com/science/article/pii/S0950584923000526,Applications of statistical causal inference in software engineering,July 2023,Not Found,Julien=Siebert: julien.siebert@iese.fraunhofer.de,"Abstract
Context:
The aim of statistical causal inference (SCI) methods is to estimate causal effects from 
observational data
 (i.e., when 
randomized controlled trials
 are not possible). In this context, Pearl’s framework based on causal 
graphical models
 is an approach that has recently gained popularity and allows for explicit reasoning about issues related to spurious correlations.
Objective:
Our primary goal is to understand to which extend and how Pearl’s graphical framework is applied in 
software engineering
 (SE).
Methods:
We performed a 
systematic mapping study
 and analysed a total of 
25
 papers published between 2010 and 2022.
Results:
Our results show that the application of Pearl’s SCI framework in SE is relatively recent and that the corresponding research community is fragmented. Most of the selected papers focus on software quality analysis. There is no clear and widespread 
community of practice
 (yet) on how to implement and evaluate SCI in SE.
Conclusions:
To the best of our knowledge this is the first time such a mapping study is done. We believe that SE practitioners might benefit from such a work, as it both provides an overview of the work and people involved in the application of causal inference methods, but also outlines the potential and limitations of such approaches.",Information and Software Technology,18 Mar 2025,6.0,The study on the application of Pearl's graphical framework in software engineering could have a moderate impact on enhancing causal inference methods in early-stage startups.
https://www.sciencedirect.com/science/article/pii/S0950584923000757,"A survey on smart contract vulnerabilities: Data sources, detection and repair",July 2023,Not Found,Hanting=Chu: htchu@hhu.edu.cn; Pengcheng=Zhang: pchzhang@hhu.edu.cn; Hai=Dong: hai.dong@rmit.edu.au; Yan=Xiao: dcsxan@nus.edu.sg; Shunhui=Ji: shunhuiji@hhu.edu.cn; Wenrui=Li: wenrui_li@163.com,"Abstract
Smart contracts
 contain many built-in security features, such as non-immutability once being deployed and non-involvement of third parties for contract execution. These features reduce security risks and enhance users’ trust towards smart contracts. However, smart contract security issues still persist, resulting in huge financial losses. Contract publishers cannot fully cover contract vulnerabilities through contract version updating. These security issues affect further development of 
blockchain technologies
. So far, there are many related studies focusing on smart contract security issues and tend to discuss from a particular perspective (e.g., 
development cycle
, vulnerability attack methods, security detection tools, etc.). However, smart contract security is a complicated issue that needs to be explored from a multi-dimensional perspective. In this paper, we explore smart contract security from the perspectives of vulnerability data sources, 
vulnerability detection
, and vulnerability defense. We first analyze the existing security issues and challenges of smart contracts, investigate the existing vulnerability classification frameworks and common 
security vulnerabilities
, followed by reviewing the existing contract 
vulnerability injection
, detection, and repair methods. We then analyze the performance of existing security methods. Next, we summarize the current status of smart contract security-related research. Finally, we summarize the state of the art and future trends of smart contract security-related research. This paper aims to provide 
systematic knowledge
 and references to this research field.",Information and Software Technology,18 Mar 2025,7.0,Exploring smart contract security from multiple perspectives can provide valuable insights for European early-stage ventures working on blockchain technologies.
https://www.sciencedirect.com/science/article/pii/S0950584923000538,Git command recommendations using crowd-sourced knowledge,July 2023,Not Found,Haitao=Jia: sz2116123@nuaa.edu.cn; Wenhua=Yang: ywh@nuaa.edu.cn; Chaochao=Shen: ccshen@nuaa.edu.cn; Minxue=Pan: mxp@nju.edu.cn; Yu=Zhou: zhouyu@nuaa.edu.cn,"Abstract
Context:
Git is a fast, scalable, distributed version control system with a rich command set that provides high-level operations and full access to the internals. It has been widely used by millions of developers worldwide. However, due to the flexibility of the usage of Git commands and the scarcity of Git documentation, many developers have experienced difficulties when using Git commands.
Objective:
This paper aims to propose an automatic approach to recommending Git commands for developers given a query described by natural language.
Method:
Our approach makes recommendations by mining the crowd-sourced knowledge related to Git on Stack Overflow. It first constructs a keyword-command mapping database from Git-related posts, then analyzes the similarity between the query given by the developer and the keywords in the database to retrieve the candidate commands, and proposes an algorithm to rank the candidate commands.
Results:
Our approach’s recommendation results significantly outperform the baseline approaches in several metrics (e.g., Top-K accuracy). Meanwhile, the experimental results have shown that the favorable efficiency of our approach can promise its use by developers in real-world scenarios.
Conclusion:
The Git command recommendation approach proposed in this paper is effective and can be helpful for developers to use Git commands for more efficient development.",Information and Software Technology,18 Mar 2025,8.0,"The automatic approach to recommending Git commands can significantly benefit developers, including those in early-stage ventures, improving efficiency in development processes."
https://www.sciencedirect.com/science/article/pii/S0950584923000502,Studying the challenges of developing hardware description language programs,July 2023,Not Found,Fatemeh=Yousefifeshki: fatemeh.yousefifeshki@polymtl.ca; Heng=Li: heng.li@polymtl.ca; Foutse=Khomh: foutse.khomh@polymtl.ca,"Abstract
Context:
Developing domain specific architectures (e.g., Google’s TPU) typically requires writing programs in 
Hardware Description Languages
 (HDLs). Compared to traditional general-purpose programming languages (GPPLs) (e.g., C++, Java, Python), developing programs in HDLs (e.g., VHDL or Verilog) lacks support from our community. Such an imbalance in the support for GPPLs and HDLs will impede future advances in 
computer systems
.
Objective:
We believe that our 
software engineering
 community should pay more attention to supporting HDL development. Thus, we make an initial attempt in this direction to study the challenges of developing programs in HDLs by mining HDL-related questions in technical forums.
Method:
We identified 16,700 HDL-related questions in two Stack Exchange forums: Stack Overflow (SO) and Electrical Engineering (EE) Stack Exchange. Through qualitative analysis, 
topic modeling
, and quantitative analysis, we examined the types of questions, the questions’ topics, and identified the most challenging topics for developers.
Results:
We identified ten types of HDL-related questions, including seven types identified in prior work and three new types more relevant to HDLs (e.g., questions related to code explanation and tool search). We also observed that most of the challenges facing HDL developers are similar to those facing GPPL developers, while some challenges (e.g., lower-level operations such as bit and register operations) are more specific to HDLs. Finally, we observed that HDL-related questions are less likely and take a longer time to get accepted answers than GPPL-related questions, and identified the most challenging topics of questions (e.g., file/memory I/O).
Conclusion:
Our work identified opportunities for different stakeholders in the software and hardware communities to improve the practices of developing 
HDL programs
: 
software engineering
 researchers may leverage their expertise to help in advancing HDL languages and methodology, such as to improving the language abstractions for low-level operations such as bit/register operations or memory/file I/Os; Stack Exchange and its moderators may leverage the community size and expertise in both the SO and EE forums to collectively recommend experts to answer questions related to HDLs; HDL language and library developers may provide more actionable error messages, better documentation and logging support to help HDL developers address their encountered issues; tool developers are encouraged to provide advanced IDEs and testing frameworks to help HDL developers improve their development and testing productivity.",Information and Software Technology,18 Mar 2025,5.0,"Studying the challenges of developing programs in HDLs may offer insights, but the practical impact on European early-stage ventures may be limited due to the niche nature of the topic."
https://www.sciencedirect.com/science/article/pii/S0950584923000551,An initial theory to understand and manage requirements engineering debt in practice,July 2023,"Requirements engineering, Requirements engineering debt, Interview study, Online survey, Theory",Julian=Frattini: julian.frattini@bth.se; Davide=Fucci: Not Found; Daniel=Mendez: Not Found; Rodrigo=Spínola: Not Found; Vladimir=Mandić: Not Found; Nebojša=Taušan: Not Found; Muhammad Ovais=Ahmad: Not Found; Javier=Gonzalez-Huerta: Not Found,"Abstract
Context:
Advances in technical debt research demonstrate the benefits of applying the financial debt metaphor to support decision-making in software development activities. Although decision-making during 
requirements engineering
 has significant consequences, the debt metaphor in requirements engineering is inadequately explored.
Objective:
We aim to conceptualize how the debt metaphor applies to requirements engineering by organizing concepts related to practitioners’ understanding and managing of requirements engineering debt (RED).
Method:
We conducted two in-depth expert interviews to identify key requirements engineering debt concepts and construct a survey instrument. We surveyed 69 practitioners worldwide regarding their perception of the concepts and developed an initial analytical theory.
Results:
We propose a RED theory that aligns key concepts from technical debt research but emphasizes the specific nature of requirements engineering. In particular, the theory consists of 23 falsifiable propositions derived from the literature, the interviews, and survey results.
Conclusions:
The concepts of requirements engineering debt are perceived to be similar to their technical debt counterpart. Nevertheless, measuring and tracking requirements engineering debt are immature in practice. Our proposed theory serves as the first guide toward further research in this area.",Information and Software Technology,18 Mar 2025,6.0,"The exploration of requirements engineering debt concepts can be beneficial for startups in managing software development activities, but the practical implementation may require further research and development."
https://www.sciencedirect.com/science/article/pii/S0950584923000691,Characteristics and generative mechanisms of software development productivity distributions,July 2023,Not Found,Magne=Jørgensen: magnej@simula.no,"Abstract
Context
There is considerable variation in the productivity of software developers. Better knowledge about this variation may provide valuable inputs for the design of skill tests and recruitment processes.
Objective
This paper aims to identify properties of software development productivity distributions and gain insight into mechanisms that potentially explain these productivity differences.
Method
Four data sets that contain the results of software developers solving the same programming tasks were collected. The properties of the productivity distributions were analyzed, the fits of different types of distributions to the productivity data were compared, and potential generative mechanisms that would lead to the types of distributions with the best fit to the productivity data were evaluated.
Results
The coefficient of variance of the productivity of the software developers was, on average, 0.55, with the top 50% of developers having average productivity that was 2.44 times higher than the bottom 50% of developers. All productivity samples were right-skewed, with an average skew of 1.79. About 30% of the observed productivity variance was explained by non-systematic, i.e., within-developer, variance. The distributions with the best fit to the empirical productivity data were the lognormal and power-law-with-an-exponential-cutoff distributions. The analysis of the mechanisms leading to productivity differences found no support for the ""rich-getting-richer"" explanation proposed for other disciplines. Instead, it suggests a constant productivity difference with increasing experience.
Conclusion
The substantial difference in productivity among software developers solving programming tasks indicates that a thorough evaluation of skill in the recruitment process can be rewarding. In particular, the long 
tail
 towards higher productivity values demonstrates the large gains that can be achieved by detecting and recruiting developers with very high productivity. More research is needed to understand the mechanisms leading to the large productivity differences.",Information and Software Technology,18 Mar 2025,7.0,"This abstract provides insights into the productivity variations among software developers, which can be valuable for early-stage ventures in optimizing recruitment processes. The potential gains from detecting and recruiting highly productive developers demonstrate practical value for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000721,Dev2vec: Representing domain expertise of developers in an embedding space,July 2023,Not Found,Arghavan Moradi=Dakhel: arghavan.moradi-dakhel@polymtl.ca; Michel C.=Desmarais: michel.desmarais@polymtl.ca; Foutse=Khomh: foutse.khomh@polymtl.ca,"Abstract
Context:
Accurate assessment of the domain expertise of developers is essential for assigning the proper candidate to contribute to a project, or to attend a job role. Since the potential candidate can come from a large pool, the automated assessment of this domain expertise is a desirable goal. While previous methods have had some success within a single software project, the assessment of a developer’s domain expertise from contributions across multiple projects is more challenging.
Objective:
In this paper, we employ 
doc2vec
 to represent the domain expertise of developers across multiple projects as embedding vectors, and assess expertise level from authored code fragments.
Method:
For this purpose, we derived embedding vectors from different sources that contain evidence of developers’ expertise, such as the description of repositories they contributed, their issue resolving history, and API calls in their commits. We name it dev2vec and demonstrate its effectiveness in representing and assessing the technical specialization of developers.
Results:
Our results indicate that encoding the expertise of developers in an embedding vector outperforms state-of-the-art methods and improves the F1-score up to 21%. Moreover, our findings suggest that the “issue resolving history” of developers is the most informative source of information to represent the domain expertise of developers in embedding spaces.
Conclusion:
Our proposed approach sheds light on the effectiveness of representing the technical expertise of developers in embedding vectors, and it can act as initial filtering for recruiters and project managers.",Information and Software Technology,18 Mar 2025,8.0,"Automated assessment of domain expertise in developers across multiple projects can significantly benefit startups in assigning suitable candidates to projects. The proposed dev2vec method shows promising results in assessing technical specialization, which can be valuable for recruiters and project managers."
https://www.sciencedirect.com/science/article/pii/S0950584923000678,Effuzz: Efficient fuzzing by directed search for smart contracts,July 2023,Not Found,Songyan=Ji: Not Found; Jin=Wu: Not Found; Junfu=Qiu: Not Found; Jian=Dong: dan@hit.edu.cn,"Abstract
Context:
A large number of 
Ethereum
 
smart contracts
 have been deployed on 
blockchain
 to manage assets. Unfortunately, due to the immutable nature of 
blockchain
, 
smart contracts
 cannot be modified after deployment, even if vulnerabilities have been exposed to attackers. Therefore, it is critical to efficiently and thoroughly test smart contracts. Greybox fuzzing is a prosperous technique for detecting smart contract vulnerabilities. However, most existing 
fuzzers
 have a common drawback in that they cannot efficiently satisfy hard-to-cover branch constraints.
Objective:
The goal of this paper is to solve the problem of how to efficiently satisfy hard-to-cover branch constraints. After solving this problem, 
fuzz testing
 can execute more code, and there is a higher probability of executing vulnerabilities.
Method:
We propose an approach for addressing this problem. Specifically, we design an input parameter analysis strategy to selectively mutate a subset of input parameters to reduce invalid mutations. Also, to accelerate the processing of satisfying branch constraints, we design an accelerated multi-objective search strategy to reduce the waste of resources.
Result:
We implemented this approach in a tool called Effuzz and applied it to real-world smart contracts. Experiments show that Effuzz finds more vulnerabilities and is more efficient than existing state-of-the-art 
fuzzers
.
Conclusion:
In this paper, we present an approach to efficiently satisfy hard-to-cover branch constraints. Our approach addresses two main problems, i.e., how to select the subset of input parameters for mutation with considering the characteristic of 
Ethereum
 smart contracts, and how to accelerate the search to satisfy hard-to-cover branch constraints without generating excessive ineffective test cases that waste resources. The experimental results show that our approach is effective.",Information and Software Technology,18 Mar 2025,9.0,"Efficiently testing smart contracts is crucial for startups utilizing blockchain technology. The Effuzz tool presented in this abstract offers a solution to efficiently satisfy hard-to-cover branch constraints, leading to the discovery of more vulnerabilities. This has high practical value for early-stage ventures utilizing smart contracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000678,Effuzz: Efficient fuzzing by directed search for smart contracts,July 2023,Not Found,Songyan=Ji: Not Found; Jin=Wu: Not Found; Junfu=Qiu: Not Found; Jian=Dong: dan@hit.edu.cn,"Abstract
Context:
A large number of 
Ethereum
 
smart contracts
 have been deployed on 
blockchain
 to manage assets. Unfortunately, due to the immutable nature of 
blockchain
, 
smart contracts
 cannot be modified after deployment, even if vulnerabilities have been exposed to attackers. Therefore, it is critical to efficiently and thoroughly test smart contracts. Greybox fuzzing is a prosperous technique for detecting smart contract vulnerabilities. However, most existing 
fuzzers
 have a common drawback in that they cannot efficiently satisfy hard-to-cover branch constraints.
Objective:
The goal of this paper is to solve the problem of how to efficiently satisfy hard-to-cover branch constraints. After solving this problem, 
fuzz testing
 can execute more code, and there is a higher probability of executing vulnerabilities.
Method:
We propose an approach for addressing this problem. Specifically, we design an input parameter analysis strategy to selectively mutate a subset of input parameters to reduce invalid mutations. Also, to accelerate the processing of satisfying branch constraints, we design an accelerated multi-objective search strategy to reduce the waste of resources.
Result:
We implemented this approach in a tool called Effuzz and applied it to real-world smart contracts. Experiments show that Effuzz finds more vulnerabilities and is more efficient than existing state-of-the-art 
fuzzers
.
Conclusion:
In this paper, we present an approach to efficiently satisfy hard-to-cover branch constraints. Our approach addresses two main problems, i.e., how to select the subset of input parameters for mutation with considering the characteristic of 
Ethereum
 smart contracts, and how to accelerate the search to satisfy hard-to-cover branch constraints without generating excessive ineffective test cases that waste resources. The experimental results show that our approach is effective.",Information and Software Technology,18 Mar 2025,9.0,"Similar to abstract 13, this abstract offers a solution to efficiently test smart contracts using the Effuzz tool. The effectiveness of the proposed approach in finding vulnerabilities and improving efficiency is highly beneficial for startups working with Ethereum smart contracts."
https://www.sciencedirect.com/science/article/pii/S095058492300068X,Predicting neural network confidence using high-level feature distance,July 2023,Not Found,Jie=Wang: wang_jie@buaa.edu.cn; Jun=Ai: aijun@buaa.edu.cn; Minyan=Lu: lmy@buaa.edu.cn; Jingyu=Liu: liujingyu1@buaa.edu.cn; Zili=Wu: wuzili@buaa.edu.cn,"Abstract
Context:
Neural networks
 have achieved state-of-the-art performance in many fields. However, they are often reported to produce overconfident predictions, especially for 
misclassifications
. Therefore, confidence prediction is vitally important in practical applications to enable models to provide reasonable confidence.
Objective:
The objective of this paper is to address the problem of overconfidence in neural networks. This is achieved by constructing a detector that can predict the probability of incorrect output of the neural network. The goal of the detector is to identify incorrect outputs and adjust their raw confidences to reduce the overconfidence of misclassification.
Method:
The idea of the detector is to learn the relationship between high-level features of inputs and their classification correctness. The high-level feature is the output of the deep hidden layer in the network, and for the 
CNNs
, we chose the last 
convolutional layer
. The training of the detector requires a hold-out validation set, which in practice can be the same set used for hyperparameter tuning. The detector predicts which inputs are likely to be misclassified by neural networks and estimates the probability of misclassification which is then used to adjust the raw softmax confidence, thereby reducing the confidence of misclassification. The detector is learned by deeply mining the 
classification results
 of the validation data produced during the training process of the neural network, no additional data such as disturbance samples needs to be collected.
Results:
Experimental results on the CIFAR-10 dataset and two typical 
neural network structures
, ResNet20 and VGG16, show that our method is effective in reducing the confidence of 
misclassifications
 and maintaining the confidence of correct classifications. The effectiveness of our method is demonstrated on the non-disturbance i.i.d test set and three types of disturbance sets. It outperforms two 
baseline methods
 on all test sets, especially for the i.i.d set, on the misclassification identification task.
Conclusion:
This new method is proven to perform well on both misclassification identification and out-of-distribution detection tasks. In contrast to previous softmax 
calibration methods
 that aim to decrease the confidence of all classifications, the method proposed in this paper innovatively reduces the confidence of misclassification straightforwardly. As a result, it becomes feasible to visually interpret the correctness of classifications using confidence scores. This will lead to a better understanding of the model’s behavior and facilitate more reliable decision-making. Overall, our proposed confidence prediction method represents a promising step towards addressing the overconfidence problem in 
classification tasks
 in 
deep learning
, especially 
image classification
, and is of great value for real-world 
deep learning
 applications.",Information and Software Technology,18 Mar 2025,8.0,"Addressing the issue of overconfidence in neural networks is crucial for practical applications, including startups utilizing deep learning for image classification. The proposed method in this abstract shows effectiveness in reducing misclassification confidence, which can aid startups in making more reliable decisions based on model behavior."
https://www.sciencedirect.com/science/article/pii/S095058492300054X,Continuous deployment in software-intensive system-of-systems,July 2023,Not Found,Anas=Dakkak: anas.dakkak@ericsson.com; Jan=Bosch: jan.bosch@chalmers.se; Helena Holmström=Olsson: helena.holmstrom.olsson@mau.se; David=Issa Mattos: david.mattos@volvocars.com,"Abstract
Context:
While continuous deployment is popular among web-based software development organizations, adopting continuous deployment in software-intensive system-of-systems is more challenging. On top of the challenges arising from deploying software to a single software-intensive embedded system, software-intensive system-of-systems (SiSoS) add a layer of complexity as new software undergoes an extensive field validation applied to individual components of the SiSoS, as well as the overall SiSoS, to ensure that both legacy and new functionalities are working as desired.
Objectives:
This paper aims to study how SiSoS transitions to continuous deployment by exploring how continuous deployment impacts field testing and validation activities, how continuous deployment can be practiced in SiSoS, and to identify the 
success factors
 that companies need to consider when transitioning to continuous deployment.
Method:
We conducted a 
case study
 at Ericsson AB focusing on the 
embedded software
 of the Third Generation 
Radio Access Network
 (3G RAN). The 3G RAN consists of two large-scale software-intensive embedded systems, representing a simple SiSoS composed of two systems. 3G RAN software was the first to transition to continuous deployment and is used as a reference case for other products within Ericsson AB.
Results:
Software deployment, in addition to field testing and validation, have transitioned from being a discrete activity performed at the end of software development to a continuous process performed in parallel to software development. Further, our study reveals an orchestrating approach for software deployment, which allows pre/post validation of legacy behavior and new features in a shorter release and deployment cadence. Furthermore, we identified the essential 
success factors
 that organizations should consider when transitioning to continuous deployment.
Conclusion:
Transition to continuous deployment, in addition to field testing and validation, shall be considered and planned carefully. In this paper, we provide a set of success factors and orchestration technique that helps organization when transitioning to continuous deployment in the software-intensive embedded system-of-systems context.",Information and Software Technology,18 Mar 2025,8.0,"This abstract provides valuable insights into transitioning to continuous deployment in software-intensive systems-of-systems, offering essential success factors for companies. The practical implications for startups in Europe are significant."
https://www.sciencedirect.com/science/article/pii/S0950584923000514,Transparency and explainability of AI systems: From ethical guidelines to requirements,July 2023,"Transparency, Explainability, Ethical guidelines, Quality requirements, Explainability requirements, AI systems",Nagadivya=Balasubramaniam: nagadivya.balasubramaniam@aalto.fi; Marjo=Kauppinen: marjo.kauppinen@aalto.fi; Antti=Rannisto: antti.rannisto@aalto.fi; Kari=Hiekkanen: kari.hiekkanen@aalto.fi; Sari=Kujala: sari.kujala@aalto.fi,"Abstract
Context and Motivation
Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few 
case studies
 that describe the current state of defining these quality requirements in practice.
Objective
This study consisted of two phases. The first goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and 
explainable AI
 systems and then we investigated how explainability requirements can be defined in practice.
Methods
In the first phase, we analyzed the ethical guidelines in 16 organizations representing different industries and public sector. Then, we conducted an empirical study to evaluate the results of the first phase with practitioners.
Results
The analysis of the ethical guidelines revealed that the importance of transparency is highlighted by almost all of the organizations and explainability is considered as an integral part of transparency. To support the definition of explainability requirements, we propose a model of explainability components for identifying explainability needs and a template for representing explainability requirements. The paper also describes the lessons we learned from applying the model and the template in practice.
Contribution
For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a systematic and structured way to define explainability requirements of AI systems. Furthermore, the results emphasize a set of good practices that help to define the explainability of AI systems.",Information and Software Technology,18 Mar 2025,6.0,"While transparency and explainability in AI systems are important, this abstract focuses more on guidelines and models rather than practical implementations. It provides valuable insights for researchers but may have limited direct impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000514,Transparency and explainability of AI systems: From ethical guidelines to requirements,July 2023,"Transparency, Explainability, Ethical guidelines, Quality requirements, Explainability requirements, AI systems",Nagadivya=Balasubramaniam: nagadivya.balasubramaniam@aalto.fi; Marjo=Kauppinen: marjo.kauppinen@aalto.fi; Antti=Rannisto: antti.rannisto@aalto.fi; Kari=Hiekkanen: kari.hiekkanen@aalto.fi; Sari=Kujala: sari.kujala@aalto.fi,"Abstract
Context and Motivation
Recent studies have highlighted transparency and explainability as important quality requirements of AI systems. However, there are still relatively few 
case studies
 that describe the current state of defining these quality requirements in practice.
Objective
This study consisted of two phases. The first goal of our study was to explore what ethical guidelines organizations have defined for the development of transparent and 
explainable AI
 systems and then we investigated how explainability requirements can be defined in practice.
Methods
In the first phase, we analyzed the ethical guidelines in 16 organizations representing different industries and public sector. Then, we conducted an empirical study to evaluate the results of the first phase with practitioners.
Results
The analysis of the ethical guidelines revealed that the importance of transparency is highlighted by almost all of the organizations and explainability is considered as an integral part of transparency. To support the definition of explainability requirements, we propose a model of explainability components for identifying explainability needs and a template for representing explainability requirements. The paper also describes the lessons we learned from applying the model and the template in practice.
Contribution
For researchers, this paper provides insights into what organizations consider important in the transparency and, in particular, explainability of AI systems. For practitioners, this study suggests a systematic and structured way to define explainability requirements of AI systems. Furthermore, the results emphasize a set of good practices that help to define the explainability of AI systems.",Information and Software Technology,18 Mar 2025,6.0,"Similar to abstract 17, this abstract explores transparency and explainability in AI systems without a strong emphasis on practical implementations. It contributes to the research field but may have limited immediate value for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000563,Zero-shot learning for requirements classification: An exploratory study,July 2023,"0000, 1111",Waad=Alhoshan: Not Found; Alessio=Ferrari: alessio.ferrari@isti.cnr.it; Liping=Zhao: liping.zhao@manchester.ac.uk,"Abstract
Context:
Requirements engineering
 (RE) researchers have been experimenting with 
machine learning
 (ML) and 
deep learning
 (DL) approaches for a range of RE tasks, such as requirements classification, requirements tracing, ambiguity detection, and modelling. However, most of today’s ML/DL approaches are based on 
supervised
 learning techniques, meaning that they need to be trained using a large amount of task-specific labelled 
training data
. This constraint poses an enormous challenge to RE researchers, as the lack of labelled data makes it difficult for them to fully exploit the benefit of advanced ML/DL technologies.
Objective:
This paper addresses this problem by showing how a 
zero-shot learning
 (ZSL) approach can be used for requirements classification without using any labelled training data. We focus on the 
classification task
 because many RE tasks can be framed as classification problems.
Methods:
The ZSL approach used in our study employs contextual word-embeddings and transformer-based 
language models
 (LMs). We demonstrate this approach through a series of experiments to perform three classification tasks: (1) FR/NFR — classification functional requirements vs non-functional requirements; (2) 
NFR
 — identification of NFR classes; (3) Security — classification of security vs non-security requirements.
Results:
The study shows that the ZSL approach achieves an F1 score of 0.66 for the FR/NFR task. For the NFR task, the approach yields F1
∼
0
.
72
−
0
.
80
, considering the most frequent classes. For the Security task, F1 
∼
0
.
66
. All of the aforementioned F1 scores are achieved with zero-training efforts.
Conclusion:
This study demonstrates the potential of ZSL for requirements classification. An important implication is that it is possible to have very little or no training data to perform classification tasks. The proposed approach thus contributes to the solution of the long-standing problem of data shortage in RE.",Information and Software Technology,18 Mar 2025,9.0,"This abstract introduces a novel approach using zero-shot learning for requirements classification without labeled training data, addressing a significant challenge for RE researchers. The practical implications of this approach can greatly benefit early-stage ventures in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584923000575,Enhanced abbreviation–expansion pair detection for glossary term extraction,July 2023,Not Found,Hussein=Hasso: hussein.hasso@fkie.fraunhofer.de; Katharina=Großer: grosser@uni-koblenz.de; Iliass=Aymaz: iliass.aymaz@fkie.fraunhofer.de; Hanna=Geppert: hanna.geppert@fkie.fraunhofer.de; Jan=Jürjens: juerjens@uni-koblenz.de,"Abstract
Context:
Providing precise definitions of all project specific terms is a crucial task in 
requirements engineering
. In order to support the glossary building process, many previous tools rely on the assumption that the requirements set has a certain level of quality. Yet, the parallel detection and correction of quality weaknesses in the context of glossary terms is beneficial to requirements definition.
Objective:
In this paper, we focus on detection of uncontrolled usage of abbreviations by identification of abbreviation–expansion pair (AEP) candidates.
Methods:
We compare our feature-based approach (ILLOD+) to other similarity measures to detect AEPs and propose how to extend the glossary term extraction (GTE) and synonym clustering with AEP-specific methods.
Results:
It shows that feature-based methods are more accurate for AEPs than 
syntactic
 and 
semantic similarity measures
. Experiments with PURE data-sets extended with uncontrolled abbreviations show that ILLOD+ is able to extract abbreviations as well as match their expansions viably in a real-world setting and is well suited to augment previous synonym clusters with clusters that combine AEP candidates. AEP clusters generated with ILLOD+ are generally smaller than those based on 
syntactic
 or 
semantic similarity measures
 and have a higher recall.
Conclusion:
In this paper, we present ILLOD+, an extended feature-based approach to AEP detection and propose a workflow for its integration to clustering of glossary term candidates to enhance term consolidation in evolving requirements.",Information and Software Technology,18 Mar 2025,7.0,"The abstract presents an approach for detecting uncontrolled abbreviations in requirements engineering, providing a valuable method for enhancing glossary building processes. While beneficial, the direct impact on startups may be more limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000290,Application of Deep Learning in Software Defect Prediction: Systematic Literature Review and Meta-analysis,June 2023,Not Found,Zuhaira Muhammad=Zain: zmzain@pnu.edu.sa; Sapiah=Sakri: Not Found; Nurul Halimatul Asmak=Ismail: Not Found,"Abstract
Context
Despite recent attention given to Software 
Defect Prediction
 (SDP), the lack of any systematic effort to assess existing empirical evidence on the application of 
Deep Learning
 (DL) in SDP indicates that it is still relatively under-researched.
Objective
To synthesize literature on SDP using DL, pertaining to measurements, models, techniques, datasets, and achievements; to obtain a full understanding of current SDP-related methodologies using DL; and to compare the DL models’ performances with those of 
Machine Learning
 (ML) models in classifying software defects.
Method
We completed a thorough review of the literature in this domain. To answer the research issues, results from primary investigations were synthesized. The preliminary findings for DL vs. ML in SDP were verified by using meta-analysis (MA).
Result
We discovered 63 primary studies that passed the systematic literature review quality evaluation. However, only 19 primary studies passed the MA quality evaluation. The five most popular performance measurements employed in SDP were f-measure, recall, accuracy, precision, and Area Under the Curve (AUC). The top five 
DL techniques
 used in building SDP models were 
Convolutional Neural Network
 (CNN), 
Deep Neural Network
 (DNN), Long Short-Term Memory (LSTM), 
Deep Belief Network
 (DBN), and Stacked 
Denoising
 
Autoencoder
 (SDAE). PROMISE and NASA datasets were found to be used more frequently to train and test 
DL models
 in SDP. The MA results show that DL was favored over ML in terms of study and dataset across accuracy, f-measure, and AUC.
Conclusion
The application of DL in SDP remains a challenge, but it has the potential to achieve better 
predictive performance
 when the performance-influencing parameters are optimized. We provide a 
reference point
 for future research which could be used to improve research quality in this domain.",Information and Software Technology,18 Mar 2025,7.0,The abstract presents valuable insights on the application of Deep Learning in Software Defect Prediction which can potentially benefit early-stage ventures in the tech industry.
https://www.sciencedirect.com/science/article/pii/S0950584923000290,Application of Deep Learning in Software Defect Prediction: Systematic Literature Review and Meta-analysis,June 2023,Not Found,Zuhaira Muhammad=Zain: zmzain@pnu.edu.sa; Sapiah=Sakri: Not Found; Nurul Halimatul Asmak=Ismail: Not Found,"Abstract
Context
Despite recent attention given to Software 
Defect Prediction
 (SDP), the lack of any systematic effort to assess existing empirical evidence on the application of 
Deep Learning
 (DL) in SDP indicates that it is still relatively under-researched.
Objective
To synthesize literature on SDP using DL, pertaining to measurements, models, techniques, datasets, and achievements; to obtain a full understanding of current SDP-related methodologies using DL; and to compare the DL models’ performances with those of 
Machine Learning
 (ML) models in classifying software defects.
Method
We completed a thorough review of the literature in this domain. To answer the research issues, results from primary investigations were synthesized. The preliminary findings for DL vs. ML in SDP were verified by using meta-analysis (MA).
Result
We discovered 63 primary studies that passed the systematic literature review quality evaluation. However, only 19 primary studies passed the MA quality evaluation. The five most popular performance measurements employed in SDP were f-measure, recall, accuracy, precision, and Area Under the Curve (AUC). The top five 
DL techniques
 used in building SDP models were 
Convolutional Neural Network
 (CNN), 
Deep Neural Network
 (DNN), Long Short-Term Memory (LSTM), 
Deep Belief Network
 (DBN), and Stacked 
Denoising
 
Autoencoder
 (SDAE). PROMISE and NASA datasets were found to be used more frequently to train and test 
DL models
 in SDP. The MA results show that DL was favored over ML in terms of study and dataset across accuracy, f-measure, and AUC.
Conclusion
The application of DL in SDP remains a challenge, but it has the potential to achieve better 
predictive performance
 when the performance-influencing parameters are optimized. We provide a 
reference point
 for future research which could be used to improve research quality in this domain.",Information and Software Technology,18 Mar 2025,7.0,"Similar to abstract 21, this abstract provides significant findings on the use of Deep Learning in Software Defect Prediction, which could be valuable for European startups in the software development sector."
https://www.sciencedirect.com/science/article/pii/S0950584923000307,Requirements engineering for artificial intelligence systems: A systematic mapping study,June 2023,Not Found,Khlood=Ahmad: ahmadkhl@deakin.edu.au; Mohamed=Abdelrazek: mohamed.abdelrazek@deakin.edu.au; Chetan=Arora: chetan.arora@monash.edu; Muneera=Bano: muneera.bano@csiro.au; John=Grundy: john.grundy@monash.edu,"Abstract
Context:
In traditional software systems, 
Requirements Engineering
 (RE) activities are well-established and researched. However, building 
Artificial Intelligence
 (AI) based software with limited or no insight into the system’s inner workings poses significant new challenges to RE. Existing literature has focused on using AI to manage RE activities, with limited research on RE for AI (RE4AI).
Objective:
This paper investigates current approaches for specifying requirements for AI systems, identifies available frameworks, methodologies, tools, and techniques used to model requirements, and finds existing challenges and limitations.
Method:
We performed a 
systematic mapping study
 to find papers on current RE4AI approaches. We identified 43 primary studies and analyzed the existing methodologies, models, tools, and techniques used to specify and model requirements in real-world scenarios.
Results:
We found several challenges and limitations of existing RE4AI practices. The findings highlighted that current 
RE applications
 were not adequately adaptable for building AI systems and emphasized the need to provide new techniques and tools to support RE4AI.
Conclusion:
Our results showed that most of the empirical studies on RE4AI focused on autonomous, self-driving vehicles and managing data requirements, and areas such as ethics, trust, and explainability need further research.",Information and Software Technology,18 Mar 2025,5.0,"While the abstract addresses challenges in Requirements Engineering for AI systems, the practical implications for early-stage ventures may be limited compared to the abstracts focusing on software defect prediction."
https://www.sciencedirect.com/science/article/pii/S095058492300023X,Just-in-time code duplicates extraction,June 2023,Not Found,Eman Abdullah=AlOmar: ealomar@stevens.edu; Anton=Ivanov: apivanov_1@edu.hse.ru; Zarina=Kurbatova: zarina.kurbatova@jetbrains.com; Yaroslav=Golubev: yaroslav.golubev@jetbrains.com; Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Timofey=Bryksin: timofey.bryksin@jetbrains.com; Le=Nguyen: ln8378@rit.edu; Amit=Kini: ak3328@rit.edu; Aditya=Thakur: at4415@rit.edu,"Abstract
Context:
Refactoring is a critical task in software maintenance, and is usually performed to enforce better design and coding practices, while coping with design defects. The 
Extract Method
 refactoring is widely used for merging duplicate code fragments into a single new method. Several studies attempted to recommend 
Extract Method
 refactoring opportunities using different techniques, including program slicing, program 
dependency graph
 analysis, change history analysis, 
structural similarity
, and feature extraction. However, irrespective of the method, most of the existing approaches interfere with the developer’s workflow: they require the developer to stop coding and analyze the suggested opportunities, and also consider all refactoring suggestions in the entire project without focusing on the development context.
Objective:
To increase the adoption of the 
Extract Method
 refactoring, in this paper, we aim to investigate the effectiveness of 
machine learning
 and 
deep learning algorithms
 for its recommendation while maintaining the workflow of the developer.
Method:
The proposed approach relies on mining prior applied 
Extract Method
 refactorings and extracting their features to train a deep learning classifier that detects them in the user’s code. We implemented our approach as a plugin for IntelliJ IDEA called 
AntiCopyPaster
. To develop our approach, we trained and evaluated various popular models on a dataset of 18,942 code fragments from 13 Open Source Apache projects.
Results:
The results show that the best model is the 
Convolutional Neural Network
 (CNN), which recommends appropriate 
Extract Method
 refactorings with an F-measure of 0.82. We also conducted a qualitative study with 72 developers to evaluate the usefulness of the developed plugin.
Conclusion:
The results show that developers tend to appreciate the idea of the approach and are satisfied with various aspects of the plugin’s operation.",Information and Software Technology,18 Mar 2025,8.0,"This abstract offers a concrete approach using machine learning and deep learning for recommending code refactoring, which could have a direct impact on the productivity and efficiency of European early-stage software development startups."
https://www.sciencedirect.com/science/article/pii/S095058492300023X,Just-in-time code duplicates extraction,June 2023,Not Found,Eman Abdullah=AlOmar: ealomar@stevens.edu; Anton=Ivanov: apivanov_1@edu.hse.ru; Zarina=Kurbatova: zarina.kurbatova@jetbrains.com; Yaroslav=Golubev: yaroslav.golubev@jetbrains.com; Mohamed Wiem=Mkaouer: mwmvse@rit.edu; Timofey=Bryksin: timofey.bryksin@jetbrains.com; Le=Nguyen: ln8378@rit.edu; Amit=Kini: ak3328@rit.edu; Aditya=Thakur: at4415@rit.edu,"Abstract
Context:
Refactoring is a critical task in software maintenance, and is usually performed to enforce better design and coding practices, while coping with design defects. The 
Extract Method
 refactoring is widely used for merging duplicate code fragments into a single new method. Several studies attempted to recommend 
Extract Method
 refactoring opportunities using different techniques, including program slicing, program 
dependency graph
 analysis, change history analysis, 
structural similarity
, and feature extraction. However, irrespective of the method, most of the existing approaches interfere with the developer’s workflow: they require the developer to stop coding and analyze the suggested opportunities, and also consider all refactoring suggestions in the entire project without focusing on the development context.
Objective:
To increase the adoption of the 
Extract Method
 refactoring, in this paper, we aim to investigate the effectiveness of 
machine learning
 and 
deep learning algorithms
 for its recommendation while maintaining the workflow of the developer.
Method:
The proposed approach relies on mining prior applied 
Extract Method
 refactorings and extracting their features to train a deep learning classifier that detects them in the user’s code. We implemented our approach as a plugin for IntelliJ IDEA called 
AntiCopyPaster
. To develop our approach, we trained and evaluated various popular models on a dataset of 18,942 code fragments from 13 Open Source Apache projects.
Results:
The results show that the best model is the 
Convolutional Neural Network
 (CNN), which recommends appropriate 
Extract Method
 refactorings with an F-measure of 0.82. We also conducted a qualitative study with 72 developers to evaluate the usefulness of the developed plugin.
Conclusion:
The results show that developers tend to appreciate the idea of the approach and are satisfied with various aspects of the plugin’s operation.",Information and Software Technology,18 Mar 2025,8.0,"Similar to abstract 24, this abstract presents a valuable approach for recommending code refactoring using machine learning and deep learning, which can be beneficial for European startups in the software maintenance domain."
https://www.sciencedirect.com/science/article/pii/S0950584923000241,An investigation of causes and effects of trust in Boundary Artefacts,June 2023,"Software development, Boundary Artefact, Trust, Trusting beliefs",Raquel=Ouriques: raquel.ouriques@bth.se; Fabian=Fagerholm: Not Found; Daniel=Mendez: Not Found; Baldvin Gislason=Bern: Not Found,"Abstract
Context:
Boundary Artefacts (BAs) support software development activities in many aspects because it carries lots of information in the same object that can be used and interpreted by several social groups within an organisation. When the BAs are inconsistent regarding their content, such as many meanings or lack of contextual information, their efficiency is reduced because stakeholders will not trust them.
Objective:
This study aimed to understand the implications of differences in the perception of trust on software projects and their influence on stakeholders’ behaviour.
Methods:
We conducted an exploratory 
case study
 to observe the creation and utilisation of one specific BA and the implications of differences in trust and their influence on stakeholders’ behaviour.
Results
: Our investigation has shown that practitioners adding and adjusting existing content do not entirely understand the stakeholders’ needs. Together with the partial management of the content, trust is impacted. When the content of BAs does not meet the trust factors, specifically reliability and predictability, the stakeholders cannot execute their tasks appropriately, and several implications affect the software development project. Additionally, they create workarounds to supply their needs.
Conclusion:
The differences in trust in BAs affect software projects in different areas of the organisation and interfere with the task execution of various stakeholders. The decrease in trust results from inconsistencies in the content associated with the lack of management of the BA. A structured strategy for representing and managing a BA’s content seems appropriate to increase trust levels and efficiency.",Information and Software Technology,18 Mar 2025,7.0,"The study addresses a critical issue in software development affecting trust levels and efficiency, which can have a significant impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000174,It’s about time: How to study intertemporal choice in systems design,June 2023,"Intertemporal choice, Temporal discounting, Judgement and decision making, Naturalistic decision making, Cognitive task analysis, Psychology, Human factors",Fabian=Fagerholm: fabian.fagerholm@aalto.fi; Andres=De los Ríos: andres.dlr94@gmail.com; Carol=Cárdenas Castro: carolcardenasc@gmail.com; Jenny=Gil: gil.j.jenny@gmail.com; Alexander=Chatzigeorgiou: achat@uom.edu.gr; Apostolos=Ampatzoglou: a.ampatzoglou@uom.edu.gr; Christoph=Becker: christoph.becker@utoronto.ca,"Abstract
Context:
Decision making
 pervades software and systems engineering. 
Intertemporal
 decisions involve trade-offs among outcomes at different points in time. They play a central role in systems design, as recognised since the inception of the 
software engineering
 (SE) field. They are also crucial for the sustainability of design decisions. However, temporal decision making is not adequately understood in SE. The field of Judgement and Decision Making (JDM) offers important empirical findings and research methods that could be utilised.
Objective:
This article establishes a baseline for studying how software professionals handle intertemporal choices. It examines how temporal distance affects choices in an example scenario, explores in what areas of software development such decisions can be found, and examines how systems design decisions can be characterised and studied as intertemporal.
Method:
We developed a method to study intertemporal choice in SE, based on an initial set of psychological 
theory grounded
 in JDM. We instantiated the method in a study to elicit responses to an intertemporal choice task followed by a 
Cognitive Task Analysis
 (CTA) interview.
Results:
We found that study participants overall tended to discount future outcomes, but individual participants varied wildly in how they valued present vs. future outcomes. They indicated several locations in which intertemporal choices occur in everyday software development. Based on these findings, and by reconciling our initial theory with existing JDM theory and results, we further developed and refined our theory and study method into a framework for studying intertemporal decision making in SE.
Conclusions:
To obtain a basis for more sustainable software systems design decisions, SE research should adopt a more comprehensive, detailed, and empirically consistent way of understanding and studying intertemporal choices. We provide suggestions for how future research could achieve practical methods that address essential characteristics of real-life systems design decisions.",Information and Software Technology,18 Mar 2025,6.0,"The research on intertemporal decision making in software engineering can provide valuable insights, but may have a slightly lower practical impact compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000277,Squeeziness for non-deterministic systems,June 2023,"Software testing, Failed error propagation, Non-deterministic systems, Information theory",Alfredo=Ibias: a.ibias@sanoscience.org; Manuel=Núñez: mn@sip.ucm.es,"Abstract
Context:
Failed 
Error Propagation
 greatly reduces the effectiveness of Software Testing by masking faults present in the code. This situation happens when the System Under Test executes a faulty statement, the state of the system is affected by this fault, but the expected output is observed. Therefore, it is a must to assess its impact in the testing process. Squeeziness has been shown to be a useful measure to assess the likelihood of fault masking in deterministic systems.
Objective:
The main goal of this paper is to define a new Squeeziness notion that can be used in a scenario where we may have non-deterministic behaviours. The new notion should be a conservative extension of the previous one. In addition, it would be necessary to evaluate whether the new notion appropriately estimates the likelihood that a component of a system introduces Failed Error Propagation.
Method:
We defined our black-box scenario where non-deterministic behaviours might appear. Next, we presented a new Squeeziness notion that can be used in this scenario. Finally, we carried out different experiments to evaluate the usefulness of our proposal as an appropriate estimation of the likelihood of Failed Error Propagation.
Results:
We found a high correlation between our new Squeeziness notion and the likelihood of Failed Error Propagation in non-deterministic systems. We also found that the extra computation time with respect to the deterministic version of Squeeziness was negligible.
Conclusion:
Our new Squeeziness notion is a good measure to estimate the likelihood of Failed Error Propagation being introduced by a component of a system (potentially) showing non-deterministic behaviours. Since it is a conservative extension of the original notion and the extra computation time needed to compute it, with respect to the time needed to compute the former notion, is very small, we conclude that the new notion can be safely used to assess the likelihood of fault masking in deterministic systems.",Information and Software Technology,18 Mar 2025,8.0,The new Squeeziness notion for assessing Failed Error Propagation in non-deterministic systems can have direct practical applications and benefits for early-stage ventures.
https://www.sciencedirect.com/science/article/pii/S0950584923000253,Microservice extraction using graph deep clustering based on dual view fusion,June 2023,Not Found,Lifeng=Qian: Not Found; Jing=Li: lijing@nuaa.edu.cn; Xudong=He: Not Found; Rongbin=Gu: Not Found; Jiawei=Shao: Not Found; Yuqi=Lu: Not Found,"Abstract
Context:
With the increasing scale of software, traditional 
monolithic architecture
 applications are challenging to maintain and scale on cloud platforms. Many companies increasingly adopt 
microservices architecture
 as a more flexible choice.
Objective:
However, 
microservice
 migration is still challenging due to the lack of higher-quality 
microservice
 extraction methods. Traditional microservice extraction methods cannot effectively combine the structural dependency and business functions of 
monolithic applications
; thus, their performance warrants improvement.
Method:
This paper proposes a graph deep 
clustering method
 based on dual view fusion (GDC-DVF) for microservice extraction. GDC-DVF constructs a graph of invocation relationships between classes, which is the structural dependency view, using the runtime trace data of a monolithic application. Then the business function view is constructed by the 
random walk
 algorithm and uniform random sampling using the structural dependency view. Next, the fused node feature embedding representations of the two views are learned using a graph encoder based on a graph attention adaptive 
residual network
. Clustering is performed on the fused feature embedding representations to obtain microservice extraction proposals.
Results:
GDC-DVF is tested on four open-source 
monolithic applications
 and achieves better performance compared with comparison methods.
Conclusion:
Experimental results show that GDC-DVF can extract high-quality microservice collections and validate the effectiveness and scalability of the 
graph neural network
 (GNN) for microservice extraction problems.",Information and Software Technology,18 Mar 2025,9.0,"The proposed GDC-DVF method for microservice extraction addresses a current challenge in software architecture, offering a valuable solution for startups seeking to migrate to microservices."
https://www.sciencedirect.com/science/article/pii/S0950584923000319,Maintainability enhancement based on uncertain model transformations,June 2023,Not Found,Youness=Laghouaouta: laghouaouta@inpt.ac.ma; Pierre=Laforcade: pierre.laforcade@univ-lemans.fr,"Abstract
Context:
Managing uncertainty while expressing model transformations is problematic. Indeed, we are constrained to express various transformation specifications implementing the different possibilities. These possibilities are driven by the need to realize the relevance of each scenario to choose the best one (uncertainty on a transformation scenario) or result from the need to propose other alternatives to a given scenario if it is not feasible (uncertainty on the feasibility of a transformation scenario). In both cases, we face 
maintainability
 issues related to handling separated and frequently changed transformation specifications.
Objective:
This paper gives a global overview of our approach to deal with uncertainty in model transformations while focusing on 
maintainability
 aspect.
Methods:
We have proposed a new approach for dealing with uncertainty in model transformations. Basically, our approach makes use of partiality to allow expressing a transformation specification that covers different possibilities. The current paper focuses on the impact of our proposal to enhance changeability. This has been demonstrated by carrying out 
comparative experiments
 involving three other transformation techniques while considering the effort required to implement a change.
Results:
Our experiments show that our approach has proven useful and effective for implementing changes, mainly for complex ones.
Conclusion:
This paper provides an overview of our approach for managing uncertainty within model transformations. Mainly, it focuses on the impact of our proposal to enhance changeability. The experiment results reveal that our proposal allows expressing highly changeable specifications.",Information and Software Technology,18 Mar 2025,8.0,"The approach for managing uncertainty in model transformations, focusing on maintainability, can be highly beneficial for early-stage ventures facing complex transformation scenarios."
https://www.sciencedirect.com/science/article/pii/S095058492300040X,Towards an understanding of reliability of software-intensive systems-of-systems,June 2023,Not Found,Francisco Henrique Cerdeira=Ferreira: francisco.ferreira@uniriotec.br; Elisa Yumi=Nakagawa: Not Found; Rodrigo Pereira dos=Santos: Not Found,"Abstract
Context:
Large-scale software-intensive Systems-of-Systems (SoS) have become present in several critical domains and have sometimes depended on diverse trending technologies, such as 
cloud computing
 and 
machine learning
. At the same time, the 
SoS dynamic
 architecture makes it difficult to assure SoS reliability leading to diverse studies with specific solutions, while the need for a shared view of what precisely SoS reliability refers to still exists.
Objective:
The main contribution of this article is to go towards an understanding of SoS reliability. We present a conceptual model whose concepts as well as their definitions and relationships were defined by systematically examining the literature of the field.
Methods:
We surveyed 36 practitioners and researchers regarding ambiguity, 
explanatory power
, parsimony, generality, and utility of our model. Next, we adjusted our model according to their contribution.
Results:
We reach a conceptual model containing 29 concepts and their relationships that help to comprehend SoS reliability. In addition, we provided a glossary with a definition of each concept of our conceptual model. We also proposed a SoS reliability definition grounded on the literature.
Conclusions:
By organizing the knowledge of SoS reliability, this conceptual model makes it possible to expand the body of knowledge in the area and opens several opportunities for further investigations; in particular, this model serves as a basis for novel solutions aiming to assure SoS reliability.",Information and Software Technology,18 Mar 2025,7.0,"The conceptual model presented in this abstract can help expand the knowledge in the area of SoS reliability, providing opportunities for further investigations and solutions for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000423,Describing the APIs comprehensively: Obtaining the holistic representations from multiple modalities data for different tasks,June 2023,Not Found,Xun=Li: Not Found; Lei=Liu: Not Found; Zhiqi=Chen: Not Found; Yuzhou=Liu: liuyuzhou@jlu.edu.cn; Huaxiao=Liu: Not Found,"Abstract
Context:
API (Application Programming Interface) is an important object in software development, and describing them properly is the basis for solving related problems, such as API recommendation. Recently, multimodal data fusing approaches become a hot 
research topic
 in different fields, and they can be used to get comprehensive representations of things by describing them from different angles. This provides us with a new useful way for API representation.
Objective:
In this work, we aim at describing APIs comprehensively by fusing information from multimodal data for supporting different API-related tasks.
Method:
To achieve this goal, we propose a novel approach BDBM (Bimodal Deep Boltzmann Machine) to obtain holistic representations of APIs by fusing the information in text and code modalities, which are the API descriptions and the codes of the products. Then, the BDBM is applied to two typical API tasks (API recommendation and similar API mining) to analyze its performance.
Results and Conclusion:
The results show that the API recommendation based on BDBM outperforms the ones based on unimodal 
API information
, our method’s precisions can reach 0.67, 0.65, 0.61 at top-3, top-5 and top-10, while MAP and MRR are 0.66 and 0.67. Meanwhile, the close representations give similar APIs with similar functionalities as well as similar usage in codes. Thus, we believe that 
multimodal data fusion
 is suitable for describing APIs, and the holistic representations given by BDBM can be used in different API-related tasks.",Information and Software Technology,18 Mar 2025,8.0,"The approach proposed in this abstract for API representation based on multimodal data fusion can have a significant impact on software development, providing new ways to describe APIs and improve performance in related tasks for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000411,Fault-insertion and fault-fixing behavioural patterns in Apache Software Foundation Projects,June 2023,"Faults analysis, LDA, Mining software repositories",Marco=Ortu: marco.ortu@unica.it; Giuseppe=Destefanis: giuseppe.destefanis@brunel.ac.uk; Tracy=Hall: tracy.hall@lancaster.ac.uk; David=Bowes: d.h.bowes@lancaster.ac.uk,"Abstract
Background:
Developers inevitably make human errors while coding. These errors can lead to faults in code, some of which may result in system failures. It is important to reduce the faults inserted by developers as well as fix any that slip through.
Aim:
To investigate the fault insertion and fault fixing activities of developers. We identify developers who insert and fix faults, ask whether code topic ‘experts’ insert fewer faults, and experts fix more faults and whether patterns of insertion and fixing change over time.
Methods:
We perform a time-based analysis of developer activity on twelve Apache projects using 
Latent Dirichlet Allocation
 (LDA), 
Network Analysis
 and 
Topic Modelling
. We also build three models (using Petri-net, 
Markov Chain
 and Hawkes Processes) which describe and simulate developers’ bug-introduction and fixing behaviour.
Results:
We show that: the majority of the projects we analysed have developers who dominate in the insertion and fixing of faults; Faults are less likely to be inserted by developers with code topic expertise; Different projects have different patterns of fault inserting and fixing over time.
Conclusions:
We recommend that projects identify the code topic expertise of developers and use expertise information to inform the assignment of project work.",Information and Software Technology,18 Mar 2025,5.0,"While the investigation on fault insertion and fixing activities of developers is relevant, the practical value for startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584923000320,Automated event extraction of CVE descriptions,June 2023,Not Found,Ying=Wei: Not Found; Lili=Bo: lilibo@yzu.edu.cn; Xiaobing=Sun: Not Found; Bin=Li: lb@yzu.edu.cn; Tao=Zhang: Not Found; Chuanqi=Tao: Not Found,"Abstract
Context:
The dramatically increasing number of vulnerabilities makes manual 
vulnerability analysis
 increasingly more difficult. Automatic extraction of 
vulnerability information
 can help improve 
vulnerability analysis
. However, the existing 
vulnerability information
 extraction methods do not extract from the perspective of events, and the existing 
event extraction
 methods do not consider the unique sentence structure characteristics of vulnerability descriptions, which makes it difficult to extract vulnerability information effectively.
Objective:
To extract vulnerability information, we treat each vulnerability as an event, and propose an approach, 
VE-Extractor
, to automatically perform vulnerability 
event extraction
 from textual descriptions in vulnerability reports for vulnerability analysis, including extraction of vulnerability event trigger (cause) and event arguments (e.g., consequence, operation).
Method:
First, we propose a new labeling method BIOFR (Begin, Inside, Outside, Front, Rear) to construct an event-perspective vulnerability data benchmark. Then, we design a question template based on event trigger, to automatically extract vulnerability event arguments through the 
BERT
 Q&A model.
Results:
Experiments show the effectiveness of 
VE-Extractor
 for automatically extracting events from vulnerability description, with significant 
performance improvement
 over state-of-the-art techniques, e.g., F1-score is increased by 45.12% and 21.02% in vulnerability consequence and operation extraction, respectively.
Conclusion:
The proposed 
VE-Extractor
 achieves a higher precision and accuracy than the state-of-the-art methods. Experiments results show that our approach is effective in extracting vulnerability event information and can be used to assist vulnerability analysis, such as vulnerability classification.",Information and Software Technology,18 Mar 2025,9.0,"The VE-Extractor approach presented in this abstract can greatly benefit vulnerability analysis, providing a more effective way to automatically extract vulnerability information for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000447,Detecting multi-type self-admitted technical debt with generative adversarial network-based neural networks,June 2023,Not Found,Jiaojiao=Yu: Not Found; Xu=Zhou: Not Found; Xiao=Liu: Not Found; Jin=Liu: jinliu@whu.edu.cn; Zhiwen=Xie: Not Found; Kunsong=Zhao: Not Found,"Abstract
Context:
Developers often introduce the self-admitted technical debt (SATD), i.e., a compromised solution to satisfy the delivery of the current goals, in code comments but do not eliminate them timely in the following software development and maintenance process. Automatically identifying the SATDs to reduce potential harm to software has attracted the attention of researchers. However, existing approaches only identified SATDs at a coarse-grained level, which impacts developers to locate and remove them.
Objective:
This paper proposes a novel model named GCF, which is a 
deep learning
 method to enhance the performance of multi-type SATD classification based on 
generative adversarial network
. Method: The GCF model employs the JSD Generative Adversarial Network to solve the imbalance problem, utilizes CodeBERT to fuse information of code snippets and natural language for initializing the instances as embedding vectors, and introduces the feature extraction module to extract the instance features more comprehensively.
Results:
The experimental results show that, the GCF model obtains better performance compared with the state-of-the-art method. Moreover, experiments on the GCF model variants and others with different GAN models show the superiority of the GCF model.
Conclusion:
Our proposed GCF model effectively solves the problem of imbalanced types of SATD, fuses the information of code snippets and natural language, and extracts key features to achieve outstanding performance in detecting multi-type SATD. Therefore, the GCF model is an effective method for detecting multi-type SATD.",Information and Software Technology,18 Mar 2025,8.0,"The GCF model proposed in this abstract addresses an important issue in software development (identifying self-admitted technical debt) and shows better performance compared to existing methods, which can be valuable for startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000496,User story extraction from natural language for requirements elicitation: Identify software-related information from online news,June 2023,Not Found,Daniel=Siahaan: daniel@if.its.ac.id; Indra Kharisma=Raharjana: Not Found; Chastine=Fatichah: Not Found,"Abstract
Context
The user story is a popular artifact in 
agile software development
. Extracting user stories is helpful for process improvement in 
requirements elicitation
, closing limitations such as limited access, and uncovering new and unique domains. Most sources of 
requirements elicitation
 are available in natural language form. However, the approach to extracting user stories from natural language is still limited.
Objective
This study aims to extract user stories from natural language. It includes identifying the aspect of who (stakeholder), aspect of what (stakeholder's wants), and aspect of why (the reason why the aspect of what exists).
Method
This study used online news as a 
case study
 because information related to stakeholders and their needs is available. Aspects of who, what, and why are obtained using a rule-based approach using part-of-speech (POS) chunking, 
named entity recognition
 (NER), 
dependency parsing
, WordNet, and BloomSoft.
Result
We found that online news tends to generate requirements with hard-goals or soft-goals types. In identifying aspects of who, we succeeded in increasing the F-score value by combining stakeholder identification methods according to the characteristics of online news. We also found that PUblic REquirements (PURE), domain specificity, and WordNet lexical names can significantly improve the extraction of software-related information in identifying the aspects of what.
Conclusion
This study demonstrates that information related to software requirements could arise from non-software-related artifacts such as online news.",Information and Software Technology,18 Mar 2025,7.0,"The study on extracting user stories from natural language has practical value for agile software development, process improvement, and requirements elicitation, which can benefit early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000484,An Abstract Syntax Tree based static fuzzing mutation for vulnerability evolution analysis,June 2023,Not Found,Wei=Zheng: wzheng@nwpu.edu.cn; Peiran=Deng: dengpeiran@mail.nwpu.edu.cn; Kui=Gui: guikui@mail.nwpu.edu.cn; Xiaoxue=Wu: xiaoxuewu@yzu.edu.cn,"Abstract
Context:
Zero-day vulnerabilities are highly destructive and sudden. However, traditional static and dynamic testing methods cannot efficiently detect them.
Objective:
In this paper, a static fuzzy mutation method for program code is studied. This method can improve the efficiency of mutation sample generation according to the vulnerability evolution law, thus promoting the development of zero-day 
vulnerability detection
 methods based on 
deep learning techniques
.
Method:
A static fuzzy mutation method based on the 
Abstract Syntax Tree
 (AST) is proposed. Under the guidance of software vulnerability evolution law, potential evolution paths that threaten program security are detected, and mutation samples containing vulnerabilities are generated at the syntax tree level based on the paths. To verify the effectiveness of static fuzzy mutation based on ASTs, this paper starts with Concurrent Use After Free (CUAF) homologous vulnerability. It uses multi-threaded programs to perform vulnerability feature statement insertion processing to infer the optimal 
mutation operator
 execution sequence corresponding to CUAF vulnerabilities triggered by data competition. The Linux kernel code is used to verify whether it can effectively reduce the number of invalid mutation samples.
Results:
In this paper, we filter the code fragments in the Linux kernel public code containing CUAF vulnerability fix commits and perform static fuzzy mutation on the fix versions of the vulnerabilities to reproduce the vulnerabilities of this type triggered by these code fragments on the timeline. We compare the process with the execution of the random 
mutation operator
 in traditional detection methods horizontally and improve the efficiency by 42.4% on average.
Conclusion:
The static fuzzy mutation based on the AST is effective in stages. When this method is explored in more vulnerability-type evolution laws, it is expected to promote the development of the zero-day vulnerability active detection technology framework.",Information and Software Technology,18 Mar 2025,9.0,"The study on static fuzzy mutation for detecting zero-day vulnerabilities using deep learning techniques has high impact potential for improving security measures in software development, making it valuable for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000484,An Abstract Syntax Tree based static fuzzing mutation for vulnerability evolution analysis,June 2023,Not Found,Wei=Zheng: wzheng@nwpu.edu.cn; Peiran=Deng: dengpeiran@mail.nwpu.edu.cn; Kui=Gui: guikui@mail.nwpu.edu.cn; Xiaoxue=Wu: xiaoxuewu@yzu.edu.cn,"Abstract
Context:
Zero-day vulnerabilities are highly destructive and sudden. However, traditional static and dynamic testing methods cannot efficiently detect them.
Objective:
In this paper, a static fuzzy mutation method for program code is studied. This method can improve the efficiency of mutation sample generation according to the vulnerability evolution law, thus promoting the development of zero-day 
vulnerability detection
 methods based on 
deep learning techniques
.
Method:
A static fuzzy mutation method based on the 
Abstract Syntax Tree
 (AST) is proposed. Under the guidance of software vulnerability evolution law, potential evolution paths that threaten program security are detected, and mutation samples containing vulnerabilities are generated at the syntax tree level based on the paths. To verify the effectiveness of static fuzzy mutation based on ASTs, this paper starts with Concurrent Use After Free (CUAF) homologous vulnerability. It uses multi-threaded programs to perform vulnerability feature statement insertion processing to infer the optimal 
mutation operator
 execution sequence corresponding to CUAF vulnerabilities triggered by data competition. The Linux kernel code is used to verify whether it can effectively reduce the number of invalid mutation samples.
Results:
In this paper, we filter the code fragments in the Linux kernel public code containing CUAF vulnerability fix commits and perform static fuzzy mutation on the fix versions of the vulnerabilities to reproduce the vulnerabilities of this type triggered by these code fragments on the timeline. We compare the process with the execution of the random 
mutation operator
 in traditional detection methods horizontally and improve the efficiency by 42.4% on average.
Conclusion:
The static fuzzy mutation based on the AST is effective in stages. When this method is explored in more vulnerability-type evolution laws, it is expected to promote the development of the zero-day vulnerability active detection technology framework.",Information and Software Technology,18 Mar 2025,9.0,"The study on static fuzzy mutation for detecting zero-day vulnerabilities using deep learning techniques has high impact potential for improving security measures in software development, making it valuable for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000472,"Introduction to special issue on Agile UX: challenges, successes and barriers to improvement",June 2023,Not Found,Eva-Maria=Schön: eva-maria.schoen@hs-emden-leer.de; Tiago=Silva da Silva: silva.tiago@unifesp.br; Andreas=Hinderks: andreas@hinderks.org; Helen=Sharp: helen.sharp@open.ac.uk; Jörg=Thomaschewski: joerg.thomaschewski@hs-emden-leer.de,"Abstract
The integration of Agile software development and User Experience (UX) has become a growing field of research, as both approaches play critical roles in building digital products and services. In this special issue on Agile UX, the current state of the field is explored through a combination of systematic literature reviews and qualitative and quantitative studies. The special issue provide an overview of the key trends, challenges, and successes in combining Agile and UX, and highlight the importance of involving stakeholders throughout development. The shift from plan-driven approaches to Agile UX approaches has brought a focus on human values and a better understanding of the importance of considering users’ needs. We present recent advances in research and practice, showing that Agile UX is a continuous journey towards changing user behavior by delivering value.",Information and Software Technology,18 Mar 2025,6.0,"The exploration of Agile UX in building digital products and services is valuable for startups, but the abstract lacks specific implementation details or findings that could directly impact early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000472,"Introduction to special issue on Agile UX: challenges, successes and barriers to improvement",June 2023,Not Found,Eva-Maria=Schön: eva-maria.schoen@hs-emden-leer.de; Tiago=Silva da Silva: silva.tiago@unifesp.br; Andreas=Hinderks: andreas@hinderks.org; Helen=Sharp: helen.sharp@open.ac.uk; Jörg=Thomaschewski: joerg.thomaschewski@hs-emden-leer.de,"Abstract
The integration of Agile software development and User Experience (UX) has become a growing field of research, as both approaches play critical roles in building digital products and services. In this special issue on Agile UX, the current state of the field is explored through a combination of systematic literature reviews and qualitative and quantitative studies. The special issue provide an overview of the key trends, challenges, and successes in combining Agile and UX, and highlight the importance of involving stakeholders throughout development. The shift from plan-driven approaches to Agile UX approaches has brought a focus on human values and a better understanding of the importance of considering users’ needs. We present recent advances in research and practice, showing that Agile UX is a continuous journey towards changing user behavior by delivering value.",Information and Software Technology,18 Mar 2025,6.0,"The exploration of Agile UX in building digital products and services is valuable for startups, but the abstract lacks specific implementation details or findings that could directly impact early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584923000113,Improved measurement of software development effort estimation bias,May 2023,Not Found,Magne=Jørgensen: magnej@simula.no,"Abstract
Context
While prior software development effort estimation research has examined the properties of estimation 
error
 measures, there has not been much research on the properties of measures of estimation 
bias
.
Objectives
Improved measurement of software development effort estimation bias.
Methods
Analysis of the extent to which measures of estimation bias meet the criterion that perfect estimates should result in zero bias.
Results
Recommendations for measurement of estimation bias for estimates of the mean, median, and mode software development effort. The results include the recommendation to avoid a commonly used measure of effort estimation bias.
Conclusion
Proper evaluation of estimation bias requires knowledge about the type of estimates evaluated, together with the selection of a measure of estimation bias that gives zero bias for perfect estimates of that type.",Information and Software Technology,18 Mar 2025,3.0,"While the recommendation for measuring estimation bias in software development is valuable, it may not directly impact European early-stage ventures or startups significantly."
https://www.sciencedirect.com/science/article/pii/S0950584923000113,Improved measurement of software development effort estimation bias,May 2023,Not Found,Magne=Jørgensen: magnej@simula.no,"Abstract
Context
While prior software development effort estimation research has examined the properties of estimation 
error
 measures, there has not been much research on the properties of measures of estimation 
bias
.
Objectives
Improved measurement of software development effort estimation bias.
Methods
Analysis of the extent to which measures of estimation bias meet the criterion that perfect estimates should result in zero bias.
Results
Recommendations for measurement of estimation bias for estimates of the mean, median, and mode software development effort. The results include the recommendation to avoid a commonly used measure of effort estimation bias.
Conclusion
Proper evaluation of estimation bias requires knowledge about the type of estimates evaluated, together with the selection of a measure of estimation bias that gives zero bias for perfect estimates of that type.",Information and Software Technology,18 Mar 2025,3.0,"Similar to abstract 41, the focus on measuring estimation bias in software development is important but may not have a high practical value for European early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S0950584923000198,Finding the best learning to rank algorithms for effort-aware defect prediction,May 2023,Not Found,Xiao=Yu: xiaoyu@whut.edu.cn; Heng=Dai: daiheng726@163.com; Li=Li: lilicoding@ieee.org; Xiaodong=Gu: xiaodong.gu@sjtu.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Kwabena Ebo=Bennin: kwabena.bennin@wur.nl; Fuyang=Li: fyli@whut.edu.cn; Jin=Liu: jinliu@whu.edu.cn,"Abstract
Context:
Effort-Aware 
Defect Prediction
 (EADP) ranks software modules or changes based on their predicted number of defects (i.e., considering modules or changes as effort) or 
defect density
 (i.e., considering LOC as effort) by using learning to 
rank algorithms
. Ranking instability refers to the inconsistent conclusions produced by existing empirical studies of EADP. The major reason is the poor 
experimental design
, such as comparison of few 
learning to rank
 algorithms, the use of small number of datasets or datasets without indicating numbers of defects, and evaluation with inappropriate or few metrics.
Objective:
To find a stable ranking of 
learning to rank
 algorithms to investigate the best ones for EADP,
Method:
We examine the practical effects of 34 algorithms on 49 datasets for EADP. We measure the performance of these algorithms using 7 module-based and 7 LOC-based metrics and run experiments under cross-release and cross-project settings, respectively. Finally, we obtain the ranking of these algorithms by performing the Scott-Knott ESD test.
Results:
When module is used as effort, 
random forest
 regression performs the best under cross-release setting, and linear regression performs the best under cross-project setting among the 
learning to rank
 algorithms; (2) when LOC is used as effort, LTR-linear (Learning-to-Rank with the linear model) performs the best under cross-release setting, and Ranking 
SVM
 performs the best under cross-project setting.
Conclusion:
This comprehensive experimental procedure allows us to discover a stable ranking of the studied algorithms to select the best ones according to the requirement of software projects.",Information and Software Technology,18 Mar 2025,8.0,The study on stable rankings of learning to rank algorithms for software projects can directly impact European early-stage ventures and startups by improving decision-making processes and efficiency in software development.
https://www.sciencedirect.com/science/article/pii/S0950584923000198,Finding the best learning to rank algorithms for effort-aware defect prediction,May 2023,Not Found,Xiao=Yu: xiaoyu@whut.edu.cn; Heng=Dai: daiheng726@163.com; Li=Li: lilicoding@ieee.org; Xiaodong=Gu: xiaodong.gu@sjtu.edu.cn; Jacky Wai=Keung: jacky.keung@cityu.edu.hk; Kwabena Ebo=Bennin: kwabena.bennin@wur.nl; Fuyang=Li: fyli@whut.edu.cn; Jin=Liu: jinliu@whu.edu.cn,"Abstract
Context:
Effort-Aware 
Defect Prediction
 (EADP) ranks software modules or changes based on their predicted number of defects (i.e., considering modules or changes as effort) or 
defect density
 (i.e., considering LOC as effort) by using learning to 
rank algorithms
. Ranking instability refers to the inconsistent conclusions produced by existing empirical studies of EADP. The major reason is the poor 
experimental design
, such as comparison of few 
learning to rank
 algorithms, the use of small number of datasets or datasets without indicating numbers of defects, and evaluation with inappropriate or few metrics.
Objective:
To find a stable ranking of 
learning to rank
 algorithms to investigate the best ones for EADP,
Method:
We examine the practical effects of 34 algorithms on 49 datasets for EADP. We measure the performance of these algorithms using 7 module-based and 7 LOC-based metrics and run experiments under cross-release and cross-project settings, respectively. Finally, we obtain the ranking of these algorithms by performing the Scott-Knott ESD test.
Results:
When module is used as effort, 
random forest
 regression performs the best under cross-release setting, and linear regression performs the best under cross-project setting among the 
learning to rank
 algorithms; (2) when LOC is used as effort, LTR-linear (Learning-to-Rank with the linear model) performs the best under cross-release setting, and Ranking 
SVM
 performs the best under cross-project setting.
Conclusion:
This comprehensive experimental procedure allows us to discover a stable ranking of the studied algorithms to select the best ones according to the requirement of software projects.",Information and Software Technology,18 Mar 2025,8.0,"Similar to abstract 43, the research on stable rankings of learning to rank algorithms for software projects can have a tangible impact on European early-stage ventures and startups by enhancing their software development practices."
https://www.sciencedirect.com/science/article/pii/S0950584923000022,A light-weight data augmentation method for fault localization,May 2023,Not Found,Jian=Hu: jianhu@cqu.edu.cn; Huan=Xie: huanxie@cqu.edu.cn; Yan=Lei: yanlei@cqu.edu.cn; Ke=Yu: keyu@cqu.edu.cn,"Abstract
Context:
Fault localization (FL) is essentially a search over the space of program statements to find suspicious entities that might have caused a program failure. However, the input data is high-dimensional and extremely imbalanced since the real-world programs are large in size and the number of failing test cases is much less than that of passing test cases, which limits the effectiveness and efficiency of existing FL methods. The state-of-the-art FL method (Aeneas) solves the imbalanced and high-dimensional problem but in a complex and time-consuming process.
Objective:
Due to the limited effectiveness of original FL methods and the low efficiency of Aeneas, this paper proposes 
Lamont
, a 
L
ight-weight d
a
ta aug
m
entati
on
 me
t
hod to improve the effectiveness of original FL methods and the efficiency of Aeneas.
Methods:
Lamont
 uses revised linear 
discriminant analysis
 (LDA) to reduce the dimensionality of the original coverage matrix and leverage synthetic minority over-sampling (SMOTE) to generate the synthesized failing tests. The balanced coverage matrix with reduced dimensionality is fed into FL methods to obtain the ranked suspicious list of statements. To evaluate the efficiency and effectiveness, we compare 
Lamont
 with six representative FL methods and Aeneas on 458 versions of 10 real-life programs.
Results:
It can be observed that 
Lamont
 outperforms in most cases for Top-K metric and reduces the number of statements that need to be checked from 17.45% to 79.81% compared with the original six FL methods. Furthermore, Lamont saves the time over the state-of-the-art data augmentation method Aeneas from 55.33% to 68.39% with comparable effectiveness.
Conclusion:
This work conducts a large-scale experimental study to investigate the effectiveness and efficiency of 
Lamont
. Two conclusions can be obtained based on the experimental results. First, it shows that 
Lamont
 is more effective than the original FL methods. Second, it shows 
Lamont
 is more efficient than Aeneas with similar effectiveness in six FL methods.",Information and Software Technology,18 Mar 2025,9.0,The proposal of Lamont to improve fault localization methods can significantly benefit European early-stage ventures and startups by enhancing the efficiency and effectiveness of their software development processes.
https://www.sciencedirect.com/science/article/pii/S0950584923000186,Automated engineering of domain-specific metamorphic testing environments,May 2023,"Metamorphic testing, Model-driven engineering, Domain-specific languages, Cloud computing, Simulation",Pablo=Gómez-Abajo: Pablo.GomezA@uam.es; Pablo C.=Cañizares: Pablo.Cerro@uam.es; Alberto=Núñez: Alberto.Nunez@pdi.ucm.es; Esther=Guerra: Esther.Guerra@uam.es; Juan=de Lara: Juan.deLara@uam.es,"Abstract
Context:
Testing is essential to improve the correctness of software systems. Metamorphic testing (MT) is an approach especially suited when the system under test lacks oracles, or they are expensive to compute. However, building an MT environment for a particular domain (e.g., cloud simulation, model transformation, machine learning) requires substantial effort.
Objective:
Our goal is to facilitate the construction of MT environments for specific domains.
Method:
We propose a model-driven engineering approach to automate the construction of MT environments. Starting from a meta-model capturing the domain concepts, and a description of the domain execution environment, our approach produces an MT environment featuring comprehensive support for the MT process. This includes the definition of domain-specific metamorphic relations, their evaluation, detailed reporting of the testing results, and the automated search-based generation of follow-up test cases.
Results:
Our method is supported by an extensible platform for Eclipse, called 
Gotten
. We demonstrate its effectiveness by creating an MT environment for simulation-based testing of 
data centres
 and comparing with existing tools; its suitability to conduct MT processes by replicating previous experiments; and its generality by building another MT environment for video streaming APIs.
Conclusion:
Gotten
 is the first platform targeted at reducing the development effort of domain-specific MT environments. The environments created with 
Gotten
 facilitate the specification of metamorphic relations, their evaluation, and the generation of new test cases.",Information and Software Technology,18 Mar 2025,7.0,The automated construction of Metamorphic Testing environments can benefit European early-stage ventures by reducing development effort and facilitating testing processes in various domains.
https://www.sciencedirect.com/science/article/pii/S0950584923000162,A taxonomy for mining and classifying privacy requirements in issue reports,May 2023,Not Found,Pattaraporn=Sangaroonsilp: ps642@uowmail.edu.au; Hoa Khanh=Dam: hoa@uow.edu.au; Morakot=Choetkiertikul: morakot.cho@mahidol.ac.th; Chaiyong=Ragkhitwetsagul: chaiyong.rag@mahidol.ac.th; Aditya=Ghose: aditya@uow.edu.au,"Abstract
Context:
Digital and physical trails of user activities are collected over the use of 
software applications
 and systems. As software becomes ubiquitous, protecting user privacy has become challenging. With the increase of user privacy awareness and advent of privacy regulations and policies, there is an emerging need to implement software systems that enhance the protection of 
personal data
 processing. However, existing data protection and privacy regulations provide key principles in high-level, making it difficult for software engineers to design and implement privacy-aware systems.
Objective:
In this paper, we develop a taxonomy that provides a comprehensive set of privacy requirements based on four well-established 
personal data protection
 regulations and privacy frameworks, the 
General Data Protection Regulation
 (GDPR), ISO/IEC 29100, Thailand Personal 
Data Protection Act
 (Thailand PDPA) and Asia-Pacific Economic Cooperation (APEC) privacy framework.
Methods:
These requirements are extracted, refined and classified (using the goal-based requirements analysis method) into a level that can be used to map with issue reports. We have also performed a study on how two large open-source software projects (Google Chrome and Moodle) address the privacy requirements in our taxonomy through mining their issue reports.
Results:
The paper discusses how the collected issues were classified, and presents the findings and insights generated from our study.
Conclusion:
Mining and classifying privacy requirements in issue reports can help organisations be aware of their state of compliance by identifying privacy requirements that have not been addressed in their software projects. The taxonomy can also trace back to regulations, standards and frameworks that the software projects have not complied with based on the identified privacy requirements.",Information and Software Technology,18 Mar 2025,6.0,"Developing a taxonomy for privacy requirements can aid software engineers in designing privacy-aware systems, aligning with the increasing need for data protection regulations in Europe."
https://www.sciencedirect.com/science/article/pii/S0950584923000137,Many-objective optimization of non-functional attributes based on refactoring of software models,May 2023,"Multi-objective optimization, Search-based software engineering, Performance, Reliability, Refactoring, Model-driven engineering, Software architecture",Vittorio=Cortellessa: vittorio.cortellessa@univaq.it; Daniele=Di Pompeo: daniele.dipompeo@univaq.it; Vincenzo=Stoico: vincenzo.stoico@graduate.univaq.it; Michele=Tucci: tucci@d3s.mff.cuni.cz,"Abstract
Context:
Software quality estimation is a challenging and time-consuming activity, and models are crucial to 
face
 the complexity of such activity on modern 
software applications
. In this context, software refactoring is a crucial activity within development life-cycles where requirements and functionalities rapidly evolve.
Objective:
One main challenge is that the improvement of distinctive 
quality attributes
 may require contrasting refactoring actions on software, as for trade-off between performance and reliability (or other non-functional attributes). In such cases, multi-objective optimization can provide the designer with a wider view on these trade-offs and, consequently, can lead to identify suitable refactoring actions that take into account independent or even competing objectives.
Method:
In this paper, we present an approach that exploits the 
NSGA-II
 as the 
genetic algorithm
 to search optimal 
Pareto frontiers
 for software refactoring while considering many objectives. We consider performance and reliability variations of a model alternative with respect to an initial model, the amount of performance antipatterns detected on the model alternative, and the architectural distance, which quantifies the effort to obtain a model alternative from the initial one.
Results:
We applied our approach on two 
case studies
: a Train Ticket Booking Service, and 
CoCoME
. We observed that our approach is able to improve performance (by up to 42%) while preserving or even improving the reliability (by up to 32%) of generated model alternatives. We also observed that there exists an order of preference of refactoring actions among model alternatives.
Conclusion:
Based on our analysis, we can state that performance antipatterns confirmed their ability to improve performance of a subject model in the context of many-objective optimization. In addition, the metric that we adopted for the architectural distance seems to be suitable for estimating the refactoring effort.",Information and Software Technology,18 Mar 2025,8.0,The approach presented for multi-objective optimization in software refactoring can significantly impact European startups by improving software quality attributes efficiently and effectively.
https://www.sciencedirect.com/science/article/pii/S0950584923000137,Many-objective optimization of non-functional attributes based on refactoring of software models,May 2023,"Multi-objective optimization, Search-based software engineering, Performance, Reliability, Refactoring, Model-driven engineering, Software architecture",Vittorio=Cortellessa: vittorio.cortellessa@univaq.it; Daniele=Di Pompeo: daniele.dipompeo@univaq.it; Vincenzo=Stoico: vincenzo.stoico@graduate.univaq.it; Michele=Tucci: tucci@d3s.mff.cuni.cz,"Abstract
Context:
Software quality estimation is a challenging and time-consuming activity, and models are crucial to 
face
 the complexity of such activity on modern 
software applications
. In this context, software refactoring is a crucial activity within development life-cycles where requirements and functionalities rapidly evolve.
Objective:
One main challenge is that the improvement of distinctive 
quality attributes
 may require contrasting refactoring actions on software, as for trade-off between performance and reliability (or other non-functional attributes). In such cases, multi-objective optimization can provide the designer with a wider view on these trade-offs and, consequently, can lead to identify suitable refactoring actions that take into account independent or even competing objectives.
Method:
In this paper, we present an approach that exploits the 
NSGA-II
 as the 
genetic algorithm
 to search optimal 
Pareto frontiers
 for software refactoring while considering many objectives. We consider performance and reliability variations of a model alternative with respect to an initial model, the amount of performance antipatterns detected on the model alternative, and the architectural distance, which quantifies the effort to obtain a model alternative from the initial one.
Results:
We applied our approach on two 
case studies
: a Train Ticket Booking Service, and 
CoCoME
. We observed that our approach is able to improve performance (by up to 42%) while preserving or even improving the reliability (by up to 32%) of generated model alternatives. We also observed that there exists an order of preference of refactoring actions among model alternatives.
Conclusion:
Based on our analysis, we can state that performance antipatterns confirmed their ability to improve performance of a subject model in the context of many-objective optimization. In addition, the metric that we adopted for the architectural distance seems to be suitable for estimating the refactoring effort.",Information and Software Technology,18 Mar 2025,8.0,The multi-objective optimization approach for software refactoring can have a positive impact on European early-stage ventures by enhancing software quality attributes and demonstrating improved performance and reliability.
https://www.sciencedirect.com/science/article/pii/S0950584923000204,A novel detection model for abnormal network traffic based on bidirectional temporal convolutional network,May 2023,Not Found,Jinfu=Chen: Not Found; Tianxiang=Lv: Not Found; Saihua=Cai: caisaih@ujs.edu.cn; Luo=Song: Not Found; Shang=Yin: Not Found,"Abstract
Context:
The increasingly complex and diverse network environment has increased traffic intrusion behaviors, but the traditional machine learning-based model has the problems of time-consuming and low detection accuracy due to the need of manually selecting features. Therefore, it is very important to construct an automatically abnormal network traffic detection model with a high detection accuracy.
Objective:
The goal of this paper is to train the network traffic through 
deep learning
 technology to generate an automatic abnormal network traffic detection model without manual design of features.
Methods:
We propose an abnormal network traffic detection model called BiTCN based on bidirectional time convolution network, it first uses 
temporal convolutional network
 (TCN) model to better grasp the sequence characteristics of network traffic, and then uses Exponential Linear Unit (ELU) 
activation function
 to replace ReLU in the model training stage to avoid the problem of neuron “death” leading to the reduction of detection accuracy, as well as improves the original one-way model to a two-way model to capture the two-way semantic fusion characteristics of network traffic.
Results:
We evaluate the efficiency and effectiveness of the proposed BiTCN model by comparing it with different models on the CTU and USTC-TFC2016 datasets. The experimental results show that the proposed BiTCN model outperforms other models in terms of the precision, accuracy, recall and F1-measure.
Conclusion:
In this paper, we propose a novel detection model for abnormal network traffic based on bidirectional 
temporal convolutional network
 , it solves some shortcomings and limitations of existing models, and obtains a high detection accuracy of abnormal network traffic with a high stability.",Information and Software Technology,18 Mar 2025,7.0,The development of an automatic abnormal network traffic detection model using deep learning technology can provide practical value to European startups by enhancing network security measures with high detection accuracy.
https://www.sciencedirect.com/science/article/pii/S0950584923000034,A system-based view of blockchain governance,May 2023,"Blockchain governance, Systems theory, Systematic literature review",Gabriella=Laatikainen: gabriella.laatikainen@jyu.fi; Mengcheng=Li: Not Found,"Abstract
Context
Governance is crucial in achieving the success and sustainability of 
blockchain
 systems. However, 
blockchain
 governance is multi-faceted, complex, dynamic, and challenging due to its decentralized nature and automatically enforced rules and mechanisms.
Objectives
This study aims to advance the theory of blockchain governance and support practitioners to deepen the researchers’ and practitioners’ understanding of blockchain governance.
Methods
The study is a 
systematic literature review
 of 75 articles that applies systems theory to conceptualize blockchain governance as a system and parsimoniously organize its interrelated elements into a conceptual model.
Results
The paper proposes a holistic definition and a conceptual model of blockchain governance. Blockchain governance encompasses technical and social means to make decisions on the different levels (e.g., individual, community, organizational, national, international) related to actors, roles, rights, incentives, responsibilities, rules, and the business, technological, legal, and regulatory aspects of a blockchain system during its whole lifecycle.
Conclusion
The system-based model of blockchain governance can serve as a reference framework and structured foundation for analyzing, discussing, and developing the governance of blockchain systems.",Information and Software Technology,18 Mar 2025,7.0,"The study on blockchain governance provides a structured foundation for analyzing and developing governance systems, which can be valuable for startups utilizing blockchain technology."
https://www.sciencedirect.com/science/article/pii/S0950584923000034,A system-based view of blockchain governance,May 2023,"Blockchain governance, Systems theory, Systematic literature review",Gabriella=Laatikainen: gabriella.laatikainen@jyu.fi; Mengcheng=Li: Not Found,"Abstract
Context
Governance is crucial in achieving the success and sustainability of 
blockchain
 systems. However, 
blockchain
 governance is multi-faceted, complex, dynamic, and challenging due to its decentralized nature and automatically enforced rules and mechanisms.
Objectives
This study aims to advance the theory of blockchain governance and support practitioners to deepen the researchers’ and practitioners’ understanding of blockchain governance.
Methods
The study is a 
systematic literature review
 of 75 articles that applies systems theory to conceptualize blockchain governance as a system and parsimoniously organize its interrelated elements into a conceptual model.
Results
The paper proposes a holistic definition and a conceptual model of blockchain governance. Blockchain governance encompasses technical and social means to make decisions on the different levels (e.g., individual, community, organizational, national, international) related to actors, roles, rights, incentives, responsibilities, rules, and the business, technological, legal, and regulatory aspects of a blockchain system during its whole lifecycle.
Conclusion
The system-based model of blockchain governance can serve as a reference framework and structured foundation for analyzing, discussing, and developing the governance of blockchain systems.",Information and Software Technology,18 Mar 2025,7.0,"The study on blockchain governance provides a structured foundation for analyzing and developing governance systems, which can be valuable for startups utilizing blockchain technology."
https://www.sciencedirect.com/science/article/pii/S0950584923000046,DevOps critical success factors — A systematic literature review,May 2023,"DevOps, Development and operations, Success factors, Barriers, Literature review",Nasreen=Azad: nasren.azad@lut.fi; Sami=Hyrynsalmi: Not Found,"Abstract
Context:
DevOps
 is a set of software development and operation practices and a recent addition to a large family of different kinds of software process models. The model emerged out of the observation that 
information systems
 operations and developments should be closely integrated activities to ensure the success of any organization. Thus, DevOps methods are an additive tool for companies to improve overall performance in their software development processes and operations.
Objective:
This paper aims to identify the various critical 
success factors
 (CSFs) of DevOps projects that have been discussed in prior research. In addition, this study proposes a comprehensive framework for depicting how these CSFs impact or drive DevOps success.
Method:
This study consists of a systematic literature review to collect the primary articles for the analysis.
Results:
After searches in four major publication databases and snowballing, we selected 38 primary studies for the analysis. Nearly 100 different CSFs were identified, which were then categorized into 
Technical
, 
Organizational
, and 
Social & Cultural
 dimensions. Based on the results of the literature analysis, a comprehensive framework is proposed that depicts how the CSFs impact or drive DevOps success.
Conclusion:
This paper presents a DevOps framework with various CSFs based on prior literature. The proposed framework will provide collective knowledge of DevOps success factors, which will allow researchers and practitioners to enhance their understanding of CSFs and learn how to handle DevOps issues in organizations. In particular, the paper highlights a number of future research directions related to CSFs.",Information and Software Technology,18 Mar 2025,8.0,The study on DevOps success factors and framework can offer practical insights for startups looking to improve their software development processes and operations.
https://www.sciencedirect.com/science/article/pii/S0950584923000216,The discovery effort worthiness index: How much product discovery should you do and how can this be integrated into delivery?,May 2023,Not Found,Stefan=Trieflinger: stefan.trieflinger@reutlingen-university.de; Dominic=Lang: Not Found; Selina=Spies: Not Found; Jürgen=Münch: Not Found,"Abstract
Context
In a world of high dynamics and uncertainties, it is almost impossible to have a long-term prediction of which products, services, or features will satisfy the needs of the customer. To counter this situation, the conduction of Continuous Improvement or Design Thinking for product discovery are common approaches. A major constraint in conducting product discovery activities is the high effort to discover and validate features and requirements. In addition, companies struggle to integrate product discovery activities into their agile processes and iterations.
Objective
This paper aims at suggests a supportive tool, the “Discovery Effort Worthiness (DEW) Index”, for product owners and agile teams to determine a suitable amount of effort that should be spent on Design Thinking activities. To operationalize DEW, proposals for practitioners are presented that can be used to integrate product discovery into product development and delivery.
Method
A case study was conducted for the development of the DEW index. In addition, we conducted an expert workshop to develop proposals for the integration of product discovery activities into the product development and delivery process.
Results
First, we present the ""Discovery Effort Worthiness Index"" in form of a formula. Second, we identified requirements that must be fulfilled for systematic integration of product discovery activities into product development and delivery. Third, we derived from the requirements proposals for the integration of product discovery activities with a company's product development and delivery.
Conclusion
The developed ""Discovery Effort Worthiness Index"" provides a tool for companies and their product owners to determine how much effort they should spend on Design Thinking methods to discover and validate requirements. Integrating product discovery with product development and delivery should ensure that the results of product discovery are incorporated into product development. This aims to systematically analyze product risks to increase the chance of product success.",Information and Software Technology,18 Mar 2025,8.0,"The proposed tool and methodology for product discovery can help startups optimize their design thinking activities and integrate them into agile processes, contributing to product success."
https://www.sciencedirect.com/science/article/pii/S0950584922002440,Industry-academia collaboration for realism in software engineering research: Insights and recommendations,April 2023,"Software engineering, Industry-academia collaboration",Qunying=Song: qunying.song@cs.lth.se; Per=Runeson: per.runeson@cs.lth.se,"Abstract
Context:
Effective industry-academia collaboration may increase 
software engineering
 research relevance by increased realism, yet very challenging for reasons like confidentiality concerns, different objectives and priorities.
Objective:
We analyse industry-academia collaboration scenarios based on our own experiences as Ph.D. student and supervisor, and provide insights and recommendations to facilitate future collaborations with 
industry
.
Method:
We first present our industry-academia collaboration experiences that span over two and a half years with different companies. Then, we analyse both facilitators and problems from those scenarios and synthesize recommendations based on that.
Results:
Five different scenarios are analysed, including both success and failure scenarios. Reflections and insights into these experiences as well as some general recommendations are presented.
Conclusion:
We believe such experiences and insights are helpful for academic researchers to pursue industry-academia collaboration. We plan to continuously report our experience and provide our suggestions for effective collaboration with industry.",Information and Software Technology,18 Mar 2025,6.0,The insights and recommendations on industry-academia collaboration can be beneficial for startups looking to collaborate with industry partners to enhance their research relevance.
https://www.sciencedirect.com/science/article/pii/S0950584922002440,Industry-academia collaboration for realism in software engineering research: Insights and recommendations,April 2023,"Software engineering, Industry-academia collaboration",Qunying=Song: qunying.song@cs.lth.se; Per=Runeson: per.runeson@cs.lth.se,"Abstract
Context:
Effective industry-academia collaboration may increase 
software engineering
 research relevance by increased realism, yet very challenging for reasons like confidentiality concerns, different objectives and priorities.
Objective:
We analyse industry-academia collaboration scenarios based on our own experiences as Ph.D. student and supervisor, and provide insights and recommendations to facilitate future collaborations with 
industry
.
Method:
We first present our industry-academia collaboration experiences that span over two and a half years with different companies. Then, we analyse both facilitators and problems from those scenarios and synthesize recommendations based on that.
Results:
Five different scenarios are analysed, including both success and failure scenarios. Reflections and insights into these experiences as well as some general recommendations are presented.
Conclusion:
We believe such experiences and insights are helpful for academic researchers to pursue industry-academia collaboration. We plan to continuously report our experience and provide our suggestions for effective collaboration with industry.",Information and Software Technology,18 Mar 2025,7.0,"The abstract provides insights and recommendations for industry-academia collaboration, which can be valuable for early-stage ventures seeking partnerships."
https://www.sciencedirect.com/science/article/pii/S0950584922002427,Progress on class integration test order generation approaches: A systematic literature review,April 2023,Not Found,Yanru=Ding: yrding@cumt.edu.cn; Yanmei=Zhang: ymzhang@cumt.edu.cn; Guan=Yuan: yuanguan@cumt.edu.cn; Shujuan=Jiang: shjjiang@cumt.edu.cn; Wei=Dai: weidai@cumt.edu.cn,"Abstract
Context:
Integration testing is an effective way to detect unit test results and ensure the correct and stable operation of software modules. One of the crucial problems in integration testing is the class integration test order (CITO) generation problem. Its purpose is to reasonably determine the test order of each class in a program to reduce test consumption. In recent years, the CITO generation problem has made a lot of progress but also faces more challenges.
Objective:
The goal of this paper is to provide an overview of the research progress on the CITO generation problem. By summarizing applied techniques, evaluation indicators, and datasets, this paper aims to identify research challenges and suggest future opportunities.
Method:
We conduct a systematic literature review of CITO generation approaches, including the problems investigated, the solutions proposed, the techniques applied, the evaluation indicators used, and the datasets covered.
Results:
Based on research techniques and evaluation indicators, we classified and analyzed 30 papers published between 2011 and 2022. Our analysis reveals that more (47%) of the studies on the CITO generation problem still prefer to use search-based techniques, and the vast majority (90%) of the studies choose to use the stubbing complexity as the indicator to evaluate the stubbing cost of generating CITOs. We have extracted five challenges that the CITO generation problem is facing, corresponding to which we have given suggestions for future research.
Conclusion:
In this paper, we have outlined the research status of CITO generation approaches, summarized the challenges, and proposed corresponding opportunities for future study. We expect this paper to better help software testing workers understand the CITO generation problem and improve efficiency in practical work.",Information and Software Technology,18 Mar 2025,6.0,"The abstract addresses challenges in integration testing, which could impact startups in the software development industry."
https://www.sciencedirect.com/science/article/pii/S0950584922002543,Digital-twin-based testing for cyber–physical systems: A systematic literature review,April 2023,"Digital twin, Cyber–physical system, Testing, Systematic literature review",Richard J.=Somers: rsomers1@sheffield.ac.uk; James A.=Douthwaite: Not Found; David J.=Wagg: Not Found; Neil=Walkinshaw: Not Found; Robert M.=Hierons: Not Found,"Abstract
Context:
Cyber–physical systems present a challenge to testers, bringing complexity and scale to safety-critical and collaborative environments. 
Digital twins
 enhance these systems through data-driven and simulation based models coupled to 
physical systems
 to provide visualisation, predict future states and communication. Due to the coupling between digital and physical worlds, digital twins provide a new perspective into cyber–physical system testing.
Objective:
The objectives of this study are to summarise the existing literature on digital-twin-based testing. We aim to uncover emerging areas of adoptions, the testing techniques used in these areas and identify future research areas.
Method:
We conducted a systematic literature review which answered the following research questions: What cyber–physical systems are digital twins currently being used to test? How are test oracles defined for cyber–physical systems? What is the distribution of white-box, black-box and grey-box modelling techniques used for digital twins in the context of testing? How are test cases defined and how does this affect test inputs?
Results:
We uncovered 26 relevant studies from 480 produced by searching with a curated search query. These studies showed an adoption of digital-twin-based testing following the introduction of digital twins in industry as well as the increasing accessibility of the technology. The oracles used in testing are the digital twin themselves and therefore rely on both system specification and data derivation. Cyber–physical systems are tested through passive testing techniques, as opposed to either active testing through test cases or predictive testing using digital twin prediction.
Conclusions:
This review uncovers the existing areas in which digital twins are used to test cyber–physical systems as well as outlining future research areas in the field. We outline how the infancy of digital twins has affected their wide variety of definitions, emerging specialised testing and modelling techniques as well as the current lack of 
predictive ability
.",Information and Software Technology,18 Mar 2025,8.0,"The abstract explores digital twin-based testing in cyber-physical systems, a cutting-edge technology that could have significant implications for European startups in tech and IoT sectors."
https://www.sciencedirect.com/science/article/pii/S0950584922002403,Knowledge diffusion trajectories of agile software development research: A main path analysis,April 2023,Not Found,Yulianus=Palopak: ypalopak@unai.edu; Sun-Jen=Huang: huangsj@mail.ntust.edu.tw; Wiwit=Ratnasari: ratnasariwiwit@gmail.com,"Abstract
Context
The dramatic growth of agile software development (ASD) research has resulted in a large number of diverse theoretical and empirical publications. The citation relationships among these publications indicate knowledge dissemination across and within academia or scientists.
Objective
This study offers a comprehensive understanding of the ASD literature by exploring the knowledge diffusion path through the citation network of publications that have made significant contributions to its research development.
Method
We employ a quantitative citation-based methodology, main path analysis (MPA), to examine the citation relationship of 1431 scientific articles published in the Web of Science (WoS) between 2001 and 2021 and visualize the MPA results using Pajek software.
Results
Through citation analysis this study discovers knowledge diffusion trajectories of publications concerning ASD method. Our key results present 32 publications identified along the key-route main path as the most influential ones in the trajectories of ASD. There are three phases of ASD research development: introduction, evaluation, and deployment and expansion. Using the multiple-global main path, we further uncover the publication trends from a set of recent papers and reveal four sub-themes: tailoring of agile practices, large-scale agile context, challenges and success factors of large-scale organizations, and agile global software development.
Conclusions
Although there was little academic interest in the initial phase, ASD-related publication and citation trends have consistently increased over time. The historical development of ASD methods was established in three distinct phases of publications in the domain. Each phase presents a narrative of agile methods’ development with different focuses. The most recent trends of ASD publications tend to focus on the agile tailoring and scaling process in the global and distributed environment.",Information and Software Technology,18 Mar 2025,5.0,"While the abstract provides insights into agile software development research, the practical value for early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922002403,Knowledge diffusion trajectories of agile software development research: A main path analysis,April 2023,Not Found,Yulianus=Palopak: ypalopak@unai.edu; Sun-Jen=Huang: huangsj@mail.ntust.edu.tw; Wiwit=Ratnasari: ratnasariwiwit@gmail.com,"Abstract
Context
The dramatic growth of agile software development (ASD) research has resulted in a large number of diverse theoretical and empirical publications. The citation relationships among these publications indicate knowledge dissemination across and within academia or scientists.
Objective
This study offers a comprehensive understanding of the ASD literature by exploring the knowledge diffusion path through the citation network of publications that have made significant contributions to its research development.
Method
We employ a quantitative citation-based methodology, main path analysis (MPA), to examine the citation relationship of 1431 scientific articles published in the Web of Science (WoS) between 2001 and 2021 and visualize the MPA results using Pajek software.
Results
Through citation analysis this study discovers knowledge diffusion trajectories of publications concerning ASD method. Our key results present 32 publications identified along the key-route main path as the most influential ones in the trajectories of ASD. There are three phases of ASD research development: introduction, evaluation, and deployment and expansion. Using the multiple-global main path, we further uncover the publication trends from a set of recent papers and reveal four sub-themes: tailoring of agile practices, large-scale agile context, challenges and success factors of large-scale organizations, and agile global software development.
Conclusions
Although there was little academic interest in the initial phase, ASD-related publication and citation trends have consistently increased over time. The historical development of ASD methods was established in three distinct phases of publications in the domain. Each phase presents a narrative of agile methods’ development with different focuses. The most recent trends of ASD publications tend to focus on the agile tailoring and scaling process in the global and distributed environment.",Information and Software Technology,18 Mar 2025,5.0,"Similar to abstract 59, the abstract focuses on agile software development research, which may not directly impact early-stage ventures in a tangible way."
https://www.sciencedirect.com/science/article/pii/S0950584922002397,Graph-based code semantics learning for efficient semantic code clone detection,April 2023,Not Found,Dongjin=Yu: yudj@hdu.edu.cn; Quanxin=Yang: Not Found; Xin=Chen: Not Found; Jie=Chen: Not Found; Yihang=Xu: Not Found,"Abstract
Recent studies have shown that high-quality code semantics learning can effectively improve the performance of code clone detection. However, existing approaches suffer from two major drawbacks: (a) insufficient utilization of code representations, leading to inefficient semantics learning, and (b) low efficiency of clone detection, resulting in massive detection time. Therefore, we are motivated to propose an efficient semantics learning method while speeding up the detection process. Specifically, to address the first one, we adopt either CFG (Control Flow Graph) or PDG (Program Dependency Graph) as our initial code representation because of their rich semantic information. Further, we propose a novel graph-based code semantics learning method, which can capture critical information at token, statement, edge, and graph levels. To address the second one, we design a Siamese graph-matching network based on 
attention mechanisms
. It can uniformly generate graph embeddings for code fragments and facilitate parallel detection of semantic clones, thus significantly boosting the speed of semantic clone detection.
We evaluated our approach on two Java benchmark datasets, Google Code Jam and BigCloneBench. The experimental results show that our model outperforms the SOTA (State-Of-The-Art) lightweight models and is over 20x faster in detection. In addition, our model performs on par with the large Bert-based models and is over 110x faster in detection. Our code and dataset are available online at: 
https://github.com/HduDBSI/CodeGraph4CCDetector
.",Information and Software Technology,18 Mar 2025,8.0,"This abstract presents a novel approach to code clone detection that outperforms existing models and significantly boosts detection speed, which can be valuable for European startups dealing with large codebases."
https://www.sciencedirect.com/science/article/pii/S0950584922002555,A modeling assistant to manage technical debt in coupled evolution,April 2023,Not Found,Davide=Di Ruscio: davide.diruscio@univaq.it; Amleto=Di Salle: amleto.disalle@univaq.it; Ludovico=Iovino: ludovico.iovino@gssi.it; Alfonso=Pierantonio: alfonso.pierantonio@univaq.it,"Abstract
Context:
Model-Driven Engineering helps formalize problem domains by using metamodels. Modeling ecosystems consisting of purposely designed editors, transformations, and 
code generators
 are defined on top of the metamodels. Similar to other software artifacts, metamodels can evolve by possibly compromising the validity of existing artifacts. Coupled evolution provides techniques for restoring artifacts’ validity in response to metamodel evolution.
Objective:
In this paper, we propose the adoption of 
deprecation
 in metamodeling to mitigate the difficulties in performing manual model adaptations in response to metamodel evolutions. Moreover, we aim to measure and resolve the 
technical debt
 during the co-evolution, which can be seen as the outcome of procrastinating artifact migrations.
Methods:
We propose a novel approach and supporting tool to manage the concepts of 
deprecation
 and 
technical debt
 in metamodeling.
Results:
We conducted a judgment study using the focus group methodology to assess the proposed approach’s usefulness in migrating models affected by breaking non-resolvable changes completely.
Conclusions:
The proposed approach can identify the technical debt in metamodel evolution. Furthermore, it deals with the coupled evolution problem by assisting the modeler through interactive visualization tools, which highlight and quantify the technical dept of the artifacts under analysis that need to be evolved.",Information and Software Technology,18 Mar 2025,6.0,"The proposed approach addresses technical debt in metamodel evolution, which can be useful for startups using Model-Driven Engineering, but the impact may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002439,"Composite refactoring: Representations, characteristics and effects on software projects",April 2023,Not Found,Ana Carla=Bibiano: abibiano@inf.puc-rio.br; Anderson=Uchôa: andersonuchoa@ufc.br; Wesley K.G.=Assunção: wassuncao@inf.puc-rio.br; Daniel=Tenório: doliveira@inf.puc-rio.br; Thelma E.=Colanzi: thelma@din.uem.br; Silvia Regina=Vergilio: silvia@inf.ufpr.br; Alessandro=Garcia: afgarcia@inf.puc-rio.br,"Abstract
Context:
code refactoring
 is a code transformation that aims to improve software quality. A composite refactoring (or, simply, composite) is defined by two or more interrelated refactorings, which is often applied by developers. Each composite needs to be somehow represented and has its own characteristics (e.g., code scope) as well as its effects on software quality. However, these basic elements of composites are rarely studied systematically. The lack of 
systematic knowledge
 also misguides the design of automated support tools for supporting composite refactoring. Thus, researchers might have controversial views about basic elements of composite refactorings. An example of these literature conflicts concerns the effect of composites: while some studies suggest composites more often remove code smells, other studies indicate composites often introduce code smells.
Objective:
in this sense, our study aims at analyzing the technical literature of composite refactoring and building a conceptual framework of the representation models, characteristics, and the effect of composite refactoring.
Method:
we conducted a 
systematic mapping
 with 140 primary empirical studies about refactoring. Our 
systematic mapping
 summarizes the current knowledge on composites and also presents a conceptual framework intended to characterize composite refactoring.
Results:
our conceptual framework presents seven representation models, nine characteristics, and thirteen effects of composites. We found out that studies used multidimensional representations, like graphs, to determine what refactoring(s) may be suggested and combined. On composite characteristics, studies mentioned developers often finish a composite in up to a month. However, these studies do not detail why and when composites span for several weeks. Then, we discussed other existing gaps on the current literature of composites. For instance, while most of the studies report the effect of composites on internal software quality, e.g., code smells, their effect on external software quality is little explored.
Conclusion:
our results can motivate future studies to more deeply investigate composite refactoring applications, and the improvement of tooling support for composite refactorings.",Information and Software Technology,18 Mar 2025,7.0,"The study on composite refactoring provides valuable insights into representing, characterizing, and understanding the effects of composites, which can benefit startups looking to improve software quality."
https://www.sciencedirect.com/science/article/pii/S0950584922002518,Negative effects of gamification in education software: Systematic mapping and practitioner perceptions,April 2023,Not Found,Cláuvin=Almeida: almeidaclauvin@gmail.com; Marcos=Kalinowski: kalinowski@inf.puc-rio.br; Anderson=Uchôa: andersonuchoa@ufc.br; Bruno=Feijó: bfeijo@inf.puc-rio.br,"Abstract
Context:
While most research shows positive effects of 
gamification
, the focus on its adverse effects is considerably smaller and further understanding of these effects is needed.
Objective:
To provide a comprehensive overview on research reporting negative effects of game design elements and to provide insights into the awareness of developers on these effects and into how they could be considered in practice.
Method:
We conducted a 
systematic mapping study
 of the negative effects of game design elements on education/learning systems. We also held a focus 
group discussion
 with developers of a gamified software, discussing the mapping study results with regard to their awareness and perceptions on the reported negative effects in practice.
Results:
The mapping study revealed 87 papers reporting undesired effects of game design elements. We found that badges, leaderboards, competitions, and points are the game design elements most often reported as causing negative effects. The most cited negative effects were lack of effect, worsened performance, motivational issues, lack of understanding, and irrelevance. The ethical issues of gaming the system and cheating were also often reported. As part of our results, we map the relations between game design elements and the negative effects that they may cause. The focus group revealed that developers were not aware of many of the possible negative effects and that they consider this type of information useful. The discussion revealed their agreement on some of those potential negative effects and also some positive counterparts.
Conclusions:
Gamification, when properly applied, can have positive effects on education/learning software. However, gamified software is also prone to generate harmful effects. Revealing and discussing potentially negative effects can help to make more informed decisions considering their trade-off with respect to the expected benefits.",Information and Software Technology,18 Mar 2025,5.0,"While the study on the negative effects of gamification is interesting, its practical impact on European startups may be less direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002518,Negative effects of gamification in education software: Systematic mapping and practitioner perceptions,April 2023,Not Found,Cláuvin=Almeida: almeidaclauvin@gmail.com; Marcos=Kalinowski: kalinowski@inf.puc-rio.br; Anderson=Uchôa: andersonuchoa@ufc.br; Bruno=Feijó: bfeijo@inf.puc-rio.br,"Abstract
Context:
While most research shows positive effects of 
gamification
, the focus on its adverse effects is considerably smaller and further understanding of these effects is needed.
Objective:
To provide a comprehensive overview on research reporting negative effects of game design elements and to provide insights into the awareness of developers on these effects and into how they could be considered in practice.
Method:
We conducted a 
systematic mapping study
 of the negative effects of game design elements on education/learning systems. We also held a focus 
group discussion
 with developers of a gamified software, discussing the mapping study results with regard to their awareness and perceptions on the reported negative effects in practice.
Results:
The mapping study revealed 87 papers reporting undesired effects of game design elements. We found that badges, leaderboards, competitions, and points are the game design elements most often reported as causing negative effects. The most cited negative effects were lack of effect, worsened performance, motivational issues, lack of understanding, and irrelevance. The ethical issues of gaming the system and cheating were also often reported. As part of our results, we map the relations between game design elements and the negative effects that they may cause. The focus group revealed that developers were not aware of many of the possible negative effects and that they consider this type of information useful. The discussion revealed their agreement on some of those potential negative effects and also some positive counterparts.
Conclusions:
Gamification, when properly applied, can have positive effects on education/learning software. However, gamified software is also prone to generate harmful effects. Revealing and discussing potentially negative effects can help to make more informed decisions considering their trade-off with respect to the expected benefits.",Information and Software Technology,18 Mar 2025,5.0,"Similar to abstract 64, this study on the negative effects of gamification, while informative, may have a limited practical impact on European startups compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002531,A systematic mapping study and practitioner insights on the use of software engineering practices to develop MVPs,April 2023,Not Found,Silvio=Alonso: smarques@inf.puc-rio.br; Marcos=Kalinowski: Not Found; Bruna=Ferreira: Not Found; Simone D.J.=Barbosa: Not Found; Hélio=Lopes: Not Found,"Abstract
Background:
Many startup environments and even traditional software companies have embraced the use of MVPs (Minimum Viable Products) to allow quickly experimenting solution options. The MVP concept has influenced the way in which development teams apply 
Software Engineering
 (SE) practices. However, the overall understanding of this influence of MVPs on SE practices is still poor.
Objective:
Our goal is to characterize the publication landscape on practices that have been used in the context of software MVPs and to gather practitioner insights on the identified practices.
Method:
We conducted a 
systematic mapping study
 using a hybrid search strategy that consists of a database search and parallel forward and backward snowballing. Thereafter, we discussed the mapping study results in two 
focus groups sessions
 involving twelve industry practitioners that extensively use MVPs in their projects to capture their perceptions on the findings of the mapping study.
Results:
We identified 33 papers published between 2013 and 2020. We observed some trends related to MVP ideation (or MVP conception) and evaluation practices. For instance, regarding ideation, we found six different approaches (
e.g.
, Design Thinking, Lean Inception) and mainly informal end-user involvement practices (
e.g.
, workshops, interviews). Regarding evaluation, there is an emphasis on end-user validations based on practices such as 
usability tests
, A/B testing, and usage data analysis. However, there is still limited research related to MVP 
technical feasibility
 assessment and effort estimation. Practitioners of the focus group sessions reinforced the confidence in our results regarding ideation and evaluation practices, being aware of most of the identified practices. They also reported how they deal with the 
technical feasibility
 assessments (involving developers during the ideation and conducting informal experiments) and effort estimation in practice (based on expert opinion and using 
practices common
 to 
agile methodologies
, such as Planning Poker).
Conclusion:
Our analysis suggests that there are opportunities for solution proposals and evaluation studies to address literature gaps concerning technical feasibility assessment and effort estimation. Overall, more effort needs to be invested into empirically evaluating the existing MVP-related practices.",Information and Software Technology,18 Mar 2025,7.0,The study on MVP practices in software development can have a significant impact on early-stage ventures by improving product development processes and enhancing the understanding of technical feasibility and effort estimation.
https://www.sciencedirect.com/science/article/pii/S0950584922002257,Burnout in software engineering: A systematic mapping study,March 2023,"Burnout, Software engineering, Systematic mapping study",Tien Rahayu=Tulili: t.r.tulili@rug.nl; Andrea=Capiluppi: a.capiluppi@rug.nl; Ayushi=Rastogi: a.rastogi@rug.nl,"Abstract
Context:
Burnout is a work-related syndrome that, similar to many occupations, influences most software developers. For decades, studies in software engineering(SE) have explored the causes of burnout and its consequences among IT professionals.
Objective:
This paper is a 
systematic mapping study
 (SMS) of the studies on burnout in SE, exploring its causes and consequences, and how it is studied (e.g., choice of data).
Method:
We conducted a systematic mapping study and identified 92 relevant research articles dating as early as the early 1990s, focusing on various aspects and approaches to detect burnout in software developers and IT professionals.
Results:
Our study shows that early research on burnout was primarily qualitative, which has steadily moved to more quantitative, data-driven in the last decade. The emergence of 
machine learning
 (ML) approaches to detect burnout in developers has become a 
de-facto
 standard.
Conclusion:
Our study summarises what we now know about burnout, how software artifacts indicate burnout, and how machine learning can help its early detection. As a comprehensive analysis of past and present 
research works
 in the field, we believe this paper can help future research and practice focus on the 
grand challenges
 ahead and offer necessary tools.",Information and Software Technology,18 Mar 2025,6.0,"While the study on burnout in software developers is important for the well-being of individuals, its direct impact on early-stage ventures may be limited compared to other topics."
https://www.sciencedirect.com/science/article/pii/S0950584922002257,Burnout in software engineering: A systematic mapping study,March 2023,"Burnout, Software engineering, Systematic mapping study",Tien Rahayu=Tulili: t.r.tulili@rug.nl; Andrea=Capiluppi: a.capiluppi@rug.nl; Ayushi=Rastogi: a.rastogi@rug.nl,"Abstract
Context:
Burnout is a work-related syndrome that, similar to many occupations, influences most software developers. For decades, studies in software engineering(SE) have explored the causes of burnout and its consequences among IT professionals.
Objective:
This paper is a 
systematic mapping study
 (SMS) of the studies on burnout in SE, exploring its causes and consequences, and how it is studied (e.g., choice of data).
Method:
We conducted a systematic mapping study and identified 92 relevant research articles dating as early as the early 1990s, focusing on various aspects and approaches to detect burnout in software developers and IT professionals.
Results:
Our study shows that early research on burnout was primarily qualitative, which has steadily moved to more quantitative, data-driven in the last decade. The emergence of 
machine learning
 (ML) approaches to detect burnout in developers has become a 
de-facto
 standard.
Conclusion:
Our study summarises what we now know about burnout, how software artifacts indicate burnout, and how machine learning can help its early detection. As a comprehensive analysis of past and present 
research works
 in the field, we believe this paper can help future research and practice focus on the 
grand challenges
 ahead and offer necessary tools.",Information and Software Technology,18 Mar 2025,6.0,"Similar to abstract 67, the study on burnout in software developers is valuable but may have limited direct impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002373,Machine learning in software defect prediction: A business-driven systematic mapping study,March 2023,Not Found,Szymon=Stradowski: Not Found; Lech=Madeyski: lech.madeyski@pwr.edu.pl,"Abstract
Context:
Machine learning
 is a valuable tool in 
software engineering
 allowing fair 
defect prediction
 capabilities at a relatively small expense. However, although the practical usage of machine learning in 
defect prediction
 has been studied over many years, there is not sufficient systematic effort to analyse its potential for 
business application
.
Objective:
The following 
systematic mapping study
 aims to analyse the current state-of-the-art in terms of machine learning 
software defect
 prediction modelling and to identify and classify the emerging new trends. Notably, the analysis is done from a business perspective, evaluating the opportunities to adopt the latest techniques and methods in commercial settings to improve software quality and lower the cost of 
development life cycle
.
Method:
We created a broad search universe to answer our research questions, performing an automated query through the Scopus database to identify relevant primary studies. Next, we evaluated all found studies using a 
classification scheme
 to map the extent of 
business adoption
 of machine learning 
software defect
 prediction based on the keywords used in the publications. Additionally, we use PRISMA 2020 guideline to validate reporting.
Results:
After the application of the selection criteria, the remaining 742 primary studies included in Scopus until February 23, 2022 were mapped to classify and structure the research area. The results confirm that the usage of commercial datasets is significantly smaller than the established datasets from NASA and open-source projects. However, we have also found meaningful emerging trends considering business needs in analysed studies.
Conclusions:
There is still a considerable amount of work to fully internalise business applicability in the field. Performed analysis has shown that purely academic considerations dominate in published research; however, there are also traces of in vivo results becoming more available. Notably, the created maps offer insight into future machine learning software defect prediction research opportunities.",Information and Software Technology,18 Mar 2025,8.0,"The analysis of machine learning applications in software development from a business perspective can provide actionable insights for early-stage ventures looking to adopt new techniques and improve software quality, making it highly valuable."
https://www.sciencedirect.com/science/article/pii/S0950584922002142,An empirical study on bugs in JavaScript engines,March 2023,Not Found,Ziyuan=Wang: wangziyuan@njupt.edu.cn; Dexin=Bu: Not Found; Nannan=Wang: Not Found; Sijie=Yu: Not Found; Shanyi=Gou: Not Found; Aiyue=Sun: Not Found,"Abstract
Context:
JavaScript is a prototype-based dynamic type 
scripting language
. The correct running of a JavaScript program depends on the correctness of both the program and the JavaScript engine.
Objective:
An in-depth understanding of the characteristics of bugs in JavaScript engines can help detect and fix them.
Methods:
We conduct an empirical study on the bugs in three mainstream JavaScript engines: V8, SpiderMonkey, and Chakra. Such an empirical study involves 19,019 
bug reports
, 16,437 revisions, 805 test cases, and root causes of randomly selected 540 bugs.
Results:
(1) The Compiler and the 
DOM
 are the most buggy component in V8 and SpiderMonkey, respectively. Most of the source files contain only one bug. (2) The scales of the testing programs that reveal bugs are usually small. Most bug fixes involve only limited modifications since the number of modified source files and lines of code modified are small. (3) Most bugs can be fixed within half a year (80.33% for V8 and 91.9% for SpiderMonkey). Only 4.33% of SpiderMonkey bugs need more than a year to fix. Bugs in SpiderMonkey are usually fixed faster than bugs in V8. (4) High priority tends to be assigned to Infrastructure bugs in V8 and Release Automation bugs in SpiderMonkey. The duration of bugs is not strictly correlated with their priorities. (5) Semantic bugs are the most common root causes of bugs. And among semantic bugs, the processing bugs, missing features bugs and function call bugs are more than others.
Conclusion:
This study deepens our understanding of bugs in JavaScript engines, and empirical results could indicate some potential problems during the detecting and fixing of bugs in JavaScript engines, assist developers of JavaScript engines in improving their development quality, assist maintainers in detecting and fixing bugs more effectively, and suggest users of JavaScript evade potential risks.",Information and Software Technology,18 Mar 2025,5.0,"While the study on bugs in JavaScript engines is informative, its practical impact on early-stage ventures may be less immediate compared to studies focusing on development practices or business applications."
https://www.sciencedirect.com/science/article/pii/S0950584922002221,Parallel evolutionary test case generation for web applications,March 2023,Not Found,Weiwei=Wang: Not Found; Shumei=Wu: Not Found; Zheng=Li: Not Found; Ruilian=Zhao: rlzhao@mail.buct.edu.cn,"Abstract
Context:
Web applications follow a client–server schema, so it is more appropriate for evolutionary test case generation considering both client and server. However, test cases from the client-side are composed of event sequences, which are quite time-consuming when executed due to the interaction with the browser. Furthermore, premature convergence is a problem for 
evolutionary algorithms
 because of the decline of population diversity. These problems restrict the applicability of 
evolutionary algorithms
 in test case generation for web applications.
Objective:
Parallelization
 has been proven helpful in optimizing test case generation. So, to improve the efficiency and effectiveness of test generation for web applications, this paper proposes a parallel evolutionary test case generation approach where test cases are generated from the client-side behavior model to cover the sensitive paths of server-side code by using a parallel 
genetic algorithm
 based on the island model.
Method:
A parallel execution strategy is presented to drive multi-individuals to execute on multi-browsers simultaneously to shorten the 
execution time
 of populations during evolution. And an island model with a corresponding migration mechanism and subpopulation evolution strategy is well-designed to increase population diversity during evolution. Meanwhile, the server-side code triggered by parallel individuals is identified to guide the evolution process.
Results:
Experiments are conducted on six widely-used web applications, and the results show that compared with the sequential evolutionary test case generation, our approach decreases the iterations and evolution time required by 33.43% and 63.10% on average, respectively. The efficiency of test generation has been greatly enhanced.
Conclusion:
This paper provides a parallel evolutionary test case generation for web applications, where the parallel execution strategy is presented to shorten the 
execution time
 of populations during evolution, increasing test generation efficiency. Moreover, the island model with a migration mechanism is introduced to increase population diversity during evolution, improving the test generation effectiveness.",Information and Software Technology,18 Mar 2025,9.0,"The proposed approach of parallel evolutionary test case generation for web applications shows significant improvements in efficiency and effectiveness, which can have a high impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002117,Issues-Driven features for software fault prediction,March 2023,Not Found,Amir=Elmishali: amirelm@post.bgu.ac.il; Meir=Kalech: kalech@bgu.ac.il,"Abstract
Context:
Software systems are an integral part of almost every modern industry. Unfortunately, the more complex the software, the more likely it will fail. A promising strategy is applying fault prediction models to predict which components may be defective. Since features are essential to the prediction model’s success, extracting significant features can improve the model’s accuracy. Previous research studies used software metrics as features in fault prediction models. One disadvantage of these features is that they measure the code developed rather than the requirements. On the other hand, faults are frequently the result of a mismatch between the software’s behavior and its needs.
Objective:
We present a novel paradigm for constructing features that consider the requirements as well by combining novel requirement metrics, called 
Issues-Driven features
, and traditional 
code metrics
.
Method:
We experimentally compare the performance of 
Issues-Driven features
 and state-of-the-art traditional features on 86 open-source projects from two organizations.
Results:
The results show that 
Issues-Driven features
 are significantly better than state-of-the-art features and achieve an improvement of 6 to 13 percent in terms of AUC.
Conclusions:
The study concludes that integrating the requirements into fault prediction features overcomes the limitations of traditional software metrics that are agnostic to the requirements of the software.",Information and Software Technology,18 Mar 2025,8.0,"The integration of requirements into fault prediction features shows promising results in improving accuracy, which can be valuable for startups in improving software quality."
https://www.sciencedirect.com/science/article/pii/S095058492200218X,WINE: Warning miner for improving bug finders,March 2023,Not Found,Yoon-ho=Choi: yhchoi@handong.ac.kr; Jaechang=Nam: jcnam@handong.edu,"Abstract
Context:
Bug finders have been actively used to efficiently detect bugs. However, developers and researchers found that the bug finders show high false positive rate. The 
false positives
 can be caused by two major reasons: (1) users rejecting warnings and (2) false-positive inducing issues (FPI), i.e., incorrect or incomplete rule implementations.
Objective:
The objective of this study is to reduce warning validation costs for developers of bug finders when they validate the implementation of bug finders to reduce 
false positives
 caused by FPI.
Methods:
To achieve the objective, we propose a novel approach, 
WINE
. The key idea of 
WINE
 is to extract 
representative warnings
 that are structurally equal to other warnings, or structurally contain other warnings from numerous warnings. The rationale behind the approach is that the warnings detected based on structural information and tokens might be equal to each other, or contain other warnings structurally.
Results:
We evaluated our approach with PMD, an open source bug finder, and 1,008 Java 
open source projects
 maintained by Apache Software Foundation. As a result, 
WINE
 extracted just about 2% of all warnings. Among the 2% of warnings, we could find the 28 FPIs of PMD. Among them, ten FPIs were already fixed among them. In addition, we simulated our approach in regression testing of PMD with twelve versions changes of PMD (6.25.0 to 6.37.0). As a result, we observed that 
WINE
 can effectively reduce the inspection costs by removing about 95% changed warnings.
Conclusion:
Based on the results, we suggest that 
WINE
 could be adopted to improve the bug finders in terms of reducing false positives cause by FPI. In addition, 
WINE
 is helpful in the 
development processes
 of bug finders to identify false positives and 
false negatives
, especially in regression testing of bug finders.",Information and Software Technology,18 Mar 2025,7.0,"The proposed approach of WINE for reducing false positives in bug finders demonstrates effectiveness, which can be beneficial for startups in reducing validation costs and improving bug detection accuracy."
https://www.sciencedirect.com/science/article/pii/S095058492200221X,Detecting code smells using industry-relevant data,March 2023,Not Found,Lech=Madeyski: lech.madeyski@pwr.edu.pl; Tomasz=Lewowski: tomasz.lewowski@pwr.edu.pl,"Abstract
Context
Code smells are patterns in 
source code
 associated with an increased defect rate and a higher maintenance effort than usual, but without a clear definition. Code smells are often detected using rules hard-coded in detection tools. Such rules are often set arbitrarily or derived from data sets tagged by reviewers without the necessary industrial know-how. Conclusions from studying such data sets may be unreliable or even harmful, since algorithms may achieve higher values of performance metrics on them than on models tagged by experts, despite not being industrially useful.
Objective
Our goal is to investigate the performance of various 
machine learning algorithms
 for automated code smell detection trained on code smell data set(MLCQ) derived from actively developed and industry-relevant projects and reviews performed by experienced software developers.
Method
We assign the severity of the smell to the code sample according to a consensus between the severities assigned by the reviewers, use the Matthews 
Correlation Coefficient
 (MCC) as our main performance metric to account for the entire 
confusion matrix
, and compare the median value to account for non-normal distributions of performance. We compare 6720 models built using eight 
machine learning techniques
. The entire process is automated and reproducible.
Results
Performance of compared techniques depends heavily on analyzed smell. The median value of our performance metric for the best algorithm was 0.81 for Long Method, 0.31 for Feature Envy, 0.51 for Blob, and 0.57 for Data Class.
Conclusions
Random Forest
 and Flexible 
Discriminant Analysis
 performed the best overall, but in most cases the performance difference between them and the median algorithm was no more than 10% of the latter. The performance results were stable over multiple iterations. Although the F-score omits one quadrant of the 
confusion matrix
 (and thus may differ from MCC), in code smell detection, the actual differences are minimal.",Information and Software Technology,18 Mar 2025,6.0,"The investigation of machine learning algorithms for automated code smell detection provides valuable insights, but the practical implications for startups may not be as direct compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002233,Boosting input data sequences generation for testing EFSM-specified systems using deep reinforcement learning,March 2023,Not Found,Ting=Shu: shuting@zstu.edu.cn; Cuiping=Wu: 202030504154@mails.zstu.edu.cn; Zuohua=Ding: zuohuading@zstu.edu.cn,"Abstract
Context:
Input data sequence (IDS) is an important component of test sequences for testing from the Extended 
Finite State Machine
 (EFSM) model. During test generation, frequent IDS derivation is time-consuming. Therefore, it has become one of the key factors that restrict the efficiency of test sequences generation.
Objective:
To address this issue, this paper introduces 
deep reinforcement learning
 (DRL) to propose a novel approach named IDSG-DRL to accelerate IDS derivation.
Method:
Our method first formalizes the problem of generating IDS for EFSM-based testing as a Markov decision problem. It then incorporates the 
DRL algorithm
 to learn experience from previous input data generation and train a decision-making model to significantly enhance the efficiency of subsequent data derivation for the newly generated test sequences. To improve the convergence of 
DRL algorithm
 and ensure the success rate of data generation, a state representation based on variable deviation and action formulation using adaptive exploration are elaborately designed. Finally, a DRL-based algorithm for efficiently yielding IDS is presented for any subject test sequence.
Results:
We evaluate the proposed approach against the random method, GA-based method as well as a 
particle swarm optimization
 (PSO) based method. Experimental statistics show that IDSG-DRL significantly outperforms the baselines in terms of 
iteration steps
, runtime cost, and the success rate of input data derivation. Specifically, compared to random, GA-based and PSO-based methods, IDSG-DRL can reduce the average number of 
iteration steps
 by up to 87.09%, 78.57%, and 56.35%, respectively. Regarding the average runtime, our approach is about 3.52 and 1.58 times faster than the GA-based and PSO-based methods. Additionally, given a larger input range, we observed that the performance of IDSG-DRL is more stable and its advantages are more significant.
Conclusion:
The experimental results suggest that our method is very promising to speed up IDS generation for EFSM-based testing.",Information and Software Technology,18 Mar 2025,8.0,"The use of deep reinforcement learning to accelerate IDS derivation in EFSM-based testing shows promising results in efficiency improvement, which can be beneficial for startups in optimizing testing processes."
https://www.sciencedirect.com/science/article/pii/S0950584922002294,Selection of human evaluators for design smell detection using dragonfly optimization algorithm: An empirical study,March 2023,"Software quality, Design smell detection, Dragonfly Algorithm, Search-based software engineering, Optimization, God class, Empirical study",Sultan M.=Al Khatib: s.al-khatib@bau.edu.jo; Khalid=Alkharabsheh: khalidkh@bau.edu.jo; Sadi=Alawadi: sadi.alawadi@it.uu.se,"Abstract
Context:
Design smell detection is considered an efficient activity that decreases 
maintainability
 expenses and improves software quality. Human context plays an essential role in this domain.
Objective:
In this paper, we propose a search-based approach to optimize the selection of human 
evaluators
 for design smell detection.
Method:
For this purpose, Dragonfly Algorithm (DA) is employed to identify the optimal or near-optimal human evaluator’s profiles. An online survey is designed and asks the evaluators to evaluate a sample of classes for the presence of god class design smell. The Kappa-Fleiss test has been used to validate the proposed approach.
Results:
The results show that the dragonfly optimization algorithm can be utilized effectively to decrease the efforts (time, cost ) of design smell detection concerning the identification of the number and the optimal or near-optimal profile of human experts required for the evaluation process.
Conclusions:
A Search-based approach can be effectively used for improving a god-class design smell detection. Consequently, this leads to minimizing the maintenance cost.",Information and Software Technology,18 Mar 2025,7.0,"This abstract presents a practical approach to optimize the selection of human evaluators for design smell detection, which can lead to cost and time savings in software development."
https://www.sciencedirect.com/science/article/pii/S0950584922002130,Metamorphic testing of Advanced Driver-Assistance System (ADAS) simulation platforms: Lane Keeping Assist System (LKAS) case studies,March 2023,Not Found,Muhammad=Iqbal: mi759@uowmail.edu.au; Jia Cheng=Han: jch458@uowmail.edu.au; Zhi Quan=Zhou: zhiquan@uow.edu.au; Dave=Towey: dave.towey@nottingham.edu.cn; Tsong Yueh=Chen: tychen@swin.edu.au,"Abstract
Context:
Simulation-based testing is essential when developing Advanced Driver-Assistance Systems (ADASs) and 
autonomous driving
 (AD) systems, producing fast, high-quality test results, at relatively low cost. Simulation testing relies on the quality of the ADAS simulation platform: If the simulation platform is faulty, then the simulation results may be incorrect, and hence useless. However, because of the lack of suitable test oracles — mechanisms to determine the correctness of the software output or behavior — it can be too difficult (or expensive) to verify or validate ADAS/AD simulation platforms, a situation known as the oracle problem.
Objective:
To alleviate the oracle problem and better understand ADAS simulation software.
Methods:
We develop geometric-transformation-based metamorphic testing approaches, and report on empirical studies conducted on the verification and validation (V&V) of three popular simulation platforms for ADAS development: 
Simulink
, CarMaker and 51Sim-One Cloud. Our examination focused on the platforms’ Lane Keeping Assist Systems (LKASs).
Results:
When tested with ordinary (traditional) test cases, no issues were identified on any simulation platform. However, after applying geometric-transformation-based metamorphic testing, issues were revealed, some of which were later confirmed by the MATLAB and IPG Automotive teams. To the best of our knowledge, this paper is the first to report on real bugs and issues in ADAS simulation platforms.
Conclusion:
Our research shows the simplicity, effectiveness and applicability of the proposed approach for ADAS simulation testing. This paper also provides successful examples of incorporating metamorphic testing into the testing of ADAS standards and protocols, and shows how practitioners can design effective metamorphic relations (MRs) inspired by using the symmetry metamorphic relation pattern.",Information and Software Technology,18 Mar 2025,10.0,"This abstract introduces a novel approach to detect real bugs in ADAS simulation platforms, which is crucial for the development of Advanced Driver-Assistance Systems and autonomous driving systems, impacting safety and reliability."
https://www.sciencedirect.com/science/article/pii/S0950584922002245,Comparison of multi-criteria decision-making methods for online controlled experiments in a launch decision-making framework,March 2023,Not Found,Jie J.W.=Wu: jiewu@gwu.edu; Thomas A.=Mazzuchi: Not Found; Shahram=Sarkani: Not Found,"Abstract
Context
User-intensive software systems such as Web and mobile applications are defined as systems that serve and interact with an increasingly large number of users. Inefficient launch decisions in user-intensive systems in domains such as social media, information retrieval and e-commerce can lead to dramatic loss in the goal metrics of these highly scalable applications, and therefore impact potentially billions of users.
Objective
Due to the complexity of user-intensive systems, engineers rely heavily on A/B testing (i.e., online controlled experiments) to evaluate and measure the impact of new changes. However, little attention has been paid to improve the empirical process of making launch decisions based on the A/B testing results. In this paper, we propose a framework to address this issue.
Method
We propose a Multi-Criteria Decision Making (MCDM) framework that uses A/B testing results to provide launch 
decisions analysis
, as a complementary tool to assist decision making. The framework includes modules for 1) configuration setup, 2) criteria weighting, 3) 
pairwise comparison
 between criteria and alternatives 4) analysis of alternatives using MCDM and produces launch decisions based on the A/B testing results.
Results
Experimental results from publicly available dataset that compares well-known and widely applied MDCM methods shows that a good combination of the Analysis of Alternative method (such as TOPSIS-Vector, MMOORA, and VIKOR) and Criteria Weighting method (such as Standard Deviation) in the framework can effectively assistlaunch decision making.
Conclusion
We formulate the problem of launch decision making using A/B testing results and propose a MCDM based framework for it, as an imperfect first step to address this problem. The experiments suggest that 
MCDM methods
 such as 
TOPSIS
, MMOORA and 
VIKOR
 may be effective at making launch decisions based on A/B testing results.",Information and Software Technology,18 Mar 2025,8.0,"This abstract proposes a framework to improve launch decisions for user-intensive systems, addressing the need for better decision-making tools in A/B testing, which can have a significant impact on the success of web and mobile applications."
https://www.sciencedirect.com/science/article/pii/S0950584922002385,A probabilistic framework for mutation testing in deep neural networks,March 2023,Not Found,Florian=Tambon: florian-2.tambon@polymtl.ca; Foutse=Khomh: Not Found; Giuliano=Antoniol: Not Found,"Abstract
Context:
Mutation Testing (MT) is an important tool in traditional 
Software Engineering
 (SE) white-box testing. It aims to artificially inject faults in a system to evaluate a test suite’s capability to detect them, assuming that the test suite defects finding capability will then translate to real faults. If MT has long been used in SE, it is only recently that it started gaining the attention of the 
Deep Learning
 (DL) community, with researchers adapting it to improve the 
testability
 of 
DL models
 and improve the trustworthiness of 
DL systems
.
Objective:
If several techniques have been proposed for MT, most of them neglected the 
stochasticity
 inherent to DL resulting from the training phase. Even the latest MT approaches in DL, which propose to tackle MT through a 
statistical approach
, might give inconsistent results. Indeed, as their 
statistic
 is based on a 
fixed set
 of sampled training instances, it can lead to different results across instances set when results should be consistent for any instance.
Methods:
In this work, we propose a Probabilistic Mutation Testing (PMT) approach that alleviates the inconsistency problem and allows for a more consistent decision on whether a mutant is killed or not.
Results:
We show that PMT effectively allows a more consistent and informed decision on mutations through evaluation using three models and eight 
mutation operators
 used in previously proposed 
MT methods
. We also analyze the trade-off between the 
approximation
 error and the cost of our method, showing that relatively small error can be achieved for a manageable cost.
Conclusion:
Our results showed the limitation of current MT practices in 
DNN
 and the need to rethink them. We believe PMT is the first step in that direction which effectively removes the lack of consistency across test executions of previous methods caused by the 
stochasticity
 of 
DNN
 training.",Information and Software Technology,18 Mar 2025,9.0,"This abstract presents a new Probabilistic Mutation Testing approach to improve the testability of Deep Learning models, addressing a critical need to enhance the trustworthiness of DL systems, with potential implications for various industries."
https://www.sciencedirect.com/science/article/pii/S0950584922002269,PAFL: Probabilistic Automaton-based Fault Localization for Recurrent Neural Networks,March 2023,"Fault localization, Faults, Recurrent neural networks, n-gram, Probabilistic finite automata",Yuta=Ishimoto: ishimoto@posl.ait.kyushu-u.ac.jp; Masanari=Kondo: kondo@ait.kyushu-u.ac.jp; Naoyasu=Ubayashi: ubayashi@ait.kyushu-u.ac.jp; Yasutaka=Kamei: kamei@ait.kyushu-u.ac.jp,"Abstract
Context:
If 
deep learning
 models in safety–critical systems misbehave, serious accidents may occur. Previous studies have proposed approaches to overcome such misbehavior by detecting and modifying the responsible faulty parts in 
deep learning
 models. For example, 
fault localization
 has been applied to 
deep neural networks
 to detect neurons that cause misbehavior.
Objective:
However, such approaches are not applicable to 
deep learning models
 that have 
internal states
, which change dynamically based on the input 
data samples
 (e.g., 
recurrent neural networks
 (RNNs)). Hence, we propose a new fault localization approach to be applied to RNNs.
Methods:
We propose 
probabilistic automaton-based fault localization (PAFL)
. PAFL enables developers to detect faulty parts even in RNNs by computing 
suspiciousness
 scores
 with fault localization using 
n
-grams. We convert RNNs into 
probabilistic 
finite automata
 (PFAs)
 and localize faulty sequences of 
state transitions
 on PFAs. To consider various sequences and to detect faulty ones more precisely, we use 
n
-grams inspired by 
natural language processing
. Additionally, we distinguish data samples related to the misbehavior to evaluate PAFL. We also propose a novel suspiciousness score, 
average
 
n
-gram suspiciousness (ANS) score
, based on 
n
-grams to distinguish data samples. We evaluate PAFL and ANS scores on eight publicly available datasets on three RNN variants: simple 
recurrent
 neural network, 
gated recurrent units
, and long short-term memory.
Results:
The experiment demonstrates that ANS scores identify faulty parts of RNNs when 
n
 is greater than one. Moreover, PAFL is statistically significantly better and has large 
effect sizes
 compared to state-of-the-art fault localization in terms of distinguishing data samples related to the misbehavior. Specifically, PAFL is better in 66.74% of the experimental settings.
Conclusion:
The results demonstrate that PAFL can be used to detect faulty parts in RNNs. Hence, in future studies, PAFL can be used as a baseline for fault localization in RNNs.",Information and Software Technology,18 Mar 2025,10.0,"This abstract introduces a new fault localization approach for RNNs, addressing a critical issue in deep learning models with internal states. The proposed method demonstrates significant improvements in detecting faulty parts, which can impact the safety and reliability of deep learning models in safety-critical systems."
https://www.sciencedirect.com/science/article/pii/S095058492200194X,Exploring granular test coverage and its evolution with matrix visualizations,March 2023,Not Found,Kaj=Dreef: kdreef@uci.edu; Vijay Krishna=Palepu: Vijay.Palepu@microsoft.com; James A.=Jones: jajones@uci.edu,"Abstract
Context:
Current software-development tools that are used in practice make understanding the test execution of software difficult, for both granular tasks (
e.g.,
 answering questions such as, “which test cases execute this method?”) and global tasks (
e.g.,
 answering questions such as, “what is the proportion of unit tests to system tests?”). Current tools typically support local, file-based views of a project’s test suite and its execution data, and rarely offer a global overview. Even more rarely, do they provide access to historical information of this nature. Such global overviews can provide a larger context for a method’s execution by test cases; help identify other similar, or related methods; and even reveal similarity between individual tests.
Objective:
This work approaches such challenges with a novel, interactive, matrix-based visual interface that provides a global overview of a software project’s test suite, specifically in the context of the methods available in the project’s codebase. Through a series of interactive functions to sort, filter, query, and explore a test-matrix visualization, we evaluate how developers can effectively answer questions about their project’s test suite, and the code executed by such tests.
Method:
We built a dynamic test-suite analysis and software-visualization tool that implements our designed interface to address the challenges of understanding the testing of software systems. With this implementation, we conducted a user study of 20 software developers to assess their ability to understand and report test execution information and measured accuracy and time. Additionally, we present a series of 
case studies
 to demonstrate a number of insights that our tool reveals.
Results:
Our evaluations, performed on 
26
 real-world software systems, show that the interactive visualization assisted developers to answer questions about software tests and the code they execute. Further, the visualization consistently outperforms traditional development tools, both in accuracy and time taken to complete software-engineering tasks.
Conclusion:
Global-overview test matrices offer novel perspectives on test-suite composition, which can guide software development and testing practices.",Information and Software Technology,18 Mar 2025,9.0,"The research provides a practical tool for software developers to improve understanding of test execution, showing performance improvement over existing methods."
https://www.sciencedirect.com/science/article/pii/S095058492200194X,Exploring granular test coverage and its evolution with matrix visualizations,March 2023,Not Found,Kaj=Dreef: kdreef@uci.edu; Vijay Krishna=Palepu: Vijay.Palepu@microsoft.com; James A.=Jones: jajones@uci.edu,"Abstract
Context:
Current software-development tools that are used in practice make understanding the test execution of software difficult, for both granular tasks (
e.g.,
 answering questions such as, “which test cases execute this method?”) and global tasks (
e.g.,
 answering questions such as, “what is the proportion of unit tests to system tests?”). Current tools typically support local, file-based views of a project’s test suite and its execution data, and rarely offer a global overview. Even more rarely, do they provide access to historical information of this nature. Such global overviews can provide a larger context for a method’s execution by test cases; help identify other similar, or related methods; and even reveal similarity between individual tests.
Objective:
This work approaches such challenges with a novel, interactive, matrix-based visual interface that provides a global overview of a software project’s test suite, specifically in the context of the methods available in the project’s codebase. Through a series of interactive functions to sort, filter, query, and explore a test-matrix visualization, we evaluate how developers can effectively answer questions about their project’s test suite, and the code executed by such tests.
Method:
We built a dynamic test-suite analysis and software-visualization tool that implements our designed interface to address the challenges of understanding the testing of software systems. With this implementation, we conducted a user study of 20 software developers to assess their ability to understand and report test execution information and measured accuracy and time. Additionally, we present a series of 
case studies
 to demonstrate a number of insights that our tool reveals.
Results:
Our evaluations, performed on 
26
 real-world software systems, show that the interactive visualization assisted developers to answer questions about software tests and the code they execute. Further, the visualization consistently outperforms traditional development tools, both in accuracy and time taken to complete software-engineering tasks.
Conclusion:
Global-overview test matrices offer novel perspectives on test-suite composition, which can guide software development and testing practices.",Information and Software Technology,18 Mar 2025,8.0,"Similar to abstract 81, this research offers a valuable visualization tool for software developers, enhancing the understanding of test suite execution."
https://www.sciencedirect.com/science/article/pii/S0950584922002270,Introduction to Special Issue on Visualization Applied to Software Engineering,March 2023,Not Found,Paul=Leger: Not Found; Alexandre=Bergel: Not Found; Juan Pablo Sandoval=Alcocer: Not Found; Leonel=Merino: Not Found,"Abstract
Software visualization is a broad research area whose general goal is to enhance and promote the theory, realization, and evaluation of approaches to visually encode and analyze software systems, including software development practices, evolution, structure, and software runtime behavior. Software visualization is inherently interdisciplinary, drawing on theories and techniques from information visualization and computer graphics and applying these in the software engineering domain.
This special issue on software visualization aims to bring together a community of researchers from software engineering, information visualization, computer graphics, human-computer interaction, and data science to discuss theoretical foundations, algorithms, techniques, tools, and applications related to software visualization. The special issue received 17 submissions of which 6 were accepted for publication (i.e., acceptance rate of 35.3%). Amongst the accepted papers, three correspond to extended versions of papers published in the IEEE Working Conference on Software Visualization (VISSOFT) 2021.",Information and Software Technology,18 Mar 2025,5.0,"While software visualization is important, this abstract focuses more on academic discussion and community gathering rather than direct impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002154,Lessons learned to improve the UX practices in agile projects involving data science and process automation,March 2023,Not Found,Bruna=Ferreira: bruna@exacta.inf.puc-rio.br; Silvio=Marques: Not Found; Marcos=Kalinowski: Not Found; Hélio=Lopes: Not Found; Simone D.J.=Barbosa: Not Found,"Abstract
Context:
User-Centered Design (UCD) and 
Agile methodologies
 focus on human issues. Nevertheless, agile methodologies focus on contact with contracting customers and generating value for them. Usually, the communication between end users (they use the software and have low decision power) and the agile team is mediated by customers (they have high decision power but do not use the software). However, they do not know the actual problems that end users (may) face in their routine, and they may not be directly affected by software shortcomings. In this context, UX issues are typically identified only after the implementation, during user testing and validation.
Objective:
Aiming to improve the understanding and definition of the problem in agile projects, this research investigates the practices and difficulties experienced by agile teams during the development of data science and process automation projects. Also, we analyze the benefits and the teams’ perceptions regarding user participation in these projects.
Method:
We 
collected data
 from four agile teams, in the context of an academia and industry collaboration focusing on delivering data science and process automation solutions. Therefore, we applied a carefully designed questionnaire answered by developers, scrum masters, and UX designers. In total, 18 subjects answered the questionnaire.
Results:
From the results, we identify practices used by the teams to define and understand the problem and to represent the solution. The practices most often used are prototypes and meetings with stakeholders. Another practice that helped the team to understand the problem was using Lean Inception (LI) ideation workshops. Also, our results present some specific issues regarding data science projects.
Conclusion:
We observed that end-user participation can be critical to understanding and defining the problem. They help to define elements of the domain and barriers in the implementation. We identified a need for approaches that facilitate user-team communication in data science projects to understand the data and its value to the users’ routine. We also identified insights about the need of more detailed requirements representations to support the development of data science solutions.",Information and Software Technology,18 Mar 2025,7.0,"The research addresses the practical challenges faced by agile teams, providing insights on improving user participation in data science projects, which can benefit early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002191,Becoming an entrepreneur: A study of factors with women from the tech sector,March 2023,"Women in tech, Entrepreneurship, Affecting factors, Equality, Gender bias",Yekaterina=Kovaleva: Not Found; Sonja=Hyrynsalmi: Not Found; Andrey=Saltan: Not Found; Ari=Happonen: Not Found; Jussi=Kasurinen: jussi.kasurinen@lut.fi,"Abstract
Context
The gender imbalance in technology, sciences, and engineering is a global problem and according to the statistics, this really has not changed much in the last thirty years. Moreover, there is also a lack of women in tech entrepreneurship; most success stories are about male entrepreneurs, and in Silicon Valley the term describing the start-up culture is called “tech bros” for a reason.
Objective
This paper identifies different factors affecting the women's decision to select a tech sector and become an entrepreneur in the tech sector. In this paper we also aim to identify different pitfalls and problems, which could influence the attractiveness of the tech sector, and specifically technology entrepreneurship, towards the women interested in the science, technology, and engineering domains.
Method
To study the factors affecting women's interest towards entrepreneurship in the technology sector, we conducted a series of surveys and interviews to understand the underlying phenomena. Overall, this study interviewed ten female company founders, and conducted two surveys with women working, interested, or studying towards the tech sector, allowing us to combine and compare the qualitative data from the women who had become entrepreneurs against the quantitative trends and ideas collected from the general audiences.
Results
The most common factors limiting the individuals’ interest towards entrepreneurship such as financial risks or high responsibilities might not be gender-related, but there are also aspects as social acceptance, discrimination, and lack of role models, which affect especially the women interested in the possibilities of becoming an entrepreneur in tech.
Conclusions
In general, the current 
younger generations
 are aware of the option of becoming entrepreneurs, and what becoming one requires. Initiatives, such as adding positive examples of females’ success, or supporting entry-level opportunities towards full-time entrepreneurship, could have a meaningful impact of reducing the gender imbalance in the STEM fields, and in technology entrepreneurship in general.",Information and Software Technology,18 Mar 2025,6.0,"This research identifies important factors affecting women's participation in tech entrepreneurship, but the direct impact on European early-stage ventures is somewhat indirect."
https://www.sciencedirect.com/science/article/pii/S0950584922002191,Becoming an entrepreneur: A study of factors with women from the tech sector,March 2023,"Women in tech, Entrepreneurship, Affecting factors, Equality, Gender bias",Yekaterina=Kovaleva: Not Found; Sonja=Hyrynsalmi: Not Found; Andrey=Saltan: Not Found; Ari=Happonen: Not Found; Jussi=Kasurinen: jussi.kasurinen@lut.fi,"Abstract
Context
The gender imbalance in technology, sciences, and engineering is a global problem and according to the statistics, this really has not changed much in the last thirty years. Moreover, there is also a lack of women in tech entrepreneurship; most success stories are about male entrepreneurs, and in Silicon Valley the term describing the start-up culture is called “tech bros” for a reason.
Objective
This paper identifies different factors affecting the women's decision to select a tech sector and become an entrepreneur in the tech sector. In this paper we also aim to identify different pitfalls and problems, which could influence the attractiveness of the tech sector, and specifically technology entrepreneurship, towards the women interested in the science, technology, and engineering domains.
Method
To study the factors affecting women's interest towards entrepreneurship in the technology sector, we conducted a series of surveys and interviews to understand the underlying phenomena. Overall, this study interviewed ten female company founders, and conducted two surveys with women working, interested, or studying towards the tech sector, allowing us to combine and compare the qualitative data from the women who had become entrepreneurs against the quantitative trends and ideas collected from the general audiences.
Results
The most common factors limiting the individuals’ interest towards entrepreneurship such as financial risks or high responsibilities might not be gender-related, but there are also aspects as social acceptance, discrimination, and lack of role models, which affect especially the women interested in the possibilities of becoming an entrepreneur in tech.
Conclusions
In general, the current 
younger generations
 are aware of the option of becoming entrepreneurs, and what becoming one requires. Initiatives, such as adding positive examples of females’ success, or supporting entry-level opportunities towards full-time entrepreneurship, could have a meaningful impact of reducing the gender imbalance in the STEM fields, and in technology entrepreneurship in general.",Information and Software Technology,18 Mar 2025,7.0,"The study on factors affecting women's interest in entrepreneurship in the tech sector is important for promoting gender balance and diversity in startups, potentially impacting European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922002282,Understanding and predicting incident mitigation time,March 2023,Not Found,Weijing=Wang: wangweijing@tju.edu.cn; Junjie=Chen: junjiechen@tju.edu.cn; Lin=Yang: linyang@tju.edu.cn; Hongyu=Zhang: hongyu.zhang@newcastle.edu.au; Zan=Wang: wangzan@tju.edu.cn,"Abstract
Context:
Incident management plays a significant role in 
online service
 systems. Incidents should be mitigated as soon as possible in order to achieve high service stability. However, available resources tend to be limited, and thus engineers have to schedule their tasks carefully. Time to Mitigate (TTM) refers to the time an incident requires to restore the service availability. Predicting TTM can help better estimate maintenance efforts and provide developers more information when arranging their tasks.
Objective:
Our work aims to predict TTM precisely, which consists of two main steps. First, we perform an empirical study to understand incidents deeply. Then, we design an effective approach for TTM prediction based on the findings from the empirical study.
Methods:
In the empirical study, we used 20 Microsoft 
online service
 systems to investigate the duration of each stage in incident management and the relationship between TTM and incident indicators. Then, we propose TTMPred, a deep-learning-based approach for TTM prediction in the continuous triage scenario based on the features identified from our empirical study. In particular, we improve the generality of TTMPred by extending it to predicting the fixing time of traditional software bugs.
Results:
We investigate the effectiveness of TTMPred on four large-scale online service systems in Microsoft, as well as four widely-used Bugzilla-based projects. The results show that TTMPred performs better than the compared approaches for both incident TTM prediction and bug-fixing time prediction. For example, on average, TTMPred improves the state-of-the-art regression-based approach by 25.66% in terms of MAE (Mean Absolute Error) on the incident data and 42.14% on MAE on the bug data.
Conclusion:
TTMPred can be extended to the bug scenario, and continuously predict accurate bug-fixing time during the triage process.",Information and Software Technology,18 Mar 2025,9.0,"The predictive model for incident TTM and bug-fixing time can greatly benefit online service systems, startups, and developers in Europe by improving service stability and efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584922002282,Understanding and predicting incident mitigation time,March 2023,Not Found,Weijing=Wang: wangweijing@tju.edu.cn; Junjie=Chen: junjiechen@tju.edu.cn; Lin=Yang: linyang@tju.edu.cn; Hongyu=Zhang: hongyu.zhang@newcastle.edu.au; Zan=Wang: wangzan@tju.edu.cn,"Abstract
Context:
Incident management plays a significant role in 
online service
 systems. Incidents should be mitigated as soon as possible in order to achieve high service stability. However, available resources tend to be limited, and thus engineers have to schedule their tasks carefully. Time to Mitigate (TTM) refers to the time an incident requires to restore the service availability. Predicting TTM can help better estimate maintenance efforts and provide developers more information when arranging their tasks.
Objective:
Our work aims to predict TTM precisely, which consists of two main steps. First, we perform an empirical study to understand incidents deeply. Then, we design an effective approach for TTM prediction based on the findings from the empirical study.
Methods:
In the empirical study, we used 20 Microsoft 
online service
 systems to investigate the duration of each stage in incident management and the relationship between TTM and incident indicators. Then, we propose TTMPred, a deep-learning-based approach for TTM prediction in the continuous triage scenario based on the features identified from our empirical study. In particular, we improve the generality of TTMPred by extending it to predicting the fixing time of traditional software bugs.
Results:
We investigate the effectiveness of TTMPred on four large-scale online service systems in Microsoft, as well as four widely-used Bugzilla-based projects. The results show that TTMPred performs better than the compared approaches for both incident TTM prediction and bug-fixing time prediction. For example, on average, TTMPred improves the state-of-the-art regression-based approach by 25.66% in terms of MAE (Mean Absolute Error) on the incident data and 42.14% on MAE on the bug data.
Conclusion:
TTMPred can be extended to the bug scenario, and continuously predict accurate bug-fixing time during the triage process.",Information and Software Technology,18 Mar 2025,9.0,"The predictive model for incident TTM and bug-fixing time can greatly benefit online service systems, startups, and developers in Europe by improving service stability and efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584922001999,Exploring privacy requirements gap between developers and end users,February 2023,Not Found,Jianzhang=Zhang: jianzhang.zhang2017@gmail.com; Jinping=Hua: huajinping@stu.hznu.edu.cn; Nan=Niu: nan.niu@uc.edu; Sisi=Chen: chensisi1@stu.hznu.edu.cn; Juha=Savolainen: juha.savolainen@danfoss.com; Chuang=Liu: liuchuang2022@sina.com,"Abstract
Context:
Privacy policies document the privacy requirements guiding developers. Though privacy policies analysis has drawn increasing attention recently, how end users perceive privacy requirements has been less explored.
Objective:
We empirically explore the privacy requirements gap between developers and end users to derive beneficial insights into users’ privacy concerns to support maintenance.
Method:
We present a semi-automatic privacy requirements gap analysis framework based on text mining including information retrieval, 
topic modeling
, and 
computational linguistic
 techniques.
Results:
The preliminary results of applying our framework to Facebook show that: (1) topic comparison reveals that both privacy related reviews and policy statements involve privacy requirements types of collection, usage, and disclosure as well as account security. The retention requirements are almost not mentioned in reviews as they are hard to be directly perceived; (2) content comparisons reveal that though overlapping with the privacy policy statements, reviews are more general, informal, and negative in wording.
Conclusion:
The illustrative example with Facebook demonstrates the potential usage of our framework in informing software maintenance, e.g., privacy relevant testing and privacy 
policy refinement
.",Information and Software Technology,18 Mar 2025,5.0,The privacy requirements gap analysis framework is relevant for developers but may have limited direct impact on early-stage ventures in Europe compared to the other abstracts.
https://www.sciencedirect.com/science/article/pii/S0950584922001999,Exploring privacy requirements gap between developers and end users,February 2023,Not Found,Jianzhang=Zhang: jianzhang.zhang2017@gmail.com; Jinping=Hua: huajinping@stu.hznu.edu.cn; Nan=Niu: nan.niu@uc.edu; Sisi=Chen: chensisi1@stu.hznu.edu.cn; Juha=Savolainen: juha.savolainen@danfoss.com; Chuang=Liu: liuchuang2022@sina.com,"Abstract
Context:
Privacy policies document the privacy requirements guiding developers. Though privacy policies analysis has drawn increasing attention recently, how end users perceive privacy requirements has been less explored.
Objective:
We empirically explore the privacy requirements gap between developers and end users to derive beneficial insights into users’ privacy concerns to support maintenance.
Method:
We present a semi-automatic privacy requirements gap analysis framework based on text mining including information retrieval, 
topic modeling
, and 
computational linguistic
 techniques.
Results:
The preliminary results of applying our framework to Facebook show that: (1) topic comparison reveals that both privacy related reviews and policy statements involve privacy requirements types of collection, usage, and disclosure as well as account security. The retention requirements are almost not mentioned in reviews as they are hard to be directly perceived; (2) content comparisons reveal that though overlapping with the privacy policy statements, reviews are more general, informal, and negative in wording.
Conclusion:
The illustrative example with Facebook demonstrates the potential usage of our framework in informing software maintenance, e.g., privacy relevant testing and privacy 
policy refinement
.",Information and Software Technology,18 Mar 2025,5.0,The privacy requirements gap analysis framework is relevant for developers but may have limited direct impact on early-stage ventures in Europe compared to the other abstracts.
https://www.sciencedirect.com/science/article/pii/S0950584922002002,COSMOS: A comprehensive framework for automatically generating domain-oriented test suite,February 2023,Not Found,Akram=Kalaee: Not Found; Saeed=Parsa: prasa@iust.ac.ir; Negar=Fathi: Not Found,"Abstract
Context
Coverage criteria are satisfied by at least one examination of the test target, while many faults are not revealed by one execution. However, despite executing the faulty statement, the test result is correct in certain circumstances. Such coincidentally passing test cases execute the faulty statement but do not cause failures.
Objective
This paper introduces the new concept of domain solver. Domain solvers attempt to detect the domain of inputs rather than a single input satisfying a path constraint. Domain coverage is a new metric to evaluate the relative accuracy of the detected domains. The promising point is that the proposed approach similarly treats nonlinear and 
linear constraints
.
Method
Domain solver splits a path constraint into conjunctions of simple conditions comparing two expressions. Such a splitting simplifies the constraint-solving task to detect regions of the input space satisfying a comparison between two expressions. After finding a region, an improved version of an algorithm, update, is used to determine the domain of variables involved in the comparing expressions.
Results
Our proposed approach, COSMOS, is implemented using the Roslyn compiler. We compared COSMOS with well-known 
constraint solvers
 using various linear/nonlinear constraints. The results show that COSMOS improves the number of supported 
data types
 involved in a constraint and solves100% of the instances in which the other solvers fail. Besides, COSMOS achieves the best relative accuracy of 84% compared to the existing domain-oriented test suite generation approaches. Moreover, our experiment results illustrate that COSMOS improves the fault-finding capability of other existing test coverage criteria by detecting coincidentally correct test cases.
Conclusion
Combining domain coverage and compiler as a service makes a powerful 
constraint satisfaction
 method outperforming the existing 
constraint solvers
 regarding the number of solved linear/nonlinear constraints. Augmenting other structural test coverage criteria with domain coverage reveals the coincidentally correct test cases.",Information and Software Technology,18 Mar 2025,8.0,The proposed approach of COSMOS shows significant improvement in solving linear/nonlinear constraints compared to existing solvers. This can have a practical impact on early-stage ventures dealing with constraint-based problems.
https://www.sciencedirect.com/science/article/pii/S0950584922002099,A property specification pattern catalog for real-time system verification with UPPAAL,February 2023,Not Found,Thomas=Vogel: thomas.vogel@informatik.hu-berlin.de; Marc=Carwehl: carwehl@informatik.hu-berlin.de; Genaína Nunes=Rodrigues: Not Found; Lars=Grunske: Not Found,"Abstract
Context:
The goal of specification pattern catalogs for real-time requirements is to mask the complexity of specifying such requirements in a timed temporal logic for verification. For this purpose, they provide frontends to express and translate pattern-based natural language requirements to formulae in a suitable logic. However, the widely used real-time model checking tool UPPAAL only supports a restricted subset of those formulae that focus only on basic and non-nested reachability, safety, and 
liveness properties
. This restriction renders many specification patterns inapplicable. As a workaround, timed observer 
automata
 need to be constructed manually to express sophisticated requirements envisioned by these patterns.
Objective:
In this work, we fill these gaps by providing a comprehensive specification pattern catalog for UPPAAL. The catalog supports qualitative and real-time requirements and covers all corresponding patterns of existing catalogs.
Method:
The catalog we propose is integrated with UPPAAL. It supports the specification of qualitative and real-time requirements using patterns and provides an automated generator that translates these requirements to observer 
automata
 and TCTL formulae. The resulting artifacts are used for verifying systems modeled as 
timed automata
 in UPPAAL. Thus, our catalog enables an automated end-to-end 
verification process
 for UPPAAL based on property specification patterns and observer automata.
Results:
We evaluate our catalog on three UPPAAL system models reported in the literature and mostly applied in an industrial setting. As a result, not only the reproducibility of the related UPPAAL models was possible, but also the validation of an automated, seamless, and accurate pattern- and observer-based 
verification process
.
Conclusion:
The proposed property specification pattern catalog for UPPAAL enables practitioners to specify qualitative and real-time requirements in a pattern-based way – without directly using a temporal logic – and to verify them in UPPAAL while supporting a comprehensive set of patterns.",Information and Software Technology,18 Mar 2025,9.0,The catalog for UPPAAL fills a significant gap in supporting a comprehensive set of qualitative and real-time requirements. This can be highly beneficial for startups working on system verification and validation.
https://www.sciencedirect.com/science/article/pii/S0950584922002105,Assessing attitudes towards evidence-based software engineering in a government agency,February 2023,Not Found,Sebastián=Pizard: spizard@fing.edu.uy; Fernando=Acerenza: Not Found; Diego=Vallespir: Not Found; Barbara=Kitchenham: Not Found,"Abstract
Context:
Evidence-based practice (EBP) has allowed several disciplines to become more mature by emphasizing the use of evidence from well-designed and well-conducted research in decision-making. Its application in 
SE
, Evidence-based software engineering (EBSE) can help to bridge the gap between academia and 
industry
 by bringing together academic rigor and research of practical relevance. To achieve this, it seems necessary to improve its adoption.
Objective:
We sought both to study the attitudes towards EBSE of stakeholders working in a government agency (GA) and to assess whether knowledge of EBSE would impact their working practices.
Method:
We conducted a multi-stage field investigation in an Uruguayan national GA that is responsible for digital policies. First, we organized an EBSE awareness lecture and we collected and analyzed participants’ perceptions of the value and limitations of EBSE. Sixteen months later, in a second stage, we contacted the agency and asked participants whether they had made use of the information about EBSE we presented to them.
Results:
Initially, participants reported that EBSE seemed useful for tackling challenging problems and, in particular, considered its use appropriate given the agency’s responsibilities. Perceived barriers to EBSE adoption were the need for institutional support, the lack of government practice reports, inadequate skills or motivation, the cost of conducting 
systematic reviews
, and the lack of evidence about emerging issues. In the follow-up survey, although the participants were not undertaking 
systematic reviews
 themselves, many reported improvements in how they searched for and evaluated information to support their work.
Conclusion:
Our study presents some insights to better understand EBSE adoption. With the exception of GA-specific issues, perceived value and barriers to adoption were consistent with those reported in software engineering and other disciplines. Our follow-up study confirms the potential value of evidence in the context of IT regulatory and government bodies.",Information and Software Technology,18 Mar 2025,7.0,"Studying the attitudes towards EBSE and its impact on working practices provides valuable insights, but the direct practical implications for startups may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922002129,Crowdtesting Practices and Models: An Empirical Approach,February 2023,Not Found,Li=Zhang: laridzhang@gmail.com; Shufeng=Hu: hushufeng@msn.com; Zizheng=Fan: 1027174871@qq.com; Qianyu=Wang: by2006163@buaa.edu.cn,"Abstract
Context
Crowdsourced software testing (CST) has received significant attention. After these years, CST has made new progress and changes.
Objective
While current literature lists many CST challenges, this paper analyzes industrial CST practices, finds that many challenges already have practical solutions, summarizes their commonalities, and comes up with new CST models and processes.
Method
We look for well-known CST websites to participate in and take a secret and unobtrusive approach where customers, platform managers, and fellow workers do not know that we are mainly interested in CST research. We then register at selected CST websites, collect any public documents such as whitepapers, open rules, and public training materials, and join as many test tasks as possible.
Results
We analyze the confrontation and collaboration among clients, platforms, and workers in the CST sessions. Clients want to get as much bug information as possible for a small amount of pay, but workers want to get paid as much as possible for a small amount of bug information. We also study the process and method of selecting suitable CST workers. Based on these, this paper proposes three future research directions.
Conclusion
Data security and privacy at CST are paramount. If this problem can be overcome, CST will have wider applications. Additionally, the integration of workers, internal workers, software automation, and 
artificial intelligence
 will be major drivers for CST. It is also critical to develop a standardized CST structure and processes, and this will push the field to grow significantly.",Information and Software Technology,18 Mar 2025,6.0,"While the analysis of CST practices and future research directions are interesting, the direct application and impact on European early-stage ventures may not be as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001938,Visualizations for the evolution of Variant-Rich Systems: A systematic mapping study,February 2023,"Variant-rich systems, Software product lines, Visualization, Evolution, Maintenance, Mapping study",Raul=Medeiros: raul.medeiros@ehu.eus; Jabier=Martinez: jabier.martinez@tecnalia.com; Oscar=Díaz: oscar.diaz@ehu.eus; Jean-Rémy=Falleri: falleri@labri.fr,"Abstract
Context:
Variant-Rich Systems (VRSs), such as Software Product Lines or variants created through clone & own, aim at reusing existing assets. The long lifespan of families of variants, and the scale of both the code base and the workforce make VRS maintenance and evolution a challenge. Visualization tools are a needed companion.
Objective:
We aim at mapping the current state of visualization interventions in the area of VRS evolution. We tackle evolution in both functionality and architecture. Three research questions are posed: What sort of analysis is being conducted to assess VRS evolution? (Analysis perspective); What sort of visualizations are displayed? (Visualization perspective); What is the research maturity of the reported interventions? (Maturity perspective).
Methods:
We performed a 
systematic mapping study
 including automated search in digital libraries, expert knowledge, and snowballing.
Results:
The study reports on 41 visualization approaches to cope with VRS evolution. Analysis wise, feature identification and location is the most popular scenario, followed by variant integration towards a Software Product Line. As for visualization, nodelink diagram visualization is predominant while researchers have come up with a wealth of ingenious visualization approaches. Finally, maturity wise, almost half of the studies are solution proposals. Most of the studies provide proof-of-concept, some of them also include publicly available tools, yet very few 
face
 proof-of-value.
Conclusions:
This study introduces a comparison framework where to frame future studies. It also points out distinct research gaps worth investigating as well as shortcomings in the evidence about relevance and contextual considerations (e.g., scalability).",Information and Software Technology,18 Mar 2025,7.0,"The study on visualization interventions in VRS evolution offers valuable insights, but the immediate practical value for startups may be more long-term compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001987,CADV: A software visualization approach for code annotations distribution,February 2023,Not Found,Phyllipe=Lima: phyllipe@unifei.edu.br; Jorge=Melegati: jorge@jmelegati.com; Everaldo=Gomes: everaldogjr@gmail.com; Nathalya Stefhany=Pereira: nathalya.stefhany@gec.inatel.br; Eduardo=Guerra: eduardo.guerra@unibz.it; Paulo=Meirelles: paulo.meirelles@ufabc.edu.br,"Abstract
Context:
Code annotations
 is a widely used feature in Java systems to configure custom metadata on programming elements. Their increasing presence creates the need for approaches to assess and comprehend their usage and distribution. In this context, software visualization has been studied and researched to improve 
program comprehension
 in different aspects.
Objectives:
This study aimed at designing a software visualization approach that graphically displays how code annotations are distributed and organized in a software system and developing a tool, as a reference implementation of the approach, to generate views and interact with users.
Methods:
We conducted an empirical evaluation through questionnaires and interviews to evaluate our visualization approach considering four aspects: (i) effectiveness for 
program comprehension
, (ii) perceived usefulness, (iv) perceived ease of use, and (iv) suitability for the intended audience. The resulting data was used to perform a qualitative and quantitative analysis.
Results:
The tool identifies package responsibilities providing visual information about their annotations at different levels. Using the developed tool, the participants achieved a high correctness rate in the program comprehension tasks and performed very well in questions about the overview of the system under analysis. Finally, participants perceived that the tool is suitable to visualize the distribution of code annotations.
Conclusions:
The results show that the visualization approach using the developed tool is effective in program comprehension tasks related to code annotations, which can also be used to identify responsibilities in the application packages. Moreover, it was evaluated as suitable for newcomers to overview the usage of annotations in the system and for architects to perform a deep analysis that can potentially detect misplaced annotations and abnormal growths on their usage.",Information and Software Technology,18 Mar 2025,8.0,"The visualization approach and tool developed have practical value for improving program comprehension and identifying code annotations, which can benefit early-stage ventures in software development."
https://www.sciencedirect.com/science/article/pii/S0950584922001951,Increasing the UX maturity level of clients: A study of best practices in an agile environment,February 2023,"Client-UX relationship, Case study, UX maturity, Agile UX, UX practitioners, UX strategy, Best practices","Elaine, E.G.=Buis: elainebuis@gmail.com; Simone, S.R.=Ashby: Not Found; Kristel, K.P.A.=Kouwenberg: Not Found","Abstract
Context
While multiple studies have attempted to define and measure 
User Experience
 (UX) Maturity — i.e., how familiar organizations are with UX concepts or strategies— more practice-based insight is needed to examine how UX practitioners maneuver in their relationships with low UX Maturity organizations and help these clients become more ‘UX Mature’.
Objective
This study evaluates how UX practitioners work with low UX Maturity clients, what obstacles they face, and how they cope with these obstacles. From these insights, a set of best practices are identified for UX practitioners who work with low UX Maturity clients and wish to increase their clients’ UX maturity in an agile environment.
Method
These best practices were collected in the form of 
case studies
, involving a total of 20 case studies based on interviews with 22 UX practitioners. The case studies reflect on past projects that were conducted for clients with a low UX Maturity level. Data was obtained through semi-structured interviews and analyzed using a grounded theory approach combined with elements of a thematic analysis.
Results
The results help to identify frequently experienced obstacles in working with low UX Maturity organizations, as well as six best practices for increasing the UX Maturity of these clients.
Conclusions
The study results demonstrate that UX practitioners indeed fulfill a significant role in overcoming organizational UX boundaries. A Low UX Maturity Best Practice model was developed, which summarizes how UX practitioners can optimize their impact in working with low UX Maturity clients, while simultaneously contributing to a more user-centered focus on the part of their clients.",Information and Software Technology,18 Mar 2025,10.0,"The study provides insights and best practices for UX practitioners working with low UX Maturity clients, which can have a significant impact on early-stage ventures focusing on user experience and product development."
https://www.sciencedirect.com/science/article/pii/S0950584922001951,Increasing the UX maturity level of clients: A study of best practices in an agile environment,February 2023,"Client-UX relationship, Case study, UX maturity, Agile UX, UX practitioners, UX strategy, Best practices","Elaine, E.G.=Buis: elainebuis@gmail.com; Simone, S.R.=Ashby: Not Found; Kristel, K.P.A.=Kouwenberg: Not Found","Abstract
Context
While multiple studies have attempted to define and measure 
User Experience
 (UX) Maturity — i.e., how familiar organizations are with UX concepts or strategies— more practice-based insight is needed to examine how UX practitioners maneuver in their relationships with low UX Maturity organizations and help these clients become more ‘UX Mature’.
Objective
This study evaluates how UX practitioners work with low UX Maturity clients, what obstacles they face, and how they cope with these obstacles. From these insights, a set of best practices are identified for UX practitioners who work with low UX Maturity clients and wish to increase their clients’ UX maturity in an agile environment.
Method
These best practices were collected in the form of 
case studies
, involving a total of 20 case studies based on interviews with 22 UX practitioners. The case studies reflect on past projects that were conducted for clients with a low UX Maturity level. Data was obtained through semi-structured interviews and analyzed using a grounded theory approach combined with elements of a thematic analysis.
Results
The results help to identify frequently experienced obstacles in working with low UX Maturity organizations, as well as six best practices for increasing the UX Maturity of these clients.
Conclusions
The study results demonstrate that UX practitioners indeed fulfill a significant role in overcoming organizational UX boundaries. A Low UX Maturity Best Practice model was developed, which summarizes how UX practitioners can optimize their impact in working with low UX Maturity clients, while simultaneously contributing to a more user-centered focus on the part of their clients.",Information and Software Technology,18 Mar 2025,10.0,"Similar to Abstract 97, this study offers valuable best practices for UX practitioners dealing with low UX Maturity clients, contributing to enhancing user-centered focus in organizations, which is crucial for startups."
https://www.sciencedirect.com/science/article/pii/S0950584922001963,Service Design Handover to user experience design – a systematic literature review,February 2023,"Knowledge transfer, Service Design Handover, Systematic literature review, UX design, Agile UX, Design process",Aarne=Leinonen: aarne.leinonen@aalto.fi; Virpi=Roto: virpi.roto@aalto.fi,"Abstract
Context:
Knowledge transfer plays an important role in digital Service Creation Projects where information should flow through service design, Agile UX, and software implementation phases. One context for these 
handovers
 exists in projects where the service designers participate in the early phases of exploring and scoping the service, while agile 
user experience
 specialists take over the digital parts of service design and programmers the software implementation.
Objective:
The purpose of this study is to summarise 
scientific knowledge
 into best practices for effective information flow in real world Service Creation Projects. 
Special attention
 is paid on an important and understudied project phase, knowledge handover from service design to software implementation, which is referred as Service Design Handover in this study.
Method:
A 
systematic literature review
 was conducted to analyse the current scientific knowledge on knowledge transfer in digital Service Creation Projects. PRISMA 2020 statement was used for reporting the review, which also influenced planning and execution of the systematic review process. SCOPUS search brought up 773 publications, and the full content analysis was done for the 41 most relevant publications.
Results:
Based on the literature analysis, the best practices for effective knowledge transfer are related to communication quality and quantity, circumventing the need for communication, and verifying successful communication. To provide an overview of effective knowledge transfer, frameworks of Service Creation Project information flow and Service Design Handover are proposed.
Conclusion:
The existing knowledge transfer literature is voluminous, but this literature review is the first to study knowledge transfer in Service Creation Project context. The framework, best practices, and list of potential problem sources in knowledge transfer provide new knowledge for managing the information flow in service creation. The research gaps found in this literature review show the need for future research, such as empirical studies on service creation practice.",Information and Software Technology,18 Mar 2025,7.0,"The best practices identified for effective knowledge transfer in Service Creation Projects can benefit early-stage ventures, especially startups involved in digital service design and implementation."
https://www.sciencedirect.com/science/article/pii/S0950584922002166,"Does maturity level influence the use of Agile UX methods by digital startups? Evaluating design thinking, lean startup, and lean user experience",February 2023,Not Found,Fernando Henrique=Lermen: fernando-lermen@hotmail.com; Paula Kvitko=de Moura: Not Found; Vanessa Becker=Bertoni: Not Found; Paola=Graciano: Not Found; Guilherme Luz=Tortorella: Not Found,"Abstract
Context
Agile UX methods such as Design Thinking, 
Lean Startup
, and Lean 
User Experience
 have been employed to deliver customer value and improve organizational performance. However, there is a lack of studies that assess how these tools are used at different stages of maturity of digital startups.
Objective
The present study aims to compare the knowledge of graduated, incubated, and pre-incubated digital startups at university 
incubators
 concerning the use of Agile UX methods so that weaknesses and opportunities can be identified to provide co founders and scholars with new strategic insights.
Method
Six reduced focus groups were conducted with 14 members of the six selected startups via multiple 
case studies
. Answers were registered by researchers and then analyzed using an inductive process and codification.
Results
The results indicated that digital startups had contact with consumers through market research, viability analysis, and product discontinuity. However, except for one startup, deficiencies in co-founders' participation throughout developing products and services projects were identified. As far as the multiple 
case studies
 are concerned, Design Thinking and 
Lean Startup
 were employed by four of the startups, while two of them used the Lean 
User Experience
 method due to its higher maturity level.
Conclusion
Although all Agile UX methods were employed, all six digital startups reported having made adaptations to the methods or to have used them only partially. Finally, it was concluded that the maturity level influences the Agile UX methods of each digital startup according to its nature and its stage of development in the market.",Information and Software Technology,18 Mar 2025,9.0,"By comparing Agile UX methods knowledge among different stages of digital startups, this study provides strategic insights that can be valuable for early-stage ventures in improving customer value delivery and organizational performance."
https://www.sciencedirect.com/science/article/pii/S0950584922001872,Community smells—The sources of social debt: A systematic literature review,January 2023,Not Found,Eduardo=Caballero-Espinosa: eduardo.caballero@utp.ac.pa; Jeffrey C.=Carver: carver@cs.ua.edu; Kimberly=Stowers: kim.stwrs@gmail.com,"Abstract
Context:
Social debt describes the accumulation of unforeseen project costs (or potential costs) from sub-optimal software 
development processes
. Community smells are sociotechnical anti-patterns and one source of social debt. Because community smells impact software teams, 
development processes
, outcomes, and organizations, we to understand their impact on 
software engineering
.
Objective:
To provide an overview of community smells in social debt, based on published literature, and describe future research.
Method:
We conducted a systematic literature review (SLR) to identify properties, understand origins and evolution, and describe the emergence of community smells. This SLR explains the impact of community smells on teamwork and team performance.
Results:
We include 25 studies. Social debt describes the impacts of poor socio-technical decisions on work environments, people, software products, and society. For each of the 30 community smells identified as sources of social debt, we provide a detailed description, management approaches, organizational strategies, and mitigation effectiveness. We identify five groups of management approaches: organizational strategies, frameworks, models, tools, and guidelines. We describe 11 common properties of community smells. We develop the 
Community Smell Stages Framework
 to concisely describe the origin and evolution of community smells. We then describe the causes and effects for each community smell. We identify and describe 8 types of causes and 11 types of effects related to the community smells. Finally, we provide 8 comprehensive Sankey diagrams that offer insights into threats the community smells pose to teamwork factors and team performance.
Conclusion:
Community smells explain the influence work conditions have on software developers. The literature is scarce and focuses on a small number of community smells. Thus, the community smells still need more research. This review helps by organizing the state of the art about community smells. Our contributions provide motivations for future research and provide educational material for 
software engineering
 professionals.",Information and Software Technology,18 Mar 2025,7.0,"The abstract provides comprehensive insights into community smells in social debt and offers management approaches, strategies, and frameworks. This can be valuable for early-stage ventures to optimize their software development processes."
https://www.sciencedirect.com/science/article/pii/S0950584922001872,Community smells—The sources of social debt: A systematic literature review,January 2023,Not Found,Eduardo=Caballero-Espinosa: eduardo.caballero@utp.ac.pa; Jeffrey C.=Carver: carver@cs.ua.edu; Kimberly=Stowers: kim.stwrs@gmail.com,"Abstract
Context:
Social debt describes the accumulation of unforeseen project costs (or potential costs) from sub-optimal software 
development processes
. Community smells are sociotechnical anti-patterns and one source of social debt. Because community smells impact software teams, 
development processes
, outcomes, and organizations, we to understand their impact on 
software engineering
.
Objective:
To provide an overview of community smells in social debt, based on published literature, and describe future research.
Method:
We conducted a systematic literature review (SLR) to identify properties, understand origins and evolution, and describe the emergence of community smells. This SLR explains the impact of community smells on teamwork and team performance.
Results:
We include 25 studies. Social debt describes the impacts of poor socio-technical decisions on work environments, people, software products, and society. For each of the 30 community smells identified as sources of social debt, we provide a detailed description, management approaches, organizational strategies, and mitigation effectiveness. We identify five groups of management approaches: organizational strategies, frameworks, models, tools, and guidelines. We describe 11 common properties of community smells. We develop the 
Community Smell Stages Framework
 to concisely describe the origin and evolution of community smells. We then describe the causes and effects for each community smell. We identify and describe 8 types of causes and 11 types of effects related to the community smells. Finally, we provide 8 comprehensive Sankey diagrams that offer insights into threats the community smells pose to teamwork factors and team performance.
Conclusion:
Community smells explain the influence work conditions have on software developers. The literature is scarce and focuses on a small number of community smells. Thus, the community smells still need more research. This review helps by organizing the state of the art about community smells. Our contributions provide motivations for future research and provide educational material for 
software engineering
 professionals.",Information and Software Technology,18 Mar 2025,7.0,"Similar to abstract 101, this abstract also delves into community smells in social debt and offers management approaches. The research findings can be beneficial for startups looking to enhance their software development practices."
https://www.sciencedirect.com/science/article/pii/S0950584922001574,Constrained detecting arrays: Mathematical structures for fault identification in combinatorial interaction testing,January 2023,"Combinatorial interaction testing, Detecting arrays, Constraint handling, Fault identification",Hao=Jin: k-kou@ist.osaka-u.ac.jp; Ce=Shi: shice060@lixin.edu.cn; Tatsuhiro=Tsuchiya: t-tutiya@ist.osaka-u.ac.jp,"Abstract
Context:
Detecting arrays are mathematical structures aimed at fault identification in combinatorial interaction testing. However, they cannot be directly applied to systems that have constraints on the test parameters. These constraints are prevalent in real-world systems.
Objective:
This paper proposes constrained detecting arrays (CDAs), an extension of detecting arrays, which can be used for systems with constraints.
Methods:
The properties and capabilities of CDAs are examined with rigorous arguments. Moreover, two algorithms are proposed for constructing CDAs: one is aimed at generating minimum CDAs, and the other is a heuristic algorithm aimed at fast generation of CDAs. The algorithms were experimentally evaluated using a benchmark dataset.
Results:
Experimental results show that the first algorithm can generate minimum CDAs if a sufficiently long generation time is allowed, and the second algorithm can generate minimum or near-minimum CDAs in a reasonable time.
Conclusion:
CDAs extend the range of application of detecting arrays to systems with constraints. The two proposed algorithms have different advantages with respect to array size and generation time.",Information and Software Technology,18 Mar 2025,5.0,"The abstract introduces constrained detecting arrays as an extension of detecting arrays, which can be useful for systems with constraints. While the topic is relevant, the direct impact on European early-stage ventures might be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922001574,Constrained detecting arrays: Mathematical structures for fault identification in combinatorial interaction testing,January 2023,"Combinatorial interaction testing, Detecting arrays, Constraint handling, Fault identification",Hao=Jin: k-kou@ist.osaka-u.ac.jp; Ce=Shi: shice060@lixin.edu.cn; Tatsuhiro=Tsuchiya: t-tutiya@ist.osaka-u.ac.jp,"Abstract
Context:
Detecting arrays are mathematical structures aimed at fault identification in combinatorial interaction testing. However, they cannot be directly applied to systems that have constraints on the test parameters. These constraints are prevalent in real-world systems.
Objective:
This paper proposes constrained detecting arrays (CDAs), an extension of detecting arrays, which can be used for systems with constraints.
Methods:
The properties and capabilities of CDAs are examined with rigorous arguments. Moreover, two algorithms are proposed for constructing CDAs: one is aimed at generating minimum CDAs, and the other is a heuristic algorithm aimed at fast generation of CDAs. The algorithms were experimentally evaluated using a benchmark dataset.
Results:
Experimental results show that the first algorithm can generate minimum CDAs if a sufficiently long generation time is allowed, and the second algorithm can generate minimum or near-minimum CDAs in a reasonable time.
Conclusion:
CDAs extend the range of application of detecting arrays to systems with constraints. The two proposed algorithms have different advantages with respect to array size and generation time.",Information and Software Technology,18 Mar 2025,5.0,"Similar to abstract 103, this abstract discusses constrained detecting arrays. While the concept is interesting, its practical applicability to early-stage ventures in Europe might be somewhat restricted."
https://www.sciencedirect.com/science/article/pii/S0950584922001756,Memorization and generalization in neural code intelligence models,January 2023,Not Found,Md Rafiqul Islam=Rabin: mrabin@uh.edu; Aftab=Hussain: Not Found; Mohammad Amin=Alipour: Not Found; Vincent J.=Hellendoorn: Not Found,"Abstract
Context:
Deep Neural Networks
 (DNNs) are increasingly being used in 
software engineering
 and code intelligence tasks. These are powerful tools that are capable of learning highly 
generalizable
 patterns from large datasets through millions of parameters. At the same time, their large capacity can render them prone to 
memorizing
 data points. Recent work suggests that the memorization risk manifests especially strongly when the training dataset is noisy, involving many ambiguous or questionable samples, and memorization is the only recourse.
Objective:
The goal of this paper is to evaluate and compare the extent of memorization and generalization in neural code intelligence models. It aims to provide insights on how memorization may impact the learning behavior of 
neural models
 in code intelligence systems.
Method:
To observe the extent of memorization in models, we add random noise to the original training dataset and use various metrics to quantify the impact of noise on various aspects of training and testing. We evaluate several state-of-the-art neural code intelligence models and benchmarks based on Java, Python, and Ruby codebases.
Results:
Our results highlight important risks: millions of trainable parameters allow the 
neural networks
 to memorize 
anything
, including noisy data, and provide a false sense of generalization. We observed all models manifest some forms of memorization. This can be potentially troublesome in most code intelligence tasks where they rely on rather noise-prone and repetitive 
data sources
, such as code from GitHub.
Conclusion:
To the best of our knowledge, we provide the first study to quantify memorization effects in the domain of 
software engineering
 and code intelligence systems. This work raises awareness and provides new insights into important issues of training 
neural models
 in code intelligence systems that are usually overlooked by software engineering researchers.",Information and Software Technology,18 Mar 2025,8.0,"The abstract provides insights into the memorization effects in neural code intelligence models, which can be crucial for startups utilizing deep neural networks in software engineering tasks. The findings can help startups optimize their model training processes."
https://www.sciencedirect.com/science/article/pii/S0950584922001768,Exploring the challenges in software testing of the 5G system at Nokia: A survey,January 2023,"0000, 1111",Szymon=Stradowski: Not Found; Lech=Madeyski: lech.madeyski@pwr.edu.pl,"Abstract
Context:
The ever-growing size and complexity of industrial software products pose significant quality assurance challenges to engineering researchers and practitioners, despite the constant effort to increase knowledge and improve the processes. 5G technology developed by Nokia is one example of such a grand and highly complex system with improvement potential.
Objective:
The following paper provides an overview of the current quality assurance processes used by Nokia to develop the 5G technology and provides insight into the most prominent challenges by an evaluation of perceived importance, urgency, and difficulty to understand the future opportunities.
Method:
Nokia mode of operation, briefly introduced in this paper, has been subjected to extensive analysis by a selected group of experienced test-oriented professionals to define the most critical areas of concern. Secondly, the identified problems were evaluated by Nokia gNB system-level test professionals in a dedicated survey.
Results:
The questionnaire was completed by 312 out of 2935 (10.63%) possible respondents. The challenges are seen as the most important and urgent: customer scenario testing, performance testing, and competence ramp-up. Challenges seen as the most difficult to solve are low occurrence failures, hidden feature dependencies, and hardware configuration-specific problems.
Conclusions:
Our research identified several improvement areas in the quality assurance processes used to develop the 5G technology by determining the most important and urgent problems that at the same time have a low perceived difficulty. Such initiatives are attractive from a business perspective. On the other hand, challenges seen as the most impactful yet difficult may be of interest to the academic research community.",Information and Software Technology,18 Mar 2025,7.0,"The research provides valuable insights into quality assurance processes for developing 5G technology by Nokia, highlighting important challenges and improvement areas. This can have a practical impact on early-stage ventures in the tech industry."
https://www.sciencedirect.com/science/article/pii/S0950584922001744,Machine translation-based fine-grained comments generation for solidity smart contracts,January 2023,Not Found,Chaochen=Shi: shicha@deakin.edu.au; Yong=Xiang: yong.xiang@deakin.edu.au; Jiangshan=Yu: jiangshan.yu@monash.edu; Keshav=Sood: keshav.sood@deakin.edu.au; Longxiang=Gao: Not Found,"Abstract
Context.
As self-executing programs on 
blockchain
 platforms, 
smart contracts
 can build a trusted environment between multi-parties. However, participants who lack programming knowledge usually have difficulties understanding 
smart contracts
 by reading the 
source code
. It brings them difficulties and risks when interacting with decentralized applications.
Objective.
We aim to translate the smart contract 
source code
 into natural language descriptions as fine-grained in-line comments to help people better understand, learn and operate smart contracts.
Method.
We propose an automated translation approach for smart contracts written in Solidity, termed SolcTrans, based on an Syntax Tree (AST) and formal grammar. We have investigated representative Solidity smart contracts, identified the AST 
parsing
 paths and core attributes used for translation, and proposed corresponding translation templates for special statements. Then, we leveraged 
reinforcement learning
 to train a Probabilistic Context-Free Grammar-based syntax synthesizer used to generate comprehensible English sentences as comments.
Result.
The experimental results show that SolcTrans outperforms four state-of-the-art neural machine 
translation models
 under currently available 
training data
 and is less affected by lengths of code snippets and translation outputs. We also conducted a human evaluation among 20 volunteers and asked them to score the generated comments. The results demonstrate that SolcTrans performs well on three metrics: Accuracy, Readability, and Instructiveness.
Conclusion.
Our approach produces high-quality fine-grained comments for smart contract source code under the small training dataset, which creates a paradigm for future studies.",Information and Software Technology,18 Mar 2025,9.0,The approach of translating smart contract source code into natural language descriptions can greatly benefit participants without programming knowledge. This innovation has the potential to improve accessibility and reduce risks for startups in the blockchain industry.
https://www.sciencedirect.com/science/article/pii/S095058492200177X,Integrating DSGEO into test case generation for path coverage of MPI programs,January 2023,Not Found,Baicai=Sun: Not Found; Dunwei=Gong: dwgong@vip.163.com; Xiangjuan=Yao: yaoxj@cumt.edu.cn,"Abstract
Context:
When testing a 
M
essage-
P
assing 
I
nterface (MPI) program composed of multiple processes, the testing cost for each process is different, and those expensive processes restrict the testing efficiency of the entire MPI program.
Objective:
To overcome this limitation, this paper proposes an approach to integrating 
d
istributed-
s
urrogate-
g
uided 
e
volutionary 
o
ptimization (DSGEO) into test case generation for path coverage of MPI programs.
Method:
In the proposed approach, we first determine each expensive process and its input variables, and generate a sample set for the determined process, which is used to train a 
surrogate model
. Then, the fitness components of a test case in those expensive processes are estimated by the corresponding surrogate models, and are then combined with the real fitness components of the test case in cheap processes to form the fitness estimation. Finally, we select a small number of test cases with good fitness estimations to execute the MPI program, and calculate their real fitness to guide the subsequent test case generation.
Results:
We use the proposed approach to seven benchmark MPI programs and compare with four state-of-the-art approaches. The experimental results show that the proposed approach can significantly decrease the cost for test case generation.
Conclusion:
The proposed approach is also applicable to more complex MPI programs, thus supporting the scalability of the proposed approach.",Information and Software Technology,18 Mar 2025,8.0,"The proposed approach for test case generation in MPI programs shows a significant decrease in testing costs, which can be beneficial for startups working on distributed systems. The scalability of the approach adds to its practical value."
https://www.sciencedirect.com/science/article/pii/S0950584922001884,Mastering scrum with a focus on team maturity and key components of scrum,January 2023,"Agile software development, Scrum teams, team performance, maturity, success",Maja Due=Kadenic: Maja@btech.au.dk; Konstantinos=Koumaditis: Not Found; Louis=Junker-Jensen: Not Found,"Abstract
Context
Several studies contribute with valuable insights into agile teamwork performance. Currently, Scrum is dominating the industrial 
agile software development
 practices. Yet, there is a lack of studies that directly explores the role of team maturity and key components of the Scrum framework on being successful at Scrum.
Objective
We investigate the impact of team maturity and four categories of the Scrum framework (team composition, Scrum values, Scrum roles, and Scrum events) on the perception of being successful at Scrum. Hence, we uncover and provide deeper insights into the characteristics and practices of what makes a team successful at Scrum.
Method
We carry out a large-scale and cross-sectional survey. We conduct 
Pearson's
 chi-square test of independence and 
logistic regression
 analysis for team maturity and the remaining variables on being successful.
Results
After surveying 182 Scrum team members, the results show that being successful at Scrum depends on the team maturity level. Team composition variables (fully allocated, low turnover rates, required skills and expertise, and self-management) and directing work in accordance with Scrum values (openness and courage) have an impact. All three Scrum roles are important. Particularly impactful are the developers’ ability to adapt their plans, the product owners’ mandate to prioritize, and the Scrum masters’ ability to ensure that all events take place. Following all Scrum events has an effect on the perception of being successful at Scrum.
Conclusion
This work constitutes a valuable contribution to agile practitioners and organizations who are already involved in 
agile development
 or plan to pursue agility. Organizations can influence Scrum teams’ journey towards becoming successful at Scrum by ensuring the stability required to allow team maturation and decision-making relevant to team composition variables. This work also provides reflections that are useful for Scrum teams’ practices and internal dynamics related to values, roles, and events.",Information and Software Technology,18 Mar 2025,6.0,"The study on agile teamwork performance and Scrum framework provides insights into team success factors, which can be beneficial for startups adopting agile practices. The focus on team maturity and key components of Scrum can offer guidance for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001914,Learning migration models for supporting incremental language migrations of software applications,January 2023,Not Found,Bruno Góis=Mateus: Not Found; Matias=Martinez: matias.martinez@uphf.fr; Christophe=Kolski: Not Found,"Abstract
Context:
A Legacy system can be defined as a system that significantly resists modification and evolution. According to the literature, there are two main strategies to migrate a legacy system: (a) to replace the legacy system by a new one, (b) to incrementally migrate parts from the legacy system to the new one. Incremental migration allows developers to better control the risks that may occur during the migration process. However, this strategy is more complex because it requires decomposition of the legacy system into different parts, e.g. a set of files, and to define the order of migration of them along the migration process. To our knowledge, there is no approach to support developers on those activities.
Objective:
This paper presents an approach, named MigrationExp, to support incremental language migrations of applications from one 
source
 language to another 
target
 language. MigrationExp recommends the files that should be migrated first in a particular migration iteration. As a novelty, our approach relies on a ranking model learned, using a 
learning-to-rank
 algorithm, from migrations made by developers.
Method:
We validate our approach in the context of the migrations of 
Android
 apps, from Java to Kotlin, a new 
official language
 for 
Android
. We train our model using migrations of Java code to Kotlin written by developers on open-source applications.
Results:
The results show that, on the task of proposing files to migrate, our approach outperforms a previous migration strategy proposed by Google, in terms of its ability to accurately predict empirically observed migration orders.
Conclusion:
Since most 
Android applications
 are written in Java, we conclude that approaches to support developers such as MigrationExp may significantly impact the development of 
Android applications
.",Information and Software Technology,18 Mar 2025,8.0,The approach presented for incremental language migrations of Android apps can have a significant impact on developers working on legacy systems. This can be particularly useful for startups looking to modernize their applications and improve their development processes.
https://www.sciencedirect.com/science/article/pii/S0950584922001926,FRL-MFPG: Propagation-aware fault root cause location for microservice intelligent operation and maintenance,January 2023,Not Found,Yuhua=Chen: Not Found; Dongqi=Xu: Not Found; Ningjiang=Chen: chnj@gxu.edu.cn; Xu=Wu: Not Found,"Abstract
Context:
Due to the continuous updates and complex dependencies of 
microservices
, the probability of a fault occurrence and the difficulty of doing a diagnosis have increased, making it hard for 
operation and maintenance
 staff to quickly and accurately troubleshoot a fault and locate its root cause.
Objective:
To fulfill the requirements of 
artificial intelligence
 for IT operations, called AIOps, this paper studies microservice fault root cause location technology from two aspects, microservice 
fault propagation
 relationships and fault root cause location.
Method:
First, this paper designs a microservice 
fault propagation
 
graph construction
 method MFPG-FC based on fault correlation. The method effectively depicts the propagation relationship and the scope of influence of microservice faults and improves the accuracy of locating a fault’s root cause. Second, in terms of fault root cause location, this paper proposes a microservice fault root cause location algorithm based on a microservice fault propagation relationship graph called FRL-MFPG. The FRL-MFPG algorithm is designed to improve the globalization, flexibility and accuracy of the 
fault location
 search range and rate. Finally, an AIOps-oriented microservice fault root cause location framework (AIOps-MFRL) is designed.
Results:
The experimental results show that, compared with the traditional method, the method proposed in this paper is more accurate and can locate the root cause of a fault more accurately. After detecting the fault of 
microservices
, it can achieve the goal of locating the root cause of the fault, which is helpful to improve the efficiency of intelligent 
operation and maintenance
.
Conclusion:
The method in this paper can effectively locate the root cause of a fault and identify the root cause indicators of the fault after the fault is detected in the microservice. It has better timeliness and accuracy, reduces troubleshooting time and the losses caused by faults, and improves operation and maintenance efficiency.",Information and Software Technology,18 Mar 2025,8.0,"The paper proposes a method to improve fault location in microservices, which can enhance the efficiency of operation and maintenance for startups dealing with microservices."
https://www.sciencedirect.com/science/article/pii/S0950584922001975,An optimized case-based software project effort estimation using genetic algorithm,January 2023,Not Found,Shaima=Hameed: Not Found; Yousef=Elsheikh: y_elsheikh@asu.edu.jo; Mohammad=Azzeh: Not Found,"Abstract
Software development companies have long suffered from inaccurate estimation of their software projects. This in turn led to huge losses, especially in the financial resources available for the project as well as the time required to complete it. As a result of this, the research community has developed different methods for estimating effort in software projects in the 
hope
 of achieving high levels of accuracy and efficiency in the use of available resources. Among those methods that have proven to be accurate in estimating the effort of software projects is the use of machine learning (ML) techniques, especially the case-based reasoning technique (CBR). This technique is based on adapting previously successful solutions for similar software projects. However, the CBR technique suffers from a problem which is its multiple parameters that are difficult to be tuned. This justifies the importance of the adaptation and adjustment process as an essential part of CBR to produce accurate and efficient results with least absolute 
estimation error
. In this paper, one of the most efficient multi-objective evolutionary techniques, the 
Genetic Algorithm
 (GA), are used to help find the best set of classical CBR parameters (feature selection, feature weighting, similarity measures, and 
k
 number of nearest neighbors) to produce the most accurate effort estimates for software projects. The proposed CBR-GA model showed the effectiveness of using the GA algorithm to search for the best combination of CBR parameters and thus improve its accuracy. This in turn is beneficial for project managers in the early financial planning phase for effort estimation and thus project cost control. To validate the proposed CBR-GA model, we used a set of public benchmark datasets available on PROMISE data repository, in addition we used a set of reliable 
evaluation metrics
. The obtained results are promising in terms of accuracy and 
significance tests
. This implies the importance of search-based techniques for tuning effort estimation methods.",Information and Software Technology,18 Mar 2025,7.0,"The research aims to improve effort estimation in software projects using machine learning techniques, which can be beneficial for startups in optimizing resource allocation."
https://www.sciencedirect.com/science/article/pii/S0950584922001902,A systematic literature review of the Design Critique method,January 2023,Not Found,Lorans=Alabood: lorans.alabood@ucalgary.ca; Zahra=Aminolroaya: zahra.aminolroaya@ucalgary.ca; Dianna=Yim: dyim@ucalgary.ca; Omar=Addam: okaddam@ucalgary.ca; Frank=Maurer: fmaurer@ucalgary.ca,"Abstract
Context:
The Design Critique (DC) method is becoming more common in Human–Computer Interaction (HCI) and 
User Experience
 (UX) studies as the need for new evaluation methods of emerging technologies is increasing. However, there is an clear lack of guidelines on how to conduct DC studies in the UX context.
Objective:
The goal of this paper is to provide an overview of the DC method in the fields of UX. In addition, this paper aims to propose a 
generic process
 of running DC studies in the same context.
Methods:
We present a systematic literature review of the DC method. Moreover, we conduct a course of thematic analysis on the selected papers to identify the various DC processes and explore the following attributes: participant categories, data collection methods, and data analysis methods in each process.
Results:
We identified three different trends of DC processes: detailed, moderate and minimal. In addition, we proposed a generic DC process consisting of 10 steps divided into three main phases: preparation, conducting design critique, and pro-processing. We found that domain experts represent the majority of studies participants. Using interviews to collect qualitative data and using script coding analysis are the two most common methods of collecting and analyzing data.
Conclusion:
Conducting DC studies can improve overall 
systems usability
 by addressing design flaws at an early stage of development. The process of conducting a DC varies, depending on the project goals and states. The DC method aligns well with the small light-weight steps approach in Agile methods.",Information and Software Technology,18 Mar 2025,9.0,"The paper provides a generic process for conducting Design Critique studies, which can help startups improve system usability at an early stage of development."
https://www.sciencedirect.com/science/article/pii/S0950584922001902,A systematic literature review of the Design Critique method,January 2023,Not Found,Lorans=Alabood: lorans.alabood@ucalgary.ca; Zahra=Aminolroaya: zahra.aminolroaya@ucalgary.ca; Dianna=Yim: dyim@ucalgary.ca; Omar=Addam: okaddam@ucalgary.ca; Frank=Maurer: fmaurer@ucalgary.ca,"Abstract
Context:
The Design Critique (DC) method is becoming more common in Human–Computer Interaction (HCI) and 
User Experience
 (UX) studies as the need for new evaluation methods of emerging technologies is increasing. However, there is an clear lack of guidelines on how to conduct DC studies in the UX context.
Objective:
The goal of this paper is to provide an overview of the DC method in the fields of UX. In addition, this paper aims to propose a 
generic process
 of running DC studies in the same context.
Methods:
We present a systematic literature review of the DC method. Moreover, we conduct a course of thematic analysis on the selected papers to identify the various DC processes and explore the following attributes: participant categories, data collection methods, and data analysis methods in each process.
Results:
We identified three different trends of DC processes: detailed, moderate and minimal. In addition, we proposed a generic DC process consisting of 10 steps divided into three main phases: preparation, conducting design critique, and pro-processing. We found that domain experts represent the majority of studies participants. Using interviews to collect qualitative data and using script coding analysis are the two most common methods of collecting and analyzing data.
Conclusion:
Conducting DC studies can improve overall 
systems usability
 by addressing design flaws at an early stage of development. The process of conducting a DC varies, depending on the project goals and states. The DC method aligns well with the small light-weight steps approach in Agile methods.",Information and Software Technology,18 Mar 2025,9.0,"The paper provides a generic process for conducting Design Critique studies, which can help startups improve system usability at an early stage of development."
https://www.sciencedirect.com/science/article/pii/S0950584922001732,CodeCity: A comparison of on-screen and virtual reality,January 2023,"CodeCity, City metaphor, Software visualization, Software evolution, Reverse engineering, Virtual reality, Web, 3D",David=Moreno-Lumbreras: d.morenolu@alumnos.urjc.es; Roberto=Minelli: Not Found; Andrea=Villaverde: Not Found; Jesus M.=Gonzalez-Barahona: Not Found; Michele=Lanza: Not Found,"Abstract
Context:
Over the past decades, researchers proposed numerous approaches to visualize source code. A popular one is 
CodeCity
, an interactive 3D software visualization representing software system as cities: buildings represent classes (or files) and districts represent packages (or folders). Building dimensions represent values of software metrics, such as number of methods or lines of code. There are many implementations of 
CodeCity
, the vast majority of them running on-screen. Recently, some implementations using virtual reality (VR) have appeared, but the usefulness of 
CodeCity
 in VR is still to be proven.
Aim:
Our comparative study aims to answer the question 
“Is VR well suited for 
CodeCity
, compared to the traditional on-screen implementation?”
Methods:
We performed two experiments with our web-based implementation of 
CodeCity
, which can be used on-screen or in 
immersive VR
. First, we conducted a controlled experiment involving 24 participants from academia and industry. Taking advantage of the obtained feedback, we improved our approach and conducted a second controlled experiment with 26 new participants.
Results:
Our results show that people using the VR version performed the assigned tasks in much less time, while maintaining a comparable level of correctness.
Conclusion:
VR is at least equally well-suited as on-screen for visualizing 
CodeCity
, and likely better.",Information and Software Technology,18 Mar 2025,7.0,"The comparative study on using VR for CodeCity visualization can be beneficial for startups exploring innovative ways of presenting source code, potentially improving their development processes."
https://www.sciencedirect.com/science/article/pii/S0950584922001720,A hybrid model for efficient decision-making in self-adaptive systems,January 2023,Not Found,Fatma=Kachi: fatma.kachi@univ-constantine2.dz; Chafia=Bouanaka: chafia.bouanaka@univ-constantine2.dz,"Abstract
Context:
Engineering self-adaptive systems to guarantee the required quality properties is challenging and particularly in presence of uncertainties. Such uncertainties may occur in a variety of situations, ranging from variations in the system’s operating environment to ambiguity while selecting the appropriate adaptation option. Formal methods provide a rigorous means to specify and verify the behaviour of self-adaptive systems. They are applied both during system design and at runtime to provide guarantees on the required properties of self-adaptive systems. However, existing approaches generally use exhaustive verification at runtime to pick adaptation options and achieve adaptation objectives, which is time and resource consuming.
Objective:
Aiming to tackle this shortcoming, we target a twofold objective. Firstly, we reduce the adaptation space, and then we predict the impact of each adaptation plan on the rest of system qualities, to assist the decision-making process in determining the most suitable adaptation plans and side effects.
Method:
An Adaptation-space Reducer component is added to the analyser element; it uses 
deep learning
 to reduce the adaptation space. Furthermore, the planner element has been extended with a Decision Impact Predictor component, which employs quantitative analysis to forecast the impact of a decision.
Results:
The DLA4EDM is defined as an approach for providing self-adaptive systems (SASs) with an efficient decision-making process. Our approach is applied on a self-adaptive 
Internet of Things
 application and the obtained results are compared to those of other approaches. Results show that the adaptation space is reduced by 97.57%, and the error rate in the decision-making is very low.
Conclusion:
Reducing the adaptation space and resolving uncertainties to be faced in the decision-making of self-adaptive systems contribute considerably to enhance the efficiency and quality of the adaptation process and hence ensure that the quality requirements are met. Evaluating the impact of the identified adaptation plans on the obtained guarantees ensures that the system is effectively operational.",Information and Software Technology,18 Mar 2025,8.0,"The proposed approach addresses a significant challenge in engineering self-adaptive systems, showcasing a substantial reduction in adaptation space and decision-making errors. The use of deep learning and quantitative analysis enhances the efficiency and quality of the adaptation process, with practical implications for startups in the early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001720,A hybrid model for efficient decision-making in self-adaptive systems,January 2023,Not Found,Fatma=Kachi: fatma.kachi@univ-constantine2.dz; Chafia=Bouanaka: chafia.bouanaka@univ-constantine2.dz,"Abstract
Context:
Engineering self-adaptive systems to guarantee the required quality properties is challenging and particularly in presence of uncertainties. Such uncertainties may occur in a variety of situations, ranging from variations in the system’s operating environment to ambiguity while selecting the appropriate adaptation option. Formal methods provide a rigorous means to specify and verify the behaviour of self-adaptive systems. They are applied both during system design and at runtime to provide guarantees on the required properties of self-adaptive systems. However, existing approaches generally use exhaustive verification at runtime to pick adaptation options and achieve adaptation objectives, which is time and resource consuming.
Objective:
Aiming to tackle this shortcoming, we target a twofold objective. Firstly, we reduce the adaptation space, and then we predict the impact of each adaptation plan on the rest of system qualities, to assist the decision-making process in determining the most suitable adaptation plans and side effects.
Method:
An Adaptation-space Reducer component is added to the analyser element; it uses 
deep learning
 to reduce the adaptation space. Furthermore, the planner element has been extended with a Decision Impact Predictor component, which employs quantitative analysis to forecast the impact of a decision.
Results:
The DLA4EDM is defined as an approach for providing self-adaptive systems (SASs) with an efficient decision-making process. Our approach is applied on a self-adaptive 
Internet of Things
 application and the obtained results are compared to those of other approaches. Results show that the adaptation space is reduced by 97.57%, and the error rate in the decision-making is very low.
Conclusion:
Reducing the adaptation space and resolving uncertainties to be faced in the decision-making of self-adaptive systems contribute considerably to enhance the efficiency and quality of the adaptation process and hence ensure that the quality requirements are met. Evaluating the impact of the identified adaptation plans on the obtained guarantees ensures that the system is effectively operational.",Information and Software Technology,18 Mar 2025,7.0,"The study investigating the usage of business process models in agile software development projects provides practical implications for startups. The systematic analysis and focus group design offer valuable insights into the benefits of process modeling, particularly in the initial phases of the development cycle, supporting management and process issues in agile projects."
https://www.sciencedirect.com/science/article/pii/S0950584922001483,Uses of business process modeling in agile software development projects,December 2022,Not Found,Cielo=González Moyano: c.gonzalez.moyano@hu-berlin.de; Luise=Pufahl: Not Found; Ingo=Weber: Not Found; Jan=Mendling: Not Found,"Abstract
Context:
Agile 
methodologies and frameworks
 are widely used in software development projects because of their support for 
continuous change
 and delivery. 
Agile software development
 advocates de-prioritizing aspects such as processes and documentation. In traditional 
software engineering
 methodologies, however, business process models have been extensively used to support these aspects. Up until now, it is unclear to what extent recommendations to focus on code imply that 
conceptual modeling
 should be discontinued.
Objective:
The objective of this study is to investigate this hypothesis. More specifically, we develop a theoretical argument of how business process models are and can be used to support agile software development projects.
Method:
To this end, we use a multi-method study design. First, we conduct a systematic literature review, in which we identify studies on the usage of business process models in agile software development. Second, we apply procedures from thematic synthesis to analyze the connection between these uses and the phases of the 
development cycle
. Third, we use a focus group design with practitioners to systematically reflect upon how these uses can help regarding four categories of challenges in agile software development: management, team, technology, and process.
Results:
From 37 relevant studies, we distill 15 different uses. The results highlight the benefits of process modeling as an instrument to support agile software development projects from different angles and in all project phases. Process modeling appears to be particularly relevant for the first phases of the 
development cycle
, and for management and process issues in agile projects.
Conclusion:
We conclude that business process models indeed provide benefits for agile software development projects. Our findings have practical implications and emphasize the need for future research on modeling and 
agile development
.",Information and Software Technology,18 Mar 2025,6.0,"Identifying metrics for GUI-based testing research and formulating a taxonomy for coverage metrics contribute to improving the quality of studies in the domain. The proposed taxonomy can facilitate replication studies and macro-analysis, providing a foundation for future research in the field, which could benefit early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001719,A taxonomy of metrics for GUI-based testing research: A systematic literature review,December 2022,Not Found,Riccardo=Coppola: riccardo.coppola@polito.it; Emil=Alégroth: Not Found,"Abstract
Context:
GUI-based testing is a sub-field of software testing research that has emerged in the last three decades. GUI-based testing techniques focus on verifying the functional conformance of the system under test (SUT) through its graphical user interface. However, despite the research domains growth, studies in the field have low reproducibility and 
comparability
. One observed cause of these phenomena is identified as a lack of research rigor and commonly used metrics, including coverage metrics.
Objective:
We aim to identify the most commonly used metrics in the field and formulate a taxonomy of coverage metrics for GUI-based testing research.
Method:
We adopt an evidence-based approach to build the taxonomy through a systematic literature review of studies in the GUI-based testing domain. Identified papers are then analyzed with Open and Axial Coding techniques to identify hierarchical and mutually exclusive categories of metrics with common characteristics, usages, and applications.
Results:
Through the analysis of 169 papers and 315 
metric definitions
, we obtained a taxonomy with 55 codes (common names for metrics), 17 metric categories, and 4 higher level categories: Functional Level, GUI Level, Model Level and Code Level. We measure a higher number of mentions of Model and Code level metrics over Functional and GUI level metrics.
Conclusions:
We propose a taxonomy for use in future GUI-based testing research to improve the general quality of studies in the domain. In addition, the taxonomy is perceived to help enable more replication studies as well as macro-analysis of the current body of research.",Information and Software Technology,18 Mar 2025,5.0,"The introduction of COR-NSGA-II for variability testing of Software Product Lines addresses an important problem in optimization algorithms. The experiments demonstrate promising results, outperforming existing algorithms, but the practical implications for European early-stage ventures may require further exploration and validation."
https://www.sciencedirect.com/science/article/pii/S0950584922001501,Variability testing of software product line: A preference-based dimensionality reduction approach,December 2022,Not Found,Thiago=Ferreira: thiagod@umich.edu; Silvia Regina=Vergilio: silvia@inf.ufpr.br; Marouane=Kessentini: marouane@umich.edu,"Abstract
Context:
Multi- and many-evolutionary algorithms have been applied to derive products for the variability testing of Software Product Lines (SPLs). This problem refers to the selection of an adequate product set to test a SPL by optimizing some objectives related to the number of products to be tested, testing criteria to be satisfied, and revealed faults. However, some problems emerge when the number of objectives to be optimized increases, for example: the solutions generated by the 
optimization algorithms
 become incomparable, designing a Pareto-front in this context requires a large number of solutions, and the visualization of such solutions requires special techniques. Several techniques are proposed to tackle this problem, such as decomposition and algorithms based on indicators. Among them, algorithms based on dimensionality reduction and user preferences are widely used, but there are no studies in the literature investigating the usage of both in a combined way.
Objective:
In light of this, we introduce COR-NSGA-II (Confidence-based Objective Reduction NSGA-II). COR-NSGA-II defines for each objective a confidence-level calculated with the user preferences provided interactively. The objectives with higher values of confidence are removed from the next algorithm execution.
Method:
For assessing the feasibility of COR-NSGA-II, experiments were conducted by using six different SPLs, seven objectives, two types of 
reference points
 representing the user preferences, and two scenarios to simulate different user profiles.
Results:
COR-NSGA-II is evaluated against four algorithms explored in the literature for the problem, and outperforms most of them according to R-HV and R-IGD. It takes less time to execute and generates a reduced number of solutions, all of them satisfying the user preferences.
Conclusion:
A qualitative analysis performed with 12 potential users shows that the task of selecting a solution generated by COR-NSGA-II is easier than selecting a solution generated by the other algorithms.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584922001501,Variability testing of software product line: A preference-based dimensionality reduction approach,December 2022,Not Found,Thiago=Ferreira: thiagod@umich.edu; Silvia Regina=Vergilio: silvia@inf.ufpr.br; Marouane=Kessentini: marouane@umich.edu,"Abstract
Context:
Multi- and many-evolutionary algorithms have been applied to derive products for the variability testing of Software Product Lines (SPLs). This problem refers to the selection of an adequate product set to test a SPL by optimizing some objectives related to the number of products to be tested, testing criteria to be satisfied, and revealed faults. However, some problems emerge when the number of objectives to be optimized increases, for example: the solutions generated by the 
optimization algorithms
 become incomparable, designing a Pareto-front in this context requires a large number of solutions, and the visualization of such solutions requires special techniques. Several techniques are proposed to tackle this problem, such as decomposition and algorithms based on indicators. Among them, algorithms based on dimensionality reduction and user preferences are widely used, but there are no studies in the literature investigating the usage of both in a combined way.
Objective:
In light of this, we introduce COR-NSGA-II (Confidence-based Objective Reduction NSGA-II). COR-NSGA-II defines for each objective a confidence-level calculated with the user preferences provided interactively. The objectives with higher values of confidence are removed from the next algorithm execution.
Method:
For assessing the feasibility of COR-NSGA-II, experiments were conducted by using six different SPLs, seven objectives, two types of 
reference points
 representing the user preferences, and two scenarios to simulate different user profiles.
Results:
COR-NSGA-II is evaluated against four algorithms explored in the literature for the problem, and outperforms most of them according to R-HV and R-IGD. It takes less time to execute and generates a reduced number of solutions, all of them satisfying the user preferences.
Conclusion:
A qualitative analysis performed with 12 potential users shows that the task of selecting a solution generated by COR-NSGA-II is easier than selecting a solution generated by the other algorithms.",Information and Software Technology,18 Mar 2025,8.0,"The introduction of COR-NSGA-II for software testing optimization shows significant improvement and outperforms existing algorithms, providing practical value for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001525,"Different, Really! A comparison of Highly-Configurable Systems and Single Systems",December 2022,Not Found,Raphael Pereira=de Oliveira: raphael.oliveira@academico.ufs.br; Paulo Anselmo da Mota Silveira=Neto: Not Found; Qi Hong=Chen: Not Found; Eduardo Santana=de Almeida: Not Found; Iftekhar=Ahmed: Not Found,"Abstract
Context:
The development of systems that handle configuration options according to a specific environment is considered a hard activity. These kind of systems, Highly-Configurable Systems (HCS) are perceived by researchers and developers as complex and difficult to maintain due to the necessity of handling variation points. Although this perception is reported in the literature, no prior study investigated the differences between HCS and Single Systems (SS).
Objective:
This study investigated similarities and differences between HCS and SS using well known metrics from the literature according to three different perspectives: 
product perspective
 (bug-proneness, complexity, and change size); 
process perspective
 (number of contributors, number of core developers, and accidental contributors); and 
people perspective
 (contributor retention and number of paid contributors).
Method:
To perform this comparison, we 
collected data
 from two surveys and from a mining study (within 15,769 releases of 124 GitHub projects written in C).
Results:
In general, we identified that for the majority of the metrics, the perception of practitioners and researchers about HCS and SS is different from our mining results.
Conclusion:
The identification of similarities and differences of HCS and SS will help to initiate a discussion and further research in this direction.",Information and Software Technology,18 Mar 2025,5.0,"The study on Highly-Configurable Systems vs. Single Systems provides insights, but the impact on early-stage ventures is not as significant as other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001288,Yet another combination of IR- and neural-based comment generation,December 2022,Not Found,Yuchao=Huang: yuchao2019@iscas.ac.cn; Moshi=Wei: moshiwei@yorku.ca; Song=Wang: wangsong@eecs.yorku.ca; Junjie=Wang: junjie@iscas.ac.cn; Qing=Wang: wq@iscas.ac.cn,"Abstract
Background:
Code comment generation techniques aim to generate natural language descriptions for 
source code
. There are two orthogonal approaches for this task, i.e., information retrieval (IR) based and neural-based methods. Recent studies have focused on combining their 
strengths
 by feeding the input code and its similar code snippets retrieved by the IR-based approach to the neural-based approach, which can enhance the neural-based approach’s ability to output low-frequency words and further improve the performance.
Aim:
However, despite the tremendous progress, our pilot study reveals that the current combination is not generalizable and can lead to 
performance degradation
. In this paper, we propose a straightforward but effective approach to tackle the issue of existing combinations of these two comment generation approaches.
Method:
Instead of binding IR- and neural-based approaches statically, we combine them in a dynamic manner. Specifically, given an input code snippet, we first use an IR-based technique to retrieve a similar code snippet from the corpus. Then we use a Cross-Encoder based classifier to decide the comment generation method to be used dynamically, i.e., if the retrieved similar code snippet is a 
true positive
 (i.e., is semantically similar to the input), we directly use the IR-based technique. Otherwise, we pass the input to the neural-based model to generate the comment.
Results:
We evaluate our approach on a large-scale dataset of Java projects. Experiment results show that our approach can achieve 25.45 BLEU score, which improves the state-of-the-art IR-based approach, neural-based approach, and their combination by 41%, 26%, and 7%, respectively.
Conclusions:
We propose a straightforward but effective dynamic combination of IR-based and neural-based comment generation, which outperforms state-of-the-art approaches by a substantial margin.",Information and Software Technology,18 Mar 2025,7.0,The proposed dynamic combination of IR-based and neural-based approaches for code comment generation shows substantial improvement and practical value for startups in the software industry.
https://www.sciencedirect.com/science/article/pii/S0950584922001537,"An empirical study on ML DevOps adoption trends, efforts, and benefits analysis",December 2022,Not Found,Dhia Elhaq=Rzig: dhiarzig@umich.edu; Foyzul=Hassan: foyzul@umich.edu; Marouane=Kessentini: kessentini@oakland.edu,"Abstract
Context:
Machine Learning
 (ML), including Deep Learning(DL), based systems, have become ubiquitous in today’s solutions to many real-world problems. ML-based approaches are being applied to solve complex problems such as 
autonomous driving
, recommendation systems, etc.
Objective:
To improve the quality and 
deliverability
 of ML-based applications, the software development community is adopting state-of-the-art 
DevOps
 practices within them. However, we currently lack knowledge about the 
DevOps
 adoption trends, maintenance efforts and benefits among ML-based projects, and this work attempts to remedy this knowledge-gap.
Methods:
In this 
research work
, we conducted a large-scale empirical analysis on 4031 ML projects, including 1116 ML Tools and 2915 
ML Applied
 projects to quantify DevOps adoption, maintenance effort and benefits. To characterize the development behaviors, we performed configuration-script-analysis and commit-change-analysis on DevOps 
configuration files
. To compare the characteristics of ML DevOps to those of traditional software projects, we performed the same analysis on 4076 non-ML projects.
Results:
Our analysis identified that ML projects, more specifically ML-Applied projects, have a slower, lower, and less efficient adoption of DevOps tools in general. DevOps 
configuration files
 in ML-Applied projects tended to experience more frequent changes than ML-Tool projects and were less likely to occur in conjunction with build and bug fixes. It’s also evident that adopting DevOps in ML projects correlates with an increase in development productivity, code quality, and a decrease in bug resolution time, especially in ML-Applied projects which have the most to gain by adopting these tools.
Conclusion:
We identified the characteristics and improvement scopes of ML DevOps, such as the slower adoption of DevOps in certain ML projects, and the need for automatic configuration 
synchronization
 tools for these projects. We also identified the improvements the productivity of ML teams and projects associated with DevOps adoption, including better code quality, more frequent code sharing and integration and faster issue resolution.",Information and Software Technology,18 Mar 2025,9.0,"The analysis of DevOps adoption in ML projects and the identified improvement scopes provide valuable insights for European startups using ML-based systems, contributing significantly to the field."
https://www.sciencedirect.com/science/article/pii/S0950584922001665,Introduction to the special issue on managing software processes using soft computing techniques,December 2022,Not Found,Arif Ali=Khan: arif.khan@oulu.fi; Mahmood=Niazi: Not Found,"Abstract
The coronavirus outbreak dramatically changed the work culture in the software industry. Most software practitioners began working remotely, which significantly revolutionized the traditional software processes landscape. Software development organizations have begun thinking about automating software processes to cope with the challenges raised by remote work. This special issue presents papers describing soft computing solutions for improving traditional software processes and capabilities. This editorial introduces the accepted papers and reflects on their contributions.",Information and Software Technology,18 Mar 2025,3.0,"While discussing the impact of the coronavirus outbreak on software processes is relevant, the automation of software processes for remote work may not directly impact early-stage ventures in Europe as significantly."
https://www.sciencedirect.com/science/article/pii/S0950584922001665,Introduction to the special issue on managing software processes using soft computing techniques,December 2022,Not Found,Arif Ali=Khan: arif.khan@oulu.fi; Mahmood=Niazi: Not Found,"Abstract
The coronavirus outbreak dramatically changed the work culture in the software industry. Most software practitioners began working remotely, which significantly revolutionized the traditional software processes landscape. Software development organizations have begun thinking about automating software processes to cope with the challenges raised by remote work. This special issue presents papers describing soft computing solutions for improving traditional software processes and capabilities. This editorial introduces the accepted papers and reflects on their contributions.",Information and Software Technology,18 Mar 2025,5.0,"While the topic of automating software processes is relevant, the abstract lacks specific details on the practical impact for early-stage ventures or startups."
https://www.sciencedirect.com/science/article/pii/S0950584922001549,Undulate: A framework for data-driven software engineering enabling soft computing,December 2022,"Soft computing, Multilevel modelling, Dimensional database, Continuous experimentation, Data-driven software engineering",Timo=Asikainen: timo.o.asikainen@helsinki.fi; Tomi=Männistö: tomi.mannisto@helsinki.fi,"Abstract
Context.
Especially web-facing software systems enable the collection of usage data at a massive scale. At the same time, the scale and scope of software processes have grown substantively. Automated tools are needed to increase the speed and quality of controlling software processes. The usage data has great potential as a driver for software processes. However, research still lacks constructs for collecting, refining and utilising usage data in controlling software processes.
Objective.
The objective of this paper is to introduce a framework for data-driven 
software engineering
. The 
Undulate
 framework covers generating, collecting and utilising usage data from software processes and business processes supported by the software produced. In addition, we define the concepts and process of extreme continuous experimentation as an exemplar of a software engineering process.
Method.
We derive requirements for the framework from the research literature, with a focus on papers inspired by practical problems. In addition, we apply a multilevel 
modelling language
 to describe the concepts related to extreme continuous experimentation.
Results.
We introduce the 
Undulate
 framework and give requirements and provide an overview of the processes of collecting usage data, augmenting it with additional 
dimensional data
, aggregating the data along the dimensions and computing different metrics based on the data and other metrics.
Conclusions.
The paper represents significant steps inspired by previous research and practical insight towards standardised processes for data-driven software engineering, enabling the application of soft computing and other methods based on 
artificial intelligence
.",Information and Software Technology,18 Mar 2025,7.0,The framework for data-driven software engineering presented in this abstract could have a significant impact on improving software processes and capabilities for early-stage ventures and startups.
https://www.sciencedirect.com/science/article/pii/S0950584922001690,Agile software development and UX design: A case study of integration by mutual adjustment,December 2022,Not Found,John Stouby=Persson: Not Found; Anders=Bruun: bruun@cs.aau.dk; Marta Kristín=Lárusdóttir: Not Found; Peter Axel=Nielsen: Not Found,"Abstract
Context
Agility is an overarching ideal for empirically-driven software development processes that embrace change in order to improve quality, economy, and simplicity. While the pursuit of Agility has held prominence in software practice and research for over two decades, 
user experience
 (UX) designers struggle to integrate their work processes with 
agile software development
.
Objective
As empirical processes are constantly evolving, so is this integration struggle for UX designers. We, therefore, present an industrial 
case study
 of how a Danish software company integrates UX design and agile software development.
Method
We conducted a case study involving (a) one iteration of individual interviews with 10 employees (four UX designers, three software developers, two project managers, and one solution architect) and (b) a follow-up iteration consisting of a workshop with 6 employees (three UX designers, two solution architects, and one project manager) two years later. We analyzed how the company's approach to integration with 'upfront design' and 'work in parallel' involve mutual adjustments as opposed to assimilation or separation of UX design and software development.
Results
Our analysis shows how integration through mutual adjustments made distinct contributions to UX designers' and software developers' pursuit of Agility. They experienced notably different work processes that still dealt effectively with change and contributed to quality, economy, or simplicity. Nevertheless, as shown from a follow-up workshop two years after our first interviews, these processes were still susceptible to integration struggles over time.
Conclusion
We conclude that integration based on mutual adjustment potentially makes Agility for UX designers and software developers different and mutually complementary. This integration contrasts with assimilation, which potentially makes their Agility mutually indistinguishably, and with separation, which makes their Agility different and mutually competing.",Information and Software Technology,18 Mar 2025,9.0,"The industrial case study on integrating UX design and agile software development provides actionable insights for early-stage ventures and startups, making it highly valuable."
https://www.sciencedirect.com/science/article/pii/S0950584922001690,Agile software development and UX design: A case study of integration by mutual adjustment,December 2022,Not Found,John Stouby=Persson: Not Found; Anders=Bruun: bruun@cs.aau.dk; Marta Kristín=Lárusdóttir: Not Found; Peter Axel=Nielsen: Not Found,"Abstract
Context
Agility is an overarching ideal for empirically-driven software development processes that embrace change in order to improve quality, economy, and simplicity. While the pursuit of Agility has held prominence in software practice and research for over two decades, 
user experience
 (UX) designers struggle to integrate their work processes with 
agile software development
.
Objective
As empirical processes are constantly evolving, so is this integration struggle for UX designers. We, therefore, present an industrial 
case study
 of how a Danish software company integrates UX design and agile software development.
Method
We conducted a case study involving (a) one iteration of individual interviews with 10 employees (four UX designers, three software developers, two project managers, and one solution architect) and (b) a follow-up iteration consisting of a workshop with 6 employees (three UX designers, two solution architects, and one project manager) two years later. We analyzed how the company's approach to integration with 'upfront design' and 'work in parallel' involve mutual adjustments as opposed to assimilation or separation of UX design and software development.
Results
Our analysis shows how integration through mutual adjustments made distinct contributions to UX designers' and software developers' pursuit of Agility. They experienced notably different work processes that still dealt effectively with change and contributed to quality, economy, or simplicity. Nevertheless, as shown from a follow-up workshop two years after our first interviews, these processes were still susceptible to integration struggles over time.
Conclusion
We conclude that integration based on mutual adjustment potentially makes Agility for UX designers and software developers different and mutually complementary. This integration contrasts with assimilation, which potentially makes their Agility mutually indistinguishably, and with separation, which makes their Agility different and mutually competing.",Information and Software Technology,18 Mar 2025,9.0,"Similar to abstract 128, this case study on integrating UX design and agile software development offers practical value and insights for early-stage ventures and startups."
https://www.sciencedirect.com/science/article/pii/S0950584922001677,Software defect prediction with semantic and structural information of codes based on Graph Neural Networks,December 2022,Not Found,Chunying=Zhou: zcy9838@stu.hubu.edu.cn; Peng=He: penghe@hubu.edu.cn; Cheng=Zeng: zc@hubu.edu.cn; Ju=Ma: dcsxan@nus.edu.sg,"Abstract
Context:
Most 
defect prediction
 methods consider a series of traditional manually designed static 
code metrics
. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional 
Neural Network
 (CNN) to capture the potential semantic information based on the program’s Syntax 
Trees
 (ASTs). In recent years, leveraging the 
dependency relationships
 between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in 
defect prediction
. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN.
Objective:
This study aims to validate the feasibility and performance of the proposed method in 
software defect
 prediction.
Method:
Abstract Syntax Trees
 and a Class Dependency Network (CDN) are first generated based on the 
source code
. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a 
Graph Convolutional Network
 (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction.
Results:
The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks.
Conclusion:
The proposed method of combining semantic and structural information can improve the performance of 
software defect
 prediction.",Information and Software Technology,18 Mar 2025,7.0,The proposed method for software defect prediction utilizing semantic and structural information could benefit early-stage ventures and startups by improving software quality and reliability.
https://www.sciencedirect.com/science/article/pii/S0950584922001677,Software defect prediction with semantic and structural information of codes based on Graph Neural Networks,December 2022,Not Found,Chunying=Zhou: zcy9838@stu.hubu.edu.cn; Peng=He: penghe@hubu.edu.cn; Cheng=Zeng: zc@hubu.edu.cn; Ju=Ma: dcsxan@nus.edu.sg,"Abstract
Context:
Most 
defect prediction
 methods consider a series of traditional manually designed static 
code metrics
. However, only using these hand-crafted features is impractical. Some researchers use the Convolutional 
Neural Network
 (CNN) to capture the potential semantic information based on the program’s Syntax 
Trees
 (ASTs). In recent years, leveraging the 
dependency relationships
 between software modules to construct a software network and using network embedding models to capture the structural information have been helpful in 
defect prediction
. This paper simultaneously takes the semantic and structural information into account and proposes a method called CGCN.
Objective:
This study aims to validate the feasibility and performance of the proposed method in 
software defect
 prediction.
Method:
Abstract Syntax Trees
 and a Class Dependency Network (CDN) are first generated based on the 
source code
. For ASTs, symbolic tokens are extracted and encoded into vectors. The numerical vectors are then used as input to the CNN to capture the semantic information. For CDN, a 
Graph Convolutional Network
 (GCN) is used to learn the structural information of the network automatically. Afterward, the learned semantic and structural information are combined with different weights. Finally, we concatenate the learned features with traditional hand-crafted features to train a classifier for more accurate defect prediction.
Results:
The proposed method outperforms the state-of-the-art defect prediction models for both within-project prediction (including within-version and cross-version) and cross-project prediction on 21 open-source projects. In general, within-version prediction achieves better performance in the three prediction tasks.
Conclusion:
The proposed method of combining semantic and structural information can improve the performance of 
software defect
 prediction.",Information and Software Technology,18 Mar 2025,8.0,"The proposed method of combining semantic and structural information for software defect prediction shows significant improvement over existing models, which can benefit European early-stage ventures in improving the quality of their software products."
https://www.sciencedirect.com/science/article/pii/S0950584922001707,Guidelines for the development of a critical software under emergency,December 2022,"Safety–critical systems development, Software certification, Lessons learned, Guidelines, Healthcare",Andrea=Bombarda: Not Found; Silvia=Bonfanti: silvia.bonfanti@unibg.it; Cristiano=Galbiati: Not Found; Angelo=Gargantini: Not Found; Patrizio=Pelliccione: Not Found; Elvinia=Riccobene: Not Found; Masayuki=Wada: Not Found,"Abstract
Context:
During the first wave of the COVID-19 pandemic, an international and heterogeneous team of scientists collaborated on a social project to produce a mechanical ventilator for intensive care units (MVM). MVM has been conceived to be produced and used also in poor countries: it is open-source, no patents, cheap, and can be produced with materials that are easy to retrieve.
Objective:
The objective of this work is to extract from the experience of the MVM development and software certification a set of lessons learned and then guidelines that can help developers to produce safety–critical devices in similar 
emergency situations
.
Method:
We conducted a 
case study
. We had full access to source code, comments on code, change requests, test reports, every deliverable (60 in total) produced for the software certification (safety concepts, requirements specifications, architecture and design, testing activities, etc.), notes, whiteboard sketches, emails, etc. We validated both lessons learned and guidelines with experts.
Findings:
We contribute a set of validated lessons learned and a set of validated guidelines, together with a discussion of benefits and risks of each guideline.
Conclusion:
In this work we share our experience in certifying software for healthcare devices produced under emergency, i.e. with strict and pressing time constraints and with the difficulty of establishing a heterogeneous development team made of volunteers. We believe that the guidelines will help engineers during the development of critical software under emergency.",Information and Software Technology,18 Mar 2025,7.0,"The experience and guidelines shared in certifying software for healthcare devices produced under emergency situations can provide valuable insights for startups working on critical software with limited time constraints, potentially impacting European early-stage ventures in the healthcare sector."
https://www.sciencedirect.com/science/article/pii/S0950584922001689,"Theories in Agile Software Development: Past, Present, and Future Introduction to the XP 2020 Special Section",December 2022,Not Found,Viktoria=Stray: Not Found; Rashina=Hoda: Not Found; Maria=Paasivaara: Not Found; Valentina=Lenarduzzi: Not Found; Daniel=Mendez: Not Found,"Abstract
Over the last two decades, agile software development has gained popularity among software engineering researchers and practitioners. However, the development and use of theories in agile research remain relatively low. While analyzing publications on agile software development in the Scopus database from the last decade, we found that only 7% of the papers used or developed a theory. This trend seems stable. However, it is promising that most theory-centric studies use or propose theories to address cognitive and behavioral aspects of people working in agile development. We argue that these aspects build fundamental pillars in agile software development. In this special section, we introduce extended versions of four papers selected from the XP2020 Conference. These papers make valuable contributions to aspects of learning and behavior in agile software development. We encourage researchers to be more theory-centric in their future empirical studies of agile methods and practices by familiarizing themselves with existing theories and applying and developing theories. This way, they can contribute to a reliable, evidence-based body of knowledge in our community.",Information and Software Technology,18 Mar 2025,5.0,"While the encouragement for researchers to be more theory-centric in agile software development studies is valuable, the practical impact on European early-stage ventures may be limited as it focuses more on research methodologies than direct application."
https://www.sciencedirect.com/science/article/pii/S0950584922001689,"Theories in Agile Software Development: Past, Present, and Future Introduction to the XP 2020 Special Section",December 2022,Not Found,Viktoria=Stray: Not Found; Rashina=Hoda: Not Found; Maria=Paasivaara: Not Found; Valentina=Lenarduzzi: Not Found; Daniel=Mendez: Not Found,"Abstract
Over the last two decades, agile software development has gained popularity among software engineering researchers and practitioners. However, the development and use of theories in agile research remain relatively low. While analyzing publications on agile software development in the Scopus database from the last decade, we found that only 7% of the papers used or developed a theory. This trend seems stable. However, it is promising that most theory-centric studies use or propose theories to address cognitive and behavioral aspects of people working in agile development. We argue that these aspects build fundamental pillars in agile software development. In this special section, we introduce extended versions of four papers selected from the XP2020 Conference. These papers make valuable contributions to aspects of learning and behavior in agile software development. We encourage researchers to be more theory-centric in their future empirical studies of agile methods and practices by familiarizing themselves with existing theories and applying and developing theories. This way, they can contribute to a reliable, evidence-based body of knowledge in our community.",Information and Software Technology,18 Mar 2025,5.0,"Similar to abstract 133, the emphasis on theory-centric studies in agile software development may have limited practical impact on European early-stage ventures, as it leans towards research frameworks rather than direct implementation."
https://www.sciencedirect.com/science/article/pii/S0950584922001331,Predictive maintenance using digital twins: A systematic literature review,November 2022,"Systematic literature review, Active learning, Digital twin, Predictive maintenance",Raymon=van Dinter: Not Found; Bedir=Tekinerdogan: bedir.tekinerdogan@wur.nl; Cagatay=Catal: Not Found,"Abstract
Context
Predictive maintenance
 is a technique for creating a more sustainable, safe, and profitable industry. One of the key challenges for creating predictive maintenance systems is the lack of failure data, as the machine is frequently repaired before failure. Digital Twins provide a real-time representation of the physical machine and generate data, such as asset degradation, which the predictive maintenance algorithm can use. Since 2018, scientific literature on the utilization of Digital Twins for predictive maintenance has accelerated, indicating the need for a thorough review.
Objective
This research aims to gather and synthesize the studies that focus on predictive maintenance using Digital Twins to pave the way for further research.
Method
A systematic literature review (SLR) using an active learning tool is conducted on published primary studies on predictive maintenance using Digital Twins, in which 42 primary studies have been analyzed.
Results
This SLR identifies several aspects of predictive maintenance using Digital Twins, including the objectives, application domains, Digital Twin platforms, Digital Twin representation types, approaches, abstraction levels, design patterns, communication protocols, twinning parameters, and challenges and solution directions. These results contribute to a Software Engineering approach for developing predictive maintenance using Digital Twins in academics and the industry.
Conclusion
This study is the first SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models.",Information and Software Technology,18 Mar 2025,9.0,"The systematic literature review on predictive maintenance using Digital Twins offers valuable insights and solutions for challenges in developing predictive maintenance models, which can have a practical impact on European early-stage ventures looking to enhance their maintenance strategies."
https://www.sciencedirect.com/science/article/pii/S0950584922001331,Predictive maintenance using digital twins: A systematic literature review,November 2022,"Systematic literature review, Active learning, Digital twin, Predictive maintenance",Raymon=van Dinter: Not Found; Bedir=Tekinerdogan: bedir.tekinerdogan@wur.nl; Cagatay=Catal: Not Found,"Abstract
Context
Predictive maintenance
 is a technique for creating a more sustainable, safe, and profitable industry. One of the key challenges for creating predictive maintenance systems is the lack of failure data, as the machine is frequently repaired before failure. Digital Twins provide a real-time representation of the physical machine and generate data, such as asset degradation, which the predictive maintenance algorithm can use. Since 2018, scientific literature on the utilization of Digital Twins for predictive maintenance has accelerated, indicating the need for a thorough review.
Objective
This research aims to gather and synthesize the studies that focus on predictive maintenance using Digital Twins to pave the way for further research.
Method
A systematic literature review (SLR) using an active learning tool is conducted on published primary studies on predictive maintenance using Digital Twins, in which 42 primary studies have been analyzed.
Results
This SLR identifies several aspects of predictive maintenance using Digital Twins, including the objectives, application domains, Digital Twin platforms, Digital Twin representation types, approaches, abstraction levels, design patterns, communication protocols, twinning parameters, and challenges and solution directions. These results contribute to a Software Engineering approach for developing predictive maintenance using Digital Twins in academics and the industry.
Conclusion
This study is the first SLR in predictive maintenance using Digital Twins. We answer key questions for designing a successful predictive maintenance model leveraging Digital Twins. We found that to this day, computational burden, data variety, and complexity of models, assets, or components are the key challenges in designing these models.",Information and Software Technology,18 Mar 2025,7.0,The research on predictive maintenance using Digital Twins presents significant value for the industry in terms of efficiency and cost-effectiveness. This systematic literature review provides valuable insights for developing predictive maintenance models.
https://www.sciencedirect.com/science/article/pii/S0950584922001318,UX professionals’ learning and usage of UX methods in agile,November 2022,"User experience, UX, Agile development, UX professionals, UX methods, Lifelong learning",Åsa=Cajander: asa.cajander@it.uu.se; Marta=Larusdottir: marta@ru.is; Johannes L.=Geiser: jogeiser@icloud.com,"Abstract
Context
The usage of 
User Experience
 (UX) methods has been studied through the years. However, little is known about UX professionals’ 
lifelong learning
 processes related to UX methods in Agile, choosing what UX methods to use, and the enablers and hindrances for using the UX methods.
Objective
The study aims to broaden current knowledge about UX professionals’ lifelong learning practices to understand their work situations better. The paper describes how UX professionals learn about and choose UX methods, their frequency of use, and the enablers and barriers when using the UX methods in Agile.
Method
An interview study was conducted with 13 UX professionals from various industries and two countries working with Agile and UX. We used a qualitative approach, and a thematic analysis was carried out to answer the research questions.
Results
The results show that support from colleagues is an essential component for learning about the methods and how to use UX methods. Time pressure makes UX professionals choose methods they know will deliver their desired results. Prototyping, user testing, user journeys, and workshops are the most frequently used UX methods. Additionally, the results show that UX professionals think that the UX methods are often too complicated and take too long to learn. Additionally, they find it challenging to integrate UX methods into Agile.
Conclusion
These findings indicate that UX methods might work better if designed to be less complicated and deliver results more efficiently. Moreover, collegial and 
peer learning
 is central to UX professionals. The HCI community could be more active in supporting this culture by sharing information and learning. Finally, the usability and UX of the tools affect which UX methods are used.",Information and Software Technology,18 Mar 2025,5.0,"The study on UX professionals' lifelong learning practices offers insights into improving UX methods, but the practical impact on early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001276,Detecting relevant app reviews for software evolution and maintenance through multimodal one-class learning,November 2022,Not Found,Marcos P.S.=Gôlo: marcosgolo@usp.br; Adailton F.=Araújo: adailton.araujo@usp.br; Rafael G.=Rossi: rafael.g.rossi@ufms.br; Ricardo M.=Marcacini: ricardo.marcacini@icmc.usp.br,"Abstract
Context:
Mobile app reviews are a rich source of information for software evolution and maintenance. Several studies have shown the effectiveness of exploring relevant reviews in the 
software development lifecycle
, such as release planning and 
requirements engineering
 tasks. Popular apps receive even millions of reviews, thereby making manual extraction of relevant information an impractical task. The literature presents several 
machine learning approaches
 to detect relevant reviews. However, these approaches use multi-class learning, implying more user effort for data labeling since users must label a significant set of relevant and irrelevant reviews.
Objective:
This article investigates methods for detecting relevant app reviews considering scenarios with small sets of labeled data. We evaluated unimodal and multimodal representations, different labeling levels, as well as different app review domains and languages.
Method:
We present a one-class multimodal learning method for detecting relevant reviews. Our approaches have two main contributions. First, we use one-class learning that requires only the labeling of relevant app reviews, thereby minimizing the labeling effort. Second, to handle the smaller amount of labeled reviews without harming classification performance, we also present methods to improve feature extraction and reviews representation. We propose the Multimodal 
Autoencoder
 and the Multimodal 
Variational Autoencoder
. The methods learn representations which explore both textual data and visual information based on the density of the reviews. Density information can be interpreted as a summary of the main topics or clusters extracted from the reviews.
Results:
Our methods achieved competitive results even using only 25% of labeled reviews compared to models that used the entire training set. Also, our 
multimodal approaches
 obtain the highest 
F
1
-Score and AUC-ROC in twenty-three out of twenty-four scenarios.
Conclusion:
Our one-class multimodal methods proved to be a competitive alternative for detecting relevant reviews and promising for practical scenarios involving data-driven software evolution and maintenance.",Information and Software Technology,18 Mar 2025,9.0,The investigation on detecting relevant app reviews using multimodal learning with minimized labeling effort is highly practical and valuable for software evolution. The competitive results and practical scenarios make this research highly impactful.
https://www.sciencedirect.com/science/article/pii/S095058492200129X,Recruiting credible participants for field studies in software engineering research,November 2022,"Credibility, Validity, Reliability, Data collection, Sampling, Subjects, Participants, Recruitment",Austen=Rainer: Not Found; Claes=Wohlin: claes.wohlin@bth.se,"Abstract
Context:
Software practitioners are a primary provider of information for 
field studies
 in 
software engineering
. Research typically recruits practitioners through some kind of sampling. But sampling may not in itself recruit the “right” participants.
Objective:
To assess existing guidance on participant recruitment, and to propose and illustrate a framework for recruiting professional practitioners as credible participants in field studies of software engineering.
Methods:
We review 
existing guidelines
, checklists and other advisory sources on recruiting participants for field studies. We develop a framework, partly based on our prior research and on the research of others. We search for and select three exemplar studies (a 
case study
, an interview study and a survey study) and use those to illustrate the framework.
Results:
Whilst existing guidance recognises the importance of recruiting participants, there is limited guidance on how to recruit the “right” participants. The framework suggests the conceptualisation of participants as “research instruments” or, alternatively, as a sampling frame for items of interest. The exemplars suggest that at least some members of the research community are aware of the need to carefully recruit the “right” participants.
Conclusions:
The framework is intended to encourage researchers to 
think differently
 about the involvement of practitioners in field studies of software engineering. Also, the framework identifies a number of characteristics not explicitly addressed by existing guidelines.",Information and Software Technology,18 Mar 2025,4.0,"While the framework for recruiting professional practitioners in field studies of software engineering is valuable for research methodology, the direct impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922001306,A comprehensive empirical study on bug characteristics of deep learning frameworks,November 2022,Not Found,Yilin=Yang: yilin.yang@smail.nju.edu.cn; Tianxing=He: Not Found; Zhilong=Xia: Not Found; Yang=Feng: fengyang@nju.edu.cn,"Abstract
Context:
Deep Learning
 (DL) frameworks enable developers to build 
DNN
 models without learning the underlying algorithms and models. While some of these DL-based software systems have been deployed in safety-critical areas, such as self-driving cars and medical diagnostics, for DL frameworks, characterizing their bugs and thus helping researchers to design specific 
quality assurance techniques
 become desperately needed.
Objective:
Our research aims to characterize bugs typical of DL frameworks at the 
source code
 level for an in-depth analysis of bug symptoms, root causes, and bug fixes. In this way, we hope to provide insights for researchers to design automatic 
quality assurance techniques
, such as automatic repair techniques and 
fault location
 techniques, applicable to DL frameworks and DL-based software systems.
Method:
We started by summarizing the DL framework reference architecture and proposing the DL framework bug taxonomy. Then, we mined 1,127 DL framework 
bug reports
 from eight popular DL frameworks and labeled the bug types, root causes, and symptoms. Finally, we discussed the bug characteristics and explored how developers could possibly deal with these bugs.
Results:
Our main findings are: (i) 
DNN
 model building bugs and general type bugs accounted for one-third of the total defects. (ii) DNN model building bugs are more prone to algorithm logic constraints, internal API errors, and data/numerical errors. (iii) Fifteen bug-fixing patterns are summarized, providing reference for common DL framework bug repair and future research on the development of automatic DL framework bug detection tools.
Conclusion:
By analyzing the bug-fixing changes, we characterize the occurrences, root causes, symptoms, and fixing of these bugs. The study results have provided researchers with insights into how to ensure DL framework quality and presented actionable suggestions for DL framework developers to improve their code quality.",Information and Software Technology,18 Mar 2025,8.0,"The research on characterizing bugs in DL frameworks provides valuable insights for quality assurance techniques, which are crucial in safety-critical areas. The study's outcomes offer practical benefits for developers working with DL frameworks."
https://www.sciencedirect.com/science/article/pii/S0950584922001264,Improving microservices extraction using evolutionary search,November 2022,Not Found,Khaled=Sellami: khaled.sellami.1@ulaval.ca; Mohamed Aymen=Saied: mohamed-aymen.saied@ift.ulaval.ca; Salah=Bouktif: salahb@uaeu.ac.ae; Mohamed Wiem=Mkaouer: mwmvse@rit.edu,"Abstract
Context:
Microservices
 constitute a modern style of building 
software applications
 as collections of small, cohesive, and loosely coupled services, 
i.e.
, modules, that are developed, deployed, and scaled independently.
Objective:
The migration from legacy systems towards the microservice-based architecture is not a trivial task. It is still manual, time-consuming, error-prone and subsequently costly. The most critical and challenging issue is the cost-effective identification of microservices boundaries that ensure adequate 
granularity
 and cohesiveness.
Method:
To address this problem, we introduce in this paper a novel approach, named 
MSExtractor
 , that formulates microservices identification as a multi-objective 
optimization problem
. The proposed solution aims at decomposing a legacy application into a set of cohesive, loosely-coupled and coarse-grained services. We employ the Indicator-Based 
Evolutionary Algorithm
 (IBEA) to drive a search process towards optimal microservices identification while considering structural and 
semantic dependencies
 in the source code.
Results:
We conduct an empirical evaluation on a benchmark of seven software systems to assess the efficiency of our approach. Results show that 
MSExtractor
 is able to carry out an effective identification of relevant microservice candidates and outperforms three other existing approaches.
Conclusion:
In this paper, we show that MSExtractor is able to extract cohesive and loosely coupled services with higher performance than three other considered methods. However, we advocate that while automated microservices identification approaches are very helpful, the role of the human experts remains crucial to validate and calibrate the extracted microservices.",Information and Software Technology,18 Mar 2025,8.0,"The proposed approach addresses a crucial issue in migrating towards microservices and outperforms existing methods, which can benefit early-stage ventures in improving software architecture efficiently."
https://www.sciencedirect.com/science/article/pii/S0950584922001434,Using clarification questions to improve software developers’ Web search,November 2022,Not Found,Mia Mohammad=Imran: imranm3@vcu.edu; Kostadin=Damevski: kdamevski@vcu.edu,"Abstract
Context:
Recent research indicates that Web queries written by software developers are not very successful in retrieving relevant results, performing measurably worse compared to general purpose Web queries. Most approaches up to this point have addressed this problem with software engineering-specific automated 
query reformulation
 techniques, which work without 
developer involvement
 but are limited by the content of the original query. In other words, these techniques automatically improve the existing query but cannot contribute new, previously unmentioned, concepts.
Objective:
In this paper, we propose a technique to guide software developers in manually improving their own 
Web search
 queries. We examine a conversational approach that follows unsuccessful queries with a clarification question aimed at eliciting additional query terms, thus providing to the developer a clear dimension along which the query could be improved.
Methods:
We describe a set of clarification questions derived from a corpus of software developer queries and a neural approach to recommending them for a newly issued query.
Results:
Our evaluation indicates that the recommendation technique is accurate, predicting a valid clarification question 80% of the time and outperforms simple baselines, as well as, state-of-the-art Learning To Rank (LTR) baselines.
Conclusion:
As shown in the experimental results, the described approach is capable at recommending appropriate clarification questions to software developers and considered useful by a sample of developers ranging from novices to experienced professionals.",Information and Software Technology,18 Mar 2025,6.0,"The technique proposed can be useful for software developers to improve their web search queries, but may have limited direct impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001446,The essential competencies of software professionals: A unified competence framework,November 2022,"Software engineering, Software development, Competence, Competencies, Kano model",Nana=Assyne: nana.m.a.assyne@student.jyu.fi; Hadi=Ghanbari: Not Found; Mirja=Pulkkinen: Not Found,"Abstract
Context
Developing high-quality software requires skilled software professionals equipped with a set of basic and essential software engineering competencies (SEC). These competencies and the satisfaction levels derived from them change over a project's lifecycle, or as software professionals move from one project to another.
Objective
Previous studies suggest a lack of means enabling SEC stakeholders to identify and assess competencies suitable for different projects. Additionally, previous research has mainly portrayed SEC to be static and overlooked their evolution over time and across projects. We investigate how we could effectively identify and match the competencies of software professionals necessary for different projects.
Method
We follow a mixed-method approach to iteratively develop and evaluate a framework for identifying and managing SEC. In so doing, we use the results of an extensive literature review, focus 
group discussions
 with experts from academia and 
industry
, and 
data collected
 through interviews with 138 individuals with a supervisory role in the software industry.
Results
Drawing on the Kano model and Competency Framework for Software Engineers, we propose a Unified Competence Gate for Software Professionals (UComGSP), a framework for identifying and managing SEC. The UComGSP consists of 62 hard competencies, 63 soft competencies, and 25 essential SEC competencies. Additionally, we propose three stakeholders’ satisfaction levels for SEC assessment: basic, performance, and delighter. Furthermore, based on empirical observation, we report 27 competencies not mentioned in the reviewed literature; 11 of them are considered essential competencies.
Conclusion
Competence development involves different stakeholders, including software professionals, educators, and the software industry. The UComGSP framework enables SEC stakeholders to (i) identify SE competencies, (ii) identify the essential SEC, and (iii) assess the satisfaction levels that can be derived from different competencies. Future research is needed to evaluate the effectiveness of the proposed framework across software development projects.",Information and Software Technology,18 Mar 2025,9.0,The framework introduced for identifying and managing software engineering competencies can be highly valuable for early-stage ventures in optimizing team composition and project success.
https://www.sciencedirect.com/science/article/pii/S0950584922001458,A multi-objective agile project planning model and a comparative meta-heuristic approach,November 2022,Not Found,Nilay=Ozcelikkan: nilay.ozcelikkan@gmail.com; Gulfem=Tuzkaya: gulfem.tuzkaya@marmara.edu.tr; Cigdem=Alabas-Uslu: cigdem.uslu@marmara.edu.tr; Bahar=Sennaroglu: bsennar@marmara.edu.tr,"Abstract
Agile software development
 methodologies are used to meet the changing needs in the market. The most popular framework among these methodologies is the Scrum framework. In Scrum planning, the assignment of user stories to sprints requires the consideration of multiple objectives to use the limited resources more effectively. In this paper, a multi-objective mixed-integer programming model is developed which considers three objectives: maximizing the sprint capacity usage, maximizing the assignment of user stories with high priority to primary sprints, and maximizing the assignment of affine user stories to the same sprint. The aim is to contribute to both theory and practice of Scrum planning considering multiple objectives. Additionally, different from the existing literature of Scrum planning, alternative user stories are also taken into account. The proposed model is applied to the small, medium, and big-sized instances of the problem taken from a real-life system. Non-dominated Sorting 
Genetic Algorithm
 (NSGA-II) and Strong Pareto 
Evolutionary Algorithm
 (SPEA2) are used as heuristic approaches since big-sized instances of the problem could not be solved using optimization approaches. To analyze the performances of these algorithms, Hypervolume (HV), Epsilon (
ϵ
), Generational Distance (GD), Inverted Generational Distance (IGD), Inverted Generational Distance Plus (IGD+), and Spread (
Δ
) indicators are used. Results showed that NSGA-II performs better than SPEA2 according to 
ϵ
 indicator for big-sized instance. On the other hand, SPEA2 performs better than NSGA-II according to HV, GD, IGD, IGD+, and 
Δ
 indicators. However, the results are very close to each other for HV, 
ϵ
, IGD, and IGD+ indicators. In conclusion, both algorithms can be used to deal with the multi-objective Scrum planning problem.",Information and Software Technology,18 Mar 2025,7.0,"The multi-objective approach for Scrum planning contributes to theory and practice, benefiting early-stage ventures in efficient resource allocation, but the direct impact may vary based on the size of the venture."
https://www.sciencedirect.com/science/article/pii/S0950584922001495,Towards a model and methodology for evaluating data quality in software engineering experiments,November 2022,Not Found,Carolina=Valverde: mvalverde@fing.edu.uy; Adriana=Marotta: Not Found; José Ignacio=Panach: Not Found; Diego=Vallespir: Not Found,"Abstract
Context
Data collected
 during 
software engineering
 experiments might contain quality problems, leading to wrong experimental conclusions.
Objective
We present a 
data quality
 (DQ) model and a methodology specific to 
software engineering
 experiments, which provides a systematic approach in order to analyze and improve 
data quality
 in this domain.
Method
Our proposal considers a multifaceted view of data quality suitable for this context, which enables the discovery of DQ problems that are not generally addressed. We successfully applied the model (DQMoS) and methodology (DQMeS) in four controlled experiments, detecting different quality problems that could impact the experimental results. We present, through a running example, how we applied the DQMoS and DQMeS to one of the four experimental data.
Results
We found that between 55% and 75% of the 
DQ metrics
 applied showed the presence of a DQ problem in all four experiments. In all cases, the experimental results had already been obtained before the DQMeS application. This means that the DQ problems we found, were not discovered by the experimenters during or before making their experiment's analysis. Results yield data quality problems that experimenters did not detect on their own analysis, and that affect the experimental response variables. Our proposal shows a formalized framework that measures and improves the 
quality of software
 engineering experimental data. The results of a survey distributed to the experiments’ responsibles show that they value the improvements introduced by the model and methodology, and that they intend to apply them again in future experiences.
Conclusions
DQMoS and DQMeS are useful to increase the confidence in the quality of data used in software engineering experiments, and improve the trust in experimental results.",Information and Software Technology,18 Mar 2025,8.0,"The DQ model and methodology introduced can significantly improve the quality of data in software engineering experiments, leading to more reliable results, which can benefit early-stage ventures in decision-making and product development."
https://www.sciencedirect.com/science/article/pii/S095058492200146X,S-DABT: Schedule and Dependency-aware Bug Triage in open-source bug tracking systems,November 2022,Not Found,Hadi=Jahanshahi: hadi.jahanshahi@ryerson.ca; Mucahit=Cevik: Not Found,"Abstract
Context:
In 
software engineering
 practice, fixing bugs in a timely manner lowers various potential costs in software maintenance. However, manual bug fixing scheduling can be time-consuming, cumbersome, and error-prone.
Objective:
In this paper, we propose the Schedule and Dependency-aware Bug Triage (S-DABT), a bug triaging method that utilizes 
integer programming
 and 
machine learning techniques
 to assign bugs to suitable developers.
Methods:
Unlike prior works that largely focus on a single component of the 
bug reports
, our approach takes into account the textual data, bug fixing costs, and bug dependencies. We further incorporate the schedule of developers in our formulation to have a more comprehensive model for this multifaceted problem. As a result, this complete formulation considers developers’ schedules and the blocking effects of the bugs while covering the most significant aspects of the previously proposed methods.
Results:
Our numerical study on four open-source software systems, namely, ECLIPSEJDT, LIBREOFFICE, GCC, and MOZILLA, shows that taking into account the schedules of the developers decreases the average bug fixing times. We find that S-DABT leads to a high level of developer utilization by a fair distribution of the tasks among the developers and efficient use of the free spots in their schedules. Via the simulation of the issue tracking system, we also show how incorporating the schedule in the model formulation reduces the bug fixing time, improves the assignment accuracy, and utilizes the capability of each developer without much comprising in the model run times.
Conclusion:
We find that S-DABT decreases the complexity of the bug 
dependency graph
 by prioritizing blocking bugs and effectively reduces the infeasible assignment ratio due to bug dependencies. Consequently, we recommend considering developers’ schedules while automating bug triage.",Information and Software Technology,18 Mar 2025,8.0,"The proposed bug triaging method shows practical value in reducing bug fixing times and increasing developer utilization, with tangible results from numerical studies on open-source software systems."
https://www.sciencedirect.com/science/article/pii/S0950584922001422,Sentiment analysis tools in software engineering: A systematic mapping study,November 2022,Not Found,Martin=Obaidi: martin.obaidi@inf.uni-hannover.de; Lukas=Nagel: lukas.nagel@inf.uni-hannover.de; Alexander=Specht: alexander.specht@inf.uni-hannover.de; Jil=Klünder: jil.kluender@inf.uni-hannover.de,"Abstract
Context:
Software development is a collaborative task. Previous research has shown 
social aspects
 within development teams to be highly relevant for the success of software projects. A team’s mood has been proven to be particularly important. It is paramount for project managers to be aware of negative moods within their teams, as such awareness enables them to intervene. 
Sentiment analysis
 tools offer a way to determine the mood of a team based on textual communication.
Objective:
We aim to help developers or stakeholders in their choice of sentiment analysis tools for their specific purpose. Therefore, we conducted a 
systematic mapping study
 (SMS).
Methods:
We present the results of our SMS of sentiment analysis tools developed for or applied in the context of 
software engineering
 (SE). Our results summarize insights from 106 papers with respect to (1) the application domain, (2) the purpose, (3) the used data sets, (4) the approaches for developing sentiment analysis tools, (5) the usage of already existing tools, and (6) the difficulties researchers face. We analyzed in more detail which tools and approaches perform how in terms of their performance.
Results:
According to our results, sentiment analysis is frequently applied to open-source software projects, and most approaches are 
neural networks
 or support-vector machines. The best performing approach in our analysis is 
neural networks
 and the best tool is 
BERT
. Despite the frequent use of sentiment analysis in SE, there are open issues, e.g. regarding the identification of irony or sarcasm, pointing to future research directions.
Conclusion:
We conducted an SMS to gain an overview of the current state of sentiment analysis in order to help developers or stakeholders in this matter. Our results include interesting findings e.g. on the used tools and their difficulties. We present several suggestions on how to solve these identified problems.",Information and Software Technology,18 Mar 2025,7.0,"The systematic mapping study on sentiment analysis tools provides valuable insights for developers and stakeholders, highlighting the best performing approaches and tools in software engineering."
https://www.sciencedirect.com/science/article/pii/S095058492200132X,Collaborative program comprehension via software visualization in extended reality,November 2022,"Program comprehension, Software visualization, City metaphor, Extended reality, Virtual reality, Augmented reality",Alexander=Krause-Glau: akr@informatik.uni-kiel.de; Malte=Hansen: Not Found; Wilhelm=Hasselbring: Not Found,"Abstract
Context:
In software visualization research, various approaches strive to create 
immersive environments
 by employing 
extended reality
 devices. In that context, only few research has been conducted on the effect of collaborative, i.e., multi-user, extended reality environments.
Objective:
We present our journey toward a web-based approach to enable (location-independent) collaborative 
program comprehension
 using desktop, virtual reality, and mobile 
augmented reality
 devices.
Method:
We designed and implemented three multi-user modes in our web-based live trace visualization tool ExplorViz. Users can employ desktop, mobile, and virtual reality devices to collaboratively explore software visualizations. We conducted two preliminary user studies in which subjects evaluated our VR and AR modes after solving common program comprehension tasks.
Results:
The VR and AR environments can be suitable for collaborative work in the context of program comprehension. The analyzed feedback revealed problems regarding the usability, e.g., readability of visualized entities and performance issues. Nonetheless, our approach can be seen as a blueprint for other researchers to replicate or build upon these modes and results.
Conclusions:
ExplorViz’s multi-user modes are our approach to enable heterogeneous 
collaborative software
 visualizations. The preliminary results indicate the need for more research regarding effectiveness, usability, and acceptance. Unlike related work, we approach the latter by introducing a multi-user augmented reality environment for software visualizations based on off-the-shelf mobile devices.",Information and Software Technology,18 Mar 2025,6.0,"The web-based approach for collaborative program comprehension using extended reality devices presents an interesting concept for software visualization research, despite needing more research on usability and acceptance."
https://www.sciencedirect.com/science/article/pii/S095058492200132X,Collaborative program comprehension via software visualization in extended reality,November 2022,"Program comprehension, Software visualization, City metaphor, Extended reality, Virtual reality, Augmented reality",Alexander=Krause-Glau: akr@informatik.uni-kiel.de; Malte=Hansen: Not Found; Wilhelm=Hasselbring: Not Found,"Abstract
Context:
In software visualization research, various approaches strive to create 
immersive environments
 by employing 
extended reality
 devices. In that context, only few research has been conducted on the effect of collaborative, i.e., multi-user, extended reality environments.
Objective:
We present our journey toward a web-based approach to enable (location-independent) collaborative 
program comprehension
 using desktop, virtual reality, and mobile 
augmented reality
 devices.
Method:
We designed and implemented three multi-user modes in our web-based live trace visualization tool ExplorViz. Users can employ desktop, mobile, and virtual reality devices to collaboratively explore software visualizations. We conducted two preliminary user studies in which subjects evaluated our VR and AR modes after solving common program comprehension tasks.
Results:
The VR and AR environments can be suitable for collaborative work in the context of program comprehension. The analyzed feedback revealed problems regarding the usability, e.g., readability of visualized entities and performance issues. Nonetheless, our approach can be seen as a blueprint for other researchers to replicate or build upon these modes and results.
Conclusions:
ExplorViz’s multi-user modes are our approach to enable heterogeneous 
collaborative software
 visualizations. The preliminary results indicate the need for more research regarding effectiveness, usability, and acceptance. Unlike related work, we approach the latter by introducing a multi-user augmented reality environment for software visualizations based on off-the-shelf mobile devices.",Information and Software Technology,18 Mar 2025,6.0,"The web-based approach for collaborative program comprehension using extended reality devices presents an interesting concept for software visualization research, despite needing more research on usability and acceptance."
https://www.sciencedirect.com/science/article/pii/S0950584922001471,Automatically repairing tensor shape faults in deep learning programs,November 2022,Not Found,Dangwei=Wu: wudangwei@sjtu.edu.cn; Beijun=Shen: bjshen@sjtu.edu.cn; Yuting=Chen: chenyt@sjtu.edu.cn; He=Jiang: jianghe@dlut.edu.cn; Lei=Qiao: fly2moon@163.com,"Abstract
Context:
Software developers frequently invoke 
deep learning
 (DL) APIs to incorporate 
artificial intelligence
 solutions into software systems. However, misuses of these APIs can cause various DL faults, such as 
tensor shape faults
. Tensor shape faults occur when restriction conditions of operations are not met; they are prevalent in practice, leading to many system crashes. Meanwhile, researchers and engineers still face a strong challenge in detecting tensor shape faults — static techniques incur heavy overheads in defining detection rules, and the only dynamic technique requires human engineers to rewrite APIs for tracking shape changes.
Objective:
This paper introduces a novel technique that leverages 
machine learning
 to detect tensor shape faults, and as well uses patterns to repair faults detected.
Methods:
We first construct SFData, a set of 146 buggy programs with 
crashing tensor shape faults
 (i.e., those causing programs to crash). We also conduct an empirical study on crashing tensor shape faults, categorizing them into four types and revealing twelve repair patterns. Then we propose Tensfa2, an automated approach to detecting and repairing crashing tensor shape faults. Tensfa2 employs a 
machine learning method
 to learn from crash messages and 
decision trees
 to detect tensor shape faults. Next, Tensfa2 tracks shape properties by a customized Python 
debugger
, analyzes their 
data dependences
, and uses the twelve patterns to generate patches. Tensfa2 is an extended version of Tensfa—our previous approach presented at ISSRE’21. Its performance is enhanced by two techniques: a search-based method for repairing shape value faults, and a bundle of three ranking strategies for prioritizing the repair patterns.
Results:
Tensfa2 is evaluated on SFData and IslamData (another dataset of tensor shape faults). The results show the effectiveness of Tensfa2. In particular, Tensfa2 achieves an F1-score of 96.88% in detecting the faults and repairs 82 out of 146 buggy programs in SFData.
Conclusion:
We believe that repair patches generated by our approach will help engineers fix their 
deep learning
 programs much more efficiently, saving their time and efforts.",Information and Software Technology,18 Mar 2025,9.0,"The novel technique leveraging machine learning to detect and repair tensor shape faults in deep learning programs shows significant impact in improving efficiency for software developers, with impressive results in fault detection and program repairs."
https://www.sciencedirect.com/science/article/pii/S0950584922001033,Find potential partners: A GitHub user recommendation method based on event data,October 2022,Not Found,Shuotong=Bai: Not Found; Lei=Liu: Not Found; Huaxiao=Liu: liuhuaxiao@jlu.edu.cn; Mengxi=Zhang: Not Found; Chenkun=Meng: Not Found; Peng=Zhang: Not Found,"Abstract
Context:
GitHub has attracted much popularity among a large number of software developers around the world and introduced the social function 
follow
 to strengthen the relationship among developers. Like other social networks, GitHub users usually follow others who are popular in the community, co-workers, or friends in real life. However, according to our investigation, more than half of GitHub users prefer to follow recently like-minded developers other than their traditional networks for communicating with timely feedback, discovering niche repositories, and attracting more active contributors to cooperate, while these users are hard to find.
Objective:
Our objective in this paper is to leverage recent activities-
Event Data
 of GitHub users and conduct a recommendation approach to help them match some recently like-minded developers to follow or reach out.
Methods:
As a first step, we conduct one empirical research—an online survey to investigate and analyze the opinions of GitHub users whether they are willing to follow others with similar recent events and which kind of events they will focus on during the follow process. Regarding the results from our survey, we partition 12 types of events focused by participants into three 
Event
 sets of 
Communication
, 
Exploration
, and 
Cooperation
. As a second step, we collect 
Event Data
 of 12,713 GitHub users who participated in repositories written in python and build a time-based multi-dimensional recommendation approach based on a calculating vector-similarity method, a 
clustering approach
, and a 
deep learning model
.
Results and Conclusion:
The experimental results show that our approach achieves an improvement of 607.64%, 564.59%, and 599.19% on average compared with two baselines in terms of 
P
r
e
c
i
s
i
o
n
@
N
, 
R
e
c
a
l
l
@
N
, and 
F
1
−
S
c
o
r
e
@
N
. Such a series of experiments have proved that our method is effective and feasible.",Information and Software Technology,18 Mar 2025,6.0,"The recommendation approach for matching like-minded developers on GitHub can potentially benefit early-stage ventures by improving communication and cooperation, but the focus on GitHub users may limit its impact."
https://www.sciencedirect.com/science/article/pii/S0950584922001033,Find potential partners: A GitHub user recommendation method based on event data,October 2022,Not Found,Shuotong=Bai: Not Found; Lei=Liu: Not Found; Huaxiao=Liu: liuhuaxiao@jlu.edu.cn; Mengxi=Zhang: Not Found; Chenkun=Meng: Not Found; Peng=Zhang: Not Found,"Abstract
Context:
GitHub has attracted much popularity among a large number of software developers around the world and introduced the social function 
follow
 to strengthen the relationship among developers. Like other social networks, GitHub users usually follow others who are popular in the community, co-workers, or friends in real life. However, according to our investigation, more than half of GitHub users prefer to follow recently like-minded developers other than their traditional networks for communicating with timely feedback, discovering niche repositories, and attracting more active contributors to cooperate, while these users are hard to find.
Objective:
Our objective in this paper is to leverage recent activities-
Event Data
 of GitHub users and conduct a recommendation approach to help them match some recently like-minded developers to follow or reach out.
Methods:
As a first step, we conduct one empirical research—an online survey to investigate and analyze the opinions of GitHub users whether they are willing to follow others with similar recent events and which kind of events they will focus on during the follow process. Regarding the results from our survey, we partition 12 types of events focused by participants into three 
Event
 sets of 
Communication
, 
Exploration
, and 
Cooperation
. As a second step, we collect 
Event Data
 of 12,713 GitHub users who participated in repositories written in python and build a time-based multi-dimensional recommendation approach based on a calculating vector-similarity method, a 
clustering approach
, and a 
deep learning model
.
Results and Conclusion:
The experimental results show that our approach achieves an improvement of 607.64%, 564.59%, and 599.19% on average compared with two baselines in terms of 
P
r
e
c
i
s
i
o
n
@
N
, 
R
e
c
a
l
l
@
N
, and 
F
1
−
S
c
o
r
e
@
N
. Such a series of experiments have proved that our method is effective and feasible.",Information and Software Technology,18 Mar 2025,6.0,"Similar to Abstract 151, the recommendation approach for GitHub users can be beneficial for startups by enhancing collaboration, but the niche focus on GitHub users may limit its broader practical value."
https://www.sciencedirect.com/science/article/pii/S0950584922000994,How higher order mutant testing performs for deep learning models: A fine-grained evaluation of test effectiveness and efficiency improved from second-order mutant-classification tuples,October 2022,Not Found,Yanhui=Li: Not Found; Weijun=Shen: Not Found; Tengchao=Wu: Not Found; Lin=Chen: lchen@nju.edu.cn; Di=Wu: Not Found; Yuming=Zhou: Not Found; Baowen=Xu: Not Found,"Abstract
Context:
Given the prevalence of 
Deep Learning
 (DL) models in 
daily life
, it is crucial to guarantee their reliability by 
DL
 testing. Recently, researchers have adapted mutation testing into 
DL
 testing to measure the test power of test sets. The bottleneck of DL mutation testing is the expensive costs of generating a large number of mutants.
Objective:
We want to study whether the traditional ideology of “Higher Order” and “Strongly Subsuming” in Higher Order Mutant Testing is still applicable for DL mutation testing, i.e., whether they can be used to optimize DL mutation testing by reducing the number of mutants.
Method:
We propose a new mutation testing framework supporting a fine-grained evaluation of test power, called mutant-classification tuples which consist of mutants and classification categories. Based on mutant-classification tuples, we construct First Order (FOTs) and Higher (Second) Order Tuples (HOTs) by applying 
mutation operators
 twice, and search for “Strongly Subsuming” HOTs (SSHOTs) from HOTs.
Results:
The experimental results conducted on four widely used datasets and five DL model structures tell us that (1) we can find a considerable number of SSHOTs (from 720 to 25,840 in five models) which can greatly reduce the 
original set
 of FOTs (with the reduction ratio from 28.69% to 91.97% in our studied DL models). (2) The reduced tuples by SSHOTs can perform very well in test case selection, since the selected test set is almost the same effective (i.e., with almost the same mutation score) and much more efficient (i.e., with a smaller test size, which is more than 50% reduced) for most studied DL models.
Conclusions:
Our study shows that “Higher Order” and “Strongly Subsuming” are useful to optimize DL mutation testing, i.e., SSHOTs can be introduced to reduce the number of mutants and test cases.",Information and Software Technology,18 Mar 2025,7.0,"Optimizing DL mutation testing using 'Higher Order' and 'Strongly Subsuming' concepts can have practical implications for early-stage ventures working with DL models, potentially improving efficiency and effectiveness in testing."
https://www.sciencedirect.com/science/article/pii/S0950584922001082,An empirical study of IoT security aspects at sentence-level in developer textual discussions,October 2022,Not Found,Nibir=Mandal: Not Found; Gias=Uddin: gias.uddin@ucalgary.ca,"Abstract
Context:
IoT
 is a rapidly emerging paradigm that now encompasses almost every aspect of our modern life. As such, ensuring the security of 
IoT devices
 is crucial. 
IoT
 devices can differ from traditional computing (e.g., low power, storage, computing), thereby the design and implementation of proper security measures can be challenging in 
IoT devices
. We observed that IoT developers discuss their security-related challenges in developer forums like Stack Overflow (SO). However, we find that IoT security discussions can also be buried inside non-security discussions in SO.
Objective:
In this paper, we aim to understand the challenges IoT developers face while applying security practices and techniques to IoT devices. We have two goals: (1) Develop a model that can automatically find security-related IoT discussions in SO, and (2) Study the model output (i.e., the security discussions) to learn about IoT developer security-related challenges.
Methods:
First, we download all 53K posts from StackOverflow (SO) that contain discussions about various IoT devices, tools, and techniques. Second, we manually labeled 5,919 sentences from 53K posts as 1 or 0 (i.e., whether they contain a 
security aspect
 or not). Third, we then use this benchmark to investigate a suite of 
deep learning
 transformer models. The best performing model is called SecBot. Fourth, we apply SecBot on the entire 53K posts and find around 30K sentences labeled as security. Fifth, we apply 
topic modeling
 to the 30K security-related sentences labeled by SecBot. Then we label and categorize the topics. Sixth, we analyze the evolution of the topics in SO.
Results:
We found that (1) SecBot is based on the retraining of the 
deep learning model
 RoBERTa. SecBot offers the best F1-Score of .935, (2) there are six error categories in misclassified samples by SecBot. SecBot was mostly wrong when the keywords/contexts were ambiguous (e.g., ‘gateway’ can be a 
security gateway
 or a simple gateway), (3) there are 9 security topics grouped into three categories: Software, Hardware, and Network, and (4) the highest number of topics belongs to software security, followed by 
network security
 and hardware security.
Conclusion:
IoT researchers and vendors can use SecBot to collect and analyze security-related discussions from developer discussions in SO. The analysis of nine security-related topics can guide major IoT stakeholders like IoT Security Enthusiasts, Developers, Vendors, Educators, and Researchers in the rapidly emerging IoT ecosystems.",Information and Software Technology,18 Mar 2025,8.0,"Developing a model like SecBot to automatically identify security-related IoT discussions in developer forums can significantly benefit startups in ensuring the security of IoT devices, providing valuable insights into challenges faced by IoT developers."
https://www.sciencedirect.com/science/article/pii/S0950584922001069,On the effectiveness of testing sentiment analysis systems with metamorphic testing,October 2022,Not Found,Mingyue=Jiang: mjiang@zstu.edu.cn; Tsong Yueh=Chen: tychen@swin.edu.au; Shuai=Wang: shuaiw@cse.ust.hk,"Abstract
Context:
Metamorphic testing (MT) has been successfully applied to a wide scope of software systems. In these applications, the testing results of MT form the basis for drawing conclusions about the target system’s performance. Therefore, the effectiveness of MT is crucial to the trustfulness of the derived conclusions.
Objective:
However, due to the nature of MT, its effectiveness can be affected by various factors. Despite of MT’s success, it is still important to study its effectiveness under different application contexts.
Method:
To investigate the effectiveness of MT, we focus on an important aspect, namely, false satisfactions (which are satisfactions of metamorphic relations that involve at least one failing execution), and revisit the application of MT to 
sentiment analysis
 (SA) systems. An in-depth analysis of the essence of false satisfactions reveals the situations where they would occur, and how they would affect the effectiveness of MT. Furthermore, 20 metamorphic relations (MRs) are identified for supporting a user-oriented evaluation of SA systems.
Results:
The occurrence rates of false satisfactions are reported with respect to four SA systems. For the majority of MRs, false satisfactions account for about 20% to 50% of all MR satisfactions, suggesting that false satisfactions occur quite frequently in the evaluation of SA systems. It is also demonstrated that such high occurrence rates of false satisfactions adversely affect the users’ selection of SA systems.
Conclusion:
Our analysis reveals that without considering the occurrence of false satisfactions, MT may overestimate the system’s conformance to the relevant MR. Furthermore, our experiments empirically show that conclusions derived from MT can be adversely affected when there are many false satisfactions. Our findings will help the MT community to adopt a more fair and reliable way of using the test outcomes of MT, and can also inspire the development of solid foundations for MT.",Information and Software Technology,18 Mar 2025,7.0,"Studying the effectiveness of Metamorphic Testing in different application contexts, such as sentiment analysis systems, can provide essential insights for startups looking to ensure the trustworthiness of their software systems, leading to more reliable testing outcomes."
https://www.sciencedirect.com/science/article/pii/S095058492200101X,Approaches to manage the user experience process in Agile software development: A systematic literature review,October 2022,"User experience management, UX process, User experience, UX, Usability, HCI, Agile methods, Agile, Systematic literature review",Andreas=Hinderks: andreas.hinderks@iwt2.org; Francisco José=Domínguez Mayo: fjdominguez@us.es; Jörg=Thomaschewski: joerg.thomaschewski@hs-emden-leer.de; María José=Escalona: mjescalona@us.es,"Abstract
Context:
Software development companies use Agile methods to develop their products or services efficiently and in a goal-oriented way. But this alone is not enough to satisfy user demands today. It is much more important nowadays that a product or service should offer a great 
user experience
 — the user wants to have some positive user experience while interacting with the product or service.
Objective:
An essential requirement is the integration of user experience methods in 
Agile software development
. Based on this, the development of positive user experience must be managed. We understand management in general as a combination of a goal, a strategy, and resources. When applied to UX, user experience management consists of a UX goal, a UX strategy, and UX resources.
Method:
We have conducted a systematic literature review (SLR) to analyse suitable approaches for managing user experience in the context of Agile software development.
Results:
We have identified 49 relevant studies in this regard. After analysing the studies in detail, we have identified different primary approaches that can be deemed suitable for UX management. Additionally, we have identified several UX methods that are used in combination with the primary approaches.
Conclusions:
However, we could not identify any approaches that directly address UX management. There is also no general definition or common understanding of UX management. To successfully implement UX management, it is important to know what UX management actually is and how to measure or determine successful UX management.",Information and Software Technology,18 Mar 2025,7.0,"This abstract addresses the importance of integrating user experience methods in Agile software development, which can have a significant impact on European early-stage ventures by improving user satisfaction and product quality."
https://www.sciencedirect.com/science/article/pii/S0950584922000921,The role of awareness and gamification on technical debt management,October 2022,Not Found,Yania=Crespo: yania@infor.uva.es; Carlos=López-Nozal: clopezno@ubu.es; Raúl=Marticorena-Sánchez: rmartico@ubu.es; Margarita=Gonzalo-Tasis: marga@infor.uva.es; Mario=Piattini: Mario.Piattini@uclm.es,"Abstract
Context:
Managing technical debt and developing easy-to-maintain software are very important aspects for technological companies. Integrated development environments (IDEs) and static measurement and analysis tools are used for this purpose. Meanwhile, 
gamification
 also is gaining popularity in professional settings, particularly in software development.
Objective:
This paper aims to analyse the improvement in technical debt indicators due to the use of techniques to raise developers’ awareness of technical debt and the introduction of 
gamification
 into technical debt management.
Method:
A quasi-experiment that manipulates a training environment with three different treatments was conducted. The first treatment was based on training in the concept of technical debt, bad smells and refactoring, while using multiple plugins in IDEs to obtain reports on quality indicators of both the code and the tests. The second treatment was based on enriching previous training with the use of 

 to continuously raise awareness of technical debt. The third was based on adding a 
gamification
 component to technical debt management based on a contest with a top ten ranking. The results of the first treatment are compared with the use of 

 for continuously raising developers’ awareness of technical debt; while the possible effect of 
gamification
 is compared with the results of the previous treatment.
Results:
It was observed that continuously raising awareness using a technical debt management tool, such as 

 , significantly improves the technical debt indicators of the code developed by the participants versus using multiple code and test quality checking tools. On the other hand, incorporating some kind of competition between developers by defining a contest and creating a ranking does not bring about any significant differences in the technical debt indicators.
Conclusion:
Investment in staff training through tools to raise developers’ awareness of technical debt and incorporating it into continuous integration pipelines does bring improvements in technical debt management.",Information and Software Technology,18 Mar 2025,8.0,"This abstract explores the use of gamification and tools to raise developers' awareness of technical debt, which can benefit startups in improving software quality and maintenance."
https://www.sciencedirect.com/science/article/pii/S0950584922001185,Can test input selection methods for deep neural network guarantee test diversity? A large-scale empirical study,October 2022,Not Found,Chunyu=Zhao: 2010320004@stmail.ntu.edu.cn; Yanzhou=Mu: 2019218009@tju.edu.cn; Xiang=Chen: xchencs@ntu.edu.cn; Jingke=Zhao: ke1206371563@gmail.com; Xiaolin=Ju: ju.xl@ntu.edu.cn; Gan=Wang: wg_98@tju.edu.cn,"Abstract
Context:
Recently, various methods on test input selection for deep 
neural network
 (TIS-DNN) have been proposed. These methods can effectively reduce the labeling cost by selecting a subset from the original test inputs, which can still accurately estimate the performance (such as accuracy) of the target 
DNN models
.
Objective:
Previous studies on TIS-DNN mainly focused on the performance on all the classes. However, the selected subset may miss the coverage of some classes or decrease the performance on some classes, which will reduce the test diversity of the original test inputs.
Methods:
Therefore, we conducted a large-scale empirical study to investigate whether previous TIS-DNN methods can guarantee test diversity in the subset. In our study, we selected five state-of-the-art TIS-DNN methods: SRS, 
CSS
, CES, DeepReduce and PACE. Then we selected 18 pairs of 
DNN models
 and the corresponding test inputs from seven popular DNN datasets.
Results:
Our experimental results can be summarized as follows. (1) Previous TIS-DNN methods can guarantee the performance on all the classes. However, these methods have a 
negative impact
 on the test diversity and the performance on each class is not satisfactory. (2) Reducing the performance 
estimation error
 on each class can help reduce the 
estimation error
 on the test adequacy of the original inputs based on DNN-based coverage criteria (especially for the criterion NC and the criterion TKNC). (3) There still exists great room for 
performance improvement
 (i.e., 7.637% improvement on all the classes and 12.833% improvement on each class) after comparing the TIS-DNN method PACE with approximately optimal solutions.
Conclusion:
The above experimental findings implicate there is still a long way for the TIS-DNN issue to go. Given this, we present observations about the road ahead for this issue.",Information and Software Technology,18 Mar 2025,6.0,"The study on test input selection for deep neural networks provides insights into improving performance estimation, but it may not have a direct practical impact on European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001203,A three-stage transfer learning framework for multi-source cross-project software defect prediction,October 2022,"Transfer learning, Cross-project defect prediction, Source selection, Multi-source utilization, 3SW-MSTL",Jiaojiao=Bai: Not Found; Jingdong=Jia: jiajingdong@buaa.edu.cn; Luiz Fernando=Capretz: Not Found,"Abstract
Context
Transfer learning techniques have been proved to be effective in the field of Cross-project defect prediction (CPDP). However, some questions still remain. First, the conditional distribution difference between source and target projects has not been considered. Second, facing multiple source projects, most studies only rarely consider the issues of source selection and multi-source data utilization; instead, they use all available projects and merge multi-source data together to obtain one final dataset.
Objective
To address these issues, in this paper, we propose a three-stage weighting framework for multi-source 
transfer learning
 (3SW-MSTL) in CPDP. In stage 1, a source selection strategy is needed to select a suitable number of source projects from all available projects. In stage 2, a transfer technique is applied to minimize marginal differences. In stage 3, a multi-source data utilization scheme that uses conditional distribution information is needed to help guide researchers in the use of multi-source transferred data.
Method
First, we have designed five source selection strategies and four multi-source utilization schemes and chosen the best one to be used in stage 1 and 3 in 3SW-MSTL by comparing their influences on prediction performance. Second, to validate the performance of 3SW-MSTL, we compared it with four multi-source and six single-source CPDP methods, a baseline within-project defect prediction (WPDP) method, and two unsupervised methods on the data from 30 widely used open-source projects.
Results
Through experiments, bellwether and weighted vote are separately chosen as a source selection strategy and a multi-source utilization scheme used in 3SW-MSTL. And, our results indicate that 3SW-MSTL outperforms four multi-source, six single-source CPDP methods and two unsupervised methods. And, 3SW-MSTL is comparable to the WPDP method.
Conclusion
The proposed 3SW-MSTL model is more effective for considering the two issues mentioned before.",Information and Software Technology,18 Mar 2025,9.0,The proposed three-stage weighting framework for multi-source transfer learning in Cross-project defect prediction can greatly benefit European early-stage ventures by improving prediction performance and addressing key issues.
https://www.sciencedirect.com/science/article/pii/S0950584922001197,System and software architecting harmonization practices in ultra-large-scale systems of systems: A confirmatory case study,October 2022,"Systems of systems, SoS architecting, Confirmatory case study, Empirical software engineering, Scientific instruments, Qualitative research",Héctor=Cadavid: h.f.cadavid.rengifo@rug.nl; Vasilios=Andrikopoulos: v.andrikopoulos@rug.nl; Paris=Avgeriou: p.avgeriou@rug.nl; P. Chris=Broekema: broekema@astron.nl,"Abstract
Context:
The challenges posed by the architecting of System of Systems (SoS) has motivated a significant number of research efforts in the area. However, literature is lacking when it comes to the interplay between the disciplines involved in the 
architecting process
, a key factor in addressing these challenges.
Objective:
This paper aims to contribute to this line of research by confirming and extending previously characterized architecting harmonization practices from Systems and 
Software Engineering
, adopted in an ultra-large-scale SoS.
Methods:
We conducted a confirmatory 
case study
 on the Square-Kilometre Array (SKA) project to evaluate and extend the findings of our exploratory case on the LOFAR/LOFAR2.0 radio-telescope projects. In doing so, a pre-study was conducted to map the findings of the previous study with respect to the SKA context. A survey was then designed, through which the views of 46 SKA engineers were collected and analyzed.
Results:
The study confirmed in various degrees the four practices identified in the exploratory case, and provided further insights about them: (1) the friction between disciplines caused by long-term 
system requirements
, and how they can be ameliorated through intermediate, short-term requirements; (2) the way design choices with a cross-cutting impact on multiple agile teams have an indirect impact on the 
system architecture
; (3) how these design choices are often caused by the criteria that guided early system decomposition; (4) the seemingly 
recurrent
 issue with the lack of details about the dynamic elements of the interfaces; and (5) the use of machine-readable 
interface specifications
 for aligning hardware/software development processes.
Conclusions:
The findings of this study and its predecessor support the importance of a cross-disciplinary view in the Software Engineering 
research agenda
 in SoS as a whole, not to mention their value as a convergence point for research on SoS architecting from the Systems and Software Engineering standpoints.",Information and Software Technology,18 Mar 2025,7.0,"The study on architecting practices in System of Systems contributes valuable insights, but the practical impact on European early-stage ventures may be limited without direct implementation strategies."
https://www.sciencedirect.com/science/article/pii/S0950584922001215,Keyword-guided abstractive code summarization via incorporating structural and contextual information,October 2022,Not Found,Wuyan=Cheng: wuyanc@mails.ccnu.edu.cn; Po=Hu: phu@mail.ccnu.edu.cn; Shaozhi=Wei: wsz@mails.ccnu.edu.cn; Ran=Mo: moran@mail.ccnu.edu.cn,"Abstract
Context:
Source code
 summarization is a crucial yet far from settled task for describing structured code snippets in natural language. High-quality code summaries could effectively facilitate 
program comprehension
 and software maintenance. A good code summary is supposed to have the following characteristics: complete information, correct meaning, and consistent description. In recent years, numerous approaches have been proposed for code summarization, but it is still very challenging for developers to automatically learn the complex semantics from the source code and generate complete, correct and consistent code summaries.
Objective:
In this paper, we propose 
KGCodeSum
, a novel keyword-guided abstractive code summarization approach that incorporates structural and contextual information.
Methods:
To improve summaries’ quality, we leverage both the structural 
information embedded
 in code itself and the contextual information from related code snippets. Meanwhile, we make use of keywords to guide summaries’ generation to guarantee the code summaries contain key information. Finally, we propose a new dynamic vocabulary strategy which can effectively resolve the UNK problems in code summaries.
Results:
Through our evaluation on the large-scale benchmark datasets with 2.1 million java method-comment pairs and 1.1 million C/C++ function-summary pairs, We have observed that our approach could generate better code summaries than existing state-of-the-art approaches in terms of completeness, correctness and consistency. In addition, we also find that incorporating the dynamic vocabulary strategy into our approach could significantly save time and space in the model training process.
Conclusion:
Our 
KGCodeSum
 approach could effectively generate code summaries.",Information and Software Technology,18 Mar 2025,8.0,"The KGCodeSum approach addresses a crucial task in software development, improving the quality of code summaries. The incorporation of structural and contextual information, along with a dynamic vocabulary strategy, results in better code summaries than existing approaches. This has a practical value for developers in understanding and maintaining code."
https://www.sciencedirect.com/science/article/pii/S0950584922001252,Test case recommendation based on balanced distance of test targets,October 2022,Not Found,Weisong=Sun: weisongsun@smail.nju.edu.cn; Quanjun=Zhang: quanjun.zhang@smail.nju.edu.cn; Chunrong=Fang: fangchunrong@nju.edu.cn; Yuchen=Chen: yuc.chen@outlook.com; Xingya=Wang: xingyawang@outlook.com; Ziyuan=Wang: wangziyuan@njupt.edu.cn,"Abstract
Context:
Unit testing has been widely regarded as an effective technique to ensure software quality. Writing unit test cases is time-consuming and requires developers to have abundant knowledge and experience. Automated test case generation, a promising technology for liberating developers and improving test efficiency, currently performs not satisfactory in real-world projects. As a complement, test case recommendation (TCR) has been receiving the attention of researchers. TCR can improve the efficiency of test case writing by recommending test case code to developers for their reference and reuse. The overarching idea of TCR techniques is that two similar test targets can reuse each other’s test cases.
Objective:
Existing TCR techniques either fail to recommend relevant test cases for a given test target or are vulnerable to the mismatch of test target signatures. Our objective is to effectively and robustly recommend relevant test cases for test targets given by developers.
Method:
In this paper, we propose a novel TCR technique that measures the similarity of test targets based on a balanced distance. The balanced distance integrates the distances on code snippets and comments, making the measurement of test target similarity more accurate and robust. In particular, we take the distance on control flows into account to compensate for the shortcomings in measuring the similarity only based on the literal text of code snippets. As a proof-of-concept application, we implement a test case recommender named BDTCR.
Results:
We construct a test case corpus containing more than 13,000 test cases collected from GitHub. Based on this corpus, we conduct comprehensive experiments to evaluate the effectiveness and usefulness of BDTCR. The experimental results show that BDTCR can effectively recommend relevant test cases and outperform the state-of-the-art techniques.
Conclusion:
It can be concluded that (1) BDTCR is an effective TCR technique; (2) BDTCR is a robust TCR technique that can effectively resist the interference of the mismatch of test target signatures; (3) BDTCR is practical to help developers write test cases quickly and effectively.",Information and Software Technology,18 Mar 2025,7.0,"The BDTCR technique aims to recommend relevant test cases for developers, improving test efficiency. By measuring the similarity of test targets based on a balanced distance, BDTCR outperforms existing techniques. This has a moderate impact on improving software quality by facilitating test case writing."
https://www.sciencedirect.com/science/article/pii/S0950584922001240,Microservice extraction based on knowledge graph from monolithic applications,October 2022,Not Found,Zhiding=Li: Not Found; Chenqi=Shang: Not Found; Jianjie=Wu: wujianjie@hust.edu.cn; Yuan=Li: lyjingmen@sina.com,"Abstract
Context
Re-architecting monolithic systems with microservice architecture is a common trend. However, determining the ""optimal"" size of individual services during microservice extraction has been a challenge in software engineering. Common limitations of the literature include not being reasonable enough to be put into practical application; relying too much on human experience; neglection of the impact of hardware environment on the performance.
Objective
To address these problems, this paper proposes a novel method based on knowledge-graph to support the extraction of microservices during the initial phases of re-architecting existing applications.
Method
According to the microservice extraction method based on the AKF principle which is a widely practiced microservice design principle in the industry, four kinds of entities and four types of entity-entity relationships are designed and automatically extracted from specification and design artifacts of the monolithic application to build the knowledge graph. A constrained Louvain algorithm is proposed to identify microservice candidates.
Results
Our approach is tested based on two open-source projects with the other three typical methods: the domain-driven design-based method, the similarity calculation-based method, and the graph clustering-based method . Conducted experiments show that our method performs well concerning all the evaluation metrics.",Information and Software Technology,18 Mar 2025,6.0,"The proposed method based on knowledge-graph for microservice extraction addresses a common challenge in software engineering. By automating the extraction of microservices, the method is practical and aims to overcome limitations of existing techniques. This has a moderate impact on improving software architecture."
https://www.sciencedirect.com/science/article/pii/S0950584922001239,A comparative study on vectorization methods for non-functional requirements classification,October 2022,Not Found,Pattara=Leelaprute: pattara.l@ku.ac.th; Sousuke=Amasaki: amasaki@cse.oka-pu.ac.jp,"Abstract
Context:
Identifying non-functional requirements (NFRs) and their categories at the early phase is crucial for analysts to design software systems and recognize constraints. Automatic non-functional requirements classification methods have been studied for reducing the costs of that labor-intensive task. Our previous study focused on the differences among 
vectorization
 methods that converted requirements written in natural language into numerical vectors for classification. It had some limitations regarding the number of datasets used, the types of 
vectorization
 methods supporting pre-trained data, and the performance evaluation procedure.
Objective:
To examine whether different vectorization methods lead to differences in the classification performance of NFRs and their categories with extended settings.
Methods:
Comparative experiments
 were conducted with five 
open data
. Nine vectorization methods, including ones with pre-trained data and four 
supervised classification
 methods, were supplied. Performance was evaluated with AUC and Scott-Knott 
ESD
 test.
Results:
Some advanced methods could achieve better performance than traditional ones when combined with some classifiers. The use of pre-trained data was useful for some categories.
Conclusion:
It is beneficial to consider using some combinations of vectorization methods and classifiers for classifying non-functional requirements categories.",Information and Software Technology,18 Mar 2025,5.0,"The study on classifying non-functional requirements based on vectorization methods provides insights into improving the efficiency of requirement classification. While the findings are beneficial, the impact on European early-stage ventures may be limited compared to other abstracts."
https://www.sciencedirect.com/science/article/pii/S0950584922001021,The journey to technical excellence in agile software development,October 2022,"Agile software development, Software development methods, Technical excellence, Agile principles",Adam=Alami: adaa@itu.dk; Oliver=Krancher: Not Found; Maria=Paasivaara: Not Found,"Abstract
Context:
Technical excellence is a nebulous term in 
agile software development
. This vagueness is risky because it may lead to misunderstandings and to agile implementations that may overlook a key principle of 
agile development
.
Objective:
This study investigates how agile practitioners interpret the concept of technical excellence brought up in Principle 9 of the 
Agile manifesto
. Moreover, we investigate how agile practitioners put the concept into practice and what conditions facilitate putting technical excellence into practice.
Methods:
We conducted semi-structured interviews with twenty agile practitioners, coded the data inductively, and performed two sessions to validate the emerging findings.
Results:
We find that technical excellence is first and foremost a mindset that is underpinned by continuous attention to sustainable code, continuous learning, and teamwork. Fostering technical excellence requires the adoption of design and development practices, such as continuous architecting, and is supported by continuous learning. We also identify three enabling conditions for technical excellence: Leadership support, customer buy-in, and psychological safety. These enablers provide teams with leeway to nurture their pursuit of technical excellence.
Conclusion:
Our findings highlight the key role of people-based strategies in promoting technical excellence in agile software development. They show that the attainment of technical excellence does not only involve technical practices. On the contrary, it relies on social and 
organizational support
 and, most importantly, a mindset.",Information and Software Technology,18 Mar 2025,4.0,"The investigation on technical excellence in agile software development offers valuable insights into fostering a mindset of continuous attention to sustainable code. While important for software development, the practical impact on early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922001094,Taxonomy of bug tracking process smells: Perceptions of practitioners and an empirical analysis,October 2022,Not Found,Khushbakht Ali=Qamar: ali.qamar@bilkent.edu.tr; Emre=Sülün: emre.sulun@bilkent.edu.tr; Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr,"Abstract
Context:
While there is no consensus on a formally specified bug tracking process, some certain rules and best practices for an optimal bug tracking process are accepted by many companies and open-source software (OSS) projects. Despite slight variations between different platforms, the primary aim of all these rules and practices is to perform a more efficient bug tracking process. Practitioners’ non-compliance with the best practices not only impedes the benefits of the bug tracking process but also negatively affects the other phases of 
software development life cycle
.
Objective:
The goal of this study is to gain a better knowledge of the bad practices that occur during the bug tracking process (
bug tracking process smells
) and to perform quantitative analysis to show that these process smells exist in 
bug tracking systems
. Moreover, we want to know the perception of software practitioners related to these process smells and also observe the impact of process smells on the bug tracking process.
Methods:
Based on the results of a multivocal literature review, we analyzed 60 sources in academic and gray literature and propose a taxonomy of 12 bad practices in the bug tracking process. To quantitatively analyze these process smells, we inspected 
bug reports
 collected from eight projects which use Jira, Bugzilla, and GitHub Issues. To get an idea about the perception of practitioners about the taxonomy of bug tracking process smells, we conducted a targeted survey with 30 software practitioners. Moreover, we statistically analyzed the impact of bug tracking process smells on the resolution time and reopening count of bugs.
Results:
We observed from our empirical results that a considerable amount of bug tracking process smells exist in all projects and some of the process smell categories have statistically significant impacts on quality and speed. Survey results shows that the majority of software practitioners agree with the proposed taxonomy of BT process smells.
Conclusion:
The statistical analysis reveals that bug tracking process smells have an impact on OSS projects. The proposed taxonomy may serve as a foundation for best practices and tool support for detecting and avoiding bug tracking process smells.",Information and Software Technology,18 Mar 2025,8.0,"The study provides insights into bad practices in bug tracking processes that have a significant impact on software quality and speed, offering a proposed taxonomy to improve practices and tool support, which can benefit early-stage ventures by enhancing development efficiency."
https://www.sciencedirect.com/science/article/pii/S0950584922001094,Taxonomy of bug tracking process smells: Perceptions of practitioners and an empirical analysis,October 2022,Not Found,Khushbakht Ali=Qamar: ali.qamar@bilkent.edu.tr; Emre=Sülün: emre.sulun@bilkent.edu.tr; Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr,"Abstract
Context:
While there is no consensus on a formally specified bug tracking process, some certain rules and best practices for an optimal bug tracking process are accepted by many companies and open-source software (OSS) projects. Despite slight variations between different platforms, the primary aim of all these rules and practices is to perform a more efficient bug tracking process. Practitioners’ non-compliance with the best practices not only impedes the benefits of the bug tracking process but also negatively affects the other phases of 
software development life cycle
.
Objective:
The goal of this study is to gain a better knowledge of the bad practices that occur during the bug tracking process (
bug tracking process smells
) and to perform quantitative analysis to show that these process smells exist in 
bug tracking systems
. Moreover, we want to know the perception of software practitioners related to these process smells and also observe the impact of process smells on the bug tracking process.
Methods:
Based on the results of a multivocal literature review, we analyzed 60 sources in academic and gray literature and propose a taxonomy of 12 bad practices in the bug tracking process. To quantitatively analyze these process smells, we inspected 
bug reports
 collected from eight projects which use Jira, Bugzilla, and GitHub Issues. To get an idea about the perception of practitioners about the taxonomy of bug tracking process smells, we conducted a targeted survey with 30 software practitioners. Moreover, we statistically analyzed the impact of bug tracking process smells on the resolution time and reopening count of bugs.
Results:
We observed from our empirical results that a considerable amount of bug tracking process smells exist in all projects and some of the process smell categories have statistically significant impacts on quality and speed. Survey results shows that the majority of software practitioners agree with the proposed taxonomy of BT process smells.
Conclusion:
The statistical analysis reveals that bug tracking process smells have an impact on OSS projects. The proposed taxonomy may serve as a foundation for best practices and tool support for detecting and avoiding bug tracking process smells.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584922001227,Trace visualization within the Software City metaphor: Controlled experiments on program comprehension,October 2022,"Trace visualization, Software city, Program comprehension, Aggregation, Heatmap, Root cause analysis",Veronika=Dashuber: veronika.dashuber@qaware.de; Michael=Philippsen: michael.philippsen@fau.de,"Abstract
Context:
Especially with the rise of 
microservice architectures
, software is hard to understand when just the static dependencies are known. The actual call paths and the dynamic 
behavior
 of the application are hidden behind network communication. To comprehend what is going on in the software the vast amount of runtime data (traces) needs to be reduced and visualized.
Objective:
This work explores more effective visualizations to support 
program comprehension
 based on runtime data. The pure 
DynaCity
 visualization supports understanding normal behavior, while 
DynaCity


rc
 supports the comprehension of faulty behavior.
Method:
DynaCity
 uses the city metaphor for visualization. Its novel trace visualization displays dynamic dependencies as arcs atop the city. To reduce the number of traces, 
DynaCity
 aggregates all requests between the same two components into one arc whose brightness reflects both the number and the total duration of the requests. 
DynaCity
 also encodes dynamic trace data in a heatmap that it uses to light up the building: the brighter a building is, the more active it is, i.e., the more and the longer the requests are that it receives and/or spawns. An additional color scheme reflects any error/status codes among the aggregated traces. In a controlled experiment, we compare our approach with a traditional trace visualization built into the same Software City but showing all dependencies (without aggregation) as individual arcs and also disabling the heatmap. We also report on a second study that evaluates if an error-based coloring of only the arcs is sufficient or if the buildings should also be colored. We call this extension 
DynaCity


rc
 as it is meant to support 
r
oot 
c
ause analyses. The 
source code
 and the raw data of the 
quantitative evaluations
 are available from 
https://github.com/qaware/dynacity
.
Results:
We show quantitatively that a group of professional software developers who participated in a controlled experiment solve typical software comprehension tasks more correctly (11.7%) and also saved 5.83% of the total allotted time with the help of 
DynaCity
 and that they prefer it over the more traditional dynamic trace visualization. The color scheme based on HTTP error codes in 
DynaCity


rc
 supports developers when performing 
root cause analyses
, as the median of them stated that the visualization helped them 
much
 in solving the tasks. The evaluation also shows that subjects using 
DynaCity


rc
 with colored arcs and buildings find the responsible component 26.2% and the underlying root cause 33.3% more correctly than the group with just colored arcs. They also ranked it 40% more helpful to color both.
Conclusion:
The 
DynaCity
 visualization helps professional software engineers to understand the dynamic behavior of a software system better and faster. The color encoding of error codes in 
DynaCity


rc
 also helps them with 
root cause analyses
.",Information and Software Technology,18 Mar 2025,9.0,"The visualization techniques introduced in this work have shown to help professional software developers understand software systems better and faster, demonstrating improvements in comprehension tasks and root cause analyses, which can be valuable for early-stage ventures for efficient troubleshooting and development."
https://www.sciencedirect.com/science/article/pii/S0950584922001227,Trace visualization within the Software City metaphor: Controlled experiments on program comprehension,October 2022,"Trace visualization, Software city, Program comprehension, Aggregation, Heatmap, Root cause analysis",Veronika=Dashuber: veronika.dashuber@qaware.de; Michael=Philippsen: michael.philippsen@fau.de,"Abstract
Context:
Especially with the rise of 
microservice architectures
, software is hard to understand when just the static dependencies are known. The actual call paths and the dynamic 
behavior
 of the application are hidden behind network communication. To comprehend what is going on in the software the vast amount of runtime data (traces) needs to be reduced and visualized.
Objective:
This work explores more effective visualizations to support 
program comprehension
 based on runtime data. The pure 
DynaCity
 visualization supports understanding normal behavior, while 
DynaCity


rc
 supports the comprehension of faulty behavior.
Method:
DynaCity
 uses the city metaphor for visualization. Its novel trace visualization displays dynamic dependencies as arcs atop the city. To reduce the number of traces, 
DynaCity
 aggregates all requests between the same two components into one arc whose brightness reflects both the number and the total duration of the requests. 
DynaCity
 also encodes dynamic trace data in a heatmap that it uses to light up the building: the brighter a building is, the more active it is, i.e., the more and the longer the requests are that it receives and/or spawns. An additional color scheme reflects any error/status codes among the aggregated traces. In a controlled experiment, we compare our approach with a traditional trace visualization built into the same Software City but showing all dependencies (without aggregation) as individual arcs and also disabling the heatmap. We also report on a second study that evaluates if an error-based coloring of only the arcs is sufficient or if the buildings should also be colored. We call this extension 
DynaCity


rc
 as it is meant to support 
r
oot 
c
ause analyses. The 
source code
 and the raw data of the 
quantitative evaluations
 are available from 
https://github.com/qaware/dynacity
.
Results:
We show quantitatively that a group of professional software developers who participated in a controlled experiment solve typical software comprehension tasks more correctly (11.7%) and also saved 5.83% of the total allotted time with the help of 
DynaCity
 and that they prefer it over the more traditional dynamic trace visualization. The color scheme based on HTTP error codes in 
DynaCity


rc
 supports developers when performing 
root cause analyses
, as the median of them stated that the visualization helped them 
much
 in solving the tasks. The evaluation also shows that subjects using 
DynaCity


rc
 with colored arcs and buildings find the responsible component 26.2% and the underlying root cause 33.3% more correctly than the group with just colored arcs. They also ranked it 40% more helpful to color both.
Conclusion:
The 
DynaCity
 visualization helps professional software engineers to understand the dynamic behavior of a software system better and faster. The color encoding of error codes in 
DynaCity


rc
 also helps them with 
root cause analyses
.",Information and Software Technology,18 Mar 2025,,
https://www.sciencedirect.com/science/article/pii/S0950584922001057,Consolidating a common perspective on Technical Debt and its Management through a Tertiary Study,September 2022,Not Found,Helvio Jeronimo=Junior: jeronimohjr@cos.ufrj.br; Guilherme Horta=Travassos: ght@cos.ufrj.br,"Abstract
Context
Technical Debt
 (TD) contextualizes the technical decisions on shortcuts and workarounds during software development, positively and negatively influencing software evolution. However, TD still seems to confound with any issue occurring during software development, impacting its proper understanding and management in software projects.
Goal
To synthesize evidence regarding the conceptualization, characteristics, and management of TD in software projects.
Method
To undertake a tertiary study to strengthen the knowledge of TD using the principles of Grounded Theory to support qualitative analysis.
Results
Nineteen secondary studies provide evidence on TD and its management. They provided information regarding the TD's understanding (definitions and characteristics) and management (actions and technologies). Some causes, such as project constraints, technical decisions, and team members, promote different types of TD in software projects. The secondary studies also supported identifying the impacts of TD regarding project management, team members, the 
organization's business
, and internal software quality. Besides helping identify TD challenges, such studies contributed to integrating a conjectured conceptual model of TD that can support future discussions and investigations regarding TD's understanding and management.
Conclusions
The set of evidence regarding TD's understanding, actions, and technologies to manage TD can aid software practitioners in their software projects. However, it is observable an interpretation overload regarding its definition, inducing to classify any issue occurring during the software development as TD. Therefore, further discussions and investigations still represent essential steps towards consolidating a common perspective on TD and its management.",Information and Software Technology,18 Mar 2025,7.0,"The synthesis of evidence regarding Technical Debt (TD) and its management in software projects provides valuable insights for software practitioners, although there may still be challenges in defining and managing TD, the study offers a conceptual model that could guide future discussions and investigations, which can be beneficial for startups in managing technical decisions and addressing software evolution issues."
https://www.sciencedirect.com/science/article/pii/S0950584922000878,Alternatives for testing of context-aware software systems in non-academic settings: results from a Rapid Review,September 2022,"Context-aware software systems, Software testing, Rapid review, Contemporary software systems",Domenico=Amalfitano: Not Found; Andrea=Doreste: Not Found; Anna Rita=Fasolino: Not Found; Guilherme Horta=Travassos: Not Found,"Abstract
Context
Context-awareness challenges the engineering of contemporary software systems and jeopardizes their testing. The variation of context represents a relevant behavior that deepens the limitations of available software testing practices and technologies. However, such software systems are mainstream. Therefore, researchers in non-academic settings also face challenges when developing and testing contemporary software systems.
Objective
To understand how researchers deal with the variation of context when testing context-aware software systems developed in non-academic settings.
Method
To undertake a secondary study (
Rapid Review
) to uncover the necessary evidence from primary sources describing the testing of context-aware software systems outside academia.
Results
The current testing initiatives in non-academic settings aim to generate or improve test suites that can deal with the context variation and the sheer volume of test input possibilities. They mostly rely on modeling the systems' dynamic behavior and increasing computing resources to generate test inputs to achieve this. We found no evidence of test results aiming at managing context variation through the testing lifecycle process.
Conclusions
So far, the identified testing initiatives and strategies are not ready for mainstream adoption. They are all domain-specific, and while the ideas and approaches can be reproduced in distinct settings, the technologies are to be re-engineered and tailored to the context-awareness of contemporary software systems in different problem domains. Further and joint investigations in academia and experiences in non-academic settings can evolve the body of knowledge regarding the testing of contemporary software systems in the field.",Information and Software Technology,18 Mar 2025,5.0,"The abstract discusses challenges in testing context-aware software systems, but the identified testing initiatives are not ready for mainstream adoption. The focus on testing practices may have limited immediate practical value for European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000878,Alternatives for testing of context-aware software systems in non-academic settings: results from a Rapid Review,September 2022,"Context-aware software systems, Software testing, Rapid review, Contemporary software systems",Domenico=Amalfitano: Not Found; Andrea=Doreste: Not Found; Anna Rita=Fasolino: Not Found; Guilherme Horta=Travassos: Not Found,"Abstract
Context
Context-awareness challenges the engineering of contemporary software systems and jeopardizes their testing. The variation of context represents a relevant behavior that deepens the limitations of available software testing practices and technologies. However, such software systems are mainstream. Therefore, researchers in non-academic settings also face challenges when developing and testing contemporary software systems.
Objective
To understand how researchers deal with the variation of context when testing context-aware software systems developed in non-academic settings.
Method
To undertake a secondary study (
Rapid Review
) to uncover the necessary evidence from primary sources describing the testing of context-aware software systems outside academia.
Results
The current testing initiatives in non-academic settings aim to generate or improve test suites that can deal with the context variation and the sheer volume of test input possibilities. They mostly rely on modeling the systems' dynamic behavior and increasing computing resources to generate test inputs to achieve this. We found no evidence of test results aiming at managing context variation through the testing lifecycle process.
Conclusions
So far, the identified testing initiatives and strategies are not ready for mainstream adoption. They are all domain-specific, and while the ideas and approaches can be reproduced in distinct settings, the technologies are to be re-engineered and tailored to the context-awareness of contemporary software systems in different problem domains. Further and joint investigations in academia and experiences in non-academic settings can evolve the body of knowledge regarding the testing of contemporary software systems in the field.",Information and Software Technology,18 Mar 2025,6.0,"The abstract proposes a framework for cross-version defect prediction, showing improvements in performance compared to state-of-the-art approaches. The research addresses practical challenges in software development and could have a moderate impact on early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S095058492200088X,ST-TLF: Cross-version defect prediction framework based transfer learning,September 2022,Not Found,Yanyang=Zhao: Not Found; Yawen=Wang: wangyawen@bupt.edu.cn; Yuwei=Zhang: Not Found; Dalin=Zhang: Not Found; Yunzhan=Gong: Not Found; Dahai=Jin: Not Found,"Abstract
Context:
Cross-version 
defect prediction
 (CVDP) is a practical scenario in which 
defect prediction
 models are derived from defect data of historical versions to predict potential defects in the current version. Prior research employed defect data of the latest historical version as the training set using the empirical recommended method, ignoring the concept drift between versions, which undermines the accuracy of CVDP.
Objective:
We customized a 
S
elected 
T
raining set and 
T
ransfer 
L
earning 
F
ramework (ST-TLF) with two objectives: a) to obtain the best training set for the version at hand, proposing an approach to select the training set from the 
historical data
; b) to eliminate the concept drift, designing a transfer strategy for CVDP.
Method:
To evaluate the performance of ST-TLF, we investigated three research problems, covering the generalization of ST-TLF for 
multiple classifiers
, the accuracy of our training set matching methods, and the performance of ST-TLF in CVDP compared against state-of-the-art approaches.
Results:
The results reflect that (a) the eight classifiers we examined are all boosted under our ST-TLF, where 
SVM
 improves 49.74% considering 
MCC
, as is similar to others; (b) when performing the best training set matching, the accuracy of the method proposed by us is 82.4%, while the experience recommended method is only 41.2%; (c) comparing the 12 
control methods
, our ST-TLF (with BayesNet), against the best contrast method P15-NB, improves the average 
MCC
 by 18.84%.
Conclusions:
Our framework ST-TLF with various classifiers can work well in CVDP. The training set selection method we proposed can effectively match the best training set for the current version, breaking through the limitation of relying on experience recommendation, which has been ignored in other studies. Also, ST-TLF can efficiently elevate the CVDP performance compared with 
random forest
 and 12 
control methods
.",Information and Software Technology,18 Mar 2025,7.0,"The abstract studies the impact of magic literals in source code, providing qualitative and quantitative insights. The findings can potentially help improve source code comprehension and maintenance, which could benefit European early-stage ventures in software development."
https://www.sciencedirect.com/science/article/pii/S0950584922000908,What do developers consider magic literals? A smalltalk perspective,September 2022,Not Found,N.=Anquetil: nicolas.anquetil@inria.fr; J.=Delplanque: Not Found; S.=Ducasse: Not Found; O.=Zaitsev: Not Found; C.=Fuhrman: Not Found; Y.-G.=Guéhéneuc: Not Found,"Abstract
Context:
Literals are 
constant values
 (numbers, strings, etc.) used in the source code. 
Magic literals
 are such values used without an explicit explanation of their meaning. Such undocumented values may hinder source-code comprehension, negatively impacting maintenance. Relatively little literature can be found on the subject beyond the usual (and very old) recommendation of avoiding literals and preferring named constants. Yet, magic literals are still routinely found in source code.
Objective:
We studied literal values in source code to understand when they should be considered magic or not (i.e., acceptable).
Methods:
First, we perform a 
qualitative
 study of magic literals, to establish why and under which conditions they are considered harmful. We formalize hypotheses about the reasoning behind how literals are considered magic. Second, we perform a 
quantitative
 study on seven real systems ranging from small (a few classes) to large (thousands of classes). We report the literals’ types (number, string, Boolean, …), their 
grammatical function
 (e.g., argument in a call, operand in an expression, value assigned, …), or the purpose of the code in which they appear (test methods, regular code). Third, we report on another study involving 26 programmers who analyzed about 24,000 literals, to understand which ones they consider magic. Finally, we evaluate the 
hypotheses
 defining specific conditions under which literals are acceptable.
Results:
We show that (1) literals still exist and are relatively frequent (found in close to 50% of the methods considered); (2) they are more frequent in test methods (in 80% of test methods); (3) to a large extent, they were considered acceptable (only 25% considered magic); and (4) the hypotheses concerning acceptable literals are valid to various degrees.
Conclusion:
We thus pave the way to future research on magic literals, for example, with tools that could help developers deciding if a literal is acceptable.",Information and Software Technology,18 Mar 2025,8.0,"The abstract addresses the issue of systematic labeling bias in task assignment datasets and proposes a debiasing method. The results show significant improvements in task assignment techniques, which could directly impact the performance of software development tasks in European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001008,Cleaning ground truth data in software task assignment,September 2022,Not Found,K. Ayberk=Tecimer: ayberk.tecimer@tum.de; Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr; Cansu=Moran: cansu.moran@ug.bilkent.edu.tr; Hakan=Erdogmus: hakane@andrew.cmu.edu,"Abstract
Context:
In the context of 
collaborative software development
, there are many 
application areas
 of task assignment such as assigning a developer to fix a bug, or assigning a code reviewer to a pull request. Most task assignment techniques in the literature build and evaluate their models based on datasets collected from real projects. The techniques invariably presume that these datasets reliably represent the “ground truth”. In a project dataset used to build an automated task assignment system, the recommended assignee for the task is usually assumed to be the best assignee for that task. However, in practice, the task assignee may not be the best possible task assignee, or even a sufficiently qualified one.
Objective:
We aim to clean up the ground truth by removing the samples that are potentially problematic or suspect with the assumption that removing such samples would reduce any systematic labeling bias in the dataset and lead to 
performance improvements
.
Method:
We devised a debiasing method to detect potentially problematic samples in task assignment datasets. We then evaluated the method’s impact on the performance of seven task assignment techniques by comparing the Mean Reciprocal Rank (MRR) scores before and after debiasing. We used two different task assignment applications for this purpose: Code Reviewer Recommendation (CRR) and Bug Assignment (BA).
Results:
In the CRR application, we achieved an average MRR improvement of 18.17% for the three learning-based techniques tested on two datasets. No significant improvements were observed for the two optimization-based techniques tested on the same datasets. In the BA application, we achieved a similar average MRR improvement of 18.40% for the two learning-based techniques tested on four different datasets.
Conclusion:
Debiasing the ground truth data by removing suspect samples can help improve the performance of learning-based techniques in software task assignment applications.",Information and Software Technology,18 Mar 2025,7.0,"The abstract presents a debiasing method to improve the ground truth data in task assignment applications, leading to performance improvements in learning-based techniques. This research could contribute to enhancing software task assignment processes in European early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922001008,Cleaning ground truth data in software task assignment,September 2022,Not Found,K. Ayberk=Tecimer: ayberk.tecimer@tum.de; Eray=Tüzün: eraytuzun@cs.bilkent.edu.tr; Cansu=Moran: cansu.moran@ug.bilkent.edu.tr; Hakan=Erdogmus: hakane@andrew.cmu.edu,"Abstract
Context:
In the context of 
collaborative software development
, there are many 
application areas
 of task assignment such as assigning a developer to fix a bug, or assigning a code reviewer to a pull request. Most task assignment techniques in the literature build and evaluate their models based on datasets collected from real projects. The techniques invariably presume that these datasets reliably represent the “ground truth”. In a project dataset used to build an automated task assignment system, the recommended assignee for the task is usually assumed to be the best assignee for that task. However, in practice, the task assignee may not be the best possible task assignee, or even a sufficiently qualified one.
Objective:
We aim to clean up the ground truth by removing the samples that are potentially problematic or suspect with the assumption that removing such samples would reduce any systematic labeling bias in the dataset and lead to 
performance improvements
.
Method:
We devised a debiasing method to detect potentially problematic samples in task assignment datasets. We then evaluated the method’s impact on the performance of seven task assignment techniques by comparing the Mean Reciprocal Rank (MRR) scores before and after debiasing. We used two different task assignment applications for this purpose: Code Reviewer Recommendation (CRR) and Bug Assignment (BA).
Results:
In the CRR application, we achieved an average MRR improvement of 18.17% for the three learning-based techniques tested on two datasets. No significant improvements were observed for the two optimization-based techniques tested on the same datasets. In the BA application, we achieved a similar average MRR improvement of 18.40% for the two learning-based techniques tested on four different datasets.
Conclusion:
Debiasing the ground truth data by removing suspect samples can help improve the performance of learning-based techniques in software task assignment applications.",Information and Software Technology,18 Mar 2025,8.0,"The debiasing method presented in this abstract can significantly improve the performance of learning-based techniques in software task assignment applications, which can be highly valuable for early-stage ventures."
https://www.sciencedirect.com/science/article/pii/S0950584922000891,A literature review on optimization techniques for adaptation planning in adaptive systems: State of the art and research directions,September 2022,Not Found,Elia=Henrichs: elia.henrichs@uni-hohenheim.de; Veronika=Lesch: veronika.lesch@uni-wuerzburg.de; Martin=Straesser: martin.straesser@uni-wuerzburg.de; Samuel=Kounev: samuel.kounev@uni-wuerzburg.de; Christian=Krupitzer: christian.krupitzer@uni-hohenheim.de,"Abstract
Context:
Recent developments in modern IT systems including 
internet of things
, edge/fog computing, or cyber–physical systems support intelligent and seamless interaction between users and systems. This requires a reaction to changes in their environment or the system. Adaptive systems provide mechanisms for these reactions.
Objective:
To implement this functionality, several approaches for the planning of adaptations exist that rely on rules, 
utility functions
, or advanced techniques, such as 
machine learning
. As the adaptation space with possible options is often extensively huge, optimization techniques might support efficient determination of the adaptation space and identify the system’s optimal configuration. With this paper, we provide a 
systematic review
 of adaptation planning as the optimization target.
Method:
In this paper, we review which optimization techniques are applied for adaptation planning in adaptive systems using a systematic literature review approach.
Results:
We reviewed 115 paper in detail out of an initial search set of 9,588 papers. Our analysis reveals that learning techniques and 
genetic algorithms
 are by far dominant; in total, heuristics (anytime learning) are more frequently applied as exact algorithms. We observed that around 57% of the approaches target multi-objectiveness and around 30% integrate 
distributed optimization
. As last dimension, we focused on situation-awareness, which is only supported by two approaches.
Conclusion:
In this paper, we provide an overview of the current state of the art of approaches that rely on optimization techniques for planning adaptations in adaptive systems and further derive 
open research
 challenges, in particular regarding the integration of 
distributed optimization
 and situation-awareness.",Information and Software Technology,18 Mar 2025,6.0,"The systematic review of adaptation planning using optimization techniques provides insights into the current state of the art, but the practical impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922000891,A literature review on optimization techniques for adaptation planning in adaptive systems: State of the art and research directions,September 2022,Not Found,Elia=Henrichs: elia.henrichs@uni-hohenheim.de; Veronika=Lesch: veronika.lesch@uni-wuerzburg.de; Martin=Straesser: martin.straesser@uni-wuerzburg.de; Samuel=Kounev: samuel.kounev@uni-wuerzburg.de; Christian=Krupitzer: christian.krupitzer@uni-hohenheim.de,"Abstract
Context:
Recent developments in modern IT systems including 
internet of things
, edge/fog computing, or cyber–physical systems support intelligent and seamless interaction between users and systems. This requires a reaction to changes in their environment or the system. Adaptive systems provide mechanisms for these reactions.
Objective:
To implement this functionality, several approaches for the planning of adaptations exist that rely on rules, 
utility functions
, or advanced techniques, such as 
machine learning
. As the adaptation space with possible options is often extensively huge, optimization techniques might support efficient determination of the adaptation space and identify the system’s optimal configuration. With this paper, we provide a 
systematic review
 of adaptation planning as the optimization target.
Method:
In this paper, we review which optimization techniques are applied for adaptation planning in adaptive systems using a systematic literature review approach.
Results:
We reviewed 115 paper in detail out of an initial search set of 9,588 papers. Our analysis reveals that learning techniques and 
genetic algorithms
 are by far dominant; in total, heuristics (anytime learning) are more frequently applied as exact algorithms. We observed that around 57% of the approaches target multi-objectiveness and around 30% integrate 
distributed optimization
. As last dimension, we focused on situation-awareness, which is only supported by two approaches.
Conclusion:
In this paper, we provide an overview of the current state of the art of approaches that rely on optimization techniques for planning adaptations in adaptive systems and further derive 
open research
 challenges, in particular regarding the integration of 
distributed optimization
 and situation-awareness.",Information and Software Technology,18 Mar 2025,6.0,"Similar to abstract 177, while the overview of optimization techniques for adaptation planning is informative, the direct impact on European early-stage ventures may be limited."
https://www.sciencedirect.com/science/article/pii/S0950584922000854,Self-adaptive systems: A systematic literature review across categories and domains,August 2022,Not Found,Terence=Wong: terence.wong@adelaide.edu.au; Markus=Wagner: markus.wagner@adelaide.edu.au; Christoph=Treude: christoph.treude@unimelb.edu.au,"Abstract
Context:
Championed by IBM’s vision of 
autonomic computing
 paper in 2003, the 
autonomic computing
 research field has seen increased research activity over the last 20 years. Several conferences (SEAMS, SASO, ICAC) and workshops (SISSY) have been established and have contributed to the 
autonomic computing
 
knowledge base
 in search of a new kind of system — a self-adaptive system (SAS). These systems are characterized by being context-aware and can act on that awareness. The actions carried out could be on the system or on the context (or environment). The underlying goal of a SAS is the sustained achievement of its goals despite changes in its environment.
Objective:
Despite a number of literature reviews on specific aspects of SASs ranging from their requirements to 
quality attributes
, we lack a systematic understanding of the current state of the art.
Method:
This paper contributes a 
systematic literature review
 into self-adaptive systems using the dblp computer science 
bibliography
 as a database. We filtered the records systematically in successive steps to arrive at 293 relevant papers. Each paper was critically analyzed and categorized into an attribute matrix. This matrix consisted of five categories, with each category having multiple attributes. The attributes of each paper, along with the summary of its contents formed the basis of the literature review that spanned 30 years (1990–2020).
Results:
We characterize the maturation process of the research area from theoretical papers over practical implementations to more holistic and generic approaches, frameworks, and exemplars, applied to areas such as networking, web services, and robotics, with much of the recent work focusing on 
IoT
 and 
IaaS
.
Conclusion:
While there is an ebb and flow of application domains, domains like bio-inspired approaches, security, and cyber–physical systems showed promise to grow heading into the 2020s.",Information and Software Technology,18 Mar 2025,9.0,"The systematic literature review on self-adaptive systems provides a comprehensive understanding of the field over 30 years, which can be highly valuable for startups looking to implement such systems."
https://www.sciencedirect.com/science/article/pii/S0950584922000660,Combining multiple granularity variability in a software product line approach for web engineering,August 2022,"Annotations, Composition, Feature models, SPL, Variability, Web engineering",Jose-Miguel=Horcas: horcas@lcc.uma.es; Alejandro=Cortiñas: alejandro.cortinas@udc.es; Lidia=Fuentes: lff@lcc.uma.es; Miguel R.=Luaces: miguel.luaces@udc.es,"Abstract
Context:
Web engineering involves managing a high diversity of artifacts implemented in different languages and with different levels of 
granularity
. Technological companies usually implement variable artifacts of Software Product Lines (SPLs) using annotations, being reluctant to adopt hybrid, often complex, approaches combining composition and annotations despite their benefits.
Objective:
This paper proposes a combined approach to support fine and coarse-grained variability for web artifacts. The proposal allows web developers to continue using annotations to handle fine-grained variability for those artifacts whose variability is very difficult to implement with a composition-based approach, but obtaining the advantages of the composition-based approach for the coarse-grained variable artifacts.
Methods:
A combined approach based on feature modeling that integrates annotations into a generic composition-based approach. We propose the definition of compositional and annotative variation points with custom-defined semantics, which is resolved by a scaffolding-based derivation engine. The approach is evaluated on a real-world web-based SPL by applying a set of variability metrics, as well as discussing its quality criteria in comparison with annotations, compositional, and combined existing approaches.
Results:
Our approach effectively handles both fine and coarse-grained variability. The mapping between the feature model and the web artifacts promotes the traceability of the features and the uniformity of the variation points regardless of the 
granularity
 of the web artifacts.
Conclusions:
Using well-known techniques of SPLs from an architectural point of view, such as feature modeling, can improve the design and maintenance of variable web artifacts without the need of introducing complex approaches for implementing the underlying variability.",Information and Software Technology,18 Mar 2025,7.0,"The combined approach proposed for handling fine and coarse-grained variability in web artifacts can be beneficial for web developers, but the practical impact on European early-stage ventures may vary."
https://www.sciencedirect.com/science/article/pii/S0950584922000660,Combining multiple granularity variability in a software product line approach for web engineering,August 2022,"Annotations, Composition, Feature models, SPL, Variability, Web engineering",Jose-Miguel=Horcas: horcas@lcc.uma.es; Alejandro=Cortiñas: alejandro.cortinas@udc.es; Lidia=Fuentes: lff@lcc.uma.es; Miguel R.=Luaces: miguel.luaces@udc.es,"Abstract
Context:
Web engineering involves managing a high diversity of artifacts implemented in different languages and with different levels of 
granularity
. Technological companies usually implement variable artifacts of Software Product Lines (SPLs) using annotations, being reluctant to adopt hybrid, often complex, approaches combining composition and annotations despite their benefits.
Objective:
This paper proposes a combined approach to support fine and coarse-grained variability for web artifacts. The proposal allows web developers to continue using annotations to handle fine-grained variability for those artifacts whose variability is very difficult to implement with a composition-based approach, but obtaining the advantages of the composition-based approach for the coarse-grained variable artifacts.
Methods:
A combined approach based on feature modeling that integrates annotations into a generic composition-based approach. We propose the definition of compositional and annotative variation points with custom-defined semantics, which is resolved by a scaffolding-based derivation engine. The approach is evaluated on a real-world web-based SPL by applying a set of variability metrics, as well as discussing its quality criteria in comparison with annotations, compositional, and combined existing approaches.
Results:
Our approach effectively handles both fine and coarse-grained variability. The mapping between the feature model and the web artifacts promotes the traceability of the features and the uniformity of the variation points regardless of the 
granularity
 of the web artifacts.
Conclusions:
Using well-known techniques of SPLs from an architectural point of view, such as feature modeling, can improve the design and maintenance of variable web artifacts without the need of introducing complex approaches for implementing the underlying variability.",Information and Software Technology,18 Mar 2025,6.0,The proposed combined approach for handling fine and coarse-grained variability in web artifacts can potentially benefit early-stage ventures by improving design and maintenance without introducing complex approaches.
https://www.sciencedirect.com/science/article/pii/S0950584922000763,Improving Stack Overflow question title generation with copying enhanced CodeBERT model and bi-modal information,August 2022,Not Found,Fengji=Zhang: zhangfengji@whu.edu.cn; Xiao=Yu: xiaoyu@whut.edu.cn; Jacky=Keung: jacky.keung@cityu.edu.hk; Fuyang=Li: fyli@whut.edu.cn; Zhiwen=Xie: xiezhiwen@whu.edu.cn; Zhen=Yang: zhyang8-c@my.cityu.edu.hk; Caoyuan=Ma: macaoyuan@whu.edu.cn; Zhimin=Zhang: zhangzhimin@whu.edu.cn,"Abstract
Context:
Stack Overflow is very helpful for software developers who are seeking answers to programming problems. Previous studies have shown that a growing number of questions are of low quality and thus obtain less attention from potential answerers. Gao et al. proposed an LSTM-based model (i.e., BiLSTM-CC) to automatically generate question titles from the code snippets to improve the question quality. However, only using the code snippets in the question body cannot provide sufficient information for title generation, and LSTMs cannot capture the long-range dependencies between tokens.
Objective:
This paper proposes CCBERT, a 
deep learning
 based novel model to enhance the performance of question title generation by making full use of the bi-modal information of the entire question body.
Method:
CCBERT follows the encoder–decoder paradigm and uses CodeBERT to encode the question body into hidden representations, a stacked Transformer decoder to generate predicted tokens, and an additional copy attention layer to refine the output distribution. Both the encoder and decoder perform the multi-head self-attention operation to better capture the long-range dependencies. This paper builds a dataset containing around 200,000 high-quality questions filtered from the data officially published by Stack Overflow to verify the effectiveness of the CCBERT model.
Results:
CCBERT outperforms all the 
baseline models
 on the dataset. Experiments on both code-only and low-resource datasets show the superiority of CCBERT with less 
performance degradation
. The human evaluation also shows the excellent performance of CCBERT concerning both readability and correlation criteria.
Conclusion:
CCBERT is capable of automatically capturing the bi-modal 
semantic information
 from the entire question body and 
parsing
 the long-range dependencies to achieve better performance. Therefore, CCBERT is an effective approach for generating Stack Overflow question titles.",Information and Software Technology,18 Mar 2025,8.0,"CCBERT model shows superior performance in question title generation on Stack Overflow dataset, which can be valuable for startups seeking to enhance the quality of questions and user engagement on similar platforms."
https://www.sciencedirect.com/science/article/pii/S0950584922000775,How ReadMe files are structured in open source Java projects,August 2022,Not Found,Yuyang=Liu: yuyang@cs.toronto.edu; Ehsan=Noei: e.noei@utoronto.ca; Kelly=Lyons: kelly.lyons@utoronto.ca,"Abstract
Context:
Recent studies on 
open source platforms
, such as GitHub, provide insights into how developers engage with software artifacts such as 
ReadMe
 files. Since 
ReadMe
 files are usually the first item users interact with in a repository, it is important that 
ReadMe
 files provide users with the information needed to engage with the corresponding repository.
Objective:
We investigate and compare 
ReadMe
 files of open source Java projects on GitHub in order to (i) determine the degree to which 
ReadMe
 files are aligned with the official guidelines, (ii) identify the common patterns in the structure of 
ReadMe
 files, and (iii) characterize the relationship between 
ReadMe
 file structure and popularity of associated repositories.
Method:
We apply statistical analyzes and 
clustering methods
 on 14,901 Java repositories to identify structural patterns of 
ReadMe
 files and the relationship of 
ReadMe
 file structure to repository stars.
Results:
While the majority of 
ReadMe
 files do not align with the GitHub guidelines, repositories whose 
ReadMe
 files follow the GitHub guidelines tend to receive more stars. We identify 32 clusters of common 
ReadMe
 file structures and the features associated with each structure. We show that projects with 
ReadMe
 files that contain project name, usage information, installation instructions, license information, code snippets, or links to images tend to get more stars.
Conclusion:
ReadMe
 file structure shares a statistically significant relationship with popularity as measured by number of stars; however, the most frequent 
ReadMe
 file structures are associated with less popular repositories on GitHub. Our findings can be used to understand the importance of 
ReadMe
 file structures and their relationship with popularity.",Information and Software Technology,18 Mar 2025,5.0,"The study on GitHub ReadMe files provides insights into the relationship between file structure and repository popularity, which may be helpful for startups to understand how to format their ReadMe files for better engagement."
